Available online at www.sciencedirect.com


Electronic Notes in Theoretical Computer Science 296 (2013) 7–26
www.elsevier.com/locate/entcs

Backward Solution of Markov Chains and Markov Regenerative Processes: Formalization and Applications
Elvio G. Amparore1 and Susanna Donatelli2
Dipartimento di Informatica, Universita` di Torino, Italy

Abstract
In this paper we investigate the computation, and the stochastic interpretation, of backward probabilities of Markov chains (transient and steady-state probabilities derived from backward Kolmogorov equations) and its extension to the case of Markov Regenerative Processes (MRP). The study is then extended to the case of non-ergodic settings, which enlights a substantial difference between the forward solution process (based on forward Kolmogorov equations) and the backward one.
We shall clarify the role that backward solutions play in computing absorption probabilities and in the
model-checking of stochastic logics as CSL and CSLTA, which typically require the steady state solution of a non-ergodic CTMC and MRP respectively. Moreover we show that the algorithm for the computation of the whole set of states that satisfy a CSL formula, which is standard practice in CSL model-checkers, can be seen as a case of computation of backward probabilities of Continuous Time Markov Chains (CTMCs). The backward computation of MRP is then inserted in the context of matrix-free solution technique, which allows to deal with MRP of much bigger size than the standard approach based on the computation and solution of the embedded Markov chain.
Keywords: Stochastic Model Checking, Forward and Backward, Kolmogorov, MRP


Introduction
It is from the very first chapters of any performance evaluation book that we learn about backward and forward Chapman Kolmogorov equations for Discrete Time Markov Chains (DTMC) and Continuous Time Markov Chains (CTMC). But then most of the remaining topics in the books only deal with forward solution (from an initial state towards a target state) and dedicate a very limited attention to the backward case (from a target state back to possible initial states). So we could find no formal setting to deal with backward probabilities for non-ergodic (reducible)

1 Email:amparore@di.unito.it
2 Email:susi@di.unito.it

1571-0661 © 2013 Elsevier B.V. Open access under CC BY-NC-ND license.
http://dx.doi.org/10.1016/j.entcs.2013.07.002

systems, or for more complex stochastic processes, like Markov Regenerative Pro- cesses (MRP).
It is known that the computation of the forward probabilities of reducible CTMCs requires two steps: each recurrent class is solved in isolation, and this solution is normalized using the probability of entering each class from a given initial state or distribution. As we shall show in this paper, backward solution also has the interesting peculiarities of not requiring a two step procedure.
A second question answered in this paper is whether the same approach used for Markov chains can be applied to reducible and irreducible Markov Regenerative Processes (MRP).
The solution of an MRP is usually based on the steady state probabilities of its embedded Discrete Time Markov Chain (EMC) built upon the solution of a number of subordinated CTMCs, one per MRP state. This method is often inapplicable because of the cost of building and storing the EMC: indeed even for a very sparse MRP the resulting EMC is usually very dense. A different, matrix-free, approach has been presented in [13], later extended in [7], that does not require the explicit construction of the EMC, at the price of a more complex solution schema. In this paper we shall conclude that we can indeed go backward when dealing with MRPs (ergodic and non-ergodic), even in the more complex case of matrix-free solution.
There are some obvious applications of these results, for example for the compu- tation of the absorption probability (probability of reaching, from each state, a set of ”final” states) of Stochastic Petri Nets (SPN) [2] or of Determinstic SPN (DSPN) [1,19], which requires, respectively, a CTMC and an MRP solution.
A more recent application comes instead from stochastic model checking (or, more precisely, the model checking of stochastic logics) for Continuous Time Markov Chains (CTMC). Stochastic model checking allows to check whether a state s sat- isfies, in probability, a given condition, which is usually defined over the paths that stem from s in the CTMC, where a (timed) path is a possible (timed) execution of the CTMC process. The most popular of these logics is CSL [8][9]. CSL identifies paths of two fixed types, specified by the NeXt and the Until path operators, with additional conditions on the time constraints that have to be satisfied along the considered paths (timed Until and timed neXt). The computation of timed neXt is pretty immediate, and we shall not consider it in this paper, but to check if a single state s in a CTMC satisfies a timed Until requires instead the concatenated (usually transient) solution of two CTMCs, obtained from the original one by making certain states absorbing (as proved in [9]). Concatenated means that the solution of the first one is used as initial distribution of the second CTMC. The approach in [9] is based on the solution at time t of the forward Kolmogorov equations of the CTMC (forward solution).
Solving for one state at a time is not efficient when we need to compute Sat (ϕ), the whole set of states that satisfy a formula ϕ, as required in the computation of nested CSL formulas, since the same computation has to be repeated with each single state taken as the initial state of the CTMC. In [15] an algorithm is given that computes at the same time the whole set of states that satisfies ϕ with a procedure

that starts from the ”goal” states and computes backwards a vector of probabilities, in which the entry for state s is the probability that s satisfies the formula.
In this paper we formalize the computation done by the algorithm in [15] as backward Kolmogorov equations for CTMCs, and we write down the equations that allow to prove that backward and forward computation produce the same Sat set, but with backward being more efficient when the whole set of satisfying states has to be computed.
MRPs arise instead in the model checking of stochastic logics like CSLTA. CSLTA was defined in [11] as an extension of CSL (and of CSL with actions [14]) to allow a richer characterization of timed paths, identified through a single clock Timed automaton [3]. In [11] it was also shown that the model checking of CSLTA for- mulas for a CTMC requires the computation of the probability of reaching a set of absorbing states in a (reducible) Markov Regenerative Process. Again, nested formulas require the computation of the whole Sat set, and the question then arises on whether we can go backward or not in the solution of a reducible MRP.
Literature overview.
We could find very little work on backward solutions, apart from the classical backward and forward Kolmogorov equations for irreducible Markov chain. There is a clear relationship with the computation of absorbing probabilities [17], although it is usually not made explicit. We found no extension to the case of reducible DTMCs/CTMCs and no previous work at all on the backward solution of MRPs. Al- though most of the basic results on backward and forward probabilities for CTMCs have surely already been presented in various books and papers, we could not find a comprehensive treatment of these topics and of their implications on model checking algorithms.
The work in [15] is surely the most relevant previous work for this paper, as it provides the main motivation of this investigation. The paper is mainly devoted to the symbolic (decision diagram based) CSL model-checking. The “faster” (back- ward) solution of the title is presented as a pseudo-code algorithm, without any formal probabilistic derivation, its correctness being supported by a similar algo- rithm for the model-checking of the discrete case (PCTL logic for DTMCs), which was certainly adequate for the purpose of the paper, but that was not enough as a basis for an extension to MRPs, as the one we aimed at in this paper. This algo- rithm in [15] is the one currently implemented in tools like PRISM [18] and MRMC [16].
For what concerns CSLTA model checking, the work in [10] uses an iteration scheme that is basically a backward solution of the embedded DTMC, but this ob- viously requires the construction of the embedded DTMC, which has a time and space cost that we shall avoid with the proposal of a matrix-free backward solution.

The paper is structured as follows. Section 2 and 3 present backward and forward solution of DTMCs and CTMCs respectively. Both irreducible and reducible chains are considered. Section 4 applies the backward and forward solutions to the problem

of CSL model checking, to prove that they are equivalent, in terms of the solution computed, but that backward is faster if the whole Sat set is required (as for the algorithm in [15]). Section 5 recalls the definition of Markov Regenerative Processes (MRP) and derives a forward and backward solution for irreducible and reducible MRPs , while Section 6 extends the derivations to the matrix-free solution of MRPs, and Section 7 applies it to CSLTA. Section 8 concludes the paper.

Forward and backward solution of DTMCs
In this section we describe the forward and a backward computation of the transient and steady-state probabilities for irreducible and reducible DTMCs.
We indicate with D = {Yn | n ∈ N} a time-homogeneous Discrete Time Markov Chain (DTMC) defined over a finite state space S. Let P be the stochastic matrix of D. The dynamic behavior of a DTMC can be described in terms of forward probability or in terms of backward probability distributions, based on the forward and backward Chapman-Kolmogorov equations [23, p. 342].
Forward probabilities give the behavior of the evolution of the system after t time units, for a given initial fixed state i The probability of being in state j after n steps, knowing that at time 0 the state was i, is denoted by:
πD(i, j, n) = Pr{Yn = j | Y0 = i}	(1)
When we consider an initial distribution α rather than a single initial state, the vector πD(α, t) of forward state probabilities conditioned by α becomes:
πD(α, n) (j) =    α(i) · πD(i, j, n)	(2)
i∈S
Equation (2) is subject to the forward Chapman-Kolmogorov equations (for the time-homogeneous case), for n ≥ 0:
πD(α, n) = α · Pn	(3)
The j-th element of the vector πD(α, n) is the probability of reaching state j in n steps starting from an initial distribution α. When we need instead to compute the probability of reaching the fixed state j in n steps from every other state i, we need to recompute the above formula |S| times, one for each α = ii, ii being the indicator vector for state i.
Backward probabilities represent the probability that the system started in state
i at time 0, given that at step n is observed in a given destination state j:
ξD(i, j, n) = Pr{Y0 = i | Yn = j}	(4)
If we now consider a measure vector ρ over a target set of states at step n, we can introduce the backward probability vector ξD(ρ, n) that represents the backward probabilities conditioned by the target vector ρ:
ξD(ρ, n) (i) =   ρ(j) · ξD(i, j, m)	(5)
j∈S

Vector ξQ(ρ, n) does not represent a probability distribution: indeed it does not sum to one, and each entry is an independent quantity. When ρ = ij then the vector ξQ(ρ, n) gives the probability of reaching the fixed state j in n steps from each possible initial state i. Equation (5) is governed by the backward Chapman- Kolmogorov equation:
ξQ(ρ, n) = Pn · ρ	(6)
and it is important to observe that forward and backward probabilities are tied together by the relation:
πQ(α, n) · ρ = α · ξQ(ρ, n)	(7) which can be easily proven since: α · Pn · ρ = α · Pn · ρ .
As usual, the stationary behavior is defined as:
πQ(α) = lim πQ(α, n) = α · lim Pn	(8)
n→∞	n→∞
ξQ(ρ) = lim ξQ(ρ, n) = lim Pn · ρ	(9)
n→∞	n→∞
and again forward and backward are tied together by:
πQ(α) · ρ = α · ξQ(ρ)	(10)
We recall that for irreducible DTMCs, πQ(α) always exists, it is unique and inde- pendent of α ( πQ(α) = πQ(αj)). It is less known instead that the vector ξQ(ρ) depends on ρ (ξQ(ρ) /= ξQ(ρj)), and that each entry of the vector has the same value ξ (ξQ(ρ)[k] = ξQ(ρ)[l]) and ξ is uniquely dependent on ρ. Note that when ρ = is then the value ξ is exactly πQ(α) · is, so computing the whole vector of steady state probabilities backward has an extra cost of |S|.




Reducible DTMCs.
When D is reducible, its stochastic matrix P can be reordered as an upper triangular block form (the reducible normal form):


P = ⎢⎢⎣ .
1
.  . . .
. ⎥⎥⎦

0 0 ··· Rm
The state space S is partitioned into the set of transient states ST and m sets of recurrent states SRi (recurrent classes). The sub-matrix T is the sub-stochastic DTMC of the transient states ST. Each rectangular sub-matrix Fi is the probability matrix of going into the i-th recurrent class from ST. Each square sub-matrix Ri is the DTMC of the i-th recurrent class.

We now derive the structure of lim
Pn, as in equations (8) and (9) when P is

reducible. The powers of P are:

⎡ Tn Λ1(n) ··· Λm(n) ⎤

0	n	⎢
Rn
···	0

P = I,	P
. . .	⎥
⎢⎣ .	.	.	⎦


n−1
0	0	···	Rn

with Λi(n)= Σ Tk Fi Rn−k−1 and Λi(0) = 0.
k=0
The n-th power of P reveals the well-known structure of a reducible process after n steps: the process stays for k steps (k ≤ n) in the transient class ST, then a single Fi transition occurs and moves the process in the i-th recurrent class SRi, after which the process remains in SRifor the remaining (n−k−1) steps.
Transient forward and backward probabilities can then be rewritten from equa- tions (3) and (6) using the expression for Pk derived above; it is convenient to separate the part for the recurrent and transient states, to obtain:
πQ(α, n) = αT · Tn
πQ (α, n) = αT · Λi(n)+ αRi · Rn

Ri
ξQ(ρ, n) =
n
Λi(n) · ρRi
i=1
i
 + Tn · ρT
(11)

ξQ (ρ, n) = Rn · ρRi
Ri	i
Let J = Σ∞  Tk· be a matrix whose entries J(i, j) can be interpreted as the
mean number of discrete steps from state i to state j, without leaving the transient
set. Observe that since J = Σ∞  Tk = (I−T)−1, then it is possible to compute any
vector-matrix products with J in (12) as the solutions of a linear equation system in (I − T), instead of computing a product with J directly, i.e.:

for any measure vector b in the R|S| space.

Considering that	lim
Tn = 0, using the definition of J we can rewrite the

limiting behavior of Pn as:


n→∞
0	lim Rn
⎢
n→∞  m
···	0


0	0	···	lim Rn
n→∞  m

From which the limiting behaviors of (11) result in:
πQ(α) = 0


Ri
Σm 



n→∞  i
 


(12)

ξQ (ρ) = lim Rn · ρRi
Ri	n→∞  i
Observe that therefore the vector πQ(α) is zero in every transient state (as expected since we do not find the system in a transient state in the long run). Moreover, given a recurrent class SRi, since the vector αT·J·Fi can be interpreted as the probability of entering SRi in the long run, from the set ST, then the probability of the elements of a recurrent classes πQ (α) are obtained by multiplying the steady

state solution in isolation of each recurrent class ( lim
Rn) by a weighting vector.

For backward probabilities we can observe that ρ values associated to ST (ρT) have no influence on the probability of neither the transient states ( ξQ(ρ)) nor for recurrent states (ξQ (ρ)) . This is indeed a consequence of the fact that a transient state cannot be encountered as a target on the long run. Moreover the steady state backward probability of a recurrent state can be computed on the recurrent class in isolation (all the quantities in the equation for ξQ (ρ) refer only to the recurrent class SRi). As explained before, all the states of the same recurrent class have the same value of backward probability. More interesting is the case of backward probability of transient states ξQ(ρ), in which the probability of each recurrent class is “projected back” to the initial transient states through the multiplication with matrix Fi (one step probability of reaching SRi from ST) and matrix J (transient behavior).
The two relations (7) and (10) still hold for reducible Markov chains, which can be proven easily by expanding them with the terms of (12) and (11).
Note that when ρ is the indicator vector of a set of absorbing states then ξQ(ρ, n) is commonly known as “transient absorption probability”[17].

Forward and backward solution of CTMCs
Given a Continuous Time Markov Chain (CTMC) M = {Xt | t ∈ R}, with a finite state space S and infinitesimal generator Q, its evolution is governed by the forward/backward Kolmogorov differential equations [17, th. 2.3]. The probability of being in state j at time t, knowing that at time 0 the state was i, is denoted by:



or, in vector form:
πM(i, j, t) = Pr{Xt = j | X0 = i}	(13)

πM(α, t) (j) =	α(i) · πM(i, j, t)	(14)
i∈S

with α a probability distribution at time 0. Vector (14) is the solution of the forward Kolmogorov differential equation:

d πM(α, t) dt
= πM
(α, t) · Q	(15)

with entrance condition πM(α, 0) = α. The solution of (15) for t ≥ 0 is:
πM(α, t) = α · eQt	(16)
Backward probability gives the probability that M was in state i at time 0, given that at time t is observed in state j, is:
ξM(i, j, t) = Pr{X0 = i | Xt = j}	(17)

or, in vector form:

ξM(ρ, v) (i) =	ρ(j) · ξM(i, j, v)	(18)
j∈S

with ρ a measure vector over the target states at time t. The resulting vector is the solution of the backward Kolmogorov differential equation:

d ξM(ρ, t) dt
= Q · ξM
(ρ, t)	(19)

with exit condition ξM(ρ, t)= ρ. Solution of (19) is:
ξM(ρ, t) = eQt · ρ	(20)
Forward and backward formulas are tied by the relation:
πM(α, t) · ρ = α · ξM(ρ, t)	(21) which is equivalent to: α · eQt · ρ = α · eQt · ρ , and:
πM(α) · ρ = α · ξM(ρ)	(22)
The computation of the transient measures (16) and (20) may be carried out in many ways [21]; the popular uniformization method can be used also for backward probabilities, leading to the two following Taylor series expansion of the solution of the first-order constant coefficients ODE of the Kolmogorov differential equations:



πM(α, t) = α · eQt  = α ·
∞	e−qt(qt)n
n!
n=0
Un 


(23)

ξM(ρ, t) = eQt · ρ =
∞	e−qt(qt)n
n!
Un  · ρ

n=0
with q = − maxi∈S Q(i, i) and U = 1/qQ + I the uniformized matrix of Q. As usual,
U is the stochastic matrix of the mean behavior after a time step of 1/q.
With πM(α) and ξM(ρ) we denote the stationary forward and backward vectors of the CTMC. Many well-established algorithms exist for the computation of the limiting behavior of a CTMC.

Reducible CTMCs.
When the Markov process M is reducible, its infinitesimal generator Q can be written in reducible normal form:


Q = ⎢⎢⎣ .
1
.  . . .
. ⎥⎥⎦
(24)

0 0 ··· Rm
As for DTMCs, we derive the structure of lim

eQt to show how to derive tran-

sient and stationary (forward and backward) formulas. The powers of Q are:


0	n	⎢
0	Rn
···	0

Q = I,	Q
. . .	⎥
⎢⎣ .	.	.	⎦


n−1
0	0	···	Rn

with Λi(n)= Σ Tk Fi Rn−k−1 and Λi(0) = 0. The exponential of Q t is then:

k=0
⎡eTtΘ1(t)·· ·Θm(t)⎤

Σ Qn tn
0  eR1t ···	0

eQt =
n!
n=0
⎢⎣ .
.	. . .
R t ⎥⎦

0	0	··· e m
with the term Θi(t) defined as:

∞	n	∞
n−1	k
n−k−1 n	∞  ∞
n+k+1

Θ (t)= Σ Λi(n) t  = Σ Σ T
	

Fi Ri	t



= Σ Σ Tn F


Rk 	t	

The last factor can be rewritten:
tn+k+1

 1 	t
=	xn

(t − x)k dx

(n + k + 1)!	n! k!  0
so that the term Θi(t) can be reformulated:

Θi(t)= Σ
Tn
· Fi ·
 Σ∞
Rk ∫ t



xn (t − x)k dx  =

n!
n=0
k!
k=0

∫ t  Σ∞
Tn xn 



· Fi ·
 Σ∞
Rk (t − x)k 



dx =

0	n=0
∫ t  Tx

n!
R (t−x)
k!
k=0


This last equation can be interpreted as follows: the process initially passes x time units in the transient class ST, then one Fi transition occurs, after which the process spends the remaining time (t − x) in the i-th recurrent class.

Transient forward and backward equations for ST and SRi state partitions can then be rewritten as:
πM(α, t) = αT · eTt
πM(α, t) = αT · Θi(t)+ αRi · eRit

ξM(ρ, t)  =
m
Θi(t) · ρRi
i=1
 + eTt · ρT
(26)

ξM(ρ, t) = eRit · ρRi
By defining the term:

∞
W =	eTx
0
dx	(27)

which is the expected sojourn time matrix in the transient states, it is possible to rewrite the limit of Θi(t) by integration by parts:

lim Θi(t) =
t→∞
∞
eTx
0
dx · Fi · lim e
t→∞
Rit  =


The term  lim
= W · Fi · lim eRit	(28)
t→∞
eRit is the stationary stochastic matrix of the i-th recurrent class.

The limiting behavior of a reducible Markov chain is therefore:

	

lim eQt =
0	lim eR1t	···	0
t→∞

t→∞
. .
⎢⎣ .	.	.	.	⎥⎦

0	0	···	lim eRmt
t→∞
Since T has at least one row that has a negative rowsum, then the limiting

behavior of	lim
eTt  tends to 0. Therefore  lim
eQt has the column of ST states

zeroed, and the integral (27) is equivalent to: W = −T−1, so that a product with
W can be computed as the solution of a linear system in T. Stationary expressions for πM(α) and ξM(ρ) are:
πM(α) = 0


Ri
Σm 



t→∞
 

(29)

ξM(ρ) = lim eRit · ρRi
Ri	t→∞
and the considerations done for their discrete counterparts (12) hold also for (29).

Application to CSL model checking
We now show the role that backward and forward probabilities of CTMCs plays in the CSL model-checking of CTMCs. For the purpose of this paper we concentrate

on the key operator Until.
An Until formula of CSL has the form P  (Φ U [t,t′]Ψ); this formula is true for a state s of a CTMC M if the probability of the set of paths of M that starts in s (Pathsn(s)) and satisfies Φ U [t,t′]Ψ is da λ, where da ∈ {<, ≤, ≥, >} is a comparison operator. A timed path of M satisfies Φ U [t,t′]Ψ if it is ina Ψ-state at time u ∈ [t, tj], and ∀uj ∈ [0, u) the path passes only through Φ-states.
Model-checking of a formula θ comes in two variations: given a state s, to determine if that state satisfies the formula θ (written s |= θ), or to identify the set Sat (θ) ⊆S of states that satisfy θ
Givena timed Until formula ϕ = (Φ U [t,t′]Ψ), a state s satisfies the CSL formula Pdaλ(ϕ) if Probn(s, ϕ) da λ, where Probn(s, ϕ)= Pr{σ ∈ Pathsn(s) | σ |= ϕ} is the probability measure of all paths σ that start in s and satisfy ϕ. Therefore the model checking of CSL Until formula for CTMC reduces to the computation of the probability of a set of paths starting from a given state.
In [8] the quantity Probn(s, ϕ) was shown to be measurable, while [9] showed that the computation of Probn(s, ϕ) can be done with a (transient/steady state) solution of at most two CTMCs, derived from the original model M by making certain states absorbing. .
Central to the solution method is the idea of modiﬁed CTMC, obtained through the Sat -based filtering operator M[Φ] for a certain CSL formula Φ. The labeled CTMC M[Φ] is obtained by making absorbing all the states that satisfy Φ in M.
The formula for the Sat -set computation depends on the shape of the time interval I of Φ UI Ψ. The interval I can be I = [0, t], I = [t, t], or I = [t, tj], with 0 < t < tj. We first review the computation based on the forward approach, since it is more intuitive, and then we move to backward.
The classical formulas of the Until given in [9] are forward formulas, and we can express them as:
Probn(s, Φ U [0,t] Ψ) = i · πn[чΦVΨ] i , t Probn(s, Φ U [t,t] Ψ) = iΦΛΨ · πn[чΦ] is, t 

The vectors iΨ, iΦΛΨ and is are 1 in the states of Sat (Ψ), Sat (Φ ∧ Ψ) and {s}, respectively, and 0 in every other state. The IΦ is the identity matrix where rows corresponding to states that do not satisfy Φ are set to zero.
The intuition behind is simple. The probability Probn(s, Φ U [0,t] Ψ) is com- puted as the probability of being, at time t, in any Ψ-state on the modified CTMC M[¬Φ ∨ Ψ]. In the modified chain the Ψ states are absorbing, so even if a Ψ state is reached before t, the chain will still be in that state at time t, the time horizon for the transient probability computation. Similarly, if a ¬Φ-state sj is encountered before a Ψ state is reached, the modified chain stays trapped in sj, and that path will not be counted (unless sj is also a Ψ-state). Note the use of the inner product with iΨ to sum over all possible Ψ states, and that the computation of the transient probability assumes the modified chain is in state s at time 0 (initial vector is). The more complicated case of I = [t, tj] requires the path to stay in Φ-states during

the time interval [0, t], and then to behave as a path that satisfies Φ U [0,(t′—t)] Ψ). This requires the transient solution of two modified CTMCs: at time t, assuming we start in s at time 0, for the chain πn[чΦ] and at time tj − t, assuming we start at time 0 with a probability vector which is the result of the previous computation, for the chain πn[чΦVΨ]. Note that the result of the first computation is filtered out using the IΦ vector, to put to zero the probability of all states which are not Φ states: as a consequence the second transient analysis starts from an initial vector that does not necessarily sum up to one.
To check if a formula ϕ is true for a (single) given state s, can be particularly inefficient in case of nested formulas: to verify that s satisfies the nested formula: Pdaλ1 (X (Pdaλ2 (Φ U Ψ))) requires the computation of the Sat -set of the inner formula (Pdaλ (Φ U Ψ)) for each state sj ∈ S, which leads to a multiplicative factor of |S| in the time complexity. The work in [15] shows that it is actually possible to compute in a single step the whole Sat -set for a U formula, using a different computational scheme, derived from the one already used for PCTL that starts from the goal states and goes back to the initial ones.
Starting from the observation that the solution in [15] is actually a case of back- ward probability computation, we can write the formulas in terms of the backward operator ξn(ρ, v) and prove that forward/backward formulas are equivalent.
Using backward probabilities it is indeed possible to compute at the same time the vector of probabilities Probn(Φ U [t,t′] Ψ), which allows to identify the proba- bility of all the elements in the whole Sat set. We can then formalize the solution proposed in [15] by writing three equations in vector form for the three cases of the Until, based on the backward equation (17):

Probn(Φ U [0,t] Ψ) = ξn[чΦVΨ] i , t
Probn(Φ U [t,t] Ψ) = ξn[чΦ] iΦΛΨ, t 

The Prob formulas based on the backward ξn(ρ, v) probabilities are specular to the ones based on the forward πn(α, t) ones: the interval Until case is still computed in two steps, but the order in which the two modified chains are solved is reversed in the backward approach.


Model M:
Forward Until computation:
Backward Until computation:

M[¬Φ]	M[¬Φ ∨ Ψ]
M[¬Φ ∨ Ψ]
M[¬Φ]

s0	1
Φ  .3 .7
0

s0	s0	0
.3 .7	.7
0

0	s0
.7
0

s0  .7
.3  .3
⎫⎪⎪⎬

s1	.4 s2
s1	.4 s2
s1	s2
= Prob(s, ϕ)
s1	s2
s1	.4 s2
= Prob(ϕ)

∅	.3



Φ, Ψ	0	.3

		 

.3	1

	

1	.3

	


.3	⎪ Probability



Ψ
(a)
α0 =is
πt	πt'  iΨ
(b)	(c)
ρt'=iΨ
ξt	ξ0
(d)	(e)

with: πt = πM[¬φ](α0, t)
with: ξt
= ξM[¬Φ∨Ψ](ρ ' , t′ −t)

αt = IΦ · πt
M[¬Φ∨Ψ]
t'
(αt, t′ −t)
ρt = IΦ · ξt'
ξ = ξM[¬φ]
(ρt, t)

Figure 1. Numerical analysis of the CSL formula q =Φ C [t,t' ] Ψ on a simple model.

To better explain the relationship between the backward and forward approach, Figure 1 illustrates the numerical analysis based on the πn and ξn approaches for the until formula ϕ =Φ U [t,t′] Ψ. The initial CTMC is shown on the left (a). The central portion of Figure 1 illustrates the forward computation of Prob(s, ϕ) for an initial state s: a transient analysis at time t on the modified CTMC M[¬Φ] is done (b), then the probability of being in (¬Φ)-states is set to zero and the resulting vector is used as the initial distribution for the transient analysis (c) at time tj − t of the chain M[¬Φ ∨ Ψ]. The computed probability is then summed-up over all Ψ states by the cross product with iΨ. Looking along the time axis we can observe that the use of the behavior at time t as initial vector for the transient solution at time tj − t leads to the computation of the behavior of the system at time tj, and to the consequent choice of calling πt′ the vector resulting from the solution of
(c). The right portion of Figure 1 illustrates the computation of the entire Prob(ϕ) vector at once with the backward formula. The model checker starts by computing the backward probabilities for time tj −t on the goal vector iΨ, considered as the state at time tj, in the modified CTMC M[¬Φ ∨ Ψ] (d). In the resulting vector ξt the ¬Φ states are zeroed, to produce the measure vector ρt. Finally a backward probability analysis at time t is carried out on M[¬Φ] (e), using ρt as exit condition, leading to a vector ξ0. The set of states that satisfies the formula is then built by taking all states whose corresponding entry in ξ0 is da λ. It is then easy to link the forward and backward model checking through the following theorem
Theorem 4.1 Forward and backward computations of the probability of paths sat-

isfying P
daλ
(Φ U [t,t′]Ψ), for a given initial state s, lead to the same result.

Proof To prove this theorem, it is sufficient to reformulate each Prob formula with the relation of (21), which connect forward and backward probabilities:
Probn(s, Φ U [0,t] Ψ) = iΨ · πn[чΦVΨ] is, t	= ξn[чΦVΨ] iΨ, t  · is  =
= Probn(Φ U [0,t] Ψ) · is
Probn(s, Φ U [t,t] Ψ) = iΦΛΨ · πn[чΦ] is, t	= ξn[чΦ] iΦΛΨ, t  · is  =
= Probn(Φ U [t,t] Ψ) · is

Probn(s, Φ U [t,t′] Ψ)	= i
· πn[чΦVΨ] IΦ · πn[чΦ] is, t , tj−t  =

= πn[чΦ] i , t  · IΦ · ξn[чΦVΨ] i , tj−t	=
= ξn[чΦ] IΦ · ξn[чΦVΨ] iΨ, tj−t , t · is  =
= Probn(Φ U [t,t′] Ψ) · i
s
which proves the relation for each initial state s.	2
5	Forward and backward solution of MRPs
We now consider the forward and backward stationary analysis for Markov Regener- ative Processes (MRP). MRPs are stochastic processes where firing times can have a general distribution (general events). Events with an exponentially distributed firing times are called exponential events. A renewal time is a point in time where the value of every random variable g that accounts for the age of the (enabled) gen-

eral events are zero. States of the process encountered at renewal times are called regeneration points. When general events are restricted to be enabled at most one per state, the stochastic process is a Markov Regenerative Process, which can be described upon a Markov Renewal Sequence (MRS).
Definition 5.1 [Markov renewal sequence] Let S be a finite discrete state space of the MRP. A sequence of bivariate random variables {⟨Yn, Tn⟩| n ∈ N} is called a Markov renewal sequence with regeneration points Yn ∈ S encountered at renewal times Tn ∈ R≥0 iff:
0= T0 < T1 < T2 < . . .
Pr{Yn+1 = j, Tn+1−Tn ≤t | Yn = i, Tn ··· Y0, T0} = Pr{Y1 = j, T1 ≤ t | Y0 = i} The process Yn is a DTMC, called the embedded Markov chain (EMC).
Definition 5.2 [Markov regenerative process] A stochastic process R = {Xt | t ≥ 0} is a Markov regenerative process if there exists an MRS {⟨Yn, Tn⟩ | n ∈ N} such that all the conditional finite dimensional distributions of {XTn+t | t ≥ 0} given
{Xu | 0 ≤ u ≤ Tn, Yn = i} are the same of {Xt | t ≥ 0} given Y0 = i, so that:
Pr{XTn+t = j | Xu, 0 ≤ u ≤ Tn, Yn = i} = Pr{Xt = j | X0 = i}
The process behavior {Xt | Tn ≤ t < Tn+1} between two regeneration points Yn and Yn+1 is described by a continuous time process, called the subordinated process of Yn, that we assume to be a CTMC.
We use the notation of [12]. Let G be the set of random variables that describe the ages of the general events. Given g ∈ G, we denote with Fg(x) the ﬁring time distribution, and with fg(x) the density function of g.
The set SE ⊆S is the exponential state subset, where no general event is enabled; Sg is the set of states where g is enabled, and SG ≡ g∈G Sg is the general state subset. State transitions are classified into three kinds:
Transition due to a general event completion (ﬁring ).
Exponential event whose firing has no effect on the age of the enabled general transition (non-preemptive).
Exponential event whose firing resets the age of the currently enabled general transition (preemptive).
Events of the first and of the third type may only happen in a general state i ∈ SG.
The next state j depends on the current state i and on the age of the currently enabled general event g (if any), but not on the past history. We assume a preemptive repeat different policy for general events.
A sample dynamic of an MRP is depicted in Figure 2.
In Figure 2 the MRP process Xt passes through various states: from state x1 to state x4 a general event g is enabled, and this enabling ends with the firing event of g (denoted with a δ arc). The same happens from state x4 to x6, where the enabling of g ends due to an exponential event that disables g (denoted with a q¯ arc). The age of g is not 0 in states x2, x3 and x5, therefore these states are not regeneration points, and do not appear in the embedded process Yn.

An MRP can be described[12] by 3 matrices Q, Q¯
and Δ:

in SE

in Sg

in Sg

in SE

¸ x` ˛ 	x`		 x`
Xt
¸ x` ˛

x0	x1	x2 x3	x4 x5	x6	x7
Tn

t0
Yn
y0 = x0
t1	t2	t3	t4
y1 = x1	y2 = x4 y3 = x6 y4 = x7
Figure 2. Sample MRP dynamic.

Q(i, j), i /= j: non-preemptive exponential events rate from state i to state j;
Q¯ (i, j),i ∈ Sg: preemptive exponential events rate from state i to state j that
disables g enabled in i;
Q(i, i) is the negative sum of all the rates of exponential events leaving state i;
Δ(i, j),i∈Sg: probability that the firing of g in state i leads to state j.
Observe that Q¯ (i, i) can indeed be non-zero as well (a self-loop with preemption).

The diagonal of Q accounts for the rates of both Q and Q¯ . Rows of Q¯
corresponding to exponential states are zero.
and Δ

MRP formulas are simpler with the help of a ﬁltering notation. Let SU ⊆S be a subset of S, and let A be a matrix. With AU we denote the ﬁltered matrix where all rows which do not correspond to SU states are zeroed. For instance, IG, Q¯ g and QE are all filtered matrices w.r.t. the general and the exponential subsets of S.
The time evolution of the EMC follows all the regeneration points, and the evolution from one regeneration point Yn to the next is given by subordinated CTMCs (one CTMC per regeneration point) of state Yn.
Following [12], let Ωg be the state probability matrix in the instant before g ﬁres, defined for a subset Sg as:
g	g	g ∫ ∞ Qgx	g
	
Let Ψg be the conditional expected sojourn time matrix in the states of Xt from the enabling of g to the firing, defined for a subset Sg as:
Ψg(i, j) ≡ E[sojourn time of X in j, | Y0 = i, i ∈ Sg]= 
T1
=	Pr{X(τ )= j | Y0 = i, i ∈ £g} dτ

0	∞
= Ig
0
eQgx · (1 − Fg(x)) dx	(31)

We use the shorthand notations Ω = g∈G Ωg and Ψ = g∈G Ψg to denote the summations for each general event (30) and (31). Let diag—1(QE) be the diagonal matrix where the diagonal entry of each exponential state i ∈ SE is Q(i, i)—1, and 0 in every other entry. The stochastic matrix P of the EMC is then [12]:

P = IE − diag—1(QE)QE + ΩΔ+ ΨQ¯
along with its conversion factors matrix C:
(32)

C = −diag—1(QE) + Ψ	(33)

such that C(i, j)= E[sojourn time of X in state j | Y0 = i]. The conversion factors matrix is used to convert a state probability vector from discrete-time to continuous- time. Therefore if πQ(α) and ξQ(ρ) are the forward and backward stationary solution of the EMC, then the stationary solutions of the MRP process R at any time instant ( πR(α) and ξR(ρ)) can be obtained by multiplying πQ(α) and ξQ(ρ) with the conversion factors matrix C (with a proper normalization).

Forward and backward MRP iterative solutions with matrix-free products
Using P explicitly may not be feasible since the matrices defined by equations (32) and (33) tend to have dense portions, that make its storage impractical for large

systems even when Q, Q¯
and Δ are sparse matrices. This happens because Ω and

Ψ contain a matrix exponential, which generates the transitive closure of QG. This is the well-known problem of ﬁll-in, which has been studied in [20] and [13]. The solution in [13] consists in avoiding entirely the computation and the storage of P and C: every time a vector-matrix product is needed with these two matrices, it can be computed by expanding the expressions of (32) and (33).
Given the product: y = xP, it can be rewritten as:


= x IE −diag—1(QE)QE + xΩ Δ+ xΨ Q¯
A product: y = Px, can instead be written as:
y =  IE − diag—1(QE)QE + ΩΔ+ ΨQ¯ x =
(34)

=	IE−diag—1(QE)QE x + Ω Δx + Ψ Q¯ x	(35)
The four terms xΩ , xΨ , Ωx and Ψx of (34) and (35) are vector by matrix products that can be rewritten by expanding the matrix exponentials Ω and Ψ with their Taylor series expansions, resulting in the Jensen’s formulas [24] for transient and cumulative transient probabilities under the time distribution of g. Jensen’s formulas require only left and right vector multiplications with Qg.
The terms xΩ and xΨ can be expanded as:

xΩ =

gΣ∈G
Σ

∞
I
0
g ∫ ∞

x · e

Qgx


Qgx

· fg
(x) dx	(36)

g

A complete expansion of these equations can be found in [13]. The other two products Ωx and Ψx needed for backward formulas are as (36) and (37), with x on the right side of the exponential.
Forward stationary behavior of an irreducible EMC requires the fixed point solution of the linear equation system πQ(α) = πQ(α) · P. For instance, the iterative power method [22] algorithm uses only vector-matrix products with P, so

the steady-state solution can be computed with (34) or (35), avoiding the ﬁll-in of
P. Also Krylov-subspace methods uses only vector-matrix products, so they are suitable for a matrix-free solution of MRPs (as in [7]).

Reducible MRPs.
When the MRP is reducible, the EMC matrix P can be written in reducible normal form, derivable from a structural analysis of Q + Q¯ +Δ (as shown in [12, p. 237]). Also in this case it is very important to avoid the explicit construction of
P. In [7] the matrix-free products with the sub-matrices T, Fi and Ri of P were derived, as required by the equations in (12). In short, the products (xTT) and (T xT) are easily done by restricting the MRP to the ST states, i.e. by using QT, Q¯ T and ΔT. The same applies for (xRiRi) and (Ri xRi) using QRi, Q¯ Ri and ΔRi. It has been shown [7, sec. 5] that the product xT Fi can be computed from:
hx	0i · T Fi  =  xT T 

using the subset ST ∪ SRi. A similar schema can be derived for the transposed product (Fi xT). Since these products with the sub-matrices of an MRP can be done just by isolating the corresponding blocks in the generator matrices Q, Q¯ and
Δ, then forward and backward solutions can be computed avoiding the ﬁll-in even when the EMC is reducible.

Application to CSLTA model checking
CSLTA [11] is a stochastic logic which extends CSL by allowing a richer definition of paths, described as the accepted and rejected paths of a (timed) automaton that reads the language of CTMC paths. The CSLTA probabilistic path formula is written as Pdaλ(A), where A is a single-clock Deterministic Timed Automaton (DTA). A state s of a CTMC satisfies a formula Pdaλ(A) if the probability of the set of paths accepted by the DTA A is da λ.
CSLTA is a superset of CSL, since it is possible to express the neXt and the Until with two appropriate DTAs. The model checking of ϕ = Pdaλ(A) over a CTMC M is done as follows ([11, sec. III]). A new process M×A is constructed as the “synchronized product” of the CTMC M with the DTA A. This process M×A is an MRP that has a large initial transient and m ≥ 2 recurrent classes, of which two special absorbing classes ST and S⊥ are identified. The reducible normal form of the EMC P is therefore:


⎡

P = ⎢
⎢⎣
ST
SR1
SR(m—2) ST
S⊥
⎤

⎥
⎥⎦

The absorbing state in £T is the T-state, i.e. the state that is reached by A when the CTMC path is accepted. The computation of the Sat set of the CSLTA formula ϕ = Pdaλ(A) for an initial state s is equivalent to the problem of finding the steady state probability of being in the T state of the EMC of the process M×A, starting with α = is. Observe that T is a regeneration point of the M×A MRP, so it appears in the renewal sequence Yn, and therefore is an EMC state.
The forward probability measure is given by:
Probn×A(s) = iT · πn×A(is)	(38) where iT is 1 in T, and 0 otherwise. Since the only interesting value is the T
probability, we can rewrite (38) by expanding (12) with the matrix structure of P:
Probn×A(s) = is · (I — T)—1 · FT · 1	(39)
where 1 is a single element vector with value 1, and and FT is the single-step transition to T. The backward case for CSLTA is more interesting: the backward probability vector is defined as:
Probn×A = ξn×A(iT)	(40)
with ρ = iT. Therefore the backward probability ξn×A(ρ) is1 in £T and 0 in every other recurrent class. The values of ξn×A(ρ) are less trivial: we can simplify (40) by expanding (12) with the DTMC structure of M×A and obtain:
Probn×A = (I — T)—1 · FT · 1	(41)
which is simply the solution of the linear equations system:

(I — T) · Probn×A
= b	(42)

with b = FT · 1. Hence, the backward computation of the CSLTA formula ϕ reduces to the solution of (42). The two equations (38) and (40) are easily proven to be equivalent, since: iT · πn×A(is) = ξn×A(iT) · is by relation (22), which is similar to theorem 4.1 for CSL. Observe also that (39), (41) and (42) are computable with a ﬁll-in avoidance strategy for reducible MRPs.
Conclusions
In this paper we have discussed the computation and the possible applications of backward probabilities of Markov chains and Markov regenerative processes. All the equations and the outlined solution methods presented in this paper are available as concrete implementations, with accessible source code, at http://www.di.unito
.it/~amparore/DSPN.tgz, and are currently under integration in the existing (for- ward) CSLTA model checker MC4CSLTA [6], and in the DSPN solver DSPN-tool[5]. For CSL model checking the definition of backward probability provides a prob- abilistic formalization of the CSL model-checking algorithm given in [15], which is the basis for current CSL tools. It is known to be |£| times faster than a classical forward approach when nested formulas have to be evaluated, or when the whole Sat set is the goal. The probabilistic formalization also allows a clear understanding

of the dualism between forward and backward solutions of reducible CTMCs, which explain why a two-steps procedure it is not required by CSL model checkers, even if typically they need to solve non-ergodic CTMCs.
For MRPs we have shown that they can be solved backward with a matrix- free approach, and we are currently investigating whether the backward approach can be applied together with the decomposition-based solution of reducible MRPs proposed in [4]. This will pave the way for an efficient model-checking of CSLTA.

References
Ajmone Marsan, M. and G. Chiola, On Petri nets with deterministic and exponentially distributed firing times, in: Advances in Petri Nets, Lecture Notes in Computer Science 266/1987 (1987), pp. 132–145.
Ajmone Marsan, M., G. Conte and G. Balbo, A class of generalized stochastic petri nets for the performance evaluation of multiprocessor systems, ACM Trans. Comput. Syst. 2 (1984), pp. 93–122.
Alur, R. and D. L. Dill, A theory of timed automata, Theoretical Comp. Science 126 (1994), pp. 183– 235.
Amparore, E. and S. Donatelli, A Component-based Solution Method for Non-Ergodic Markov Regenerative Processes, in: EPEW, Lecture Notes in Computer Science 6342 (2010), pp. 236–251.
Amparore, E. G. and S. Donatelli, DSPN-Tool: a new DSPN and GSPN solver for GreatSPN, in:
International Conference on Quantitative Evaluation of Systems (2010), pp. 79–80.
Amparore, E. G. and S. Donatelli, MC4CSLTA: an efficient model checking tool for CSLTA, in:
International Conference on Quantitative Evaluation of Systems (2010), pp. 153–154.
Amparore, E. G. and S. Donatelli, Revisiting the Iterative Solution of Markov Regenerative Processes, Numerical Linear Algebra with Applications, Special Issue on Numerical Solutions of Markov Chains 18 (2011), pp. 1067–1083.
Aziz, A., K. Sanwal, V. Singhal and R. Brayton, Model-checking continuous-time Markov chains, ACM Trans. Comput. Logic 1 (2000), pp. 162–170.
Baier, C., B. Haverkort, H. Hermanns and J.-P. Katoen, Model-Checking Algorithms for Continuous- Time Markov Chains, IEEE Trans. Softw. Eng. 29 (2003), pp. 524–541.
Barbot, B., T. Chen, T. Han, J.-P. Katoen and A. Mereacre, Efficient ctmc model checking of linear real-time objectives, in: TACAS’11, 2011, pp. 128–142.
Donatelli, S., S. Haddad and J. Sproston, Model checking timed and stochastic properties with CSLTA, IEEE Transactions on Software Engineering 35 (2009), pp. 224–240.
German, R., “Performance Analysis of Communication Systems with Non-Markovian Stochastic Petri Nets,” John Wiley & Sons, Inc., New York, NY, USA, 2000.
German, R., Iterative analysis of Markov regenerative models, Performance Eval. 44 (2001), pp. 51–72.
Hermanns, H., J.-P. Katoen, J. Meyer-Kayser and M. Siegle, Towards model checking stochastic process algebra, in: Proceedings of the Second International Conference on Integrated Formal Methods, IFM ’00 (2000), pp. 420–439.
Katoen, J.-P., M. Z. Kwiatkowska, G. Norman and D. Parker, Faster and symbolic CTMC model checking, in: Proceedings of the Joint International Workshop on Process Algebra and Probabilistic Methods, Performance Modeling and Verification, PAPM-PROBMIV ’01 (2001), pp. 23–38.
Katoen, J.-P., I. S. Zapreev, E. M. Hahn, H. Hermanns and D. N. Jansen, The ins and outs of the probabilistic model checker MRMC, Performance Evaluation 68 (2011), pp. 90–104.
Kulkarni, V. G., “Modeling and analysis of stochastic systems,” Chapman & Hall Ltd., London, UK, 1995.
Kwiatkowska, M., G. Norman and D. Parker, PRISM: Probabilistic Model Checking for Performance and Reliability Analysis, ACM SIGMETRICS Performance Evaluation Review 36 (2009), pp. 40–45.


Lindemann, C., “Performance Modelling with Deterministic and Stochastic Petri Nets,” John Wiley & Sons, Inc., New York, NY, USA, 1998.
Malhis, L. M. and W. H. Sanders, An efficient two-stage iterative method for the steady-state analysis of Markov regenerative stochastic petri net models, Perform. Eval. 27/28 (1996), pp. 583–601.
Moler, C. and C. V. Loan, Nineteen dubious ways to compute the exponential of a matrix, SIAM Review
20 (1978), pp. 801–836.
Stewart, W. J., “Introduction to the numerical solution of Markov chains,” Princeton University Press, 1994.
Trivedi, K. S., “Probability and Statistics with Reliability, Queuing, and Computer Science Applications,” John Wiley and Sons Ltd., 2002, 632 pp.
Trivedi, K. S., A. L. Reibman and R. Smith, Transient analysis of Markov and Markov reward models, in: Computer Performance and Reliability ’87, 1987, pp. 535–545.
