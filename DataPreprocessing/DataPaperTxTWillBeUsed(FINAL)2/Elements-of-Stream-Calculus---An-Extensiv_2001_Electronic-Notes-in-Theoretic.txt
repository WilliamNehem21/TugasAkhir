Electronic Notes in Theoretical Computer Science 45 (2001)
URL: http://www.elsevier.nl/locate/entcs/volume45.html 66 pages


Elements of Stream Calculus (An Extensive Exercise in Coinduction)

J.J.M.M. Rutten
CWI, P.O. Box 94079, 1090 GB Amsterdam, The Netherlands
http://www.cwi.nl/~janr



Abstract
Based on the presence of a final coalgebra structure on the set of streams (infinite sequences of real numbers), a coinductive calculus of streams is developed. The main ingredient is the notion of stream derivative, with which both coinductive proofs and definitions can be formulated. In close analogy to classical analysis, the latter are presented as behavioural differential equations. A number of applications of the calculus are presented, including difference equations, analytical differential equations, continued fractions, and some problems from discrete mathematics and combinatorics.
Key words: Coinduction, coalgebra, finality, stream, derivative, differential equation, difference equation, Euler formula, counting, formal power series, weighted automaton




















◯c 2001 Published by Elsevier Science B. V. Open access under CC BY-NC-ND license.

Contents


Introduction
Treating infinite sequences of real numbers, called streams here, as single entities, a calculus of streams is developed in two ways:
as in analysis, involving stream differentiation and integration;
as in algebra, where one calculates with operators, and establishes iden- tities.
Starting point is the fact that the set Rω of all streams carries a ﬁnal coalgebra structure, consisting of the following pair of operations:
Rω	σ_
⟨O,T ⟩	J 
R	JR ω	⟨σ(0), σ'⟩
They assign to a stream σ = (s0, s1, s2,.. .) its initial value σ(0) ∈ R and its
stream derivative σ' ∈ Rω, which are defined by
σ(0) = s0
σ' = (s1, s2, s3,.. .)


(In computer science, these operators are usually referred to as head and tail .) Being a final coalgebra, the set Rω satisfies a coinduction proof principle and a coinduction deﬁnition principle, both formulated in terms of the notions of ini- tial value and stream derivative. We shall think of and deal with the operation of stream derivation in close analogy to classical analysis. Notably, coinduc- tive definitions take the shape of what we have called behavioural differential equations, defining streams and stream operators by means of equations that involve initial values and derivatives of streams (see Section 3 for some first
elementary examples). By means of such behavioural differential equations, many stream operators are introduced, some familiar (such as sum, convo- lution product, shuffle product) and some less familiar (for instance, shuffle inverse, stream exponentiation, square root). They are summarized in the following table:

A large number of basic and somewhat more advanced facts are proved. Among the most interesting ones are the identities for stream exponentia- tion and for shuﬄe elimination (Sections 8 and 10). All our reasoning, that is, almost all definitions and proofs, will be coinductive.


In addition to the development of the stream calculus itself, some applica- tions of the calculus are presented, relating to a number of different disciplines in mathematics:
discrete mathematics: solving difference equations (Sections 6 and 9) and a generalised Euler formula (Section 11);
analysis: solving differential equations (Section 12), and continued fractions (Section 17);
combinatorics: coinductive counting (Section 17).
In the ongoing work on coalgebra, the present paper can be seen as a study in concrete coalgebra, as opposed to the more general and abstract studies of universal coalgebra. Another way of putting this, as expressed by the subtitle of this paper, is to view stream calculus of a study of ‘coinduction at work’. We have tried to make the paper as self-contained as possible. In particular, everything the reader needs to know about coalgebra and coinduction, will be explicitly introduced.
In conclusion of this introduction, we briefly summarise related work, which will be discussed more extensively in Section 18.
The present paper builds on [25], by repeating some of its basics, extending its results on streams, and adding the applications mentioned above.
An important source of inspiration has been [22], both for the guiding role of analysis in the development of the present calculus, and for the application to analytical differential equations.
Generating functions are a classical tool in mathematics for reasoning about streams; [30] and [11] are two inspiring references. We believe coinductive stream calculus to be an alternative to the calculus of generating functions, being both more formal (essentially because of a rigid use of coinduction) and more expressive (because of the presence of a number of non-standard stream operators, such as shuffle inverse).
Formal power series (see [6]), which are often taken as the more formal version of generating functions, occur in the present paper towards the end (Section 14) under the name of multivariate streams. Again, we see some advantages in the use of some of the non-standard stream operators presented here, as well as in the use of the coinduction definition and proof principles.
Streams are a canonical example in the paradigm of lazy functional program- ming. Because of this close connection, behavioural differential equations can be interpreted as effective, directly implementable recipes for the step- wise generation of streams. Both [16,17] and [14,15] have served as very enjoyable sources of examples. One thing that coinductive stream calculus seems to add to this type of lazy functional programming, is coinduction as a systematic way of reasoning about streams.

Streams and coinduction
The set Rω of all streams is introduced. Using some elementary notions from universal coalgebra, Rω is shown to satisfy a proof principle called coinduction. Moreover, Rω is shown to have the universal property of being a final stream automaton (coalgebra). Finality will be the basis for coinductive definition schemata, in Section 3.
The set of all streams is formally defined by
Rω = {σ | σ : {0, 1, 2,.. .} → R }
We shall call σ(0) the initial value of σ. The derivative of a stream σ is defined, for all n ≥ 0, by
σ'(n) = σ(n + 1)
Although streams, which are infinite sequences of real numbers, will be viewed and handled as single mathematical entities, it will at various moments be convenient to refer to the individual elements of which they are made. For this, we shall use the following notation:
σ = (σ(0), σ(1), σ(2),.. .)
=  (s0, s1, s2,.. .)
(Similarly, we shall write τ = (t0, t1, t2,.. .) and the like.) With this notation, the derivative of σ is given by
σ' = (s1, s2, s3,.. .)
For any n  0, the real number σ(n) = sn is called the n-th element of σ. It can also be expressed in terms of higher-order stream derivatives, defined, for all k ≥ 0, by
σ(0) = σ,	σ(k+1) = (σ(k))'
Now the n-th element of σ is also given by
(1)	σ(n) = σ(n)(0)
In order to conclude that two streams σ and τ are equal, it is both necessary

and sufficient to prove (2)

∀ n ≥ 0, σ(n) = τ (n)

What general methods for establishing the validity of (2) are there? A straight- forward induction on the natural number n (prove σ(0) = τ (0) and show that σ(n) = τ (n) implies σ(n + 1) = τ (n + 1)) may seem the obvious answer, but very often it is not. There will be numerous occasions where we will have no workable description or formula for σ(n) and τ (n), and where, consequently, induction simply cannot be applied.
Instead, we shall take a coalgebraic perspective on Rω, and use almost exclusively the proof principle of coinduction, which is formulated in terms of the following notion from the world of universal coalgebra. A bisimulation on


Rω is a relation R ⊆ Rω × Rω such that, for all σ and τ in Rω,
if σ R τ then	σ(0) = τ (0) and
σ' R τ '
(Here σRτ denotes σ, τ  R; both notations will be used.) One easily checks that unions and (relational) compositions of bisimulations are bisimulations again. We write σ  τ whenever there exists a bisimulation R with σRτ . This relation , called the bisimilarity relation, is the union of all bisimulations and, therewith, the greatest bisimulation.
Theorem 2.1 [Coinduction] If two streams σ and τ are bisimilar: σ ∼ τ, then it follows that σ(n) = τ (n), for all n ≥ 0, and, consequently, σ = τ. That is, for all σ, τ ∈ Rω,
σ ∼ τ ⇒ σ = τ
(Note that the converse trivially holds, since σ, σ σ Rω is a bisimulation relation on Rω.) Thus in order to prove the equality of two streams σ and τ , it is sufficient to establish the existence of a bisimulation relation R ⊆ Rω × Rω with ⟨σ, τ ⟩ ∈ R.
Proof. Consider two streams σ and τ and let R ⊆ Rω × Rω be a bisimulation on Rω containing the pair ⟨σ, τ ⟩. It follows by induction on n that ⟨σ(n),τ (n)⟩ ∈ R, for all n ≥ 0, because R is a bisimulation. This implies, again because R is a bisimulation, that σ(n)(0) = τ (n)(0), for all n ≥ 0. By identity (1), σ(n) = τ (n), for all n ≥ 0. Now σ = τ follows.	✷
We shall see many examples of proofs by coinduction: one of the main reasons why we have become interested in Rω at all, is that it offers a perfect playground for demonstrating the use and usefulness of coinduction.
The word coinduction is also used as a term for certain definitions. This will be the subject of Section 3, where coinductive definitional schemata are introduced in terms of so-called behavioural differential equations. Such equa- tions can be shown to have unique solutions on the basis of a universal property of Rω, which we introduce next, again using a little bit of elementary universal coalgebra.
A stream coalgebra or automaton is a pair Q = (Q, o, t ) consisting of a set Q of states, together with an output function o : Q	R, and a transition function t : Q	Q. A homomorphism between stream automata (Q, o, t ) and (Q', o', t' ) is a function f : Q	Q' such that, for all q in Q, o(q) = o'(f (q)) and f (t(q)) = t'(f (q)) or, in other words, such that the following diagram commutes:
Q 	f	 Q '

' '

⟨o,t⟩
J 
⟨o ,t ⟩
J 

R × Q 1R×f R × Q'


(The function 1R × f maps a pair ⟨r, q⟩ ∈ R × Q to ⟨r, f (q)⟩ ∈ R × Q'.)
The set  of all streams can itself be turned into a stream automaton. Defining O : Rω   R by O(σ) = σ(0) and T : Rω   Rω by T (σ) = σ', we obtain a stream automaton (Rω, O, T ). It has the following universal property.
Theorem 2.2 The automaton (Rω, ⟨O, T ⟩) is final among the family of all stream automata. That is, for any automaton (Q, ⟨o, t⟩) there exists a unique homomorphism l : Q → Rω:
Q _ _ _∃!l_ _ zR ω

⟨o,t⟩
J 
⟨O,T ⟩
J ω

R	Q _ _ _ zR  R
1R×l

Proof. Let (Q, o, t ) be an automaton and let the function l : Q	Rω assign to a state q in Q the stream (o(q), o(t(q)), o(t(t(q))), .. .). It is straightfor- ward to show that l is a homomorphism from (Q, o, t ) to (Rω, O, T ). For uniqueness, suppose f and g are homomorphisms from Q to Rω. The equality of f and g follows by coinduction from the fact that R =	f (q), g(q)	q	Q is a bisimulation on Rω, which is proved next. Consider f (q), g(q)		 R. Be- cause f and g are homomorphisms, O(f (q)) = o(q) = O(g(q)). Furthermore, T (f (q)) = f (t(q)) and T (g(q)) = g(t(q)). Because f (t(q)), g(t(q))		 R, this shows that R is a bisimulation. Thus f (q)	g(q), for any q in Q. Now f = g follows by the coinduction proof principle Theorem 2.1.					✷

Behavioural differential equations
In stream calculus, streams and operators on streams will be defined by means of (systems of) behavioural differential equations, specifying their derivatives and initial values. Much of the theory of behavioural differential equations has been extensively dealt with in [25]. Here we shall summarize the main ideas by treating two typical examples, and refer the reader to [25] for more details. Moreover, as an appendix, Section 19 contains a theorem stating the unique existence of solutions for a rather general family of behavioural differential
equations, comprising about all the equations actually encountered in the present paper.
As a first and very elementary example, we prove that there exists a unique stream σ satisfying the following behavioural differential equation:

This example is so simple that the solution is immediate: take σ = (1, 1, 1,.. .) and note that, indeed, σ' = σ and that σ(0) = 1. Showing that this is the only


solution should not be too difficult, either. But just as an exercise, let us try to base our argument solely on coinduction and the finality of Rω. We shall benefit from this experience in the next example, which is no longer trivial. In order to find a solution, we define an automaton (S, o, t ), which contains one state: S = s . The automaton structure o, t is defined next in such a manner that this state behaves as the solution σ should behave according to the differential equation. Thus we define t : S  S by t(s) = s and o : S  R by o(s) = 1. By the finality of the automaton (Rω, O, T ) (Theorem 2.2), there exists a unique homomorphism l : S  Rω. We can now define σ = l(s). Because l is a homomorphism, σ' = T (σ) = T (l(s)) = l(t(s)) = l(s) = σ, and σ(0) = O(σ) = O(l(s)) = o(s) = 1, indeed. Thus we have found a solution of our behavioural differential equation. If ρ is a stream satisfying ρ' = ρ and ρ(0) = 1, then σ = ρ follows, by the coinduction proof principle Theorem 2.1, from the fact that σ, ρ  is a bisimulation relation of Rω. Which shows that σ is the only solution of the differential equation.
So this was easy and proving the unique existence of a solution for any of the equations we shall encounter will, in essence, be just as easy. The only difference will be that the design of the automaton (S, o, t ) generally requires a bit more work (for one thing, the state space S usually is infinite). All of this is very clearly illustrated by our second example, which defines the binary operators of sum and shuffle product. These operators will be motivated and discussed in all detail later. Without having any idea what these operators are about, here we just prove, mechanically as it were, that they are well-defined, again by exploiting coinduction and the finality of Rω.
We shall prove that for any two streams σ and τ , there exist unique streams σ + τ and σ τ , satisfying the following system of behavioural differential equations:

Note that it is not so easy now to see in one glance how the solutions should look like. Still, the equations can be rather straightforwardly interpreted as recipes for the construction of the respective elements of the solutions. For instance,
(σ ⊗ τ )(0)  =  σ(0) × τ (0)
(σ ⊗ τ )(1) = (σ ⊗ τ )'(0)
= (σ' ⊗ τ + σ ⊗ τ ')(0)
= σ'(0) × τ (0) + σ(0) × τ '(0)
= σ(1) × τ (0) + σ(0) × τ (1)
(σ ⊗ τ )(2) = (σ ⊗ τ )''(0)
= (σ' ⊗ τ + σ ⊗ τ ')'(0)


=  ··· 
=  σ(2) × τ (0) + 2 × σ(1) × τ (1) + σ(0) × τ (2)
and so on. This illustrates the algorithmic aspect of the behavioural differ- ential equations. A formal proof of the unique existence of their solutions, however, can be much better (and more generally) based on the finality of Rω, as follows. We construct what could be called a syntactic stream automaton, whose states are given by expressions including all the possible shapes that occur on the right side of the behavioural differential equations above. The so- lutions are then given by the unique homomorphism into Rω. More precisely, let the set E of expressions be given by the following syntax:
E ::= σ | E + F | E ⊗ F
The set E contains for every stream σ in Rω a constant symbol σ. The opera- tors that we are in the process of defining, are represented in E by a syntactic counterpart, denoted by the same symbols + and ⊗ again. The set E is next supplied with an automaton structure (E , ⟨o, t⟩) by defining functions o : E → R and t : E → E. For the definition of o and t on the constant symbols σ, the automaton structure (Rω, ⟨O, T ⟩) on Rω is used:
t(σ) = T (σ) = σ',  o(σ) = O(σ) = σ(0)
Thus the constant σ behaves in the automaton precisely as the stream σ behaves in the automaton Rω. (This includes Rω as a subautomaton in .) For composite expressions, the definitions of o and t literally follow the definition of the corresponding behavioural differential equations. Writing E(0) for o(E) and E' for t(E), for any expression E in E, we put

The above defines the functions o and t, by induction on the structure of the expressions. Since  now has been turned into an automaton ( , o, t ), and because Rω is a final automaton, there exists, by Theorem 2.2, a unique homomorphism l :	Rω, which assigns to each expression E the stream l(E) it represents. It can be used to define the operators on Rω that we are looking for, as follows:
σ + τ = l(σ + τ ),	σ ⊗ τ = l(σ ⊗ τ )
Using the coinduction proof principle (Theorem 2.1), these operators can now be shown to to be the unique solutions of the behavioural differential equations above.
The above two operators are the only ones in the present paper for which we provide a proof of well-definedness. ¿From now on, we shall without further ado introduce all kinds of streams and operators by means of behavioural differential equations. All of them can be justified in the same manner as


above, by coinduction and finality of Rω. A rather general theorem is presented in appendix Section 19, stating the well-definedness of a large class of (systems of) behavioural differential equations.
Taking the existence of solutions of behavioural differential equations from now on for granted, much energy will still be spent on the computation of closed formulae for such solutions, expressing them in terms of a basic set of stream constants and stream operators. We shall see, for instance, that the solution σ = (1, 1, 1,.. .) of the first example above, can be expressed by means of the following formula:
1
σ =
1 − X
which will be derived from the defining behavioural differential equation in an algebraic fashion. But now we are getting ahead of our story.

Basic stream calculus
A number of basic stream operators is introduced, by means of behavioural differential equations, and some elementary properties and examples are dis- cussed. The presentation of the various coinductive proofs in this section will at moments seem tediously detailed, but along the way, we shall establish some notions and results that will be very helpful in future, less elementary situations. An example is the introduction of the notion of bisimulation-up-to. First of all, we want to be able to view any real number as a constant stream.	For r	R, let [r] be the unique stream satisfying the following
behavioural differential equation:

Hadn’t we been obsessed with the use of our behavioural differential equations, we would have given the following definition, which is clearly equivalent:
[r] = (r, 0, 0, 0,.. .)
Having once formally introduced the inclusion of the reals into the set of streams by means of this operator [ ] : R  Rω, we immediately observe that there will in stream calculus hardly be any chance of confusing the stream [r] with the real number r it represents. Therefore we shall usually simply write r for [r].
The following equation defines one more constant. Let X be the unique stream satisfying

The constant X plays a crucial role in stream calculus, and may be thought


of as a formal variable. Again, there is a more explicit equivalent definition:
X = (0, 1, 0, 0, 0,.. .)
Next we repeat the definition of the operation of sum that we have already seen as an example in Section 3. The sum σ + τ of two streams σ and τ is defined as the unique stream satisfying:

(Note that we are using the same symbol + both for the sum of streams and the sum of real numbers.) Alternatively and equivalently, the sum of σ = (s0, s1, s2,.. .) and τ = (t0, t1, t2,.. .) is given by
σ + τ = (s0 + t0, s1 + t1, s2 + t2, .. .)
Sum satisfies the following familiar identities: For all σ, τ, ρ ∈ Rω,
σ +0 = σ
σ + τ = τ + σ
σ + (τ + ρ) = (σ + τ )+ ρ
Here is a first very easy exercise in coinductive reasoning:
Proof of (3): Let R =	σ + τ, τ + σ	σ, τ	Rω .  Since (σ + τ )(0) =
σ(0) + τ (0) = (τ + σ)(0) and
(σ + τ )'  =  (σ' + τ ')
R  (τ ' + σ')
=  (τ + σ)'
for any σ and τ , R is a bisimulation relation on Rω. The identity now follows by coinduction (Theorem 2.1).	✷
For the motivation of the next operator, let us briefly look at the world of (real-valued) functions, which at more than one occasion, will be a source of inspiration for stream calculus. Consider a function f : R → R and a stream (of coefficients) σ = (s0, s1, s2,.. .) such that f (x) = s0 + s1x + s2x2 + ·· ·.
Writing f¯(x) = s1 + s2x + s3x2 + ·· ·, we have
f (x) = s0 + (x × f¯(x))
Let g : R → R and τ = (t0, t1, t2,.. .) be another such function and stream, with g(x) = t0 + t1x + t2x2 + ··· and write, similarly, g(x) = t0 + (x × g¯(x)).
Computing now the (elementwise) function product f (x) × g(x), one finds
f (x) × g(x)
= (s0 + (x × f¯(x))) × (t0 + (x × g¯(x)))
= (s0 × t0)+ x × (f¯(x) × g(x) + s0 × g¯(x))
This is one way of motivating the following definition. (An alternative, equally valid way would be to view streams as sets of words, that is, languages, with


multiplicities, and stream concatenation as language concatenation. More about this later.) Let the convolution product σ  τ of two streams σ and τ be the unique stream satisfying:

(Note that we are using the same symbol  both for the product of streams and the product of real numbers. Further note that in the above definition, σ(0) × τ ' is a shorthand for [σ(0)] × τ '.) We shall use the following standard conventions: for all n ≥ 0,

−σ ≡ [−1] × σ,	στ ≡ σ × τ,	σ
≡ 1,	σ
n+1
≡ σ × σ

On the basis of the analogy between function multiplication and stream mul- tiplication, one might have expected
(σ × τ )' = (σ' × τ )+ (σ × τ ')
which generally is not valid, indeed. Apparently, stream differentiation does not quite correspond to function derivation in analysis. Rather, it corresponds

to the above transformation of a function f into
f¯, an operation which is

not usually present in analysis. Later we shall see variations on both the notion of stream derivative and the operator of multiplication, which have more familiar properties. Let it be noted, however, that in stream calculus, both the operations of stream derivative and of convolution product, with their non-standard properties, are of central importance.
There is also the following formula for the n-th element of σ × τ , for any
n ≥ 0,


n
(σ × τ )(n) =	σ(n − k) × τ (k)
k=0

which could have been (and traditionally is) taken as an alternative definition of σ τ . (Since it will play no role in what follows, a proof of this identity, which would not be too difficult, is omitted.) Note that stream product shares this property with the function product considered above, since
f (x) × g(x) = s0t0 + (s1t0 + s0t1) × x + (s2t0 + s1t1 + s0t2) × x2 + ··· 
As we shall see time and again, coinductive reasoning directly in terms of the above behavioural differential equation is quite a bit simpler than the use of (5), because of the summation over the indices k and (n k) in the latter. (Equally importantly, we shall see examples of other definitions, such as that of inverse below, where no formula for the n-th element is known.)
Having constants, sum, and product at our disposal, we are ready to for- mulate the first theorem of stream calculus. First we state the following basic properties


0 × σ  =  0
1 × σ  =  σ
[r] × [s] = [r × s]
which are immediate by rather trivial coinduction.
Theorem 4.1 [Fundamental Theorem]
For all streams σ ∈ Rω: σ = σ(0) + (X × σ').
The name ‘Fundamental Theorem’ is chosen in analogy to analysis. Viewing left multiplication with the constant stream X as a kind of stream integration, the theorem tells us that stream derivation and stream integration are inverse operations: the equality gives a way of obtaining σ out of σ' (and the initial value σ(0)). As a consequence, the Fundamental Theorem enables us to solve differential equations in stream calculus in an algebraic manner, which will be the subject of Section 5.

Proof of Theorem 4.1:
Define R = {⟨σ, σ⟩ | σ ∈ Rω}∪ {⟨σ, σ(0) + (X × σ')⟩ | σ ∈ Rω}. We have
σ' R  σ'
= (σ(0) + (X × σ'))'
from which it follows that R is a bisimulation (all other conditions that are to be checked are trivial). The theorem follows therefore by coinduction.   ✷

The proof of the following basic property of stream product introduces a gen- eralisation of the coinduction proof principle that turns out to be extremely useful:
σ × (τ + ρ) = (σ × τ )+ (σ × ρ)

Proof of (6): Let Q =  σ  (τ + ρ), (σ  τ )+ (σ  ρ)  σ, ρ, τ  Rω . The initial values of the first and second components of such pairs are clearly the same. Computing derivatives, we find
(σ × (τ + ρ))'	=	(σ' × (τ + ρ)) + (σ(0) × (τ ' + ρ'))
Q + Q  ((σ' × τ )+ (σ' × ρ)) + ((σ(0) × τ ')+ (σ(0) × ρ'))
=	((σ' × τ )+ (σ(0) × τ ')) + ((σ' × ρ)+ (σ(0) × ρ'))
[using (3) and (4)]
=	((σ × τ )+ (σ × ρ))'
where Q + Q has the obvious meaning: for all α, β, γ, δ ∈ Rω, (α + β) Q + Q (γ + δ) iff (αQ γ) and (β Q δ)
We see that the derivatives themselves are not related by Q, but each consists of a sum of streams that are pairwise related. This type of relation is an instance of the following generalisation of the notion of bisimulation.


A relation R	Rω	Rω is a bisimulation-up-to if, for all σ, τ	Rω: if
σ R τ then
σ(0) = τ (0)
There exist n ≥ 0, α0,..., αn, β0,..., βn ∈ Rω, such that σ' = α0+·· ·+αn
and τ ' = β0 + ··· + βn and, for all 0 ≤ i ≤ n: either αi = βi or αi R βi.
The latter condition will usually be denoted by
α0 + ··· + αn (ΣR) β0 + ··· + βn
thus generalising our notation Q + Q from above.
Theorem 4.2 [Coinduction-up-to] For all σ, τ ∈ Rω:
(∃ R, bisimulation-up-to: σ R τ ) ⇒ σ = τ
Proof. Let R  Rω Rω be a bisimulation-up-to with σ R τ . Let R¯ be the smallest relation satisfying
R ⊆ R¯
{⟨σ, σ⟩ | σ ∈ Rω} ⊆ R¯
for all α0, α1, β0, β1 ∈ Rω, if α0 R¯ β0 and α1 R¯ β1 then (α0 +α1) R¯ (β0 +β1).
Using the fact that R is a bisimulation-up-to, one can easily prove by induction on the definition of R¯ that the latter is an (ordinary) bisimulation relation on Rω. Since R  R¯, the theorem follows by (ordinary) coinduction, Theorem
2.1.	✷

Proof of (6), continued: Clearly the relation Q introduced above is a bisimulation-up-to. The identity now follows by coinduction-up-to.	✷


Similarly, one proves (7)

(τ + ρ) × σ = (τ × σ)+ (ρ × σ)


Stream product is also associative:
σ × (τ × ρ) = (σ × τ ) × ρ

Proof of (8): Define R =	σ	(τ	ρ), (σ	τ )	ρ	σ, τ, ρ	Rω . Initial values are okay and computing derivatives gives
(σ × (τ × ρ))'
=	σ' × (τ × ρ) + σ(0) × (τ ' × ρ + τ (0) × ρ')
=	σ' × (τ × ρ) + σ(0) × (τ ' × ρ) + σ(0) × (τ (0) × ρ')	[using (6)]
ΣR  (σ' × τ ) × ρ + (σ(0) × τ ') × ρ + (σ(0) × τ (0)) × ρ'
=	(σ' × τ + σ(0) × τ ') × ρ + (σ(0) × τ (0)) × ρ'	[using (7)]
=	((σ × τ ) × ρ)'


Thus R is a bisimulation-up-to, and identity (8) follows by coinduction-up-to.
✷

Stream product is commutative:
σ × τ = τ × σ
even though the shape of its defining behavioural differential equation is not symmetric. (Later we shall benefit from this asymmetry, since the definition of product can be immediately generalised to streams over alphabets of many variables. For such streams, product will no longer be commutative.) Identity
(9) is an easy consequence of (5), but let us try to resist the temptation offered by the use of explicit formulae for the elements of streams, and present a proof by coinduction.
Proof of (9): The following identities will be used as lemmata in the proof. For all r ∈ R, σ ∈ Rω,




r × σ = σ × r
(X × σ)' = σ
σ × X = X × σ

The first two identities are easy. For (12), define R = {⟨σ × X, X × σ⟩ | σ ∈
Rω}. Since
(σ × X)'	=	(σ' × X)+ σ(0)
=	σ(0) + (σ' × X)
ΣR  σ(0) + (X × σ')
=	σ	[Theorem 4.1]
=	(X × σ)'	[by (11)]
R is a bisimulation-up-to, and identity (12) now follows by coinduction-up- to. Next let Q =  σ  τ, τ  σ  σ, τ  Rω . Initial values coincide and computing derivatives gives
(σ × τ )'	=	((σ(0) + (X × σ')) × τ )'	[Theorem 4.1]
=	(σ(0) × τ )' + (X × σ') × τ ))'
=	(σ(0) × τ )' + (σ' × τ )	[identity (11)]) ΣR (σ(0) × τ )' + (τ × σ')
=	(τ × σ(0))' + (X × (τ × σ'))'	[identities (10) and (11)]
=	(τ × σ(0))' + (τ × (X × σ'))'	[identity (12) ]
=	(τ × (σ(0) + (X × σ')))'
=	(τ × σ)'	[Theorem 4.1]
This proves that Q is a bisimulation-up-to and (9) follows by coinduction-up- to.	✷
As was already suggested by the comparison between function product and stream product, streams can be viewed as power series in one formal variable


(namely, the constant stream X). In order to make this more precise, we need to introduce generalised sums of streams. Countable ones will be sufficient for our purposes. Let therefore σ0, σ1, σ2,... be a sequence of streams such that, for all k 0, σ0(k)+ σ1(k)+ σ2(k)+ < . Such a sequence is called summable. We define:



Often we shall also write

∞
σn
n=0

= σ0

+ σ1

+ σ2

+ ··· 

Infinite sum is as well-behaved as binary sum. For instance, we have

( ∞
n=0
σ ) × τ = ∞ (σ
n=0
× τ )

and similarly for the other basic properties of sum. For the proof of the theorem below, we shall need the following basic property, which can be easily proved by induction: for all n ≥ 0,


(Xn+1)' = Xn

Theorem 4.3 For all streams σ = (s0, s1, s2,.. .), the sequence of streams
s0, s1 × X1, s2 × X2, ... 
is summable, and satisﬁes
σ = s0 + (s1 × X1) + (s2 × X2) + ··· 
Proof. Using the defining equation for infinite sum; the fact that if a stream σ is summable, then also σ' is summable; and identity (13), the proof is a straightforward coinduction.	✷

Streams for which the power series on the right is finite, are called polynomial . That is, a stream π is polynomial if there exists n ≥ 0 and real numbers p0, p1,... pn such that
π = p0 + p1X + ··· + pnXn = (p0, p1,..., pn, 0, 0, 0,.. .) For instance,
1	X = (1,	1, 0, 0, 0,.. .)
1+ 7X + √2X5 = (1, 7, 0, 0, 0, √2, 0, 0, 0,.. .)
both are polynomial.
Before we show some applications of Theorem 4.3 (identities (19)-(25) be- low), we first introduce an operator on streams that is inverse to multiplication in the following sense. Given a stream σ, we look for a stream σ−1 such that σ × σ−1 = 1. Constant streams [r] = (r, 0, 0, 0,.. .) with r /= 0, clearly have


[r]−1 = (r−1, 0, 0, 0,.. .) = [r−1] as their inverse. Considering now an arbitrary stream σ with σ(0) = 0, and assuming for a second that σ−1 indeed existed, it would have to satisfy
0 = 1' = (σ × σ−1)' = σ' × σ−1 + σ(0) × (σ−1)'
Multiplying (on the left) with the inverse of (the stream) σ(0), one obtains
(σ−1)' = −σ(0)−1 × (σ' × σ−1)
Thus the equation 1 = σ σ−1 determines what (σ−1)' should be. It also determines the initial value (σ−1)(0) = σ(0)−1. What has happened is that we have derived from our ‘specification’ σ σ−1 = 1 a behavioural differential equation, which we can now simply take as the definition of inverse. For all σ ∈ Rω with σ = 0, let σ−1 be the unique stream satisfying the following equation:

Whenever writing σ−1, we shall silently assume that σ(0) = 0. As usual, we shall write
σ−n ≡ (σ−1)n,	σ ≡ σ × τ −1
With this convention, we can write (σ−1)' as

( 1 )' =
σ
−σ'

σ(0) × σ

which is a bit easier to remember. (For similar reasons as with stream mul- tiplication, stream derivation of inverse behaves differently from what we are used to in analysis. In particular, (σ−1)' = −σ' × σ−2 generally does not hold.) Was our preference to use behavioural differential equations for the def-
inition of the operators so far based on either obsession (the constants) or computational convenience (product), in the case of inverse, it turns out to be essential. For inverse, no explicit formula such as (5) for product, is known (not in the literature, not to us):
1
(  )(n) = ?
σ
(The best one can do is to define inverse by means of a recurrence relation as follows. The elements of σ−1 are given by σ−1(0) = σ(0)−1 and
Σn−1

for n	1. This is an immediate consequence of the requirement that σ σ−1 = 1 and identity (5) above. Note that this recurrence is of so-called unbounded order: the n-th element σ−1(n) depends on all of the n preceding values σ−1(0) through σ−1(n	1). Reasoning in terms of such recurrences is not only extremely tedious but even next to impossible.)


The good news is that in stream calculus, there is no need for a closed formula for σ−1(n). All our reasoning about inverse, in fact about all streams and stream operators, will be coinductive, calculating with stream derivatives as specified by behavioural differential equations. For instance, the following properties are readily verified by coinduction: for all σ, τ ∈ Rω,





σ × σ−1 = 1 σ−1 × σ = 1 (σ−1)−1 = σ
(σ × τ )−1 = τ −1 × σ−1


Proof of (14)-(17): For identity (14) note that
(σ × σ−1)' =  (σ' × σ−1)+ (σ(0) × (−σ(0)−1 × σ' × σ−1))
=  (σ' × σ−1)+ (−σ' × σ−1)
=  0
and coinduction does the rest. Identity (15) clearly follows from (14) and the commutativity of convolution product (9). A direct coinductive proof not using the latter is also possible and is interesting in itself, since it will also apply to the inverse operator in the multivariate case in Section 15, where product will no longer be commutative. So we let
R = {⟨ρ × (σ−1 × σ), ρ⟩ | ρ, σ ∈ Rω}
and calculate as follows to see that R is a bisimulation-up-to: (ρ × (σ−1 × σ))'	=	ρ' × (σ−1 × σ) + 
ρ(0) × ((−σ(0)−1 × σ' × σ−1) × σ + (σ(0)−1 × σ'))
=	ρ' × (σ−1 × σ) −
ρ(0) × σ(0)−1 × σ' × (σ−1 × σ) + 
ρ(0) × σ(0)−1 × σ'
ΣR ρ' − (ρ(0) × σ(0)−1 × σ') + (ρ(0) × σ(0)−1 × σ')
=	ρ'
Identity (15) then follows by coinduction-up-to. For (16), note that ((σ−1)−1)' = −(σ−1(0))−1 × (σ−1)' × (σ−1)−1
=  −σ(0) × (−σ(0)−1 × σ' × σ−1) × (σ−1)−1
= σ' × (σ−1 × (σ−1)−1)
= σ'  [by identity (14)]
and use coinduction. Identity (17) follows from
(σ × τ ) × (τ −1 × σ−1) = σ × (τ × τ −1) × σ−1
= σ × σ−1
=  1
and the observation, by (14), that inverse is uniquely defined.	✷


Here are a few examples of streams involving the operation of inverse. The stream (1 X)−1 is particularly well-behaved in that it equals its own deriva- tive:


1
(
1 − X
)' =	1
1 − X

(We shall elaborate extensively on this fact later.) As an immediate conse- quence, one has


 1	 = 1 + X + X2 + X3 + 1 − X

or, in a notation that emphasises the fact that we are dealing with streams,
1



(1, −1, 0, 0, 0,.. .)
=  (1, 1, 1,.. .)

Here are some further identities:
X × (s0, s1, s2,.. .) = (0, s0, s1, s2,.. .)










1


1+ X
	1	
1	X2
	1	
(1	X)2
	1	
1	rX
  X	
1+ X2
= 1 − X + X2 − X3 + ··· 
=  1 + X2 + X4 + ··· 
=  1 + 2X + 3X2 + 4X3 ··· 
=  1 + rX + r2X2 + r3X3 + ··· 
=  X − X3 + X5 − X7 + ··· 


Proof of (20)-(25): For instance, (21) follows by coinduction from the fact that
{⟨(1 + X)−1, 1 − X + X2 − X3 + ·· ·⟩,
⟨−(1 + X)−1, −1+ X − X2 + X3 −· · ·⟩}
is a bisimulation relation on Rω. Similarly, (23) follows by coinduction since
1	k	2
{⟨ (1 − X)2 + 1 − X , (k + 1)+ (k + 2)X + (k + 3)X + ·· ·⟩ | k ≥ 0}
is a bisimulation relation.	✷
The definition of the following operation on streams is again clearly inspired by analysis. For all streams σ and τ with τ (0) = 0, the composition σ τ is defined as the unique stream satisfying the following behavioural differential equation:




We shall often write

σ ◦ τ ≡ σ(τ )

The condition that τ (0) = 0 is needed in the proof of the following identity, which shows that composition behaves as usual. For σ = (s0, s1, s2,.. .) and τ with τ (0) = 0,
1	2
σ(τ ) = s0 + (s1 × τ ) + (s2 × τ ) + ··· 

Proof of (26): Because τ (0) = 0, we have (τn+1)' = τ '	τn, for all n	0. As a consequence,
(s0 + (s1 × τ 1) + (s2 × τ 2) + ·· ·)'
= (s1 × τ ') + (s2 × τ ' × τ ) + (s3 × τ ' × τ 2) + ··· 
= τ ' × (s1 + (s2 × τ ) + (s3 × τ 2) + ·· ·) Now (with σ = (s0, s1, s2,.. .)) let
R = {⟨ρ × σ(τ ), ρ × (s0 + (s1 × τ 1) + (s2 × τ 2) + ·· ·)⟩ | 
σ, τ, ρ ∈ Rω,  τ (0) = 0}
Because
(ρ × σ(τ ))'	=	(ρ' × σ(τ )) + (ρ(0) × (τ ' × σ'(τ )))
=	(ρ' × σ(τ )) + (ρ(0) × τ ') × σ'(τ ))
ΣR  ρ' × (s0 + (s1 × τ 1) + (s2 × τ 2) + ·· ·) + (ρ(0) × τ ') × (s1 + (s2 × τ 1) + (s3 × τ 2) + ·· ·)
=	(ρ × (s0 + (s1 × τ 1) + (s2 × τ 2) + ·· ·))'
R is a bisimulation-up-to, and identity (26) follows by coinduction-up-to.	✷

Here are a few useful instances and applications of this fact:
σ(X)  =  σ
σ(−X)  =  s0 − s1X + s2X2 − s3X3 + ··· 
=  (s0, −s1, s2, −s3,.. .)




1
2 (σ(X)+ σ(−X)) = (s0, 0, s3, 0,.. .)
σ(X2)  =  s0 + s1X2 + s2X4 + s3X6 + ··· 


Solving behavioural differential equations
The calculus we have just developed will now be used to solve a number of behavioural differential equations in an algebraic manner. In particular, it will be shown how to solve (homogeneous or non-homogeneous) linear equations, possibly with non-constant coefficients. In Sections 6 and 12, these solutions will be used to solve difference equations and analytical differential equations of a similar kind.


Let us start with linear behavioural differential equations with constant coefficients. The method we are about to explain will apply to any equation of the following type:

where n ≥ 1, σ(k) denotes the k-th stream derivative of σ, r0,..., rn−1 are real numbers (interpreted as constant streams [rk]), c0,..., cn−1 are also real numbers, and τ is an arbitrary stream. If τ = 0 the equation is called homo- geneous, otherwise it is called non-homogeneous. The claim is that
there exists a unique stream σ satisfying the equation;
σ can be expressed in terms of τ , the coefficients r0,..., rn−1, the initial values c0,..., cn−1, and the operators of plus, product and inverse.
Rather than giving a proof of this claim in its full generality, we prefer to treat a few special cases, being (lazy and) confident that they will bring the main idea across. Let us start with a simple example of a homogeneous equation:

In order to solve it we multiply the left and right side of the equation with X 2
(where 2 is the coefficient of the highest derivative):
(X2 × σ'') − (X2 × σ') − (X2 × σ) = 0 
Applying the Fundamental Theorem 4.1 to both σ and σ', we obtain, using
σ(0) = 0 and σ'(0) = 1,
σ = X × σ',	σ' = 1 + (X × σ'')
implying X2	σ'' =	X + σ and X2	σ' = X	σ. Substituting this above gives
0  =  (X2 × σ'') − (X2 × σ') − (X2 × σ)
= −X + σ − (X × σ) − (X2 × σ)
= −X + (1 − X − X2) × σ
yielding as the final outcome the following expression for the solution of the differential equation:
X

σ = (1 − X − X2)
One could continue by manipulating this expression still further in order to obtain a so-called closed formula for the n-th element of σ, expressing σ(n) in terms of a formula on the natural numbers depending on (the variable) n. We shall come back to this in Section 6.


Here is another example, this time non-homogeneous:

By Theorem 4.1, we obtain X × σ' = σ − 1, whence
X × (1 − X)−1 =  (X × σ') − (X × σ)
= σ − 1 − (X × σ)
= −1+ (1 − X) × σ
As a consequence, the following expression is obtained:
1

(28)
σ = (1 − X)2

The following table contains some further examples which the reader may wish to use to test his or her stream-calculus abilities:
The solutions of these equations are

σ = 		3 − 8X	,	τ = 1 − 7X + 10X2
1+ X + X2
1+ r2X2  ,	ρ =
1 − X + 2X + 6X3

1 − X

The fact that the coefficients of the equations so far have been constant real numbers is by no means crucial. Here is the more general formulation:

where now not only τ but also ρ0,..., ρn−1 are arbitrary streams. The claim is again that
there exists a unique stream σ satisfying the equation;
σ can be expressed in terms of the streams τ and ρ0,..., ρn−1, the initial values c0,..., cn−1, and the operators of plus, product and inverse.
The proof for arbitrary n	1 is not more difficult (just more writing) than the proof for n = 1, which is presented next. Consider the equation

where ρ and τ are arbitrary streams. Calculating as before (multiplying both


sides of the equation by X, invoking Theorem 4.1), we obtain for the solution of this equation the following expression:
σ = σ(0) + (X × τ )
1+ (X × ρ)
Application: solving difference equations
The techniques of Section 5 will next be used to solve linear difference equa- tions (also called linear recurrence relations) with constant coefficients. (An example of an equation with non-constant coefficients will be dealt with in Section 9.) The main idea is to transform difference equations, which can be seen as inductive definitions of streams, in a canonical fashion into be- havioural differential equations. The heart of the matter is thus a systematic transformation of inductive stream definitions into coinductive ones.
More precisely, we consider non-homogeneous linear difference equations of order k with constant coefficients:
where k ≥ 1 (the order of the equation), n ≥ 0, the coefficients r0,..., rn−1 are real numbers (the coefficient for sn+k has been taken identical to 1 for con- venience), and t0, t1, t2,... is an arbitrary sequence of real numbers. Defining
σ = (s0, s1, s2,.. .),	τ = (t0, t1, t2,.. .)
we set out to transform the above difference equation into a behavioural dif- ferential equation in the variable σ, by multiplying both sides of the equation with the constant stream Xn:
sn+k Xn + rk−1sn+k−1Xn + ··· + r1sn+1Xn + r0snXn = tnXn
Next we take on both sides the infinite sum over all n ≥ 0:

∞


n=0
sn+k
Xn + r

k−1
∞


n=0
sn+k−1
Xn + ··· + r1
∞


n=0
sn+1
Xn + r0
∞


n=0
snXn



Since, for any i ≥ 0,
= ∞
n=0

tnXn

σ(i) = si + si+1X1 + si+2X2 + ··· 
which is an immediate corollary of Theorem 4.3, we obtain
σ(k) + rk−1σ(k−1) + ··· + r1σ(1) + r0σ = τ
with initial values
σ(0) = s0,	σ(1)(0) = s1,  ...,  σ(k−1)(0) = sk−1
And so we are done, since we have learned in Section 5 how to solve this type of behavioural differential equation.


Let us look at a few examples. Here is maybe the most famous difference equation of all:

defining the Fibonacci numbers. The method above transforms it into

which we recognize from Section 5, where the solution was shown to be
X
σ =
(1 − X − X2)
This in principle answers the question as to what stream is defined by the difference equation we started with. A further question that is often raised is how the n-th element σ(n) looks like, ideally as a function of n. The method of partial fractions, well-known from the theory of generating functions, also works in stream calculus. Defining

1+ √5
r+ =	,	r−
= 1 − √5
2

which are the roots of 1	X	X2 since 1	X	X2 = (1	r+X)(1	r−X),
we have
X
σ =
(1 − X − X2)

1
=
r+ − r−
1
(
1 − r+
1
X − 1 − r−X

 1 
=  √5 (
∞


n≥0
rn Xn −
∞


n≥0
rn X
—
n)	[by identity (24)]

giving the familiar answer

1	n	n

σ(n) = √5 (r+ − r−)
Note that the entire game is played here inside the world of stream calculus, without any reference to (generating) functions. For a second example, non- homogeneous this time, consider

Our method transforms it into



(using the fact that (1	X)−1 = 1 + X + X2 +	, identity (19)). For the solution we look again at Section 5:
σ  =  (1 − X)−2	[identity (28)]
=  1 + 2X + 3X2 + 4X3 + ···	[by identity (23)]
= (1, 2, 3, 4,.. .)
which comes as no surprise. Here is yet another example of a non-homogeneous equation:

Writing	2n+1 =	2	2n and using identity (24), the following differential equation is obtained:

Using the method of partial fractions again, the solution found in Section 5 can be rewritten as
σ = 	3 − 8X	
1 − 7X + 10X2

= 2 (1	2X)−1 + 3
7
(1	5X)−1
3

yielding, again by identity (24),

σ(n) = 

22n +
3

75n 3

Solving quadratic equations in stream calculus
The operation of the square root of a stream is introduced, and is used to solve quadratic equations in stream calculus. (Although only square root is treated, it will be obvious how to deal with variations.)
As in the case of the definition of the inverse operator, we simply state what we wish and then derive a definition that gives us precisely that. For a
initial value as the real number (√σ)(0) = σ(0) (implying that σ(0) should be positive). Taking derivatives on both sides of our specification, we get
(√σ' × √σ) + (√σ(0) × √σ') = σ'
implying, under the assumption that σ(0) /= 0,

√σ'
σ'
= √σ(0) + √σ

And so we arrive at the following behavioural differential equation. For all streams σ with σ(0) > 0, let	σ be the unique stream satisfying the following


equation:

It is an immediate consequence of this definition that, indeed,
(29)	√σ × √σ = σ
The following theorem expresses a basic property of square root.
Theorem 7.1 For all streams σ and τ with σ(0) > 0,
if τ × τ = σ then either τ = √σ	or τ = −√σ
depending on whether τ (0) is positive or negative.
Note that the theorem is less trivial than it seems. Although a similar state- ment hold√sfor real numbers s and t with s> 0: if t × t = s then either t =	s
or t = −  s, such a property is not valid for arbitrary functions. If f and g
are two real-valu√ed functi√ons with f > 0 and such that g × g = f , then g need
not be equal to	f or −  f .



τ (0) is either
σ(0) or −
σ(0). We assume in the rest of the proof that


	


σ' = (τ × τ )'
= (τ ' × τ ) + (τ (0) × τ ')
= τ ' × (τ (0) + τ )

= τ ' × (	σ(0) + τ )
we have for τ ' a similar expression as for
'




√σ':
σ'

(30)
τ  = √σ(0) + τ

It is this equality which tells us how to build a suitable bisimulation relation, which will be a bit more complicated than the ones that we have encountered so far. Let R ⊆ Rω × Rω be the smallest relation such that
⟨τ, √σ⟩ ∈ R
{⟨ρ, ρ⟩ | ρ ∈ Rω} ⊆ R
For all streams α0, α1, β0, β1: if ⟨α0, β0⟩ ∈ R and ⟨α1, β1⟩ ∈ R then
⟨α0 + α1, β0 + β1⟩ ∈ R
⟨α0 × α1, β0 × β1⟩ ∈ R
⟨(α0)−1, (β0)−1⟩ ∈ R
Using identity (30) above, one can now prove, with induction on the definition of R, that R is a bisimulation relation. The theorem then follows by coinduc- tion.	✷


Just as an entertaining aside 1 , note that the defining equation for square root immediately gives rise to a representation as a continued fraction:
√σ  =  √σ(0) + (X × √σ')	[Theorem 4.1]

= √σ(0) +
√ X × σ'√

=  √σ(0) +	X × σ'

2√σ(0) +	X × σ'

. . .
(We shall come back to continued fractions in Section 17.) Here are a few basic properties and examples of square roots:
(31)	√σ × √τ  = √σ × τ

(32)
1	 1 
σ	=  √σ

(33)
√(1, 1, 1,.. .)  =  (1,
1 3	5
, ,	,.. .)
2 8 16

(34)
√

√(1, 2, 3,.. .) = (1, 1, 1,.. .)


Proof of identities (31)-(35): The first identity is immediate by Theorem
and the observation that
(√σ × √τ ) × (√σ × √τ ) = σ × τ
For identity (32), we calculate as follows:

1	=  1 ×  1



1
=  ( √σ ×
√σ)	1
σ

 1 	1

=  √σ ×
1
=  √σ ×
1
=  √σ
σ × σ	[by identity (31)]
√1

Example (34) follows from
(1, 1, 1,.. .)2 =  (	1
1 − X



)2	[identity (19)]

1 This was suggested to us by Alexandru Baltag.

1
=
(1 − X)2
=  (1, 2, 3,.. .)	[by identity (23)]
The elements of the other two examples can be computed one by one, by unfolding the defining equation of the operation of square root. Alternatively, example (35) is best understood in the context of the solution of the quadratic equation below.	✷

As an example of the use of the square root operator, we set out to solve the following quadratic equation:
2
(36)	γ = 1 + (X × γ )
A first observation is that a stream γ satisfies this equation iff it satisfies the following differential equation:

As a consequence, we note that equation (36) has a unique solution. Comput- ing the respective stream derivatives of γ, one finds
γ = (1, 1, 2, 5, 14,.. .)
which the reader may recognize as the stream of so-called Catalan numbers. In order to express the stream γ in terms of constants and stream operators, now also including the square root operator, one calculates as follows:
γ = 1 + (X × γ2)
iff  (4X2 × γ2) − (4X × γ) + 4X = 0 iff (4X2 × γ2) − (4X × γ) + 1 = 1 − 4X iff (2X × γ − 1) = 1 − 4X
iff  (2X × γ) − 1 = −	1 − 4X
[by Theorem 7.1; note that ((2X × γ) − 1)(0) = −1] Now it is tempting to conclude that
1	√1	4X
γ =
2X
but let us not get carried away: we are living in stream calculus here, and are not dealing with functions.  Dividing by (the constant stream) X = (0, 1, 0, 0, 0,.. .) has no meaning because inverse is only defined for streams with initial value different from 0. Fortunately, we are still able to get rid of the ‘X×’, simply by stream differentiation, since (X × γ)' = γ. Thus
γ = 1 + (X  γ2)
iff (2X × γ) − 1 = −√1 − 4X
iff γ = 1/2(1 − √1 − 4X)'

2
iff  γ = 1+ √1 − 4X	[using the defining equation of square root]
It is not too difficult to generalise this example to more general quadratic equations, in one unknown σ, with as coefficients arbitrary streams α, β, and γ:
(α × σ2) + (β × σ) + γ = 0 
and to determine the conditions on the coefficients which guarantee the exis- tence of a unique solution.


Shuﬄe product and shuﬄe inverse
The power of stream calculus is further increased by the introduction of a number of new operators, notably shuffle product and shuffle inverse. They will play a role in various applications later, including the solution of analytical differential equations.
As we observed earlier, stream differentiation of (convolution) product and inverse does not behave the way we are used to from analysis. A somewhat formalistic way of motivating the definition of the following two operators is that they constitute, in this respect, more familiarly behaved alternatives to product and inverse. For streams σ and τ , let the shuffle product σ τ and the shuffle inverse σ−1 be the unique streams satisfying the following behavioural differential equations:

(Note that we use an underlined symbol 1 to distinguish shuffle inverse from the inverse to the convolution product.) Viewing streams again as sets of words with multiplicities in the reals, shuffle product can also be interpreted as (a generalisation of) the shuffle of languages, which provides another type of motivation and at the same time accounts for the terminology (more about his later). Yet another way of explaining the relevance of shuffle product is provided by the following property. For streams σ = (s0, s1, s2,.. .) and
τ = (t0, t1, t2,.. .), one has
(s + s1 X1 + s2 X2 + ·· ·) × (t + t1 X1 + t2 X2 + ·· ·)
= (σ ⊗ τ )(0) + (σ ⊗ τ )(1) X1 + (σ ⊗ τ )(2) X2 + ··· 
which is an immediate consequence of the following formula for (σ ⊗ τ )(n), for



any n ≥ 0:

Σ , n 


Similar to the case of convolution product, the latter formula could also have been taken as an alternative definition to the behavioural differential equation above. Reasoning in terms of (37), however, is again unnecessarily compli- cated, because of the use of the indices, and the occurrence of the binomial coefficient. And as with ordinary inverse, no similar such formula for shuffle inverse is known.
We shall use the following conventions, for all n ≥ 0:
σ0 ≡ 1,	σn+1 ≡ σ ⊗ σn,	σ−n ≡ (σ−1)n
Here are a few basic properties of shuffle product and shuffle inverse. For all streams σ = (s0, s1, s2,.. .), τ and ρ, for all r ∈ R, and for all n ≥ 0,

(38)
(39)
(40)
(41)
(42)
(43)
(44)
(45)
(46)
(47)
(48)
(49)

(50)

(51)
σ ⊗ τ = τ ⊗ σ r ⊗ σ  =  r × σ
0 ⊗ σ  =  0
1 ⊗ σ  =  σ
σ ⊗ (τ ⊗ ρ) = (σ ⊗ τ ) ⊗ ρ
σ ⊗ (τ + ρ) = (σ ⊗ τ )+ (σ ⊗ ρ) (σn+1)' = n ⊗ σ' ⊗ σn
Xn = n! × Xn σ ⊗ σ−1 = 1 (σ−1)−1 = σ
(σ ⊗ τ )−1 = σ−1 ⊗ τ −1
X ⊗ σ  =  s0X1 + 2s1X2 + 3s2X3 + ··· 
= (0, s0, 2s1, 3s2,.. .)
(X ⊗ σ')'  =  s1 + 2s2X1 + 3s3X2 + ··· 
= (s1, 2s2, 3s3,.. .)
(1 − X)−1 =  1+ 1!X + 2!X2 + 3!X3 ··· 


Proof of identities (38)-(51): We treat a few examples. For (38), define
R = {⟨σ ⊗ τ, τ ⊗ σ⟩ | σ, τ ∈ Rω}
and observe that
(σ ⊗ τ )'		=	(σ' ⊗ τ ) + (σ ⊗ τ ') ΣR (τ ⊗ σ') + (τ ' ⊗ σ)
=	(τ ' ⊗ σ) + (τ ⊗ σ')
=	(τ ⊗ σ)'
Identity (38) now follows by coinduction-up-to (Theorem 4.2). Identity (44)


can be proven with induction on n. For (46) define
Q = {⟨ρ ⊗ (σ ⊗ σ−1), ρ⟩ | ρ, σ, τ ∈ Rω}
Computing derivatives gives
(ρ ⊗ (σ ⊗ σ−1))'	=	ρ' ⊗ (σ ⊗ σ−1) + 
ρ ⊗ ((σ' ⊗ σ−1) + (σ ⊗ (−σ' ⊗ σ−1 ⊗ σ−1)))
=	ρ' ⊗ ((σ ⊗ σ−1) + 
ρ ⊗ (σ' ⊗ σ−1) − (ρ ⊗ (σ' ⊗ σ−1)) ⊗ (σ ⊗ σ−1) ΣQ ρ' + ρ ⊗ (σ' ⊗ σ−1) − ρ ⊗ (σ' ⊗ σ−1)
=	ρ'
which proves that Q is a bisimulation-up-to, allowing us again to apply coinduction- up-to. For identity (49), let
T = {⟨X ⊗ σ, s0X1 + 2s1X2 + 3s2X3 + ·· ·⟩ | σ = (s0, s1, s2,.. .) ∈ Rω}
and note that
(X ⊗ σ)'	=	σ + (X ⊗ σ')
ΣT	σ + (s1X1 + 2s2X2 + 3s3X3 + ·· ·)
=	(s0 + s1X1 + s2X2 + ·· ·) + 
(s1X1 + 2s2X2 + 3s3X3 + ·· ·)	[by Theorem 4.3]
=	s0 + 2s1X1 + 3s2X2 + 4s3X3 + ··· 
=	(s0X + 2s1X2 + 3s2X3 + 4s3X4 + ·· ·)'
showing that T is a bisimulation-up-to. Finally for (51), observe that
{⟨n!(1 − X)−n+1, n!+ (n + 1)!X + (n + 2)!X2 + ·· ·⟩ | n ≥ 0}
is a bisimulation relation on Rω.	✷

There exist obvious variations for shuffle product and inverse on some of the definitions and observations regarding convolution product and inverse. For instance, using identity (45), the following Taylor expansion theorem for streams is an immediate consequence of Theorem 4.3.  For a stream σ = (s0, s1, s2,.. .),

∞
σ =
n=0
σ(n)(0)	n
n!	× X

=  s + s1 X1 + s2 X2 + ··· 
And the following behavioural differential equation defines an operation of ‘shuffle square root’:

satisfying σ1/2 ⊗ σ1/2 = σ.


More important for what follows is the operation of stream exponentia- tion. For a stream σ let exp(σ) be the unique stream satisfying the following behavioural differential equation:

where eσ(0) is the analytical function ex applied to the real number σ(0). Exponentiation has many familiar properties that we shall formulate in a second. The for our purposes most important property is less familiar, in fact rather surprising: for all r ∈ R,

(52)
exp(rX) = 
1


1 − rX

Here are some further identities involving exponents:

(53)
exp(σ) = 1 +
σ1	σ2
1! + 2! + ··· 

(54)
(55)
exp(σ) ⊗ exp(τ ) = exp(σ + τ ) exp(−σ) = exp(σ)−1

The following related identities will come in handy later:
1	1	1

(56)
=	⊗
1 − (r + s)X	1 − rX	1 − sX

(57)
1
(
1 − rX
)n  =	1
1 − nrX

(58)
(59)
((1 + rX)n)'  =  r(1 + rX)n−1 + r(1 + rX)n−2 + ··· + r(1 + rX)+ r
( 	1	 )' = 	r	 + 	r	 + ··· + 	r	

(1 − rX)n
(1 − rX)n	(1 − rX)n−1
1 − rX

(60)
Xn+1	 1	
1 − X
= −1 − X −· · · − Xn +   1	

Proof of identities (52)-(60): Again we only treat a few examples. For
(52) let R = {⟨s × exp(rX),  s  ⟩ | r, s ∈ R}. It is a bisimulation relation,

since
1−rX

(s × exp(rX))'  =  (r × s) × exp(rX)
R  r × s 
1 − rX
s
=  (	)'
1 − rX
For identity (55) let Q =	τ	exp( σ), τ	exp(σ)−1	σ, τ	Rω	and compute as follows:
(τ ⊗ exp(−σ))'  =  (τ ' − (τ ⊗ σ')) ⊗ exp(−σ)
Q  (τ ' − (τ ⊗ σ')) ⊗ exp(σ)−1
= (τ ' ⊗ exp(σ)−1) − (τ ⊗ σ' ⊗ exp(σ)−1)


= (τ ' ⊗ exp(σ)−1) −
(τ ⊗ σ' ⊗ exp(σ) ⊗ exp(σ)−1 ⊗ exp(σ)−1)
=  (τ ' ⊗ exp(σ)−1) + 
(τ ⊗ (−σ' ⊗ exp(σ) ⊗ exp(σ)−1 ⊗ exp(σ)−1))
= (τ ' ⊗ exp(σ)−1) + (τ ⊗ (exp(σ)−1)')
= (τ ⊗ exp(σ)−1)'
which proves that Q is a bisimulation. Identity (56) follows from identities
(52) and (54). The remaining identities follow by induction on n.	✷

Application: a divergent recurrence
As an addendum to Section 6, this very short section presents an example of a difference equation (recurrence relation) involving non-constant coefficients:

One moments thought suffices to see that the stream (0!, 1!, 2!,.. .) is the solution of this equation. But as before, one would like to express this solution in terms of the constants and operators of stream calculus. As we shall see in a second, the two new operators of shuffle product and shuffle inverse will allow us to do so.
The stream (0!, 1!, 2!,.. .) is the prototypical example of a divergent stream, in the sense that if one were to define a function f (x) = 0! + 1!x + 2!x +  , it would satisfy f (0) = 0, and would be undefined everywhere else. Therefore, the above recurrence cannot be solved with the use of generating functions (as in [30]), which is the traditional approach in mathematics. The problem can be solved with the help of formal power series, but computing the solution of the present example leads to fairly complicated calculations, involving so-called hypergeometric series (cf. [11, pp.346-348]).
In contrast, the solution is obtained in stream calculus in a surprisingly quick manner. Multiplying both sides of the behavioural differential equation with Xn+1 (rather than Xn) and summing over all n ≥ 0 gives

∞


n=0

sn+1
Xn+1 − ∞ (n + 1)s
n=0

Xn+1 = 0 

Putting as before σ = (s0, s1, s2,.. .) we find σ − σ(0) = σ − 1 for the first infinite sum and, using identity (49), X ⊗ σ for the second:
σ − 1 − X ⊗ σ = 0 
This gives 1 = σ − X ⊗ σ = (1 − X) ⊗ σ. As a consequence,
σ = (1 − X)−1
which by (51) is, indeed, what we expected: σ = (0!, 1!, 2!,.. .).

Comparing convolution product and shuﬄe product
The relation between the two types of product and inverse is investigated. Its precise formulation will be in terms of a new type of stream derivation, which will later turn out be useful for other purposes as well.
Let the analytical stream derivative of a stream σ be defined by

(61)
As usual, we shall also write
 d  (σ) = (X	σ')' dX

dσ	d
dX ≡ dX (σ)
There is the following general formula for our new type of derivation:

(62)
 d 
(s + s X1 + s X2 + ·· ·) = s
+ 2s X1 + 3s X2 + ··· 

which we recognize as identity (50), and which explains the name of analytical stream derivation. Analytical stream derivation behaves for (convolution) product and inverse in the, from analysis, familiar way. In particular, there are the following identities:

(63)
d (σ × τ )
dσ 	dτ 
=  (	× τ )+ (σ ×	)

dX
d σ−1
dX	dX
dσ	−1	−1

(64)

(65)
dX	= − dX × σ	× σ
d σn+1
dX	= (n + 1) × σ' × σ


Proof of identities (63)-(65): In the proof of identity (63), the following equalities are used (the proofs of these are left to the reader). For all summable families {σn}n∞=0 and all τ in Rω, for all n ≥ 0,

d (		n∞=0 σn) dX
∞
=
n=0
d σn dX

d (Xn	τ )
=  (
dX
d Xn+1
d Xn	n
dX × τ ) + (X
n
dτ 
× dX )

dX	= (n + 1) × X
Next consider σ = (s0, s1, s2,.. .) and τ in Rω and note that

d (σ × τ ) dX
d ((	n∞=0 sn × Xn) × τ ) dX
d (	n∞=0 sn × (Xn × τ ))
dX

[Theorem 4.3]

∞
=
n=0
d (sn × (Xn × τ )) dX



∞
=
n=0
Σ∞




sn ×
d (Xn × τ ) dX
d Xn






n	dτ 

∞
=
n=0
sn × (
d Xn
dX × τ ) + 
∞


n=0
sn × (X
dτ 
× dX )

=	∞ (n × s
n=1
× Xn−1 × τ ) +  ∞ s
n=0
n	dτ 
× (X  × dX )

= ( ∞
n=1
dσ 
n × sn
× Xn−1) × τ
dτ 
∞
+ (	sn
n=0
n	dτ 
× X ) × dX

= ( dX × τ )+ (σ × dX )	[identity (62) and Theorem 4.3] Identities (64) and (65) easily follow from (63).	✷

Note that properties (63)-(65) reflect precisely how ordinary stream derivation behaves on shuffle product and shuffle inverse, which satisfy
(σ ⊗ τ )' = (σ' ⊗ τ )+ (σ ⊗ τ ') (σ−1)' = −σ' ⊗ (σ−1 ⊗ σ−1) (σn+1)' = (n + 1) ⊗ σ' ⊗ σn
Analytical stream derivation is used in the following definition of an operator on streams:
One can easily prove that Λc transforms a stream (s0, s1, s2, s3,.. .) into
(0!s0, 1!s1, 2!s2, 3!s3,.. .)
or, equivalently,

Λ (s
+ s1 X + s2 X2 + s3 X3 + ·· ·) = s
+ s X + s X2 + s X3 + ··· 

In combinatorics, this is referred to as the Laplace-Carson transform (cf. [4, p.350] and [8, p.48]), hence our notation. The following theorem shows that with Λc, we can relate the two types of product and inverse.
Theorem 10.1 For all r ∈ R, σ, τ ∈ Rω,
Λ ( dσ ) = Λ (σ)'
c dX	c
Λc(r)  =  r
Λc(X)  =  X
Λc(σ + τ ) = Λc(σ)+ Λc(τ )


Λc(σ × τ ) = Λc(σ) ⊗ Λc(τ ) Λc(σ−1) = Λc(σ)−1
Proof. The first equality is by definition and the next two are trivial. For the latter three, let R ⊆ Rω × Rω be the smallest relation such that
{⟨σ, σ⟩ | σ ∈ Rω} ⊆ R
for all σ1, σ2, τ1, τ2 ∈ Rω, if ⟨Λc(σ1), τ1⟩ ∈ R and ⟨Λc(σ2), τ2⟩ ∈ R then
⟨Λc(σ1 + σ2), τ1 + τ2⟩ ∈ R
⟨Λc(σ1 × σ2), τ1 ⊗ τ2⟩ ∈ R
⟨Λc((σ1)−1, (τ1)−1⟩ ∈ R
Then R is a bisimulation on Rω and the result follows by coinduction.   ✷

Thus the operator Λc allows one to switch between the two different ring struc- tures on Rω that are determined by convolution product and shuffle product, each of which comes along with its own type of (partially defined) operation of inverse, and its own type of derivative:
Λ : ⟨Rω, +, ×, (−)−1, d (−)⟩ → ⟨Rω, +, ⊗, (−)−1, (−)'⟩
Let us emphasize, however, that for the stream calculus we are developing, it is of crucial importance to have both structures present at the same time. Notably the interplay between the various operators from both worlds, turns out to constitute the most interesting part of the calculus. The following iden- tities clearly illustrate this point, since they involve both the shuffle product and the (convolution) inverse. They all have in common that they provide a
way of eliminating the occurrence of the shuffle product, a procedure we shall sometimes refer to as shuﬄe elimination.
Theorem 10.2 For all r ∈ R and σ ∈ Rω:
1	1

(66)
1 =  1+ rX ⊗ 1 − rX

2	dσ 
X ⊗ σ  = (X ×	)+ (X × σ)
1	1	X

(68)
( 1 − rX ) ⊗ σ  =  ( 1 − rX ) × (σ ◦ 1 − rX )

s0	s1X
s2X2

(69)
=  1 − rX + (1 − rX)2 + (1 − rX)3 + ··· 

Proof. Identity (66) follows from (56). For (67), observe that
(X2	dσ )+ (X	σ)
dX
=  (X2 × (X ⊗ σ')')+ (X × σ)
=  (X × (X × (X ⊗ σ')')) + (X × σ)
=  (X × (X ⊗ σ')) + (X × σ)

[Fundamental Theorem 4.1, (X ⊗ σ')(0) = 0]
=  X × ((X ⊗ σ')+ σ)
=  X × ((X ⊗ σ)')
= X ⊗ σ	[Fundamental Theorem 4.1, (X ⊗ σ)(0) = 0] And for (68), define
R = {⟨( 	s	 ) ⊗ σ, ( 	s	 ) × (σ ◦ 	X	)⟩ | r, s ∈ R,σ ∈ Rω}

1 − rX
1 − rX
1 − rX

and compute as follows to see that R is a bisimulation-up-to:

(( 	s	 ) ⊗ σ)'	=	(  r × s  ) ⊗ σ + (	s
) ⊗ σ'

1 − rX
1 − rX
1 − rX

ΣR (  r × s  ) × (σ ◦   X	) + 
1 − rX	1 − rX
( 	s	 ) × (σ' ◦   X	)
1 − rX	1 − rX
=	( 	s	 )' × (σ ◦   X	) + (s × (σ ◦ 	X	)')

1 − rX
1 − rX
1 − rX

=	(( 	s	 ) × (σ ◦ 	X	 ))'
1 − rX	1 − rX
Identity (68) then follows by coinduction-up-to. Identity (69) follows from
and (26).	✷

To illustrate identity (67), we compute
X ⊗ 	1	  = X2 ×  d  ( 	1	 )+ (X × 	1	 )

=  X2 ×   −2X	 +   X	

[identity (63)]

(1 + X2)2
X	X3

=  (1 + X2)2
1+ X2

Similar computations give

X
X ⊗ 1+ X2	=
2X2

(1 + X2)2

2	1
X ⊗ 1+ X2	=
2	X
X ⊗ 1+ X2	=
X2 − 3X4 (1 + X2)3
−3X + X

(1 + X2)3

The following two identities are useful special cases of (68):

(70)
n	1
X  ⊗ 1 − rX	=
Xn
(1 − rX)n+1

(71)
(1 + rX)n		1	
1 − rX
	1	
=  (1 − rX)n+1

Application: a generalised Euler formula
As an illustration of the use of stream exponentiation and shuffle elimination, we present a quick stream calculus derivation of a so-called generalised Euler formula. Let the difference ∆σ of a stream σ = (s0, s1, s2,.. .) be defined as

(72)
∆σ  =  σ' − σ
=  (s1 − s0, s2 − s1, s3 − s2,.. .)

Defining, as usual, ∆0σ = σ and ∆n+1σ = ∆(∆nσ), for all n	0, we have the following identity:
1
σ ⊗ 1+ X
(73)	=  (∆0σ)(0) + (∆1σ)(0) × X1 + (∆2σ)(0) × X2 + ··· 

Proof of (73): First note that for all n ≥ 0,
∆n+1σ  = ∆(∆nσ)
=  (∆nσ)' − ∆nσ
=  ∆n(σ') − ∆nσ
Next define R = {⟨σ⊗   1  , (∆0σ)(0) + (∆1σ)(0)×X1 + (∆2σ)(0)×X2 + ···⟩ |
σ ∈ Rω} and compute as follows to see that R is a bisimulation-up-to: (σ ⊗  1	 )'	=	(σ' ⊗   1	 ) − (σ ⊗  1	 )
ΣR  ((∆0σ')(0) + (∆1σ')(0) × X1 + ··· ) −
((∆0σ)(0) + (∆1σ)(0) × X1 + ··· )
=	(∆0σ' − ∆0σ)(0) + (∆1σ' − ∆1σ)(0) × X1 + ··· 
=	(∆1σ)(0) + (∆2σ)(0) × X1 + (∆3σ)(0) × X2 + ··· 
=	((∆0σ)(0) + (∆1σ)(0) × X1 + (∆2σ)(0) × X2 + ··· )'
Identity (73) now follows by coinduction-up-to.	✷


Equivalently, we have
  1	
σ ⊗ 1+ X


=  s0

+ (s1

— s0)X + (s2

— 2s1

+ s0)X2 +

(s3 − 3s2 + 3s1 − s0)X3 + ··· 
which is immediate from the fact that, for all n ≥ 0,
Σ	, n 

Using identity (73), the following theorem can now be proved.
Theorem 11.1 For any stream σ,





Proof.
(∆0σ)(0)
σ =	+
1 − X
(∆1σ)(0)	X1
(1 − X)2	+
(∆2σ)(0)	X2
(1 − X)3	+ ··· 

σ  =  σ	1
1	1
=  σ ⊗ 1+ X ⊗ 1 − X	[identity (66)]
= ((∆0σ)(0) + (∆1σ)(0) × X1 + (∆2σ)(0) × X2 + ·· ·) ⊗   1	
[identity (73)]

(∆0σ)(0)
=	+
1 − X
(∆1σ)(0)	X1
(1 − X)2	+
(∆2σ)(0)	X2
(1 − X)3	+ ··· 

[identity (69), for r = 1]
✷
The reader is invited to compare this derivation with the one of, for instance, [28, 11.38], where the same formula can be derived only under a number of convergence assumptions.

Application: solving analytical differential equations
A classical technique in analysis for the solution of differential equations defin- ing analytical functions, is the method of undetermined coefficients (cf. [5, p.82]). The idea is quickly explained by means of an example. In order to solve the differential equation

one assumes the solution to be of the shape

f (x) = s
+ s1 x + s2 x2 + ··· 


Computing f '' gives
0	1!	2!

f ''(x) = s
+ s3 x + s4 x2 + ··· 

Substituting the expressions for f and f '' in the differential equation, one obtains the following difference equation for the coefficients (s0, s1, s2,.. .) of f :

Thus this method reduces the problem of solving a differential equation for f to the problem of solving a difference equation for the Taylor coefficients of f . Though conceptually very simple, the method of undetermined coefficients has


two major drawbacks. Firstly, more interesting differential equations quickly lead to very complicated difference equations. Secondly, there is no general technique for translating the solution of the difference equation (if found at all) back into a workable expression for f .
Here we shall present a variant of the method above, which in many ap- plications is free of these restrictions. Defining
A = {f : R → R | f is analytic in (a neighborhood of) 0 }
our main tool will be the function  :	Rω, which sends an analytic function f to its Taylor series  (f ) = (f (0),f '(0),f ''(0),.. .). Formally,  (f ) is defined by the following system of behavioural differential equations (one for each f ∈ A):

(Note that the first occurrence of ' in  (f )' =  (f ') stands for stream deriva- tion, whereas the second denotes analytical function derivation.) This defini- tion is a variation on a definition by Pavlovi´c and Escardo´ [22], who charac- terised as a final coalgebra homomorphism, in order to give a coinductive characterization of the Laplace transform. Here  is studied in its own right, and will serve rather as an alternative to Laplace transform. For that reason, we shall sometimes refer to the stream T (f ) as the Taylor transform of f .
Our method is characterised by the following three steps:
The function is used to transform, in a systematic fashion, a differential equation for f into a behavioural differential equation for the stream (f ) of Taylor coefficients of f .
The behavioural differential equation is solved in stream calculus by means of the techniques of Section 5.
The resulting solution is translated back in a systematic manner into an expression for f .
First of all, the following theorem expresses that the function transforms functions into their Taylor series in a systematic manner, indeed. For functions f and g, we shall be using the following familiar definitions: for all x ∈ R,
(f + g)(x) = f (x)+ g(x), (f · g)(x) = f (x) × g(x), f −1(x) = f (x)−1,  ef (x) = ef(x)
Theorem 12.1 For all analytic functions f, g ∈ A,

(74)
(75)
(76)
(77)
(78)
T (f )(0) = f (0)
T (f ') = T (f )'
T (f + g) = T (f )+ T (g)
T (f · g) = T (f ) ⊗T (g) T (f −1) = T (f )−1


T (e ) = exp(T (f ))
The most useful instantiation of identity (79) will be the case that f (x) = rx: see indentity (82) below. Identities (74)-(77) are implicitly present in [22]; see also [25].
Proof. Identities (74) and (75) are immediate by the definition of T . For the others we use coinduction: let R ⊆ Rω × Rω be the smallest relation on streams such that ⟨T (f ), T (f )⟩ ∈ R, for all f ∈ A, and such that if
⟨T (f1), T (f2)⟩ ∈ R and ⟨T (g1), T (g2)⟩ ∈ R then
⟨T (f1 + g1), T (f2)+ T (g2)⟩ ∈ R
⟨T (f1 · g1), T (f2) ⊗T (g2)⟩ ∈ R
⟨T (f1−1), T (f2)−1⟩ ∈ R
⟨T (ef1 ), exp(T (f2))⟩ ∈ R
The relation R is a bisimulation:  consider for instance ⟨T (f · g), T (f ) ⊗ T (g)⟩ ∈ R.	Both streams clearly have the same initial value.	Moreover,
⟨T (f · g)', (T (f ) ⊗T (g))'⟩ ∈ R, since
T (f · g)'
=  T ((f · g)')
=  T (f ' · g + f · g')
R  T (f ') ⊗T (g)+ T (f ) ⊗T (g')
=  T (f )' ⊗T (g)+ T (f ) ⊗T (g)'
= (T (f ) ⊗T (g))'
Similarly for the other elements of R. Now the theorem follows by coinduction.
✷

The following set of identities on the Taylor transforms of some well known functions will be useful when solving differential equations.
Theorem 12.2 For all r ∈ R, n ≥ 0, f ∈ A,




T (r) = r
T (x ) = n!X
rx		1	
T (e  ) =  1	rX
rX




T (sin(rx)) =
T (cos(rx)) =


1+ r2X2
1


1+ r2X2


rx		1			X	
T (f × e  )  =  (	) × (T (f ) ◦	)

1 − rX	1 − rX
2	d T (f )
T (f × x) = (X ×	) + (X ×T (f ))


Proof. The first two equalities are straightforward. For (82)-(84), define
R = {⟨T (s × erx), 	s	 ⟩ | r, s ∈ R} ∪ 
{⟨T (s × sin(rx)), (s × r)X ⟩ | r, s ∈ R} ∪ 
s
{⟨T (s × cos(rx)), 1+ r2X2 ⟩ | r, s ∈ R}
and use coinduction. For (85), note that

T (f × e
) =  T (f ) ⊗T (e
1
)	[identity (77)]

=  T (f ) ⊗ ( 1 − rX )	[identity (82)]
1	X
= ( 1	rX ) × (T (f ) ◦ 1	rX )	[identity (68)] For (86), finally, we have:
T (f × x)  =  T (f ) ⊗T (x)	[identity (77)]
=  T (f ) ⊗ X	[identity (81)]
=  (X2 × d T (f )) + (X ×T (f ))	[identity (67)]
✷

By now, we are sufficiently prepared to tackle a variety of differential equa- tions:
As a warming up, consider the equation from the beginning of the present section:
Applying T to both sides of the equation, and putting σ = T (f ) gives

This constitutes step (1) of our method. In step (2), the resulting be- havioural differential equation is solved according to the techniques of Section 5, yielding
X
σ = 1+ X2
In order to translate this outcome back into the function f —step (3) of our method—we can apply identity (25), yielding
σ = X − X3 + X5 − X7 + ··· 
which, in combination with identity (81) gives
x3	x5	x7
f (x) = x − 3! + 5! − 7! + ··· 


Often, we can improve on the last step. In this particular example, it is sufficient to consult our set of basic identities on Taylor transforms, to find that identity (83) provides us immediately with an answer:
f (x) = sin(x)
For a second example, consider the following non-homogeneous equation:

Using identity (82) and writing σ = (f ), step (1) transforms this equa- tion into
The solution of this equation, step (2), is identity (28). For step (3), we combine σ =  (f ) with identities (23) and (81), yielding
2	 3	 4
f (x) = 1 +	x +	x2 +	x3 ··· 
Again, we can do better than this. Using some elementary stream calcu- lus, we can rewrite σ as follows:
1
σ =
(1 − X)2
1
=  (1 + X) ⊗ 1	X	[by identity (71)]
Using now identities (76), (77), and (82), we get
f (x) = (1 + x) · ex
Here is example number three:

Putting σ = T (f ), step (1) gives

For step (2) we recall the solution of this equation from Section 5, and perform some elementary stream calculus on it:
1+ X + X2
σ =	1+ r2X2
1	X	X2
=  1+ r2X2 + 1+ r2X2 + 1+ r2X2
1	1	rX	1	1
=  1+ r2X2 + r 1+ r2X2 + r2 (1 − 1+ r2X2 )


The rewriting was done to make step (3) easy: applying identities (83) and (84) yields the final outcome:
1	1
f (x) = cos(rx)+ r sin(rx)+ r2 (1 − cos(rx))
Example number four:

Step (1) gives

As before, we recall the solution of this equation (step (2)) from Section 5, and perform some elementary stream calculus on it:
1 − X + 2X + 6X3
σ =
1 − X

=	7	8X	6X2 +8	1
1 − X
[applying identity (60) four times]

Applying the by now familiar identities on the Taylor transforms, step
(3) yields
f (x) = −7 − 8x − 3x2 + 8ex

Weighted stream automata
In this section, the notion of weighted stream automaton is introduced (called nondeterministic automaton in [25]), the transition diagrams of which can serve as pleasant graphical representations of streams and their successive derivatives. Finite such automata turn out to correspond to rational streams, but as we shall see, infinite weighted automata will be useful too.
A R-weighted stream automaton, or weighted automaton for short, is a pair Q = (Q, o, t ) consisting of a set Q of states, together with an output function o : Q  R, and a transition function t : Q  (Q  f R), where the latter set contains only functions of finite support :
Q →f R = {φ : Q → R | |{q ∈ Q | φ(q) /= 0}| < ∞} 
The output function o assigns to each state q in Q a real number o(q) in R. The transition function t assigns to a state q in Q a function t(q) : Q  f R, which specifies for any state q' in Q a real number t(q)(q') in R. This number can be thought of as the weight (cost, multiplicity, duration, etc.) with which the transition from q to q' occurs. The following notation will be used:
q →−r  q' iff t(q)(q') = r

q ⇒r
iff o(q) = r


which will allow us to present weighted automata by pictures. In such pictures, only those arrows will be drawn that have a non-zero label. For q ∈ Q, let
{q1,..., qn} be the support of t(q), that is, the set of all states qi for which
t(q)(qi) = 0, and let ri = t(q)(qi), for 1	i	n. The following diagram contains all the relevant information about the state q in the automaton Q:



r1 
    
q ¸ o(q)	z 
¸¸¸¸rn
¸¸¸

q1 ,s
z 
···	n

Note that the requirement of finite support implies that the automaton Q is ﬁnitely branching , in the sense that from q, there are only finitely many (non-zero) arrows.
The stream behaviour of a state q in a weighted automaton Q is the stream S(q) ∈ Rω, defined coinductively by the following system of behavioural dif- ferential equations (one for each state in Q):

(As before, q1,..., qn is the support of t(q) and ri = t(q)(qi), for 1  i  n.) The pair (Q, q) is called a representation of the stream S(q). A stream σ  Rω is called ﬁnitely representable if there exists a ﬁnite weighted automaton Q and q ∈ Q with σ = S(q). Such streams are also called recognizable.
For a simple example, consider the following two state weighted automaton:
q1,,
1	−1
qtz	 z 
r,~¸ ,,2 ,1

We have the following equations for the behaviour of q1 and q2:

Applying the methodology of Section 5 (generalised to systems of equations), we find:
X	1
S(q1) = (1 − X)2 ,	S(q2) = (1 − X)2
Thus the stream X(1 − X)−2 is represented by the state q1 above. Note that representations are by no means unique: X(1 − X)−2 is also represented by


the state r1 in the following automaton:

r,~¸1~v
1
r,~¸1~v
 r2 ,1	z 
1

since one readily computes that S(r1) = X(1 − X)−2 and S(r2) = (1 − X)−1. The following proposition describes how the behaviour of a state of a weighted automaton can be computed in terms of the labels of its transi- tion sequences. Although this proposition provides some operational intuition about the behaviour of weighted automata, it is not very suited for reasoning
about them; it will play no role in the remainder of this paper.
Proposition 13.1 For a weighted automaton Q, for all q ∈ Q and k ≥ 0,

S(q)(k) = Σ {l0l1
··· l

k−1
l | q = q0 →−
q1 →−
lk−1
−−→ k

For instance, in the last example of the (two state) automaton above, one readily verifies that S(r1)(n) = n, for all n ≥ 0, which is consistent with what we found earlier, since (0, 1, 2, 3,.. .) = X(1 − X)−2.
Proof. Using the differential equation for S(q) and the observation that
S(q)(k + 1) = S(q)(k+1)(0)
=  (S(q)')(k)(0)
= (r1S(q1)+ ··· + rnS(qn))(k)(0)
= r1S(q1)(k)(0) + ··· + rnS(qn)(k)(0)
=  r1S(q1)(k)+ ··· + rnS(qn)(k)
the proof follows by induction on k.	✷

There is also the following algebraic characterisation of the behaviour of a ﬁnite weighted automaton Q = (Q, ⟨o, t⟩). It will play no role in the remainder of this paper. Let Q = q1,..., qn and let µ be the n  n matrix with entries µij = t(qi)(qj). Furthermore write o : Q   R as a column vector ot = (o(q1),..., o(qn))t.
Proposition 13.2 For any sequence of real numbers a = (a1,..., an) (viewed as a row vector), and for all k ≥ 0,
a1S(q1)(k)+ ··· + anS(qn)(k) = a × µ  × o
where on the right, matrix multiplication is used.
Proof. The proof is an immediate consequence of Proposition 13.1.	✷

The streams that can be represented by finite weighted automata are precisely the rational streams, which are introduced and characterised next.


Theorem 13.3 The following three conditions are equivalent. Any stream σ
satisfying them is called rational.
There exist polynomial streams π and ρ with ρ(0) = 0 such that
π
σ = 
ρ
There exists n ≥ 1, real numbers sij, for 1 ≤ i ≤ n and 1 ≤ j ≤ n, real numbers k1,..., kn, and streams σ1, σ2,..., σn with σ = σ1, satisfying the following ﬁnite system of behavioural differential equations:
σ has a ﬁnite representation (is recognizable): There exist a ﬁnite weighted automaton Q and a state q ∈ Q with σ = S(q).
Proof. A proof can be found in [25]. (See also Section 18 for further references on rationality.) Most interesting is the proof that (1) implies (2), which is as follows. Consider polynomials π = p0 + p1X + ··· + pnXn and ρ = r0 + r1X +
··· + rmX  and let σ = π × ρ  . For notational convenience, we assume that r0 = 1. We also assume that 0 < n < m (the case that m  n can be dealt with similarly). Using the defining behavioural differential equations of sum, convolution product, and inverse, σ is readily seen to satisfy the following finite system of behavioural differential equations:



where
v =  pi − p0ri if 1 ≤ i ≤ n
 −p0ri	if n<i ≤ m

The equivalence between (2) and (3) follows from the correspondence between finite systems of behavioural differential equations and finite representations. More concretely, the above system of equations for π × ρ−1 corresponds to the


following weighted automaton:
1  p0	 z 
¸¸¸¸¸¸¸v
v2	¸m¸
J	¸¸¸z˛
v1	Xρ−1 ¸,1	 ··· ¸,1  Xm−1ρ−1

.,
1	−r2
,,,, ¸
,,,,

v(zz,,,,,, −rm
−r1 r,~¸ ,,,
✷

Note that in the above construction of a weighted automaton for rational streams, we have used the streams themselves (π  ρ−1, Xρ−1, etc.) as the states of this automaton. The transitions of any stream (state) in this au- tomaton are obtained by ‘splitting the derivative’ of this stream into its ‘+’ components. Here is an example, for π = 2 − X and ρ = 1 − X + X2:
  2−X    2  z 
1−X+X2
−2
J 
1 	X	
1−X+,X,2
1	−1
  z(1zz 	 z 
r,~¸ 1− X,,+X,2	1
In this automaton, the transitions of for instance the lower state are deter- mined by the fact that its derivative is a sum of two streams, as follows:
(	1	 )' = −	X	 + 	1	
1 − X + X2	1 − X + X2	1 − X + X2
Later we shall apply this procedure of ‘splitting derivatives’ also in the con- struction of infinite weighted automata for non-rational streams.
Recall that in Theorem 10.2, a number of identities for shuffle elimination was proved. The following theorem expresses that, as a consequence of The- orem 13.3 above, we now know how to eliminate shuffle products of any two rational streams.
Theorem 13.4 If σ and τ are rational streams then σ ⊗ τ is rational too.
Proof. Consider two rational streams σ and τ . According to Theorem 13.3, there exist finite systems of behavioural differential equations
{(σi)' = si1σ1 + ··· + sinσn | σi(0) = ki}n

and

{(τi)' = ti1τ1 + ··· + timτm | τi(0) = li}m


which are satisfied by σ = σ1 and τ = τ1. It is an immediate consequence of the definition of the shuffle product that σ τ = σ1 τ1 satisfies the following finite system of behavioural differential equations:
{(σi ⊗ τj)' =
si1(σ1 ⊗ τj)+ ··· + sin(σn ⊗ τj)+ tj1(σi ⊗ τ1)+ ··· + tjm(σi ⊗ τm) }i,j
with initial values (σi τj)(0) = ki lj i,j. Thus σ τ is rational, again by Theorem 13.3.	✷

The proof of Theorem 13.4 in fact describes a general algorithm for the shuffle elimination for rational streams, which is illustrated by the following example. Consider two streams σ = (1 + X2)−1 and τ = X(1 + X2)−1. Since σ' = −τ and τ ' = σ, we have the following system of equations for σ ⊗ τ :
(σ ⊗ τ )' =  −τ ⊗ τ + σ ⊗ σ
(σ ⊗ σ)'  =  −2σ ⊗ τ
(τ ⊗ τ )' = 2σ ⊗ τ
with the obvious initial values. Solving this system of behavioural differential equations, one finds
1	X	X
1+ X2 ⊗ 1+ X2	=  1+ 4X2
Note that rational streams are not closed under shuffle inverse. A basic ex- ample is the stream
(1 − X)−1 = (0!, 1!, 2!,.. .)
which can be shown to be non-rational. (A proof would be based on the fact that the elements of any rational stream can be expressed in terms of some polynomial expression, that can never ‘grow’ as fast as the stream of factorials.)
One of the advantages of weighted automata is that they provide finite representations for rational streams. It turns out to be worthwhile to study also infinite weighted automata representing non-rational streams. We hope the next example convinces the reader hereof.
The function tan(x) satisfies the following (ordinary) differential equation:

Putting τ =  (tan(x)) for the Taylor series of tan(x), and recalling iden- tity (77) from Theorem 12.1, we obtain the following behavioural differential equation:



The Taylor series of tan(x) is notoriously difficult in that no closed formula for its elements, the so-called tangent numbers, is known. Here a representation for τ is constructed in the form of an infinite weighted automaton. Applying again the ‘splitting of derivatives’ procedure for the construction of a weighted automaton Q for τ , the first streams to be included as states of the automaton
are τ , 1, and τ ⊗ τ = τ 2. Computing the derivative of the latter, we find, using the differential equation for τ again,
(τ 2)' = 2τ ' ⊗ τ
=  2(1 + τ 2) ⊗ τ
= 2τ + 2τ 3
Continuing this way, one obtains Q = 1, τ,τ 2,τ 3,τ 4,.. . with transitions and initial values as in the following diagram:


¸c1 
¸1, 
  1  z2_
2  z3_
3  z4_
4 z_

1	τ ¸¸  τ  ¸_  τ ¸_  τ  ¸_  ··· 
2	3	4	5
Thus we have obtained an, albeit infinite but extremely regular and simple weighted automaton, in which the state τ represents (itself, that is) the Taylor series of tan(x).
Applying Proposition 13.1 yields a closed formula for the n-th tangent number, formulated in terms of a finite sum over all paths of length n in the automaton that start in τ and end in 1. Possibly more interesting is the fact that the above automaton gives rise in a rather straightforward manner to the following continued fraction representation of the stream τ :
X
τ = 
1 · 2 · X2
2 · 3 · X2
3 · 4 · X2
1 −	. .
A proof by coinduction is readily given, but rather we refer to Section 17, where a far more general result is proved.
We conclude the present section with a coalgebraic characterization of the assignment of streams S(q) to the states q in a weighted stream automaton, which was defined above by means of a system of behavioural differential equations. (None of this will play a role in the remainder of the paper.) Consider a weighted stream automaton (Q, o, t ). The following diagram tells it all:
S

Q  (Q →f R)	zzR ω

{·}	,,,,
∃!l

⟨o,t⟩
,,,
J , ,,  ⟨oˆ,tˆ⟩
⟨O,T ⟩
J 

R	(Q	R) _ _ _ _ _ _ _ _ _ _ _ zR  Rω
1R×l


The function {·} is defined, for all q, q' ∈ Q, by
q (q') =	1 if q = q'
0 otherwise
For φ ∈ (Q →f R), with support {q1,..., qn}, the functions oˆ and tˆ are given
oˆ(φ) = o(q1) × φ(q1)+ ··· + o(qn) × φ(qn) and, for any q ∈ Q, by
tˆ(φ)(q) = t(q1)(q) × φ(q1)+ ··· + t(qn)(q) × φ(qn)
With these functions, we have provided (Q →f R) with an ordinary (that is, as in Section 2) stream automaton structure ( (Q →f R), ⟨oˆ, tˆ⟩ ). It is consistent with the weighted automaton structure on Q, in that, for all q ∈ Q,
oˆ({q}) = o(q),	tˆ({q}) = t(q)
(We are dealing here with a generalisation of the ‘powerset’ construction from automata theory, which is used to transform nondeterministic automata into deterministic ones.) By the finality (Theorem 2.2) of the (ordinary) stream automaton (Rω, O, T ), there exists a unique homomorphism l : (Q	f R) Rω. The formal statement that the above diagram is meant to express, is that for all q ∈ Q,
S(q) = l({q})
This can now be proved by a straightforward coinduction.

Multivariate streams
Recall from Theorem 4.3 that any stream σ = (s0, s1, s2,.. .) can be viewed as a power series in the formal variable X:
σ = s0 + s1 × X1 + s2 × X2 + ··· 
Another way of putting this is to view σ as a ‘weighted’ language over the one letter alphabet X , where the n-th element sn of σ gives the multiplicity with which the word Xn ‘occurs’ in σ. This view on streams is in fact equivalent to the original definition of streams as functions σ :  0, 1, 2,.. .   R, because of the existence of an isomorphism
Rω ∼= R{X}∗
where {X}∗ = {ε, X, X2,.. .}, the set of all finite words over the alphabet
{X} (with ε denoting the empty word).
Using this latter view, the present section generalises streams over the sin- gleton alphabet X to multivariate streams, which are ‘weighted’ languages over an arbitrary (possibly infinite) alphabet A. More precisely, the set of multivariate streams is defined by
RA∗ = {σ | σ : A∗ → R}


where A∗ is the set of all finite words over the alphabet A. Multivariate streams are also known in the literature as formal power series:
multivariate streams	≡	formal power series
A multivariate stream σ assigns to each word w  A∗ a real number σ(w), which can be thought of as the weight or multiplicity with which this word ‘occurs’ in σ. We shall encounter denotations for multivariate streams that are similar to the ones we have seem before, such as
7+ 3X + √2(X	Y )+ Z3		1	
1 − (X × Z)
where the alphabet is X, Y, Z . As before, we develop a theory of multi- variate streams in analogy to analysis (now involving the notion of partial stream derivative), but still more so than before, multivariate stream calculus will often behave differently from what we are used to. Most importantly, (convolution) product will no longer be commutative: in general,
X × Y /= Y × X
In many cases, our guiding intuitions are to be taken from the theory of formal languages, rather than from analysis. The definition of the convolution prod- uct of multivariate streams, for instance, will be a generalisation of language concatenation.
The move from univariate streams to multivariate ones is conceptually dramatic and will lead to a far greater expressivity, but as we shall see, the technical development of the theory requires only minor variations on the results obtained thus far. Below we shall present multivariate streams in some more detail. The following sections will deal with multivariate stream calculus and some of its applications.
So let A be an arbitrary alphabet, the elements of which we call (formal) variables. The initial value of a multivariate stream σ ∈ RA∗ is denoted, as before, by σ(0), and is defined as the value that σ assigns to the empty word ε ∈ A∗:
σ(0) = σ(ε)
For any variable X ∈ A, the partial derivative σX ∈ RA  of σ with respect to
∗
X, or X-derivative for short, is defined, for any w ∈ A∗, by
σX(w) = σ(X · w) (here X · w denotes concatenation of words).
Using the notions of initial value and partial derivative, the bit of universal
coalgebra that we introduced for Rω in Section 2, can now be easily generalised as follows. A bisimulation on RA∗ is a relation R  RA∗	RA∗ such that, for all σ and τ in RA∗ ,
if σ R τ  then   σ(0) = τ (0) and
 σX R τX	for all X ∈ A


The greatest bisimulation relation ∼ is again called the bisimilarity relation.
Theorem 14.1 [Multivariate coinduction]
For all σ, τ ∈ RA∗ : σ ∼ τ ⇒ σ = τ.
Proof. Using the defining properties of a bisimulation relating σ and τ , one can prove for all words w	A∗, by induction on their length, that σ(w) = τ (w).		✷
Coinductive definitions will again be phrased in terms of behavioural differ- ential equations, which are now partial . Unique existence of solutions of such equations will again follow from finality, which can be formulated using the following notion. A multivariate stream coalgebra or automaton is a pair Q = (Q, ⟨o, t⟩) consisting of a set Q of states, together with an output func- tion o : Q → R, and a transition function t : Q → QA, with
QA = {g | g : A → Q }
The transition function t assigns to each state q a function t(q) : A → Q that for each variable X ∈ A yields a next state t(q)(X). A homomorphism between stream automata (Q, ⟨o, t⟩) and (Q', ⟨o', t'⟩) is a function f : Q → Q' such that, for all q in Q and all X ∈ A, o(q) = o'(f (q)) and f (t(q)(X)) = t'(f (q))(X):
Q 	f	 Q '

' '

⟨o,t⟩
J 
⟨o ,t ⟩
J 

R	QA 	 R  (Q')A
1R×f A

(The function 1R  f A maps a pair r, g  R  QA to r, f  g)  R  (Q')A.) The set RA∗ of all multivariate streams can itself be turned into such an automaton as well. Defining O : RA∗ → R by O(σ) = σ(0) and T : RA∗ →
(RA∗ )A by T (σ)(X) = σ , for all X ∈ A, we obtain a multivariate stream
automaton (RA∗ , ⟨O, T ⟩), which, as in the case of Rω, is final.
Theorem 14.2 For any multivariate automaton (Q, ⟨o, t⟩) there exists a unique homomorphism l : Q → RA∗ :
Q _ _ _ ∃_!l _ _ zR A∗
⟨o,t⟩	⟨O,T ⟩
J	J ∗
R	QA _ _ _ zR  (RA )A
1R×lA

Proof. The function l : Q  RA∗ assigns to a state q in Q the multivariate stream l(q) defined, for any variable X  A and word w  A∗, using induction on the length of words, by
l(q)(ε) = o(q),	l(q)(X · w) = l(t(q)(X))(w)
This function is a homomorphism from Q to RA∗ and, by coinduction, the only such one.	✷

Multivariate stream calculus

Almost literally following the calculus that we have developed for (univariate) streams, a calculus for multivariate streams is presented. Operators will again be defined by (systems of) behavioural differential equations, which are now partial. We shall not prove the existence of unique solutions for such equations; it follows from the finality of RA∗ in very much the same way as before (cf. [24,25]).
We present all the operators in one go, by the following large system of behavioural partial differential equations. For all X, Y  A, σ, τ  RA∗ , r  R, the following equations have unique solutions:

(Note that for inverse, square root, and shuffle inverse, σ(0) should satisfy the same side condition as before.) Almost all of the above definitions are obtained by replacing in the corresponding equation for streams the occur- rences of ' (stream derivative) by X-derivatives. The only exception is the variable Y , for which it makes a difference whether one takes a Y -derivative (which yields 1) or an X-derivative (which yields 0 for X = Y ). Furthermore, basic properties such as associativity, commutativity, and distributivity, hold pretty much as before; we will not repeat them here. There is, however, one notable exception. As mentioned earlier, convolution product is no longer commutative. Although for r ∈ R and σ ∈ RA∗ , one still has
r × σ = σ × r
this no longer applies to arbitray τ ; generally,
σ × τ /= τ × σ
Indeed, convolution product is more like language concatenation, as expressed by the following formula, with which convolution product of formal power


series is traditionally introduced: for all w ∈ A∗,

(σ × τ )(w) = 
u,v: w=u·v
σ(u) × τ (v)

It generalises identity(5) and shares its disadvantage for actual computation, of being an indexed sum. As always, our reasoning will be coinductive and therefore, we shall not need it.
Note that since product is no longer commutative, we have to be more careful in our notational conventions. We define
σ ≡ σ × τ −1
which generally is different from τ −1 σ. Further note that the operation of (convolution) inverse still is both a left and a right inverse:
σ × σ−1 = 1
σ−1 × σ = 1
Proofs of the above and similar such identities can be given using coinduction Theorem 14.1. Also the notion of bisimulation-up-to and the corresponding proof principle of coinduction-up-to (Theorem 4.2) can be straightforwardly adapted to the multivariate case.
Many behavioural partial differential equations can again be solved alge- braically, as in Section 5, now using the following generalisation of Theorem 4.1, which can be easily proved by coinduction.
Theorem 15.1 [Fundamental Theorem] For all σ ∈ RA∗ ,
σ = σ(0) +	X × σX
X∈A

By way of example, Theorem 15.1 is used to solve the following partial differ- ential equation:

By Theorem 15.1, we have
σ  = σ(0) + (X × σX)+ (Y × σY )
= 1 + X × ((Y × σ)+ 2) + Y × σ
=  1 + 2X + (XY + Y ) × σ
As a consequence, (1 − (XY + Y )) × σ = 1 + 2X, whence
σ = (1 − (XY + Y ))−1(1+ 2X)
(Note that the order of multiplication is important here: τ = (1 + 2X)(1 −
(XY + Y ))−1 is not a solution of the same equation. For one thing, τY /= τ .)


Many of the earlier identities for streams also apply to multivariate streams.
For instance,

exp(σ) = 1 +
σ1	σ2
1! + 2! + ··· 

exp(σ) ⊗ exp(τ )  =  exp(σ + τ )
1	1	1
1 − rX ⊗ 1 − sY	=  1 − (rX + sY )
Weighted automata for multivariate streams
In preparation of the applications of multivariate stream calculus, this section shows how the definition of weighted stream automaton can be adapted to multivariate streams.
A multivariate R-weighted stream automaton, or multivariate weighted au- tomaton for short, is a pair Q = (Q, o, t ) consisting of a set Q of states, together with an output function o : Q   R, and a transition function t : Q   (Q  f R)A, where, as before, (Q  f R) contains only functions of finite support. The output function o assigns to each state q in Q a real number o(q) in R. The transition function t assigns to a state q in Q a function t(q) : (Q  f R)A, which specifies for any variable X  A and state q' in Q a real number t(q)(X)(q') in R. As before, this number can be thought of as the weight (cost, multiplicity, duration, etc.) with which the (X-)transition from q to q' occurs. The following notation will be used:

X r
−−→
q' iff t(q)(X)(q') = r
r

q ⇒ iff o(q) = r
which will again allow us to present weighted multivariate automata by pic- tures. Note that multivariate weighted automata are nondeterministic in that we can have transitions

q X|r1
q ,	q X|r2  q

−−−→ 1	−−−→ 2
for different states q1 /= q2.
The behaviour of a state q in a multivariate weighted automaton Q is now a multivariate stream S(q) ∈ RA∗ , defined coinductively as follows. Let X ∈ A, let {q1,..., qn} be the support of t(q)(X), and let ri = t(q)(X)(qi), for 1 ≤ i ≤ n. Then S(q) is defined by the following system of partial differential equations (one for each q ∈ Q and X ∈ A):

For an example, consider the following finite automaton over the alphabet


{X, Y }, with states {q, r, s} and weights a, b, c ∈ R:
Y |b ,r¸~~v X|a	

qJ  
X c	,, 
Y |b
zr X|a s  1	z 

Its behaviour is defined by the following system of partial differential equa- tions:
For S(q) the following expression can be obtained
S(q) = (1 − abXY − cX − bY )−1a2X2
by solving the system of equations as before, using Theorem 15.1.
Propositions 13.1 and 13.2, and Theorems 13.3 and 13.4 can be straight- forwardly generalised to multivariate weighted automata. Since they will play no role in the applications presented in Section 17, they are omitted.

Application: coinductive counting
Multivariate weighted automata turn out to be very well suited for the mod- elling of various classical counting problems from combinatorics. In this sec- tion, the techniques from the previous sections are illustrated by means of a number of examples of what could be called coinductive counting .
Consider the following infinite multivariate weighted automaton


  1  rJ~ ~,v L0|l0
rJ~ ~,v L1|l1
rJ~ ~ v, L2|l2

¸c q0,¸
U0|u0
 q1 ,¸


U1|u1



D1|d1
D2|d2
D3|d3

with state space {q0, q1, q2,.. .}, weights li, ui, di ∈ R, and alphabet
{L0, L1, L2,.. .}∪ {U0, U1, U2,.. .}∪ {D1, D2, D3,.. .}
If we picture this automaton vertically, with q0 at the bottom, we may think of the symbols Li, Ui and Di as transition steps (starting in the state qi and) representing moves that remain level , go up, or go down, respectively. The multivariate stream behaviour of this automaton is characterised by the following theorem, which is closely related to [10] (see also Section 18).
Theorem 17.1 The multivariate stream behaviour of the state q0 in the au- tomaton above is given by the following continued fraction:
1

S(q0) = 
	(u × U ) | (d × D )	

1 − (l
× L ) −
0	0	1	1

0	0
1 − (l1 × L1) −
(u1 × U1) | (d2 × D2)
. .

.
where the following notational convention is used: for any σ, τ, ρ ∈ RA∗ ,

σ | τ ρ
≡ σ × ρ−1 × τ

Before we prove this equality, let us make sure we understand how the con- tinued fraction on the right is actually defined. Suppose for a second that the continued fraction is well-defined and that, more generally, the multivariate streams σi below are well-defined, for any i ≥ 0:
1

σi =
	(u × U ) | (d	× D	)	

1 − (l
× L ) −
i	i	i+1
i+1

i	i
1 − (li+1 × Li+1) −
(ui+1 × Ui+1) | (di+2 × Di+2)
. .

.
For such multivariate streams σi we would have, for any i ≥ 0,
1

σi =
1 − (li
× Li) − (ui
× Ui) × σ

i+1
× (d

i+1
× Di+1)

The latter equations can now simply be taken as a definition. Or, rather more precisely, from these equations we can now read off the following system of partial behavioural differential equations, the unique solution of which is taken as the formal definition of the multivariate streams σi:

Proof. A proof of Theorem 17.1 on the basis of the above system of differ- ential equations formally defining the streams σi, is now a straightforward


coinduction. Let τ0 = σ0 and let, for i ≥ 1,
τi = σi × (di × Di) × σi−1 × (di−1 × Di−1) ×· · · × σ1 × (d1 × D1) × σ0
Then S(q0) = σ0 follows by coinduction (Theorem 14.1) from the fact that
{⟨r × S(qi),r × τi⟩ | r ∈ R, i ≥ 0}
is a bisimulation relation on RA∗ .	✷

Many counting problems can be expressed in terms of the weighted automaton above, which is illustrated by the following example. As an alphabet we take the set consisting of the two bracket symbols
A = { <, > }
We are interested in counting the number of words over this alphabet that are “well-bracketed” in the obvious sense: the number of opening brackets used should equal the number of closing brackets, and any prefix of the word should contain at least as many opening as closing brackets. For instance, here are all the well-bracketed words containing three opening and three closing brackets:
<<<> >>,  <<>< >>,  <<>> <>,  <><< >>,  <><> <>
The following (classical) automaton, with q0 as initial and only accepting state, is a representation of the set of all well-bracketed words, which correspond precisely to all the paths starting and ending in the state q0:
q   <  zq _ <  zq _ <  z· ·_· 

Adding everywhere the trivial weight 1, and giving q0 the output value 1 (and all other states output value 0), we obtain the following multivariate weighted automaton

¸c1   q
 <|1 zq
 <|1 zq
<|1 z_



0 ¸_ 
>|1
1_¸_ 
>|1
2_¸_
>|1
··· 

which clearly is an instantiation of our automaton above, with Ui = <, Di =
>, ui = di = 1 (and li = 0). By Theorem 17.1, we have
1

S(q0) = 


1		< | >	
  < | >	

1
1	< | >
. .

Putting σ = S(q0), one finds


which is equivalent to
.

1
σ =
1 − < × σ × >

σ = 1 + < × σ × > × σ


Recall that the problem we are trying to solve is that of counting the respective numbers of well-bracketed words. The (univariate) stream of all these numbers is obtained from the multivariate stream σ by identifying the variables < and
>, replacing them by one and the same variable X:
β = σ(X, X)
(Although we have not introduced a general operation of substitution for mul- tivariate streams, this type of variable substitution can be readily defined formally by means of behavioural differential equations.) As an immediate consequence of (87), β is the unique stream satisfying the following equation:
β = 1 + (X × β × X × β)
Since β is now a univariate stream, that is, an element of Rω, the techniques of Section 7 apply, and we find
1
β =	X2
1 −	X2
1 −	X2
1 − . .
2
= 1+ √1 − 4X2
=  (1, 0, 1, 0, 2, 0, 5, 0, 14, 0,.. .)
Here we recognize the numbers at the even positions as the Catalan numbers, which we already encountered as the solution of equation (36). (As an aside, note that, indeed,
2	2	2
1+ √1 − 4X2 = 1+ √1 − 4X (X )
where ( )(X2) refers to the composition operation on streams, as in identity (27).)
In the above example, the weights in the automaton, all being 1, played only a trivial role. In conclusion of this section, we recall the weighted au- tomaton for the Taylor series of the tangent function from Section 13, which has more interesting weights. In the notation of the present section, it looks like

¸c1   q
¸X,|1
q  X|1 zq
 X|2 zq
 X|3 z_

0	1 ¸_ 
X|2
2_¸_ 
X|3
3_¸_
X|4
··· 

where now the state q1 represent the Taylor series τ of tan(x), that is, τ =
S(q1). By (the proof of) Theorem 17.1, we find that
X
τ =
1 · 2 · X2
2 · 3 · X2
3 · 4 · X2
1 −	. .


which was mentioned but not yet proved in Section 13.

Discussion and related work
General references on (universal) coalgebra are [13,26]. Earlier work on a coalgebraic approach to automata, formal languages, and formal power series include [23,24]. The formulation of a coinductive proof principle in terms of bisimulation relations goes back to work by Aczel and Mendler [1,2], general- ising Park and Milner’s [21,19] notion of bisimulation to a categorical setting. The notion of stream derivative is a special instance of the notion of input
derivative, which goes back to [7]. It plays a role also in [9], where the chapter ‘The differential calculus of events’ already suggests a connection with classical calculus.
The definition of bisimulation-up-to is a variation on a similar notion by Milner [20] (see also [27]). In [3], variations and coalgebraic generalisations of coinductive proof methods are given. The present notion of bisimulation- up-to (identity and sum), can be easily generalised along the lines of [3], to a version which would allow derivatives to be bisimilar up to arbitrary contexts (including product, inverse, and the other operators). The proofs of for instance identities (15) and (26) could be simplified if we would have used bisimulation-up-to product.
The present paper extends [25], repeating part of its basic definitions and results on streams. A number of new operators have been added, as well as many new identities (including those on exponentiation and shuffle elimina- tion). Moreover, all of the applications are new.
Pavlovi´c and Escardo´’s paper on calculus in coinductive form [22], em- phasising the close connection between classical analysis and coinduction, has been an important source of inspiration for our work, motivating in particular the application of stream calculus to analytical differential equations. Other than parts of Theorems 10.1 and 12.1, the papers have, technically speaking, not very much in common.
Motivating sources of examples of streams and stream operators have been the books [11] and [30], and the papers by McIlroy [16,17] and Karczmarczuk [14,15].
The solution of difference equations by means of stream calculus is concep- tually very simple, since the entire game is played within the world of streams. In contrast to the classical technique of generating functions (as in [11] and [30]), functions (from R to R) are just not needed in stream calculus, and convergence issues thereby simply do not enter the picture.
As we have seen, streams can be viewed as formal power series (in one variable), which are often used as a formal alternative to generating func- tions, precisely to avoid convergence considerations. We see some advantages of stream calculus also over the use of formal power series. First, there is the rigorous use of coinduction, both in definitions and in proofs, which makes


stream calculus possibly more formal than the use of ‘formal’ power series usually is. Notably this applies to the use of the operation of inverse, which is not always treated strictly formally within theories of power series. Secondly, stream calculus is a more expressive calculus, because of the simultaneous presence of two types of multiplication: convolution product and shuffle prod- uct; of two corresponding types of inverse; and of two types of derivatives (ordinary and analytical). This is for instance illustrated by the example of a divergent recurrence in Section 9. The interplay between the various opera- tors, notably between convolution inverse and shuffle product, moreover gives rise to quite a few interesting identities (such as in Theorem 10.2), which seem to be the underlying facts for various results in different parts of mathematics. For instance, identity (68) is used both in the proof of the Euler formula (in Section 11) and in the proof of the characterisation of the Taylor transform of products with the exponential function (identity (85)).
Also in our proof of the Euler formula, no assumptions on convergence need to be made, in contrast to certain analytical proofs (as in [28, 11.38]). It shares with certain proofs in operator arithmetic the fact that it is very short and transparent, but has the additional advantage of being entirely formal, whereas the latter proofs often are by “a somewhat optimistic application of operator arithmetic” (cf. [28, page 75]).
Solving differential equations in stream calculus essentially amounts to the classical method of undetermined coefficients [5, p.82], with the difference that the obtained difference equations for the Taylor coefficients of the analytical solution, are solved within the world of streams. This approach is technically closely related to the use of Laplace transforms (cf. [29,18]), because the oper- ation of assigning the Taylor series (f ) to an analytical function f implicitly uses the Laplace-Carson transform (introduced in Section 10). Formulae such as (80)-(86) are similar to but different from the formulae of the corresponding Laplace transforms (cf. [29, page 519]). Conceptually, the use of stream cal- culus is different and, again, a bit simpler than these traditional approaches. In particular, analytical integration plays no role, since the difference equa- tions are solved by stream integration (applying the Fundamental Theorem of stream calculus, Theorem 4.1).
For a general reference on (rational) formal power series, see [6]. Theorems
13.3 and 13.4 are classical results. New about our use of weighted automata as representations for streams are: -the coinductive definition of their behaviour;
-the way such automata are constructed by means of splitting derivatives (as in the proof of Theorem 13.3); -and our use of infinite weighted automata (as in the example of (tan)). Part of all this can already be found in [25]. New with respect to the latter is the use of continued fractions, and the application in Section 17 to coinductive counting. Theorem 17.1 is a (slightly more general) variation on a classical result by Flajolet [10, Theorem 1], phrased here in terms of weighted automata and with a somewhat simpler coinductive proof. Weighted automata seem to offer an interesting alternative to the structures


for modelling enumerative problems used in [10], such as sets of labelled paths and path diagrams.
Another approach to counting is the categorical theory of species [4]. It offers a framework that is far more general than the present calculus of streams, but there are many connections. It would be worthwhile, more generally speaking, to investigate the possible role of coinduction in the world of species in some detail.
In conclusion, we observe that there are some obvious ways in which the results of stream calculus can be generalised. For one thing, one can look at other fields (such as the complex numbers) or even arbitrary semirings (such as the Booleans or so-called tropical semirings [12]). The role of inverse will then be replaced by the operation of Kleene star. Another variation would be to consider other structures such as binary trees. Finally, it could be interesting to look at partial streams, which would correspond to the elements of the final coalgebra of type R × (1+ (−)).

Appendix
Here is a more general theorem on the unique existence of the solution of systems of behavioural differential equations. Let Σ = {f, g,.. .} be a set of function symbols with arities rf , rg,.. ., and let T be the set of all terms built from symbols in Σ and the elements in Rω (now viewed as variables). Consider for each f ∈ Σ with arity r = rf a term tf ∈ T containing (at most) the variables σ1,..., σr, σ1' ,..., σr' , and σ1(0),..., σr(0) (the latter real numbers considered as constant streams). And consider a real-valued function hf : Rr → R.
Theorem 19.1 The following system of behavioural differential equations (one for each f ∈ Σ):

has a unique solution. That is, there exists for each f  Σ a unique stream operator (denoted by the same symbol) f : (Rω)r Rω satisfying the equation above.
Most of the equations that occur in Section 4 fit into the format of the theorem.
For instance, in

we have f = ×, r = 2, tf = (σ' × τ )+ (σ(0) × τ ') with variables τ, σ',τ ', σ(0), and hf is the multiplication of real numbers. The only operator that does not quite fit into the format is the generalised sum (because it takes a set I many


arguments). It is, however, rather easy either to generalise the formulation of the present theorem, or to treat the case of the generalised sum separately.
Proof. The set of all terms T can be turned into a stream coalgebra, by induction on the syntactic complexity of the terms, and following the equa- tions of the theorem. By finality, there exists a unique homomorphism from the coalgebra T into the coalgebra Rω, which assigns to each syntactic term f (σ1,..., σr) a stream in Rω. This stream is then what we define to be the effect of the operator f on the argument streams (σ1,..., σr). Rather than providing more detail here, we refer the reader to [25], where this construction is carried out in all detail for (a subset of) the operators of stream calculus. For a more general treatment of this type of coinductive definitions, see also [3].	✷

Acknowledgements
I am much indebted to Alexandru Baltag, Falk Bartels, and Alexander Kurz for numerous stimulating discussions, suggestions, and corrections. Special thanks are due to Falk Bartels for detailed comments on a draft of this paper. I am also grateful to the following persons for various types of comments, suggestions, and pointers to the literature: Jan Komenda, Gilbert Labelle, Doug McIlroy, Dusko Pavlovic, Andy Pitts, Jan van Schuppen, Nico Temme, and the members of the ACG Colloquium, headed by Jaco de Bakker.


References
P. Aczel. “Non-well-founded Sets,” Number 14 in CSLI Lecture Notes. Center for the Study of Languages and Information, Stanford, 1988.
P. Aczel and N. Mendler. A ﬁnal coalgebra theorem, In D.H. Pitt, D.E. Ryeheard, P. Dybjer, A. M. Pitts, and A. Poigne, editors, Proceedings category theory and computer science, Lecture Notes in Computer Science 389 (1989),
pp. 357–365.
F. Bartels. Generalised coinduction, Report SEN-R0043, CWI, 2000. Available at URL: www.cwi.nl. Extended abstract in Electronic Notes in Theoretical Computer Science 44.1 (2001), Elsevier, 2001, Available at URL: http://www.elsevier.nl/locate/entcs/volume44.html.
F. Bergeron, G. Labelle, and P. Leroux. “Combinatorial Species and Tree-like Structures,” Volume 67 of Encyclopedia of Mathematics and its Applications, Cambridge University Press, 1998.
G. Birkhoff and G.-C. Rota. “Ordinary Differential Equations (Third Edition),” John Wiley and Sons, 1978.


J. Berstel and C. Reutenauer. “Rational Series and Their Languages,” Volume 12 of EATCS Monographs on Theoretical Computer Science, Springer- Verlag, 1988.
J.A. Brzozowski. Derivatives of regular expressions, Journal of the ACM 11
(4) (1964), pp. 481–494.
L. Comtet. “Advanced Combinatorics,” D. Reidel Publishing Company, 1974.
J.H. Conway. “Regular Algebra and Finite Machines,” Chapman and Hall, 1971.
P. Flajolet. Combinatorial aspects of continued fractions, Discrete Mathematics
32 (1980), pp. 125–161.
R.L. Graham, D.E. Knuth, and O. Patashnik. “Concrete Mathematics,” Second Edition. Addison-Wesley, 1994.
J. Gunawardena. “Idempotency,” Publications of the Newton Institute. Cambridge University Press, 1998.
Bart Jacobs and Jan Rutten. A tutorial on (co)algebras and (co)induction,
Bulletin of  the  EATCS  62  (1997),  pp  222–259.	Available at URL:
www.cwi.nl/∼janr.
J. Karczmarczuk. Generating power of lazy semantics, Theoretical Computer
Science 187 (1997), pp. :203–219.
J. Karczmarczuk. Lazy processing and optimization of discrete sequences, In
Proceedings of the JFLA’2000, 2000. In French.
M.D. McIlroy. Power series, power serious, Journal of Functional Programming 9 (1999), pp. :323–335.
M.D. McIlroy.	The music of streams,	Information Processing Letters, 77
(2001), pp. 189–195.
J. Mikusinski. “Operational calculus,” Volume 109. Pergamon press, 1983.
R. Milner. “A Calculus of Communicating Systems,” Lecture Notes in Computer Science 92 (1980), Springer-Verlag, Berlin.
R. Milner. “Communication and Concurrency,” Prentice Hall, 1989.
D.M.R. Park. Concurrency and automata on inﬁnite sequences, In P. Deussen, editor, Proceedings 5th GI conference, volume 104 of Lecture Notes in Computer Science, pages 15–32. Springer-Verlag, 1981.
D. Pavlovi´c and M. Escardo´. Calculus in coinductive form, In Proceedings of the 13th Annual IEEE Symposium on Logic in Computer Science, pages 408–417. IEEE Computer Society Press, 1998.
J.J.M.M. Rutten. Automata and coinduction (an exercise in coalgebra), Report SEN-R9803, CWI, 1998. Available at URL: www.cwi.nl. Also in the proceedings of CONCUR ’98, LNCS 1466, 1998, pp. 194–218.


J.J.M.M. Rutten. Automata, power series, and coinduction: taking input derivatives seriously (extended abstract), Report SEN-R9901, CWI, 1999. Available at URL: www.cwi.nl. Also in the proceedings of ICALP ’99, LNCS 1644, 1999, pp. 645–654.
J.J.M.M. Rutten. Behavioural differential equations: a coinductive calculus of streams, automata, and power series, Report SEN-R0023, CWI, 2000. Available at URL: www.cwi.nl.
J.J.M.M. Rutten. Universal coalgebra: a theory of systems, Theoretical Computer Science, 249(1):3–80, 2000.
D. Sangiorgi. On the bisimulation proof method, Mathematical Structures in Computer Science, 8(5):447–479, 1998.
F. Scheid. “Theory and problems of numerical analysis (Schaum’s outline series),” McGraw-Hill, 1968.
I.N. Sneddon. “The use of integral transforms.” McGraw-Hill, 1972.
H.S. Wilf. “Generatingfunctionology,” Academic Press, San Diego, CA, 1994.
