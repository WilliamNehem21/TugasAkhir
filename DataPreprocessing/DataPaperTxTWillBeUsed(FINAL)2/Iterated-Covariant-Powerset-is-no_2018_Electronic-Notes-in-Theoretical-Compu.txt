Available online at www.sciencedirect.com


Electronic Notes in Theoretical Computer Science 341 (2018) 261–276
www.elsevier.com/locate/entcs
Iterated Covariant Powerset is not a Monad 1
Bartek Klin2
Faculty of Mathematics, Informatics, and Mechanics University of Warsaw
Warsaw, Poland
Julian Salamanca 3
Faculty of Mathematics, Informatics, and Mechanics University of Warsaw
Warsaw, Poland

Abstract
We prove that the double covariant powerset functor PP does not admit any monad structure. The same applies to the n-fold composition of P for any n > 1.
Keywords: monad, double covariant powerset, distributive law

Introduction
The categorical concept of a monad (see e.g. [19, Ch. VI]) has found multiple appli- cations in mathematical foundations of programming science, and they have become an important design pattern in languages such as Haskell [12, 33] or Scala [27]. De- pending on the context, monads can be viewed as abstract notions of computational effects [26, 34], or as collections to gather computed values [24], or as structures of values to be computed upon [3]. These perspectives are not mutually exclusive: for example, the (covariant) powerset monad  can be seen either as a very simple kind of unstructured collections, or as a carrier of nondeterminism as a computational effect.
An application where monads are viewed both as effects and as collections is the coalgebraic study of trace semantics of transition systems and automata (e.g. [6, 11,

1 Research supported by the European Research Council (ERC) under the European Unions Horizon 2020 research and innovation programme (ERC consolidator grant LIPA, agreement no. 683080).
2 Email: klin@mimuw.edu.pl
3 Email: jsalamanca@mimuw.edu.pl

https://doi.org/10.1016/j.entcs.2018.11.013
1571-0661/© 2018 The Author(s). Published by Elsevier B.V.
This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).

13,15,18,28,29]). There, a monad usually appears as a component of the type of be- haviour of transition systems; more specifically, the component that represents the “type of branching” that systems exhibit, as opposed to the other component, the “type of transition”, usually required to be simply an endofunctor. Typical mon-
powerset monad f for nondeterministic systems, and the probability distribution monad for probabilistic systems. One then resolves branching by interpreting sys- tems in either the Kleisli or the Eilenberg-Moore category for the monad, either to collect behaviour traces of a system or to return a determinised system of a simpler type.
With this rough idea in mind, one naturally turns attention to alternating au- tomata [5], which play a fundamental role in language theory and verification. To model them coalgebraically, it is natural to consider systems where the branching type is modeled by the double powerset functor. There are actually two functors
2−
that bear this name and act in the same way on objects: the double powerset 2 ,
which is the composition of the contravariant powerset with itself, and the double powerset  , which is the composition of the covariant powerset with itself. Coal- gebras for the former functor (which, by the way, is a well-known monad), called neighbourhood frames [10], have a rather different behaviour from alternating au- tomata. The use of double covariant powerset is more promising (see [14,15,17]), but before one applies, off-the-shelf style, the machinery of coalgebraic trace semantics to alternating automata, one needs to answer the question: is   a monad?
This simple question does not seem to get a simple answer in the literature so far. Some authors avoid the question by looking for more laborious ways to deal with alternating behaviour (e.g. [15, Sec. 5.3] or [17, Ex. 4.5] or [14, Ex. 12] or [2]), which suggests that they do not expect an easy positive answer. Others give an explicit negative answer [31], but without any concrete evidence for it. On the other hand, Manes in [21, Ex. 2.12] proposed a specific monad structure on
, only to remark later [23] that the structure is flawed. (The same mistake was repeated in [22, Ex. 2.4.7] and independently by one of us in [16, Ex. 9], then noticed in [4, Sec. 7] and [17, Ex. 6.8].)
Our main contribution in this paper is a proof that the double covariant powerset
finite powerset PfPf. More generally, neither Pn nor Pn (i.e. the n-fold composition
f

It is a standard result that a distributive law λ TS	ST of a monad T over a monad S defines a monad structure on the composite functor ST . Our result therefore implies that there is no distributive law of the monad  over itself.
an endofunctor equipped with a unit natural transformation η ∶ Id =⇒ P, with no
of this resembles a previously known proof (credited to Plotkin in [32, Prop. 3.2]) that the probability distribution monad does not admit any distributive law over
, and we formulate it in a way that generalises both cases: if a pointed functor T ,

(1) preserves preimages and (2) admits what we call a nontrivial idempotent term, then there is no distributive law of T over	(both considered as pointed functors). This contrasts with (but does not contradict) some known positive results about the existence of distributive laws. In [13, Sec. 4] it is proved that every functor that preserves weak pullbacks admits a distributive law over the monad	. By [25, Thm. 2.9], every analytic functor has a distributive law over every commutative monad. (	is commutative, and although it is not analytic, it is easy to find an analytic functor that satisfies our conditions (1) and (2) above.) Finally, [15, Lem. 8] shows a very simple distributive law of any monad over the underlying functor of another monad, provided that the two monads are linked by a monad morphism. In all these works, distributive laws of the functor-over-monad or monad-over-functor shape are constructed, whereas we show the lack of distributive laws of pointed
functors over pointed functors.
The structure of this paper is as follows. In Section 2 we prove a negative result about the existence of distributive laws of pointed functors. In Section 3, we prove
n
any n > 1. In Section 5 we summarise some previous erroneous attempts to define
We are grateful to Miko-laj Bojan´czyk for inspiring discussions and to Filippo Bonchi, Fabio Zanasi and Maaike Zwart for valuable comments. The first author thanks Joost Winter for pointing out the mistake in [16], and Jurriaan Rot for tracing it back to [22].
Distributive laws
Throughout this paper we work only in the category of sets and functions. A monad
transformations η ∶ Id =⇒ T (the unit) and μ ∶ TT =⇒ T (the multiplication) such


T   ηT zT T3¸Tcη	T
TTT  T μ  zT T3

(†)
μ
(‡)
  z
μT	μ
  z	 z
(1)

T	TT	μ	zT.3
When no risk of confusion arises, we will denote such a monad simply by T .
The (covariant) powerset monad	is defined so that	X is the set of all subsets of X, and:
ηX (x)= {x},	μX (Φ)= ⋃Φ	for x ∈ X, Φ ⊆ PX.
All results in this paper remain true when P is replaced by the ﬁnite powerset
f
To simplify the presentation, we will only consider functors T that preserve inclusions, i.e., such that X	Y implies TX	TY and the inclusion function from

X to Y is mapped by T to the inclusion function from TX to TY . This assumption only matters in this section, and it could be dropped with little effort. The functor
obviously preserves inclusions.
A pointed functor (T, η) is an endofunctor T together with a unit natural trans-
(functor. A distributive law of a pointed functor (T, ηT ) over a pointed functor
λ ∶ TS =⇒ ST
such that the following two unit laws hold:

TηS	ηT S

T 	 zT S3¸c  S
(2)

λ
ηST	v ,zjSηT
ST	.
If S and T are monads, λ becomes a distributive law of the monad T over the monad S if it satisfies two further axioms that involve the multiplication structures of S and T (see [1]).
The following definition is taken from [9] (where it is formulated more generally, without assumming that T preserves inclusions). Functors with the property below are also known as taut [20] or semi-analytic [30].
Definition 2.1 A functor T preserves preimages if for every function f ∶ X → Y ,a 

if	Tf (t)∈ TZ	then	t ∈ T (f −1(Z)),	(3) where f −1(Z)⊆ X denotes the inverse image of Z along f .
If, additionally, X	Y and f	X	Y is the inclusion function, the above
property specialises to
TX ∩ TZ ⊆ T (X ∩ Z).	(4)
Most functors considered in coalgebra theory, including	, preserve preimages (see [9] for a detailed study).
Definition 2.2 A nontrivial idempotent term for a pointed functor T, η is a nat- ural transformation


such that:
β ∶ Id × Id =⇒ T

βX (x, x)= ηX (x) for each x ∈ X (idempotence), and
β{0,1}(0, 1) ∈/ T {0}∪ T {1} (non-triviality).

Example 2.3 The functor P admits a nontrivial idempotent term defined by:
βX (x, y)= {x, y}	for x, y ∈ X.
The probability distribution monad (called V in [32], but studied also in e.g. [8]) also admits a nontrivial idempotent term:
β (x, y)= 1 x + 1 y	for x, y ∈ X.

Other examples of a nontrivial idempotent term include: the free (distributive) lattice monad (βX x, y	x y) and the free idempotent monoid monad (βX x, y


canonically corresponds to an element of T 2. For T = P, the β above corresponds


trivial idempotent term, then there is no distributive law of (T, η) over the pointed

Proof. Assume, towards a contradiction, that there is such distributive law λ ∶

A = {a, b, c, d}	and	U = {u, v}
and three functions f, g, h ∶ A → U defined by:
f (a)= f (b)= u,	g(a)= g(c)= u,	h(a)= h(d)= u,
f (c)= f (d)= v,	g(b)= g(d)= v,	h(b)= h(c)= v.	(5)
Consider the element
t = βPA({a, b}, {c, d}) ∈ T PA
and analyse how the three naturality squares for f , g and h act on t:

T PA  T Pf  T P¸U
T PA  T Pg T P¸U

T PA  T Ph T P¸U

λA	λU	λA
  
λU	λA	λU
  	  

PTA PTf P¸TU 
PTA PTg P¸TU 
PTA PTh P¸T U.

Recall that P acts on functions by taking direct images, so in particular:
Pf {a, b}= {u}	Pg{a, b}= Ph{a, b}= {u, v},
Pf {c, d}= {v}	Pg{c, d}= Ph{c, d}= {u, v}.
By naturality and idempotence of β we get:
T Pg(t)= T Ph(t)= βPU ({u, v}, {u, v}) = ηPU {u, v}

hence, by a unit law for λ in (2):
λU (T Pg(t)) = λU (T Ph(t)) = {ηU (u), ηU (v)}.
By naturality squares for g and h we obtain:
PTg(λA(t)) = PT h(λA(t)) = {ηU (u), ηU (v)}
which implies that λA(t) is nonempty and
Tg(s),Th(s)∈ {ηU (u), ηU (v)}	for every s ∈ λA(t).	(6)
Now, if for example Tg(s) = ηU (u) ∈ T {u} then, by (3) for Z = {u}, we obtain

s ∈ (T {a, c}∪ T {b, d}) ∩ (T {a, d}∪ T {b, c})	for every s ∈ λA(t).
Distributing intersections over unions and using the intersection preservation prop- erty (4), we get:
s ∈ T {a}∪ T {b}∪ T {c}∪ T {d}	for every s ∈ λA(t).	(7) Now let us come back to the function f . By naturality of β we get:
T Pf (t)= βPU ({u}, {v})
hence, by the naturality square for f and by a unit law for λ in (2):
PTf (λA(t)) = λU (T Pf (t)) = {βU (u, v)}.


This means that

Tf (s)= βU (u, v)	for every s ∈ λA(t).

But this, together with (7), contradicts the assumption that β is nontrivial. Indeed, if for example s  T a  then Tf s  T u  so Tf s  cannot be βU u, v .
This is essentially the same proof as in [32, Prop. 3.2] for the probability distri- bution monad taken as T , in that the same sets A, U and functions f, g, h are used there. Here we distilled assumptions so that the proof covers also the case of T   .
PP is not a monad
Theorem 2.4 implies that there is no distributive law of the monad P over itself.
this does not prove yet that such a monad structure does not exist. As shown in [1], composite monads that arise from distributive laws are of a special form, and not every monad is of that form in general.

Example 3.1 For any monoid (M, e, ⋅), the functor TX = M × X is a monad with
ηX (x)= (e, x),	μX (g, h, x)= (g ⋅ h, x)	for x ∈ X, g, h ∈ M.	(8)
Z
the set {0, 1, 2, 3} ≅ 2 × 2 defines a monad structure on the functor TT . Pick the
infinity (i.e., x ⋅ 3 = 3 for every x and 2 ⋅ 2 = 3). From [1] we know that for every
is a monad morphism. Both our T and TT arise from monoids as in (8), and monad morphisms between such monads correspond to homomorphisms between the corresponding monoids. However, the only monoid homomorphism from Z2 to our M is trivial and therefore non-injective. This gives a contradiction, since by
† in (1) the transformation ηT must be pointwise injective. As a result, our M
cannot be derived from any distributive law of T over T .
This example shows that sometimes monads on composite functors do not arise from distributive laws between those functors, so Theorem 2.4 does not quite answer our main question yet. However:
Theorem 3.2 There is no monad structure on PP.
Proof. We use the same situation with sets A, U and functions f, g, h  A  U as in (5) in the proof of Theorem 2.4, but we analyse it some more. We remark that this idea is not unexpected. Indeed, in the recent work [7] it is stated that
PprDobability distribution monad D, can be modified to show that the composition Denote T = PP. Assume, towards contradiction, that there exist natural trans-

Nat(Id,T )= Nat(Set(1, ),T )≅ T 1 = PP1 = {∅, {∅}, {1}, {∅, 1}}.
Therefore, there are only four possible choices for η, which are defined for every
x  X as:
η♣ (x)= ∅, η♢ (x) = {∅}, η♡ (x)= {{x}} and η♠ (x)= {∅, {x}}.
Note that η♣ and η♢ cannot be the unit of such a monad since, by † in (1), every component of ηT must be injective.
PPCPoPnsider now the case of η♡. For A = {a, b, c, d}, consider the element S ∈ TTA =

S = {{{{a}, {b}}, {{c}, {d}}}}.	(9)

Notice that, for U = {u, v}:
μU ⎛{{{{u}}, {{v}}}}⎞ = {{u, v}}	and	μU ⎛{{{{u}, {v}}}}⎞ = {{u}, {v}},

⎝	⎠	⎝
⎠
(10)

which follow from (‡) in (1) acting on {{u, v}} ∈ TU and from (†) in (1) acting on { u , v }  TU , respectively. Now, consider the function f  A  U as defined in (5). By naturality of μ we have:
(Tf ○ μ )(S) = (μ  ○ TTf )(S) (1=0) {{u, v}}.
Therefore, since T acts on functions by taking direct images, we have that:
∅≠ μA(S) ⊆ {{a, b, c, d}, {a, b, c}, {a, b, d}, {a, c, d}, {b, c, d}, {a, c}, {a, d}, {b, c}, {b, d}}.
Now, consider the function g ∶ A → U as defined in (5). By naturality of μ we have:
(Tg ○ μA)(S) = (μU ○ TTg)(S)  =  {{u}, {v}}.
(10)
Together with (11), this implies that:
μA(S) = {{a, c}, {b, d}}.	(12)
With this established, consider the function h	A	U as defined in (5). By naturality of μ we have:
{{u, v}} (1=2) (Th ○ μ )(S) = (μ ○ TTh)(S) (1=0) {{u}, {v}},
which is a contradiction. Therefore, η♡ cannot be the unit of such a monad.
Finally, consider the case of η♠. For A = {a, b, c, d} as before, consider the

S = {∅, {{∅, {a}, {b}}, {∅, {c}, {d}}}}.	(13)
By analogy to (10), for U = {u, v} we have that:
μU ⎛{∅, {{∅, {u}}, {∅, {v}}}}⎞ = {∅, {u, v}}	and
⎝	⎠
μU ⎛{∅, {{∅, {u}, {v}}}}⎞ = {∅, {u}, {v}}	(14)
⎝	⎠
which follow from (‡) in (1) acting on {∅, {u, v}} ∈ TU and from (†) in (1) acting on
{ , u , v }	TU , respectively. Now, consider the function f A	U as defined in (5). By naturality of μ we have:
(Tf ○ μA)(S) = (μU ○ TTf )(S) (1=4) {∅, {u, v}}.

Therefore, we have that:
∅≠ μA(S) ⊆ {∅, {a, b, c, d}, {a, b, c}, {a, b, d}, {a, c, d}, {b, c, d}, {a, c}, {a, d}, {b, c}, {b, d}}.
Now, consider the function g ∶ A → U as defined in (5). By naturality of μ we have:
(Tg ○ μA)(S) = (μU ○ TTg)(S)  =  {∅, {u}, {v}}.
(14)
Together with (15), this implies that:
μA(S) = {∅, {a, c}, {b, d}}.	(16)
With this established, consider the function h A  U as defined in (5). By naturality of μ we have:
{∅, {u, v}} (1=6) (Th ○ μ )(S) = (μ ○ TTh)(S) (1=4) {∅, {u}, {v}},
which is a contradiction. Therefore, η♠ cannot be the unit of such a monad. This finishes the proof that there is no monad structure on T = PP.	◻
Pn is not a monad for n > 1
Intuitively, the cases of η♡ and η♠ in the proof of Theorem 3.2 clearly follow a similar pattern. To generalise the theorem to n (i.e. the n-fold composition of ) we need to understand that pattern better, since candidates for a monad unit for
n are more numerous and complicated, making ad-hoc reasoning impossible.
Theorem 4.1 There is no monad structure on Pn, for any n > 1.
Proof. Denote T = Pn. The case n = 2 was dealt with in Theorem 3.2, so we transformations η ∶ Id =⇒ T and μ ∶ TT =⇒ T that make the diagrams in (1) We use the same situation with sets A = {a, b, c, d}, U = {u, v} and functions
Denote 1 = {⋆}. For a set X and elements x ≠ y ∈ X, define γx,y ∶ P21 → P2X
by:
γx,y(∅) = ∅	γx,y({{⋆}})= {{x}, {y}}
γx,y({∅}) = {∅}	γx,y({∅, {⋆}})= {∅, {x}, {y}}.
Then define Bx,y ∈ PnX by:
Bx,y = (Pn−2γx,y)(η1(⋆)).
We shall use three objects defined by this formula: Ba,b, Bc,d ∈ PnA and Bu,v ∈ PnU .

Furthermore, define a function σ ∶ P1 → Pn+1A by:
σ(∅) = ∅	σ({⋆}) = {Ba,b, Bc,d}
and let S ∈ P2nA be defined by:
S = (Pn−1σ)(η1(⋆)).	(17)
Note that this definition of	coincides with (9) and (13) for the two particular η’s considered in the proof of Theorem 3.2.
We will strive for contradiction by looking at the naturality squares for μ on maps f , g and h from (5), acting on the element	:


P2nA P2nf P¸2nU
P2nA P2ng P¸2nU
P2nA P2nh P¸2nU

μA	μU	μA
  
μU	μA	μU
  	  

PnA

Pnf
 P¸nU
PnA

Png
 P¸nU
PnA

Pnh
 P¸nU.

First, since f (a)= f (b)= u, the composition
P2f ○ γa,b ∶ P21 → P2U
is the function P2(⋆ ↦ u). As a result we obtain
(Pnf )Ba,b = (Pnf )((Pn−2γa,b)(η1(⋆))) = (Pn−2(P2f ○ γa,b))(η1(⋆))
= (Pn(⋆ ↦ u))(η1(⋆)) = ηU (u).	(18)
By the same reasoning we get
(Pnf )Bc,d = ηU (v).	(19)
On the other hand, since g(a)= u and g(b)= v, the composition
P2g ○ γa,b ∶ P21 → P2U
is simply the function γu,v, and the same applies to h instead of g and/or c, d instead of a, b. As a result we obtain
(Png)Ba,b = (Png)Bc,d = (Pnh)Ba,b = (Pnh)Bc,d = Bu,v.	(20) Now come back to the function σ. Using (18) and (19), the composition:
Pn+1f ○ σ ∶ P1 → Pn+1U
is mapping ∅ to ∅ and {⋆} to {ηU (u), ηU (v)}. Define a function θ ∶ P1 → PU by:
θ(∅) = ∅	θ({⋆}) = {u, v}.

We have just shown that


We can therefore derive:


Pn+1f ○ σ = PηU ○ θ.	(21)

(P2nf )(S) (1=7) (P2nf )((Pn−1σ)(η (⋆))) = (Pn−1(Pn+1f ○ σ))(η (⋆))


(2=1) (Pnη
1	1
)((Pn−1θ)(η1(⋆))).

By the unit law (‡) in (1) this implies that
μU ((P2nf )(S)) = (Pn−1θ)(η1(⋆)),
which by naturality of μ means that
(Pnf )(μA(S)) = (Pn−1θ)(η1(⋆)).	(22)
Let us now turn attention to the function g. By (20), the composition
Pn+1g ○ σ ∶ P1 → Pn+1U
is mapping ∅ to ∅ and {⋆} to {Bu,v}. This means that:
(P2ng)(S) (1=7) (P2ng)((Pn−1σ)(η (⋆))) = (Pn−1(Pn+1g ○ σ))(η (⋆))
1	1
=  (Pn(⋆ ↦ Bu,v))(η1(⋆)) = ηP nU (Bu,v).
The same applies to h instead of g. This, by the unit law † in (1) and by naturality of μ, implies that
(Png)(μA(S)) = (Pnh)(μA(S)) = Bu,v = (Pn−2γu,v)(η1(⋆)).	(23)
From now on we will work with (22) and (23). We will first bring the exponent n
in these equations down to 3, which will be enough to obtain a contradiction.
To this end, consider the natural transformation
ν ∶ Pn−2 =⇒ P
which is the standard multiplication of the monad P, iterated in the obvious sense


and by (22) post-composed side-wise with νP2U , and denoting Q	νP2A
we obtain:
μA(S) ,

(P3f )(Q)= ν

P2U
((Pnf )(μA
(S))) (2=2) ν

P2U
((Pn−1θ)(η1(⋆)))

= (P2θ)(νP2A(η1(⋆))).	(24)

Similarly, postcomposing both sides of (23) with νP2U , we obtain:

(P3g)(Q)= ν

P2U
((Png)(μA
(S))) (2=3)

νP2U
((Pn−2γ


u,v
)(η1(⋆)))



and the same for h in place of g.
=	(Pγu,v)(νP2A(η1(⋆)))	(25)

Note that the function γu,v takes on only four distinct values. Denoting Γ = {∅, {∅}, {{u}, {v}}, {∅, {u}, {v}}}⊆ P2U,
we may write the type of this function as γu,v ∶ P21 → Γ. Similarly, the function θ

Θ = {∅, {∅}, {{u, v}}, {∅, {u, v}}}⊆ P2U.

From (24) and (25) we infer:
(P3f )(Q)∈ PΘ,	(P3g)(Q)∈ PΓ,	(P3h)(Q)∈ PΓ.
This means that for every R ∈ Q we have
(P2f )(R)∈ Θ,	(P2g)(R)∈ Γ,	(P2h)(R)∈ Γ.
The first two of these conditions taken together imply, by using a similar reasoning as in the proof of Theorem 3.2, that:
R ∈ {∅, {∅}, {{a, c}, {b, d}}, {∅, {a, c}, {b, d}}}.

Then the extra condition (P2h)(R)∈ Γ implies that R ∈ {∅, {∅}}, so we infer
Q ⊆ {∅, {∅}} = P2∅	hence	Q ∈ P3∅.
Recall that Q denotes νP 2A(μA	). By the way the natural transformation ν is defined, we get


Using (22) we infer
μA(S)∈ Pn∅.

(Pn−1θ)(η1(⋆)) ∈ Pn∅

hence, by definition of θ and by how Pn−1 acts on functions,
η1(⋆) ∈ Pn∅.
By naturality of η we get that for every set X and element x ∈ X
ηX (x)∈ Pn∅.

But the set Pn∅ is finite and it does not depend on X, therefore for every X such since by the unit law (†) in (1) the function ηTX must be injective for every X. ◻
Mistakes
We shall now summarise different sources in which it has been mistakenly concluded that	is a monad.
Mistake by Klin and Rot, 2015 [16]
In [16, Ex. 9], it is claimed that a monad-over-monad distributive law λ
could be formally defined by:
λX (A) = {Pg(A) ∣ g ∶ A → X s.t. g(A)∈ A for each A ∈ A}	for A ⊆ PX. (26) In words, given a family A of subsets of X, λX returns the family of subsets obtained
The mistake in this is that λ is not a natural transformation. This was noticed in [4, Sec. 7]; a variant of the argument, pointed out to us by J. Winter, is the following. Consider
X = {a, b, c}	Y = {d, e}	f (a)= f (b)= d	f (c)= e.
The naturality square for f ∶ X → Y does not commute, as shown here:
{{a, c}_, {b, c}} 	 {{¸d_, e}}
∈	∋
P2X	P2f	 P¸2Y

λX	λY
P2f	 

P2X
 P¸2Y
∋	{{d}, {e}}

∈	∈	≠
{{a, b}, {a, c} {  }, {c}} 	 {{¸d}, {d, e},

Mistake by Manes and Mulry, 2003-07 [21, 22]
In [22, Ex. 2.4.7], a “distributive law” of P over P is defined by:

λX (A) = {{aA ∣ A ∈ A} ∣ (aA)∈ ∏ A}	for A ⊆ PX.	(27)

It is not difficult to see that this definition is equivalent to (26), and so it does not define a natural transformation. In [22] naturality of λ is actually inferred from the naturality of the unit and multiplication of a purported monad   claimed there.

The reader of [22] is referred to [21, pages 76–79] for a proof that PP is a monad.
multiplication μ is derived from that in the usual way (see [21, Prop. 2.14]).
Given a function f ∶ X → PPY , a function f # ∶ PPX → PPY is defined in [21]

by:

f #(A) = { ⋃ Bx ∣ A ∈ A, ∀x ∈ A.Bx ∈ f (x)} .


This is equivalent to saying that
B ∈ f #(A) ⇐⇒ ∃A ∈ A.∃(Bx ∈ f (x))x∈A. B = ⋃ Bx	(28) for A ⊆ PX. Here, the second existential quantifier means that “there exists a Viewing this (−)# as a Kleisli extension and the obvious ηX (x) = {{x}} as the
Since that structure is wrong, one expects problems with the Kleisli triple, and indeed the axiom:
(g# ○ f )# = g# ○ f #	for f ∶ X → PPY, g ∶ Y → PPZ	(29)
fails.
In [21], on pages 78–79, a proof of the axiom is attempted. The left-hand side is rewritten as:

C ∈ (g# ○ f )#(A) ⇐⇒ ∃A ∈ A.∃(Bx ∈ f (x))x∈A.∃(Cx,y ∈ g(y))x∈A,y∈B

.C = ⋃ ⋃ Cx,y

x∈A y∈Bx
and this transformation is correct. The right-hand side is first rewritten as:
C ∈ (g#(f #(A)) ⇐⇒ ∃B ∈ f #(A).∃(Cy ∈ g(y))y∈B. C = ⋃ Cy
⇐⇒ ∃A ∈ A.∃(Bx ∈ f (x))x∈A.∃(Cy ∈ g(y))x∈A,y∈⋃x∈A Bx .C =	⋃	Cy

and this is also correct. However, in the last equivalence on page 78, this is then equated to the left-hand side, and this is incorrect. Intuitively, looking at the third existential quantifiers on both sides above, the equality may not hold if the family Bx x∈A contains some overlapping sets.
Indeed, the axiom (29) fails for the following data:
X = {1, 2}	Y = {∗}	Z = {a, b} f (1)= f (2)= {{∗}}	g(∗) = {{a}, {b}}.
To see this, calculate from (28)
B ∈ f #({{1, 2}}) ⇐⇒ ∃A = {1, 2}.∃B1, B2 = {∗}.B = B1 ∪ B2

so f #({{1, 2}})= {{∗}}. Further, again from (28):

C ∈ g#({{∗}}) ⇐⇒ ∃B = {∗}.∃C∗ ∈ {{a}, {b}}.C = C∗
so
g#(f #({{1, 2}}))= g#({{∗}})= {{a}, {b}}.
On the other hand, g# ○ f ∶ X → PPZ is defined by:
g#(f (1)) = g#(f (2)) = g#({{∗}})= {{a}, {b}}.

So calculate from (28):
C ∈ (g# ○ f )#({{1, 2}}) ⇐⇒ ∃A = {1, 2}.∃C1, C2 ∈ {{a}, {b}}.C = C1 ∪ C2
therefore


hence
(g# ○ f )#({{1, 2}})= {{a}, {b}, {a, b}}

(g#f )#({{1, 2}})≠ g#(f #({{1, 2}})).


References
Jon Beck. Distributive laws. In B. Eckmann, editor, Seminar on Triples and Categorical Homology Theory, pages 119–140, Berlin, Heidelberg, 1969. Springer Berlin Heidelberg.
Meven Bertrand and Jurriaan Rot. Coalgebraic determinization of alternating automata. CoRR, abs/1804.02546, 2018.
Mikol-aj Bojan´czyk. Recognisable languages over monads. In Igor Potapov, editor, Developments in Language Theory, pages 1–13. Springer International Publishing, 2015.
Filippo Bonchi and Fabio Zanasi. Bialgebraic Semantics for Logic Programming. Logical Methods in Computer Science, 11, 2015.
Ashok K. Chandra, Dexter C. Kozen, and Larry J. Stockmeyer. Alternation. J. ACM, 28(1):114–133, January 1981.
Corina Cirstea. Canonical coalgebraic linear time logics. In Lawrence S. Moss and Pawel Sobocinski, editors, 6th Conference on Algebra and Coalgebra in Computer Science (CALCO 2015), volume 35 of Leibniz International Proceedings in Informatics (LIPIcs), pages 66–85, Dagstuhl, Germany, 2015. Schloss Dagstuhl–Leibniz-Zentrum fuer Informatik.
Fredrik Dahlqvist and Renato Neves. Program semantics as Kleisli representations. to appear.
Erik P. de Vink and Jan J. M. M. Rutten. Bisimulation for probabilistic transition systems: A coalgebraic approach. Theoretical Computer Science, 221(1-2):271–293, 1999.
H. Peter Gumm and Tobias Schr¨oder. Types and coalgebraic structure. Algebra Universalis, 53(2- 3):229–252, 2005.
Helle Hvid Hansen, Clemens Kupke, and Eric Pacuit. Neighbourhood structures: Bisimilarity and basic model theory. Logical Methods in Computer Science, Volume 5, Issue 2, 2009.
Ichiro Hasuo, Bart Jacobs, and Ana Sokolova. Generic trace semantics via coinduction. Log. Meth. Comp. Sci., 3, 2007.


Paul Hudak, Simon L. Peyton Jones, Philip Wadler, Brian Boutel, Jon Fairbairn, Joseph H. Fasel, Mar´ıa M. Guzm´an, Kevin Hammond, John Hughes, Thomas Johnsson, Richard B. Kieburtz, Rishiyur S. Nikhil, Will Partain, and John Peterson. Report on the programming language Haskell, a non-strict, purely functional language. SIGPLAN Notices, 27(5):1, 1992.
Bart Jacobs. Trace semantics for coalgebras. Electronic Notes in Theoretical Computer Science, 106:167–184, 2004. Proceedings of the Workshop on Coalgebraic Methods in Computer Science (CMCS).
Bart Jacobs, Paul B. Levy, and Jurriaan Rot. Steps and traces. In Corina Cirstea, editor, 14th International Workshop on Coalgebraic Methods in Computer Science, CMCS 2018. Springer International Publishing, 2018. To appear.
Bart Jacobs, Alexandra Silva, and Ana Sokolova. Trace semantics via determinization. Journal of Computer and System Sciences, 81(5):859 – 879, 2015.
Bartek Klin and Jurriaan Rot. Coalgebraic trace semantics via forgetful logics. In FoSSaCS 2015. Proceedings, pages 151–166, 2015.
Bartek Klin and Jurriaan Rot. Coalgebraic trace semantics via forgetful logics. Log. Meth. Comp. Sci., 12, 2016.
Alexander Kurz, Stefan Milius, Dirk Pattinson, and Lutz Schr¨oder. Simplified coalgebraic trace equivalence. In Software, Services, and Systems: Essays Dedicated to Martin Wirsing on the Occasion of His Retirement from the Chair of Programming and Software Engineering, pages 75–90. Springer International Publishing, 2015.
Saunders Mac Lane. Categories for the Working Mathematician. Springer, second edition, 1998.
Ernest G. Manes. Taut monads and T0-spaces. Theor. Comput. Sci., 275(1-2):79–109, 2002.
Ernie Manes. Monads of sets. Handbook of algebra, 3:67–153, 2003.
Ernie Manes and Philip Mulry. Monad compositions I: general constructions and recursive distributive laws. Theory and Applications of Categories, 18(7):172–208, 2007.
Ernie Manes and Philip Mulry. Monad compositions II: Kleisli strength. Math. Struct. Comp. Sci., 18(3):613–643, 2008.
Ernie G Manes. Implementing collection classes with monads. Math. Struct. in Comp. Sci., 8(3):231– 276, 1998.
Stefan Milius, Thorsten Palm, and Daniel Schwencke. Complete iterativity for algebras with effects. In Alexander Kurz, Marina Lenisa, and Andrzej Tarlecki, editors, Algebra and Coalgebra in Computer Science, pages 34–48, Berlin, Heidelberg, 2009. Springer Berlin Heidelberg.
Eugenio Moggi. Notions of computation and monads. Inf. Comput., 93(1):55–92, 1991.
Martin Odersky, Lex Spoon, and Bill Venners. Programming in Scala. Artima Inc, 2008.
John Power and Daniele Turi. A coalgebraic foundation for linear time semantics. Electronic Notes in Theoretical Computer Science, 29:259 – 274, 1999. CTCS ’99, Conference on Category Theory and Computer Science.
Alexandra Silva, Filippo Bonchi, Marcello Bonsangue, and Jan Rutten. Generalizing determinization from automata to coalgebras. Logical Methods in Computer Science, Volume 9, Issue 1, 2013.
Stanis-law Szawiel and Marek Zawadowski. Monads of regular theories. Applied Categorical Structures, 23(3):215–262, 2015.
Johan van Benthem, Nick Bezhanishvili, and Sebastian Enqvist. A propositional dynamic logic for instantial neighborhood models. In Alexandru Baltag, Jeremy Seligman, and Tomoyuki Yamada, editors, Logic, Rationality, and Interaction, pages 137–150, Berlin, Heidelberg, 2017. Springer Berlin Heidelberg.
Daniele Varacca and Glynn Winskel. Distributing probability over non-determinism. Mathematical Structures in Computer Science, 16(1):87–113, 2006.
Philip Wadler. Comprehending monads. In LISP and Functional Programming, pages 61–78, 1990.
Philip Wadler. Monads for functional programming. In Advanced Functional Programming, First International Spring School on Advanced Functional Programming Techniques-Tutorial Text, pages 24–52, London, UK, UK, 1995. Springer-Verlag.
