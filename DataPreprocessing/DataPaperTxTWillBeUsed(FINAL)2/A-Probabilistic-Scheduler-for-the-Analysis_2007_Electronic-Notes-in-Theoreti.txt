Electronic Notes in Theoretical Computer Science 194 (2007) 61–83	
www.elsevier.com/locate/entcs

A Probabilistic Scheduler for the Analysis of Cryptographic Protocols 1
Sreˇcko Brlek∗, Sardaouna Hamadou∗∗, John Mullins∗,∗∗
∗ Lab. LaCIM, D´ep. d’Informatique, Universit´e du Qu´ebec a` Montr´eal. CP 8888 Succursale Centre-Ville, Montreal (Quebec), Canada, H3C 3P8.
∗∗ Lab. CRAC, D´ep. de G´enie Informatique, E´cole Polytechnique de Montr´eal
P.O. Box 6079, Station Centre-ville, Montreal (Quebec), Canada, H3C 3A7.

Abstract
When modelling cryto-protocols by means of process calculi which express both nondeterministic and prob- abilistic behavior, it is customary to view the scheduler as an intruder. It has been established that the traditional scheduler needs to be carefully calibrated in order to more accurately reflect the intruder’s capa- bilities for controlling communication channels. We propose such a class of schedulers through a semantic variant called PPCνσ , of the Probabilistic Poly-time Calculus (PPC) of Mitchell et al. [11] and we illustrate the pertinence of our approach by an extensive study of the Dining Cryptographers (DCP) [8] protocol. Along these lines, we define a new characterization of Mitchell et al.’s observational equivalence [11] more suited for taking into account any observable trace instead of just a single action as required in the analysis of the DCP.
Keywords: Process algebra, observational equivalence, probabilistic scheduling, analysis of cryptographic protocols

Introduction
Systems that combine both probabilities and nondeterminism are very convenient for modelling probabilistic security protocols. In order to model such systems, some efforts have been taken to extend (possibilistic) models based on process algebras such as either the π-calculus or the CSP, by including probabilities. One can dis- tinguish two classes of such models. On one hand, we have all purpose probabilistic models adding probabilities to nondeterministic models [1,6,3]. On the other hand, we have process algebraic frameworks that define probabilistic models in order to make them more suitable for applications in security protocols [11,4,10].
While it is customary to use schedulers for resolving non-determinism in proba- bilistic systems, scheduling processes must be carefully designed in order to reflect

1 Research partially supported by NSERC grants (Canada)

1571-0661 © 2007 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2007.10.009

as accurately as possible the intruder’s capabilities for controlling the communica- tion network without controlling the internal reactions of the system. Consider the protocol c(a).0|c(b).0 transmitting the messages a and b over c and the intruder c(x).0 eavesdropping on this channel. As the protocol is purely non deterministic, the probability of the intercepted message being either a or b should be the same. A scheduler that could assign an arbitrary probabilistic distribution to these two messages could also force the protocol to transmit either a or b. Such schedulers are too strong however, and should therefore not be admissible. But restricting the power of schedulers should also be carefully done, otherwise this could result in ad- versaries that are too weak. Forcing schedulers to give priority to internal actions, for example, makes internal actions completely invisible to attackers. An intruder is then unable to distinguish a process P from another process which could do some internal action, and then behaves like P . Consider now the following process:

P = νc'(c(x).c'(x).0|c'(1).0|c'(y).[y = 0]c(secret ).0).
In this obviously unsecure protocol, an intruder could send 0 to P over c and thus allow P to publish the secret. Such a flaw will never be detected in semantics giving priority to internal actions, since in that case P will never broadcast secret on public channel c.
Contribution. Our contribution is threefold. Firstly, we define a semantic variant of the Probabilistic Polynomial-time Process Calculus PPC [11] (Section 2), called PPCνσ, to cope with the problem of characterizing the intruders’s capacity. Con- trary to most probabilistic models, our operational semantics does not normalize probabilities. The reason is that normalizing has the effect of removing control of its own actions from the intruder. Consider the process P = c(m).Q1|c(m).Q2 : depending on whether P represents a protocol or an intruder, the scheduling of a component is respectively equiprobable or arbitrarily chosen by the intruder. A solution might be to discriminate semantically between a protocol and an intruder, but this rapidly becomes rather intricate since synchronization actions could be committed by both. We propose here a simpler solution to this problem. It consists of equipping the intruder with an attack strategy i.e., a selection process called external scheduler (Section 2.3), allowing it to choose the next action to perform at each evaluation step. This scheduling is carefully designed to reflect as accurately as possible the intruder’s real capacities, i.e. to control the communication network without controlling internal reactions of the system under its stimuli.
Secondly, we reformulate (Section 3) the observational equivalence of [11] into a more amenable form to take account of all observable traces instead only single step.
Finally, to illustrate the pertinence of our approach, we conclude the paper by an extensive case study (Section 4): the analysis of the Chaum’s Dining Cryptographers protocol [8]. We give a probabilistic version of the possibilistic specification of the anonymity property as per Schneider and Sidiropoulos [12], and prove that restricting the scheduler’s power too much may lead to very weak models which cannot detect flawed specifications of the protocol.

Related work. The technical precursor of our framework is the process calculus of Mitchell et al. [11]. Though any of the models [1,6,3,11,4,10] or any similar framework could have been an interesting starting point, the framework of Mitchell et al. [11] appears appropriate for the following reasons. Although it is a formal model, it is still close to computational setting of modern cryptography since it works directly on the cryptographic level. Indeed it defines an extension of the CCS process algebra with finite replication and probabilistic polynomial-time terms denoting cryptographic primitives. It turns out that these probabilistic polynomial functions are useful for modelling the probabilistic behaviour of security systems. Unlike formalisms such as [6,4,10], the scheduling is probabilistic, better reflecting so the ability of the attacker to control the communication network. Finally it also appears as a natural formal framework for capturing and reasoning about a variety of fundamental cryptographic notions.
The problem of characterizing the schedulers’ capacities has recently been con- sidered in [5,7,9]. In [5] the authors treated the problem of overly powerful schedulers in the context of systems modelled in a Probabilistic I/O Automata framework. They restricted the scheduler by defining two levels of schedulers. A high-level scheduler called adversarial scheduler is a component of the system and controls the communication network, i.e. it schedules public channels. This component has limited knowledge of the behaviour of other components in the system: their in- ternal choices and secret information are hidden. On the other hand, a low-level scheduler called tasks scheduler resolves the remaining non-determinism by a task schedule. These tasks are equivalence classes of actions that are independent of the high-level scheduler choices. We believe that these tasks may correspond to our “strategically equivalent action”.
In Garcia et. al. [9] a dual problem to the one we have considered here, namely the problem that arises when traditional schedulers are overly powerful, is addressed. In the context of security protocols modelled by probabilistic automata, they define a probabilistic scheduler that assign, in the current state, a probability distribu- tion on the possible non-deterministic next transitions. Unlike our scheduler, it is history-dependent since it defines equiprobable paths and it is not stochastic, and might therefore halt execution at any time. Roughly speaking, admissible sched- ulers are defined w.r.t bisimulation equivalence: any observably trace equivalent paths are equiprobably scheduled and lead to bisimilar states.
Another recent paper on the scheduling issue is presented in [7]. Unlike our scheduler and that of [9] which are both defined on the semantic level, [7] proposes a framework in which schedulers are defined and controlled on the syntactic level. They make random choices in the protocol invisible to the adversary. Note that we achieve the same goal by using the operational semantics Eval rule which reduces unblocked processes, as well as our strategically equivalent classes of actions. More investigation is needed for papers [5,7] to determine how the approaches may benefit from each other.
Finally an alternate approach is proposed in [4,10]. Instead of scheduling a single action (like ours), or a path (like the one of [9]), a process is scheduled. The

problems of discriminating between a protocol’s actions and intruder’s ones, and the privileging of internal actions, is meaningless in these models because scheduling is included implicitly in the specification. In other words, the protocol designer determines when control passes from the protocol to the attacker. Let us explain this last point. Consider the protocol P = ν(c)(c(1).|c(x).c' (0).) which, after an internal communication, outputs 0 on the public channel c'. In the frameworks of [4,10], it may be specified in two different manners

P1 = ν(c)(start().c(1).0|c(x).c' (0).0)


and

	
P2 = ν(c)(start().c(1).0|c(x).contr2Intr().getContr().c'(0).0)

depending on whether or not we want to make the internal action completely in- visible to the attacker. In this way the user has total freedom and can eliminate undesirable schedulers at the specification level. The drawback is that the protocol designer who has incomplete knowledge about the system, may specify his intuition of the protocol and so get some properties that might not be satisfied by the actual protocol.
The PPCνσ model
The process algebra PPCνσ extends semantically the Probabilistic Polynomial-time Process Calculus PPC [11] to better take into account the analysis of probabilistic security protocols.
Syntax of PPCνσ
Terms. The set of terms T of the process algebra PPCνσ consists of variables V, numbers N, pairs, and a specific term N standing for the security parameter. The security parameter may be understood as the cryptographic primitives’ key length and may appear in the probabilistic polynomial functions defined below. Formally we have
t ::= n (integer ) | x (variable ) | N (secur. param.) | (t, t) (pair )
For each term t, fv(t) is the set of variables in t. A message is a closed term (i.e. not containing variables). The set of messages is denoted M.
Functions. The call of probabilistic as well as deterministic cryptographic primi- tives, such as keys and nonces generation, encryption, decryption, etc., is modelled by probabilistic polynomial functions 2 Λ: Mk → M satisfying
∀(m1,... , mk) ∈ Mk, ∀m ∈ M, ∀λ ∈ Λ, ∃p ∈ [0, 1] such that Prob[λ(m1, ··· , mk)= m]= p.
We denote λ(m1, ··· , mk) ‹→  x the assignment of the value λ(m1, ··· , mk) to
p
the variable x and by λ(m1, ··· , mk)‹→ m if λ(m1, ··· , mk) evaluates to m with

2 See Appendix A for a formal definition of a probabilistic polynomial function

probability p. From Definition A.1 (see Appendix A), the set
p
Im(λ(m1, ··· , mk)) = {m | ∃p ∈]0..1] λ(m1, ··· , mk)‹→ m}
of m s.t. λ(m1, ··· , mk) evaluates to m with non-zero probability, is a finite set.
For instance, RSA encryption which takes as parameters, a message m to encrypt and an encryption key formed of the pair (e, n), and returns the number me mod n, is the function λRSA(m, e, n) returning c with probability 1 if c = me mod n, and 0 otherwise. Similarly, we can model the key guessing attack of a cryptosystem by the product [rand(1k) ‹→ key][dec(c, key) ‹→ x] where 1k is the size of the key randomly generated by the function rand, and the decryption function dec returns m with probability 1 if c is the cryptogram of m encrypted by k and key = k. The success of such an attack has probability p =  1 . These few examples illustrate the
2
expressive power offered by these functions. We limit ourselves to the probabilistic
polynomial ones in order to model all attacks realizable (in the model) in polynomial time.
Processes. Let C be a countable set of public channels. We assume that each channel is equipped with a bandwidth given by the polynomial function bw : C −→
N. We say that a message m belongs to the domain of a channel c, written m ∈
dom(c), if the message length |m| is less than or equal to the channel bandwidth,
i.e. m ∈ dom(c) ⇐⇒ |m| ≤ bw(c). Note that |(m, m')| = |m| + |m'| + r where r is the length of a fixed bits string, which allows us to concatenate and decompose two terms without any ambiguity.
Processes in PPCνσ are built as follows :
P ::= 0	|	c(x).P	|	c(m).P	|	P |P	|	(νc)P	|	[t = t]P	|
|	!q(N)P	|	[λ(t1, ··· , tn) ‹→ x]P
Given a process P , the set fv(P ) of free variables, is the set of variables x in P which are not in the scope of any prefix either input (of the form c(x)) or probabilistic evaluation (of the form [λ(t1, ··· , tn) ‹→  x]). A process without free variables is called closed and the set of closed processes is denoted by Proc. Hereafter, all processes are considered closed.
The mechanisms for reading, emitting, parallel composition, restriction and mat- ching are all standard. The finite replication !q(N)P is the q(N)−fold parallel com- position of P with itself, where q is a polynomial function. The novelty is the call and return of probabilistic polynomial functions
[λ(t1, ··· , tn) ‹→ x]P
This feature allows to model (probabilistic) polynomial cryptographic primitives as well as the probabilistic character of a protocol. In fact it is the main source of probability in this model.
The following examples illustrate the way PPCνσ can be used to model protocols.
Example 2.1 Let Kgen be a (probabilistic) polynomial function that, given the security parameter N, generates a secret encryption key and enc a (probabilistic)

encryption function that, given a secret key K and a message M , returns the cryp- togram of M under K. The process P that receives a message over the public channel c generates an encryption key and returns the cryptogram of this message over the same public channel. This is modeled in PPCνσ as follows:
P := c(x).[Kgen(N) ‹→ y][enc(x, y) ‹→ z]c(z).0
Example 2.2 Though that the calculus does not consider the probabilistic alter- native choice operator “+”, it is possible to simulate it by means of the parallel composition operator and some special probabilistic functions.
Let flips be a probabilistic polynomial function that given a coin return Head with probability p and T ail with probability 1 − p. Then the process Q that flips a coin and then behaves as the process Q' if the result of coin flipping is Head and as the process Q'' otherwise, is modeled in our calculus as follows:
Q := [flips(coin) ‹→ x]([x = Head]Q'|[x = T ail]Q'')
Operational semantics
The set of actions
Act = {c(m), c(m), c(m) · c(m), c(m) · c(m),τ | m ∈ M and c ∈ C}
consists of the set of partial input and output actions, of the set of synchronization actions on public channels, and of the internal action τ :
Partial = {c(m), c(m) | m ∈ M and c ∈ C}
Actual = {c(m) · c(m), c(m) · c(m),τ | m ∈ M and c ∈ C}
The set of observable actions is given by Vis = Act−{τ }. The operational semantics of PPCνσ is a probabilistic transition system (E , T , E0) generated by the inference rules given in Table 1 where E ⊆ Proc is the set of states, T ⊆ E × Act × [0, 1] ×E 

the set of transitions and E0
∈ Proc the initial state. The notation P α[p] P ' stands

for (P, α, p, P ') ∈ T . It is an extension of the CCS semantics, with a mechanism for calling probabilistic polynomial functions. We sketch it briefly here.
To make sure that internal computations of functions do not interfere with com- munication actions (in particular with those on public channels controlled by the intruder), all exposed functions in a process (Eval rule) are simultaneously eval- uated by the probabilistic polynomial function eval defined in Table 2 below as illustrated in Example 2.3. This evaluation step allows us to get what we call a blocked process, i.e. a process having no more internal computations to perform. The set of blocked processes is denoted by Blocked .
Example 2.3 If processes Q' and Q'' of Example 2.2 are blocked processes then Q reduces to Q' with probability p and to Q'' with probability 1 − p. In other words, Prob[eval (Q)= Q']= p and Prob[eval (Q)= Q'']= 1 − p.
The output mechanism allows a principal A to send a message on public channels (Output rule). Dually, the input mechanism must be ready to receive any message




m ∈ dom(c)

Eval.
p
eval(P )‹→P '	P /∈5locked

τ [p]
P −→P '
m ∈ dom(c)

Output

c(m).P
c(m)[1]
−→ P
Input

c(x).P
c(m)[1]
−→ P [m/x]


ParL.
α[p] P1−→P '
(P1|P2)∈5locked
α[p]

ParR.
α[p] P2−→P '
(P1|P2)∈5locked
α[p]

P1|P2−→P '|P2	P1|P2−→P1|P '


SyncL.


c(m)[p1] P1 −→ P '
c(m)[p2] P2 −→ P '

SyncR.
c(m)[p1] P1 −→ P '


c(m)[p2] P2 −→ P '

P1|P2
c(m).c(m)[p1.p2]
−→	P '|P '
P1|P2
c(m).c(m)[p1.p2]
−→	P ' |P '


RestCL. P
c(m).c(m)[p]
−→	P '
τ [p]
1  2
RestCR. P
1  2
c(m).c(m)[p]
−→	P '
τ [p]

(νc)P −→(νc)P '
α[p]
(νc)P −→(νc)P '

Rest
P −→P '	α/∈{c(m),c(m),c(m)·c(m),c(m)·c(m):m∈ł}	P ∈5locked
α[p]
(νc)P −→(νc)P '
Table 1
Operational semantics of PPCνσ



Prob[eval (0)= 0]= 1
Prob[eval (c(x).P )= c(x).P ]=1 and Prob[eval (c(m).P )= c(m).P ]= 1 Prob[eval ((νc)P )= (νc)Q]= Prob[eval (P )= Q]
Prob[eval ([m = m']P )= Q]= Prob[eval (P )= Q] if m = m'
Prob[eval ([m = m']P )= 0]= 1	else
Prob[eval (P |Q)= P '|Q']= Prob[eval (P )= P '] × Prob[eval (Q)= Q'] Prob[eval ([λ(m1, ·· · , mk) ‹→ x]P )= Q]= 
m∈Im(λ(m1 ,··· ,mk )) Prob[λ(m1, ·· · , mk)= m] × Prob[eval (P [m/x]) = Q]
Table 2
Reduction of unblocked processes

on a public channel (Input rule). The parallelism (Par. rules) operator is defined as usual. It is worth noting that the semantics keep track of information involved in an interaction (the message and the communication channel) (Syn. rules), contrary to most process algebra semantics where this information is lost, as the only action resulting from such a communication is usually the invisible action τ . The restriction operator ν is used to model private channels. The process (νc)P behaves like P restricted to actions not on c unless a synchronization occurs on c (i.e. actions of the form c(m) · c(m) or c(m) · c(m)). In this case, they are observed as an invisible action τ (Rest. rules).
Note that, transition systems generated by the operational semantics (Table 1) of PPCνσ processes, are not purely probabilistic. Consider for example process P = c1(a)|c2(b). Clearly, the sum of probabilities of outgoing transitions of P , is equal to 2. This is due to the parallel composition which introduces nondeterminism. In order to resolve this nondeterminism it is mandatory to schedule, at each evaluation step of the process, all available distinct actions. However, security protocols are assumed to be executed in hostile environments, i.e. environments with external intruders having full control of the communication network, with the ability to assign any probabilistic distribution to the controlled channels (to the public actions). This

is modelled by putting public actions under control of an external scheduler. Since we do not want to define a particular attack strategy, the scheduling is not included in the semantics of processes, but rather in the intruder’s definition: the intruder is then formed by the pair (Π, S) of process Π and scheduler S. One may view the hostile environment as Π interacting with the protocol, and S as its attack strategy.

External Scheduler
Given a protocol P attacked by the intruder (Π, S), evaluation of P |Π along the strategy S is a four step process consisting of:
Reduction: evaluation of all exposed probabilistic functions in P |Π.
Localization: indexing of executable actions along eval (P |Π) to discriminate whether or not an executable action interferes with an intruder’s action.
Selection: scheduling 3 S among available actions.
Execution: the action chosen by S is executed and the process is repeated until there are no more executable actions.
Localization. Scheduling should be capable of determining whether or not the in- truder is attached to an action. Since a system P attacked by the intruder Π is simply modelled by P |Π, actions are indexed by the positions of the components they belong to, e.g. if P and Π have respectively n and k parallel components, then P |Π consists of n + k components. By convention the attacker is on the right side, so that actions indexed by integers less than or equal to n belong to the protocol while those indexed by integers greater than n belong to the intruder. A partial action is indexed with an integer denoting the component to which it belongs, while a communication action is indexed by a pair of integers denoting the components to which complementary partial actions belong.
Let Index = N ∪ N2 and the function support : Act \ {τ } → C where support(α) is the name of the channel where α occurred.
Definition 2.4 The localization function χ : Blocked −→ 2Act×Index is defined recursively as follows:
χ(0)= ∅
χ(α.P )= {(α, 1)}
χ(P |Q)= χ(P ) ∪ {(α, ρ(P )+ i) | (α, i) ∈ χ(Q)}
∪{(α · α, i, ρ(P )+ j) | (α, i) ∈ χ(Q) and (α, j) ∈ χ(Q)}
χ((νc)P )= {(τ, i, j) | (α · α, i, j) ∈ χ(P ) and support(α)= c}
∪{(τ, k, l) | (τ, k, l) ∈ χ(P )}
where α ∈ Partial , max(i, (j, k)) = max(i, j, k). and
ρ(P )=	max{ID ∈ Index | (β, ID) ∈ χ(P ), β ∈ Vis} if χ(P ) /= ∅
0	otherwise

3 Note that scheduling is defined only for blocked processes. In fact, the only action available to an unblocked process is the internal action corresponding to functions evaluation.

Selection. The function χ allows for action localization, but more guidelines are needed to know whether or not an indexed action interferes with an intruder’s com- ponents. Actually, a partition of the set of indexed actions into classes of strategi- cally equiprobable actions, i.e. classes of actions uniformly chosen in a strategy S, is needed. Intuitively, a class corresponds to actions which can not be distinguished by any scheduler. The construction of the quotient set must agree with the following principles:
No strategy distinguishes between internal actions of a protocol.
No strategy allows the intruder to control internal reactions of a protocol P to any external stimulus. So, if P can react in many positions to a stimulus of the intruder, then all these positions should have the same probability to react to the intruder’s request.
In any strategy, the intruder has complete control on its own actions.
Given a protocol P and an attacker Π, we use χ to compute two sets I1 and I2
s.t. indices corresponding to the protocol’s components belong to I1 and those corresponding to the intruder’s ones belong to I2. Formally:
I =	{1, 2, ·· · , ρ(eval (P ))} if χ(eval (P )) /= ∅
1	∅	otherwise
I =	{ρ(eval (P )) + 1, ·· · , ρ(eval (P )) + ρ(eval (Π))} if χ(eval (Π)) /= ∅
2	∅	otherwise

Example 2.5 Let P = c(m).P1|c(m').P2 et Π = c(x).Π' then χ(eval (P |Π)) is the set
{(c(m), 1), (c(m'), 2), (c(m), 3), (c(m' ), 3), (c(m) · c(m), 1, 3), (c(m') · c(m'), 2, 3)}
and so, I1 = {1, 2} et I2 = {3}.
The quotient set of strategically equiprobable actions is summarized in Table 3 where [(α, ID)]I1 ×I2 denotes the equiprobable class of the indexed action (α, ID)
w.r.t. sets I1 and I2. Let us briefly describe these classes.
Due to principle (1), internal actions of P are equiprobable: it is reflected in the definition of [(τ, i, j)]I1 ×I2 ; τ actions indexed by the components positions of P (i.e. in I1) are equivalent. Otherwise [(τ, i, j)]I1 ×I2 is reduced to itself w.r.t (3). Due to principle (2), partial outputs on a given public channel are equiprobable: although the intruder can choose the public channel to spy on, it has no control of messages transmitted on it. Otherwise [(c(m), i)] is reduced to itself: being an intruder’s action, it can choose both the message and the component to build its attack. Partial input is the dual case of partial output, with, by contrast, the intruder controlling the message (sent by itself) that is received by P . The same principles apply to public synchronization. The intruder can choose a listening channel c and act merely as an observer, then any communication on c takes place between two components of P . It has no control on either the messages exchanged, nor on components where communication occurs. However, if communication arises


[(τ, i, j)]I1 ×I2	=

[(c(m), i)]I1 ×I2	=
{(τ, i',j') | i',j' ∈ I1}  if i, j ∈ I1
{(τ, i, j)}	otherwise
{(c(m'), i') | i' ∈ I1, m' ∈ dom(c)} if i ∈ I1
{(c(m), i)}	otherwise

[(c(m), i)]

I1 ×I2
=	{(c(m), j) | j ∈ I1} if i ∈ I1
{(c(m), i)}	otherwise

[(c(m)c(m), i, j)]I1 ×I2 =
{(αα, i',j') | i',j' ∈ I1, support(α)= c}	if i, j ∈ I1
{(c(m')c(m'), i',j) | i' ∈ I1, m' ∈ dom(c)} if i ∈ I1,j ∈ I2
{(c(m)c(m), i, j)}	otherwise
[(c(m)c(m), i,j)]I1 ×I2 =
{(αα, i',j') | i',j' ∈ I1, support(α)= c}  if i, j ∈ I1
{(c(m)c(m), i',j) | i' ∈ I1}	if i ∈ I1,j ∈ I2
{(c(m)c(m), i, j)}	otherwise
Table 3
Strategically equiprobable actions

from the protocol (output) to the intruder (input), then the intruder can select the channel and its (input) component. For synchronization arising in the opposite direction, the intruder can select not only the channel but also the message and its output component as well. Finally, if communication arises between two components of the intruder, then the intruder controls everything.
Definition 2.6 [External scheduler] An external scheduler is a stochastic polyno- mial probabilistic function S : 2Act×Index × 2N × 2N → Act × fndex s.t. for any non empty set A ⊆ Act × fndex and any pair of sets I1, I2 ⊆ N (with I1 /= ∅ or I2 /= ∅) satisfying 6(i1 ,i2)∈I1 ×I2 i1 < i2, the following holds:
Σ(τ,i,j)∈A,i,j∈I1 Prob[S(A, I1, I2)= (τ, i, j)] ∈ {0, 1}.
6α,β∈Aα ∈ [β]I1 ×I2 ⇒ Prob[S(A, I1, I2)= α]= Prob[S(A, I1, I2)= β].
The set of schedulers is denoted by Sched 4 .
From the stochasticity condition (being itself a progress condition since it states that at each step of the process at least one of the executable actions will be scheduled), we have the following result:
Lemma 2.7 Let P be a process s.t. A = χ(eval (P )) /= ∅ then the following holds:
6S∈SchedEα∈AProb[S(A)= α] /= 0.
Our main result on schedulers follows.
Theorem 2.8 The sum of probabilities of outgoing transitions in any state along any external scheduler is smaller than or equal to 1.
Proof. Let P be a process and Exec(P ) the set of outgoing transitions of P . Two cases follow:

4 Given a protocol P and an intruder (Π,S), we know how to compute I1 et I2 induced from A = χ(P |Π). Hereafter, for the sake of simplicity, we write S(A) for S(A, I1, I2).

[P /∈ Blocked ]: in this case there is no scheduling and

τ [q]	q
Exec(P )= {P −→Q | eval(P)‹→ Q}.
The sum of the probabilities of outgoing transitions of P is

p =	Σ
Q∈Im(eval(P))
Prob[eval(P) = Q]

≤ 1	by definition of eval . [P ∈ Blocked ]: in this case:


Exec(P )= {tID
α[q	]
−→ Q | (α, ID) ∈ χ(P )}.

The sum of the probabilities of outgoing transitions of P according to the scheduler
S is

p =	Σ
(α,ID)∈χ(P )
≤	Σ
(α,ID)∈χ(P )
Prob[S(χ(P )) = (α, ID)] × qID

Prob[S(χ(P )) = (α, ID)]	since 6ID ∈ fndex , qID ≤ 1

≤ 1	by definition of S.


Cumulative probability distribution
Transition systems induced by the operational semantics of Table 1 may have a state P with several outgoing transitions labeled by the same action and the same probability. But to correctly compute the probability of outgoing transitions of P according to a scheduler, we must ensure that they can be uniquely identified. If P is blocked then χ enables us to uniquely index the outgoing transitions of P . If P is unblocked then there exists a finite number n = |Im(eval (P ))| of processes Qi

(1 ≤ i ≤ n) s.t. E
qi/=0
τ [q ]
−→Qi
is an outgoing transition of P . We can order Qi
from

1 to n and use this ordering to index outgoing transitions of P s.t. P τ [qi]Q
being

indexed by (i, i) 5 .
Let σ = (α1, id1) ... (αn, idn) be a sequence of indexed actions. Then σ is a path from P to Q if there exist nonzero probabilities p1,... , pn s.t.

P α1[p1]	α2[p2]	αn[pn]
0 −→ P1 −→ ··· −→ Pn,
P = P0 and Q = Pn. Similarly, we say that P reaches Q by path σ with probability
σ[p]
p according to S, denoted by P =⇒S Q, if the probability that S chooses σ is
Prob[S(σ)] =  1≤i≤n qi = p where

5 by analogy to the indexing of τ actions by χ

q = ⎧⎨ pi	if Pi−1 /∈ Уlocked
⎩ Prob[S(χ(Pi−1)) = (αi, idi)] × pi  otherwise
Example 2.9 Let P be the process whose transition system in shown in Figure 1 where P1 /∈ Уlocked and Prob[eval (P1)= Pi]= pi for 3 ≤ i ≤ 5. Let S be scheduler such that
Prob[S({(α1, 1); (α2, 2)})= (α1, 1)] = q
Prob[S({(α1, 1); (α2, 2)})= (α2, 2)] = 1 — q 6
Prob[S({(α3, 1)})= (α3, 1)] = 1 (according to the stochasticity condition).

τ[p3]     P3

     τ[p4]
α1[p1]   P zzzz

)P4
α3[p6]	)Q

1	τ[p z] zz

P z 
zzzz’
5	z,
5

α2[p2]	P2
Fig. 1. Transition system of P

Then the probability that P reaches Q by the path σ = (α1, 1)(τ, (2, 2))(α3 , 1) according to the scheduler S is
Prob[S(σ)] = (p1 × q) × p4 × (p6 × 1).
An α-path is a path of type (τ, id1)(τ, id2) ... (τ, idn−1)(α, idn) (n ≥ 1). The
α[p]	σ[p]
notation P =⇒S Q means that there exists an α-path σ s.t. P =⇒S Q. Similarly

αˆ[p]
α[p]
τ ∗[p]

P =⇒S Q denotes P =⇒S Q if α /= τ and P =⇒S Q otherwise.
Let E ⊆ Уroc be a set of processes and Q ∈ E . Let P be a process, and σ an α-path from P to Q. Then σ is minimal w.r.t E if no other α-path σ' exists from P to Q' s.t. σ' is a prefix 7 of σ and Q' ∈ E . We denote by Paths(P, =α⇒, E ) the set of all minimal α-paths from P to an element of E .
Definition 2.10 Let E ⊆ Уroc be a set of processes. The cumulative probability that P reaches a process in E by an α-path according to S is computed by the cumulative probability function μ : Уroc × Act × 2Proc × Sched → [0, 1]


αˆ
μ(P, =

, E )= 
( 1	if P ∈ E ,α = τ

S	P{Prob[S(σ)] : σ ∈ Paths (P, =⇒, E )} otherwise
The next theorem follows by induction on the length of α-paths.
Theorem 2.11 The cumulative probability function is well deﬁned i.e.

6P,α,E ,S μ(P, =α⇒ˆ
S, E ) ≤ 1.



6 Note that if (α1, 1) and (α2, 2) are equiprobable then q =1 − q, i.e. q = 1 .
7 Prefixing does not take into account any indexing, e.g. (α1, id3) is a prefix of (α1, id1)(α2, id2) for all index id1 and id3. Note also that the minimality condition applies only to τ -paths.

Probabilistic behavioural equivalences
Now we plan to establish equivalences ensuring that a protocol satisfies a security property if and only if it is observationally equivalent to an abstraction of the protocol, satisfying the security property by construction. In other words we request two processes to be equivalent if and only if, when subject to same attacks, they generate “approximately” the same observations. By “approximately” we mean asymptotically closed w.r.t. the security parameter 8 .
Asymptotic observational equivalence
We start by defining the notion of an observable and the probability that a given process P generates a particular observable. An observable is simply a pair (c, m) of a public channel and a message. The set of all observables is denoted by Obs. The probability of observing (c, m) is defined as the sum of the probability of observing it directly, i.e. the cumulative probability of executing an c(m) · c(m)-path or an c(m) · c(m)-path to reach any state, and the probability of observing it indirectly,
i.e. by observing first some different visible actions before observing it. For that purpose we extend the notion of cumulative probability to the so-called cumulative probability up to H.
Definition 3.1 Let E ⊆ Уroc be a set of processes, P a process, S a scheduler and H ⊂ Actual \ {τ } a set of visible actions. The cumulative probability up to H is defined inductively as follows: 6α ∈ Actual \ H


μ(P, =⇒S/H , E )= 
μ(P, =⇒S, E )+
>: P	βˆ	αˆ

β∈H, Q∈Proc μ(P, =⇒S, {Q})μ(Q, =⇒S/H , E ) otherwise
Lemma 3.2 The cumulative probability up to H is well deﬁned, i.e. 6P, α, E , S 

and H, μ(P, =αˆ⇒
, E ) ≤ 1.

Proof. If P ∈ E  and α = τ , then μ(P, =αˆ⇒	, E ) = 1 and the result follows.
Assume that we are not in that case. Let σ = τ ∗α1 ··· τ ∗αn be a path of n actual visible actions separated by finite numbers of internal actions (we omit the index of the actions). We say that action αi (1 ≤ i ≤ n) is at distance i from process P on path σ according to the scheduler S, denoted dσ(P, αi, S)= i, if there exist both a
σ[p]
nonzero probability p, and a process Q such that P =⇒S Q and 6j < i αj /= αi.
In other words, dσ(P, α, S) is the first position of the visible action α on path σ. Similarly, let α /∈ H be an actual visible action and
ΣH(α)= {σ = τ ∗α1τ ∗α2 ··· τ ∗αnτ ∗α | n ∈ N and 6i ≤ n, αi ∈ H}.
Then α is at maximal distance k w.r.t H from the process P according to the scheduler S, denoted by dH(P, α, S) = k, if supσ∈ΣH (α) dσ(P, α, S) = k. To prove

8 For verification purpose, all along this section, we consider only actual actions (i.e. actions in Actual ) keeping in mind that partial actions are never executable. So far partial actions have been considered purely for the sake of semantic soundness and completeness.

the claim, we proceed by induction on dH (P, α, S). Let α ∈ Actual \ (H ∪ {τ }). We have:
[Basis] if dH (P, α, S)= 0 then


μ(P, =α⇒ˆ
, E )= μ(P, =α⇒ˆ
S, E ) ≤ 1.

[Inductive step] Assume that the claim holds for all Q s.t. dH (Q, α, S) < n.
Since

μ(P, =αˆ⇒
, E )= μ(P, =α⇒ˆ
+	Σ
S, E )

βˆ	, {Q})μ(Q, =αˆ⇒


, E )


β∈H, Q∈Proc
μ(P, =⇒S
S/H

and by induction hypothesis, μ(Q, =α⇒ˆ	, E ) ≤ 1, it remains to show that
S/H

μ(P, =α⇒ˆ
S, E )+	Σ
β∈H, Q∈Proc
βˆ
μ(P, =⇒S

, {Q}) ≤ 1,



But we have
μ(P, =αˆ⇒S

, E )+	Σ
β∈H, Q∈Proc

βˆ
μ(P, =⇒S

, {Q})

≤	Σ
β∈H∪{α}
βˆ
μ(P, =⇒S
, Уroc)

But that sum is smaller than the sum of the probabilities of outgoing transitions from the state P according to scheduler S, which is less than or equal to 1 according to the Theorem 2.8.	 
Definition 3.3 Let o = (c, m) be an observable and Lo = {c(m)·c(m), c(m)·c(m)}. The cumulative probability that P generates o according to S is


~	αˆ
S/(Actual \(Lo∪{τ }))
, Уroc).

α∈Lo
Lemma 3.4 The cumulative probability of an observable is well deﬁned, i.e. 6P, o,
and S, Prob[P ~S o] ≤ 1.
Proof. The proof is given in Appendix B.	 
We define our asymptotic observational equivalence relation as stating that two processes are equivalent if they generate the same observables with approximately the same probabilities when they are attacked by the same enemy.
Definition 3.5 Let Уoly : N → R+ be the set of positive polynomials and E = Уroc × Sched the set of attackers. Two processes P and Q are observationally equivalent, written P   Q, iff 6q∈Poly, 6o∈Obs, 6(Π,S)∈E , Ei0 s.t. 6N≥i0
1

|Prob[P |Π ~S o] — Prob[Q|Π ~S o]| ≤ 


q(N)

Theorem 3.6 The observational relation   is an equivalence relation.
Proof. Reflexivity and symmetry are obvious. For transitivity, let P , Q and R be processes such that P  Q and Q  R. Let q be a polynomial, o an observation and (Π, S) an attacker. Then P  Q ⇒ Ei0 such that 6N ≥ i0

|Prob[P |Π ~S

— Prob[Q|Π ~S
o]| ≤	1	,
2q(N)

and Q  R ⇒ Ej0 such that 6N ≥ j0
|Prob[Q|Π ~S o] — Prob[R|Π ~S o]| ≤ 

It follows that 6N ≥ k0 = max(i0, j0) we have
|Prob[P |Π ~S o] — Prob[R|Π ~S o]|
= |Prob[P |Π ~S o] — Prob[Q|Π ~S o]

1	.
2q(N)

+ Prob[Q|Π ~S o] — Prob[R|Π ~S o]|
≤ |Prob[P |Π ~S o] — Prob[Q|Π ~S o]|
+ |Prob[Q|Π ~S o] — Prob[R|Π ~S o]|

≤	1
2q(N)
1
+
2q(N)
1
=	.
q(N)


In order to develop methods for reasoning about security properties of crypto- protocols based on observable traces, we reformulate the observational equivalence to take into account any observable trace.
Trace equivalence
We start by defining the cumulative probability that a process P generates a se- quence of observables o1o2 ··· on recursively as the probability that the process di- rectly generates o1 and reaches a state Q, times the cumulative probability that the process Q generates the remaining sequence.
Definition 3.7 Let o1o2 ··· on be a sequence of observables s.t. 6i ≤ n, oi = (ci, mi) and P be a process. Let αi = ci(mi) · ci(mi) and βi = ci(mi) · ci(mi) 61 ≤ i ≤ n. The cumulative probability that P generates the sequence o1o2 ··· on according to scheduler S is
Prob[ P ~tr o1o2 ··· on]

= Σ (μ(P, =αˆ⇒1
, {Q}
βˆ1
, {Q}))Prob[Q ~tr o
··· o ].


Q∈Proc
S	)+ μ(P, =⇒S
S	2	n

Lemma 3.8 The cumulative probability of observing a sequence of observables is well deﬁned, i.e. 6P, o1, o2, ··· , on and S, Prob[P ~tr o1o2 ··· on] ≤ 1.
Proof. It follows easily by induction on the length of sequences and from Lemma 3.2 and Theorem 2.8.	 

Definition 3.9 Two processes P and Q are trace equivalent, as denoted by P  tr
Q, iff 6q∈Poly , 6o1,o2,··· ,on∈Obs , 6(Π,S)∈E , Ei0 s.t. 6N≥i0

|Prob[P |Π ~tr o1o2 ··· on
] — Prob[Q|Π ~tr o1o2 ··· on
1
]| ≤ 
q(N)

Theorem 3.10  tr is an equivalence relation.
Proof. Similar to the proof of Theorem 3.6.	 
To conclude this section we have the following important result that relates the two equivalence relations.
Theorem 3.11 Trace and observational equivalences are equivalent, i.e.
6P,Q∈Proc P  tr Q ⇔ P  Q.

Proof. The proof is given in Appendix B.	 

Case study: the Dining Cryptographers protocol
The Dining Cryptographers [8] protocol is a paradigmatic example of a protocol which ensures anonymity. Its author defines it as follows:
Three cryptographers are sitting down to dinner at their favorite restaurant. Their waiter informs them that arrangements have been made with the maitre d’hotel for the bill to be paid anonymously. One of the cryptographers might be paying for the dinner, or it might have been NSA (U.S. National Security Agency). The three cryptographers respect each other’s right to make an anonymous payment, but they wonder if NSA is paying.
To fairly resolve their uncertainty, they carry out the following protocol: each cryptographer flips a coin between himself and the cryptographer on his right, so that only the two of them can see the outcome. Each one of them then states whether or not the two coins he can see fell on the same side. The payer (if any!) states the opposite of what he sees. The idea is that if the coins are unbiased and the protocol is carried out faithfully then an odd number of “different” indicates that one of them is paying and neither of the other two learns anything about his identity; otherwise NSA is paying.

A flawed speciﬁcation of the protocol
In the following specification 9 we suppose that the NSA makes his choice according to a probabilistic distribution (known only to himself) defined by the function λNSA and informs each cryptographer over a secure channel if whether or not he is the payer. To ensure fairness between cryptographers, i.e. no one having advantage over another, each flip of a coin is made by an “outside trusted third party” by

9 where ⊕ is the addition modulus 2.

means of the function flips and the result is made available to both concerned cryptographers.


NSA ::=	[λNSA(3) ‹→ x](
0≤i≤3
[x = i]P ayeri)

P ayer3 ::= c0(nopay).c1(nopay).c2(nopay).0
P ayeri ::= ci(pay).ci⊕1(nopay).ci⊕2(nopay).0 if 0 ≤ i ≤ 2.
Crypts ::= [flips(coin0) ‹→ y0][flips(coin1) ‹→ y1][flips(coin2) ‹→ y2]
0≤i≤2


Crypti

Crypti ::= ci(zi).([zi = pay]Pi|[zi = nopay]Qi)
Pi ::=	[yi = yi⊕1]pubi(desagree).0|[yi /= yi⊕1]pubi(agree).0 Qi ::=	 [yi = yi⊕1]pubi(agree).0|[yi /= yi⊕1]pubi(desagree).0
The protocol is then specified as follows: DCP 1 ::= νc0c1c2(NSA|Crypts)
Speciﬁcation of anonymity
We give a probabilistic version of the anonymity specification of [12] in the pos- sibilistic model CSP. The idea is that given a set A and a set O, of anonymous and observable events respectively, a protocol P ensures the anonymity of events A to any observer who can see only events in O if P does not allow the observer to determine any causal dependency between the probabilistic distributions of A and O.
Let A and O be the sets of anonymous and observable events respectively. Perm(A) denotes the set of permutations of the elements of A and π(P ) the process obtained by replacing any occurrence of the event a in the process P by the event π(a). We defined formally the anonymity property as follows.
Definition 4.1 [Anonymity property] A protocol P ensures anonymity of events A if and only if it is trace equivalent to any of its permutations (w.r.t anonymous events), i.e.
6π∈Perm(A)P  tr π(P )
In the above specification the anonymous events of the DCP protocol are ADCP =
{(ci, m) | 0 ≤ i ≤ 2 and m = pay, nopay} and the observable events are any com- munication over a public channel. Let

Schedτ = {S ∈ Sched |	Σ
(τ,i,j)∈A,i,j∈I1
Prob[S(A, I1, I2)= (τ, i, j)] = 1}

denote the subset of schedulers that give priority to internal actions of the protocol and tr the observational trace equivalence induced by Schedτ . Then we have the following results which show that Sched can detect the flaw in DCP 1 while Schedτ cannot.
Theorem 4.2 With the notation above, the following conditions hold:

6π∈Perm(A


DCP
), if 6i=0,1,2 Prob[flips(coini)= Head]= 1 then
DCP 1  tr π(DCP 1.

Whatever the probabilistic distributions of the coins are, if π is not the identity permutation then
DCP 1 / tr π(DCP 1.
The flaw in DCP 1 results from the fact that the real payer (if any) has an advantage over the others since, because of the definition of the process Payeri, he always receives the message from the NSA before them. A scheduler that gives priority to observable actions (i.e. an intruder who attacks the protocol as soon as possible), will only generate observable traces beginning with the public channel of the real payer i.e. with an observable (c, m) where c denotes the public channel of the real payer. Under such schedulers, DCP 1 and π(DCP 1) will generate differ- ent observable traces and are hence not equivalent. A correct specification of the protocol (DCP 2) follows


NSA ::=	[λNSA(3) ‹→ x](
0≤i≤3
[x = i]P ayeri)

P ayer3 ::= c0(nopay).c1(nopay).c2(nopay).0
P ayeri ::= ci(pay).ci⊕1(nopay).ci⊕2(nopay).0 if 0 ≤ i ≤ 2.
Crypts ::= c0(z0).c1(z1).c2(z2).F lip
Flip ::=	[flips(coin0) ‹→ y0][flips(coin1) ‹→ y1][flips(coin2) ‹→ y2](
0≤i≤2



Crypti)

Crypti ::= [zi = pay]Pi|[zi = nopay]Qi
Pi ::=	[yi = yi⊕1]pubi(different).0|[yi /= yi⊕1]pubi(same).0 Qi ::=	[yi = yi⊕1]pubi(same).0|[yi /= yi⊕1]pubi(different).0

The protocol is then specified as follows: DCP 2 ::= νc0c1c2(NSA|Crypts). It blocks the coins flipping until all cryptographers receive their message from the NSA.

Acknowledgement
The authors are grateful to the reviewers for their careful reading and helpful com- ments that improved the paper’s readability.

References
A. Aldini, M. Bravetti, and R. Gorrieri. A process algebra approach for the analysis of probabilistic non-interference. Technical report, 2002.
M.J. Atallah. Algorithms and Theory of Computation Handbook. CRC Press LLC, 1999.
J. Bengt, K.G Larson, and W. Yi. Probabilistic extension of process algebra. In Handbook of process algebra, page 565, 2002.
Bruno Blanchet. A computationally sound mechanized prover for security protocols. In S&P, pages 140–154. IEEE Computer Society, 2006.
Ran Canetti, Ling Cheung, Dilsun Kirli Kaynar, Moses Liskov, Nancy A. Lynch, Olivier Pereira, and Roberto Segala. Time-bounded task-pioas: A framework for analyzing security protocols. In Shlomi Dolev, editor, DISC, volume 4167 of Lecture Notes in Computer Science, pages 238–253. Springer, 2006.
K. Chatzikokolakis and C. Palamidessi. A Framework for Analysing Probabilistic Protocols and its Applications to the Partial Secrets Exchange. In Proc. of the Sym. on Trust. Glob. Comp. (STGC’05), LNCS. Spr.-Ver., 2005.

K. Chatzikokolakis and C. Palamidessi. Making random choices invisible to the scheduler. In Proc. of CONCUR’07). To appear., 2007.
David Chaum. The dining cryptographers problem: Unconditional sender and recipient untraceability.
J. Cryptology, 1(1):65–75, 1988.
Flavio D. Garcia, Peter van Rossum, and Ana Sokolova. Probabilistic anonymity and admissible schedulers. http://arxiv.org/abs/0706.1019, 2007.
Peeter Laud and Varmo Vene. A type system for computationally secure information flow. In Maciej Liskiewicz and Ru¨diger Reischuk, editors, FCT, volume 3623 of Lecture Notes in Comp. Sc., pages 365–377. Springer, 2005.
J.C. Mitchell, A. Ramanathan, A. Scedrov, and V. Teague. A probabilistic polynomial-time process calculus for the analysis of cryptographic protocols. Theoretical Computer Science, 353:118–164, 2006.
S. Schneider and A. Sidiropoulos. Csp and anonymity. In Proc. Comp. Security - ESORICS 96, volume 1146 of LNCS, pages 198–218. Springer-Vale, 1996.

Probabilistic polynomial functions
The following definitions are standard: see for instance [2] (chapter 24, pp. 19-28).
Definition A.1 A probabilistic function F from X to Y is a function X × Y  →
[0, 1] that satisfies the following conditions.
6x ∈ X : Σy∈Y F (x, y) ≤ 1
6x ∈ X, the set {y|y ∈ Y, F (x, y) > 0} is finite.
For x ∈ X and y ∈ Y , we say F (x) evaluates to y with probability p, written Prob[F (x)= y]= p, if F (x, y)= p.
Definition A.2 The composition F = F1 ◦F2 : X ×Z → [0, 1] of two probabilistic functions F1 : X × Y  → [0, 1] and F2 : Y × Z → [0, 1] is the probabilistic function:
6x ∈ X, 6z ∈ Z : F (x, z)= Σ F1(x, y) · F2(y, z).
y∈Y
Definition A.3 An oracle Turing machine is a Turing machine with an extra oracle tape and three extra states qquery, qyes and qno. When the machine reaches the state qquery, control is passed either to the state qyes if the contents of the oracle tape belongs to the oracle set, or to the state qno otherwise.
Given an oracle Turing machine M , Mσ(—→a ) stands for the result of the appli- cation of M to —→a by using the oracle σ.
Definition A.4 An oracle Turing machine executes in polynomial time if there exists a polynomial q(—→x ) such that for all σ, Mσ(—→a ) halts in time q(|—→a |), where
—→a = (a1, ··· , ak) and |—→a | = |a1| + ··· + |ak|.
Let M be an oracle Turing machine with execution time bounded by the poly- nomial q(—→a ). Since M (—→a ) may call an oracle with at most q(—→a ) bits, we have a finite set Q of oracles for which M executes in time that is bounded by q(—→a ).
Definition A.5 We say that an oracle Turing machine is probabilistic polynomial and write Prob[M (—→a )= b]= p the probability that M applied to —→a returns b is p, if and only if, by choosing uniformly an oracle σ in the finite set Q, the probability that Mσ(—→a )= b is p.
Definition A.6 A probabilistic function F is said to be polynomial if it is com- putable by a probabilistic polynomial Turing machine, that is, for all input —→a and all output b, Prob[F (—→a )= b]= Prob[M (—→a )= b].
Proofs
Proof. [Lemma 3.4] Let o = (c, m) be an observable, Lo = {c(m)·c(m), c(m)·c(m)}, S a scheduler and P a process. Let H be the set H = Actual \ (Lo ∪ {τ }). To prove the lemma, we proceed by induction on dH (P, α, S) defined in the above proof of Lemma 3.2.

[Basis:] If 6α∈LodH (P, α, S)= 0 then Prob[P ~S o]= Σ μ(P, =αˆ⇒
α∈Lo

, Уroc )= Σ μ(P, =αˆ⇒S, Уroc)
α∈Lo

≤ Σ
β∈Act
βˆ
μ(P, =⇒S
, Уroc)

≤ 1	(according to Theorem 2.8.)
[Induction step:] Suppose that for any process Q such that 6α∈LodH (Q, α, S) < n,
Prob[Q ~S o] ≤ 1. Then we have
Prob[P ~S o]= Σ μ(P, =αˆ⇒	, Уroc )
α∈Lo
= Σ μ(P, =αˆ⇒S, Уroc)+ 
α∈Lo
Σ	Σ	βˆ	αˆ
μ(P, =⇒S, {Q})μ(Q, =⇒S/H , E )
α∈Lo β∈H, Q∈Proc
= Σ μ(P, =αˆ⇒S, Уroc)+ 
α∈Lo

(	Σ
β∈H, Q∈Proc
βˆ
μ(P, =⇒S
, {Q}))Prob[Q ~S o]

≤ Σ μ(P, =αˆ⇒S, Уroc)+ 
α∈Lo

Σ
β∈H, Q∈Proc
βˆ
μ(P, =⇒S, {Q}) (induction hypotheses)

≤ Σ
β∈Act
βˆ
μ(P, =⇒S
, Уroc)

≤ 1	(according to Theorem 2.8.)

Proof. [Theorem 3.11] (⇒). Let H ⊂ Actual \ {τ } be a set of visible actions, o = (c, m) an observable s.t. {c(m) · c(m), c(m) · c(m)}∩ H = ∅ , S a scheduler and R a process. Then dH(R, o, S) denotes
dH (R, o, S)= max(dH (R, c(m) · c(m), S), dH (R, c(m) · c(m), S)).
Now let O be a set of observables s.t. o /∈ O, and TrO(R, o, S) the set
TrO(P, o, S)= {s = o1o2 ··· oko|6i ≤ k, oi ∈ O and Prob[R ~tr s] /= 0}.

k
Then for any observable o, we have
Prob[R ~S o]= Σ	Σ
S



Prob[R ~tr s].

k≥0 s∈TrObs\{o}(R,o,S)

Let P and Q be two processes s.t. P  tr Q, o = (c, m) ∈ Obs, (Π, S) ∈ E, q ∈ Poly and

H = {α | E(c', m') ∈ Obs \ {o} and α ∈ {c'(m') · c'(m'), c'(m') · c'(m')}}.
To prove the theorem, we proceed by induction on
max(dH(P |Π, o, S), dH (Q|Π, o, S)).
[Basis:] If dH (P |Π, o, S)= dH (Q|Π, o, S)= 0, then we have:


Prob[P |Π ~
o] = μ(P |Π, =αˆ⇒
, Уroc)+ μ(P |
βˆ
, Уroc)

S	S	Π, =⇒S
where α = c(m) · c(m) and β = c(m) · c(m). Similarly


Prob[Q|Π ~
o] = μ(Q|Π, =αˆ⇒
, Уroc)+ μ(Q|
βˆ
, Уroc ).

S	S	Π, =⇒S


P  tr Q ⇒
|μ(P |Π, =α⇒ˆ

, Уroc)+ μ(P |


βˆ
, Уroc)

S	Π, =⇒S
— μ(Q|Π, =αˆ⇒ , Уroc)+ μ(Q|	βˆ	, Уroc)| ≤	1


Hence
S	Π, =⇒S

1


q(N)

|Prob[P |Π ~S o] — Prob[Q|Π ~S o]| ≤ 


q(N)

[Induction step:] assume that max(dH (P |Π, o, S), dH (Q|Π, o, S) = n, and 6q∈P oly
we have
Σ	Σ	|Prob[P |Π ~tr s] — Prob[Q|Π ~tr s]| ≤   1	 .

S
k<n s∈TrObs\{o}(R,o,S)
S	2q(N)

Now set Uk = TrH(P |Π, o, S) ∪ TrH(Q|Π, o, S), then we have
k	k
|Prob[P |Π ~S o] — Prob[Q|Π ~S o]|
= | Σ Σ (Prob[P |Π ~tr s] — Prob[Q|Π ~tr s])|
S	S
k≤n s∈Uk
≤| Σ Σ Prob[P |Π ~tr s] — Prob[Q|Π ~tr s]|
S	S
k<n s∈Uk
+ Σ |Prob[P |Π ~tr s] — Prob[Q|Π ~tr s]|
S	S
s∈Un
By induction hypothesis we have
| Σ Σ Prob[P |Π ~tr s] — Prob[Q|Π ~tr s]| ≤   1	 .

S
k<n s∈Uk
S	2q(N)

Set rn = |TrH(P |Π, o, S)| + |TrH(Q|Π, o, S)|. P  tr Q ⇒ 6s ∈ Un
n	n
|Prob[P |Π ~tr s] — Prob[Q|Π ~tr s]| ≤	1	,
S	S	rn · 2q(N)


then

Σ |Prob[P |Π ~tr s] — Prob[Q|Π ~tr s]| ≤ 	rn	 =   1	 .

S
s∈Un
S	rn · 2q(N)
2q(N)



Hence we have
|Prob[P |Π ~S

o] — Prob[P |Π ~S

o]|≤		1 2q(N)
1
+ 2q(N)

≤	1 . q(N)

(⇐). Suppose now that P  Q but P / tr Q. Then we will show that we reach a contradiction. Indeed, if P / tr Q, then there exists an attacker (Π, S), an observable trace o1o2 ··· on and a polynomial q s.t.

6N |Prob[P |Π ~tr o1o2 ··· on
] — Prob[Q|Π ~tr o1o2 ··· on
1
]| >	.
q(N)

Let o' = (c', m) s.t. c' is neither a channel of P or Q nor a channel of Π and let (Π', S') be the attacker who behaves exactly like (Π, S) exept that anytime he observes the trace o1o2 ··· on he makes the observable o' with probability 1. Then we have

|Prob[ P |Π' ~'
o'] — Prob[Q|Π' ~'
o']|

= |Prob[P |Π ~tr o1o2 ··· ono'] — Prob[Q|Π ~tr o1o2 ··· ono']|
S	S
Hence P / Q which contradicts our hypothesis.	 
