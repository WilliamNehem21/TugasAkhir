Electronic Notes in Theoretical Computer Science 188 (2007) 37–51	
www.elsevier.com/locate/entcs

A Proposal for the Cooperation of Solvers in Constraint Functional Logic Programming
S. Est´evez-Mart´ına,1	A. J. Fern´andezb,2
T. Hortala´-Gonza´leza,1	M. Rodr´ıguez-Artalejoa,1
F. S´aenz-P´ereza,1	R. del Vado-V´ırsedaa,1
a Departamento de Sistemas Informa´ticos y Programaci´on Universidad Complutense de Madrid
Madrid, Spain
b Departamento de Lenguajes y Ciencias de la Computacio´n Universidad de M´alaga
M´alaga, Spain

Abstract
This paper presents a proposal for the cooperation of solvers in constraint functional logic programming, a quite expressive programming paradigm which combines functional, logic and constraint programming using constraint lazy narrowing as goal solving mechanism. Cooperation of solvers for different constraint domains can improve the efficiency of implementations since solvers can take advantage of other solvers’ deductions. We restrict our attention to the cooperation of three solvers, dealing with syntactic equality and disequality constraints, real arithmetic constraints, and finite domain (FD) constraints, respectively. As cooperation mechanism, we consider to propagate to the real solver the constraints which have been submitted to the FD solver (and viceversa), imposing special communication constraints to ensure that both solvers will allow the same integer values for all the variables involved in the cooperation.
Keywords: Cooperating Solvers, Constraints, Functional Logic Programming, Lazy Narrowing, Implementation.


Introduction
Cooperation of different solvers for Constraint Programming (shortly CP ) has been widely investigated during the last years [4], aiming at the solution of hybrid prob- lems that cannot be handled by a single solver and also at improvements of efficiency, among other things. On the other hand, the Functional and Logic Programming styles (FP and LP , resp.) support a clean declarative semantics as well as powerful

1 Author partially supported by projects TIN2005-09207-C03-03 and S-0505/TIC0407
2 Author partially supported by projects TIN2004-7943-C04-01 and TIN2005-08818-C04-01

1571-0661 © 2007 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2007.05.037

program construction facilities. The CLP scheme for Constraint Logic Program- ming, started by a seminal paper by Jaffar and Lassez, provides a combination of CP and LP which has proved very practical for CP applications [7]. Adding a FP dimension to CLP has led to various proposals of CFLP schemes for Con- straint Functional Logic Programming, developed since 1991 and aiming at a very expressive combination of CP , higher-order lazy FP and LP .
Both CLP and CFLP are schemes that can be instantiated by means of dif- ferent constraint domains and solvers. This paper presents a proposal for solver cooperation in CFLP , more precisely in an instance of the CFLP scheme as pre-
sented in [9,2,8] which is implemented in the T OY language and system [1]. The solvers whose cooperation is supported are: a solver for the Herbrand domain H supporting syntactic equality and disequality constraints; a solver for the domain FD, which supports finite domain constraints over the set of integer numbers Z; and a solver for the domain R, which supports arithmetic constraints over the set
of real numbers R. This particular combination has been chosen because of the
usefulness of H constraints for dealing with structured data and the important role of hybrid FD and R constraints in many practical CP applications [4].
T OY has been implemented on top of SICStus Prolog [15], using the FD and R solvers provided by SICStus along with Prolog code for the H solver. CFLP goal solving takes care of evaluating calls to program defined functions by means of lazy narrowing, and decomposing hybrid constraints by introducing new local variables. Eventually, pure FD and R constraints arise, which must be submit- ted to the respective solvers. Our proposal for solver cooperation is based on the communication between the FD and R solvers by means of special communication constraints called bridges. A bridge u #== v constrains u::int and v::real to take the same integer value. Our system keeps bridges in a special store and uses them for two purposes, namely binding and propagation. Binding simply instan- tiates a variable occurring at one end of a bridge whenever the other end of the bridge becomes a numeric value. Propagation is a more complex operation which takes place whenever a pure constraint is submitted to the FD or R solver. At that moment, propagation rules relying on the available bridges are used for building a mate constraint which is submitted to the mate solver (think of R as the mate of FD and viceversa). Propagation enables each of the two solvers to take advantage of the computations performed by the other. In order to maximize the opportunities for propagation, the CFLP goal solving procedure has been enhanced with oper- ations to create bridges whenever possible, according to certain rules. Obviously, independent computing of solvers remains possible.
The rest of the paper is organized as follows. Section 2 recalls the essentials of CFLP programming and presents a CFLP program which solves a generic problem illustrating H + FD + R cooperation. Section 3 presents a formal description of co- operative goal solving by means of constraint lazy narrowing enhanced with rules for
creation of bridges and propagation of mate constraints. Section 4 presents some de- tails of our current implementation of cooperative goal solving in the T OY system, as well as performance results based on the program from Section 2, showing that

propagation of mate constraints via bridges leads to significant speedups of execu- tion time. Section 5 includes a summary of conclusions, a brief discussion of related work and some hints to planned future work.

CFLP Programming
In this section, we recall the essentials of the CFLP scheme [9,2,8] for lazy Con- straint Functional Logic Programming, which serves as a logical and semantic frame- work for our proposal of cooperation of solvers.


The Constraint Domains H, FD and R
We assume a universal signature Σ = ⟨DC, FS⟩, where DC = 
 



n∈N

DCn and

FS =
n∈N FSn are countably infinite and mutually disjoint sets of constructor

symbols and function symbols, indexed by arities. Functions are further classified
into domain dependent primitive functions PFn ⊆ FSn and user deﬁned functions DFn = FSn \ PFn for each n ∈ N. We consider a special symbol ⊥, intended to denote an undeﬁned value and we assume the Boolean constants true, false ∈ DC0. We also consider a countably infinite set V ar of variables and a set U of primitive elements (as e.g. the set Z of integer numbers or the set R of real numbers).
An expression e ∈ Exp has the syntax e ::= u | X | h | (e e1 ... em), where u ∈ U, X ∈ V ar and h ∈ DC ∪ FS, (em abbreviates e1 ... em). The following classification of expressions is useful: (X em), with X ∈ V ar and m ≥ 0, is called a flexible expression, while u ∈ U and (h em) with h ∈ DC ∪ FS are called rigid expressions. Moreover, a rigid expression (h em) is called active iff h ∈ FSn and m
≥ n, and passive otherwise. Another important subclass of expressions is the set of patterns t ∈ Pat, whose syntax is defined as t ::= u | X | (c tm) | (f tm), where u ∈ U, X ∈ V ar, c ∈ DCn with m ≤ n, and f ∈ FSn with m < n. We also consider substitutions as mappings σ, θ from variables to patterns, and by convention, we write e σ instead of σ(e) for any e ∈ Exp, and σθ for the composition of σ and θ. A constraint domain provides a set of specific primitive elements U, along with certain primitive functions p ∈ PFn operating upon them. Atomic constraints over
a given constraint domain D can have the form ♦ (denoting a constraint trivially true), ◆ (denoting a constraint trivially false) or p en →! t with en ∈ Exp and t ∈ Pat. Atomic primitive constraints have the form ♦, ◆ or p tn →! t with tn,t ∈ Pat. This paper deals with three constraint domains:
H, the so-called Herbrand domain, which supports syntactic equality and dise- quality constraints over an empty set of primitive elements.
FD, which supports ﬁnite domain constraints over Z.
R, which supports arithmetic constraints over R.
Table 1 summarizes the primitive functions available for these domains, and the way they are used for building atomic primitive constraints in practice. We also assume constraint solvers SolverH, SolverFD and SolverR associated to these

domains. In addition to the constraints just described, we also use a special kind of communication constraints built from a new primitive function equiv :: int → real → bool such that (equiv n x) returns true if x has an integer value equiva- lent to n, and false otherwise. Constraints of the form equiv e1 e2 →! true will be called bridges and abbreviated as e1 # == e2 in the sequel. We introduce a constraint domain M which operates with bridges. The cooperation of a FD solver and a R solver via communication bridges can lead to great reductions of the FD search space, manifesting as significant speedups of the execution time, as we will see in Section 4.

Table 1
The Constraint Domains H, FD, R and M


Structure of Program Rules

Programs are sets of constrained program rules of the form f tn = r ⇐ C, where f ∈ DFn, tn is a linear sequence of patterns, r is an expression and C is a fi- nite conjunction δ1,... , δm of atomic constraints δi for each 1 ≤ i ≤ m, possibly including occurrences of defined function symbols. Predicates can be modelled as defined functions returning Boolean values, and clauses p tn : − C abbreviate rules p tn = true ⇐ C. In practice, T OY and similar constraint functional logic lan- guages requires program rules to be well-typed in a polymorphic type system.

As a running example for the rest of the paper, we consider a generic program written in T OY which solves the problem of searching for a 2D point lying in the intersection of a discrete grid and a continuous region. Both grids and regions are represented as Boolean functions. They can be passed as parameters because our
programming framework supports higher-order programming features.
% Discrete versus continuous points:
type dPoint = (int, int)	type cPoint = (real, real)
% Sets and membership:
type setOf A = A -> bool isIn :: setOf A -> A -> bool
isIn Set Element = Set Element
% Grids and regions as sets of points:
type grid = setOf dPoints	type region = setOf cPoints
% Predicate for computing intersections of regions and grids: bothIn:: region -> grid -> dPoint -> bool
bothIn Region Grid (X, Y) :- X #== RX, Y #== RY,
isIn Region (RX, RY), isIn Grid (X,Y), labeling [ ] [X,Y]
We will try the bothIn predicate for various square grids and triangular regions of parametrically given sizes, defined as follows:

% Square grid:
square:: int -> grid
square N (X, Y) :- domain [X, Y] 0 N
% Triangular region:
triangle :: cPoint -> real -> region triangle (RX0, RY0) H (RX, RY) :-

r3	r2


RY >= RY0 - H, RY - RX <= RY0 - RX0, RY + RX <= RY0 + RX0
We build an isosceles triangles from a given upper vertex (RX0, RY0) and a given height H. The three vertices are (RX0, RY0), (RX0 −H, RY0 −H), (RX0 +H, RY0 − H), and the region inside the triangle is enclosed by the lines r1 : RY = RY0 − H, r2 : RY − RX = RY0 − RX0 and r3 : RY + RX = RY0 + RX0 and characterized by the conjuntion of the three linear inequalities: C1 : RY ≥ RY0−H, C2 : RY −RX ≤
RY0 − RX0 and C3 : RY + RX ≤ RY0 + RX0. This explains the real arithmetic constraints in the triangle predicate.
As an example of goal solving for this program, we fix two integer values d and
n such that (d, d) is the middle point of the grid (square n), where (n + 1)2 is

the total number of discrete points within the square grid. For instance, we could choose n =4 and d = 2. We consider three goals computing the intersection of this fixed square grid with three different triangular regions:
Goal 1: bothIn (triangle (d + 1/2, d+1) 1/2) (square n) (X,Y). This goal fails.
Goal 2: bothIn (triangle (d, d+1/2) 1) (square n) (X,Y).
This goal computes one solution for (X,Y), corresponding to the point (d, d).
Goal 3: bothIn (triangle (d, d+1/2) 2) (square n) (X,Y).
This goal computes four solutions for (X,Y), corresponding to the points (d, d), (d − 1,d − 1), (d, d − 1) and (d + 1,d − 1).


(0, n)
(n, n)
(0, n)
(n, n)
(0, n)
(n, n)



ˆv1/2
ˆ	ˆ
1
v	2
v

(0, 0)
(n, 0)
(0, 0)
(n, 0)
(0, 0)
(n, 0)

Goal 1	Goal 2	Goal 3

Cooperative Goal Solving
Extending the operational semantics given in [9,2] for lazy constraint functional logic programming, we design in this section a goal solving calculus based on constraint lazy narrowing and solver cooperation mechanisms.

Structure of the Goals

We consider goals of the general form G ≡ ∃U. P  C  M  H  F  R in order to represent a generic state of the computation with cooperation of solvers over H, FD and R. The symbol  is interpreted as conjunction.
U is a finite set of local variables in the computation.
P is a conjunction of so-called productions of the form e1 → t1, ... , en → tn, where ei ∈ Exp and ti ∈ Pat for all 1 ≤ i ≤ n. The set of produced variables of G is defined as the set pvar(P ) of variables occurring in t1 ... tn.
C is a finite conjunction of constraints to be solved possibly including occurrences of defined functions symbols.
M is the so-called communication store between FD and R, with primitive bridge constraints involving only variables and integer or real values.
H is the so-called Herbrand store, with strict equality/disequality primitive con- straints and an answer substitution with variable bindings.

F is the so-called ﬁnite domain store, with finite domain primitive constraints and an answer substitution with integer variable bindings.
R is the so-called real arithmetic store, with primitive real arithmetic constraints and an answer substitution with real variable bindings.
We work with admissible goals G satisfying the goal invariants given in [9] and such that no variable has more than one bridge in M . We also write □ to denote an inconsistent goal. Moreover, we say that a variable X is a demanded variable in a goal G iff X occurs in any of the constraint stores of G (i.e., M , H, F or R), and μ(X) /= ⊥ holds for every solution μ of the corresponding constraint store. For example, X is a demanded variable for the finite domain constraint X#>=3 but not
a demanded variable for the strict disequality constraint s(X)/=0, where s and 0 are constructor symbols. In the sequel, we use the following notations in order to indicate the transformation of a goal by applying a substitution σ and also adding σ to the corresponding store:
(P  C  M  H  F  R) @H σ =def (Pσ  Cσ  Mσ  H † σ  Fσ  Rσ)
(P  C  M  H  F  R) @F σ =def (Pσ  Cσ  Mσ  Hσ  F † σ  Rσ)
(P  C  M  H  F  R) @Rσ =def (Pσ  Cσ  Mσ  Hσ  Fσ  R † σ)
where (Π  θ) T σ =def Πσ  θσ and (Π  θ) stands for H, F or R.
Cooperative Goal Solving by means of Constrained Lazy Narrowing
The Constrained Lazy Narrowing Calculus CLNC(D) is presented in [9] as a suitable computation mechanism for solving goals for CFLP (D) over a single constraint domain D (e.g. H, FD or R) and a single constraint solver over the domain D. Now, in order to provide a formal foundation to our proposal for the cooperation of solvers
over the constraint domains H, FD and R, preserving the good properties obtained in the CFLP (D) framework, we have to reformulate the goal transformation rules of the calculus CLNC(D) to deal with the class of goals defined above. We have to distinguish two kinds of rules: rules for constrained lazy narrowing with sharing by means of productions (these rules are easily adapted from [9]; see Table 2), and new rules for cooperative constraint solving over the constraint stores.

Rules for Cooperative Goal Solving
The following three rules describe the process of lazy flattening of non-primitive arguments from constraints in C by means of new productions, the creation of new bridge constraints stored in M with the aim of enabling propagations, and the ac- tual propagation of mate constraints (recall introduction) via bridges, taking place simultaneously with the submission of primitive constraints to the FD and R stores.
FC Flatten Constraint

∃U. P  p en →! t, C  M  H  F  R ▶▶FC
∃Vm, U. am → Vm, P  p tn →! t, C  M  H  F   R
If some ei ∈/ Pat, am are those ei which are not patterns, Vm are new variables,



Table 2
Rules for Constrained Lazy Narrowing


p tn is obtained from p en by replacing each ei which is not a pattern by Vi.

SB Set Bridges

EU. P  p tn →! t, C  M  H  F  R ▶▶SB
EV, U. P  p tn →! t, C  M ', M  H  F  R
If π = p tn →! t is a primitive constraint, and
π is a JÐ constraint, and M ' = bridgesFD→R(π, M ) /= ∅ or else
π is a Y constraint, and M ' = bridgesR→FD(π, M ) /= ∅.
In both cases, V =var(M ')\var(M ) are new variables occurring in the new bridge constraints created by the bridges operations described in Tables 3, 4.

SC Submit Constraints
EU. P  p tn →! t, C  M  H F  R ▶▶SC EU. P  C  M '  H'  F '  R'
If SB cannot be used to set new bridges, and one of the following cases applies:
If p tn  →! t is a bridge u # == u' then M ' = (u # == u', M ), H' = H,
F ' = F and R' = R.

If p tn →! t is a primitive Herbrand constraint seq t1 t2 →! t then M ' = M ,
H' = (seq t1 t2 →! t, H), F ' = F and R' = R.

If p tn →! t is a primitive JÐ constraint π then M ' = M , H' = H, F ' = (π, F ) and R' = (R'', R), where R'' = propagationsFD→R(π, M ).

If p tn →! t is a primitive Y constraint π then M ' = M , H' = H, F ' = (F '', F ) and R' = (π, R), where F '' = propagationsR→FD(π, M ).
where the propagations operations given in Tables 3 and 4 take care of the con- struction of mate constraints via bridges in M for propagation between the JÐ and Y stores.




|














Table 3
Bridge Constraints and Propagations from FD to R



Rules for Constraint Solving
The last four rules describe the process of constraint solving by means of the ap- plication of a constraint solver over the corresponding stores (M, H, F or R). We note that, in order to respect the admissibility conditions of goals and perform an adequate lazy evaluation, we must protect all the produced variables χ = pvar(P ) occurring in the stores from eventual binding caused by the solvers (see [9] for more details). We use the following notations:

H ▶▶SolverH,χ EY .H' indicates one of the alternatives computed by the solver.
H ▶▶SolverH,χ◆ indicates failure of the solver (i.e., H is unsatisﬁable).
Similar notations are used to indicate the behavior of the JÐ and Y solvers. The simple behavior of the M solver is shown explicitly.
MS M -Solver

EU. P  C  X# == u', M  H F  R ▶▶MS1 EU '. (P  C M  H F  R)@F σ


Table 4
Bridge Constraints and Propagations from R to FD 


If X ∈/ pvar(P ), u' ∈ R, σ = {X '→ u} with u ∈ Z such that equiv u u', U ' = U
if X ∈/ U and U ' = U \ {X} otherwise.
EU. P  C  u# == RX, M H F  R ▶▶MS2 EU '. (P  C M H F  R)@Rσ
If RX ∈/ pvar(P ), u ∈ Z, σ = {RX '→ u'} with u' ∈ R such that equiv u u', U ' = U if RX ∈/ U and U ' = U \ {RX} otherwise.

EU. P  C  u# == u', M H F  R ▶▶MS3 EU. P  C M H F  R
If u ∈ Z, u' ∈ R and equiv u u' = true.
EU. P  C  u# == u', M  H F  R ▶▶MS4 □
If u ∈ Z, u' ∈ R and equiv u u' = false.

HS H-Solver

EU. P C M H F R ▶▶HS EY, U. (P C M H' F R)σ'
If χ = pvar(P ) ∩ var(H) and H ▶▶SolverH, χ EY. H' with H' = Π'  σ'.

FS F -Solver EU. P  C M  H F  R ▶▶FS EY, U. (P  C M  H F ' R)σ'
If χ = pvar(P ) ∩ var(F ) and F ▶▶SolverFD, χ EY. F ' with F ' = Π'  σ'.


	 
RS R-Solver EU. P C M H F R ▶▶RS EY, U. (P C M H F R')σ' If χ = pvar(P ) ∩ var(R) and R ▶▶SolverR, χ EY. R' with R' = Π'  σ'.
SF Solving Failure

EU. P  C  M  H  F  R ▶▶SF □
If χ = pvar(P ) ∩ var(K) and K ▶▶SolverD, χ ◆, where Ð is the domain H, JÐ or
Y and K is the corresponding constraint store (i.e., H, F or R).
The following example illustrates the process of flattening and propagation, start- ing with the real arithmetic constraint (RX +2 ∗ RY ) ∗ RZ <= 3.5 and bridges for RX, RY and RZ. At each goal transformation step, we underline the selected subgoal and the applied rule. We use Tables 3 and 4 in order to build new bridges
and propagations in the transformation process. In these tables, no bridges are created for #/, because integer division cannot be propagated to real division. The notations [a| (resp. [a♩), stand for the least integer upper bound (resp. the greatest integer lower bound) of a ∈ R. Constraints t1 > t2 resp. t1 >= t2 not occurring in Table 4 are treated as t2 < t1 resp. t2 <= t1.
  (RX +2 ∗ RY ) ∗ RZ <= 3.5  X# == RX, Y # == RY, Z# == RZ     ▶▶FC
∃RA. (RX +2 ∗ RY ) ∗ RZ → RA  RA <= 3.5  X# == RX, Y # == RY, Z# == RZ     ▶▶PC

∃RA.  (RX +2 ∗ RY ) ∗ RZ →! RA, RA <= 3.5  X# == RX, Y # == RY, Z# == RZ     ▶▶FC
∃RB,RA.RX +2 ∗ RY → RB RB ∗ RZ →!RA, RA<=3.5 X#==RX, Y #==RY, Z#==RZ   ▶▶PC
∃RB, RA.  RX +2 ∗ RY  →! RB, RB ∗ RZ →! RA, RA <= 3.5  X# == RX, Y # == RY, Z# == RZ
    ▶▶FC
∃RC, RB, RA. 2 ∗ RY  → RC   RX + RC →! RB, RB ∗ RZ →! RA, RA <= 3.5   X# == RX, Y # == RY, Z# == RZ   ▶▶PC
∃RC, RB, RA.   2 ∗ RY  →! RC, RX + RC →! RB, RB ∗ RZ →! RA, RA <= 3.5   X# == RX, Y # == RY, Z# == RZ   ▶▶3
∃C, B, A, RC, RB, RA.  2 ∗ RY  →! RC, RX + RC →! RB, RB ∗ RZ →! RA, RA <= 3.5  C # ==
RC, B# == RB, A# == RA, X# == RX, Y # == RY, Z# == RZ     ▶▶4
∃C, B, A, RC, RB, RA.   C# == RC, B# == RB, A# == RA, X# == RX, Y # == RY, Z# == RZ
   2 #∗ Y →! C, X #+ C →! B, B #∗ Z →! A, A # <= 3  2 ∗ RY →! RC, RX + RC →! RB, RB
∗ RZ →! RA, RA <= 3.5


Implementation and Performance Results
In this section, we present some hints about the implementation of the formal setting presented above, and we test its performance showing the improvements caused by propagation w.r.t. a restricted use of bridges for binding alone.
Implementation
Our implementation has been developed by adding a store M for bridges, as well as code for implementing bindings and propagations, on top of the existing T OY system [1]. T OY has three solvers already for the constraint domains H,

JÐ and Y, each of them with its corresponding stores. Each predefined function is implemented as a SICStus Prolog predicate that has arguments for: function arguments (as many as its arity), function result, and Herbrand constraint store.
The next example is a simplified code excerpt that shows how the binding mechanism for bridges is implemented. Actually, this is the only code needed for obtaining the performance results shown in Subsection 4.2 for computations without propagation.
#==(L, R, true, Cin, [’#==’(HL,HR)|Cout]) :-
hnf(L, HL, Cin, Cout1), hnf(R, HR, Cout1, Cout),
freeze(HL, HR is float(HL)), freeze(HR, HL is integer(HR)).
This predefined constraint demands its two arguments (L and R) to be in head normal form (hnf). Therefore, the code line (2) implements the application of the rules FC and PC (with true as t and equiv as p). Next, line (3) implements the application of the transformation rule MS. The predicate freeze suspends the evaluation of its second argument until the first one becomes ground. What we need to reflect in this constraint is to equal two arguments (variables or constants) of different type, i.e., real and integer, so that type casting is needed (float and integer operations). Binding and matching inherent in MS are accomplished by unification. Finally, the transformation rule SC (case i) is implemented by adding the flattened bridge to the communication store. The last two arguments of predicate #== stand for the input and output stores. For the sake of rapid prototyping, the current implementation mixes Herbrand and communication constraints in one single store, although they should be separated for better performance. In addition, we always add constraints to the communication store (irrespective of groundness) and never drop them; again to be enhanced in a final release.
Implementing propagation requires a modification of existing code for prede- fined constraints. For example, the code excerpt below shows the implementation of the relational constraint #>.
#>(L, R, Out, Cin, Cout) :-
hnf(L, HL, Cin, Cout1), hnf(R, HR, Cout1, Cout),
searchVarsR(HL,Cout2,Cout3,HLR), searchVarsR(HR,Cout3,Cout,HRR),
((Out=true, HL#>HR, {HLR>HRR});(Out=false, HL#<=HR, {HLR<=HRR})).
Here, line (2) implements the FC and PC goal transformation rules; line(3) implements the rule SB by adding new needed bridges to the mixed H + M store; and line (4) implements propagation (case (iii) of rule SC), sending both the JÐ constraint and its mate in Y to the corresponding solvers. Note that, because we allow reification in particular for relational constraints, the complementary cases (true and false results) correspond to complementary constraints.

Performance Results
Table 5 compares the timing results for executing the goals in Section 2 for the running example (see Subsection 2.2). The first column indicates the goal, the second and third ones indicate the parameters d and n determining the middle point and the size of the square grid, respectively. The next columns show running times (in milliseconds) in the form (tB/tBP ), where tB stands for the system using bridges for binding alone and tBP for the system using bridges also for propagation. Values ’0’ in these columns stand for very small execution times that are displayed as ’0’ by the system, last columns are headed with a number i which refers to the i-th solution found, and the last column with numbers stands for the time needed to determine that there are no more solutions. In this simple example we see that the finite domain search space has been hugely cut by the propagations from Y to
JÐ. Finite domain solvers are not powerful enough to cut the search space in such
an efficient way as simplex methods do for linear real constraints.

Table 5 Performance Results




Conclusions
We have presented a proposal for the cooperation of solvers for the three domains H, JÐ and Y in Constraint Functional Logic Programming, based on the propagation of mate constraints between the JÐ and Y solvers. Our presentation includes both a formal description of cooperative goal solving as an enrichment of existing goal solving calculi [9,2] and a discussion of an effective implementation as an extension of an existing constraint functional logic system, which was already shown to have a reasonable performance [3]. We have obtained encouraging performance results, shown by goal solving examples where the propagation of mate constraints dramatically cuts the search space, thus leading to significant speedups in execution time. Besides the benefits of improving efficiency in a sequential environment,
cooperation of solvers even opens the possibility of exploiting emerging technologies such as parallel architectures and grid computing for the parallel execution of different solvers on different processing elements (platforms, processors or cores).
As mentioned in the introduction, the cooperation of constraint solvers has been extensively investigated during the last years [4]. Let us mention at this point

just a restricted selection of related work. In his PhD thesis [12] Eric Monfroy proposed BALI (Binding Architecture for Solver integration, see also [13,14]), providing a number of cooperations primitives which can be used to combine various solvers according to different strategies. Monfroy’s approach assumes that all the solvers work over a common store, while our present proposal requires communication among different stores. Mircea Marin [10] developed a CFLP scheme that combines Monfroy’s approach to solver cooperation with a higher-order lazy narrowing calculus somewhat similar to [9] and the goal solving calculus we have presented in Section 3. In contrast to our proposal, Marin’s approach allows for higher-order unification, which leads both to greater expressivity and to less efficient implementations. Moreover, the instance of CFLP implemented by Marin and others [11] is quite different to our work, since it deals with the combination of four solvers over a constraint domain for algebraic symbolic computation. More recently, Petra Hofstedt [6,5] proposed a general approach for the combination of various constraint systems and declarative languages into an integrated system of cooperating solvers.  In Hofstedt’s proposal, the goal solving procedure of a declarative language is viewed also as a solver, and cooperation of solvers is achieved by two mechanisms: constraint propagation, that submits a constraint
belonging to some domain Ð to Ð’s constraint store, say SD; and projection of constraint stores, that consults the contents of a given store SD and deduces constraints for another domain. Propagation, as used in this paper, is more akin to Hofstedt’s projection; while Hofstedt’s propagation corresponds to our goal solving
rules for placing constraints in stores and invoking constraint solvers. Hofstedt’s ideas have been implemented in a meta-solver system called META-S, but we are not aware of any performance results.
These and other related works encourage us to continue our investigation, aiming at finding and implementing more elaborated means of communica- tion among solvers, as well as trying their performance experimentally. Fu- ture planned work also includes modelling the declarative semantics of cooper- ation. The implementation described in this paper will be soon available (see http://toy.sourceforge.net).

References
Arenas, P., A. Fern´andez, A. Gil, F. L´opez-Fraguas, M. Rodr´ıguez-Artalejo and F. S´aenz-P´erez, T OY. A Multiparadigm Declarative Language. Version 2.2.2 (2006), R. Caballero and J. S´anchez (Eds.), Available at http://toy.sourceforge.net .
del Vado-V´ırseda, R., Declarative Constraint Programming with Definitional Trees, in: Proc. FroCoS’05
(2005), pp. 184–199.
Fern´andez, A. J., T. Hortal´a-Gonz´alez, F. S´aenz-P´erez and R. del Vado-V´ırseda, Constraint Functional Logic Programming over Finite Domains, Theory and Practice of Logic Programming (2007), in Press.
Granvilliers, L., E. Monfroy and F. Benhamou, Cooperative Solvers in Constraint Programming: A Short Introduction, in: Workshop on Cooperative Solvers in Constraint Programming, 2001.
Hofstedt, P., “Cooperation and Coordination of Constraint Solvers,” Ph.D. thesis, Shaker Verlag. Aachen (2001).

Hofstedt, P. and P. Pepper, Integration of Declarative and Constraint Programming, Theory and Practice of Logic Programming (2007), in Press.
Jaffar, J. and M. Maher, Constraint Logic Programming: a Survey, Journal of Logic Programming
19&20 (1994), pp. 503–581.
Lo´pez-Fraguas, F., M. Rodr´ıguez-Artalejo and R. del Vado-V´ırseda, A New Generic Scheme for Functional Logic Programming with Constraints, Journal of Higher-Order and Symbolic Computation (2007), in Press. Extended version of Constraint Functional Logic Programming Revisited, WRLA’04, ENTCS 117, pp. 5-50, 2005.
Lo´pez-Fraguas, F., M. Rodr´ıguez-Artalejo and R. del Vado-V´ırseda, A Lazy Narrowing Calculus for Declarative Constraint Programming, in: Proc. of PPDP’04 (2004), pp. 43–54.
Marin, M., “Functional Logic Programming with Distributed Constraint Solving,” Ph.D. thesis, Johannes Kepler Universit¨at Linz (2000).
Marin, M., T. Ida and W. Schreiner, CFLP: a Mathematica Implementation of a Distributed Constraint Solving System, in: Third International Mathematica Symposium (IMS’99) (1999).
Monfroy, E., “Solver Collaboration for Constraint Logic Programming,” Ph.D. thesis (1996).
Monfroy, E., A Solver Collaboration in BALI, in: Proc. of JCSLP’98 (1998), pp. 349–350.
Monfroy, E. and C. Castro, Basic Components for Constraint Solver Cooperations, in: Proc. 18th Annual ACM Symposium on Applied Computing (SAC 2003) (2003), pp. 367–374.
SICStus Prolog (2006), http://www.sics.se/isl/sicstus .
