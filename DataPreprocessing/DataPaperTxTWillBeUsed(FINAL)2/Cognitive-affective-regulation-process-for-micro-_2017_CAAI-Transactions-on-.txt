Available online at www.sciencedirect.com
ScienceDirect


CAAI Transactions on Intelligence Technology 2 (2017) 56e61
http://www.journals.elsevier.com/caai-transactions-on-intelligence-technology/
Original Article
Cognitive-affective regulation process for micro-expressions based on Gaussian cloud distribution
Xiujun Yang, Lun Xie*, Jing Han, Zhiliang Wang
School of Computer and Communication Engineering, University of Science and Technology Beijing, Beijing 100083, China
Available online 22 December 2016

Abstract

In this paper, we explore the process of emotional state transition. And the process is impacted by emotional state of interaction objects. First of all, the cognitive reasoning process and the micro-expressions recognition is the basis of affective computing adjustment process. Secondly, the threshold function and attenuation function are proposed to quantify the emotional changes. In the actual environment, the emotional state of the robot and external stimulus are also quantified as the transferring probability. Finally, the Gaussian cloud distribution is introduced to the Gross model to calculate the emotional transitional probabilities. The experimental results show that the model in humanecomputer interaction can effectively regulate the emotional states, and can significantly improve the humanoid and intelligent ability of the robot. This model is consistent with experimental and emulational significance of the psychology, and allows the robot to get rid of the mechanical emotional transfer process.
Copyright © 2016, Chongqing University of Technology. Production and hosting by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).

Keywords: Micro-expression; Cognitive-affective regulation; Gaussian cloud distribution; Transferring probability; Emotional intensity



Introduction

Micro-expressions is a short facial expression that cannot be independently controlled by brain, and it is trying to suppress or hide the true human emotion [1]. In 1966, Haggard and Isaaes found a quick facial expression that is not so noticeable. They believe the expression is related to the self-defense mechanisms and shows some pent-up emotions. In 1969, Ekman and Friesen also independently discovered the facial expressions, and have a name for it: micro-expressions [2].
Micro-expression is closely related to the process of emotional information for human, it can't be forged and can't be controlled by conscious. At the same time, micro-expressions is reflecting the true feelings in the human's heart, but it is diffi- cult for people to perceive [3]. In this paper, we establish af-
fective computing model based on the micro-expression

* Corresponding author.
E-mail addresses: xiujun_yang@yeah.net (X. Yang), xielun@ustb.edu.cn (L. Xie), hanjing_ustb@163.com (J. Han), wzl@ustb.edu.cn (Z. Wang).
Peer review under responsibility of Chongqing University of Technology.
recognition in the humanerobot interaction. Then we verify the regulation process of robot emotion by experiment. To filter out the  human's  disguise,  micro-expression  recognition  and
emotion modeling are intended to analyze the real emotions.
Connection between micro-expressions and emotion

Sentiment exists in people's lives all the time. Although emotion is some kind of inner emotional experience, there are some external performances in touch with itdthe expression
is the external representation of emotion [4]. But micro- expression is different with common expression, it is a very quick look, the duration is only 1/4 s. Therefore, its existence is imperceptible for most people. And Ekman think that the micro-expression may contain all muscle action of general expressions [5], or may contain only a part of the muscle movements. It often occurs when a person is lying, and it expresses the real emotions that people is trying to suppress and hide. It is a spontaneous expression and action, and it also express the six basic facial expressions [6]. Shown in the following Table 1.


http://dx.doi.org/10.1016/j.trit.2016.12.002
2468-2322/Copyright © 2016, Chongqing University of Technology. Production and hosting by Elsevier B.V. This is an open access article under the CC BY-NC- ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).



Table 1
Comparison table of the facial muscle movement of micro-expression and basic emotions [6].



conflict with the environment and the social intervention. When the mood is incompatible with the specific case, they need to adapt to the situation by adjusting. Currently, there are

Basic
emotion
Facial muscle movement of micro-
expression
Facial image
a lot of emotional computing model was put forward based on cognition. The OCC model could be realized in computer with

Anger	Nostrils tighten; comers of the mouth are
pointing downward; eyes widened; Brows knitted;





Disgust	Lower lip down; upper lip thrust forward; eyebrows under pressure; eyes squeeze; tongue sticking out;





Fear	Eyes open wide; mouth opens wide; eyebrows improve; Lips retract;






Happy	Eyes get bright; wrinkles round eyes; cheekbones get prominent;






Sad	Eyes close; eyebrow furrow; comers of the mouth are pointing downward; mouth close tightly;





Surprise	Eyebrows rising; eyes open wide; mouth opened;






Emotional cognitive control

Cognitive model is the criteria of personal information processing. In addition, the criterion is the basic principle of cognitive reasoning. According to these principles, the changes of emotional state can be inferred from the effective factors in specific circumstance. And the factors include the human (H) and the environment (E) [7].
Emotional is a physiological state caused by the individual and the experience. Sometimes individual emotional reactions consistent with the change of the environment, and sometimes
the universal emotion cognition [8]. After that, emotional computing model based on HMM has been put forward by Pau- Choo Chung [9]. Xin Lun has obtained the analysis of emotion model by extending emotion process to continuous space, which enriches the robot's intermediate state making the
manemachine interaction more harmonious [10]. By the
above, we found that the method of combining the cognitive psychology and information science is the effective measure to improve robot emotion analysis. Gross Emotional regulation strategy gets more and more attentions due to the comput- ability. Gross came up with five emotion regulation strategies:
1) the situation selectiondis the top priority adjustment method; 2) the situation correctiondrefers to change the scenario that lead to the emotional events; 3) the attention distributiondincludes distraction and concentration; 4) the cognitive changedthe different interpretations of emotional events will lead to different personal emotions. 5) the adjust- ment of reaction dsuppresses emotional behavior by self- control and response-focused emotion regulation [11,12].
Among them, the first four are carried out prior to the formation of emotional response. And they are antecedent- focused emotion regulation. The adjustment of reaction is carried out after the formation of the emotional response, so it is response-focused emotion regulation. Gross proposed the process model of emotion regulation [13]. Moreover, he identified two major subdued ways of emotion regulationdthe cognitive reappraisal and the suppression of expression.
These two different emotion regulation strategies have different effects on the emotional, cognitive and social behavior [11]. What's more, the different regulations have
important implications for Individual emotional experience
and happiness in a relationship. For example, people who is accustomed to using cognitive reappraisal will experience fewer negative emotions and more positive emotions. But the one who is accustomed to using suppression of expression is just the opposite.
For the robot in humanecomputer interaction be more positive dynamic, the affect regulation come true based on cognitive reappraisal of response-focused regulation [14]. The cognitive reappraisal aims at understanding and rationalizing negative emotional events through a positive way.
Because the ability of 3D gradient vector to capture the inter-linkages is stronger, we get the key frames of micro- expression through 3D gradient projection descriptor [15]. Then we can quickly and efficiently extract the features in each image area by wavelet method. Finally, as a foundation of following affective computing, the features of micro- expression are classified by the nearest neighbor algorithm. Based on the identification and classification of micro- expressions, we propose a Gaussian cloud model to imple- ment the cognitive-affective process [16]. The specific model shown in Fig. 1 we mainly analysis and calculation for the


	

Fig. 1. Cognitive-affective regulation process for micro-expression.
Fig. 3. The emotional attenuation function.



STEP 2 and STEP 3. The influence factors are introduced to shows the effect of external stimulation of emotion in the STEP 2. Based on the first two parts, the last part implements
As shown in Fig. 2:
8>

0	x < a0

the emotion transfer from emotions x to y.
1
sinp(x — a )	a
< x < a

Cognitive-affective regulation model


>>: 1
1
cos(12p(x — a )) +  sinp(a

— a )	x > a


For each basic emotional state, m is defined as the activation threshold of emotion, and n is defined as the saturation threshold of emotional. If the stimulus intensity is lower than m, there would be no effect on the behavior of the robot. If the stimulus intensity is higher than m, the emotional state will be activated. When the emotional intensity reaches saturation threshold, its value reaches the maximum. But in general, the emotional intensity won't keep in the maximum. Instead, it has
Because the emotion of psychology is momentary. Over
time, the emotional response curve is more similar to an exponential function. So we use the exponential function as the attenuation factor of the emotional state [17]. The atten- uation function of the emotional state is shown in Fig. 3. Suppose that the attenuation begins from t0 through external stimuli and there's no new stimulus until t, then the attenuation
function of emotion is:
E = f(E )= E e—b(t—t0 )

after reaching the maximum. n ensures that emotional intensity does not overflow the boundary.

Fig. 2. The emotional activation threshold function.
Here, E0 is the emotional intensity at t0, and Et is the emotional intensity at t. In addition, b is emotional decay rate which control the emotional rate of decline. Final, t-t0 is the time it takes to decay.

2.2. The definition of emotional state description based on the Gaussian cloud distribution
First, the robot's emotional state space is defined as
S	s1; s2; /; sn . That is, the robot has a total of n different
emotional states. This includes all of the emotional states of the robot. And the robot can freely switch among them. The change of emotional state is free, discrete, and discontinuous. Therefore, we use the Gaussian cloud distribution to build the emotional state transition model of the robot [18].
The emotional state of robot changes from state sj to sk is defined as case xjk, and the probability of the occurrence is mjk.Then the pointd(xjk, mjk)dfalls into the coordinate system and forms a cloud droplet. All the cloud droplets formed from each case of emotional state transition and its possibility of the


+∞	1	"
f (x)=	,2ﬃﬃﬃpﬃﬃﬃsﬃﬃﬃ2ﬃexp —

(x — sk)2


2s2

—∞
	1	
exp
2
i
(s — si)2


2w










Fig. 4. The Gaussian cloud distribution model.


transfer fall into the coordinate system to form a Gaussian cloud model of the robot's emotional state transition. As shown in the Fig. 4:
In addition, the input stimulate of robot in the emotional state space is defined as W   w1; w2; /; wm . Here, m 6 * 2 12, is the number of emotional input from micro- expressions.
Then we use the positive Gaussian cloud algorithm to get the probability of emotional transition. At the first, we can use
In Gross emotion regulation strategy, stimulating emotional state space w accord with the situation selection and the adjustment of reaction. The external stimuli evokes the robot's
emotion and tries to influence the emotional reaction of the
robot. The robot will tend to avoid certain people, places or things to regulate emotion. The facial muscle contraction of micro-expressions is not sufficient, so the expression of emotional state is very weak. Therefore, the emotional state only has a very low intensity in stimulating space w.

2.3. Influence gene from the micro-expression

The probability of the emotional state transition is closely related to and the current emotional state of the robot and the input stimulate wi obtained from the micro-expression.
The emotions of the micro-expression are divided into the following three categories: 1) happiness is defined as positive emotion, these emotions can enhance relations and reduce

the  formula  E = NORM(sj; w2)= ¨sj¨ 2  to  generate  a
stress level in the interaction; 2) disgust, anger, fear and

Gaussian random number. Among them, sj is expectations and wj is variance. Then similarly, we generate another Gaussian random number by the formula xjk  NORM sk; E2    sk  E2 .
Finally, according to the formula:

xjk —sk 
mjk = e— 2E2
We calculate the certainty degree. In other words, that is the probability of the emotional state transition from sj to sk under the incentive wj.
Because the state transition contains all of the situations of the transfer, the sum of the state transition probability is 1 under certain stimuli. That is to say, it is a certain event. Therefore, the constraint of transferring probability is:
+∞
f (x)dx = 1
—∞
Among it, f(x) is probability density function of the Gaussian cloud distribution. Emotional state transition from state sj to sk belongs to the conditional probability event. Based on the study of Gaussian cloud distribution [19], f(x) calculation process is as follows:

hinder relations and increase stress level in the interaction; 3) in addition, the silence and surprise are defined as neutral emotions, these emotions do not change the interaction. Therefore, we define the range of wi as shown in Table 2.

Simulation and analysis

In the process of humanerobot interaction, we apply the emotion regulation model of the micro-expression to obtain the experiment results of objective psychology. Due to the robot will feel different pressure on different environments, the definitions of the functiondNORMdin various environ- ments are different. For evaluating the effectiveness of regu- lating factors, we change the NORM to simulate situation. The comparison is shown in Fig. 5. In the diagram, the blue line represents the transferring probability of environment with high pressure, and the red line shows the low one. Results show that the pressure in environment have little effect on transferring probability without external stimulation. Under the stimulation of mild happy, the relationship between human and robot becomes more harmonious, and the positive trans- ferring probability increases. What's more, the transferring



Table 2
The influence on wi caused by micro-expressions. Emotional states of robot	Micro-expressions
Happy	Calm and surprise	Disgust	Anger	Fear	Sad
Negative emotions	0 ≤ wi < 1	wi = 0	—0.25 ≤ wi < 0	—0.5 ≤ wi < —0.25	—0.75 ≤ wi < —0.5	—1 ≤ wi < —0.75
Positive emotions	—1 < wi ≤ 0	wi = 0	0 < wi ≤ 0.25	0.25 < wi ≤ 0.5	0.5 < wi ≤ 0.75	0.75 < wi ≤ 1






Fig. 5. The influence of different pressures from environment.

probability is bigger in the environment with low pressure. When the external stimulus is angry, the relationship between human and robot will become bad, and the positive emotional transferring probability will reduce.
When the pressures on different environments are same, the emulational graph of the transferring probability under the same external stimulus is shown in Fig. 6. Among them, the parameters of regulation are mainly based on the experimental environment and robot emotional state. As we can see from the figure, the transferring probability of happy increases with a slight happy stimulation, oppositely the probability of anger re- duces. When the mood reach the saturation value, the emotional transferring probability tends to be stable without stimulation. Moreover, it will reduce with time elapsing. When an external stimulus come again, the emotional transferring probability will adjust as well. The results of cognitive-affective regulation conform to the basic characteristics of the human emotions.

Conclusions

First, this article introduces the cognitive reasoning process and micro-expression recognition. Then, based on the Gaussian

Fig. 6. The transferring probability of happy and anger in the stimuli.
cloud model, we describe the realization of emotional recog- nition process of the Gross model. What's more, the attenuation function and threshold function are proposed for quantizing the
process. Further, the Gaussian cloud algorithm is introduced into the model to calculate the transferring probabilities. Finally, we discuss the value of wi.
The experimental results show that the model in human- ecomputer interaction can effectively regulate the emotional states, and can significantly improve the humanoid and intelligent ability of the robot. This model is consistent with experimental and emulational significance of the psychology, and allows the robot to get rid of the mechanical emotional transfer process. Typical functions of the conclusion of a scientific paper include 1) summing up, 2) a statement of conclusions, 3) a statement of recommendations, and 4) a graceful termination. Any one of these, or any combination, may be appropriate for a particular paper. Some papers do not need a separate concluding section, particularly if the conclusions have already been stated
in the introduction.

Acknowledgments

This work is supported by National Natural Science Foundation of China (Normal Project No. 61672093, Key Project No. 61432004) and National Key Research & Devel- opment Plan of China (No. 2016YFB1001404) and Zhenjiang City's 331 Planning Project (2014-07-79).

References

W.J. Yan, Q. Wu, J. Liang, et al., How fast are the leaked facial ex- pressions: the duration of micro-expressions, J. Nonverbal Behav. 37 (4) (2013) 217e230.
P. Ekman, Telling Lies: Clues to Deceit in the Marketplace, Politics and Marriage, second ed., Norton, New York, 2001.
Liu Xin, Xie Lun, et al., Dynamic regulation process of facial expression robot, Control Theory Appl. 28 (7) (2011) 936e946.
Wu Ran, Ren Yanju, Study on priming effect of micro-expression, Chin.
J. Appl. Psychol. 17 (3) (2011) 241e248.
P. Ekman, Lie Catching and Microexpressions. The Philosophy of Deception, Oxford University Press, 2009.
M. Gavrilescu. Proposed architecture of a fully integrated modular neural network-based automatic facial emotion recognition system based on Facial Action Coding System. 10th International Conference on Com- munications (COMM), Bucharest, Romania, May 2014, 1e6.
Yue Wang, Shoudong Huang, Rong Xiong, Jun Wu, A framework for multi-session RGBD SLAM in low dynamic workspace environment, CAAI Trans. Intell. Technol. 1 (1) (2016) 90e103.
A. Ortony, G.L. Clore, A. Collins, The Cognitive Structure of Emotions, Cambridge University Press, UK, 1988.
Chin-De Liu, Yi-Nung Chung, Pau-Choo Chung, An interaction- embedded HMM framework for human behavior understanding: with nursing environments as examples, IEEE Trans. Inf. Technol. Biomed. 14
(5) (2010) 1236e1246.
Xin Liu, Lun Xie, Complex emotional regulation process in active field state space. 12th International conference of intelligent autonomous systems, Jeju, South Korea, June, 2012, 423e432.
J.J. Gross, Emotion regulation: affective, cognitive, and social conse- quences, Psychophysiology 39 (3) (2002) 281e291.
T.J. Wiltshire, S.M. Fiore, Social cognitive and affective neuroscience in humanemachine systems: a roadmap for improving training,



humanerobot interaction, and team performance, IEEE Trans. Human- Machine Syst. 44 (6) (2014) 779e787.
Peng Xiaolan, Xie Lun, Liu Xin, Wang Zhiliang. Emotional state tran- sition model based on stimulus and personality characteristics, China Commun. 10 (6) (2013) 146e155.
Jing Han, Lun Xie, Xin Liu, Zhiliang Wang. Emotional state transfer model based on FSM. 2014 International Conference on Multisensor Fusion and Information Integration for Intelligent Systems (MFI), Bei- jing, China, Sept. 2014,1e5.
Senya Polikovsky, Yoshinari Kameda, Yuichi Ohta, Facial Micro- expressions Recognition Using High Speed Camera and 3D-gradient Descriptor. 3rd International Conference on Crime Detection and Pre- vention (ICDP 2009), United Kingdom, London, Dec, 2009, pp. 1e6.
Juebo Wu, Hehua Chi, Shuliang Wang, Lianhua Chi, Facial Expression Synthesis Based on Cloud Model, 2010 2nd International Workshop on Intelligent Systems and Applications (ISA), Wuhan, China, May, 2010,
pp. 1e4.
T. Mstsumaru, Discrimination of Emotion from Movement and Addition of Emotion in Movement to Improve Human-coexistence Robot's Per- sonal Affinity, 18th IEEE International Symposium on Robot and human
interactive, Toyama, Japan, Sept. 2009, pp. 387e394.
Li Hesong, Zhang Guangwei, Li Deyi, Li Xiangmei. Computation on attribute importance of classification based on cloud model. 2008 In- ternational Conference on Computational Intelligence for Modelling Control & Automation, Vienna, Austria, Dec, 2008, 879e883.
Liu Yuchao, Adaptive concept abstraction method on multi-granular- itydGaussian cloud transformation, Comput. Eng. Appl. 51 (9) (2015) 1e8.


Xiujun Yang born in Yunnan province in 1991. She received B.E. degree in electronic engineering from the University of Science and Technology Beijing, China, in 2013. Now, she is a graduate student in electronic science and technology, in school of Com- puter and Communication Engineering, in USTB, in Beijing
Lun Xie received his Ph.D. degree in control theory and engineering from the University of Science and Technology Beijing, China, in 2002. In 2002, he was a faculty member at USTB, China. Currently, he is a professor in the school of Computer and Communi- cation Engineering at USTB, China. He has published over 100 refereed journal and conference papers. His research interest covers intelligent robot, embedded system, simulation and design of automation system. Prof. Xie is a member of CAAI, BPES



Jing Han born in Hebei province in 1990. She received B.E. degree in electronics and information engineering from Hebei University of Science and Technology, China, in 2012. Now, she is currently a doctoral candidate in communication and information system at University of Science and Technology Bei- jing, China. His research interest covers Pattern recognition and affective computing





Zhiliang Wang received his PhD. degree in Harbin Institute of Technologies, China, in 1988, and In 1991, he was a faculty member at University of Science and Technology Beijing, China. Currently, he is a profes- sor in the school of Computer and Communication Engineering at USTB, China. He has published about over 200 refereed journal and conference papers. His research interest covers artificial psychology, internet of things, and service robotics.
