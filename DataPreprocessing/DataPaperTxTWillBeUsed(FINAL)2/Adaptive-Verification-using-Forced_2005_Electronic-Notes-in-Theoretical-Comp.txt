	Electronic Notes in Theoretical Computer Science 141 (2005) 171–197	
www.elsevier.com/locate/entcs

Adaptive Verification using Forced Simulation

Roopak Sinha1
University of Auckland Auckland, New Zealand
Partha S. Roop2
University of Auckland Auckland, New Zealand
Bakhadyr Khoussainov3
University of Auckland Auckland, New Zealand

Abstract
Simulation (a pre-order) over Kripke structures is a well known formal verification technique. Simulation guarantees that all behaviours of an abstracted structure (a property or function, F ) are contained in a larger structure (a model M ). A model, however, may not always simulate a property due to the presence of design errors. In this case, the model is debugged manually. In this paper, we propose a weaker simulation over structures called forced simulation for automated debugging. Forced simulation is applied when normal simulation fails. Forced simulation between a model (M ) and a function (F ) guarantees the existence of a modifier, D, to adapt M so that the composition of M and D is observationally equivalent to F . Observational equivalence over structures called weak bisimulation is developed in this paper. It is also established that when two structures are weakly bisimilar all CTL∗ properties holding over one also holds over the other structure. Forced simulation based algorithm has been used to adapt many designs which had failed certain properties during conventional verification.
Keywords: Formal verification, adaptive, bisimulation.


1 Email: rsin077@ec.auckland.ac.nz
2 Email:p.roop@auckland.ac.nz
3 Email:b.khoussainov@auckland.ac.nz




1571-0661 © 2005 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2005.02.047

Introduction

Formal verification techniques are being widely applied in the design, de- velopment and validation of reactive systems such as digital hardware and hardware-software embedded systems [18,11], [4,14,17]. Formal methods use precise syntax and semantics for defining specifications and models of systems so that rigorous verification of properties such as correctness, reliability and security is made possible. Model checking [4] is an automatic formal verifica- tion technique to check if a model of a design (M) satisfies a given property (a function F ) using reachability analysis over the state space of M. Model checking has become very appealing for automated verification due to initial state space reduction techniques like symbolic model checking [2] and more recently approaches using SAT solvers for bounded model checking [1]. The detection of a property failing over a model is a cause for concern as a model checker usually only produces some counter examples and the designer has to manually debug the model prior to attempting another cycle of model check- ing. Hence, approaches to automated debugging is of considerable interest to the community [6,7].
Model checking failures that lead to design debugging may be due to several reasons:
Specification or property inconsistency: A system design may have errors introduced due to typographical mistakes (for example writing if (p ≥ 0) instead of if(p ≤ 0)) that are very hard to detect using automated techniques.
Modelling inconsistency: A system may be inconsistently modelled re- sulting in model checking failure. The formal model extracted from a given system may not accurately indicate all behaviours of the given sys- tem resulting in such inconsistencies.
Consistent but buggy model: There may be errors due to incorrect inter- pretation of requirements by the designer. Such errors may either result in a design completely inconsistent with the specifications or may intro- duce redundant paths or states generalizing a more exact specification.
Automatic debugging of the first type of errors is extremely difficult, if not impossible. Approaches for debugging the second type of errors have been recently developed. Adaptive model checking [6] addresses the issue of a model checker providing false negatives due to modelling inconsistencies. Another approach debugs the design of a concurrent system using temporal logic formulas to control the stepping between system states [7]. In this paper we are primarily concerned with the third type of errors which are introduced

due to the presence of redundant paths and states in a model. We illustrate this problem using the following example.

Motivating Example and Related Work
Consider a two process mutual exclusion solution (Figure 1 ) using semaphores
[3] represented as a Kripke structure [5]. Kripke structures are standard mod- els used in model checking defined as follows:
Definition 1.1: A Kripke structure [9] is a state machine represented in a tuple of the form M < AP, S, s0, Σ, δ,λ > where:
AP is a set of atomic propositions.
S is a finite set of states.
s0 is the unique start state.
Σ is a finite set of events or signals that occur in the environment of the system.
δ ⊆ S × Σ × S is the transition relation.
λ : S → 2AP is the state labelling function that labels each state with the atomic propositions (in AP ) which it satisfies.
For the mutual exclusion example, AP = {semaphoreval = 0(available), semaphoreval = 1(taken), p1state = i(idle), p1state = c(critical), p1state = e(entering), p1state = x(exiting), p2state = i(idle), p2state = c(critical), p2state = e(entering), p2state = x(exiting)}. Also, S = {s0, s1, s2, s3, s4, s5, s6, s7, s8, s9, s10, s11} and Σ = {p1, p2}. δ is the transition relation which contains all possible transitions of the system in tuples of the form (s0, p1, s1). λ is the labelling function that provides specific labelling on individual states. For ex- ample, λ(s4)= {semaphoreval = 0, p1state = e, p2state = e} (in short {0, e, e}).
The semaphore example in Figure 1 contains 12 states, each labelled by three variables semaphoreval, p1state, p2state. The variable semaphoreval repre- sents whether the semaphore is available (0) or taken (1). The other two vari- ables show the state of the two processes and can be either i(idle), e(entering ), c(critical ) or x(exiting ). A process is idle when it does not need to enter its critical section, entering when it registers its need for the semaphore, critical when it enters its critical section and exiting when it is leaving its critical section. A transition from the current state to a successor is made when the input that triggers that transition is furnished by the operating environment of the system. The operating environment can be viewed as a process-selector which at every instance decides which process (process 1 or process 2) is allowed to evolve. For example, in the initial state s0, semaphoreval = 0, p1state=idle and p2state=idle. The transition from state s0 to s1 is triggered

when the process-selector chooses process p1 to evolve. Consequently, the variable p1state changes from i(idle) to e(entering ). The other variables re- tain their previous values. If no process is chosen to be active in the current instance, the system stays in its current state. A self-loop on every state is not shown to keep a concise description of the system.Let this be an example model M.

Fig. 1. Kripke representation of a semaphore-based two-process system

A Kripke structure F representing the desired specification of the semaphore system is shown in Figure 2. In this specification, it is required that the first process that makes a request for the semaphore (changes its state to enter- ing ), is the one that gets to finish executing its critical section first. In the specification, if process 1 evolves from its initial idle state (in s0) to entering (in s1), then it is expected that process 1 is allowed to enter into its critical state (s3). After this, both processes are allowed to evolve till one of them again changes its state to entering. This can be viewed as a fairness constraint which ensures that starvation is prevented. The given system M in Figure 1 does not satisfy this requirement. For example, by reaching state s1 from the initial state s0, process 1 has already requested for the semaphore by changing its state to entering. However, s1 can reach state s4 when the process-selector selects process 2, which in-turn makes a request for the semaphore by chang- ing its state to entering. State s4 may then make a transition to state s8 if the process-selector chooses process 2 to evolve next. In this case, process 2 gets to execute its critical section before process 1, even though process 1 had

requested the semaphore first. This sequence represents the violation of the desired property as the process that first changes its state to entering does not get to enter and consequently exit its critical section first.

Fig. 2. The desired semaphore system behaviour
Given M and F as above we cannot use existing adaptation techniques [6,7] to debug this model automatically (as there are buggy paths and states in the model not desired in the specification). Moreover, techniques like model checking will find counter examples and debugging of the model will have to be subsequently done manually. The proposed approach attempts to auto- matically debug models with faulty (buggy) states and paths using a form of dynamic model checking. The main idea is the construction of an modiﬁer pro- cess (another Kripke structure) that dynamically adapts the model to remove faulty paths and states.
Given an arbitrary model and specification (M-F ) pair, it is important for any adaptation technique to address the following fundamental issues:
Under what conditions can a model be automatically adapted to satisfy a given specification?
How can it be established that a given adaptation is correct, that is the adapted model will satisfy the given specification?
How can it be established that the adapted model is indeed consistent from its specification?
In the subsequent sections we present a formal framework for answering

these questions. We also present experimental results using an adaptive ver- ification tool called ADVERT (Adaptive Verification of ReacTive Systems). The main contributions of the paper are:
An automated algorithmic framework for debugging verification failures due to buggy states and paths is developed. The proposed algorithm is based on the notion of adaptation of a buggy model using a modifier that dynamically alters the model.
The debugging algorithm is based on a new simulation relation over Kripke structures called forced simulation that is weaker than conven- tional simulation. Forced simulation between Kripke models of a spec- ification and a model guarantees the existence of an modiﬁer (another Kripke structure) to adapt the model dynamically so that inconsistencies with respect to the specification can be removed.
In order to verify that the proposed approach produces accurate modi- fiers, a notion of weaker equivalence (observational equivalence) between structures is necessary. This lead to the development of weak bisimula- tion over Kripke structures, also developed by us. It is established that the composition of the modifier and the model is weakly bisimilar to the desired specification. It is also further established that when two struc- tures are weakly bisimilar they satisfy the same set of CTL∗ properties.
An adaptive verification tool called ADVERT has been developed by extending NuSMV [3]. ADVERT has been used to debug many standard designs having model checking failures.
Simulation and preorders over labelled transition systems (LTS) [12] and Kripke structures [5] are well known. While simulation and refinement have been used for state space reduction and implementation verification, they are not directly applicable to the problem of design debugging as the model in question has buggy paths and states that need to be removed from the model. Recently, forced simulation over labelled transition systems [16] has been de- veloped for dynamically changing a LTS description of a design for automatic reuse. In this paper, the idea of forced simulation over LTSs is substantially altered to develop forced simulation over Kripke models. Automated compo- nent reuse using forced simulation [16] proposes an algorithm which matches the states of two given LTSs using the environment inputs that trigger their transitions. However, in the presented approach the states of two given Kripke structures are matched using their state labelling. The aim of the component reuse technique using forced simulation is to make a given device weakly bisim- ilar [12] (functionally equivalent) to a given design function. In contrast, the presented approach works in a verification framework and is based on adapt-

ing a model to satisfy a given temporal specification. Forced simulation over Kripke models requires a weaker equivalence than strong bisimulation over Kripke models [13] due to the introduction of τ (internal) transitions in the debugged model. This paper develops weak bisimulation over Kripke struc- tures and also proves that this equivalence preserves CTL∗ equivalence.
The debugging problem addressed in this paper is somewhat similar to the controllability problem [15] within control systems where a controller is synthesized to make a plant behave as the desired speciﬁcation (e.g, the role of the controller is to adapt the behaviour of the plant dynamically). The task of the controller is to disable certain actions of the plant at specific points. Though this problem has been studied in a general nondeterministic setting, it is not applicable to the debugging task of reactive systems which requires specific types of adaptation. Module checking [10] is a model checking vari- ant developed for property checking of reactive systems. Unlike conventional model checking that ignores the environment, module checking takes the asyn- chronous environment of a reactive system into consideration. It considers the states of a model as either an environment state (a state that requires an envi- ronment input) or a system state (an internal state requiring no environment input) and performs model checking in the presence of environment states. In the adaptive verification approach developed in the paper, we consider an ab- straction of the design that has only environment states and as a result of our proposed debugging some system states are also introduced in the debugged model. Unlike module checking, however, the proposed approach not only considers the environment passively but also introduces an additional envi- ronment in the form of a modifier to force certain environment events into the model or to block some events in the environment from reaching the model (called disabling).
This paper is organized as follows. Section 2 introduces the forced simula- tion relation, which has been proven to be the necessary and sufficient condi- tion for adaptation. The details of how an automatically generated modifier adapts a given model appears in section 3. Weak bisimulation, an equivalence relation developed to test equivalence between an adapted model and its spec- ification is given in section 4. Section 5 presents the extension of temporal property satisfaction to weak satisfaction, used to show that a model adapted using forced simulation indeed satisfies the same set of temporal properties as the given specification. Section 7 presents theoretical and practical results of design debugging and the final section is devoted to concluding remarks.

Forced Simulation
Forced simulation is a simulation relation defined over two Kripke structures, a model (M) and a specification (F ) and aims to provide a basis for checking whether M is adaptable to meet F . It is defined as follows (In this definition the states of the function (specification) are denoted as sf and that of the model are denoted as sm with (sf0, sm0) denoting the start states of the function and model respectively.):
Definition 2.1: For Kripke structures F and M, a relation B ⊆ SF × SM ×
∗  is called a forced simulation relation (in short, an f−simulation relation)
provided the following hold (sf Bσsm is used as a shorthand for (sf , sm, σ) ∈ B
where length of σ is bounded by |SM | (number of states in M)):
sf0Bσsm0 for some σ ∈ Σ∗ .

sf
Ba.σ sm
⇒ (∃s'
: sm →
' ∧ sf
Bσs'
) for any σ ∈ Σ∗ .

s Bєs	⇒ (λ
(s ) = (λ(s
)) ∧ (∀s' , ∃s'
, ∃a.σ : s
→ s' ⇒ (s	→a

f	m
s' ∧ s' Bσs'
F	f
)).
m	f	m
f	f	m

m	f	m
The first condition requires that the start states of the two structures be related via some forcing sequence σ. The second condition requires that when any two states (sf , sm) are related via some forcing sequence a.σ then there
must be a transition from sm to some state s' that triggers using environment
input 'a' and further that sf , s'	must be related. This rule is required to
successively reduce a forcing sequence until a state that is directly similar to sf is found. Two states sf , sm are directly related when the forcing sequence is empty or ϵ. In that case, the state labelling of these states must match and further every transition out of sf must be matched by a corresponding transition out of sm and the resultant states of these transitions must be related via some sequence σ.
Definition 2.2: F ±fsim M provided there exists an f−simulation relation between them.
Consider processes M and F as shown in Figures 1 and 2. F ±fsim M since there exists R = {(sf0, sm0), (sf1, sm1), (sf2, sm2), (sf3, sm3), (sf4, sm5), (sf0, sm6), , (sf5, sm7), (sf6, sm8), (sf0, sm9)}, which can be easily shown to be an f −simulation relation.

Adaptation using a modifier
The approach for automatic debugging is based on controlling the transitions of the model to ensure that the specification is satisfied. The adaptation is performed by an automatically generated modiﬁer process which exercises

state-based control on the system. A modifier controls a model in the following ways:
Disabling action: Consider the sequence of states s0, s1, s4, s8, s11, s1 in M (Figure 1). As described earlier, this path is inconsistent with the given specification F in Figure 2 because state s1, where process 1 has already changed its state to entering, can make a transition to state s4 where process 2 changes its state to entering as well. If state s1 is forbidden from making a transition to state s4, the faulty path can be eliminated. This can be achieved if the process-selector signal p2 is hidden from the system when it is in state s1. This state-based hiding of actions is known as disabling and is achieved when the modifier absorbs one or more environment inputs and effectively disables the system to make certain transitions.
Forcing action: Consider the path s0, s1, s3, s6, s0 in M (Figure 1). This path is also inconsistent with the specification due to the presence of state s6 (p1 in its exiting state) which has no corresponding equivalent in F . If state s3 evolves to s6 by reacting to the process-selector input p1 and then if s6 makes a transition to its successor s0 without waiting for the input p1 (which triggers the transition), it would seem to the operating environment, that the system made a transition from s3 to s0 by reacting to the single environment input p1. The transition from s6 to s0 therefore becomes in- ternal transition and state s6 becomes an unobservable or internal state. This is called forcing and is achieved when the modifier artiﬁcially manufac- tures an environment input to force the system to make a specific transition without interacting with its environment. Looking at the observable part s0, s1, s3, s0 of the path s0, s1, s3, s6, s0, it can be seen that it is now consis- tent with the path s0, s1, s3, s0 in F (Figure 2). Internal or unobservable transitions are similar to CCS τ transitions and originate only from internal or unobservable states.
A modifier may allow the current state in M to evolve without any disabling or forcing.
Internal or unobservable states may be introduced into the adapted system by a modifier during forcing. An internal state is different to an observable state in that it is unobservable to the operating environment and makes an internal τ transition to its successor without waiting for any input from the environment. Such states are labelled by the proposition intern to indicate that they are unobservable.
A modifier needs strict control over all transitions of the current state in the model so that each transition can be uniquely forced or disabled if needed. As actions that trigger transitions are used to distinguish between



Fig. 3. A well formed modifier for the semaphore example
transitions, no state can have more than one transition triggered by the same action. Therefore, only deterministic models can be used under the proposed framework.
Definition 3.1: A Kripke structure A < APA, SA, sa0, ΣA, δA, λA > is said to be deterministic if and only if for any sa ∈ SA, if (sa, a, s' ) and (sa, a, s'') ∈ δA

for any sa, s' , s'' ∈ SM and a ∈ ΣM then s'
a	a
= s''.

a	a	a	a
A modifier must be well formed which means that it must not allow any
system state to accept inputs from the environment if the modifier performs forcing on it. A well-formed modifier for the semaphore example in Figure 1 is shown in Figure 3. A modifier itself does not contain any temporal information and all its states are labelled with the proposition True.
Composition of a modiﬁer and a model
The state-based control exercised by a modifier over a given system is defined using a new // composition operator as follows.
Definition 3.2: Given D < APD, SD, sd0, ΣD, δD, λD > and M< APM , SM , sm0, ΣM , δM , λM > as above, D//M is defined to be a process described by the Kripke structure D//M < AP(D//M), S(D//M), (sd0, sm0), Σ(D//M), δ(D//M), λ(D//M) > where:
AP(D//M)=APM ∪{intern} (intern is used to label internal or unobservable states)
S(D//M ) ⊆ SD × SM

(sd0, sm0) is the start state.
λ(D//M)(sd, sm) = λM (sm) for all sm ∈ SM and sd ∈ SD, if Lab(sd) /= {[a]} otherwise λ(D//M)(sd, sm)={intern}. Internal states or states that evolve by forcing are labelled by intern.
Σ(D//M ) = ΣM  {τ }
δ(D//M) is defined as follows:
Forced Move: D//M makes an unobservable τ move, when D ‘forces’ a transition in M.

s −[a→] s
,sm
−a→sm1

(s ,sm)−τ→(s
,sm1)

In this case, the state (sd, sm) is made an unobservable state due to
forcing.
External Move: D//M makes an observable move with both the M and
D simultaneously responding to the same environment input.
s −a→s ,s−a→sm1

(s ,sm)−a→(s
,sm1)

In this case, (sd, sm) is a state that is observable to the operating envi-
ronment of D//M.
The primary reason for the development of the // operator is to allow the modifier to have tight control over the states of a model. Due to this requirement, other composition operators like the CCS || operator [12] can not be used. The result of composition using the || operator is a model that has no apparent control over M. In this case, the states of either M or D may advance to their respective successors without having to synchronize with the respective states in the other model. The // operator, on the other hand, does not allow any state in either model to advance without synchronizing with its respective state in the other model, providing lock-step control to the modifier. This is similar to lock-step process synchronization [8], however the difference lies in the way a modifier performs forcing, which is not present in any available composition operator. The modifier is not required to have explicit information about which state a system is in. The current state can be determined by keeping track of the environment inputs that the system has received so far.
Given the modifier D in Figure 3 for the semaphore example, D//M is presented in Figure 4. Note that states s1 and s2 are disallowed from making a transition using the process-selection inputs p2 and p1 respectively. These disabling actions ensure that none of the violating paths s1, s2, s4, s8 or s1, s3, s4, s7 are allowed. As explained earlier, the modifier controls the in- teraction of the system on a state-wise basis, therefore inputs p2 and p1 that are disabled in states s1 and s2 are allowed in all other states of the system. Similarly, states s5, s8, s9 and s10 in D//M (or s6, s9, s10 and s11 in M) are



Fig. 4. D//M , the sample modifier in Figure 3 driving the semaphore system
forced by the modifier to make transitions to s0, s0, s2 and s1 respectively. The modifier artificially manufactures the required actions (p1,p2, p1 and p2 respectively), making these transitions internal (τ transitions) to the environ- ment. These states therefore become internal and are consequently labelled with the proposition intern.

Weak bisimulation
Once a model is adapted using forced simulation, there is a need to estab- lish that it is equivalent to the given specification. Traditionally, equivalence between two Kripke structures can be checked using strong bisimulation [13]. However, as described earlier, adaptation using forced simulation may make some states in the adapted model unobservable. Unobservable states are in- visible to the operating environment of a system and are not required while checking for equivalence of a system with a specification. In other words, there is a need to extract only the observable part of a system and use this part to check for equivalence.
To verify equivalence between two Kripke structures which may contain unobservable states or paths, a weaker equivalence relation combining weak bisimulation equivalence over LTS [12] and strong bisimulation for Kripke structures has been formulated. Two Kripke structures are considered weakly bisimilar if their observable behaviours are strongly bisimilar [13].
Before presenting weak bisimulation, some important notations are defined

as follows.
Definition 4.1: Given a Kripke structure M < AP, S, s0, Σ, δ,λ > and states
s, s' ∈ S then:
If for some action a ∈ Σ, (s, a, s') ∈ δ then:
If λ(s) /= intern then s → s' where E represents an external transition
E
from s to s'.
Otherwise, if λ(s) = intern then s → s' where τ represents an internal
τ
transition from s to s'.
Consider the set Trans = {E, τ }.
Now, if α ∈ Trans∗ = A.B.C.D...Z is a sequence of possible transitions, then s → s' implies that s → s1 → s2..sN−1 → s'.
α	A	B	Z
This definition is used to relabel the transitions of a Kripke structures as either external (E) or internal (τ ). For example, given the adapted model D//M in Figure 4, consider the path s0, s1, s3, s5, s0. It is known that s0 → s1 → s3 → s6 → s0. Identifying each transition as either external or
p1	p1	p1	τ
internal, and representing each external transition with E and each internal

transition as τ , we get s0 →
E
s1 →
E
s3 →
E
s6 →
τ
s0 in the relabelled Kripke

structure. We can also say that s0 → s0 where α = E.E.E.τ .
α

Definition 4.2: If α ∈ Trans∗
then α∈ {E}∗
is the sequence obtained by
∧

deleting all τ occurrences from α. If after deleting all τ occurrences,α contains
∧	∧
no elements, then α= ϵ (τ ∗= ϵ).
In order to check for equivalence between two structures, it is required to extract and compare only their observable paths. This definition describes how only the observable part of a sequence of observable and internal actions can be extracted. Given the path s0, s1, s3, s5, s0 in the adapted model D//M in Figure 4, we have seen that s0 → s0 where α = E.E.E.τ . Extracting the
α
∧
observable part of α, we get α= E.E.E. Consider the transition s6 → s0. In
τ
this case, α = τ and therefore by the above definition, αˆ = ϵ.
Figure 5 shows the adapted D//M model with transitions relabelled either with E or τ . All transitions triggered by environment inputs are labelled by E and all internal transitions triggered by the modifier are labelled by τ (as per Definition 4.1).

Definition 4.3: Let α ∈ {E}∗. Then s ⇒
α
s' if and only if there exists

∧
α' ∈ Trans∗ such that s → s' ∧ α =α'.
α'
Consider the initial state s0 of the adapted model D//M in Figure 5.



Fig. 5. The adapted model with only external and internal transitions
Given the sequence α = E.E.E, s0 can reach states s5, s6, s7 and s8 using α. However, states s5 and s8 are internal states and therefore make an internal τ transition to their successor s0. Therefore, state s0 can reach itself by following the sequence α' = E.E.E.τ . From definition 4.2, αˆ' = E.E.E = α. Observing from the operating environment of the adapted model, s0 can reach states s6, s7 and s0 if provided with the sequence α = E.E.E. The τ transitions are not
visible to the environment and therefore not taken into account.
Definition 4.4: Given two Kripke structures A < APA, SA, sa0, ΣA, δA, λA > and B< APB, SB, sb0, ΣB, δB, λB > over the same set of atomic propositions APA = APB, a relation B ⊆ SA × SB is a weak bisimulation if for any sa ∈ SA and sb ∈ SB, B(sa, sb) if and only if:
(λA(sa)= λB(sb)) ∨ (λA(sa)= intern) ∨ (λB(sb)= intern)
If sa → s' for some α ∈ Trans∗	'	'	'
α	∧
α
If s → s' for some α ∈ Trans∗	'	'	'
α	b	∧
α
Figure 6 shows the specification F with only external transitions (labelled by E). We can see that s0 in F and s0 in the adapted model D//M (Figure 5) are related over a weak bisimulation relation. They satisfy rule 1 as both have the same state labelling (0, i, i). They also satisfy rule 2 and 3. For every state s' that s0 in F can reach using any sequence α, s0 in D//M can observably reach a state s'' using αˆ such that s' and s'' are also weakly bisimilar (and vice versa).



Fig. 6. The specification F
Definition 4.5: Two Kripke structures A < APA, SA, sa0, ΣA, δA, λA > and B < APB, SB, sb0, ΣB, δB, λB > are weakly bisimilar if and only if there exists a weak bisimulation relation WB such that WB(sa0, aB0 ).
Two structures are considered weakly bisimilar if their initial states are related over a weak bisimulation relation. As discussed above, s0 in F and s0 in D//M are weakly bisimilar to each other. Therefore, according to the above definition, the adapted semaphore model D//M in Figure 4 is weakly bisimilar to the given specification F in Figure 2.

Weak satisfaction
A system adapted using forced simulation may contain unobservable states and paths. To check whether an adapted system satisfies a given temporal property, there is a need to extend property satisfaction to take into account the possible presence of unobservable behaviours in a given system.
This problem can be explained as follows. All temporal logic formulas, including those expressed in CTL∗ and its subsets like LT L and CTL operate on states and their direct successors. However in a system adapted using forced simulation, the direct successor of a state might be unobservable. To ensure that unobservable states are not taken into account, there is a need to weaken property satisfaction using the following approach:
Property satisfaction needs examination of states and paths. Since model

debugging introduces internal or unobservable states and paths, there is a need to extract only the observable behaviour of the given model. This is done using the operators Nextob(), used for extracting the observable current state, and Succob(s), which returns the observable successor of the current state.
The definitions for the Nextob and Succob functions are provided as follows. Definition 5.1: The function Nextob : S → S where S is the set of states of a relabelled Kripke structure (definition 4.1), such that:
Nextob(s)= s if s is observable.
Nextob(s)= {s'|s → s'∧observable(s') where n ≥ 1} if s is unobservable.
τn
Definition 5.2: The function Succob : S → S where S is the set of states of a relabelled Kripke structure (definition 4.1), such that:

Succob(s)= {s'|s →
E.τn
s' ∧ observable(s') where n ≥ 0} if s is observable.

Succob(s) = {s''|(s'' ∈ Succob(s') where (s' ∈ Nextob(sa)} if s is unobserv- able.
Given the adapted model D//M in Figure 5, consider the initial state s0. This is an observable state. Therefore, Nextob(s0)= {s0} (definition 5.1) and Succob(s0) = {s1, s2}. It can be seen that for an observable state, Nextob returns the original state and Succob returns the observable successors of the given state. Now consider the state s5 in the adapted model D//M. This is an internal state (labelled with intern. Therefore, Nextob(s5) = {s0} and Succob(s5)= {s1, s2}. For an internal state, Nextob returns its observable suc- cessor (reached by a series of one or more τ transitions) and Succob returns the observable successors of the state returned by Nextob. The above defini- tions indicate that when checking for property satisfaction, an internal state is considered equivalent to its observable successor.
Based on the above definitions, observable path can be defined as follows: Definition 5.3: An infinite observable path starting from a state s is defined as πob(s) = s0, s1, s2, ..., s∞ where s0 ∈ Nextob(s) and the states s1 to s∞ are defined recursively as si = s'|s' ∈ Succob(si−1).
Definition 5.4: For any path π(s) starting from the state s, its corresponding observable path πob(s) is obtained by removing all unobservable states from it.
The notation |=W is used to represent weak satisfaction. Weak satisfaction for states, paths and models is defined as follows.
Definition 5.5: For any CTL∗ state-formula ϕ and any state s, s |=W ϕ if and only if there exists a state s' such that s' ∈ Nextob(s') and s' |= ϕ.
Definition 5.6: For a CTL∗ path-formula ϕ and for any path π with its first

state as s, π |=W ϕ if and only if the observable path πob(s) |= ϕ. Definition 5.7: For a CTL∗ formula ϕ and a Kripke structure M < AP, S, s0, Σ, δ, λ >, M |=W ϕ if and only if:
If ϕ is a state-formula, then s0 |=W ϕ.
If ϕ is a path-formula, then for all possible paths π(s0) with their start state as s0, π(s0) |=W ϕ.
For a Kripke structure M and a CTL∗ formula ϕ, if M |= ϕ then M |=W ϕ. This assertion shows that weak satisfaction extends the notion of property sat- isfaction to structures with internal structures and at the same time conserves property satisfaction in structures with no unobservable states.
Weak satisfaction makes forced transitions in the model internal in the composite process. In the current adaptation algorithm, states that are not present in the specification may be forced by the modifier in order to make the model satisfy the desired specification. Obviously, if we extend such adapta- tion technique to model checking, then forcing needs to be restricted so that bad states (states that may cause critical failure of the property) should not be forced. Hence, forced simulation needs to be modified to include the handling of certain states which are not forceable.

Adaptive verification algorithm
An algorithm has been formulated to compute a forced simulation relation given M and F . If successful, the algorithm generates the modifier D. The proposed algorithm is an adaptation of the component matching algorithm based on forced simulation [16]. The algorithm consists of a pre-computation step which computes all reachable states from every state in M and also the shortest paths to those states. The component matching algorithm [16] computes the path from a source state to a destination state as the sequence of environment signals required to reach the destination state from the source state. However, the proposed algorithm also computes another path between two states as a sequence of state labels beginning with the state labelling of the source state, followed by the state labels of all intermediate states and finishing with the labelling of the destination state. This extra information is used to match states based on their labels. All computed states and paths are stored in a set called RS(M). An initial set of blocks is created by pairing each sf in F with all members of RS(M). One of the blocks is chosen as a refining block and all other blocks are refined based on this. The refinement process stops when a fixed point is reached. The modifier D is then generated from the refined set of blocks following a similar method to the interface generation

algorithm in the component matching algorithm [16]. The total complexity of
the proposed algorithm is O(NS2 × NS2 × m) where NSF and NSM are the
F	M
number of states in F and M respectively and m = ||ΣM ||.

Results
The following theorems prove that forced simulation is the sufficient (theorem 1) and necessary (theorem 2) condition for automated debugging described in the earlier sections. Theorem 3 establishes that if two Kripke structures are bisimilar, they weakly satisfy the same set of properties. As automatic adap- tation ensures that D//M is bisimilar to F , theorem 3 guarantees that D//M weakly satisfies the same set of properties satisfied by F (and is therefore equivalent to F ).
Theorem 1: Given F ±fsim M there exists D such that F ≈ D//M, where
≈ refers to weak bisimulation equivalence over Kripke structures.
Theorem 2: If there exists a well formed and deterministic interface D such that F ≈ D//M, then F ±fsim M.
Theorem 3: Given two Kripke structures A < APA, SA, sa0, ΣA, δA, λA > and B< APB, SB, sb0, ΣB, δB, λB > such that A ≈ B, then for any CTL∗ formula ϕ:
(A |=W ϕ) ⇔ (B |=W ϕ)
where |=W stands for weak satisfaction.
The proofs of these theorems are provided in Appendix A.
Implementation Results
An adaptive verification tool called ADVERT has been implemented using the Java programming language and the NuSMV model checker [3]. The steps followed for automated debugging are as follows:
A model M and a specification F are extracted from SMV (symbolic model checker) language files. The extraction algorithm is incorporated in the popular NuSMV model checker [3] written in C programming lan- guage. The extraction algorithm performs a breadth-first search starting from the root (or initial) node(s) of a SMV file. The explicit details of each state traversed (labelling, transitions etc) are written to an out- put text-file. These output files are then used as inputs in the forced simulation algorithm.
After reading M and F as above, the forced simulation algorithm at- tempts to establish forced simulation between the two structures and if successful, generates a modifier that can adapt M to satisfy F . The

modifier is stored as a text-file. If a forced-simulation relation does not exist between M and F , the algorithm exits with a suitable error message indicating that M is not adaptable.
The above process has been applied to debug several SMV models mainly from the collection of examples on the NuSMV Website [3]. The results of the debugging are presented in table 1. The first column contains the name and size (number of states) of the debugged model M. The next column indicates the size of the specification F . The last column indicates the type of debugging performed (forcing, disabling or both).
In some cases, such as the alternating bit protocol and the batch reactor system, a subset of the actual number of states in the original NuSMV de- scription of the given model was used for debugging. In many cases, such as the mutual exclusion and pipeline examples, models were debugged to sat- isfy given fairness constraints. In other cases, such as the producer-consumer and priority queue examples, priority-based specifications were used to debug models to give priority to a certain sub-process. Most of the debugging show how a general model can be debugged to satisfy a more specific specification.

Conclusions
Existing formal methods can comprehensively detect inconsistencies between a given model and specification. However, the detection of such inconsistencies is followed by manual debugging of the model to satisfy the given specification. This manual debugging may be time consuming and the process of verifying and debugging might be repeated more than once. Therefore, automated design debugging in case of a failure to satisfy critical specifications is of great interest. This paper proposes a formal technique for automated model debugging. Given a model M and a failed specification F , the proposed technique can determine whether M can be automatically adapted to satisfy
F . A model can be automatically debugged if it is related to the specification over a weaker simulation relation called forced simulation presented in this paper. The existence of forced simulation has been proved to be the necessary and sufficient condition for the proposed debugging. If M is forced similar to F , the debugging algorithm automatically generates a modifier D which is guaranteed to adapt M (in the form of D//M) to satisfy F .
The debugging algorithm has been implemented in the Java programming language and several models from the NuSMV collection of examples [3] have been debugged. The current implementation is limited to medium-sized mod- els as it uses explicit representation of models and specifications and executes on the less-efficient Java platform. Work is in progress to extend the proposed


Table 1 Implementation Results
algorithm to work with implicit BDD based representation [2].

References
Biere, A., Cimatti, A., Clarke, E., and Zhu, Y. (1999). Symbolic Model Checking without BDDs. Technical report, Carnegie Mellon University.
Burch, J. R. et al. (1990). Symbolic model checking: 1020 states and beyond. In Fifth Annual IEEE Symposium on Logic in Computer Science.
Cavada, R., Cimatt, A., Olivetti, E., Pistore, M., and Roveri, M. (2003). NuSMV 2.1 User Manual.
Clarke, E. M., Emerson, E. A., and Sistla, A. P. (1986). Automatic verification of finite-state concurrent systems using temporal logic specifications. In ACM Transactions on Programming Languages and Systems, volume 8, pages 244–263.
Clarke, E. M., Grumberg, O., and Peled, D. A. (1999). Model Checking. The MIT Press.
Groce, A., Peled, D., and Yannakakis, M. (2002). Adaptive model checking. In Tools and Algorithms for Construction and Analysis of Systems, pages 357–370.
Gunter, E. and Peled, D. (2002). Temporal debugging for concurrent systems. In Tools and Algorithms for the Construction and Analysis of Systems : 8th International Conference, TACAS 2002, page 431.

Hoare, C. A. R. (1978). Communicating sequential processes. Commun. ACM, 21(8):666–677.
Hughes, G. E. and Creswell, M. J. (1977). Introduction to Modal Logic. Methuen.
Kupferman, O. and Vardi, M. (1996). Module checking [model checking of open systems]. In Computer Aided Veriﬁcation. 8th International Conference, CAV ’96, pages 75–86, Berlin, Germany. Springer-Verlag.
Manna, Z. and Pnueli, A. (1983). How to cook a temporal proof system for your pet language. In 10th annual symposium on Principles of Programming Languages, pages 141–154.
Milner, R. (1989). Communication and Concurrency. Prentice-Hall, Englewood Cliffs, N.J.
Park, D. (1981). Concurrency and automata on infinite sequences. In 5th Conference on Theoretical Computer Science.
Peled, D. A. (2001). Software Reliability Methods. Springer.
Ramadge, P. J. G. and Wonham, W. M. (1989).  The control of discrete event systems.
Proceedings of the IEEE, 77:81–98.
Roop, P. S. and Sowmya, A. (2001). Forced simulation: A technique for automating component reuse in embedded systems. In ACM Transactions on Design Automation of Electronic Systems.
Sowmya, A. and Ramesh, S. (1998). Extending statecharts with temporal logic. IEEE Tr. on Software Engineering, 24(3):216–231.
Vardi, M. Y. (1987). Verification of concurrent programs: The automata theoretic framework. In 2nd IEEE Symp. on Logic in Computer Science.

Appendix A: Forced Simulation theorems
Theorem 1. Given F ±fsim M there exists D such that F ≈ (D//M ), where ≈ refers to weak bisimulation equivalence over extended Kripke structures.
Proof.
The proof of the theorem involves the generation of a modifier given F ±fsim M .
Given F ±fsim M , there exists an f−simulation Y between F and M . For simplicity, let Y be a minimal f−simulation relation such that for any pair sf ∈ Sf , sm ∈ SM , there is at most one σ ∈ Σ∗ with (s , sm, σ) ∈ Y . The proof can be carried out, however, even for a non minimal Y .
Let D be < SD, (sf0, sm0, σ0), δD, λD, ΣD > where:
SD = Y is the set of states of D,
(sf0, sm0, σ0) ∈ Y is the start state of D,
λD(sd) = {True}
ΣD = {[a]|a ∈ ΣM } S ΣM is the set of events,
δD , the transition relation is defined by the following rules:

if (s ,s 
, a.σ) ∈ Y and s
→a s'
[a]	'

f  m	m
m then (sf , sm, a.σ) → (sf , sm, σ) or δD((sf , sm, a.σ), [a],

(s , s' , σ)).
f  m
In this case Lab(sd) = {[a]} (Lab(s) returns the set of actions the state s can react to make a transition).

if (s ,s , G) ∈ Y and (s' , s' , σ') ∈ Y and s  → s' and s	→a  s'  then (s ,s 
, G) →a

f  m	f  m	f	f	m	m	f  m
(s' , s' , σ') or δ ((s ,s , G), [a], (s' , s' , σ')).
f  m	D	f  m	f  m
In this case Lab(s )= {a|(a ∈ Σ ) ∧ (δ (s , a, s' ) for some s' ∈ S )}
d	M	D  d	d	d	D

The following set of simple observations and lemmata follow directly from the definition of D.
Observation 1: For every s ∈ S  there exists (s ,s , σ) ∈ S  for some s  ∈ S	and σ ∈ Σ∗ .
f	F	f  m	D	m	M	M
Observation 2: Suppose s ∈ SD is (sf , sm, a.σ). Then Lab(s)= {[a]}.

Observation 3: Suppose s ∈ S
is (s ,s , G). Then Lab(s)= {a|(a ∈ Σ ) ∧(δ
(s, a, s') for some

s' ∈ S )}
f  m	M	D

Observation 4: D is well formed.
Observation 5: D is deterministic.
Based upon the observations, we can prove a set of lemmata useful for the proof of the theorem. Consider the composition of D and M , (D//M ) = < S(D//M), (sd0, sm0), δ(D//M), λ(KD//M ),
Σ(D//M) >. Then the following lemmata state some properties of (D//M ).
Lemma 1:

For any state s = ((s ,s 
, σ), s' ) ∈ S
, s  = s' .

f  m	m	(D//M )  m	m

For the following lemmata let s, s' ∈ S
such that s is ((s ,s , σ),s 
) and s' = ((s' , s' , σ'), s' ).

Lemma 2:
(D//M )
f  m	m
f  m	m

s →τ s' if and only if s
= s' , σ = a.σ' and s  →a s'
for some a ∈ ΣM .

This lemma establishes the fact that in (D//M ), any internal state has an observable successor, which does not need to necessarily be its immediate successor. In other words, every internal state reaches an external state after a number of τ actions.
Corollary 1: Let σ /= G. Then there exists s'' such that:

s →σ
s''
∗
and s(→τ
)((s , s'' , G), s'' ). Note that →σ
is the usual transitive closure over →a
and

m	m	f  m	m
∗
(→τ ) is the reflexive and transitive closure over →τ .
Lemma 3:
s →a s' if and only if s → s' and σ = G.
Lemma 4:
(D//M ) is deterministic.
Now, to prove the main theorem, a relation X over states of F and (D//M ) is defined as follows:
For any s ∈ S  and ((s' ,s , σ),s ) ∈ S	,
f	F	f  m	m	(D//M )
s X ((s' ,s , σ),s ) if and only if s = s' .
f	f  m	m	f	f
Lemma 5:
X is a weak bisimulation over F and (D//M ).
Proof:
To prove that X is a weak bisimulation, the following must be established:
1: sf0X ((sf0, sm0, σ0), sm0).

Given any s
∈ SF and s = ((s , sm, σ), sm) ∈ S
for some sm ∈ SM and σ ∈ Σ∗ , if s X s

f
then
f	(D//M )	M	f

2: If s
→ s'
, then there exists s' = ((s' , s' , σ'), s' ) such that s ⇒ s' and s' X s'.

f α  f
f  m	m
αˆ	f

3: If s → s' = ((s' , s' , σ'), s' ) ∈ S
, there exists s'
such that s
⇒ s'
and s'
X s'.

α	f  m
m	(D//M )
f	f αˆ f	f



Proof:
follows directly from the definition of X .
can be proved as follows:
Assume s → s' or s → s' where λ (s )= P



and λ



(s' )= P . In this case α = E (a single

f	f	f E f
F  f	0
F  f	1

external transition sequence).
For any s = ((sf , sm, σ), sm) ∈ S(D//M), there are two possibilities:
Sol. 1 If σ = G.
Then λ(D//M)(s)= λF (sf )= λM (sm)= P0

By lemma 3, s →a
s'((s' , s' , σ'), s' ) for some action a ∈ Σ
or s → s'

f  m	m
(D//M )
E

Again, there are two possibilities:

If σ' = G.
Then λ

(s')= λF (s' )= λM (s' )= P1

(D//M )	f	m
Therefore, s → s' or s ⇒ s'
αˆ
Also, s' X s' by definition of X .
∗
If σ' /= G. By corollary 1, there exists s''((s' , s'' , G), s'' ) such that s'(→τ )s'' or s' → s''.
f  m	m	τ ∗

Also, (λ
(D//M )
(s')= {intern}) and (λ
(D//M )
(s'')= P ).

So s' → s'' where α' = τ ∗.
α'
Also, s → s'
E
Therefore s → s'' where α'' = E.τ ∗.
α''
In this case αˆ'' = α and therefore s ⇒ s''
αˆ
Also, s' X s'' by definition of X .

Sol. 2 If σ /= G.
∗
By corollary 1, there exists s''((s , s'' , G), s'' ) such that s(→τ )s'' or s → s''. Also, λ


(s) = 

{intern} and λ

(D//M )
f  m	m
(s'')= P0
(D//M )
τ

So s → s'' where α' = τ ∗. (1)
α'
From Sol. 1 above, we can prove that s'' ⇒ s' where s' = ((s' , s' , G), s' ). (2)

αˆ
Combining (1) and (2), we get
s → s'' ⇒ s'
f  m	m

α'	αˆ
As α' = τ ∗ (or one or more internal transitions), we get
s ⇒ s'
αˆ
Also, s' X s' by definition of X .
The same proof can be extended to accommodate α = E∗ (a sequence of more than one external transitions) by applying Sol 1 and 2 recursively.
can be proved as follows: Let s → s' where
α

s = ((s , sm, σ), sm) and s = ((s' , s' , σ'), s' ) ∈ S
and α represents a single transition.

f	f m
m	(D//M )

There are two distinct possibilities:
σ /= G.

Then λ
(D//M )
(s) = {intern} and α = τ . Therefore, s → s' (internal transition forced by the
τ

interface) or
s →τ s'.

Therefore sf τˆ = G
= s'

We know that sf ⇒ sf
c
Also, s X s' by definition of X .
σ = G.

λ(D//M )
/= {intern} and s → s' (externally observable transition) or
E

s →a s' for some a in Σ	.
Using Lemma 3, as s →a s' and σ = G, s → s' .
Also, s' X s' by definition of X .

Theorem 1 establishes that forced simulation is a sufficient condition for forced model checking.
The next theorem shows the existence of forced simulation as a necessary condition for D.

Theorem 2. If there exists a well formed and deterministic interface D such that F ≈ (D//M ), then F ±fsim M .
Proof.
Assume that F ≈ (D//M ). Then, there exists a weak bisimulation relation S over F and
∗
(D//M ). Given S a new relation Y ⊆ SF × SM × Σ	is constructed.
By assumption D is well-formed and deterministic. Also M is deterministic. It is easy to show that then (D//M ) is deterministic. Further, for any state s in (D//M ),
Let Y be the smallest relation such that (sf , sm, σ) is in Y if and only if there exists sd ∈ D
and (sd, sm) ∈ S(D//M) with (sf , (sd, sm)) ∈ S and one of the following holding:
σ = G and λM (sd, sm)= λF (sf ) /= {intern} (no forcing, disabling might be present).

[σ] '
sd → sd is not a forcing symbol where [σ] is the sequence of forcing symbols appearing in σ. (forcing)
It is quite easy to establish that Y as defined is a forced simulation relation.
So far, a new simulation relation between F and M is proposed and Theorem 1 and Theorem 2 together establish that forced simulation is a necessary and sufficient condition for the existence of a correct D which can adapt M to satisfy F .

Theorem 3. Given two extended Kripke structures A < APA, SA, sa0, ΣA, δA, λA > and
B< APB, SB, s , ΣB, δB, λB > such that A ≈ B, then for any CTL∗ formula ϕ: (A |=W ϕ) ⇔ (B |=W ϕ)
where |=W stands for weak satisfaction.
Restriction 1: The proof of this theorem is based on the restriction that an unobservable state may always lead to one or more observable states.
This restriction is an important consideration as for temporal logics like CTL∗, every state must have an observable successor. If an internal state has an infinite path starting from it where no state in this path is observable, the given model will keep undergoing an infinite number of τ transitions and will not interact with its environment any more, entailing that it has terminated.
Before embarking on the proof of theorem 3, the following Lemmas that assist the proof are presented. The following Lemmas work on arbitrary states sa and sb from the state-spaces of the models A and B respectively.
Lemma 6:
If s  ≈ s  then for all s' where s' ∈ Next  (s ), there is a state s' ∈ Next  (s ) such that

'	' a	b	a
ob  a
ob  b

sa ≈ sb.
Proof:
By definition of Nextob
possibilities:

, for any s'

∈ Nextob

(sa), sa

→ s'
α

where there are the following two

sa
is an internal state: α = τi where i ≥ 1 and s'
is an observable state.

In this case, αˆ = G and sa
⇒ s'
c

s
is an observable state: α = G and s' = s . In this case, αˆ = α = G and s ⇒ s'

a	a	a	a		a c

As described above, regardless of whether sa
is an observable state (or otherwise), sa
⇒ s'
c

and that s' is an observable state. By definition of bisimulation (definition 4.5) on page 14, as
a	'	'	'	'

sa ≈ sb, there must be a state sb such that sb ⇒ sb and sa ≈ sb.
c
It is now important to prove that s' is (or leads to) a state in Next

(sb).

Consider such a state s' such that s ⇒ s' and s ≈ s' . There are two distinct possibilities:
b	b c  b	a	b

s' is observable: By definition of Next
, sb
∈ Nextob
(sb).

s' is unobservable: By restriction 1 stated above, s' will always lead to at least one observable

b	''
'	''
b '	''	'

state sb such that sb → sb where j ≥ 1. Therefore, sb ⇒ sb . It is quite clear that as sb ⇒ sb ⇒

s'', s'' ∈ Next
τj	c	c	c
(s ) (by definition of Next  ).

b	b	ob  b	ob
Also, it is known that for the observable state s' , s' ⇒ s' . Again by definition of bisimulation,

s' ≈ s'' and both are observable states.
a c  a

a	b

The same proof can be used to demonstrate that for any s'

∈ Next

(s ), there is a state

'	'	'
ob  b

sa ∈ Nextob(sa) such that sa ≈ sb.
Lemma 7:
If s ≈ s where both s and s


are observable states, then for each s' ∈ Succ


(s ), there is

a	b	a	b	a	ob  a
a state s' ∈ Succ  (s ) such that s' ≈ s' .

b
Proof
ob  b	a	b

Given: both sa and sb are observable states.

Consider a state s' ∈ Succ (s ). By definition of Succ
, s → s'
where α = E.τi and i ≥ 0.

a
In this case, αˆ = E.
ob  a
ob	a		a α

By definition of bisimulation (definition 4.5 on page 14), if sa ≈ s , then if sa → s'
for some

α ∈ Trans∗ then s
b	a
α
⇒ s'' and s' ≈ s' .

b		b	a	b αˆ

Therefore s
⇒ s' for some s' and s' ≈ s' .

b E  b
b	a	b

It is now shown that s' is (or leads to) a state in Succ
(s ). As s
⇒ s'' and s'
≈ s' , there

b
are two possibilities:
s' is observable: By definition of Succ


, s ∈ Succ
ob  b



(s ).
b		b	a	b αˆ

b	ob	b
ob  b

s' is unobservable: By restriction 1 stated above, s' will always lead to atleast one observable

b	''
'	''
b'	''	'

state sb such that sb → sb where j ≥ 1. Therefore, sb ⇒ sb . It is quite clear that as sb ⇒ sb ⇒

s'', s'' ∈ Succ
τj	c	E	c
(s ) (by definition of Succ  ).

b	b	ob  b	ob
Also, it is known that for the observable state s' , s' ⇒ s' . Again by definition of bisimulation,

s' ≈ s'' and both are observable states.
a	a c  a

a	b

The same reasoning can be applied to demonstrate that for every state s' ∈ Succ

(s ), there

'	'	'
b	ob  b

is a state sa ∈ Succob(sa) such that sa ≈ sb.
Lemma 8:
If sa ≈ sb, then for every observable path starting from sa, there is an equivalent observable path starting from sb and vice versa.
Proof
Let that sa ≈ sb. Let πob(sa) = sa1, sa2, sa3, ... be an observable path starting from sa. By definition of observable paths, sa1 ∈ Nextob(sf ), sa2 ∈ Succob(sa1), sa3 ∈ Succob(sa2) and so on.
A corresponding observable path πob(sb) = sb1, sb2, sb3, ... starting from sb is constructed by induction on the structure of πob(sa).
As sa ≈ sb, it is known that for the state sa1 ∈ Nextob(sa), there is a state sb1 ∈ Nextob(sb) such that sa1 ≈ sb1 (by Lemma 6). This state sa1 is chosen as the first observable state of πob(sb).
Similarly, the second state in πob(sb) can be chosen as the state sb2 ∈ Succob(sa1) with sa2 ≈
sb2. Lemma 7 guarantees that there exists such a state sb2.
The path πob(sb) can then be further constructed by choosing states sb(i) ∈ Succob that are bisimilar to sa(i).
Assuming sa(i) ≈ sb(i) for some i ≥ 1. Consider the next state sb(i+1) in πob(sb). It is known

that s
a(i+1)
∈ Succob
(sa(i)
). Using Lemma7, there must be an observable successor s' of s
b(i)
such

that s
≈ s' . This state s' can then be chosen as s
to construct π
(s ).

a(i+1)	b	b
b)(i+1)
ob  b

Given a path πob(sb) starting from sb, the construction of πob(sa) is similar.
Lemma 9:
Let ϕ be either a state formula or a path formula. If sa and sb are bisimilar states and πob(sa) and πob(sb) are their corresponding paths, then:

If ϕ is a state formula then if sa |=W ϕ ⇔ sb |=W ϕ.
If ϕ is a path formula then if pi(sa) |=W ϕ ⇔ pi(sb) |=W ϕ.
Proof
The proof of this lemma is inductive on the structure of ϕ.
Basis:
If ϕ = p for p ∈ APA.
If sa |=W p then Nextob(sa) |= p (by definition 5.5). Now, sb |=W p provided Nextob(sa) |= p.
By lemma 6, Nextobsa ≈ Nextob(sb).
Hence, λA(Nextob(sa)) = λB(Nextob(sb)) (characteristic of weak bisimulation: definition 4.5 on page 14).
Hence, Nextob(sb) |= p. Therefore, s |=W p.
Induction: Consider the following cases:
Case 1. ϕ = ¬ϕ1 , a state formula.
sa |=W ϕ ⇔ sa |/=W ϕ1
⇔ sb |/=W ϕ1 (basis)
⇔ sb |=W ϕ
The same arguments hold if ϕ is a path formula
Case 2. ϕ = ϕ1 ∨ ϕ2 , a state formula.
sa |=W ϕ⇔ sa |=W ϕ1 or sa |=W ϕ2.
⇔ sb |=W ϕ1orsb |=W ϕ2 (induction hypothesis)
⇔ sb |=W ϕ
The same arguments hold if ϕ is a path formula.
Case 3. ϕ = ϕ1 ∧ ϕ2 , a state formula. This case is similar to the previous case and the same arguments can be used if ϕ is a path formula.
Case 4. ϕ = Eϕ1 , a state formula.
sa |=W ϕ.
This implies that Nextob(sa) |= ϕ.
Therefore, there is an observable path πob(sa) starting from sa such that πob(sa) |= ϕ1. By Lemma 8, there is a corresponding path πobsb starting from sb.
By induction hypothesis, πob(sa) |=W ϕ1 if and only if πob(sb) |=W ϕ1. Therefore, sb |=W Eϕ1.
The same arguments can be used to prove that if sb |=W ϕ then sa |=W ϕ.
Case 5. ϕ = Aϕ1 , a state formula. This case is similar to the previous case and the same arguments can be used.
Case 6. ϕ = ϕ1 , where ϕ is a path formula and ϕ1 is a state formula.
Although the ϕ and ϕ1 are of the same lengths, it can be conceived that ϕ = path(ϕ) where path is a special operator that converts a state formula into a path formula.
Therefore, it is simplifying ϕ by dropping this path operator. If sa and sb are the start states
of the paths π (s' ) and π (s' ), where s' = Next (s ) and s' = Next (s ), (s' ≈ s' by Lemma

6) then,
ob  a
ob  b
a	ob  a	b
ob  b	a	b

π (s' ) |=W ϕ ⇔ s' |= ϕ1

ob  a
⇔ s' |= ϕ
a
(induction hypothesis)

b
⇔ πob
1
(s' ) |=	ϕ (

ϕ = Xϕ1, a path formula. Assuming π(sa) |=W ϕ.
Therefore, the observable path πob(sa) |= ϕ.
Therefore, pi (s' ) |= ϕ where s' ∈ Succ (s ).
ob  a	1	a	ob  a
Also, there is a corresponding path πob(sb) for πob(sa) (Lemma 8).

As π
(sa) for π
(s ), correspond, so will the paths π
(s' ) for π
(s' ) where s' ∈ Succ
(s ).

ob	ob  b
ob  a
ob  b
b	ob  b

Therefore π
(s' ) |= ϕ .

ob  b	1
Therefore πob(sb) |= ϕ.
Therefore π(sb) |=W ϕ (definition 5.6).
ϕ = ϕ1 Uϕ2 , a path formula. Assuming π(sa) |=W ϕ1Uϕ2 . Therefore, the observable path πob(sa) |= ϕ. (definition 5.6)
By definition of the until operator, there is a k such that πob(sak) |=W ϕ2 and for all 0 ≤ j < k, πob(saj) |=W f 1.
For the path πob(sa), there is a corresponding path πob(sb).
As, πob(sa) and πob(sb) correspond, so do πob(saj) and πob(sbj). (lemma 8). Therefore by induction hypothesis, πob(sbk) |= ϕ2 and for all 0 ≤ j < k,πob(sbj)|= ϕ1. Therefore πob(sb) |= ϕ
Therefore π(sb) |=W ϕ. (definition 5.6).
ϕ = ϕ1 Rϕ2, a path formula. This case is similar to the previous case and the same arguments can be used.
Proof of Theorem 3
Theorem 3 is the direct consequence of the preceding Lemma. If two Kripke structures A and
'
B are weakly similar, sa0 ≈ sb0 by definition of bisimulation. Therefore by Lemma 9, if π and π
are there corresponding observable paths, then:
If ϕ is a state formula then if sa |=W ϕ ⇔ sb |=W ϕ.
If ϕ is a path formula then if pi |=W ϕ ⇔ pi |=W ϕ.
