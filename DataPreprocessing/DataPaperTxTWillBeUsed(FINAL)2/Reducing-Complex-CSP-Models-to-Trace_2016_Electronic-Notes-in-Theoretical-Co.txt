Available online at www.sciencedirect.com


Electronic Notes in Theoretical Computer Science 325 (2016) 237–252
www.elsevier.com/locate/entcs

Reducing Complex CSP Models to Traces via Priority
David Mestel1 A.W. Roscoe2
Department of Computer Science, University of Oxford

Abstract
Hoare’s Communicating Sequential Processes (CSP) [6] admits a rich universe of semantic models. In this paper we study finite observational models, of which at least six have been identified for CSP, namely traces, failures, revivals, acceptances, refusal testing and finite linear observations [11]. We show how to use the recently-introduced priority operator ([12], ch.20) to transform refinement questions in these models into trace refinement (language inclusion) tests. Furthermore, we are able to generalise this to any (rational) finite observational model. As well as being of theoretical interest, this is of practical significance since the state-of-the-art refinement checking tool FDR3 [4] currently only supports two such models.
Keywords: CSP, denotational semantics, priority


Introduction
A number of different forms of process calculus have been developed for the mod- eling of concurrent programs, including Hoare’s Communicating Sequential Pro- cesses (CSP) [6], Milner’s Calculus of Communicating Systems (CCS) [7], and the π-calculus [8]. Unlike the latter two, CSP’s semantics are traditionally given in behavioural semantic models coarser than bisimulation.
In this paper, we study finite linear-time observational models for CSP; that is, models where all observations considered can be determined in a finite time by an experimenter who can see the visible events a process communicates and the sets of events it can offer in any stable state. While the experimenter can run the process arbitrarily often, he or she can only record the results of individual finite executions. Thus each behaviour recorded can be deduced from a single finite sequence of events together with the sets of events accepted in stable states during and immediately after this trace.

1 Email: david.mestel@cs.ox.ac.uk
2 Email: bill.roscoe@cs.ox.ac.uk

http://dx.doi.org/10.1016/j.entcs.2016.09.041
1571-0661/© 2016 The Author(s). Published by Elsevier B.V.
This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).

At least six such models have been considered for CSP, but the state-of-the art refinement checking tool, FDR3 [4], currently only supports two, namely traces and failures (it also supports the failures-divergences model, which is not finite observational).
We present a construction which produces a context C such that refinement questions in the failures model correspond to trace refinement questions under the application of C. We are able to generalise this to show (Theorem 5.4) thata similar construction is possible not only for the six models which have been studied, but also for any sensible finite observational model (where ‘sensible’ means that the model can be recognised by a finite-memory computer, in a sense which we shall make precise).
We first briefly describe the language of CSP. We next give an informal de- scription of our construction for the failures model. To prove the result in full generality, we first give a formal definition of a finite observational model, and of the notion of rationality. We then describe our general construction. Finally we discuss performance and optimisation issues.
The CSP language
We provide a brief outline of the language, largely taken from [11]; the reader is encouraged to consult [12] for a more comprehensive treatment.
Throughout, Σ is taken to be a finite nonempty set of communications that are visible and can only happen when the observing environment permits via hand- shaken communication. The actions of every process are taken from Σ ∪ {τ }, where τ is the invisible internal action that cannot be prevented by the environment. Note that the usual treatment of CSP permits sequential composition by including another un-preventable event C to represent termination; this adds slight compli- cations to each model and we omit it for simplicity. It could be added back without any significant alteration to the results of this paper.
The constant processes of CSP are
STOP which does nothing—a representation of deadlock.
div which performs (only) an infinite sequence of internal τ actions—a represen- tation of divergence or livelock.
CHAOS which can do anything except diverge. The prefixing operator introduces communication:
a → P communicates the event a before behaving like P .
There are two forms of binary choice between a pair of processes:
P H Q lets the process decide to behave like P or like Q: this is nondeterministic
or internal choice.
P 2 Q offers the environment the choice between the initial Σ-events of P and Q. If the one selected is unambiguous then it continues to behave like the one chosen; if it is an initial event of both then the subsequent behaviour is nondeterministic.

The occurence of τ in one of P and Q does not resolve the choice (unlike CCS
+). This is external choice.
We only have a single parallel operator in our core language since all the usual ones of CSP can be defined in terms of it as discussed in Chapter 2 etc. of [12].
P  Q runs P and Q in parallel, allowing each of them to perform any action in
X
Σ \ X independently, whereas actions in X must be synchronised between the
two.
There are two operators that change the nature of a process’s communications.
P \ X, for X ⊆ Σ, hides X by turning all P ’s X-actions into τ s.
P [[R ] applies the renaming relation R ⊆ Σ × Σ to P : if (a, b) ∈ R and P can perform a, then P [[R]] can perform b. The domain of R must include all visible events used by P . Renaming by the relation {(a, b)} is denoted [a/b]].
There is another operator that allows one process to follow another:
P ΘAQ behaves like P until an event in the set A occurs, at which point P is shut down and Q is started. This is the throw operator.
The final CSP construct is recursion: this can be single or mutual (including mutual recursions over infinite parameter spaces), can be defined by systems of equations or (in the case of single recursion) in line via the notation μ p.P , for a term P that may include the free process identifier p. Recursion can be interpreted operationally as having a τ -action corresponding to a single unwinding. Denation- ally, we regard P as a function on the space of denotations, and interpret μ p.P as the least fixed point of this function.
We also make use of the interleaving operator |||, which allows processes to

perform actions independently and is equivalent to
 , and the process RUN X , which
∅

always offers every element of the set X and is defined by RUN X = 2
RUN X .



Priority
x →
x∈X


The prioritisation operator is discussed in detail in Chapter 20 of [12]. It allows us to specify an ordering on the set of visible events Σ, and prevents lower-priority events from occuring whenever a higher-priority event or τ is available.
The operator described in [12] as implemented in FDR3 [4] is parametrised by three arguments: a process P , a partial order ≤ on the event set Σ, and a subset X ⊆ Σ of events that can occur when a τ is available. We require that all elements of X are maximal with respect to ≤. Writing initials(P ) ⊆ Σ ∪ {τ } for the set of events that P can immediately perform, and extending ≤ to a partial order on Σ∪{τ} by adding y ≤ τ ∀ y ∈ Σ\X, we define the operational semantics of prioritise

as follows:
P −a→ Pj ∧ ∀ b /= a.a ≤ b ⇒ b ∈/ initials(P )
prioritise(P, ≤,X) −a→ prioritise(P j, ≤,X) (a ∈ Σ ∪ {τ}).
Note that prioritise is not compositional over denotational models other than the most precise model FL, so we think of it as an optional addition to CSP rather than an integral part of it; when we refer below to particular types of observation as giving rise to valid models for CSP, we will mean CSP without priority.
Example: the failures model
We first demonstrate our construction using the failures model: we will produce a context C such that for any processes P, Q, we have that Q refines P in the failures model if and only C[Q] refines C[P ] in the traces model.
The traces and failures models
The traces model T is familiar from automata theory, and represents a process by the set of (finite) strings of events it is able to accept. Thus each process is associated (for fixed alphabet Σ) to a subset of Σ∗ the set of finite words over Σ.
The failures model F also records sets X of events that the process is able to stably refuse after a trace s (that is, the process is able after trace s to be in a state where no τ events are possible, and where the set of initial events does not meet X). Thus a process is associated to a subset of Σ∗ × (P(Σ) ∪ {•}), where
represents the absence of a recorded refusal set. 3 Note that recording • does not imply that there is no refusal to observe, simply that we have not observed stability. The observation of the refusal ∅ implies that the process can be stable after the present trace, whereas • does not.
In any model M, we say that Q M-reﬁnes P , and write P ±M Q, if the set associated to Q is a subset of that corresponding to P .
Model shifting for the failures model
The construction is as follows:
Lemma 3.1 For each ﬁnite alphabet Σ there exists a context C (over an expanded alphabet) such that for any processes P and Q we have that P ±F Q if and only if C[P ] ±T C[Q].
Proof. Step 1: We use priority to produce a process (over an expanded alphabet) that can communicate an event xj if and only if the original process P is able to stably refuse x.
This is done by expanding the alphabet Σ to Σ ∪ Σj (where Σj contains a cor- responding primed event for every event in Σ), and prioritising with respect to a

3 This is equivalent to the standard presentation in which a process is represented by a subset of Σ∗ and one of Σ∗ × r(Σ): the trace component is just {s : (s, •) ∈ r}.

partial order which prioritises each x over the corresponding xj. Recall that the definition of the priority operator means that this also causes τ to be promoted over the primed events.
We must also introduce an event stab to signify stability without requiring any refusals to be possible. This is necessary in order to be able to record an empty refusal set. Let the partial order ≤1 be defined by xj <1 x ∀ x ∈ Σ, and let the context C1 be defined by
C1[P ]= prioritise(P ||| RUN Σ∗∪{stab}, ≤1, Σ).
This process has a state ξj for each state ξ of P , where ξj has the same unprimed events (and corresponding transitions) as ξ. Furthermore ξj can communicate xj just when ξ is stable and can refuse X, and stab just when ξ is stable.
Step 2: We now recall that the definition of the failures model only allows a refusal set to be recorded at the end of a trace, and is not interested in (so does not record) what happens after the refusal set.
We gain this effect by using a regulator process to prevent a primed event (or
stab) from being followed by an unprimed event. Let

UNSTABLE =	x → UNSTABLE
x∈Σ
2	x → STABLE
x∈Σ ∪{stab}
STABLE =	x → STABLE,
x∈Σ ∪{stab}


and define C by

C[P ]= C1[P ]


Σ∪Σ∗∪{stab}

UNSTABLE.

A trace of C[P ] consists of: firstly, a trace s of P ; followed by, if P can after s be in a stable state, then for some such state σ0 any string formed from the events that can be refused in σ0, together with stab. The lemma clearly follows.	2

It is clear that any such context must involve an operator that is not compo- sitional over traces, for otherwise we would have P ±T Q implies C[P ] ±T C[Q], which is equivalent to P ±F Q, and this is not true for general P and Q (consider for instance P = a → STOP , Q = (a → STOP ) H STOP ). It follows that only contexts which like ours involve priority can achieve this.

Semantic models
In order to generalise this construction to arbitrary finite observational semantic models, we must give formal definitions not only of particular models but of the very notion of a finite observational model.

Finite observations
We consider only models arising from ﬁnite linear observations. Intuitively, we postulate that we are able to observe the process performing a finite number of visible actions, and that where the process was stable (unable to perform a τ ) immediately before an action, we are able to observe the acceptance set of actions it was willing to perform.
Note that we are unable to finitely observe instability : the most we are able to record from an action in an unstable state is that we did not observe stability. Thus in any context where we can observe stability we can also fail to observe it by simply not looking.
We take models to be defined over finite alphabets Σ, and take an arbitrary ordering on each finite Σ to be alphabetical.
The most precise finite observational model is that considering all finite linear observations, and is denoted FL:
Definition 4.1 The set of ﬁnite linear observations over an alphabet Σ is
FLΣ := {⟨A0, a1, A1,..., An−1, an, An⟩ : n ∈ N, ai ∈ Σ, Ai ⊆ Σ or Ai =•}, where the ai are interpreted as a sequence of communicated events, and the Ai
denote stable acceptance sets, or in the case of • failure to observe stability. Let
the set of such observations corresponding to a process P be denoted FLΣ(P ).
(Sometimes we will drop the Σ and just write FL(P )).
More formally, FL(P ) can be defined inductively; for instance
FL(P 2 Q) := {⟨A ∪ B⟩ˆα, ⟨A ∪ B⟩ˆβ : ⟨A⟩ˆα ∈ FL(P ), ⟨B⟩ˆβ ∈ FL(Q)}
(where X ∪• := • for any set X). See Section 11.1.1 of [12] for further details.
Observe that FL has a natural partial order corresponding to extensions (where αˆ⟨•⟩ˆβ and αˆ⟨A⟩ are both extended by αˆ⟨A⟩ˆβ for any set A and any α and β). Note that for any process P we have that FL(P ) is downwards-closed with respect to this partial order.

Finite observational models
We consider precisely the models which are derivable from the observations of FL, which are well-defined in the sense that they are compositional over CSP syntax (other than priority), and which respect extension of the alphabet Σ.
Definition 4.2 A finite observational pre-model M consists for each (finite) al- phabet Σ of a set of observations, obsΣ(M), together with a relation MΣ ⊆ FLΣ × obsΣ(M). The representation of a process P in MΣ is denoted MΣ(P ), and is given by
MΣ(P ) := MΣ(FLΣ(P )) = {y ∈ obsΣ(M): ∃ x ∈ FLΣ(P ).(x, y) ∈ MΣ}.
For processes P and Q over alphabet Σ, if we have MΣ(Q) ⊆ MΣ(P ) then we say
Q M-reﬁnes P , and write P ±M Q.

(As before we will sometimes drop the Σ).
Note that this definition is less general than if we had defined a pre-model to be any equivalence relation on P (FLΣ). For example, the equivalence relating sets of the same cardinality has no corresponding pre-model. Definition 4.2 agrees with that sketched in [12].
Without loss of generality, MΣ does not identify any elements of obsΣ(M); that is, we have M−1(x)= M−1(y) only if x = y (otherwise quotient by this equivalence
Σ	Σ
relation). Subject to this assumption, MΣ induces a partial order on obsΣ(M):
Definition 4.3 The partial order induced by MΣ on obsΣ(M) is given by: x ≤ y
if and only if for all b ∈ M−1(y) there exists a ∈ M−1(x) with a ≤ b.
Σ	Σ
Observe that for any process P it follows from this definition that M(P ) is downwards-closed with respect to this partial order (since FL(P ) is downwards- closed).
Definition 4.4 A pre-model M is compositional if for all CSP operators , say of arity k, and for all processes P1,..., Pk and Q1,..., Qk such that M(Pi)= M(Qi) for all i, we have
M  M(Pi)i=1...k  = M  M(Qi)i=1...k  .

This means that the operator defined on processes in obs(M) by taking the pushforward of  along M is well-defined: for any sets X1,..., Xk ⊆ obs(M) which correspond to the images of CSP processes, take processes P1,..., Pk such that Xi = M(Pi), and let
(Xi)i=1...k = M	(Pi)i=1...k .
Definition 4.4 says that the result of this does not depend on the choice of the Pi. Note that it is not necessary to require the equivalent of Definition 4.4 for re- cursion in the definition of a model, because of the following lemma which shows that least fixed point recursion is automatically well-defined (and formalises some
arguments given in [12]):
Lemma 4.5 Let M be a compositional pre-model. Let C1, C2 be CSP contexts, such that for any process P we have M(C1[P ]) = M(C2[P ]). Let the least ﬁxed points of C1 and C2 (viewed as functions on P(FL) under the subset order) be P1 and P2 respectively. Then M(P1)= M(P2).
Proof. Using the fact that CSP contexts induce Scott-continuous functions on
P(FL) (see [6], Section 2.8.2), the Kleene fixed point theorem gives that Pi =

∞
n=0
Cn(⊥). Now any x ∈ M(P1) is in the union taken up to some finite N , and

since finite unions correspond to internal choice, and ⊥ to the process div, we have
that the unions up to N of C1 and C2 agree under M by compositionality. Hence
x ∈ M(P2), so M(P1) ⊆ M(P2). Similarly M(P2) ⊆ M(P1).	2
Definition 4.6 A pre-model M is extensional if for all alphabets Σ1 ⊆ Σ2 we have that obsΣ1 (M) ⊆ obsΣ2 (M), and MΣ2 agrees with MΣ1 on FL(Σ1) × obsΣ1 (M).

Definition 4.7 A pre-model is a model if it is compositional and extensional.
In this setting, we now describe the five main finite observational models coarser than 7L: traces, failures, revivals, acceptances and refusal testing.
The traces model
The coarsest model measures only the traces of a process; that is, the sequences of events it is able to accept. This corresponds to the language of the process viewed as a nondeterministic finite automaton (NFA).
Definition 4.8 The traces model, f , is given by
obsΣ(f )= Σ∗, fΣ = traceΣ
where trace is the equivalence relation which relates the observation
⟨A0, a1, A1,..., an, An⟩ to the string a1 ... an.
Failures
The traces model gives us information about what a process is allowed to do, but it in some sense tells us nothing about what it is required to do. In particular, the process STOP trace-refines any other process.
In order to specify liveness properties, we can incorporate some information about the events the process is allowed to refuse, begining with the failures model. Intuitively, this captures traces s, together with the sets of events the process is allowed to stably refuse after s.
Definition 4.9 The failures model, 7 , is given by
obsΣ(7 )= Σ∗ × (P(Σ) ∪ {•}), 7Σ = fail Σ,
where fail Σ relates the observation ⟨A0,..., an, An⟩ to all pairs (a1 ... an,X), for all
X ⊆ Σ \ An if An /= •, and for X = • otherwise.
Revivals
The next coarsest model, first introduced in [11], is the revivals model. Intuitively this captures traces s, together with sets X that can be stably refused after s, and events a (if any) that can then be accepted.
Definition 4.10 The revivals model, Y, is given by
obsΣ(Y)= Σ∗ × (P(Σ) ∪ {•}) × (Σ ∪ {•}), YΣ = rev Σ),
where rev Σ relates the observation ⟨A0, a1,..., an−1, An−1, an, An⟩ to
the triples (a1 ... an−1, X, an), for all X ⊆ Σ \ An−1 if An−1 /= • and for X = •
otherwise, and
the triples (a1 ... an, X, •), for all X ⊆ Σ\An if An /= • and for X = • otherwise.
A finite linear observation is related to all triples consisting of: its initial trace; a stable refusal that could have been observed, or • if the original observation did not observe stability; and optionally (part (i) above) a single further event that can be accepted.

Acceptances
All the models considered up to now refer only to sets of refusals, which in partic- ular are closed under subsets. The next model, acceptances (also known as ‘ready sets’), refines the previous three and also considers the precise sets of events that can be stably accepted at the ends of traces.
Definition 4.11 The acceptances model, A, is given by
obsΣ(A)= Σ∗ × (P(Σ) ∪ {•}), AΣ = accΣ,
where accΣ relates the observation ⟨A0, a1,..., an, An⟩ to the pair (a1 ... an, An).
Refusal testing
The final model we consider is that of refusal testing, first introduced in [9]. This refines 7 and Y by considering an entire history of events and stable refusal sets. It is incomparable to A, because it does not capture precise acceptance sets.
Definition 4.12 The refusal testing model, Yf , is given by
obsΣ(Yf )= {⟨X0, a1, X1,..., an, Xn⟩ : n ∈ N, ai ∈ Σ, Xi ⊆ Σ or Xi =•} Yf Σ = rt Σ,
where rt Σ relates the observation ⟨A0,..., an, An⟩ to ⟨X0,..., an, Xn⟩, for all Xi ⊆
Σ \ Ai if Ai /= •, and for Xi = • otherwise.
Rational models
We will later on wish to consider only models M for which the correspondence between 7L-observations and M observations is decidable by a finite memory com- puter. We will interpret this notion as saying the the relation MΣ corresponds to the language accepted by some finite state automaton. In order to do this, we must first decide how to convert elements of 7LΣ to words in a language. We do this in the obvious way (the reasons for using fresh variables to represent the Ai will become apparent in Section 5).
Definition 4.13 The canonical encoding of 7LΣ is over the alphabet Ξ := Σ ∪ Σjj ∪ Sym, where Σjj := {ajj : a ∈ Σ} and Sym = {⟨, ⟩, ‘,’, •}. 4 It is given by the representation in Definition 4.1, where sets Ai are expressed by listing the elements of Σjj corresponding to the members of Ai in alphabetical order. We denote this encoding by φΣ : 7LΣ → Ξ∗.
We now define a model to be rational (borrowing a term from automata the- ory) if its defining relation can be recognised (when suitably encoded) by some nondeterministic finite automaton.
Definition 4.14 A model M is rational if for every alphabet Σ, there is some finite alphabet Θ and a map ψΣ : obsΣ(M) → Θ∗, such that there is a (nondeterministic)

4 Note that this somewhat unsatisfactory notation denotes a set of four elements: the angle brackets ⟨ and
⟩, the comma , and the symbol •.

finite automaton A recognising {(φΣ(x), ψΣ(y)) : (x, y) ∈ MΣ}, and such that ψΣ is order-reflecting (that is, ψΣ(x) ≤ ψΣ(y) only if x ≤ y), with respect to the prefix partial order on Θ∗, and the partial order induced by MΣ on obsΣ(M).
What does it mean for an automaton to ‘recognise’ a relation?
Definition 4.15 For alphabets Σ and T , a relation Y⊆ Σ∗ × T∗ is recognised by an automaton A just when:
The event-set of A is left.Σ ∪ right.T , and
For any s ∈ Σ∗,t ∈ T∗, we have sYt if and only if there is some interleaving of left.s and right.t accepted by A.
Note that recognisability in the sense of Definition 4.15 is easily shown to be equivalent to the common notion of recognisability by a ﬁnte state transducer given for instance in [16], but the above definition is more convenient for our purposes. Note also that 7L itself (viewing 7LΣ as the diagonal relation) is trivially rational.
Lemma 4.16 The models f , 7, Y, A and Yf are rational.
Proof. By inspection of Definitions 4.8–4.12. We takeΘ= Σ ∪ Σj ∪ Σjj ∪Sym, with Σjj and the expression of acceptance sets as in the canonical encoding of 7L, and refusal sets expressed in the corresponding way over Σj := {aj : a ∈ Σ}.	2
Note that not all relations are rational. For instance, the ‘counting relation’ mapping each finite linear observation to its length is clearly not rational. We do not know whether the additional constraint of being a finite observational model necessarily implies rationality; however, no irrational models are known. We there- fore venture the following conjecture:
Conjecture 4.17 (Rationality of finite observational models) Let M be a ﬁnite observational model. Then M is rational.

Model shifting
We now come to the main substance of this paper: we prove results on ‘model shifting’, showing that there exist contexts allowing us to pass between different semantic models and the basic traces model. The main result is Theorem 5.4, which shows that this is possible for any rational model.

Model shifting for 7L 
We begin by proving the result for the finest model, 7L. We show that there exists a context C7L such that for any process P , the finite linear observations of P correspond to the traces of C7L(P ).
Lemma 5.1 (Model shifting for 7L) For every alphabet Σ, there exists a con- text C7L over alphabet T := Σ ∪ Σj ∪ Σjj ∪ {done}, and an order-reflecting map

π : 7LΣ → T∗ (with respect to the extension partial order on 7LΣ and the pre- ﬁx partial order on T∗) such that for any process P over Σ we have f (C7L[P ]) = pref(π(7L(P ))) (where pref(X) is the preﬁx-closure of the set X).
Proof. We will use the unprimed alphabet Σ to denote communicated events from the original trace, and the double-primed alphabet Σjj to denote stable acceptances. Σj will be used in an intermediate step to denote refusals, and done will be used to distinguish ∅ (representing an empty acceptance set) from • (representing a failure to observe anything).
Step 1: We first produce a process which is able to communicate events xj, just when the original process can stably refuse the corresponding xi. Define the partial order ≤1= ⟨xj <1 x : x ∈ Σ⟩, which prevents refusal events when the corresponding event can occur.
Let the context C1 be given by
C1[X] = prioritise(X ||| RUN Σ∗ , ≤1, Σ).
Note that the third argument prevents primed events from occurring in unstable states.
Step 2: We now similarly introduce acceptance events, which can happen in stable states when the corresponding refusal can’t.
Similarly define the partial order ≤2= ⟨xjj <2 xj : x ∈ Σ⟩, which prevents acceptance events when the corresponding refusal is possible. Let the context C2 be defined by
C2[X] = prioritise(C1[X] ||| RUN Σ∗∗ , ≤2, Σ).
Step 3: We now ensure that an acceptance set inferred from a trace is a complete set accepted by the process under examination. This is most straightforwardly done by employing a regulator process, which can either accept an unprimed event or accept the alphabetically first refusal or acceptance event, followed by a refusal or acceptance for each event in turn. In the latter case it then communicates a done event, and returns to its original state.
The done event is necessary in order to distinguish between a terminal ∅, which can have a done after the last event, and a terminal •, which cannot (observe that a ∅ cannot occur other than at the end). Finally, we hide the refusal events.
Let a and z denote the alphabetically first and last events respectively, and let succ x denote the alphabetical successor of x. Define the processes

UNSTABLE =	x → UNSTABLE
x∈Σ
2 aj → STABLE (a) 2 ajj → STABLE (a)
STABLE (x)= xj → STABLE (succ x) 2 xjj → STABLE (succ x)	(x /= z)
STABLE (z)= done → UNSTABLE,

and let

C7L[X]=  C2[X]


Σ∪Σ∗∪Σ∗∗


UNSTABLE  \ Σj.

Step 4: We now complete the proof by defining the function π inductively as follows:
π(sˆ⟨•⟩)= π(s)
π(sˆ⟨x⟩)= π(s)ˆ⟨x⟩
π(sˆ⟨A = {x1,..., xk}⟩)= π(s)ˆ⟨xjj ... xjjdone⟩,
1	k
where without loss of generality the xi are listed in alphabetical order.
It is clear that this is order-reflecting, and by the construction above satisfies
f (C7L[P ]) = pref(π(7L(P ))).	2
This result allows us to translate questions of 7L-refinement into questions of trace refinement under C7L, as follows:
Corollary 5.2 For C7L as in Lemma 5.1, and for any processes P and Q, we have
P ±FL Q if and only if C7L[P ] ±T C7L[Q].
Proof. Certainly if 7L(Q) ⊆ 7L(P ) then f (C7L[Q]) = pref(π(7L(Q))) ⊆
pref(π(7L(P ))) = f (C7L[P ]) and so C7L[P ] ±T C7L[Q].
Conversely, suppose there exists x ∈ 7L(Q) \ 7L(P ). Then since 7L(P ) is downwards-closed, we have x ¢ y for all y ∈ 7L(P ). Since π is order- reflecting, we have correspondingly π(x) ¢ π(y) for all y ∈ 7L(P ). Hence π(x) ∈/ pref(π(7L(P ))), so pref(π(7L(Q))) ¢ pref(π(7L(P ))).	2

Model shifting for rational observational models
We now have essentially all we need to prove the main theorem. We record a folk result, that any NFA can be implemented as a CSP process (up to prefix-closure, since trace-sets are prefix-closed but regular languages are not):
Lemma 5.3 (Implementation for NFA) Let A = (Σ, Q, δ, q0,F ) be a (non- deterministic) ﬁnite automaton. Then there exists a CSP process PA such that pref(L(A)) = pref(f (PA)).
Proof. Trivial construction. See Chapter 7 of [10].	2
Theorem 5.4 (Model shifting for rational models) For every rational model M, there exists a context Cn such that for any process P we have f (Cn[P ]) = pref(ψ(M(P ))).
Proof. Let A be the automaton recognising (φ × ψ)(M) (as from Definition 4.14), and let PA be the corresponding process from Lemma 5.3.
We first apply Lemma 5.1 to produce a process whose traces correspond to the finite linear observations of the original process, prefixed with left: let C7L be the

context from Lemma 5.1, and let the context C1 be defined by
C1[X]= C7L[X][[left.x/x]].
We now compose in parallel with PA, to produde a process whose traces corre- spond to the M-observations of the original process. Let C2 be defined by

C2[X]=   C1[X]


{|left|}

PA \ {|left|} [[x/right.x]].

Then the traces of C2[X] are precisely the prefixes of the images under ψ of the observations corresponding to X, as required.	2
By the same argument as for Corollary 5.2, we have
Corollary 5.5 For any rational model M, let Cn be as in Theorem 5.4. Then for any processes P and Q, we have P ±M Q if and only if Cn[P ] ±T Cn[Q].

Implementation
We demonstrate the technique by implementing contexts with the property of Corol- lary 5.5; source code may be found at [1].
For the sake of efficiency we work directly rather than using the general construc- tion of Theorem 5.4. The context C1 introduces refusal events and a stab event, which can occur only when the corresponding normal events can be refused. This implements the refusal testing model, and the context CF which allows only nor- mal events optionally followed by some refusals (and stab) implements the failures model.
This is however suboptimal over large alphabets, in the typical situation where most events are refused most of the time. FDR3’s inbuilt failures refinement check- ing is able to compare acceptance sets (checking that the acceptances of the spec- ification are a subset of those of the implementation), which are typically smaller than the refusal sets.
The context C’ introduces acceptance events which can occur only in stable states where the corresponding refusal cannot, and then blocks all refusals. The problem then is: how to check that the acceptances of the speciﬁcation are a subset of those of the implementation, despite the fact that trace refinement checks for inclusion the other way?
The answer is to use priority to prevent the stab event from happening while acceptances are still available, so that CFImpl’ is able to communicate only its precise acceptance sets. We then form CFSpec’ by parallel composition with RUN for all the acceptance events, so that CFSpec’ can communicate any supersets of its acceptance set.
Similar constructions with slightly different restrictions on the permissible se- quences of events produce efficient processes for the revivals and refusal testing models. For the acceptances model, we just want to check for inclusion of the im- plementation’s acceptance sets in those of the specification, so the context CFImpl’

works for both the specification and the implementation; finite linear observations works similarly with failures replaced by refusal testing.
Testing
We test this implementation by constructing processes which are first distinguished by the failures, revivals, refusal testing and acceptance models respectively (the latter two being also distinguished by the finite linear observations model). The processes, and the models which do and do not distinguish them, are shown in Table 1 (recall the precision hierarchy of models: f ≤ 7 ≤ Y ≤ {A, Yf } ≤ 7L). The correct results are obtained when these checks are run in FDR3 with the implementation described above.

Table 1
Tests distinguishing levels of the model precision heirachy. Δ is the interrupt operator; see [12] for details.


Performance
We assess the performance of our simulation by running those examples from Table 1 of [5] which involve refinement checks (as opposed to deadlock- or divergence- freedom assertions), and comparing the timings for our construction against the time taken by FDR3’s inbuilt failures refinement check (since 7 is the only model for which we have a point of comparison between a direct implementation and the methods developed in this paper). Results are shown in Table 2, for both the original and revised contexts described above; the perfomance of the 7L check is also shown. As may be seen, performance is somewhat worse but not catastrophically so. Note however that these processes involve rather small alphabets; performance is expected to be worse for larger alphabets.

Table 2
Experimental results comparing the performance of our construction with FDR3’s inbuilt failures refinement check. |S| is the number of states, |Δ| is the number of transitions, T is the time (in seconds), and M indicates millions.


Example: Conflict detection
We illustrate the usefulness of richer semantic models than just traces and failures by giving a sample application of the revivals model. Suppose that we have a process P consisting of the parallel composition of two sub-processes Q and R. The failures

model is able to detect when P can refuse all the events of their shared alphabet, or deadlock in the case when they are synchronised on the whole alphabet. However, it is unable to distinguish between the two possible causes of this: it may be that one of the composands is able to refuse the entire shared alphabet, or it may be that each accepts some events from the shared alphabet, but the acceptances of Q and R are disjoint. We refer to the latter situation as a ‘conflict’. The absence of conflict (and similar situations) is at the core of a number of useful ways of proving deadlock-freedom for networks of processes running in parallel [14].
The revivals model can be used to detect conflicts. For a process P = Q X  Y R, we introduce a fresh event a to represent a generic event from the shared alphabet, and form the process P j = Qj X∗  Y ∗ Rj, where Qj = Q[[{(x, x), (x, a) : x ∈ X}]], Xj = X∪{a}, and similarly for Rj and Y j. Conflicts of P now correspond to revivals (s, X ∩ Y, a), where s is a trace not containing a.

Conclusions
The result of Theorem 5.4 shows that the expressibility of all finite observational (rational) models can in some sense be simulated by the traces model using the pri- ority operator. This provides a practical method of testing refinement over models that FDR does not directly support. While any such model could be implemented directly in the program itself, we have shown this is not necessary. This also serves to further demonstrate the power and usefulness of the priority operator (see also the previous work of the second-named author on the expressiveness of CSP with priority [13] and on ‘slow abstraction’ [15]).
Note that this type of construction can be used more generally. Firstly, it seems likely that the construction can be extended to non-finite models; for instance to reduce failures-divergences tests to traces-divergences, or infinite-traces-failures- divergences to infinite-traces-divergences.
Secondly, the construction does not use the requirement that a model be com- positional. This means that it will work for any rational set of observable be- haviours, such as the singleton failures semantics presented in [3]. The techniques described here can also be used to support the Timed Failures model of Timed CSP in FDR3 [2].
The limitation to rational models is from a theoretical point of view rather unsatisfactory, although it may be of little practical significance since all known models (and probably all models one would be likely to come up with) are clearly rational. However, Conjecture 4.17 remains of interest since a resolution in either direction would undoubtedly yield insight into the structure of the ‘clouds’ of models lying above Y set out in [11].

Acknowledgement
The authors are grateful to Tom Gibson-Robinson for helpful discussions and prac- tical assistance with FDR3. This work has been partially sponsored by DARPA

under agreement number FA8750-12-2-0247.

References
www.cs.ox.ac.uk/people/david.mestel/model-shifting.csp.
Philip Armstrong, Gavin Lowe, Jo¨el Ouaknine, and A.W. Roscoe. Model checking timed CSP. In Andrei Voronkov and Margarita Korovina, editors, HOWARD-60. A Festschrift on the Occasion of Howard Barringer’s 60th Birthday, pages 13–33. EasyChair, 2014.
Christie Bolton and Jim Davies. A singleton failures semantics for communicating sequential processes.
Formal Aspects of Computing, 18(2):181–210, 2006.
Thomas Gibson-Robinson, Philip Armstrong, Alexandre Boulgakov, and A.W. Roscoe. FDR3—a modern refinement checker for CSP. In Tools and Algorithms for the Construction and Analysis of Systems, pages 187–201. Springer, 2014.
Thomas Gibson-Robinson, Henri Hansen, A.W. Roscoe, and Xu Wang. Practical partial order reduction for CSP. In NASA Formal Methods, pages 188–203. Springer, 2015.
C.A.R. Hoare. Communicating Sequential Processes. Prentice-Hall, Inc., Upper Saddle River, NJ, USA, 1985.
R. Milner. A Calculus of Communicating Systems. Springer-Verlag New York, Inc., Secaucus, NJ, USA, 1982.
Robin Milner, Joachim Parrow, and David Walker. A calculus of mobile processes, i. Information and Computation, 100(1):1–40, 1992.
Iain Phillips. Refusal testing. Theoretical Computer Science, 50(3):241–284, 1987.
A. W. Roscoe. The Theory and Practice of Concurrency. Prentice Hall PTR, Upper Saddle River, NJ, USA, 1997.
A.W. Roscoe. Revivals, stuckness and the hierarchy of CSP models. The Journal of Logic and Algebraic Programming, 78(3):163–190, 2009.
A.W. Roscoe. Understanding Concurrent Systems. Texts in Computer Science. Springer, 2010.
A.W. Roscoe. The expressiveness of CSP with priority. In Proceedings of MFPS 2015, 2015.
A.W. Roscoe and Naiem Dathi. The pursuit of deadlock freedom. Information and Computation, 75(3):289 – 327, 1987.
A.W. Roscoe and Philippa J. Hopcroft. Slow abstraction via priority. In Zhiming Liu, Jim Woodcock, and Huibiao Zhu, editors, Theories of Programming and Formal Methods, pages 326–345. Springer- Verlag, Berlin, Heidelberg, 2013.
J. Shallit. A Second Course in Formal Languages and Automata Theory. Cambridge University Press, 2009.
