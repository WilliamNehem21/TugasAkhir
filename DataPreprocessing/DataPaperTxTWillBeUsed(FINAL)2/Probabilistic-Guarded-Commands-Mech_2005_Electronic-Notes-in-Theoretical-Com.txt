Electronic Notes in Theoretical Computer Science 112 (2005) 95–111 
www.elsevier.com/locate/entcs


Probabilistic Guarded Commands Mechanized in HOL
Joe Hurd
Computing Laboratory Oxford University
Annabelle McIver
Department of Computing Macquarie University
Carroll Morgan
School of Computer Science University of New South Wales

Abstract
The probabilistic guarded-command language pGCL [15] contains both demonic and probabilistic nondeterminism, which makes it suitable for reasoning about distributed random algorithms [14]. Proofs are based on weakest precondition semantics, using an underlying logic of real- (rather than Boolean-) valued functions.
We present a mechanization of the quantitative logic for pGCL [16] using the HOL theorem prover [4], including a proof that all pGCL commands satisfy the new condition sublinearity, the quantitative generalization of conjunctivity for standard GCL [1].
The mechanized theory also supports the creation of an automatic proof tool which takes as input an annotated pGCL program and its partial correctness specification, and derives from that a sufficient set of verification conditions. This is employed to verify the partial correctness of the probabilistic voting stage in Rabin’s mutual-exclusion algorithm [10].
Keywords: pGCL, formal verification, probabilistic programs

Introduction
The probabilistic guarded command language pGCL extends Dijkstra’s orig- inal guarded-command language GCL [1] to include probabilistic choice. The


1571-0661 © 2004 Elsevier B.V. O pen access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2004.01.021


extension allows the specification of quantitative properties of programs, such as “the chance that the program delivers the correct output is at least 0.95.” Demonic nondeterminism, identified by Dijkstra as the key notion underly- ing abstraction and reﬁnement, is retained. Within pGCL the combination of probability and nondeterminism allows the realistic treatment of imprecise behaviour, avoiding the problem that exact probabilities cannot be imple- mented. For instance a program that behaves correctly (indicated by an ok result) with probability at least 0.95 can be described in pGCL as
ok 0.95⊕ (чok H ok) .
Here 0.95⊕ repsesents a probabilistic choice of (0.95, 0.05) between its left,right arguments respectively; the H on the other hand represents demonic choice, thought of as a selection made arbitrarily. This combination of probabilistic and demonic choices means that programs can exhibit a range of behaviours, rather than exactly one: above, the “demon” can affect the outcome only 5% of the time, and then might behave correctly in any case. The most that can be said is that the probability that the output will be ok lies in the interval between 95% and 100%. 1
We describe the quantitative properties of probabilistic programs using pGCL’s quantitative program logic [16]. Programs are interpreted as real - rather than Boolean-valued functions of the state, and it is this generality which admits sound judgements concerning probabilistic and demonic choices, as above.

In this paper we present the following significant novelties:
a mechanization of pGCL programs (with weakest-precondition semantics) in higher-order logic, using the HOL4 theorem prover;
an automatic proof tool that takes as input annotated pGCL programs, and calculates verification conditions sufficient for their partial correctness; and
the application of this proof tool to the formal verification of the probabilis- tic voting scheme in Rabin’s mutual-exclusion algorithm [10].
A mechanized theory is one with a machine-readable logical formalization; and there are two main benefits to having a mechanized theory for pGCL. The first is the existence of a logical formalization at all: if the theory is formalized in a consistent logic by making definitions and then deriving consequences of them (instead of simply asserting axioms), then the theory has a strong assurance of consistency. The HOL4 theorem prover provides tool support

1 Another approach to the semantics of probabilistic programs [8] leaves out demonic non- determinism and instead takes these probability intervals as primitive.


for this “definitional approach,” and as a result our pGCL theories are as consistent as the base higher-order logic.
The second benefit of mechanization is machine-readabilty: we can use the mechanized pGCL theories to support the creation of automatic proof tools that use weakest-precondition semantics for reasoning. For example, verifying pGCL programs typically involves much numerical calculation, and this can be formally carried out by rewriting with relevant theorems about real numbers. Since HOL4 is a theorem prover in the LCF family, it provides a full programming language (ML) for the user to write such tools [2]. Consistency is enforced by the logical kernel, a small module that is solely empowered to create objects of type theorem, which it does by applying the inference rules of higher-order logic.
We created many small tools to speed up mechanization and program ver- ification, including the rewriting described above for real numbers. We also implemented a tool which takes as input an annotated program C, precon- dition P and postcondition Q, and generates verification conditions that are sufficient for partial correctness (the Hoare triple {P }C{Q}). It proves as many of these verification conditions as it can, simplifies the remainder and then returns them to the user as subgoals to be proved interactively.

In Sec. 2 we present the formalization of pGCL in higher-order logic, il- lustrated with a simple worked example: the Monty Hall game. In Sec. 3 we describe the proof tool for generating verification conditions; and in Sec. 4 we apply the theory and tools to the verification of the probabilistic voting scheme in Rabin’s mutual-exclusion algorithm.
Higher-order logic types include the Booleans B, reals R, and integers Z. The notation t : τ means that the term t has type τ . Applying the function f to an argument x is expressed by juxtaposition f x, and multiplication uses an explicit operator × instead of juxtaposition. We use the notation x ≡ t to mean x is defined to be t. Finally, we use the variable e to range over real-valued expressions denoting random variables over the state, t to range over transformers, s to range over states and c to range over commands.

Formalized pGCL
Fix a (possibly infinite) state space α and let α be the probability subdistri- butions over α, that is functions f : α → [0, 1] such that	x∈α f x ≤ 1 .
We can then view a probabilistic command c as a relation α × α → B
between initial states and probability subdistributions over final states. This is a relational (or operational) semantics: a program evolves from a definite


initial state yet produces not a definite final state, but rather a probability distribution over final states that reflects the probabilistic branching in its execution. Demonic branching is indicated by relating the initial state to more than one final distribution. The following example shows both why we need relations instead of functions, and probability sub-distributions.
Example 2.1 Consider the following probabilistic program
Ex1  ≡   (n:= n+1 H n:= n+2) 1/2⊕ Abort ,
where H denotes demonic choice, 1/2⊕ denotes symmetric probabilistic choice and Abort means “go into an infinite loop” (see Section 2.2 for precise defini- tions). The state space of Ex1 is Z (the possible values of the program variable n); and applying the above semantics to Ex1 gives a relation that relates initial state n = 0 to these two subdistributions over final states:
(··· , −1 '→0.0, 0 '→0.0, 1 '→0.5, 2 '→0.0, 3 '→0.0, 4 '→0.0, ·· ·)
(··· , −1 '→0.0, 0 '→0.0, 1 '→0.0, 2 '→0.5, 3 '→0.0, 4 '→0.0, ·· ·)	 
The logic for pGCL has this relational semantics as a model: it is a quanti- tative weakest-precondition formulation originally due to Kozen [9], but with demonic choice added [16]. A program’s final distributions are described by giving their expected values with respect to arbitrary random variables which we think of as “reward functions” that quantify the benefit of successful ter- mination. The effect of this approach is to simplify the resulting proof system, without conceding expressivity [14].
Given a probabilistic command c, fix a reward function Q: α → R+ from final states to non-negative real numbers. Given an initial state x we can compute the average reward from executing c repeatedly by taking the expected value of random variable Q with respect to c’s output distribution. If c is also demonic, we average over all distributions separately and take the least result (because adversaries act to minimize expected rewards). Lastly, if c does not terminate the convention is to reward with zero.
Using this procedure we can calculate the expected reward for each initial state x, and thus end up with a reward function P : α → R+ from initial states to non-negative real numbers: the weakest precondition of Q.
Example 2.2 Consider again the probabilistic program Ex1, and suppose the reward function Q on final states is defined as
Qn   ≡   “2 if n is odd, and 3 if n is even. ”
What is the expected reward function P on an initial state x? Half the time the program will loop and the reward will be zero. The remaining half of the time the least expected value over the demon’s choice will be due to whichever


assignment delivers an odd result, because the reward is only 2 for this, as opposed to 3 for the even outcome. Thus the expected reward is
P x   ≡   1/2 × 0+ 1/2 × 2 ,
that is one, for every initial state x.	 
Expected-reward functions such as P and reward functions such as Q are simply called expectations. In pGCL we view a probabilistic command c as an expectation transformer, mapping expectations on final states to expectations on the initial states. It is an elementary fact of probability theory that if the post-expectation is derived from a predicate — a characteristic function that rewards one for states satisfying the predicate and zero otherwise — then the pre-expectation gives the greatest guaranteed probability that the program terminates in a state satisfying the predicate.
We spend the remainder of this section presenting a formalization of this weakest precondition-style semantics of probabilistic programs.
Formalizing expectation transformers
In pGCL, expectations are functions from a state space α to the extended positive real numbers R+ ≡ [0, +∞]. The real numbers have previously been mechanized in several different theorem provers (for an example in Ergo see [18]), so we have a solid basis on which to construct extended positive real numbers. Accordingly, we first created a new higher-order logic type posreal to capture this domain, and lifted the usual arithmetic operations to it. Naturally we had to make some choices about how the lifted arithmetic operations should behave on ∞, and the following identities summarize our decisions:
Both addition and multiplication are defined to be commutative, so the above rules tell us that ∀x. x × 0 = 0, for example. Also, division is defined in terms of multiplication and reciprocal, so from the above we can infer that
∞/∞ = 0. In fact, the only operation not covered by the above rules is
∞− ∞, which we deliberately leave unspecified. 2
To support our later development we define min and max operations on posreal, and a useful shorthand to enforce one-boundedness: [x]≤1 ≡ min x 1. We also prove a collection of theorems that can be used as rewrites to perform numerical calculations on elements of posreal, reducing the burden on
the user in interactive proof.
2 In higher-order logic every function must be total, so ∞− ∞ must be some element x of
posreal, but there is no theorem that gives any information about x.


Example 2.3 The posreal calculations
▶ (1/3 − 1/5) × 6= 4/5
and	▶ ∞ − 53 = ∞
can be automatically carried out by the HOL4 simplifier.	 
Now we have defined the type of positive real numbers, we focus our at- tention on the type
(α)expect	≡	α → posreal ,
of expectations on the state space α. Note that α is a type variable, able to be instantiated to any higher-order logic type, and therefore the theorems that we prove about expectations do not assume any properties of the state space. 3
We define several operations on expectations, which are just pointwise liftings of the corresponding operations on positive reals:

Zero ≡ λs. 0
Infty ≡ λs. ∞
e1 ± e2 ≡ ∀s. e1 s ≤ e2 s
Min e1 e2  ≡ λs. min (e1 s) (e2 s)
Max e1 e2  ≡ λs. max (e1 s) (e2 s)
Cond b e1 e2  ≡ λs. if b s then e1 s else e2 s

Lin p e1 e2 ≡ λs. let x ← [p s]≤1 in x × e1 s + (1 − x) × e2 s .
The type (α)expect forms a complete lattice, with Min and Max being the meet and join operators, and Zero and Infty being the bottom and top elements. Whereas the Zero expectation assigns every state a value of zero, the Infty expectation assigns every state a value of ∞.
Finally, the Lin operation constructs the linear interpolation between two expectations, and Cond switches between two expectations according to a predicate on the state space.
In pGCL, the semantics of a probabilistic program is an expectation trans- former mapping postconditions on final states to weakest preconditions on initial states. Expectation transformers thus have higher-order logic type
(α)transformer ≡ (α)expect → (α)expect .
To reason about expectation transformers, we borrow a few standard con- cepts from lattice theory, in particular the existence of least and greatest fixed points of monotonic transformers, which we refer to respectively as expect lfp t and expect gfp t.
Formalizing the weakest-precondition semantics
Next we define the pGCL semantics of a simple programming language. For concreteness, we begin by defining a state space state ≡ string → Z repre-

3 In particular, the state space might be infinite.


senting a map from variable names to integer values. The following definition creates a new state from an old state by making a variable assignment of f s to v:
assign v f s	≡	λw. if w = v then f s else s w 
Next, we define a new higher-order datatype for pGCL commands:
command	≡ Abort
|  Skip
| Assign of string × (state → Z)
| Seq of command × command
| Demon of command × command
| Prob of (state → posreal) × command × command
| While of (state → B) × command .
The Abort command represents non-termination of the program; in a technical sense it is “the worst possible program.” The Demon command uses demonic choice to decide which of the two argument commands to execute, and the Prob command uses probabilistic choice. Since the probability argument of Prob is a function state → posreal, the choice probability is explicitly allowed to depend on the state.
When writing commands, we enhance the readability with the following syntactic sugar:

Abort	if none of the bi holds (on the current state)
Hi∈I ci	where I ≡ {i | 1 ≤ i ≤ n ∧ bi holds} .
In addition, we routinely suppress mention of the state in expressions and conditions, writing for example v:= n +1 instead of v:= λs. s n + 1.
We now define the weakest precondition semantic operator wp, which is a higher-order logic function of type command → (state)transformer and maps commands to their semantic meaning as expectation transformers:
▶	(wp Abort = λe. Zero)
∧ (wp Skip = λe. e)
∧ (wp (Assign v f)= λe, s. e (assign v f s)
∧ (wp (Seq c1 c2 )= λe. wp c1 (wp c2 e))
∧ (wp (Demon c1 c2 )= λe. Min (wp c1 e) (wp c2 e))
∧ (wp (Prob p c1 c2)= λe. Lin p (wp c1 e) (wp c2 e))


∧ (wp (While b c)= λe. expect lfp (λe'. Cond b (wp c e') e)) .
Example 2.4 In this example the desired final state is one in which the variables i and j have the same value, and so we use the postcondition
post  ≡  if i = j then 1 else 0 .
First consider the program
pd  ≡   i:= ⟨0, 1⟩ ; j:= {0, 1} .
The intuitive reading of pd is that the variable i is first set to either 0 or 1 by tossing a fair coin, and then the demon sets variable j to either 0 or 1. With this interpretation, it is no surprise that we can never beat the demon, and indeed we can prove that in the weakest precondition every initial state is mapped to zero:
▶ wp pd post = Zero .
Next consider the program
dp  ≡   j:= {0, 1} ; i:= ⟨0, 1⟩ ,
which does the assignments the other way around. First the demon must set variable j, and then variable i is set using the fair coin. In this case we can prove
▶ wp dp post = λs. 1/2 ,
which corresponds to our intuition that the demon does not know the outcome of the fair coin before it is tossed, and therefore can be beaten half the time on average.

Healthiness conditions
For standard GCL, Dijkstra introduced several “healthiness conditions” that characterise exactly the predicate transformers that correspond formally to an equivalent operational (relational) semantics of programs [1]; the conditions are used to derive sound proof rules for verification. Likewise there is a cor- respondence between the expectation-transformer semantics of probabilistic programs and the operational interpretation of probabilistic programs — in fact an expectation transformer is healthy if it is feasible, up continuous and sublinear [16], where up continuous is a property of lattice theory and



Feasibility is an intuitive property, corresponding to Dijkstra’s Law of the Excluded Miracle: if the value of all final states is zero, then so must be the value of all the initial states. Sublinearity in pGCL is the generalization of the conjunctivity healthiness condition in standard GCL, and is in fact equivalent to the single formula
sublinear t ≡
∀ e1, e2, x1, x2, x.
(λs. x1 × t e1 s + x2 × t e2 s − x) ± t (λs. x1 × e1 s + x2 × e2 s − x) Our present formalization does not include the proofs that connect ex-
pectation transformers with the relational semantics (which was first demon-
strated by Morgan et. al. [16]). Instead we simply define a predicate
healthy t	≡	feasible t ∧ up continuous t ∧ sublinear t
and restrict our attention to healthy transformers. The properties monotonic, scaling, linear, subtractive are all logical consequences of healthy, as we check in the theorem prover.
The main theorem of our formalization looks deceptively simple:
▶ ∀c. healthy (wp c) .
It states that applying the weakest precondition semantic operator wp to any command yields a healthy transformer.
Our direct proof is a structural induction on the command, and required 800 lines of HOL4 proof script for the main proof. (Dijkstra similarly used structural induction for the corresponding GCL proof.) The hardest part was proving sublinearity of while loops; for that we needed several lemmas, such as the monotonicity of expect lfp and that subtraction subdistributes through healthy transformers.
However the importance of healthiness conditions cannot be overstated: for instance, properties like these are what we use to deduce the simplifying rules for the verification calculator described below.

The Monty Hall game
An example is provided by the infamous Monty Hall game, where the role of the demon is played by the game show host. 4 There are three curtains and the contestant hopes to win a prize by guessing the curtain where it is hidden. The game begins with the demon choosing a prize curtain pc behind which to

4 Monty Hall was host of the game show Let’s Make a Deal from 1963 to 1976; ironically this game show was notable for requiring absolutely no skill or intelligence from its contestants.


hide the prize. Next the contestant chooses a curtain cc uniformly at random. The demon then chooses an alternative curtain ac that is not equal to either of pc and cc, and opens it. At this point the contestant may either stick with his original choice of curtain, or switch to the remaining closed curtain. Should the contestant switch?
We code up the Monty Hall contestant with the following definition:
contestant switch ≡
pc:= {1, 2, 3} ;
cc:= ⟨1, 2, 3⟩ ;
pc /=1 Λ cc /=1 → ac:= 1
| pc /=2 Λ cc /=2 → ac:= 2
| pc /=3 Λ cc /=3 → ac:= 3 ;
if чswitch then Skip else
cc:= (if cc /=1 Λ ac /=1 then 1 else if cc /=2 Λ ac /=2 then 2 else 3)
The left hand side of the definition includes switch as a parameter of the contestant; this is used in the program on the right hand side to determine whether to switch curtain in the last step. The postcondition is the desired goal of the contestant, i.e.,
win	≡	if cc = pc then 1 else 0 .
This example is small enough that we can verify it directly in HOL4 simply by rewriting away all the syntactic sugar, expanding the definition of wp and carrying out the numerical calculations. This has the effect of pushing the postcondition back to the start of the program, something that is not trivial to do by hand because the formulae become quite large. After 22 seconds and 250,536 primitive inferences in the logical kernel, the verification succeeds with the following theorem:
▶ wp (contestant switch) win = λs. if switch then 2/3 else 1/3 .
In other words, by switching the contestant is twice as likely to win the prize.

A verification-condition generator
In general, programs are shown to have desirable properties by proving lower bounds — for example a program Prog can be shown to behave correctly with probability at least 0.95 by proving the inequality
▶ (λs. 0.95)	±	wp Prog (if ok then 1 else 0) ,
where the post-expectation encodes the characteristic function of the set of states in which some Boolean ok holds. Of course if a stronger guarantee is required (a 0.99 level of confidence for example) then a stronger theorem would be required to establish it. In this section we show how to mechanize


the proof of such lower bounds; in fact we concentrate on a generalisation of the weakest liberal precondition semantics, a useful weakening of weakest precondition semantics. 5

Weakest-liberal-precondition semantics
The weakest liberal precondition operator wlp is the partial correctness ana- logue of wp. Focussing on wlp and partial correctness greatly simplifies formal verification of looping programs, since the wp least fixed-point semantics are “the wrong way around” for proving lower bounds on preconditions.
In fact, the usual technique for proving total correctness for loops in pGCL is first to prove partial correctness, and then to show that wp and wlp agree on the while loop — this amounts to proving that the loop terminates with probability 1. This is the pGCL analogue of the well-known rule
total correctness  =  partial correctness + proof of termination ,
and has been proved elsewhere for pGCL [13]. Moreover simple techniques based on program variants have also been derived. However, for the remainder of this paper we will be solely interested in partial correctness, and so questions of termination will not concern us.
For partial correctness, if a program does not terminate then it satisfies every postcondition. Since the only places where a program may diverge are the Abort and While commands, the weakest-liberal-precondition semantic operator wlp differs from wp only on those two commands: they have semantics respectively
wlp Abort	≡	λe. Infty
and  wlp (While b c)  ≡  λe. expect gfp (λe'. Cond b (wlp c e') e) .
The full HOL formalisation is based on the partial correctness theory for
pGCL [13].

wlp veriﬁcation conditions
In this section we assume that we have a pGCL command c and a postcondition q, and we wish to derive a lower bound on the weakest liberal precondition. If we think of this as the first-order query P ± wlp c q, then we can use the following theorems together with a Prolog interpreter to solve for the variable

5 In fact for terminating programs there is no weakening.


The advantage of propagating conditions backward (implemented here with a Prolog interpreter) is that unnecessary annotations can be avoided. For example, consider the sequence wlp (Seq c1 c2) q. There is no need for an annotation between the two commands, because the Prolog interpreter uses the rules to solve for a lower bound r on wlp c2 q, then solves for a lower bound p on wlp c1 r, and then returns p as a lower bound on the whole command wlp (Seq c1 c2) q.
However, annotations are required to deploy the following theorem about while loops:
▶ ∀ P, Q, b, c. P ± Cond b (wlp c P ) Q ⇒ P ± wlp (While b c) Q . 
To insert annotations, we define an assertion command that simply ignores the formula given as its first argument: thus Assert p c ≡ c . This is the precise rule we give to the Prolog interpreter:
▶ R ± wlp c P ∧ P ± Cond b R Q ⇒ P ± wlp (Assert P (While b c)) Q
It is therefore left to the user to provide a useful loop invariant P in the Assert around the while loop. Note that the Prolog tactic will succeed on the first subgoal, deriving a lower bound for the body of the while loop, but the second subgoal will fail because there are no applicable rules. In our tactic failed subgoals do not initiate backtracking, but are instead turned into verification conditions. Therefore in this way each while loop in the program will generate one verification condition, in this case that the supplied P is in fact a correct invariant for establishing Q. Nested while loops work in exactly the same way: the invariant for the outer loop will be propagated backwards through the body, and when it meets the inner while loop a verification condition will be generated.
The full wlp tactic works as follows:
Take as input a goal of the form p ± wlp c q.
Expand any syntactic sugar in c.
Create the query X ± wlp c q and pass to the Prolog interpreter.

The result will be a theorem
▶	  Vi	⇒	r ± wlp c q ,
1≤i≤n
where the Vi are verification conditions.
Apply transitivity of ± to reduce the initial goal to the subgoals p ± r
and r ± wlp c q.
Use the theorem returned by Prolog to reduce the subgoal r ± wlp c q to the subgoals V1,... , Vn.
Expand all the subgoals with the definitions of ±, Min, Lin and Cond.
Try to prove all the subgoals by simplifying them and carrying out any numerical calculations.
Return all unproved subgoals to the user, to prove interactively.
Returning to the example of the Monty Hall game, we can apply the wlp tactic to prove the following partial correctness theorem completely automat- ically:
▶ (λs. if switch then 2/3 else 1/3) ± wlp (contestant switch) win .
Since there are no while loops in the contestant program, there were no veri- fication conditions, and the only non-trivial subgoal was the p ± r generated in Step v of the tactic. However, this was proved automatically by the simpli- fication and calculation in Step viii, and so no subgoals were returned to the user.
This automatic verification of the Monty Hall game is obviously much less effort than the interactive proof version described in Section 2.4 which took 18 lines of HOL4 proof script, but the automatic version of the theorem is weaker: it only shows partial correctness.

Example: Rabin’s mutual-exclusion algorithm
Suppose N processors are concurrently executing, and from time to time some of them need to access a critical section of code. Rabin’s mutual-exclusion al- gorithm uses a probabilistic voting scheme to elect a unique “leader processor” that is permitted to enter the critical section [10].
The idea behind the voting scheme is beautifully simple: each processor tosses a fair coin until the first head is shown, 6 and the processor that required the largest number of tosses wins the election.

6 In other words, each processor picks an integer from a Geometric( 1 ) distribution.


In our verification, we do not model i processors concurrently executing the above voting scheme, but rather the equivalent formulation of that system used by Rabin [op. cit.]:
Initialize i with the number of processors competing for exclusive access to the critical section.
If i = 1 then we have a unique winner: return Success.
If i = 0 then the election has failed: return Failure.
Toss the coins: since each toss of a fair coin produces a head with prob- ability 1 , each processor retires with that probability. We reduce i by eliminating all these processors, since certainly none of them won the election.
Return to Step (ii).
The following pGCL program implements this algorithm:
rabin ≡ While (1 < i)( 
n:= i ;
While (0 < n)
(d:= ⟨0, 1⟩ ; i:= i − d ; n:= n − 1)
)
The desired postcondition, that there was a unique winner, is
post	≡	if i =1 then 1 else 0 .
A surprising fact about this voting scheme is that the probability of its success is independent of the number of processors. To prove that, we need to be able to show
(1)	pre	±	wlp rabin post ,
where pre ≡ (if i = 1 then 1 else if 1 < i then 2/3 else 0), in which the 2/3 does not depend on i.
Recall the interpretation of a pre-condition with respect to a given post- condition. The expression on the right at (1), evaluated at an initial state s, gives the probability that the postcondition will be established (namely that there is a unique winner). This must be at least the expression on the left, which is at least 2/3 for all initial states except i = 0 (when the satisfaction of the postcondition would be impossible in any case).
As rabin contains two While loops the invariant rule must be used twice. Thus two loop invariants are needed, one for the inner, and one for the outer loop, and the most challenging part of the verification turned out to be finding them (of course). The correct invariant for the outer loop is simply pre above,

but for the inner loop we used
if 0 ≤ n ≤ i then (2/3) × invar1 i n + invar2 i n else 0 ,
where
invar1 i n ≡ 1 − (if i = n then (n + 1)/2n else if i = n +1 then 1/2n else 0)
invar2 i n ≡ if i = n then n/2n else if i = n +1 then 1/2n else 0
Translating very roughly into English: invar1 corresponds to the probability that the inner loop terminates with i > 1; and invar2 to the probability that the inner loop terminates with i = 1. Therefore the probability p that the outer loop will terminate with i = 1 satisfies p = p × invar1 + invar2, and we are proving that the voting algorithm works with p = 2/3.
To deploy the wlp tactic, an equivalent annotated version of the program is required, constructed by using Assert to annotate rabin with the above invari- ants. Next the wlp tactic is applied to the produced (one as usual, plus two verification conditions generated by the while loops). The wlp tactic proves one of these automatically, and simplifies the other two. We apply some cus- tom simplifications, and are left with three non-trivial subgoals which depend on properties of exponentials. These are despatched by 58 lines of proof script, completing the verification of the specification (1) of the behaviour of rabin.

Conclusions and related work
We have shown how to formalize in higher-order logic the theory of pGCL, a language for reasoning about both demonic and probabilistic choice in a common framework; we have implemented a verification-condition generator to assist with formally proving the partial correctness of programs, and we have demonstrated it on some small examples.
This work demonstrates the benefits of mechanizing a theory of program semantics using a theorem prover. In particular, the fact that the theorem prover was interactive fitted very nicely with the verification-condition genera- tor: if subgoals appeared that could not be proved automatically, then instead of causing a failure they could be passed on to the user for manual proof. Moreover we took advantage of the LCF design of HOL4 , which preserves the consistency of user-defined tactics: the verification-condition generator is highly complex, but nevertheless any theorems that it creates have a high assurance of soundness.
Future work will focus on formalizing the correspondence between wp and wlp semantics, with the aim of implementing a total-correctness verification generator. This will additionally require proofs of termination, and it will be interesting to provide tool support for probabilistic variants and other

termination arguments.
The first author has mechanized a semantics of probabilistic programs in HOL4 [7], but this language did not support demonic choice. The third author has recently extended the B tool (a proof assistant for program refinement) with a probabilistic choice construct [6].
Probabilistic model checkers such as PRISM [11] effectively calculate weak- est preconditions for finite-state machines incorporating both probabilistic and demonic choice, and can also deal with loops without needing helpful anno- tations. On the other hand, the limited expressivity of the logic means that sometimes it cannot model algorithms in their full generality, but instead must restrict to a fixed number of processors.
Harrison has previously mechanized Dijkstra’s weakest precondition se- mantics for standard GCL in the HOL Light theorem prover [5], and Nipkow has produced a comprehensive mechanization of Hoare logics in the Isabelle theorem prover [17]. Finally, there have been several verification condition generators for while languages created for use with the HOL theorem prover, beginning with Gordon’s in 1989 [3].

Acknowledgement
This work was completed while Hurd was on leave from the Computer Lab- oratory at Cambridge, visiting McIver with the support of a Fellowship at Macquarie University in Sydney. He is currently a Junior Research Fellow at Magdalen College in Oxford.
Morgan holds an Australian Professorial Fellowship at the University of New South Wales, and is associated with NICTA.

References
E.W. Dijkstra. A Discipline of Programming. Prentice Hall, 1976.
M. Gordon, R. Milner, and C. Wadsworth. Edinburgh LCF, volume 78 of Lecture Notes in Computer Science. Springer, 1979.
M.J.C. Gordon. Mechanizing programming logics in higher order logic. In G. Birtwistle and P.A. Subrahmanyam, editors, Current Trends in Hardware Veriﬁcation and Automated Theorem Proving, pages 387–439. Springer-Verlag, 1989.
M.J.C. Gordon and T.F. Melham. Introduction to HOL (A theorem-proving environment for higher order logic). Cambridge University Press, 1993.
John Harrison. Formalizing Dijkstra. In Jim Grundy and Malcolm Newey, editors, Theorem Proving in Higher Order Logics, 11th International Conference, TPHOLs ’98, volume 1497 of Lecture Notes in Computer Science, pages 171–188, Canberra, Australia, September 1998. Springer.


Thai Son Hoang, Z. Jin, K. Robinsion, A.K. McIver, and C.C. Morgan. Probabilistic invariants for probabilistic machines. In Proceedings of the 3rd International Conference of B and Z users 2003, volume 2651 of Lecture Notes in Computer Science, pages 240–159. Springer.
Joe Hurd. Formal Veriﬁcation of Probabilistic Algorithms. PhD thesis, University of Cambridge, 2002.
Michael Huth. The interval domain: A matchmaker for aCTL and aPCTL. In Rance Cleaveland, Michael Mislove, and Philip Mulry, editors, US - Brazil Joint Workshops on the Formal Foundations of Software Systems, volume 14 of Electronic Notes in Theoretical Computer Science. Elsevier, 2000.
Dexter Kozen. A probabilistic PDL. Proceedings of the 15th ACM Symposium on Theory of Computing, 1983.
Eyal Kushilevitz and Michael O. Rabin. Randomized mutual exclusion algorithms revisited. In Maurice Herlihy, editor, Proceedings of the 11th Annual Symposium on Principles of Distributed Computing, pages 275–283, Vancouver, BC, Canada, August 1992. ACM Press.
M. Kwiatkowska, G. Norman, and D. Parker. Prism: Probabilistic symbolic model checker. In
Proceedings of PAPM/PROBMIV 2001 Tools Session, September 2001.
Annabelle McIver and Carroll Morgan. Abstraction, Reﬁnement and Proof for Probabilistic Systems. Springer Verlag, 2004.
http://www.cse.unsw.edu.au/˜carrollm/arp
A.K. McIver and C.C. Morgan. Partial correctness for probabilistic programs. Theoretical Computer Science 266 (1–2), 513–541, 2001.
Carroll Morgan. Proof rules for probabilistic loops. In Proceedings of the BCS-FACS 7th Reﬁnement Workshop. He Jifeng, John Cooke and Peter Wallis (eds). Springer Verlag Workshops in Computing, 1996.
Carroll Morgan and Annabelle McIver. pGCL: formal reasoning for random algorithms. South African Computer Journal, 1999.
Carroll Morgan, Annabelle McIver, and Karen Seidel. Probabilistic predicate transformers. ACM Transactions on Programming Languages and Systems, 18(3):325–353, May 1996. See also [12].
Tobias Nipkow. Hoare logics in Isabelle/HOL. In H. Schwichtenberg and R. Steinbru¨ggen, editors, Proof and System-Reliability, pages 341–367. Kluwer, 2002.
Jamie Shield, Ian J. Hayes, and David A. Carrington. Using theory interpretation to mechanise the reals in a theorem prover. In Colin Fidge, editor, Electronic Notes in Theoretical Computer Science, volume 42. Elsevier, 2001.
