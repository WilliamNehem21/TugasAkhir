Available online at www.sciencedirect.com



Electronic Notes in Theoretical Computer Science 276 (2011) 171–190
www.elsevier.com/locate/entcs

Precision and the Conjunction Rule in Concurrent Separation Logic
Alexey Gotsmana Josh Berdineb Byron Cookb,c
a IMDEA Software Institute
b Microsoft Research
c Queen Mary University of London

Abstract
Concurrent separation logic is a Hoare logic for modular reasoning about concurrent heap-manipulating programs synchronising via locks. It achieves modular reasoning by partitioning the program state into thread-local and lock-protected parts, and assigning resource invariants to the latter. Surprisingly, the logic is unsound unless resource invariants are precise, i.e., unambiguously carve out an area of the heap. The counterexample showing the unsoundness involves the conjunction rule. However, to date it has been an open question whether concurrent separation logic without the conjunction rule is sound when the restriction on resource invariants is dropped: all the published proofs have the precision restriction baked in. In this paper we present a single proof that shows the soundness of the logic with imprecise resource invariants, but without the conjunction rule, as well as its classical version, where resource invariants are required to be precise and the conjunction rule is included. Our proof yields a precise and direct formulation of O’Hearn’s Separation Property and provides a semantic analysis of the logic that is much more elementary than previous proofs.
Keywords: Separation logic, concurrency, precision, conjunction rule.

Introduction
Concurrent separation logic [12] is a Hoare logic for modular reasoning about concur- rent heap-manipulating programs synchronising via locks, aka mutexes. It achieves modular reasoning by imposing a partitioning of the variables and the heap form- ing the program state into several disjoint parts: thread-local parts (one for each thread, aka process) and protected parts (one for each free lock, i.e., a lock that is not held by any thread). A thread-local part may only be accessed by the cor- responding thread, and a lock-protected part only when a thread holds the lock. When such a partitioning exists, the program is said to satisfy the Separation Prop- erty. To specify the partitioning, the logic associates each lock in the program with an assertion—its resource invariant—that describes the part of the state it protects. For example, a resource invariant might state that a lock protects a singly-linked list with the head node pointed to by a particular variable. For any given thread,

1571-0661 © 2011 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2011.09.021

resource invariants restrict how the other threads can change the protected state, and hence, allow reasoning about the thread in isolation.
It is important to note that the state partitioning described above is not a part of the program itself, but is enforced by proofs in the logic to enable modular reasoning in the presence of concurrent interference. Moreover, the partitioning is not required to be static, i.e., the logic permits ownership transfer of variables and heap cells between areas owned by different threads and locks. Such a non- standard view of the program state makes the formulation and proof of soundness of the logic difficult. In fact, the logic was proposed by O’Hearn in 2001, but the first proof of soundness (due to Brookes) was given only in 2004 [2]. This is because, as Reynolds showed shortly after the logic was invented [12], it is unsound unless resource invariants are precise. Informally, a predicate over program states is precise when it unambiguously carves out an area of the heap (see Section 2.1 for a formal definition). For example, the separation logic assertion x '→0, denoting a cell at the address x storing 0, is precise; however, the assertion x '→0 ∨ emp, denoting either the cell or the empty heap, is not. The key proof rule used in the counterexample showing the unsoundness is the conjunction rule:
▶ {P1} C {Q1}	▶ {P2} C {Q2}
▶ {P1 ∧ P2} C {Q1 ∧ Q2}
The rule is useful for combining the results of two proofs; e.g., it is used by the reduced product construction in abstract interpretation [6].
O’Hearn has conjectured that the logic might be sound in the case when both the restriction of precision and the conjunction rule are dropped [12]. The question of this conjecture’s validity is not only of theoretical importance: we do want to use imprecise resource invariants in practice. For example, consider the following two definitions of a list-segment predicate [15] we could use in a resource invariant:

ls1(E, F ) ⇔ (E = F ∧ emp) ∨ (∃X. E'→X∗ ls1(X, F ) ∧ E /= F );
ls2(E, F ) ⇔ (E = F ∧ emp) ∨ (∃X. E'→X∗ ls2(X, F )),

where X is chosen fresh. The latter definition yields imprecise assertions: e.g., both the heaps described by X'→Yand ∃Z. X'→∗YY '→∗ZZ'→Ysatisfy ls2(X, Y ); only the former assertion implies ls1(X, Y ). However, the ls2 predicate validates some entailments between assertions that ls1 does not. For this reason, it is the ls2 predicate that modern program analysis tools based on separation logic use (e.g., [16]). As automatic tools based on concurrent separation logic are usually built on top of corresponding sequential analyses, these tools thus often infer imprecise resource invariants [3,9].
To date, it has been an open question whether O’Hearn’s conjecture is true: the whole of Brookes’s proof of soundness [2] and all alternative proofs published after it [4,11] depend on the precision of resource invariants and thus have the conjunc- tion rule baked in. The automatic program analyses producing imprecise invariants

have either been proved sound directly with respect to program semantics [9], or relied on the conjecture being true [3]. In this paper we present a single proof that shows the soundness of the logic with imprecise resource invariants, but without the conjunction rule, as well as its classical version, where resource invariants are required to be precise and the conjunction rule is included (Theorem 4.1). In addi- tion to showing the soundness of concurrent separation logic, our proof provides a semantic analysis that is much more elementary than the previously proposed ones, which have been based on action traces [2,4] or Petri nets [11].
We achieve this using the concept of a semantic proof that annotates program points in the code of a thread with descriptions of its local state (Section 4.1). Unlike the standard interpretations of Hoare triples, the interpretation in terms of semantic proofs is quite intentional. The definition of a triple being valid does not abstract away all the internal syntactic structure of the command or proof, while the standard interpretations are given solely in terms of the extensional meaning of the command and pre- and post-condition assertions. This use of an intentional definition is an acknowledgement that the intuitive reason for the unsoundness of the conjunction rule with imprecise resource invariants is crucially about proofs, not denotations of commands. In particular, imprecise resource invariants allow the two premisses of the conjunction rule to make conflicting choices about how to partition the state. It is these different choices of state partitioning in different branches of the proof that lead to problems, but the partitioning in question is irrelevant to the operational behaviour of the command.
One view of previous soundness proofs is that in lieu of using an intentional interpretation of triples, they instrument the semantics of commands with manip- ulation of the partitioning in order to expose enough of the intentional detail even with an extensional interpretation. A key consequence of using semantic proofs instead of an instrumented semantics is that the Separation Property can be for- mulated (Lemma 4.2) directly as an invariant of concurrent executions: for a given point in the program the local states of threads can be determined from their se- mantic proofs. Consequently, no tracking of changing instrumentation along exe- cution traces is needed, and the previously crucial and difficult step of decompos- ing a concurrent execution into an interleaving of constituent sequential executions (Brookes’s Parallel Decomposition Lemma [2]) can be avoided.
Technically, to prove the soundness of concurrent separation logic, we define a thread-local interpretation of every thread in the program as a semantic proof. A formalisation of the Separation Property (Lemma 4.2) connects the thread-local interpretation to a standard interleaving operational semantics (Section 3). We then define the notion of validity of Hoare triples for commands with respect to this interpretation and prove the soundness of all the proof rules (Section 4.2). Despite not tracking a partitioning of the state, the thread-local interpretation is strong enough to establish that provability of a program in concurrent separation logic implies that the program is data-race free (Section 5).

Concurrent separation logic
In this paper we consider the version of concurrent separation logic proposed by Calcagno et al. [4]. This version of the logic is abstract in the sense that it can be interpreted over a wide class of semantic models with a given structure, which allows reusing results about the logic in multiple contexts. As any Hoare logic, concurrent separation logic includes two formal systems—one for assertions and one for specifications. We discuss the former first.
Assertions
In abstract separation logic, assertions are interpreted with respect to a separation algebra, which represents program states.
Definition 2.1 (Separation algebra) A separation algebra is a partial commu- tative monoid (Σ, ∗, ε) with a unit element ε ∈ Σ. A partial commutative monoid is given by a partial binary operation of separate combination ∗, where the unity, commutativity and associativity laws hold for the equality that means both sides are deﬁned and equal, or both are undeﬁned.
The original definition of separation algebras given in [4] requires the ∗ operation to be cancellative: for each σ ∈ Σ, the partial function σ ∗· :Σ ~ Σ must be injective. This requirement is connected with conditions for validating the conjunction rule of Hoare logic. We have omitted it here since we also consider models of concurrent separation logic invalidating the rule.
In this paper, by a domain D we understand a lattice (D, ±, H, H, T, ⊥). For a set Σ let P(Σ)T be the domain of subsets of Σ with a special element T. The order
± in the domain P(Σ)T is subset inclusion with T being the greatest element and ∅ the least. When Σ represents program states, we usually use T to denote an error state, e.g., resulting from dereferencing an invalid pointer. Note that the order ± defines the corresponding join H and meet H operations on the domain P(Σ)T. If Σ is a separation algebra, we can lift the ∗ operation to P(Σ)T pointwise: for all p, q ∈ P(Σ)
p ∗ q = [{σ ∗ η | σ ∈ p, η ∈ q, σ ∗ η is defined};	T∗ p = p ∗T = T.

Thus, P(Σ)T has a total commutative monoid structure with the unit e = {ε}. For a separation algebra Σ, we call P(Σ)T the separation domain constructed from the algebra Σ.

We denote with ② the iterated version of ∗ on P
(Σ)T:
n
②
k=1
pk = e
∗ p1
∗ ... ∗ pn.

For σ ∈ Σ ∪ {T} we denote with {|σ|} the singleton set {σ}, if σ ∈ Σ, and T, if
σ = T. Thus, {|σ|} ∈ P(Σ)T.
A predicate p ∈ P(Σ) over a separation algebra Σ is precise [12,13] if for any state σ there exists at most one substate σ1 satisfying p: σ = σ1 ∗ σ2 for some σ2. If such a substate exists and the ∗ operation is cancellative, then the substate σ2 is unique.

Elements of separation algebras and domains are often defined using partial functions. We use the following notation: f (x)↑ means that the function f is undefined on x, and [ ] denotes a nowhere-defined function. We denote with f [x : y] the function that has the same value as f everywhere, except for x, where it has the value y (even if f (x)↑).
The following is an example of a separation algebra RAM typically used for reasoning about heap-manipulating programs:

A state consists of a stack and a heap, both finite partial functions mapping variables or locations to their values. To simplify presentation, the algebra does not include permissions [1,14]. We have also omitted logical variables; see Section 2.4. The ∗ operation forms the disjoint union of stacks and heaps: (s1, h1) ∗ (s2, h2) = (s1 s2, h1  h2). The unit element is a state with the empty stack and heap: ([ ], [ ]).
For the remainder, we fix a separation algebra (Σ, ∗, ε) and the corresponding domain P(Σ)T. We further assume an assertion language for denoting predicates over Σ, including ∨, ∧, ⇒ and ∗ connectives with the expected interpretation, and the assertion emp denoting only the empty state ε. Tautological assertions are those whose meaning is Σ. We denote with JP ) ∈ P(Σ) the meaning of the assertion P . An assertion is precise if it denotes a precise predicate.

Primitive commands and local functions
The programming language we consider in this paper is parameterised by a set PComm of primitive sequential commands. For every C ∈ PComm we assume its denotation fC :Σ → P(Σ)T, which maps each pre-state to the states obtained by executing C from it. As shown by Calcagno et al. [4], for separation logic to be sound, transformers fC for primitive commands of the programming language must behave in a local way with respect to the structure present in Σ. The following definition formalises this condition.
Definition 2.2 (Local function) For a separation algebra (Σ, ∗, ε), a function f : Σ → P(Σ)T is local if for any states σ1, σ2 ∈ Σ such that σ1 ∗ σ2 is deﬁned, we have
f (σ1 ∗ σ2) ± f (σ1) ∗ {σ2}.

Definition 2.2 is a concise way of formulating two conditions that the soundness of separation logic relies on [17]: if f : Σ → P(Σ)T is the meaning of a command C, then
(safety monotonicity) if executing C from a state σ1 ∗ σ2 results in an error f (σ1 ∗ σ2)= T, then executing C from a smaller state σ1 also produces an error: T± f (σ1) ∗ {σ2} implies f (σ1)= T;

(frame property) if executing C from a state σ1 does not produce an error, then executing C from a larger state σ1 ∗ σ2, has the same effect and leaves σ2 un- changed: in this case we often have f (σ1 ∗ σ2)= f (σ1) ∗ {σ2}.
The requirement of locality rules out commands that can check if a cell is allocated in the heap other than by trying to access it and faulting if it is not allocated. For example, let Σ = RAM (see Section 2.1) and consider the following function f : RAM → P(RAM)T:
{(s, hj)},	if h(10) is defined;
f (s, h)= 
{(s, h)},	otherwise,
where hj is identical to h except it is undefined at 10. The function f defines the denotation of a ‘command’ that disposes of the cell at the address 10 if it is allocated and acts as a no-op if it is not. The function f is not local: take σ1 = ([ ], [ ]) and σ2 = ([ ], [10 : 0]), then
f (σ1 ∗ σ2)= f (([ ], [ ]) ∗ ([ ], [10 : 0])) = f ([ ], [10 : 0]) = {([ ], [ ])}
and
f (σ1) ∗ {σ2} = f ([ ], [ ]) ∗ {([ ], [10 : 0])} =
{([ ], [ ])}∗ {([ ], [10 : 0])} = {([ ], [10 : 0])},
hence, the inequality f (σ1 ∗ σ2) ± f (σ1) ∗ {σ2} does not hold.
The pointwise lifting of a function f : Σ → P(Σ)T to P(Σ)T is a function
f : P(Σ)T → P(Σ)T defined as follows: for all p ∈ P(Σ)T

f (p)=		{f (σ) | σ ∈ p},	if p /= T; T,	 if p = T.

Given a denotation fC :Σ → P(Σ)T of a command C ∈ PComm, we can lift it to a forward predicate transformer fC : P(Σ)T → P(Σ)T. We note that the resulting transformer distributes over the H and H operations in the domain P(Σ)T:
∀p, q ∈ P(Σ)T. fC(p H q)= fC(p) H fC(q);	(1)
∀p, q ∈ P(Σ)T. fC(p H q)= fC(p) H fC(q).	(2)
Furthermore, if the denotation is local, then for the corresponding transformer we have:
∀p, q ∈ P(Σ)T. fC(p ∗ q) ± fC(p) ∗ q.
We say that the predicate transformer is local when it satisfies this property.
Typical heap-manipulating commands can be interpreted over the algebra Σ =
RAM from Section 2.1. We refer to them in Section 5, where we formulate and prove

skip, (s, h)	~	(s, h)
x=E, (s[x : u], h)	~	(s[x : JE)s[x : u]], h) x=[E], (s[x : u], h[JE)s[x : u]: b])	 ~	 (s[x : b], h[JE)s[x : u]: b]), [E]=F, (s, h[JE)s : u])	 ~	 (s, h[JE)s : JF )s])
x=new, (s[x : u], h)	~	(s[x : b], h[b : w]), if h(b)↑
delete E, (s, h[JE)s : u])	~	(s, h), if h(JE)s)↑
assume(B), (s, h)	~	(s, h), if JB)s = true
assume(B), (s, h)	~/	if JB)s = false
C, (s, h)	~	T,	otherwise
Fig. 1. Transition relation for primitive commands RAMComm. T indicates that the command faults. /~ is used to denote that the command does not fault, but gets stuck. We denote with JE)s ∈ Values and JB)s ∈ {true, false} the values of the expressions in the stack s.

the data-race freedom theorem for concurrent separation logic. Let E, F range over integer expressions and B over Boolean expressions:

x	∈	Vars
E, F  ::= NULL | x | E + F | ... 
B ::= E = F | ¬B | ... 

We consider the following set RAMComm of primitive sequential commands:
RAMComm ::= skip | x=E | x=[E] | [E]=F | x=new | delete E | assume(B)
As usual, square brackets denote pointer dereferencing. The assume(B) command acts as a filter on the state space of programs—B is assumed to be true after assume(B) is executed. We define denotations fC : RAM → P(RAM)T for C ∈ RAMComm using the transition relation ~: RAMComm × RAM × (RAM ∪ {T}) shown in Figure 1: for all σ ∈ RAM
fC(σ)= . {|σj|} | C, σ ~ σj}.

It is not difficult to show that fC is local for every C ∈ RAMComm [4].
In the rest of this paper, we assume local denotations fC : Σ → P(Σ)T of commands C ∈ PComm and their liftings to predicate transformers.

The logic
We consider a variant of concurrent separation logic [12] for a concurrent program- ming language in which programs consist of a parallel composition of several threads

(processes) that use locks (mutexes) l1,..., lm for synchronisation. The syntax of programs S is as follows:
C ::= PComm | C; C | C + C | C∗ | acquire(lk); C; release(lk)
S ::= C  ...  C

The code of threads can include primitive sequential commands from PComm, se- quential composition C; C, choice C + C, iteration C∗ and (syntactically scoped) critical regions over the available locks.
When PComm includes the assume statement, the standard commands for con- ditionals, loops and conditional critical regions (CCRs) can be defined in our pro- gramming language as follows:
if B then C1 else C2 = (assume(B); C1)+ (assume(¬B); C2)
while B do C = (assume(B); C)∗; assume(¬B)
with l when B do C = acquire(l); assume(B); C; release(l)
The original concurrent separation logic also considers nested parallel composi- tions and explicit lock declarations. The restricted form of programs chosen here simplifies the formal development and makes the underlying ideas more explicit. Our results have been extended to dynamically-allocated locks and dynamically- created threads (see [8]), which are more general constructs than lock declarations and parallel compositions.
The judgements of concurrent separation logic are of the form I ▶ {P } C {Q}, where C is a command in the code of a thread, P and Q are assertions describing the local state of the thread and I is the vector of resource invariants Ik for all the locks lk in the program. Intuitively, the judgement means that, if the thread starts executing C from an initial local state satisfying P , then it accesses only its local part of the state, respects the resource invariants I, and terminates only in local states satisfying Q.
The proof rules of concurrent separation logic are summarised in Figure 2. Most of the rules are standard ones from Hoare logic. We have a single axiom for prim- itive commands (Prim), which allows any pre- and postconditions consistent with the predicate transformer for the command. For a particular set of states Σ and denotations fC of C ∈ PComm, this axiom can be specialised to several syntactic versions, obtaining a concrete instance of the abstract logic presented here [1,14,15]. The conjunction rule (Conj) is useful for combining the results of two proofs, and the disjunction rule (Disj) for proof by cases. The frame rule (Frame) states that executing a command in a bigger local state does not change its behaviour.
Locks are treated in the logic as follows. When a thread acquires a lock, it receives the ownership of a part of the state satisfying the resource invariant of the lock (Acquire). Before releasing the lock, the thread must re-establish the corresponding resource invariant. After the lock is released, the thread relinquishes

fC(JP )) ± JQ)


I ▶ {P } C {Q}

Prim

I ▶ {P } C1 {Q}	I ▶ {Q} C2 {R}


I ▶ {P } C1; C2 {R}
I ▶ {P } C1 {Q}	I ▶ {P } C2 {Q}

Seq

I ▶ {P } C1 + C2 {Q}
I ▶ {P } C {P}
I ▶ {P } C∗ {P} Loop
Choice

I ▶ {P1} C {Q1}	I ▶ {P2} C {Q2}


I ▶ {P1 ∨ P2} C {Q1 ∨ Q2}
I ▶ {P1} C {Q1}	I ▶ {P2} C {Q2}


I ▶ {P1 ∧ P2} C {Q1 ∧ Q2}
P1 ⇒ P2	I ▶ {P2} C {Q2}	Q2 ⇒ Q1 I ▶ {P1} C {Q1}
I ▶ {P } C {Q}

Disj Conj Conseq



I ▶ {P ∗ R} C {Q ∗ R}
Frame



Acquire
I ▶ {emp} acquire(lk) {Ik}
Release
I ▶ {Ik} release(lk) {emp}
I ▶ {P1} C1 {Q1}	...	I ▶ {Pn} Cn {Qn}





Par


Fig. 2. Proof rules of concurrent separation logic
the ownership of its resource invariant (Release). Note that we can obtain global versions of the axioms Acquire and Release by closing them under the frame rule:

I ▶ {P } acquire(lk) {P ∗ Ik}	I ▶ {P ∗ Ik} release(lk) {P}
Finally, the Par rule combines judgements about several threads into a judge- ment for the whole program of the form I ▶ {P } S {Q}.
Logical variables
In program proofs we often need to use so-called logical (aka ghost) variables, which appear in assertions, but not in programs. We now show how the logic can be extended with proof rules for manipulating such variables.
Let us fix a set of integer logical variables LVars = {X, Y, . . .} and let Ints =

LVars → Z be the set of their interpretations. We say that a separation algebra Σ is an algebra with logical variables, if for some separation algebra Σj we have Σ= Σj × Ints and the ∗ operation on Σ is defined as follows:
(σ1, i1) ∗ (σ2, i2)= (σ1 ∗ σ2, i1),
if i1 = i2, and is undefined, otherwise.
For example, let RAMj = RAM × Ints for the separation algebra RAM defined in Section 2.1 with the ∗ operation on RAM lifted to RAMj as above. Then RAMj is a separation algebra with logical variables.
Given a function f : Σj → P(Σj)T on the underlying algebra without logical variables, we can lift it to a function f : Σ → P(Σ)T on the algebra with logical variables as follows:
f (σ, i)=	f (σ) × {i},	if f (σ) /= T;
T,	if f (σ)= T.

Let Σ be an algebra with logical variables, and assume an assertion language with quantifiers over logical variables:
P ::= ... | ∃X. P | ∀X. P
where the satisfaction relation is defined as follows:
(σ, i) |= ∃X. P ⇔ ∃u. (σ, i[X : u]) |= P
(σ, i) |= ∀X. P ⇔ ∀u. (σ, i[X : u]) |= P

When the functions fC defining the semantics of primitive sequential commands are lifted from functions on the underlying algebra without logical variables, we can extend concurrent separation logic with the following two proof rules for manipu- lating logical variables:


I ▶ {P } C {Q}


I ▶ {∃X. P} C {∃X. Q}
Exists
I ▶ {P } C {Q}


I ▶ {∀X. P} C {∀X. Q}
Forall

Programming language and semantics
We now define the simple operational semantics with respect to which we prove soundness. From now on, we fix a program S = C1  ...  Cn in our concurrent programming language consisting of n threads C1,..., Cn that use m locks l1,..., lm for synchronisation.
It is technically convenient to abstract from the particular syntax of the pro- gramming language and represent each thread in a program with its control-flow graph (CFG). A CFG is defined as a tuple (N, T, start, end), where N is the set of program points, T ⊆ N × Comm × N is the control-flow relation, and start and end

are distinguished initial and final program points. Edges in the CFG are labelled with commands from the set Comm, which consists of primitive sequential com- mands PComm, lock acquires acquire(lk) and releases release(lk). We assume, without loss of generality, that control-flow relations have no edges leading to start or from end.
We note that the code of a thread in our language can be translated to a CFG in a standard way. Namely, assume the set PComm of primitive sequential commands includes the skip statement. Then the CFG of a command C is constructed by induction on its syntax as follows:
A primitive command C ∈ PComm has the CFG
({start, end}, {(start, C, end)}, start, end).
Assume C1 and C2 have CFGs
(N1, T1, start1, end1) and (N2, T2, start2, end2),	(3) respectively. Then C1; C2 has the CFG
(N1 ∪ N2, T1 ∪ T2 ∪ {(end1, skip, start2)}, start1, end2).
Assume C1 and C2 have CFGs (3). Then C1 + C2 has the CFG
(N1 ∪ N2 ∪ {start, end}, T1 ∪ T2 ∪ {(start, skip, start1), (start, skip, start2), (end1, skip, end), (end2, skip, end)}, start, end).
Assume C has a CFG (N, T, start, end). Then C∗ has the CFG
(N ∪ {startj, endj},T ∪ {(startj, skip, start), (end, skip, start), (end, skip, endj)}, startj, endj).
Thus, let us represent each thread Ck in S by its CFG (Nk, Tk, startk, endk). Let

n k=1
Nk and T =  n
Tk be the set of program points and the control-flow

relation of the program S, respectively.
The interleaving operational semantics of the program S is defined by a transi- tion relation →S that transforms pairs of program counters (represented by map- pings from thread identifiers to program points) and program states:
→S: (({1,..., n}→ N ) × Σ) × (({1,..., n}→ N ) × (Σ ∪ {T})).
Note that since the critical regions formed by acquire and release commands are syntactically scoped in our programming language, we can determine the set Free(pc) ⊆ {1,..., m} of indices of free locks at every program counter pc ∈
{1,..., n} → N , i.e., the set of locks that are not held by any thread. The re- lation →S is defined by the rules in Figure 3. The semantics executes commands

(v, C, vj) ∈ T	C ∈ PComm	fC(σ) /= T	σj ∈ fC(σ)
pc[k : v],σ →S pc[k : vj], σj
(v, release(lj), vj) ∈ T
pc[k : v],σ →S pc[k : vj],σ 
(v, C, vj) ∈ T	C ∈ PComm	fC(σ)= T
pc[k : v],σ →S pc[k : vj], T
(v, acquire(lj), vj) ∈ T	j ∈ Free(pc[k : v])
pc[k : v],σ →S pc[k : vj],σ 
Fig. 3. Operational semantics
from PComm atomically. Note also that, according to our semantics, a thread that tries to acquire the same lock twice gets stuck.
Let us denote with pc0 the initial program counter [1 : start1] ... [n : startn] and with pcf the final one [1 : end1] ... [n : endn]. We say that the program S is safe when run from an initial state σ0 ∈ Σ, if it is not the case that pc0, σ0 →∗ pc, T for
some program counter pc.
Proof of soundness
The purpose of this section is to prove the following theorem, stating the soundness of the logic presented in Section 2.3.
Theorem 4.1 (Soundness) Assume I ▶ {P } S {Q}, where either
resource invariants in I are precise and the ∗ operation is cancellative; or
Conj is not used in the derivation of the triple.

Then for any σ0 ∈ Σ such that

σ0


m
②
k=1


JIk)  ,


(4)

the program S is safe when run from σ0, and if pc0, σ0 →∗ pcf , σ, we have


m
②
k=1

JIk)  .

(5)

Thread-local interpretation and Separation Property
A semantic proof is defined as a triple (C, G, I), where
C is a command with a CFG (N, T, start, end);
G : N → P(Σ) maps program points of C to semantic annotations;
I ∈ (P(Σ))m is a vector of resource invariant denotations Ik ∈ P(Σ), k = 1..m such that for all edges (v, Cj, vj) ∈ T

if Cj ∈ PComm, then

if Cj is acquire(lk), then

if Cj is release(lk), then

fC′ (G(v)) ± G(v );	(6)

G(v) ∗ Ik ⊆ G(vj);	(7)

G(v) ⊆ G(vj) ∗ Ik.	(8)

Note that the elements of P(Σ) assigned to program points by the semantic annota- tion mapping G in this definition are similar to label invariants in proof systems for unstructured control flow [7]. Inequalities (6), (7) and (8) are semantic counterparts of the axioms Prim and the global versions of Acquire and Release, respectively. The thread-local interpretation of a command is given by its semantic proof. In Section 4.2 we show how to extract a semantic proof for a thread in the program
from its syntactic proof in concurrent separation logic.
As we explained in Section 1, the core of our proof of soundness consists of establishing the Separation Property [12]: at any time, the state of the program can be partitioned into that owned by each thread and each free lock. The following lemma formalises the property in the case where the local states of threads are defined by their semantic proofs. This establishes a correspondence between our thread-local interpretation and the operational semantics of Section 3.
Lemma 4.2 (Separation Property) Assume semantic proofs (Ck, Gk, I), k =
1..n. If σ0 ∈ Σ is such that

{σ }±  n

start )  ∗	②

I  ,	(9)


then, whenever pc0, σ0 →∗ pc, σ, we have


n
②
k=1

Gk(
pc(k))	∗	②
k∈Free(pc)

Ik  .	(10)

Proof We prove the statement of the theorem by induction on the length of the derivation of σ in the operational semantics of the program S. In the base case (10) is equivalent to (9). Suppose now that
pc0, σ0 →∗ pc[j : v],σ →S pc[j : vj], σj.
Then (v, C, vj) ∈ T for some atomic command C ∈ Comm. We have to show that if



then

n
②
k=1

Gk((
pc[j : v])(k))	∗	②
k∈Free(pc[j:v])

Ik  ,	(11)

n
②
k=1
Gk((
pc[j : vj])(k))	∗	②
k∈Free(pc[j:v′])
Ik  .	(12)

There are three cases corresponding to the type of the command C.

Case 1. C ∈ PComm. In this case Free(pc[j : v]) = Free(pc[j : vj]). Let


r =	②
1≤k≤n, k/=j

Gk(pc(k))	∗	②
k∈W

Ik  ,	(13)

where W = Free(pc[j : v]) = Free(pc[j : vj]). Then

{|σj|} ± fC({σ})	definition of →S
± fC(Gj(v) ∗ r)	(11)
± fC(Gj(v)) ∗ r	fC is local
± Gj(vj) ∗ r	(6)
Case 2. C is acquire(li). In this case i ∈ Free(pc[j : v]) and i /∈ Free(pc[j : vj]).
Let r be defined by (13) with W = Free(pc[j : v]) \ {i} = Free(pc[j : vj]). Then

{|σj|} = {σ}	definition of →S
± Gj(v) ∗ Ii ∗ r	(11)
± Gj(vj) ∗ r	(7)
Case 3. C is release(li). In this case i /∈ Free(pc[j : v]) and i ∈ Free(pc[j : vj]).
Let r be defined by (13) with W = Free(pc[j : v]) = Free(pc[j : vj]) \ {i}. Then

{|σj|} = {σ}	definition of →S
± Gj(v) ∗ r	(11)
± Gj(vj) ∗ Ii ∗ r	(8)
In all cases we get inequalities equivalent to (12), completing the induction.	 

Soundness with respect to thread-local interpretation
To prove Theorem 4.1, we first define a notion of validity of Hoare triples with respect to the thread-local interpretation of Section 4.1 and prove the soundness of the proof rules in this interpretation. Soundness of the logic with respect to the concrete semantics is then a direct consequence of Lemma 4.2.
Definition 4.3 We write I ▶ {P} C {Q} if there exists a semantic proof (C, G, JI)) such that G(start) = JP ) and G(end) ⊆ JQ), where start and end are the starting and the ﬁnal program points of the CFG of C.
We say that an inference rule is sound with respect to the thread-local interpre- tation if it preserves validity of judgements (as defined by the relation ▶ above).

Lemma 4.4
Prim, Acquire, Release, Seq, Choice, Loop and
Conseq are

sound with respect to the thread-local interpretation.
Proof For illustration, we consider the cases Prim and Seq of this easy lemma and omit the others.
Prim.	Consider an application I  ▶  {P} C {Q} of the axiom Prim,
where C  ∈  PComm.  Then fC(JP )) ±  JQ).  According to the encod- ing of commands into CFGs from Section 3, the command C has the CFG ({start, end}, {(start, C, end)}, start, end). Let G(start) = JP ) and G(end) = JQ), then fC(G(start)) ± G(end).  Thus, (G, C, JI)) is a semantic proof and I  ▶
{P} C {Q} as required.
Seq. Assume I ▶ {P} C1 {Q} and I ▶ {Q} C2 {R}. Let the CFGs of C1 and C2 be (N1, T1, start1, end1) and (N2, T2, start2, end2), respectively. Then C1; C2 has the CFG (N1 ∪ N2, T1 ∪ T2 ∪ {(end1, skip, start2)}, start1, end2). There exist semantic proofs (C1, G1, JI)) and (C2, G2, JI)) such that
G1(start1)= JP ),  G1(end1) ⊆ JQ),  G2(start2)= JQ),  G2(end2) ⊆ JR).
Let G(v) = G1(v) for v ∈ N1 and G(v) = G2(v) for v ∈ N2. We have fskip(G1(end2)) ± G2(start1).  Thus, (G, (C1; C2), JI)) is a semantic proof and I ▶ {P} C1; C2 {R}.	 
We now proceed to prove the soundness of the rules Frame, Disj and Conj. To this end, we show that we can construct semantic proofs for the conclusions of these rules from semantic proofs for their premisses. This is essentially a semantic counterpart of a proof that these rules are admissible in the logic including the global Acquire and Release axioms, i.e., that a derivation using these rules can be converted into a derivation that does not use them. By using semantic proofs instead of derivations in our proof system, we avoid having to deal with the syntactic form of the proof rules in the logic and the control-flow constructs in our programming language.
Lemma 4.5 (i) For any r ∈ P(Σ), if (C, G, I) is a semantic proof, then so is
(C, Gj, I), where ∀v. Gj(v)= G(v) ∗ r.
If (C, G1, I) and (C, G2, I) are semantic proofs, then so is (C, Gj, I), where
∀v. Gj(v)= G1(v) ∪ G2(v).
If (C, G1, I) and (C, G2, I) are semantic proofs, then so is (C, Gj, I), where
∀v. Gj(v) = G1(v) ∩ G2(v), provided the resource invariant denotations in I
are precise and the ∗ operation is cancellative.
Proof Consider an edge (v, Cj, vj) in the CFG of the command C. When Cj ∈ PComm, inequality (6) for the new semantic annotation Gj follows from the fact that the predicate transformer fC′ is local and distributes over H and H. The latter is true by construction of transformers defined by pointwise lifting from Σ; see (1) and (2). We omit the easy case when Cj is acquire(lk). Suppose now that Cj is release(lk). We consider every case of the lemma in turn.

By the definition of Gj, we have
Gj(v)= G(v) ∗ r ⊆ G(vj) ∗ Ik ∗ r = Gj(vj) ∗ Ik.
The ∗ operation distributes over ∪:
∀p1, p2,q ∈ P(Σ). (p1 ∪ p2) ∗ q = (p1 ∗ q) ∪ (p2 ∗ q).
Hence,
Gj(v)= G1(v) ∪ G2(v) ⊆ (G1(vj) ∗ Ik) ∪ (G2(vj) ∗ Ik)= (G1(vj) ∪ G2(vj)) ∗ Ik = Gj(vj) ∗ Ik.
It is well-known [4] that if ∗ is cancellative, then for a precise q ∈ P(Σ) and any p1, p2 ∈ P(Σ) we have
(p1 ∩ p2) ∗ q = (p1 ∗ q) ∩ (p2 ∗ q).	(14) Thus, in this case we establish
Gj(v)= G1(v) ∩ G2(v) ⊆ (G1(vj) ∗ Ik) ∩ (G2(vj) ∗ Ik)= (G1(vj) ∩ G2(vj)) ∗ Ik = Gj(vj) ∗ Ik.
In all cases we get (8), which completes the proof.	 

Corollary 4.6 The rules
Frame and
Disj are sound with respect to the thread-

local interpretation. So is Conj when the resource invariants in I are precise and the ∗ operation is cancellative.
Lemma 4.7 If I ▶ {P } C {Q} and the restrictions on the derivation from Theo- rem 4.1 hold, then I ▶ {P} C {Q}.
The proof is by induction on the derivation of I ▶ {P } C {Q} using Lemma 4.4 and Corollary 4.6.
The proof
Proof of Theorem 4.1 Let I ▶ {Pk} Ck {Qk} be the thread-local triples used in the

rule Par to derive I ▶ {P } S {Q}. Then JP ) = (②n
JPk)) and JQ) = (②n
JQk)).

By Lemma 4.7, I ▶ {Pk} Ck {Qk} for k = 1..n, hence, by Definition 4.3, there exist
semantic proofs (Ck, Gk, JI)), k = 1..n such that Gk(startk)= JPk) and Gk(endk) ⊆ JQk). Consider a state σ0 satisfying (4). Let I = JI) in Lemma 4.2, then (9) is fulfilled. We have ∀v. Gk(v) /= T. Therefore, for any pc and σ such that pc0, σ0 →∗ pc, σ, from (10) we get {|σ|} и T, i.e., S is safe when run from σ0. Now letting pc = pcf in (10), we get (5).	 

Note that (14) does not hold in general for imprecise q. Thus, the conjunction of two semantic proofs is not necessarily a semantic proof, and Lemma 4.5 may not

be extended to show the soundness of the conjunction rule in the case of imprecise resource invariants. This is expected: the famous Reynolds counterexample [12] shows that in this case concurrent separation logic is unsound.
The intuitive reason for the unsoundness is that imprecise resource invariants al- low splitting the heap at a release command in different ways in different branches of the proof. Hence, in the two premisses of Conj there may be different under- standings of what the partitioning of the global heap into thread-local and protected parts should be. Trying to ∧-conjoin two such judgements about the local state of a thread then leads to inconsistency. Note that the simplicity of the interpretation using semantic proofs comes from not abstracting away from the crucial partition- ing choice details. Thus, conflicting partitioning choices lead to directly conflicting semantic proofs.

Logical variables
Assume that Σ is an algebra with logical variables, i.e., Σ = Σj × Ints, and that the functions fC for C ∈ PComm are lifted from functions on Σj (Section 2.4). In this case, we can add to the logic the rules Exists and Forall. We say that p ∈ P(Σ) does not depend on the interpretation of logical variables, if for any (σj, i) ∈ p and ij ∈ Ints we have (σj, ij) ∈ p. For the rules to be sound in a concurrent setting, we must require that the denotations of resource invariants do not depend on interpretations. In the case when we include Forall, we must additionally require that the resource invariants be precise and the ∗ operation be cancellative. For a logical variable X let Exists(X) : P(Σ) → P(Σ), respectively, Forall(X) : 
P(Σ) → P(Σ) be the semantic counterparts of existential, respectively, universal
quantification of X, defined as follows:
Exists(X, p)= {(σj, i) | ∃u. (σj, i[X : u]) ∈ p};
Forall(X, p)= {(σj, i) | ∀u. (σj, i[X : u]) ∈ p}.
The proof of soundness of Exists and Forall with respect to the thread-local interpretation is done by establishing the following analogue of Lemma 4.5.
Lemma 4.8 Under the above conditions, for any logical variable X and resource invariants I that do not depend on interpretations:
If (C, G, I) is a semantic proof, then so is (C, Gj, I), where ∀v. Gj(v) =
Exists(X, G(v)).
If (C, G, I) is a semantic proof, then so is (C, Gj, I), where ∀v. Gj(v) = Forall(X, G(v)), provided the resource invariant denotations in I are precise and the ∗ operation is cancellative.
The proof is similar to that of Lemma 4.5. It follows that Theorem 4.1 holds for the logic extended with the rules Exists and Forall, subject to the conditions given above.

Data-race freedom
We now show that the provability of a program in our logic implies that the program has no data races. We formalise the notion of data-race freedom and prove this result for the case when Σ = RAM (Section 2.1) and PComm = RAMComm (Section 2.2). For a state σ ∈ Σ let accesses(C, σ), respectively, writes(C, σ) be the set of variables and locations that a primitive sequential command C ∈ RAMComm may access (i.e., read, write, or dispose), respectively, write to or dispose, when run from the state σ according to the semantics of commands RAMComm defined in Figure 1.
Definition 5.1 (Interfering commands) Commands Cj and Cjj from RAMComm interfere with each other when executed from the state σ ∈ RAM, denoted with Cj daσ Cjj, if
(accesses(Cj, σ) ∩ writes(Cjj, σ) /= ∅) V (writes(Cj, σ) ∩ accesses(Cjj, σ) /= ∅).

Given this formulation of interference, the usual notion of data races is formu- lated as follows.
Definition 5.2 (Data race) Program S has a data race when run from an initial state σ0 ∈ RAM if for some i, j and pc such that i /= j, pc(i)= vi and pc(j)= vj and
state σ ∈ RAM such that pc0, σ0 →∗ pc, σ, there exist CFG edges (vi, Cj, vj) ∈ Ti
and (vj, Cjj, vj ) ∈ Tj in the control-flow relations of threads i and j labelled with
commands Cj and Cjj from RAMComm such that
Cj,σ /~ T;	Cjj,σ /~ T;	Cj daσ Cjj.	(15)
We first prove that the existence of a thread-local interpretation for a program (as defined in Lemma 4.2) implies data-race freedom.
Lemma 5.3 Under the conditions of Lemma 4.2 with Σ = RAM and PComm = RAMComm, the program S has no data races when run from initial states σ0 satis- fying (9).
Proof Suppose the contrary: there exist i, j and pc such that i /= j, pc(i) = vi
and pc(j) = vj, a state σ such that pc0, σ0 →∗ pc, σ, CFG edges (vi, Cj, vj) ∈ Ti
and (vj, Cjj, vj ) ∈ Tj labelled with commands Cj and Cjj from RAMComm such that
(15) holds.
By Lemma 4.2, σ ∈ r ∗ G(vi) ∗ G(vj) for some r. Hence,
σ = σ0 ∗ σ1 ∗ σ2,	(16)


where

σ0 ∈ r,  σ1 ∈ G(vi),  σ2 ∈ G(vj).	(17)

Since the values of G are distinct from T, it follows that fC′ (G(vi)) и T and fC′′ (G(vj)) и T. From this and (17) we obtain fC′ (σ1) ± fC′ (G(vi)) и T. So, fC′ (σ1) и T and, analogously, fC′′ (σ2) и T. Hence, Cj, σ1 /~ T and Cjj, σ2 /~ T.

From this and the fact that Cj daσ Cjj using the definitions of ∗ and the predicate transformers for commands in RAMComm, we easily get that σ1 ∗ σ2 is undefined, which contradicts (16). The intuition behind this is that from Cj, σ1 /~ T and Cjj, σ2 /~ T it follows that both σ1 and σ2 should be defined on the same variable or location accessed by Cj and Cjj, which makes the state σ1 ∗ σ2 inconsistent. 

As a corollary of Lemma 5.3, we easily get the data-race freedom theorem.
Corollary 5.4 (Data-race freedom) Under the conditions of Theorem 4.1 with Σ = RAM and PComm = RAMComm, the program S has no data races when run from initial states σ0 satisfying (4).
Conclusion
Conceptually, the idea of our proof of soundness is simple: we show the Separation Property by induction on a derivation in the operational semantics. Our proof expresses this property directly as an invariant preserved by concurrent executions, and thus does not need to unpick concurrent executions into constituent sequential ones and there track changing splittings.
Our use of semantic proofs is inspired by program analyses based on abstract interpretation [5], which compute mappings from program points to elements of an abstract domain denoting sets of states. Proofs of soundness for such analyses rely crucially on the intentional information provided by the mappings. In fact, our proof of the Separation Property (Lemma 4.2) is almost identical to the proof soundness of a program analysis for inferring resource invariants in concurrent separation logic we have previously developed [9]. The aim of this paper has been to argue that the approach based on semantic proofs is also useful in proving the soundness of program logics and to demonstrate the corresponding techniques in a clean setting. In this paper, we presented our results for a simplistic programming language.
However, we have also applied our approach to more expressive languages, including dynamic lock allocation and deallocation, dynamic thread creation and first-order procedures; see [8]. Additionally, we have applied it to prove the soundness of a logic for verifying preemptive OS kernels [10], which establishes a form of refinement. From our experience, the approach provides a low-cost way of proving the soundness of complicated concurrency logics.
An interesting question for future research raised by our results is whether there are other ways to ensure the soundness of the conjunction rule other than requiring precision. After all, equation (14), which is the only place in the proof where preci- sion is used, may be satisfied even if the predicate q in it is imprecise. Intuitively, for the conjunction rule to be sound, the proofs being combined have to split the state in the same way at every release command in the program. One way to enforce this is to require that the postcondition of release in the proofs be computed as a function of the precondition. Unfortunately, our preliminary investigations show that straightforward formulations of such functions may invalidate the frame rule. The possible fixes are not pretty, and the appropriate solution seems to depend on

the particular class of programs considered.
Acknowledgement
We would like to thank Peter O’Hearn, Hongseok Yang and the anonymous review- ers for helpful comments and suggestions.

References
Bornat, R., C. Calcagno, P. W. O’Hearn and M. Parkinson, Permission accounting in separation logic, in: POPL’05: Symposium on Principles of Programming Languages (2005), pp. 259–270.
Brookes, S. D., A semantics of concurrent separation logic, Theor. Comput. Sci. 375 (2007), pp. 227– 270, preliminary version appeared in CONCUR’04: Conference on Concurrency Theory.
Calcagno, C., D. Distefano and V. Vafeiadis, Compositional resource invariant synthesis, in: APLAS’09: Asian Symposium on Programming Languages and Systems (2009).
Calcagno, C., P. W. O’Hearn and H. Yang, Local action and abstract separation logic, in: LICS’07: Symposium on Logic in Computer Science (2007), pp. 366–378.
Cousot, P. and R. Cousot, Abstract interpretation: a unified lattice model for static analysis of programs by construction or approximation of fixpoints, in: POPL’77: Symposium on Principles of Programming Languages (1977), pp. 238–252.
Cousot, P. and R. Cousot, Systematic design of program analysis frameworks, in: POPL’79: Symposium on Principles of Programming Languages (1979), pp. 269–282.
de Bruin, A., Goto statements: Semantics and deduction systems, Acta Inf. 15 (1981), pp. 385–424.
Gotsman, A., Logics and analyses for concurrent heap-manipulating programs (2009), phD Thesis. Technical Report UCAM-CL-TR-758, University of Cambridge Computer Laboratory.
Gotsman, A., J. Berdine, B. Cook and M. Sagiv, Thread-modular shape analysis, in: PLDI’07: Conference on Programming Languages Design and Implementation (2007), pp. 266–277.
Gotsman, A. and H. Yang, Modular verification of preemptive OS kernels, in: IFCP’11: International Conference on Functional Programming, 2011, to appear.
Hayman, J. and G. Winskel, Independence and concurrent separation logic, in: LICS’06: Symposium on Logic in Computer Science (2006), pp. 147–156.
O’Hearn, P. W., Resources, concurrency and local reasoning, Theor. Comput. Sci. 375 (2007), pp. 271– 307, preliminary version appeared in CONCUR’04: Conference on Concurrency Theory.
O’Hearn, P. W., H. Yang and J. C. Reynolds, Separation and information hiding, ACM Trans. Program. Lang. Syst. 31 (2009), pp. 1–50, preliminary version appeared in POPL’04: Symposium on Principles of Programming Languages.
Parkinson, M., R. Bornat and C. Calcagno, Variables as resource in Hoare logics, in: LICS’06: Symposium on Logic in Computer Science (2006), pp. 137–146.
Reynolds, J. C., Separation logic: A logic for shared mutable data structures, in: LICS’02: Symposium on Logic in Computer Science (2002), pp. 55–74.
Yang, H., O. Lee, J. Berdine, C. Calcagno, B. Cook, D. Distefano and P. O’Hearn, Scalable shape analysis for systems code, in: CAV’08: Conference on Computer Aided Verification, LNCS 5123 (2008).
Yang, H. and P. W. O’Hearn, A semantic basis for local reasoning, in: FOSSACS’02: Conference on Foundations of Software Science and Computation Structures, LNCS 2303 (2002), pp. 402–416.
