Egyptian Informatics Journal 19 (2018) 63–73








Full length article
Hybrid methods for feature extraction for breast masses classification
Mohamed A. Berbar
Faculty of Electronic Engineering, Menoufia University, Menouf 32952, Egypt



a r t i c l e  i n f o 


Article history:
Received 16 October 2016
Revised 30 April 2017
Accepted 25 August 2017
Available online 9 September 2017


Keywords:
Mammogram
Hybrid methods for feature extraction Grey level co-occurrence matrix Wavelet based contourlet
Statistical features
Breast mass classification
a b s t r a c t 

This paper is focusing on feature extraction methods for malignant masses in mammograms and its clas- sification. It proposes seven texture features for GLCM method and to be applied on sub-images to enhance its performance. It also proposes three hybrid methods named Wavelet-CT1, Wavelet-CT2 and ST-GLCM. The three hybrid methods are merging two types of different features. In this research, we
divide the region of interest image into s × s sub-images and a contrast stretching stage is applied before
extracting the features from each sub-image. This research also introduces two Contourlet methods (CT1 and CT2). The feature extraction methods are applied on each sub-image of ROI. CT1 is applying Contourlet at level 4. CT2 is applying Contourlet at levels [4321]. GLCM uses seven texture features. Wavelet-CT1 is applying CT1 method to all bands of wavelet coefficients at level one. Wavelet-CT2 is merging high frequency bands of wavelet at level one with contourlet coefficients of CT2. ST-GLCM merges seven statistical features and seven texture features extracted from Grey level Co-occurrence Matrix (GLCM). The proposed methods are compared with multi-resolution feature extraction methods using discrete wavelet, ridgelet and curvelet transform. SVM is used for classification. Images from Digital Database for Screening Mammography (DDSM) and Mammograms Image Analysis Society (MIAS) database are used for evaluation. The performance of proposed methods ST-GLCM, GLCM, Wavelet-CT1 and Contourlet (CT2) outperform all current existing feature extraction methods in terms of AUC measure. The extracted number of features by using GLCM or ST-GLCM is small compared to multi-resolution features.
© 2018 Production and hosting by Elsevier B.V. on behalf of Faculty of Computers and Information, Cairo
University. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/
licenses/by-nc-nd/4.0/).





Introduction

Early detection of breast cancer helps in avoiding surgeries and increases the probability of patient’s survival. The abnormal signs are the presence of masses and calcifications which may indicate cancer. Screening mammography is the most common test to search for cancer and is recommended to be done regularly for women aged 40 or above even in the absence of symptoms by the American Cancer Society (ACS) [1,2]. Radiologist detects breast cancer in mammograms by visual inspection which leads to miss- ing some features and false diagnosis. Statistical studies show that radiologist who uses visual inspection have an error rate of 10–30%

E-mail address: m_berbar@hotmail.com
Peer review under responsibility of Faculty of Computers and Information, Cairo University.
for the detection of malignant masses [3]. The computer aided diagnosis (CAD) system can help to reduce that error. The most important benefit of CAD systems for breast cancer screening is the confidence of the final decision if the CAD decision is taken as a second opinion by radiologists in classifying breast cancer [4]. CAD system serves as second opinion and helps to enhance sensitivity of diagnosis by radiologists. For validating the perfor- mance, we and many researchers are using two popular databases for mammography for testing their features extraction methods. The first one is Digital Database for Screening Mammography (DDSM), which is a benchmark database for breast cancer detec- tion [5]. 1024 samples of digitized films are used. Each pixel is rep- resented with a 16-bit word and has been digitized to 42:50-mm
pixel. The Mammographic Image Analysis Society (MIAS) is the
second database used for evaluation [6]. Films have been digitized to 200-mm pixel edge with a Joyce-Loebl scanning microdensito- meter, a device linear in the optical density range 0–3.2 and repre- senting each pixel with an 8-bit word. The database contains 291 digitized films with resolution 1024 × 1024. Mammographic images are available via the Pilot European Image Processing



http://dx.doi.org/10.1016/j.eij.2017.08.001
1110-8665/© 2018 Production and hosting by Elsevier B.V. on behalf of Faculty of Computers and Information, Cairo University. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).



Archive (PEIPA) at the University of Essex. Our proposed methods are implemented using MATLAB as a programming language and using the two mentioned databases of mammogram images for testing. The DDSM samples consist of 512 normal breast images and 256 malignant images. The MIAS samples are 54 normal and 237 malignant masses images.
Two important stages of a CAD system for mass detection are the detection of suspicious Regions Of Interest (ROI) in mammo- gram images and then the classification of these ROIs into masses (malignant) or normal cases. One of the main stages in the classi- fication of ROIs is feature extraction, which highly affects the clas- sification rate. Our research is for developing reliable CAD system and the focus in this paper in producing robust feature extraction methods for mass detection. To improve the efficiency and preci- sion of a CAD system, it is important to extract the most discrimi- native features in an efficient way. Texture features have been commonly used in the analysis and interpretation of mammogram images [7,8]. Texture features based approaches use Gabor filters [9], Local Binary Pattern (LBP) [10,11], and Discreet Cosine Trans- form (DCT) to encode texture information of mammogram images [12]. Many researches focused on feature extraction and proposed many techniques for morphological features, intensity features, and multi-resolution based features. Multi resolution analysis such as Wavelet [13–17], Contourlet [18], Ridgelet [19,20] and Curvelet [20–23] have been used also for features extraction. Discrete wave- let transform is suitable to represent information of objects with point singularities and it can provide localization information about the interesting object in spatial and frequency domains. Wavelet coefficients represent information about an object at dif- ferent scales and limited directions (horizontal, vertical and diago- nal). Ridgelet transform could be used to provide better edge detection tool than wavelet because it captures line singularities in a better way. The Ridgelet is effective mainly in detecting linear radial structures. Curvelet transform is effective in detecting image discontinuities along curves instead of radial directions. Wavelet captures mainly point singularities whereas Curvelet transform is good for capturing curved singularities. The Contourlet Transform (CT) is another replacement which offers directional decomposi- tion for image representation with less complexity. It achieves directional decomposition using Directional Filter Bank (DFB) and captures curved singularities. Using a hybrid method of wavelet and contourlet captures point singularities as well as curved singu- larities. That was the motivation to propose wavelet based con- tourlet Wavelet-CT1 and Wavelet-CT2 methods. Some researchers have used Gray Level Co-occurrence Matrix (GLCM) for extracting second-order texture features from image [24– 26,27]. GLCM features give excellent classification rate with face gender classification [28] and statistical features proved reliability in [11] for breast masses classification when merged with LBP fea- tures. The results of [11] and [28] motivated us to combine both GLCM features and statistical features in the proposed ST-GLCM method.
Firstly, before applying any extraction approach, a preprocess- ing stage is applied to increase the performance of the feature extraction method, and then the original ROI image is divided into
s × s divisions (sub-images), each sub-image is resized to m × m
pixels. The feature extraction method is applied on each sub- image. The extracted features from sub-images have been concate- nated into one vector which is fed into classification stage. To get
the appropriate division s × s of an original ROI image and size
m × m of the sub-image, different divisions of the original image and different sizes of the sub-image were tested. The effects of fea- tures descriptor in classification rate are compared to find the best appropriate division and the appropriate size for the sub-image.
Wavelet-CT1 is applying Contourlet with level 4 on all bands of wavelet coefficients at level one. Wavelet-CT2 is merging high fre-
quency bands of wavelet at level one with Contourlet coefficients at levels [4321]. GLCM and ST-GLCM methods extract few fea- tures. ST-GLCM merges seven statistical features and seven texture features extracted at different directions of h from GLCM. We also employ the multi-resolution features using Discrete Wavelet, Rid- gelet and Curvelet transforms on sub-images of the ROI. The per- formances of all proposed methods are analyzed and compared. To examine the effectiveness of the proposed feature extraction methods, we employed Support Vector Machine (SVM) to classify suspicious ROIs into masses and normal cases. The best results were with using RBF kernel for SVM with certain tuning parame-
ters of c and c. The tuning parameters and the calculated kernels
of the SVM does not fall under the focus of this paper, and for more details of how the parameters are computed and the kernel is selected see the paper [29].
This research contribution are summarized in the following paragraph. It proposes seven texture features for GLCM method and to be applied on sub-images to enhance its performance. It also proposes three hybrid methods named Wavelet-CT1, Wavelet-CT2 and ST-GLCM. The three hybrid methods are merging two types of different features. The performances of all proposed methods are analyzed and compared. We implement Wavelet, Contourlet (CT1), Contourlet (CT2), Ridgelet, Curvelet, and Statistical methods. The feature extraction methods are applied on each sub-image of ROI. Dividing the image into sub-images enhances the perfor- mance of all proposed and implemented methods and got better results in terms of accuracy, and AUC measure. The method Con- tourlet (CT2) is implemented and applied in a new way which enhances the performance of Contourlet. Extracting Ridgelet fea- tures from the sub-images gives high Sensitivity and the highest number of features compared to other methods.


Related works

Reyad et al. [11] provided a comprehensive study of the effects of some feature extraction methods to be used in CAD system for classification of masses. The feature extraction methods are LBP, statistical measures. The evaluation is performed using DDSM database. The best obtained accuracy rate for masses classification is 98.63 when fusing both of statistical and LBP features. They implemented wavelet and contourlet without division of the ROI image. They proved that the highest accuracy rates of masses clas- sification are obtained using the biorthogonal wavelet filter ‘bior1.1’ to the third level and using the directional filters ’pkva’ and ’pkva8’ for contourlet to the fourth level. Berbar et al. [12] pro- posed a hybrid transform method WTDFB. WTDFB extracts multi- resolution and multi-directional texture information by employing a hybrid of Discrete Wavelet Transform (DWT) and Directional fil-
ter bank (DFB). After reading the ROI image, it is divided into 3 × 3
sub-images and each sub-image is resized to (128×128) pixels. They applied DFB decomposition on only the approximate coeffi- cients (LL sub-band) resulted from applying one level wavelet decomposition on each sub-image. DFB decomposition is imple- mented for four levels in binary tree decompositions that leads to 24 subbands. They obtained accuracy of 98.43% and sensitivity of 98%. Junior et al. [14] classified mammograms into masses and non-masses tissues based on five steps: image acquisition, his- togram equalization, wavelet transform texture characterization for multi-resolution analysis and SVM for classification. They applied their method on DDSM database and used Moran’s Index and Geary’s Coefficient for feature extraction. They obtained 98.36% of specificity and 98.13% of sensitivity. Nascimento et al.
[15] used multi-resolution analysis for feature extraction of mam- mogram image. These features were computed using three differ- ent  wavelet  functions  bi-orthogonal  3.7,  Symlet  8 and



Daubechies 8. They used the polynomial classification algorithm for the classification of the mammogram images as normal or abnormal. Their system was evaluated using only 360 digitized mammograms from DDSM database and the results of that algo- rithm had Az (area under the ROC curve) of 0.98 ± 0.03. Dual Tree M-Band Wavelet Transform (DTMBWT) has been used by Suba and Nirmala [17] to represent the digital mammogram in a multi- resolution manner and classify the tissue either malignant or benign by SVM classifier. They achieve 91.83% accuracy on Mam- mographic Image Analysis Society (MIAS) database images. lrah- man and Hamid [24] used GLCM for breast ultrasound images
enhancement at four directions of h (0, p/4, p/2, 3p/4). GLCM is
also used for breast masses classification at four directions of h (0, p/4, p/2, 3p/4) by Puneeth and Krishna [25] and Khuzi et al. [27]. The authors in [25] calculate entropy, correlation, inverse dif-
ference moment, uniformity and contrast. In [27], the authors cal- culate contrast, energy and homogeneity and correlation. In [48], the authors calculate contrast, energy, homogeneity and correla- tion of gray level values from GLCM at a distance of d = 1 and for direction of h given as 0°, 45°, 90° and 135°.
For normal and abnormal classification, the result shows that
RBFNN’s accuracy is 93.98%, while the accuracy of benign and malignant classification is 94.29%.
The main problem with [25,27] is the small number of samples about 20 abnormal and another 20 normal images are used for evaluation which is not enough to judge their methods.
Fractal method is used by Beheshti et al. [30] for detection and diagnosis of abnormalities in mammograms. Their data set consists of 168 images that were selected by a radiologist and their abnor- malities were also confirmed by biopsy. They also applied the algo- rithm on a set of images obtained from MIAS database. Performance of classifying asymmetric lesions and normal tissues under various combinations of features using image enhancement was 94.01 for accuracy and 91.54 for sensitivity using fractal fea- tures. Rouhi et al. [31] extracted Shape, Intensity, and textural fea- tures and used genetic algorithm to select best features from the set of extracted features. Multilayer perceptron (MLP) neural net- work are used for classification of the mammograms as malignant or benign. Different classifiers (such as SVM, and KNN) with using 10-fold cross validation are used for comparison. Their method was evaluated using 54 benign and 39 malignant tumors from MIAS database, and 170 mammography ROIs containing 74 benign and
96 malignant tumors from DDSM database were taken. The obtained sensitivity, specificity, and accuracy rates were 92.70%, 90.54%, and 90.16, respectively for MIAS. The obtained sensitivity, specificity, and accuracy rates were 96.87%, 95.94%, and 96.47%, respectively for DDSM.
Li et al. [32] proposed a combined scheme of texton analysis with multiple sub-sampling strategies to classify masses as benign or malignant in mammograms. Sub-sampling strategies with either uniform or non-uniform intervals are generated and a k- nearest-neighbor (KNN) classifier is trained for each subsampling strategy. Every subsampling strategy captures one discriminating structure. Their method is tested on 114 mass regions from DDSM database. The classification accuracy rate reaches 85.96%, which is lower than some existing texture based methods. The main prob- lem with [32] is the small number of samples. Shearlet transform is also used for feature extraction by Anusha [33]. He used SVM as classifier of mass as either benign or malignant and produced classification accuracy of 94% with the MIAS database. 50 images have been taken to calculate the system performance which is not enough to judge the performance. In [49] the extracted fea- tures include Shape of the lesions, Area, Compactness, Fractal, Cen- tral Moment Eccentricity, Spread, Boundary descriptors and the average gray level as density measure. AdaBoost classifier is used to determine the probability of benign and malignant masses.
The obtained results on (MIAS) database were 91.43% as a mean accuracy.
The literature review that presented above showed that the interpretation of the results is still based on heuristics and the dis- cussed methods are using different databases for validation and small set of samples [25,27,30–33,48], for training and testing. In addition, the performance factors affecting the results of different schemes include the type of classifier and the method of extracting features. This situation indicates that there is still space for further improvement and it is the motivation for us to propose new fea- ture extraction techniques and compare our results with others who use the same classifier and database.

Methods

From the literature survey, there are many feature extraction methods developed by the researchers but still the wavelet based contourlet methods have not been tested and evaluated enough in extracting features for mammogram classification. This encour- ages us to do more research in merging wavelet and contourlet fea- tures. In this section, we present the details of proposed methods as feature extraction tools. New hybrid methods merging con- tourlet and wavelet features named Wavelet-CT1 and Wavelet- CT2 are proposed. The proposed methods are compared with six methods based on GLCM texture features, statistical features, and multi-resolution features using discrete wavelet, ridgelet, curvelet and two methods using contourlet transforms. ROI is divided into s
× s (where s × s = 1 × 1 (without divisions), or 2 × 2, or.. ., or
5 × 5) which leads to (1, or 4, or 9, or 16, or 25) sub-images before features extraction. All the mentioned divisions are tested. The sub-image is resized into m × m size (64 × 64, or 128 × 128, or
256 × 256). All of these m × m sizes of the sub-image are tested and its performances are compared and finally (64 × 64) is decided
to be used. All methods including the new proposed methods are implemented and tested. The features extracted from each sub- image are concatenated to each other in one vector. Because the number of coefficients resulted from the multi-resolution methods is huge, a ratio k (5–90%) of biggest coefficients resulted from each sub-image is selected as discriminative features. A ratio k (5–90%) is tested to find the best ratio that produces the best accuracy. SVM is used for classification with all feature extraction methods.

Pre-processing stage

A preprocessing stage has been implemented and applied before extracting features for all methods under processing. It has been proved to enhance the performance. We apply contrast stretching function ‘stretchlim’ with limiting lower and upper lim- its that can be used for contrast stretching image by 1% of all pixel values [34], see Fig. 1

GLCM methods (GLCM and ST-GLCM)

GLCM describes how frequently two pixels with gray-levels a, b appears in the image separated by a distance d in direction h. The number of occurrences of the pair of gray levels (a, b) which are at a distance d apart in the sub-image is recorded in the entry (a, b) in the gray-level co-occurrence matrix. It scales the values in image into g levels so they are integers between 1 and g. The g numbers of gray-levels determine the size of the gray-level co-occurrence
matrix to be g × g. GLCM is used with varying direction h {0, p/4,
p/2, 3p/4} and distance d. So we will have number of d GLCMs each is g × g in size for each certain h. In this research, we decided to use
g = 8 for MIAS database and g = 16 for DDSM which based on our experimental results and compatible with the pixel depth of each


and using the equation provided by Soh and Tsatsoulis [35]. The two measure values of homogeneity because homogeneity mea- sure the function developed in the Matlab library gives different values compared to the implemented function proposed by [35].
ST-GLCM method merges the seven statistical features (Mean, Standard deviation, Smoothness, Skewness, Entropy, Energy, Kur- tosis) and the seven texture features extracted from GLCM algo-
rithm. ST-GLCM features are extracted from 3 × 3 sub-images of
the ROI as shown in Fig. 2. The total number of features ‘‘values” per image in ST-GLCM method is computed using the following equations:
Number of features (GLCM)
= number of directions × 0.5 × d
× number of extracted GLCM features
× number of sub — images	(1)








(b) Breast normal sample (DDSM): before and after contrast stretching.

Fig. 1. Original ROI, and the result of applying contrast stretching [34].


database. To reduce the number of extracted features values and reduce the burden on the classifier, the features may be computed in two options. The first is to work on every GLCM of the GLCMs resulted from the image or the second option is to work on every sum of pairs of GLCMs. The second option reduces the number of the features values to 50%. The second option gives the same accu- racy result as the first option and each feature in certain direction h has d/2 values. At the beginning of using GLCM, we used the 22 features mentioned in [28] but the sensitivity rates are not accept-
able. We used GLCM to extract texture features at three directions (0, p/4, and p/2). The selection of directions based on experimental tests and the selection of GLCM features based on the literature
survey [25–27] and experimental tests. Selection of best features is done heuristically. In order to select the best group of features, GLCM is used with varying h direction {0, p/4, p/2, 3p/4} and vary-
ing distance d and using different combination of features resulted from using the four directions. Experimental results of applying GLCM on mammographic images proved that using of features
from three directions of h {0, p/4, p/2} is enough to give the highest
accuracy.
The GLCM algorithm is applied on sub-images of 3 × 3 divisions. The extracted seven features from the GLCM are Contrast [26,35], Inverse Difference Moment [26,35], Entropy [35], Energy [26,35], Sum average [36] and two values of Homogeneity using matlab
Number of features (ST — GLCM)
= Number of features (GLCM)
+ 7statistical features number of sub — images	(2)
where number of directions = 3.
In next subsection, we present the methods that are based on multi-resolution analysis including our hybrid feature extraction methods Wavelet-CT1 and Wavelet-CT2 and two methods based on Contourlet (CT1 and CT2) at level = 4 and at level = [4321]. Con- tourlet Transform is applied using ‘pkva-pkva8’ filter for all con- tourlet methods. The other implemented multi-resolution methods to be compared with the proposed methods are based on Wavelet, Ridgelet and Curvelet.

Discrete Wavelet Transform (DWT)

Wavelet is applied on each resized sub-image. The output from the DWT is four images of size equal to quarter the size of the sub- image. These images are called LL (approximation) images, LH (horizontal details), HL (vertical details), and HH (diagonal details). The wavelet transform can be performed for multiple levels, where the next level of decomposition is performed using the LL image only. The authors of [11] show the results obtained with different biorthogonal wavelet filters. They proved that the best accuracy is obtained using bior1.1 filter at decomposition level 3. Based on their results, we decided to use ‘bior1.1’ filter and apply wavelet decomposition till level 3.

Ridgelet and curvelet methods

The 2-D wavelets are constructed by using one-dimensional (1- D) wavelets. It is still limited in providing directional selectivity. In 1999, new transform named Ridgelet transform was proposed by




Fig. 2. Merging Statistics and GLCM Features (ST-GLCM).



Candès and Donoho [37]. Ridgelet transform offers properties with different values when measured in different directions. The Ridge- let transform is good at representing straight-line singularities. To analyze curve singularities using ridgelet, a good idea is to consider a partition of the image, and then to apply the Ridgelet transform to the obtained sub-images. This transform is named first- generation Curvelet transform. It was first proposed by Candès and Donoho [38], [39]. Later, a considerably simpler second- generation Curvelet transform based on a frequency partition tech- nique was proposed by the same authors; see [40], [41]. The main modifications are to tile the discrete cosine domain instead of the discrete Fourier domain and to adequately reorganize the data. The second digital transformation is based on the wrapping of specially selected Fourier samples while the first is based on unequally- spaced fast Fourier transforms (USFFT). The second generation of Curvelet transforms CurveLab2.1.3 implements the Curvelet trans- forms that has been used in this paper, and is available at [42]. Sev- eral Matlab scripts are provided to demonstrate how to use this software. Both of the first and second generation transformations return a table of digital Curvelet coefficients indexed by an orien- tation parameter, a scale parameter, and a spatial location parameter.

Contourlet transform methods (CT1 and CT2)

Wavelet transform captures orientation information in the three directions (horizontal, vertical and diagonal) and cannot pro-
vide strong information about the curvatures or contours of objects. Contourlet overcomes the drawbacks of Wavelet. It decomposes an image into multi-scale and multi-orientation rep- resentation in two stages using Laplacian pyramid (LP) and direc- tional filter bank (DFB). We implemented Contourlet methods as feature extraction tools on each sub image. The mentioned filters are approved to be the best choice in extracting features from mammogram images [11]. The DFB is implemented via levels of binary tree decomposition. We propose two options of Contourlet transform. The two options named CT1 and CT2 methods. In CT1 method, Contourlet is applied using level l = 4 (see Fig. 3). In CT2, Contourlet is applied for four times for four levels with l = [4321] in binary tree decompositions that each decomposition leads to 2l sub bands with wedge-shaped frequency. In each level, the Laplacian Pyramid provides a down sampled low pass and a band pass version of the image. The band pass image is then fed into the Directional Filter Bank. This scheme is iterated in the low pass image. The coefficients are sorted and a certain ratio k% of the highest coefficients of each angular sub-band is selected. The selected highest coefficients are concatenated in one vector as shown in Fig. 4.

The proposed Multi-resolution methods (Wavelet-CT1 and Wavelet-CT2)

Wavelet-CT1 method is applying Contourlet (CT1) with level 4 on all bands of wavelet coefficients at level one. Wavelet-CT2 is




Fig. 3. The Structure of CT1 method.


Fig. 4. The Structure of CT2 method.




Fig. 5. the Structure of Wavelet-CT1.


To classify images into masses or normal, the resulted features vec- tor is feed into SVM. We employ commonly used measures of fea- ture extraction method performance: Accuracy, Sensitivity and Specificity. Sensitivity is a measure of accuracy of diagnosis of true (masses) cases. It is defined as:

Sensiti ity		TP TP + FN
%	(3)

Specificity is a measure of accuracy of diagnosis of false cases. It is defined as:

Specificity =	TN
TN + FP
%	(4)










Fig. 6. The Structure of Wavelet-CT2 method.


merging high frequency bands of wavelet at level one with Con- tourlet (CT2) coefficients at levels [4321]. The original version of Wavelet-Based Contourlet [43] was used by the author for image denoising. The image is decomposed into the low frequency LL
and three high pass bands LH, HL, and HH using Wavelet, and then
where
TP: True Positive: A patient predicted with breast cancer when he/she actually has breast cancer,
TN: True Negative: A patient predicted healthy when he/she actually is healthy,
FP: False Positive: A patient predicted with breast cancer when he/she actually is healthy, and
FN: False Negative: A patient predicted healthy when he/she actually has breast cancer.

Overall Accuracy is given as
XAccess(ti)

performing Contourlet on each high frequency sub band (LH, HL, and HH) in a given level, and start with maximum number of direc-
Accuracy = i=1
|T|
(5)

tions on the results of first level of Wavelet, and decrease the num- ber of directions at every other dyadic scale of Wavelet. Our proposed methods Wavelet-CT1 and Wavelet-CT2 merge wavelet coefficients and Contourlet coefficients in different ways so they can encode multi-resolution and multi-orientation texture microstructures. The two proposed methods are shown in Figs. 5 and 6. The 2-D wavelet decomposition is performed one level in both methods. In Wavelet-CT1, 2D wavelet transform is applied on the input sub-image for one level then Contourlet with level l = 4 are applied to the four bands LL, LH, HL, and HH resulted from Wavelet transform. In Wavelet-CT2, we considered the high fre- quency sub band (LH, HL, and HH) and ignored the low frequency sub band and applied contourlet with level l = [4321] on the input sub-image directly.

Results and discussion

Support Vector Machine (SVM) is used as classifier to validate the performance of all the proposed feature extraction methods.
where T is the set of test samples and
Access(t)=  1  if t is correctly classified
0 if t is in correctly classified
Sensitivity is the rate of detecting cancer while there is really cancer in the image. Specificity is the rate of detecting normal breast while the true state of the breast is normal. The sensitivity, specificity and accuracy are considered as the most important measures in this application so when the results show high value of sensitivity and accuracy that make the result more reliable.
We focus on accuracy and sensitivity measurements as they are much more important factors than specificity in classification of medical images as it is more important to detect true cases who are suffering cancer than detecting normal cases. For that reason we will not mention the results with high accuracy because of its high specificity and not sensitivity. The accuracy metric as a mea- sure of performance has problems because it assumes equal cost for both kinds of errors (False Positive and False negative). Receiver Operator Characteristic (ROC) plot developed to statistically model




Fig. 7. A preprocessing stage proved to enhance the performance.




Table 1
Comparing different divisions of the proposed methods (Wavelet-CT1 and Wavelet-CT2) by using DDSM database.

Wavelet-CT2 with different divisions at 10% of coefficients	Wavelet-CT1 with different divisions at 10% of coefficients













Fig. 8. Multi-resolution Methods at different ratio k%.



false positive and false negative detections. ROC is a parametric plot of the hit rate (or probability of detection) versus the false alarm rate. It is assumed by researchers in medicine and biology to be better statistical measure than most other measures. The area under the ROC curve (AUC) researchers in medicine and biology is often taken as a scalar measure of performance.
The accuracy of an SVM classifier is dependent on the choice of a proper kernel function. The RBF kernel is a reasonable first choice because of it has fewer numerical difficulties [44]. The training pro- cess is done in two phases. In the 1st phase, we tune the SVM by calculating the best parameters for the SVM as explained in [28]). The algorithm in [28] is used for tuning the parameters of





0.99
0.985
0.98
0.975
0.97
0.965
0.96
ST-GLCM and GLCM at different d



Fig. 9. GLCM and ST-GLCM at different d.


Table 2
Comparison of the performance of all methods that applied on 768 samples of DDSM database.

Method at (3 × 3) divisions	SVM parameters	Specificity	Sensitivity	Accuracy	AUC	K% (Ratio)	No. of features



Table 3
Comparison between the state of art methods using MIAS Database and SVM.




SVM c and c which produce the best Specificity, Sensitivity, and accuracy to measure the performance. In the 2nd phase, the best parameters c and c are used for training and testing the SVM using k-fold cross-validation. The options of cross validation 2, 5 and 10-
fold cross validation are tested for evaluating the performance of the classifier and compared. The best performance is when using 2-cross validation for MIAS and DDSM. The obtained results are evaluated using four common metrics specificity, sensitivity, accu- racy, and AUC to measure the performance.
A preprocessing stage has been implemented and applied before extracting features. Samples of results are shown in Fig. 7 to prove the great enhancement of the performance.
Dividing the original image into 9, 25 and 49 sub-images are tested for all methods. The best accuracy of all methods for feature extraction on DDSM and MIAS databases without dividing the orig- inal ROI image is lower than when dividing the ROI. Sample of results are shown in Table 1. The performance doesn’t increase with dividing the image into more than 25 sub-images and get worse. We found that the more dividing the original into sub- images the more increasing the execution time as we process more resized sub-images without improving the results. Applying the method on many sub-images will increase the processing time. For example processing 25 fixed-sized sub-images will take more time than processing fixed-sized 9 sub-images. Experimental
results proved that divisions of the ROI increase the performance of the features extraction methods on mammograms. The best per- formance according to AUC measure is obtained for all methods at
3 × 3 divisions (9 sub-images).
To find the best accuracy with lowest number of coefficients when using multi-resolution methods, different values of ratio k (5–90%) are tested. Fig. 8 shows specificity, sensitivity, and accu- racy with different ratios k%. Different values of d are tested to find the value of d which provides best performance and lowest num- ber of features when using GLCM and ST-GLCM methods. Fig. 9 shows AUC measure with different values of d for GLCM and ST- GLCM methods.
The proposed (3 × 3) division is decided after using different
divisions for testing for all methods. Table 2 shows a performance comparison of the proposed and implemented methods and also the SVM parameters that applied on DDSM database for other researchers to compare their works with our proposed methods. It shows also that Wavelet-CT1 and ST-GLCM are the best in AUC measure followed by Contourlet CT2 and GLCM. ST-GLCM is supe- rior in terms of number of features compared to multi-resolution features extracted by using multi-resolution methods. Multi- resolution method results huge number of features. The extracted features by using multi-resolution method are about thousands (see Table 2). The proposed methods ST-GLCM, Wavelet-CT1,


Table 4
Comparison between the state of art methods using DDSM Database and SVM.


CT2

Proposed Wavelet- CT1
Contourlet coefficients of each division of 3 × 3 divisions of the ROI
Merge of applying wavelet the Contourlet on each division of 3 × 3 divisions of the ROI
Accuracy = 98.30%
AUC = 0.98057
Sensitivity = 98.82%
Accuracy = 98.30%
AUC = 0.98637






Contourlet (CT2) and Wavelet-CT2 that applied on sub-images are very close in terms of accuracy and sensitivity. The merge of fea- tures in our proposed methods Wavelet-CT1 and ST-GLCM for fea- ture extraction gives highest AUC measure. The result of high value of sensitivity in Contourlet CT2 makes the method more reliable in cancer diagnoses. Applying Ridgelet gives high Sensitivity and unfortunately very high number of features.
The performance of all methods on MIAS is not high compared with using DDSM database. The highest result that we have gotten is sensitivity equal 97% and accuracy equal 97.89% using the pro- posed Wavelet-CT2. The performance is low with using MIAS com- pared to using DDSM because of the nature of the images in DDSM which originally 16-bits pixel depth while in MIAS 8-bits pixel
depth and DDSM has been digitized to 42:50-mm pixel while MIAS has been digitized to 200-mm pixel. For that reason, the medical images that used for CAD systems should be 16-bits pixel depth.

Comparison with related works

Tables 3 and 4 show a comparison among the proposed meth- ods and with the most recent researcher’s methods. Results of using MIAS Database are shown in Table 3 while Table 4 shows results of using DDSM Database. The researchers of previous meth- ods used incomplete database to present their work. Maximum used number is 512 samples and has been used by [11] and [12]. It is known that the increase of the number of samples from the database will decrease their classification rate. We used the data- base (malignant and normal) cases that we have and just exclude benign cases. The comparison shown in Tables 3 and 4 indicate that our methods outperform all the existing methods to the best of our knowledge even though we used bigger number of samples from the database.

Conclusion

The performance of all proposed and implemented methods got better results in terms of accuracy, and AUC measure when divid- ing the image into sub-images. The proposed method Contourlet (CT2) for feature extraction gives highest sensitivity compared to all methods. The proposed ST-GLCM outperforms all of existing methods to the best of our knowledge in the literature in terms of calculated number of features and AUC measure. The proposed methods ST-GLCM, Wavelet-CT1, Contourlet (CT2) and Wavelet- CT2 that applied on sub-images are very close in terms of accuracy. The multi-resolution methods are bad tools with MIAS database. For that reason, the medical images that used for CAD systems should be 16-bits pixel depth. We achieved high results and small number of features specially ST-GLCM method. The three proposed methods ST-GLCM, Wavelet-CT1 and Wavelet-CT2 are completely new and original and introduced for the first time. The division of the ROI enhances the GLCM performance. GLCM outperforms some common methods and needs more research. The method Contourlet (CT2) is implemented and applied in a new way which enhances the performance of Contourlet. Applying Ridgelet to sub- images gives high Sensitivity and unfortunately the highest num- ber of features.

Conflict of interest

None declared.

Funding

None
References

Bozek J, Mustra M, Delac K, et al. A survey of image processing algorithms in digital mammography, recent advances in multimedia signal processing and communications – Berlin (Heidelberg): Springer. The series Studies in Computational Intelligence. vol. 231; 2009. p. 631–57.
Jalalian A, Syamsiah BT, Mashohor HR, et al. Computer-aided detection/diagnosis of breast cancer in mammography and ultrasound: a review. Clin Imaging 2013;37(3):420–6.
Ganesan K, Acharya UR, Chua CK, et al. Computer-aided breast cancer detection using mammograms: a review. IEEE Rev Biomed Eng 2013;6:77–98. doi: http://dx.doi.org/10.1109/RBME.2012.2232289.
Warner E. Breast-cancer screening. New England J Med 2011;365(11):1025–32.
Heath M, Bowyer K, Kopans D, et al. The digital database for screening mammography. In: Proceedings international workshop on digital mammography. Medical Physics Publishing; 2001. p. 212–218. ISBN 1-
930524-00-5.
http://peipa.essex.ac.uk/info/mias.html.
Sharma V, Singh S. CFS–SMO based classification of breast density using multiple texture models. Med Biolog Eng Comput (MBEC) 2014;52(6):521–9. doi: http://dx.doi.org/10.1007/s11517-014-1158-6.
Tiedeu A, Daul C, Kentsop A, et al. Texture-based analysis of clustered microcalcifications detected on mammograms. Digital Sig Proc 2012;22:124–32.
Rangaraj RM. Ayres, Gabor filters and phase portraits for the detection of architectural distortion in mammograms. Med Biol Eng Comput (MBEC) 2006;44(10):883–94.
Xianchuan X, Zhang Q. Medical image retrieval using local binary patterns with image euclidean distance. In: Proceedings international conference on information engineering and computer science, IEEE-ICIECS, Wuhan, 19–20 Dec; 2009. p. 1–4. doi: http://dx.doi.org/10.1109/ICIECS.2009.5365709.
Reyad YA, Berbar MA, Hussain M. Comparison of statistical, LBP, and multi- resolution analysis features for breast mass classification. J Med Syst 2014;38 (9):1–15.
Berbar MA, Alqahtani A, Hussain M. Masses Classification using Discrete Cosine Transform and Wavelet-based Directional Filter Bank for Breast Cancer Diagnosis. Journal of Medical Imaging and Health Informatics 2016;6 (1):117–24.
Pereira DC, Ramos RP, Nascimento MZ. Segmentation and detection of breast cancer in mammograms combining wavelet analysis and genetic algorithm. Comput Methods Programs Biomed 2014;114(1):88–101.
Junior GB, Silva EC, Paiva AC, et al. Breast tissues classification based on the application of geo-statistical features and wavelettransform. In: Proceedings of international special topic conference on ITAB, Tokyo, 8–11, Nov; 2007. p. 227–230. doi: http://dx.doi.org/10.1109/ITAB.2007.4407388.
Nascimento MZ, Martinsm AS, Neves LA, et al. Classification of masses in mammographic image using wavelet domain features and polynomial classifier. Exp Syst Appl 2013;40(15):6213–21 [Elsevier].
Faye I, Samir BB, Eltoukhy MM. Digital mammograms classification using a wavelet based feature extraction method. In: Proceedings of second international conference on computer and electrical engineering, Dubai, 28– 30 Dec. vol. 2; 2009. p. 318–322. doi: http://dx.doi.org/10.1109/ICCEE.2009.39.
Suba C, Nirmala K. An automated classification of microcalcification clusters in mammograms using dual tree m-band wavelet transform and support vector machine. Int J Comput Appl 2015;115(20):24–9.
Moayedi F, Azimifar Z, Boostani R, et al. Contourlet-based mammography mass classification using the SVM family. Comput Biol Med 2010;40(4):373–83.
Ramos RP, Nascimento MZ, Pereira DC. Texture extraction: an evaluation of ridgelet, wavelet and co-occurrence based methods applied to mammograms. Exp Syst Appl 2010;39(12):11036–47.
AlZubi S, Naveed I, Abbod M. Multiresolution analysis using wavelet, ridgelet, and curvelet transforms for medical image segmentation. Int J Biomed Imaging. Article ID 136034; 2011. Article No. 4. doi: http://dx.doi.org/10. 1155/2011/136034.
Eltoukhy MM, Faye I, Samir BB. Breast cancer diagnosis in digital mammogram using multiscale curvelet transform. Comput Med Imaging Graph 2010;34 (4):269–76.
Majumdar A, Bhattacharya A. A comparative study in wavelets, curvelets and contourlets as features sets for pattern recognition. Int Arab J Inform Technol (IAJIT) 2009;6(1):47–51.
Francis SV, Sasikala M, Saranya S. Detection of breast abnormality from thermograms using curvelet transform based feature extraction. J Med Syst 2014;38(4):1–9 [Springer].
lrahman AA, Hamid O. Breast ultrasound images enhancement using gray level co-occurrence matrices quantizing technique. Int J Inform Sci 2012;2(5):60–4.
Puneeth L, Krishna AN. Classification of mammograms using texture features. Int J Innovat Res Develop 2014;3(7):373–7.
Haralick R et al. Textural features for image classification. IEEE Trans Syst Man Cybern 1973;3(6):610–21.
Khuzi AM, Besar R, Zaki WW, et al. Identification of masses in digital mammogram using gray level co-occurrence matrices. Biomed. Imaging Intervention J. 2009;5(3). doi: http://dx.doi.org/10.2349/biij.5.3.e17.
Berbar MA. Three robust features extraction approaches for facial gender classification. Visual Comput. 30 (1); 2014. p. 19–31. doi: http://dx.doi.org/10. 1007/s00371-013-0774-8 [Springer].



Hussain M, Wajid SK, Elzaart A, et al. A comparison of SVM kernel functions for breast cancer detection. In: Eighth international conference computer graphics, imaging and visualization, Singapore, IEEE Computer Society, 17– 19 Aug; 2011. p. 145–150. doi: http://dx.doi.org/10.1109/CGIV.2011.31.
Beheshti SMA, Noubari HA, Fatemizadeh E, et al. Classification of abnormalities in mammograms by new asymmetric fractal features. Biocyber Biomed Eng 2016;36(1):56–65.
Rouhi R, Jafari M, Kasaei S, et al. Benign and malignant breast tumors classification based on region growing and CNN segmentation. Exp Syst Appl 2015;42(3):990–1002 [Elsevier].
Li Y, Chen H, Rohde GK, et al. Texton analysis for mass classification in mammograms. Pattern Recogn Lett 2015;52(15):87–93.
Anusha DS. A hybrid scheme for mass detection and classification in mammogram. Int J Eng Sci Res Technol 2014;3(3):1591–3.
Davies E. Machine vision: theory, algorithms and practicalities. Academic Press; 1990. pp. 26–27, 79–99..
Soh L, Tsatsoulis C. Texture analysis of SAR sea ice imagery using gray level co- occurrence matrices. IEEE Trans Geosci Remote Sens 1999;37(2):780–95.
Haralick RM, Shanmugam K, Dinstein I. Textural features of image classification. IEEE Trans Syst Man Cyber SMC-3 1973(6):610–21.
Candès E, Donoho D. Ridgelets: a key to higher-dimensional intermittency? Philos Trans R Soc Lond A Math Phys Eng Sci 1999;357(1760):2495–509. doi: http://dx.doi.org/10.1098/rsta.1999.0444.
Candès E, Donoho D. Curvelets-a surprisingly effective non adaptive representation for objects with edges. In: Cohen A, Rabut C, Schumaker L, editors. Curves and surface fitting: Saint-Malo 1999. Nashville: Vanderbilt Univ.Press; 2000. p. 105–20.
Starck JL, Candes EJ, Donoho DL. The curvelet transform for image denoising. IEEE Trans Image Process 2002;11(6):670–84.
Candès E, Donoho D. Continuous curvelet transform: i. resolution of the wavefront set. Appl Comput Harmon Anal 2005;19(2):162–97.
Candès E, Donoho D. Continuous curvelet Transform. II. Discretization and frames. Appl Comput Harmon Anal 2005;19(2):198–222.
http://www.curvelet.org.
Gang L, Jing L, Quan W, et al. The translation invariant wavelet-based contourlet transform for image denoising. J Multimedia 2012;7(3):254–61. doi: http://dx.doi.org/10.4304/jmm.7.3.254-261.
Hsu CW, Chang CC, Lin CJ. A practical guide to support vector classification. Apr 15, 2010. <http://www.csie.ntu.edu.tw/~cjlin/papers/guide/guide.pdf>.
Eltoukhy MM, Faye I, Samir BB. A statistical based feature extraction method for breast cancer diagnosis in digital mammogram using multi-resolution representation. Comput Biol Med 2012;42(1):123–8 [Elsevier].
Agrawal P, Vatsa M, Singh R. Saliency based mass detection from screening mammograms. Signal Proc 2014;99:29–47 [Elsevier].
Ericeira DR, Silva AC, et al. Detection of masses based on asymmetric regions of digital bilateral mammograms using spatial description with variogram and cross-variogram functions. Comput Biol Med 2013;43(8):987–99. Paiva A. C. de.
Mellisa P, Alexander, Jeklin H, Sakka N. Mammograms classification using gray-level co-occurrence matrix and radial basis function neural network. In: International conference on computer science and computational intelligence (ICCSCI 2015).
Pak F, Kanan HR, Alikhassi A. Breast cancer detection and classification in digital mammography based on Non-Subsampled Contourlet Transform (NSCT) and super resolution, computer methods and programs in biomedicine. 22(2); 2015 Nov. p. 89–107. doi: http://dx.doi.org/10.1016/j. cmpb.2015.06.009.
