Egyptian Informatics Journal 22 (2021) 455–471











Enhanced concept-level sentiment analysis system with expanded ontological relations for efficient classification of user reviews
Asad Khattak a, Muhammad Zubair Asghar b, Zain Ishaq b, Waqas Haider Bangyal c, Ibrahim A Hameed d,⇑
a College of Technological Innovation, Zayed University, Abu Dhabi Campus, United Arab Emirates
b Institute of Computing and Information Technology, Gomal University, DIKhan, KP, Pakistan
c Department of Computer Science, University of Gujrat, Pakistan
d Department of ICT and Natural Sciences, Faculty of Information Technology and Electrical Engineering, Hovedbygget B316, Ålesund, Norway



a r t i c l e  i n f o 

Article history:
Received 21 August 2020
Revised 2 February 2021
Accepted 13 March 2021
Available online 4 April 2021

Keywords:
Machine learning techniques Support vector machine Formal concept analysis (FCA) Concept lattice
Ontological relations
a b s t r a c t 

Background/introduction: Concept-level sentiment analysis deals with the extraction and classification of concepts and features from user reviews expressed online about products and other entities like political leaders, government policies, and others. The prior studies on concept-level sentiment analysis have used a limited set of linguistic rules for extracting concepts and their associated features. Furthermore, the ontological relations used in the early works for performing concept-level sentiment analysis need enhancement in terms of the extended set of features concepts and ontological relations.
Methods: This work aims at addressing the aforementioned issues and tries to bridge the literature gap by proposing an extended set of linguistic rules for concept-feature pair extraction along with enhanced set ontological relations. Additionally, a supervised a machine learning technique is implemented for performing concept-level sentiment analysis.
Results and conclusions: Experimental results depict the effectiveness of the proposed system in terms of improved efficiency (P: 88%, R: 88%, F-score: 88%, and A: 87.5%).
© 2021 THE AUTHORS. Published by Elsevier BV. on behalf of Faculty of Computers and Artificial Intel-
ligence, Cairo University. This is an open access article under the CC BY-NC-ND license (http://creative-
commons.org/licenses/by-nc-nd/4.0/).





Introduction

Sentiment analysis (SA) is used to perceive subjective information from online reviews. This analysis gives people a swift overview of the public opinions for a certain entity, such as a hotel, and a product [18].
SA aims to provide quick information by processing the posted reviews by using machine learning (ML) methodologies instead of manually reading, that is a hard practice to decide from past experience posted online on web platforms [17,13].


* Corresponding author.
E-mail addresses: asad.khattak@zu.ac.ae (A. Khattak), zubair@gu.edu.pk (M.Z. Asghar), waqas.haider@uog.edu.pk (W.H. Bangyal), ibib@ntnu.no (I.A Hameed).
Peer review under responsibility of Faculty of Computers and Artificial Intelligence, Cairo University.

Research study motivation

Concept-level sentiment analysis is relatively a new and challenging area in text analytics. The existing studies [5,39,43,36] on concept-level SA have used a limited set of linguistic rules for extracting feature and their associated concepts. Furthermore, the aforementioned studies have used a poor selection of concept- feature pair in the form of ontological relations, which results in the less efficient classification of sentiments expressed in user reviews. To extract and classify the sentiments from a review at the concept-level, information is required to be obtained using extended ontological relationship from final reviews [43]. To acquire more efficient results, it is required to perform SA task at concept-level with extended linguistic rules and ontological relations.
Therefore, more work is required to address the aforementioned issues for efficient detection and classification of user reviews at concept-level with extended ontological relationships. The proposed work is significant in terms of an extended set of linguistic rules for concept-feature extraction and providing an expanded ontological relationship using Formal Concept Analysis (FCA) [39] for efficient sentiment classification of user reviews at concept-level.


https://doi.org/10.1016/j.eij.2021.03.001
1110-8665/© 2021 THE AUTHORS. Published by Elsevier BV. on behalf of Faculty of Computers and Artificial Intelligence, Cairo University. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).



In the proposed framework, we aim to design an enhanced concept-level SA system with expanded ontological relations to provide an efficient classification of user reviews at concept-level.

Problem statement

The SA using ontological relationships in online reviews is a challenging task due to the varying nature of ontological concepts and relations. The existing studies on concept-level SA using ontol- ogy relations [5,39,43,36] have used a limited set of concepts and features, and their ontological relations for the efficient classifica- tion sentiments in user reviews. Therefore, it is an important task to develop a concept-level SA system that overcomes the limita- tions of the aforementioned studies for efficient classification of user reviews. In this work, a concept-level SA system is proposed with an extended set of concepts and features with an enhanced set of ontology relations for efficient classification of user reviews with respect to product aspects.
This work investigated the problem of concept-level SA from online texts using ontological relationships.
An extended set of linguistic rules are proposed for concept- feature pair extraction. FCA was applied to construct the extended set of linguistic rules and finally Support Vector Machine (SVM) classifier was used to classify review text into binary sentiment classes (+ive and —ive classes) at the concept level. The goal was to develop an efficient model that could be trained on the dataset to classify the review as being that of a + ive or —ive at concept- level by extracting concept-feature pairs and constructing ontolog- ical relations using FCA.
The study aimed at proposing a concept-level SA using ontolog- ical relationship by enhancing the work proposed by [5,36,43], for efficient classification of user sentiments.

Research questions

Following are the research questions posed by this work.
RQ1: How can we extract the extended set of concepts and fea- tures to be used in classifying the user reviews?
RQ2: How can we identify extended ontological relations for efficient classification of user reviews?
RQ3: How can we efficiently classify the user reviews based on an extended set of concepts and ontological relations?

Our contributions

Following contributions are made in this study.

Proposing an extended set of linguistic rules for concept-feature extraction in user-generated product reviews.
Applying FCA for identifying an extended set of ontological rela-
tions to depict features associated with the concepts
Classifying features associated with the concepts into positive and negative classes using supervised learning-based techniques.
To estimate the efficiency of various ML methods using different
features associated with the concepts.
Comparing the efficiency of the proposed model with respect to other ML and state-of-the-art methods.
The proposed model performs better than the state-of-the-art
methods with a significant margin.

The rest of the article is organized as follows: (i) Section 2 deals with literature review, (ii) proposed methodology is presented in section 3, (iii) section 4 is about obtained results and their analysis, and (iv) finally conclusion and future work is presented in section 5.
Related work

A review of some selected literature related to concept-level SA using ontological relationship is presented as follows:
The supervised learning approaches [32] for concept-level SA have been applied in different studies. For instance, in their work on feature level sentiment classification, Shein [39] performed the Part-of-Speech (POS) tagging of words using POS tagger, then the extraction of related concepts and feature is conducted using domain ontology. Furthermore, the classification of sentiments expressed in the user reviews is performed using an SVM classifier. The results reveal that the achieved accuracy of the proposed approach is 78%. Another related study to aspect-based SA con- ducted by Varghese and Jayasree [43], used the SVM. The proposed method performs different tasks, such as (i) dependency parser, (ii) co-reference resolution, and (iii) SentiWordNet. The results depict that the accuracy achieved by the proposed approach is 78.48%. Similar to the Shein’s [39] work, which faces an issue of limited dataset size, Varghese and Jayasree [43] also used a limited dataset. Both studies aimed to handle this limitation in the future by mak- ing an increment in the dataset size and also to deal with the com- parative sentences problem for the improvement in their system’s performance. In their work on context-aware SA, Mok et al. [23] proposed an ontology-based context-aware system by utilizing the Bayesian network to overcome the complex relation ontologi- cal expression. The proposed model could be applied to the smart campus situation scenario. The system achieved satisfactory per- formance (88%) with respect to comparing methods. However, the inclusion of organizational structure could assist in providing more intelligent context-aware reasoning. There are some other studies that focus on the development of context-aware systems in the health domain. For instance, Liu et al. [22] proposed the context-aware experience detection system from online health reviews. For further investigation, there are several interesting directions, such as the inclusion of linguistic features supported by context features constraints. Types of sentiment strength could be extracted from tertiary statistics. It would be possible to get labeled sentences through patient experience via online health for- ums. Different sets of CARE network can be proposed through dif- ferent health forums. Moreover, in the area of the ontology-based context-aware system, a notable work is introduced by Rama- nathan et al. [35], using the contextual properties of the text at both sentence-structure and domain-level exerting different context-aware features. An accuracy of 73% is obtained via ontology-based SA. In another work, Fan et al. [15] proposed sentiment-oriented web-based contextual advertising by utilizing sentiments information of blog pages. The approach is experimen- tally validated using the actual blog and real ads. The sentiment detection module achieved superior performance with 74.1% preci- sion. However, a more comprehensive analysis will improve the effectiveness of the proposed system.
Twitter enables online users to express their sentiments and opinion about anything like products, events, and organizations [36]. Some of the studies have used Twitter to investigate the task of context-aware SA. For example, in their work, Ruba and Venkate- son [36] used a Twitter post to propose a custom SA tool. The method section is comprised of three steps: (i) Creation of domain ontology,
(ii) Extraction of tweets related to the features and, (iii) perform the SA on the extracted tweets using Naïve Bayes (NB) classifier. The proposed method attained performance up-gradation with respect to the state of the art studies. However, creating a completely automatic ontology technique will enhance the performance of the proposed approach. Another notable work conducted by [42], investigates the issue of contextual information via Twitter SA by modeling polarity detection as a sequential task, employing the



SVM algorithm to the entire sequence. The observed relative improvement of around 20% tweets characterized by conversational context proves that data sets provide an efficient result. Ultimately, user interaction dynamics are extremely complex in social networks and they deserve better representation about reputation authority, and influence in the future. While working on the development of context-sensitive tone lexicon for representing bipolar tone words, Babour et al. [9] achieved the highest accuracy of 77.3% via 326 usable tweets via an adjective network (AN). Furthermore, to fill the deficiency of the standard ML methods Schouten et al. [38] pro- posed the knowledge-driven solution. For both aspect detection and aspect SA, only 20% of the training data is applied to achieve the improved results as compared to standard approaches.
Effective implementation of unsupervised approaches like cluster- ing and lexicon-based method (Soni & Patel, 2014) is performed for different tasks like customer satisfaction [7], aspect-based SA [5], and context-aware sentiment lexicon [12]. In their work, Bross and Ehrig [12], proposed a novel unsupervised approach for creating context-aware sentiment lexicon via semi-structured product reviews. The high accuracy is reported during experiments. Simi- larly, following the line of unsupervised approaches, the authors Agarwal et al. [1] investigated and proposed a selective important features and aspects driven approach for the expressed opinion through the domain-specific ontology of common-sense knowledge to determine the overall sentiment of the text. The contextual senti- ment lexicon determines the further polarity of an opinion word. The accuracy of the applied method is 80.1% as compared to other methods. The problem of enriching the knowledge base can be solved using a ConeptNet. Furthermore, in the context of common sense information extraction, a novel opinion mining approach is proposed by Jain and Jain [18], to investigate public and opinion of sentiments from Twitter. Both male and female users are included at different locations of the world via concept net ontologies to mea- sure Gender concept average per city. Similar to the prior work [1], Jain and Jain explored the ConceptNet to investigate more advanced features. However, the work performed by Mukherjee et al. [26] explored the ConceptNet ontology tree to review overall polarities and accuracy. The model used in this paper achieved an accuracy of 76.06%, which is higher than the other models. Using ontology information, which captures the intrinsic specificities of product- feature relations in a given product domain.
To develop sentiment-based applications, hybrid techniques have shown promising results in different domains like politics, business, and healthcare [8]. Such techniques exploit various aspects of unsupervised, semi-supervised, and supervised methods [5]. Following the theme of a hybrid approach [5], focuses on aspect- based opinion mining. The proposed approach applies a combined framework, containing extended heuristic patterns set, a hybrid sen- timent classification unit with intensifiers support, summary gener- ation and negations. The results speak that the proposed approach outperformed the comparing methods in terms of improved Accu- racy (85%), Precision (73%) and F-measure (0.78). In the context of hybrid approaches, another notable work performed by Muhammad et al. [25], uses a combination of the supervised and lexicon-based method to address the semantic gap between prior and contextual polarity using generic lexicon to capture global context. The accu- racy of 70.6% is achieved across different social media platforms. Weichselbraun et al. [44], in their work, investigates that an auto- mated SA identifies the polarity of opinions based on ML or lexical methods. A hybrid approach is introduced with a combination of sentiment terms, context, and lexical analysis throughput, to resolve queries and improve SA. Furthermore, [50,32]inspected semi- supervised based context-aware learning approach for sentence- level sentiment using structured sentiments modeling, and global as well as local contextual information at both, intra and inter- sentential levels via posterior regularization.
A rule-based approach for SA aims to exploit an effective set of pat- terns or rules with an ability to extract specific features from the user-generated content. In this connection, Yergesh et al. [45] pro- posed an ontological model and morphological rules via SPARQL lan- guage for semantic queries using SA of Kazakh language text. The rule-based method achieves 83% accuracy with respect to compar- ing methods. However, scheduling the text is to be categorized not only into positive, negative, neutral but also to detect emotions expressed by the author via psychological models. In a similar work to opinion/sentiment extraction, Ruiz-Martinez et al. [37], identified the sentiment polarities for the financial domain using the opinion extraction approach. They obtained financial news from RSS feeds. The proposed methodology contributed towards decision support system development and functional sentiment annotation for natu- ral language resources as well as ontological resources. The accuracy outcome for this financial domain is 87.32%. Thaduri et al. [41] also follow the line of work related to the rule-based approach by demonstrating an intelligent framework for context-aware meta- database utilizing soft computing techniques. However, the designed framework needs to be considering interacting elements and each layer via a local and global variable. The different algo- rithms are to be transformed into the program for using Matlab and other interactive capabilities for checking the test data.
The aforementioned works have applied different techniques like supervised learning (SVM, and NB, etc.), unsupervised learning (lexicon-based SentiWordNet, etc.), hybrid approaches, and rule-based approaches to perform concept-level SA on the user- generated content. However, it is required to investigate more robust techniques for performing concept-level sentiment classifica- tion of user reviews.

Proposed methodology

The proposed architecture is comprised of six modules, namely: (i) Data collection (ii) Preprocessing, (iii) Extended set of concept feature extraction, (iv) Generating Ontology Representation, (v) Applying SVM classifier for sentiment classification of concept-based feature and (vi) Evaluating performance of the System, as shown in Fig. 1.

Data acquisition

This module extracts and compiles data from user-generated reviews on social media platforms (Amazon) and different publicly


Fig. 1. Proposed architecture.



available datasets. The reviews are about different smartphone products, such as: ‘‘Huwaei”, ‘‘LG Nexus”, and ‘‘Sony”. The collected dataset is stored in the Excel worksheet in a ‘‘.csv” format and used as an input in the processing module to perform further process- ing. The user reviews in the obtained dataset are categorized into two classes that are: positive and negative sentiments. The statis- tics of the acquired dataset are presented in Table 1.

Preprocessing

In this step, we pass the user reviews through preprocessing module. The preprocessing of user reviews is performed in four dif- ferent steps. (i) Tokenization: We performed the tokenization using countvectorizer provided by sklearn , where in the process of tok- enization, each input text is converted into chunks/tokens, (https:// scikit-learn.org/stable/modules/generated/sklearn.feature_extrac- tion.text.CountVectorizer.html#sklearn.feature_extraction.text.
CountVectorizer.build_analyzer) ii) Stop-word removal: During this step, all the stop words, such as ‘‘and” , ‘‘the”, ‘‘a”, and ‘‘is”, present in the user reviews are removed using sklearn countvectorizer (https://scikit-learn.org/stable/modules/generated/sklearn.fea- ture_extraction.text.CountVectorizer.html#sklearn.feature_extrac- tion.text.CountVectorizer.build_analyzer) , (iii) Case Conversion: The case of all the user reviews is converted into lowercase (https://scikit-learn.org/stable/modules/generated/sklearn.fea- ture_extraction.text.CountVectorizer.html#sklearn.feature_extrac- tion.text.CountVectorizer.build_analyzer), and (iv) POS Tagging: To assign POS tags such as: ‘‘noun”, ‘‘verb”, and ‘‘adjective” to individ- ual term, we used online POS tagger (https://parts-of-speech.info/).

Extended set of concept-feature extraction

The identification and extraction of product concepts and fea- tures underlying a given review text are performed, using the set of linguistic rules proposed by [5]. We also proposed a new set of linguistic rules. The first six linguistic rules, namely LR1, LR2, LR3, LR4, LR5, and LR6, are adapted from the existing study, and the remaining six linguistic rules: LR7, LR8, LR9, LR10, LR11, and LR12, are the newly proposed linguistic rules to extract concept- feature pair as given in Table 2. The LR7 depicts that if the first word is adjective (JJ), the second word is adjective (JJ), and the
word is a verb (VBP), the second word is an a djective (JJ), and the third word is a noun (NN), then the second word (JJ) and third word (NN) will be a bigram concept and first word (VBP) will be a feature regarding a concept. For example, in the given text: ‘‘I dis- like the video quality of LG”, the word ‘‘dislike” is a verb (feature word) and ‘‘video quality” is the adjective, noun (bigram concept). The LR11 depicts that if the first word is a noun (NN), the second word is an adverb (RB), and the third word is an adjective (JJ), then the first word (NN) is a concept and the second word (RB) and the third word (JJ) will be a bigram feature regarding a concept. For example, in the given text ‘‘I just received the Google phone and the screen is quite incredible”, the word ‘‘quite incredible” is an adverb, adjective (bigram feature word) and ‘‘screen” is the noun (concept). The LR12 shows that if the first word is noun (NN), the second word is adjective (JJ), and the third word is noun (NN), then the first word (NN) is a concept and the second word (JJ) and third word (NN) will be a bigram feature regarding a concept. For exam- ple, in the given text ‘‘The Sony phone supports screen with high quality”, the word ‘‘high quality” is adjective-noun (bigram feature word), and ‘‘screen” is the noun (concept).
Table 2 shows the aforementioned rules to extract concepts and features.
Table 2 is used to detect the corresponding concept-feature lin- guistic for an individual POS-tagged sentence in a given review. For example, after passing the given text: ‘‘The Sony phone has a superb call quality” through the POS tagger (see Fig. 2), the word ‘‘superb” is tagged as an adjective, ‘‘call” is tagged as an adjective and ‘‘qual- ity” is tagged as a noun.
In the above-mentioned example, the POS tags of ‘‘superb/JJ”, ‘‘call/JJ”, and ‘‘quality/NN” matches with LR7 (Table 3), while the term ‘‘superb” shows the feature regarding the bigram concept ‘‘call quality”. The extracted concepts and their features in a given POS tagged sentence is shown in Table 3.
Table 4 shows the sample examples related to extracted concept-feature pair.
In Algorithm 1 shows pseudocode steps of concept-feature extraction regarding concepts with their related features extraction. Table 5 presents a list of concept-feature Lexicon (E1) (see
Appendix C) that is generated as shown in Algorithm 1.

Algorithm 1. Pseudo Code Steps about Concept-Feature Extraction

third word is a noun (NN), then the second word (JJ) and third		

word (NN) will be a bigram concept and the first word (JJ) will be a feature regarding a concept. For instance, in the given text ‘‘The Sony phone has a superb call quality”, the word ‘‘superb” is adjective (feature word), and ‘‘call quality” is the adjective-noun (bigram concept). The LR8 speaks that if the first word is an adverb (RB), the second word is an adverb (RB), and the third word is a noun (NN), then the third word (NN) will be a concept and first word (RB), and the second word (RB) will be a bigram feature regarding a concept. For instance, in the given text ‘‘The LG phone comes with a very well camera”, the term ‘‘very well” is adverb- adverb (bigram feature word) and ‘‘camera” is the noun (concept). The LR9 shows that if the first word is an adjective (JJ), the second word is a noun (NN), and the third word is an adjective (JJ), then the first word (JJ) and second word (NN) will be a bigram concept and third word (JJ) will be a feature regarding a concept. For exam- ple, in the given text ‘‘The call quality of Sony phone is bad”, the word ‘‘bad” is an adjective (feature word) and ‘‘call quality” is the adjective-noun (bigram concept). The LR10 depicts that if the first
Require: POS-Tagged Pre-Processed Sentence Output: Concept-Feature Lexicon (E1)
Start
	for each POS-tagged sentence ‘‘tj” in POS-tagged sentence lexicon do
Begin
while not (concept-feature-lgrule eof) Begin
	if (POS-tagged sentence ‘‘tj” matches lgrule in concept- feature lexicon) then
Begin
	Extract concept-feature n-gram along with lgrule # from Table 3
	Collect it in concept-feature Lexicon (E1) End if
End while End for
End function




Table 1
Statistics about the acquired dataset.

Dataset#	Description	Total No. of Reviews	No. of Positive Reviews	No. of Negative Reviews D1	Phone Reviews	10,160	5080	5080


Table 2
Linguistic Rules with Examples of Concept-Feature Pair.

Linguistic Rule #	Linguistic rules for feature and concepts	Example(s)	Adaptation/proposal



Fig. 2. An Example of POS-Tagged Sentence.






Ontology construction

Ontology construction is accomplished using two steps: (i) identifying relationships, (ii) and construction of extended ontol- ogy structure.

Identifying relationships
In this module, we have used formal context (cross-table), and formal concept notations of formal concept analysis for identifying relationships, described as follows.
Formal concept analysis (FCA). Formal concept analysis is a lattice theory-based architecture and it is manipulated as a data analysis tool [4]. The FCA covers the basic notions such as formal context (cross-table), formal concept and concept lattice.
We have used Formal Concept Analysis (FCA) [39]to identify the relationship between concepts and their features. Table 6 shows, a sample set of relations and their relationship in FCA.
For example, in the input sentence: ‘‘The bad screen of Huawei phone makes reading difficult”, ‘‘screen” is a concept represented by con, ‘‘bad” is a feature represented by fea, Table 6 shows an FCA representation for the ‘‘con-fea” relationship. In Table 6, the element at the left side shows the concept (screen), and the ele- ment at the top (bad) shows the feature, whereas ‘‘X” represents a binary relationship between concept and feature.



difficult.
JJ
(Adjective
NN
Noun)

The working of the LG phone screen is slow.	DT/NN/IN/NNP/NN/NN/VBZ/JJ	{Con
NN
(Noun ,
They dislike the newly launched HTC phone camera.  PRP/VBP/DT/RB/VBN/NNP/ NN/NN	{fea
VBP
(Verb ,
fea}
JJ
Adjective)
Con}
NN
Noun)
Screen slow	LR2


Dislike camera	LR3

The high quality camera of HTC amazed me.	DT/JJ/NN/NN/IN/NNP/VBD/PRP	{bi-gram fea
JJ NN
(Adjective , Noun
Con}
NN
Noun)
High quality camera
LR4

I am satisfied with the quite incredible camera of Google phone.
PRP/VBP/VBN/IN/DT/RB/JJ /NN/IN/ NNP/NN
{bi-gram fea
RB JJ
(Adverb, Adjective
Con}
NN
Noun)
Quite incredible camera.
LR5

The battery life of Huawei phone is impressive.	DT/NN/NN/IN/DT/NNP/NN/ VBZ/JJ	{bi-gram Con
NN NN
(Noun, Noun
fea}
JJ
Adjective)
Battery life impressive
LR6

The Sony phone has a superb call quality.	DT/NNP/NN/VBZ/DT/JJ/JJ//NN	{fea
JJ
(Adjective ,

The LG phone comes with a very well camera.	DT/NNP/NN/VBZ/IN/DT/RB/RB/NN	{bi-gram fea
RB RB
(Adverb, Adverb
The call quality of Sony phone is bad.	DT/JJ/NN/IN/NNP/NN/VBZ/JJ	{bi-gram Con
JJ NN
(Adjective , Noun)
bi-gram Con}
JJ NN
Adjective , Noun) Con}
NN
Noun)

fea}
JJ
Adjective)
Superb call quality  LR7




Very well camera	LR8




Call quality bad	LR9

I dislike the video quality of LG phone for games.	PRP/VBP/DT/JJ/NN/IN/NNP/NN /IN/
NNS
{fea
VBP
(Verb,
bi-gram Con}
JJ NN
Adjective, Noun)
Dislike video quality
LR10

	I just received the Google phone and the screen is quite incredible.
PRP/RB/VBD/DT/NNP/NN/CC/ DT/ NN/VBZ/RB/JJ
{Con
NN
(Noun,
bi-gram fea}
RB JJ
Adverb, Adjective)
Screen quite incredible
LR11

The Sony phone supports screen with high quality.  DT/NNP/NN/VBZ/NN/IN/JJ/NN	{Con
NN
Noun,
bi-gram fea}
JJ NN
Adjective, Noun)
Screen high quality  LR12






Ruba and Venkateson [36] proposed an algorithm containing object-attribute relation in which P represents objects and Q represents attributes. After the tweet is input to the algorithm, the retrieval of the object is performed at step 3, whereas retrie- val of attributes is performed at step 5. The required output of the algorithm is a table covering object-attribute relations. For example, in the input sentence: ‘‘The LG with display”, ‘‘LG” is an object represented by obj, ‘‘display” is an attribute denoted by att, Table 7 shows an FCA representation for the ‘‘obj-att” relationship.
As an enhancement of the work proposed by Ruba and Ven- kateson [36], we propose to introduce a concept-feature relation- ship depicting features associated with the concepts (Algorithm 2). In the revised algorithm, ‘‘f” denotes features and ‘‘c” shows concepts. Step# 2 and 3 are used to retrieve concepts and fea- tures from the input user review. A sample output of the pro- posed algorithm is the concept-feature relation, as shown in Table 6.
Algorithm 2. Creation of Ontology for Individual Review

Input: domain(d)
Variables: e = individual tweet c = individual concept
f = individual feature Output: con_fea_table
e = retri_tweet;
c = retri_con(e);
f = retri_fea(e);
con_fea_table = (c,f)
return con_fea_table


Example: cases of Individual Sentence(Review) for Ontology Construction (Identifying relationship): We used conexp-1.3 soft- ware [2] to create a Cross Table, showing the relationship and used during ontology generation. In this section, we take different sen-



Table 4
Example(s) regarding Extracted Concept-Feature Pair.



Table 6
FCA representation for  concept-feature

Linguistic
Rule #
Linguistic rules for feature and
concepts
Example(s) of concept
feature pair
(con-fea) relationship.



Bad



Screen	X



(Adjective , Noun
LR5	{bi-gram fea
RB JJ
(Adverb, Adjective
LR6	{bi-gram Con
NN NN
(Noun, Noun
LR7	{fea
JJ
(Adjective ,

LR8	{bi-gram fea
RB RB
(Adverb, Adverb
LR9	{bi-gram Con
JJ NN
(Adjective , Noun)
LR10	{fea
VBP
(Verb,

LR11	{Con
NN
(Noun,

LR12	{Con
NN
Noun,





Table 5
Concept-feature lexicon (E1).
Noun)

Con}
NN
Noun)

fea}
JJ
Adjective)
bi-gram Con}
JJ NN
Adjective , Noun) Con}
NN
Noun)

fea}
JJ
Adjective)

bi-gram Con}
JJ NN
Adjective, Noun)
bi-gram fea}
RB JJ
Adverb, Adjective) bi-gram fea} JJ NN
Adjective, Noun)


Quite incredible camera.




Battery life impressive


Superb call quality




Very well camera




call quality bad




Dislike video quality




screen quite incredible




Screen high quality

LG	X



tences and present their relationship using relationship (cross) tables.
Review #1: ‘‘The touchpad of nokia phone is slow.”
In the above input sentence, ‘‘slow” is a feature (fea) and ‘‘touch- pad” is a concept (con) and their relationship is identified by using linguistic rule (LR2) of Table 2 and we put an ‘‘X” symbol in the cell of Fig. 3.
An example case of all Sentences(Review) for Ontology Construc- tion (Identifying relationship): In Table 8, all example cases used for relationship identification, are presented.
Algorithm 3 describes the creation of ontology for collection of reviews.

Algorithm 3. Creation of Ontology for Collection of Reviews

Input: domain(d)
Variables: E = void tweets set C = void concepts set
F = void features set Output: con_fea_table
E = retri_tweets(s);
for each e2E do
c = retri_con(e);
If c – Null then
C = C U {c};
Fˈ = retri_fea(e);
for each f 2 Fˈ such that (c , f) – £ do
F = F U {f};

User review	Concept	Feature
con_fea_table = (C,F)

1. The Sony phone has a superb call quality.	call
quality
Superb
return con_fea_table




The high-quality camera of HTC amazed me.	camera	High
quality
The LG phone comes with a very well camera.	camera	Very well
Formal context(cross-table): Fig. 4 presents a cross table, which describes a basic format for formal context. The left side elements

The bad screen of Huawei phone makes reading difficult.
I am satisfied with the quite incredible camera of Google phone.
screen	Bad

camera	Quite incredible
of a rectangular table are called concepts and the top side repre- sents feature, i.e. one row shows individual concept and one col- umn  shows  individual  feature.  The  cross  table  depicts  a

The battery life of Huawei phone is impressive.	battery	Impressive
life
The working of LG phone screen is slow.	screen	Slow
relationship among concepts and features, represented by an ‘‘X”
symbol, which illustrates that a certain corresponding concept has the corresponding feature. For example, if the concept is

The call quality of Sony phone is bad.	call
quality
I dislike the video quality of LG phone for games.  video
quality
Bad

Dislike

	I just received the Google phone and the screen is quite incredible.
	The Sony phone supports screen with high quality.
	They dislike the newly launched HTC phone camera.
screen	Quite incredible
screen	High quality
camera	Dislike







Fig. 3. Relationship (Cross) table for LR2.





Table 8
All Example Cases used for Relationship Identification.


Input sentence	Pair/Triplet	Linguistic rule

The touchpad of nokia phone is slow.	{touchpad,	LR2
slow}
Quality}, {Hate}) is a formal concept. Similarly, another formal concept form the crosstable can be derived. Fig. 5 illustrates a formal concept.

Construction of extended ontology structure
In this module, we have used concept lattice notation of formal

After few months usage, I hate the processor of Huawei Mate 10 Pro so much.
Due to poor audio quality I regret buying this phone. I would NOT recommend it AT ALL!
This Huawei smart phone has a very well display.
The frustrating issue of Nokia Lumia is that the call quality is poor.
{hate, processor}
{poor, audio quality,}
{very well, display}
{call quality, poor}
LR3 LR7 LR8 LR9
concept analysis for the construction of extended ontology struc- ture, which is described as follows.
Motivation: Anoop and Asharaf [4] proposed a concept lattice for the ‘‘cardiology” and ‘‘neurology” domain. The bottom semicircle of the concept lattice represents the disease name and the top semi- circle of the concept lattice represents the symptoms. For instance, the bottom semicircle contains ‘‘brown syndrome” as the disease

I hate the sound quality of sony phone.	{hate, sound
quality}



Table 9
The t-test on the accuracy of the given dataset (FCA VS SenticNet).






SVM)
LR10
name and ‘‘genetic trait” as the symptoms on the top semicircle of the lattice.
As a motivation of the work proposed by Anoop and Asharaf [4], we present the concept lattice for the ‘‘phone” domain. The bottom semicircle of the concept lattice represents the ‘‘concept” and the top semicircle of the concept lattice represents the ‘‘feature”. For instance, the bottom semicircle contains ‘‘touchpad” as the concept and ‘‘slow” as the feature on the top semicircle of the lattice.
Kontopoulos et al. [20] proposed a concept lattice for the ‘‘smartphone” domain in which the bottom semicircle depicts the ‘‘object” and top semicircle shows the ‘‘attributes” regarding the objects of the smart phone. For example, ‘‘Apple iphone” shows

‘‘touchpad” and the feature is ‘‘slow”, then ‘‘X” shows that ‘‘touchpad is slow”. An empty cell in a table carrying a blank symbol shows that the concept does not have a feature. For example, ‘‘touchpad is not poor”. Moreover, the cross table is used as input data for the formal concept analysis. The cross-table is known as a formal context [10].

Definition. of formal context: A formal context in FCA is a triplet: (C, F, E), where C = {Touchpad, Processor, Sound Quality, Audio Quality, Call Quality, Display} is a set of concepts, and F= {Slow, Hate, Very Well, Poor} is a set of features, whereas E is a binary relationship
between concepts and features represented as E C C × F [4].


Definition. of formal concept: A pair (P, Q) is a formal concept in a for- mal context (C, F, E), where P holds exactly those concepts, which share entire features from Q and Q holds exactly those features, which are shared over entire concepts from P [4]. For example, ({Processor, Sound
the object and the ‘‘camera” shows the attribute in the concept lat- tice. However, in our proposed approach a concept lattice is intro- duced for the ‘‘phone” domain, where the bottom semicircle of the concept lattice represents the ‘‘concept” and top semicircle repre- sents the ‘‘feature”. For example, the bottom semicircle contains ‘‘touchpad” as the concept and ‘‘slow” as the feature on the top semicircle of the lattice.

Concept lattice. The inspiration behind generating a concept lattice (see Fig. 6) is to visualize a cross table (formal context), and also to illustrate the natural concept hierarchy, occurred within a formal context [31]. The ontology lattice is a conceptual hierarchy in which the top semi-circle of a node filled with blue represents the features and a bottom semi-circle of the node represents the con- cepts [30]. Moreover, the concept-lattice consists of a root node, which is composed of a set of all concepts and an empty set of fea- tures such as: ({Touchpad, Processor, Sound Quality, Audio Quality, Call Quality, Display},{}) and a bottom node, which is composed of a set of all features and an empty set of concepts such as: ({},{Slow, Hate,




Fig. 4. Formal Context (Cross Table).




Fig. 5. Formal Concept.



Fig. 6. Concept Lattice Created from Formal Context for Phone Domain.



Very Well, Poor}) [40]. The concept-lattice is built from a cross-table (formal context) using ConExp software tool [27].
Kontopoulos et al. [20] explored ConExp software tool for cre- ation of concept lattice and we used the same analogy for gen- erating concept lattice diagram related to phone domain. . Different number of software tools can be used for the FCA namely: Lattice Miner, FCART, Concept Explorer, Galicia, Tosca- naJ, etc. [17].

Tagging the (con, fea) and (fea, con) pair
In the previous step, we received two pairs, namely (con, fea) and (fea, con) pair [43]. Now it is required to tag the features of the aforementioned both pairs. The tagging of the feature is per- formed based on the positive or negative indicative words used in the two pairs of the user review. For example, the pair (touchpad, slow) is tagged as negative, and the pair (very well, display) is tagged as positive. Now, the pairs are made input into the next module, which performs a sentiment classification of the two pairs, namely (con, fea) and (fea, con), using the supervised ML technique.
Applying SVM classifier for sentiment classification of Concept- based feature

In this module, the classification of the features related to the concept is performed using SVM Classifier.
Varghese and Jayasree [43], proposed an aspect-based SA using SVM, in which, they firstly performed a sentence level subjectivity/ objectivity classification using SentiWordNet (Esuli & Sebasitiani, 2006). After the classification, the aspect expression identification is performed by applying the POS tagging (https://www.nltk.org/ api/nltk.tag.html). The Stanford Deterministic Coreference Resolu- tion System [24,34] is used to perform co-reference resolution and the scoring of opinion words related to aspects is performed using SentiWordNet. Finally, the SVM classifier is applied for the classifica- tion of the opinion words related to aspects of the product. However, in the proposed approach, we have created a set of linguistic rules for the extraction of concepts and features. After the creation of linguis- tic rules, the concept feature relationship is identified using FCA, while the ontology is constructed using the concept lattice. Finally,



Table 10
A subset of train data.

Tweet No.	Tweets	Label of Tweets


1.	Superb call quality	Positive
2.	Very well camera	Positive
3.	Screen slow	Negative
4.	Screen is quite incredible	Positive
5.	Dislike video quality	Negative
6.	Bad screen	Negative
7.	Battery life impressive	Positive
8.	Screen high quality	Positive





the SVM classifier is implemented on the concept feature set to clas- sify the features related to the concepts. The training and testing phase used during the classification task is described as follows:

Training phase
In this phase, the training of the ML model is performed by applying the dataset [24]. The sample train set used for training the model is given in section 4 (Table 10).

Testing phase
In this phase, the trained model is used for predicting the unseen dataset labels [24]. The sample test set used for testing the model is given in section 4 (Table 11).
The workflow of the supervised learning-based sentiment clas- sification system (see Fig. 7) starts by accepting an input of pairs: (con, fea) and (fea, con) and performs classification on it using two classes, namely: positive and negative. The ML model contains both the predictor and the label at the training phase. In the next phase, the model performance is inspected on the new data for acquiring the actual predicted sentiment class.
The SVM belongs to the family of supervised learning models, which performs binary or multiple classifications on the dataset. The SVM creates a model, to map a decision line related to individ- ual class, and to separate various classes, a hyperplane is placed
Table 11
A subset of test data.

Tweet No.	Tweets	Label of tweets


1.	Call quality bad	Negative
2.	High quality camera	Positive
3.	Quite incredible camera	Positive
4.	Dislike camera	Negative


vided lines. There are two hyperplane parameters, namely regular- ization parameter ‘‘C” and kernel parameter (scaling factor) ‘‘K”, on which, the efficiency of the SVM classifier is dependent. The parameter C receives a value of 100.
The training dataset contain points, formulated as follows (Eq. (1)):
T = (x1,y1), (x2,y2), (x3,y3), ..., (xm,ym )}	(1)
Also, in terms of the set theory it is defined as:
T = {(x1, y1)|xi e Rp, yie{—1, 1}}, for i = 1..m	(2)
In Eq. (2), yi belongs to two possible values i.e. 1 or —1, each denotes the class/label of point xi. The individual xi is a p- dimensional vector. It is needed to detect the ‘maximum margin hyperplane’ in order to separate the set xi, which belongs to the yi = 1, from set xi, which belongs to the yi = -1. Mathematically, a hyperplane can be represented as follows:
w.xi + b = 0	(3)
wherein Eq. (3), w represents the normal vector to the hyperplane, and b / |w| shows the hyperplane offset from origin across the nor- mal vector w.
Fig. 8 represents the SVM hyperplane visualization in linear separable data.
Output: The result of this module is a set of triplet which con- tains the concept, its associated feature and the sentiment of the feature. The output of the classifier is recorded as given in Eqs.
(4) and (5).
Senti val = c , f , senti	(4)

during the training phase. The selection of SVM is performed on the following basis: (i) its ability to exploit a huge feature set to perform effective text classification, (ii) linear separability of the
sentiment classification task, and (iii) the proficient performance



Senti val
p


= f q,
q

cp,
r


sentir 

(5)

of SVM for sentiment classification problem in earlier studies [29]. The Jupyter notebook [3] and Python provides Support Vector Classifier (SVC), to predict the binary sentiment classes such as: positive and negative. For example, the input pair: ‘‘touchpad slow”
is labeled as a negative class. by the system.
During the training phase, the training of a classifier is performed by applying (con, fea) pairs with positive and negative labels. The probabilities P(positive|p1,.. .,pn), P(negative|p1,.. .,pn) are com- puted during the testing phase, while p1,.. .,pn, represents the pair feature vectors used for classification. The output of the classifier is a predicted sentiment label (positive or negative), if the estimated probability of the most probable class is higher than the pre- defined threshold.
In this work, we applied different kernel functions, namely lin- ear, RBF, and polynomial The linear separable dataset assists in the efficient performance of the linear function, taking less training time. Furthermore, it has a minor overfitting issue. While, in the case of the non-linear dataset, RBF is effective. The key benefit of the RBF kernel is that the training data is restrained within the pro-
where cp, and fq represents the concept, feature in a user review, and sentir represents the sentiment. It is shown in Fig. 9.

Why we used SVM?

Most text classification problems are linearly separable: The tex- tual information utilized in our work is ordered into binary labels, in view of the class labels utilized in the training dataset. Such information is linearly separable, which brings about the best exe- cution of the SVM classifier [6].
Large Feature Space: At whatever point learning text classifiers, one should deal with a great deal of (>90000) functions. It’s redun- dant that it depends on the numbers of characteristics on the grounds that the SVM classifier utilized over fitting assurance and the SVM classifier can manage such enormous feature spaces [16]. Same as a case in our dataset, where the feature space is more than 9000 so that is the reason SVM gives the best performance for classification on our dataset.
Algorithm 4 presents the proposed methodology pseudo code.




Fig. 7. Supervised Learning Technique for Sentiment Classification.


Fig. 8. SVM Hyperplane in Linear Separable Data [19].





Fig. 9. Classifier Output for (con, fea) and (fea, con) pair.


Algorithm 4. Pseudocode for the Proposed Methodology

Recall(r) =	tp
tn + tp

		where, tp = true positive and fn = false negative

Require: User Reviews
Output: Concept based feature Sentiment Class (+ve, —ve)
F-score: The mean estimation of Recall and Precision is an F- score. Numerically, it’s depicted as follows:

Main ()
2pr
2TP

Start
#Scan the entire corpus
While (there is a user review in the corpus) Do
Call Preprocessing (User Review) function
Rules Creation/Generation (Table 2)
Concept Feature Extraction (Algorithm 1)
Identify concept feature relationship using context table (Algorithm 3)
Ontology construction using concept lattice (Section 3.3)
Classify concept related features using SVM classifier (Eq. (2))
Assign sentiment class (+ve, -ve) to each feature (Eqs. (4) and (5))
End while Preprocessing(review)
tokens = tokenize (review)
for each tok in tokens
Remove stop words
Case Transformation
Apply POS Tagging
Next tok
End for
End Preprocessing (return pre-processed review) End main()





Results and discussions

In this section, we present and evaluate experimental results by answering the posed research questions.

Evaluation metrics

For looking at the productivity of various classifiers on the gained dataset, we applied diverse effectiveness assessment mea- sures: (i) Accuracy/exactness, (ii), Precision, (iii) Recall, (iv) F- Score, depicted as follows.
Accuracy: For a total number of perceptions, the rate of pre- cisely anticipated observations is known as accuracy or exactness. Numerically, it is figured as follows:
Accurcay(A) =	tp + tn
tp + tn + fn + fp
where, tp = true positive, tn = true negative, fp = false positive and fn = false negative
Precision: The positive prescient worth which gauges the preci- sion of the given model is known as Precision. For a couple of false- positive particulars, precision gets high. A Mathematical definition is introduced as follows.
tpPrecision(P) =
tp + fp
where, tp = true positive, and fp = false positive
Recall (r): It quantifies the certain cases which are accurately grouped by the model, additionally called sensitivity. High recall portrays that the quantity of + ive occurrences misclassified as – ive , is less. A numerical detailing is introduced as follows:
F — Score = p + r = 2TP + FP + FN
R = Recall, P = Precision, TP = True Positive, FP = False Positive and FN = False Negative

Answer to RQ1: ‘‘How can we extract the extended set of concepts and features to be used in classifying the user reviews?”

Concept-Feature extraction
To detect and extract the set of concepts and features underly- ing a given user review sentence, we proposed an extended set of linguistic rules (see section 3.3), which is an extension of the work performed by Asghar et al. [5]. Fig. 10 shows the extraction of con- cepts and features using the proposed linguistic rule.

Concept-feature extraction using linguistic rule LR1. The step by step process of concept-feature extraction using LR1 is pre- sented in Fig. 10. It works as follows: (i) Firstly, an input sentence is introduced, (ii) The POS tagging of the input sentence is per- formed using an online POS tagger (iii) The concepts and features present in the input sentence are extracted using LR1, that is
{fea/Adjective, Con/Noun}, which extract {bad/Adjective, screen/ Noun} from the given input text.
The same process is repeated for other linguistics rules (see Appendix E for further details)

Answer to RQ2: ‘‘How can we identify the extended ontological relations for efficient classification of user reviews?”

To answer RQ2, we applied algorithm 2(see section 3.4.1.1), which generates the cross table for a sample set of tweets.
Review #1: ‘‘The bad screen of Huawei phone makes reading difficult.”
In the above input sentence, ‘‘bad” is a feature (fea) and ‘‘screen” is a concept (con) and their relationship is identified by using lin- guistic rule (LR1) by putting an ‘‘X” symbol in the cell of Fig. 11.
The rest of the cross table for other examples are included in Appendix C.
Fig. 12 represent the combined formal context table for all of the aforementioned examples of 12 user reviews.

Applying T-test
To confirm statistically that whether the accuracy of the Pro- posed FCA for ontology building is the best when contrasted with different procedures like SenticNet, we utilized a t-test to see whether the distinction between the techniques are statistically significant. For this reason, the t-test is applied on the accuracy of both (best), in particular, ‘‘FCA and SenticNet”.
It is seen that the distinction between the techniques is gen- uinely significant. The outcomes are introduced in Table 9 and exhibited by means of a graphical portrayal (Fig. 13). Python- based (sci.py) Anaconda Framework is utilized to actualize the ideal t-test.

Answer to RQ3 ‘‘How can we efficiently classify the user reviews based on extended set of concepts and ontological relations?”

To answer RQ3, we performed experiments using SVM classifier with different parameter settings. The experimental results are




Fig. 10. Concept and Feature Extraction using LR1.





Fig. 11. Relationship (Cross) table for LR1.

shown in Appendix D. Furthermore, a partial listing of the train and test data are listed in Tables 10 and 11.

SVM parameter tuning
There is a number of SVM parameters that can be tuned to adjust the classifier efficiency for the given dataset. Specifically,
we take different values for the parameters ‘kernel’ and ‘C’ of the SVM classifier provided by the Scikit learn library [33], as shown in Table 12.
In Table 13, the parameter setting of all of the 12 SVM classi- fiers, is presented. With the kernel value linear, RBF, and poly, dif- ferent values of C, are applied. The values of accuracy, precision, recall, and F1-score of all of the 12 SVM classifiers are also shown in Table 13. After performing various experiments, it is observed that the performance of the SVM classifier with ‘kernel = rbf’ and ‘C = 1000 achieved the highest accuracy with respect to the other SVM classifiers.
In Fig. 14 the process for the classification output is presented. For example, a given user review: ‘‘The screen with larger size is an




Fig. 12. Combined Formal Context Table.


To estimate the performance of the proposed SVM classifier for the concept-based feature sentiment classification, we performed a comparison with the similar studies and the results are presented in Table 16.























Table 12














Fig. 13. Graph-based representation of performance comparison.
4.4.4. Performance comparison with Similar studies
Shein [39] performed the POS tagging of sentences using POS tagger and investigated domain ontology for the extraction of domain-related concepts and attributes. Lastly, in order to perform feature-level sentiment classification, the SVM classifier is applied, which attained an accuracy of 78%. However, in the proposed approach, after tagging the input sentences (reviews), linguistic rules are applied for the extraction of concepts and features, iden- tified in the reviews. After that, the relationship is detected between the extracted concepts and features using a context table. In the next step, the ontology for the concept and feature is con- structed using concept lattice. Finally, the classification of concept-related features is performed using an SVM classifier by achieving an accuracy of 87.5%.

SVM Parameter with different variations.



amazing feature of Samsung Galaxy” acts as an input sentence, on which linguistic rule (LR12) is applied. After the extraction of the concept-feature pair from the given review, it is made input to the ML model, namely SVM for the sentiment classification of concept-related features.

Performance comparison of the SVM classifier with other ML classifiers
Table 14 describes the performance comparison of the SVM classifier with respect to the other ML classifiers such as MNB, LR, RF, and KNN. It is observed that the best performance is achieved by the SVM classifier (Accuracy = 87.5, Precision = 88, Recall = 88, and F1-score = 88), whereas the classifier with the low- est performance is KNN having Accuracy = 56.25, Precision = 64, Recall = 56, and F1-score = 54. The objective of experimentation is to perform a concept-based sentiment classification of user reviews with extended ontological relations.

Cross-validation
We applied 10-Fold Cross-Validation to conduct experiments on multiple classifiers. The result detailed in Table 15 portrayed estimations of Mean of Accuracy, Standard Validation of Accuracy,
Varghese and Jayasree [43], proposed an aspect-based SA using SVM, in which they first performed a sentence-level subjectivity/ objectivity classification using SentiWordNet. After the classifica- tion, identification of aspect expression is performed by applying the POS tagging, Stanford Deterministic Co-reference Resolution System is applied to perform co-reference resolution [11], and the scoring of opinion words related to aspects is performed using SentiWordNet. Then the SVM classifier is applied to perform the classification of the opinion words, related to the aspect of a pro- duct by achieving an accuracy of 85.94%. However, in the proposed approach, after tagging the input sentences (reviews), linguistic rules are applied for the extraction of concepts and features, iden- tified in the reviews. After that, the relationship is identified between the extracted concepts and features using a context table. In the next step, an ontology for the concept and feature is con- structed using concept lattice. Finally, the classification of concept-related features is performed using an SVM classifier by achieving an accuracy of 87.5%.

Statistical analysis

We selected two Model M1 (SVM) and M2 (MNB), and their evaluation is performed on the given Dataset. Suppose N depicts a number of records. The error rate for SVM is e1 where e2 is used for MNB. Our main objective to verify that the difference between e1 and e2 is statistically significant (Tan Steinbench and Kumar, 2016). It is computed as follows:
r2 d ’ r2d = e1(1 — e1) + e2(1 — e2)

Mean Precision Marco, Standard Validation of Precision Marco,	n	n
Mean Recall Marco, Standard Recall Marco, Mean F-1 Marco and Standard F-1 Marco.


Table 13
Parameter setting for SVM along with performance metrics results.





Fig. 14. Process of the Classification output.





Table 14
SVM classifier VS other ML classifiers.





Table 15
Cross validation Results of different classifiers.







Table 16
Comparative result of proposed method with similar study.




Table 17
Analysis results of Models.






Error ratio variances are: e1 (1-e1)/n and e2 (1-e2)/n. (1- /)/% is the level of confidence, which is used for showing the confidence interval for dt, giving in the following equation.
dt = d  z / /2rΛd
In the above equation. We put the performance evaluation results in terms of accuracy value, accuracy difference, and error rate of both models, namely MNB and SVM classifiers. The analysis results are recorded in Table 17.
d = 0.12(1 — 0.12) + 0.25(1 — 0.25)
 
(FCA). Finally, the SVM classifier is applied to performing SA at the concept level. The performance of the proposed system is eval- uated using different metrics and also a comparison with the state- of-the-art methods is performed. Experimental results are encour- aging with improved accuracy (87.5%), precision (88%), recall (88%) and f-score (88%).

Limitations:

The dataset used in this work has a limited size, which results in performance degradation.
Using linguistic rules for concept-feature extraction has now been considered as a classical technique for performing concept-level SA.
The linguistic rules used for concept-feature extraction are lim- ited, which results in downgraded performance.
Use of FCA for the construction of ontology relations has remained a subject matter in computational and semantic web sciences for a quite long time, which can be enriched with more state-of-the methods.

3500
3500
The sentiment classification module of the proposed system is
based on the supervised learning technique, which can be

0.12 × 0.88 + 0.25 × 0.75
=	3500
0.1056 + 0.1875

=	3500
0.2931

= 3500
=0.0000837429
dt = d  z / /2rΛd.
Z//2 = 1.96 where / = 0.05
=0.1  1.96×0.0091511147
Upper Level of Models = 0.117936 and Lower-Level models are = 0.08206
The result of the upper case is 0.117205 and the lower case is 0.082795. The inside ranges esteems are not zero or under zero that is the reason we simple say that the difference is statistically significant
In the previously mentioned calculations, we applied a two- sided test for checking dt = 0 or dt – 0. Subsequent to embeddings the incentive in the previously mentioned condition, we get a cer- tainty span for dt at the 95% certainty level. Since the inward Spans esteems are zero, at that point we say that the thing that matters isn’t genuinely huge at a confidence level is 95%. The result of the Our aftereffect of the capitalized is 0.117205 and the lower case is 0.082795. The inside range esteems are not zero or under zero that is the reason we effectively say that the thing that mat- ters is measurably huge.

Conclusion and future work

This work deals with the development of a concept-level SA system with expanded ontological relations. Following tasks are carried out: (i) data collection and cleaning, (ii) extraction of extended set of concept-feature pair, (iii) construction of extended ontology structure, (iv) applying SVM classifiers for sentiment clas- sification of user reviews, and (v) evaluating the performance of the proposed system.
The proposed technique aims to classify user review text into sentiment classes (+ive and –ive classes) at the concept level. Firstly, an extended set of linguistic rules are proposed for concept-feature pair extraction. In the next phase, extended onto- logical relations are constructed using Formal Concept Analysis
replaced with other more robust methods.
A single domain dataset is used in this work, i.e. ‘‘product reviews”. Therefore, due to the single domain of the datasets used, the efficiency of the ML classifier needs further verification.
The proposed work uses a random split method for segmenting the datasets during training and testing.

Future directions

Datasets with extended size are required for conducting exper- iments to obtain more robust results.
Instead of using linguistic rules for concept-feature pair extrac- tion, state-of-the-art built-in features of different lexicons built for performing concept-level SA can be investigated.
the linguistic rules used in this study need to be extended for obtaining more reliable results.
The existing approach for constructing ontology relations using FCA can be replaced with more advanced techniques like Con- ceptNet and SenticNet.
The sentiment classification technique used in this work uses a classical ML technique, which needs to be replaced with more robust deep learning models.
It is required to conduct more experimentations with datasets in multiple domains.
There is a need to investigate other dataset splitting methods like cross-validation and others.

Human and animal rights

This study did not involve any experimental research on humans or animals; hence an approval from an ethics committee was not applicable in this regard. The data collected from the online forums are publicly available data and no personally identi- fiable information of the forum users were collected or used for this study.

Funding

This Research work was supported by Zayed University Research Incentives Fund#R19096, co-funded by Norwegian uni- versity of science and technology, Ålesund, Norway.



Declaration of Competing Interest

The authors declare that they have no known competing finan- cial interests or personal relationships that could have appeared to influence the work reported in this paper.

Appendix A. Supplementary data

Supplementary data to this article can be found online at https://doi.org/10.1016/j.eij.2021.03.001.

References

Agarwal B, Mittal N, Bansal P, Garg S. Sentiment analysis using common-sense and context information. Comput Intell Neurosci 2015;2015:30.
All things Concept Explorer. (2006). Retrieved from http://conexp.sourceforge. net/download.html.
All things jupyter. (2019). Retrieved from https://jupyter.org/.
Anoop, V., & Asharaf, S. Extracting Conceptual Relationships and Inducing Concept Lattices from Unstructured Text. Journal of Intelligent Systems.
Asghar MZ, Khan A, Zahra SR, Ahmad S, Kundi FM. Aspect-based opinion mining framework using heuristic patterns. Cluster Comput 2017:1–19.
Khattak AM, Ullah H, Khalid HA, Habib A, Asghar MZ, Kundi FM. Stock Market Trend Prediction using Supervised Learning. In: In Proceedings of the Tenth International Symposium on Information and Communication Technology. p. 85–91.
Khattak A, Habib A, Asghar MZ, Subhan F, Razzak I, Habib A. Applying deep neural networks for user intention identification. Soft Comput 2020:1–30.
Khattak A, Paracha WT, Asghar MZ, Jillani N, Younis U, Saddozai FK, et al. Fine- grained sentiment analysis for measuring customer satisfaction using an extended set of fuzzy linguistic hedges. Int J Computat Intell Syst 2020;13 (1):744–56.
Babour A, Khan JI. In: Tweet sentiment analytics with context sensitive tone- word lexicon. IEEE Computer Society; 2014. p. 392–9.
Belohlavek R. Introduction to formal concept analysis. Department of Computer Science, Olomouc: Palacky University; 2008. p. 47.
Bermudez J, & Agerri R. (2017,Feburary). corefgraph 1.2.3. Retrieved from https://pypi.org/project/corefgraph/.
Bross J, Ehrig H. Generating a context-aware sentiment lexicon for aspect- based product review mining. Web Intelligence and Intelligent Agent Technology (WI-IAT), Vol. 1. IEEE; 2010. p. 435–9.
Cardoso SD, Da Silveira M, Pruski C. Construction and exploitation of an historical knowledge graph to deal with the evolution of ontologies. Knowl- Based Syst 2020;194:105508.
Carvalho VA, Almeida JPA, Fonseca CM, Guizzardi G. Multi-level ontology- based conceptual modeling. Data Knowl Eng 2017;109:3–24.
Fan TK, Chang CH. Sentiment-oriented contextual advertising. Knowl Inf Syst 2010;23(3):321–44.
Habib A, Jelani N, Khattak AM, Akbar S, Asghar MZ. February). Exploiting Deep Neural Networks for Intention Mining. In: In Proceedings of the 2020 9th International Conference on Software and Computer Applications. p. 26–30.
Ignatov DI. Introduction to Formal Concept Analysis and Its Applications in Information Retrieval and Related Fields. In: Braslavski P, Karpov N, Worring M, Volkovich Y, Ignatov DI, editors. Information Retrieval: 8th Russian Summer School, RuSSIR 2014, Nizhniy, Novgorod, Russia, August 18–22, 2014, Revised Selected Papers. Cham: Springer International Publishing; 2015.
p. 42–141.
Jain A, Jain M. Location based twitter opinion mining using common-sense information. Global J Enterprise Inform Syst 2017;9(2):28–32.
Khandelwal R. (2018). Support Vector Machines. Retreived from https:// medium.com/datadriveninvestor/support-vector-machines-ae0ff2375479.
Kontopoulos E, Berberidis C, Dergiades T, Bassiliades N. Ontology-based sentiment analysis of twitter posts. Expert Syst Appl 2013;40(10):4065–74.
Lee H, Peirsman Y, Chang A, Chambers N, Surdeanu M, Jurafsky D. In: Stanford’s multi-pass sieve coreference resolution system at the CoNLL-2011 shared task. Association for Computational Linguistics; 2011. p. 28–34.
Liu Y, Chen Y, Tang J, Liu H. In: Context-aware experience extraction from online health forums. IEEE; 2015. p. 42–7.
Mok and H. Min, ‘‘Ontology-based context-aware model by applying Bayesian network,” 2015 12th International Conference on Fuzzy Systems and Knowledge Discovery (FSKD), Zhangjiajie, 2015, pp. 2660-2664.
Moujahid, A. (2016). A Practical Introduction to Deep Learning with Caffe and Python. Retrieved from http://adilmoujahid.com/posts/2016/06/introduction- deep-learning-python-caffe/.
Muhammad A, Wiratunga N, Lothian R. Context-aware sentiment analysis of social media. In: Advances in Social Media Analysis. Springer International Publishing; 2015. p. 87–104.
Mukherjee S, Joshi S. Sentiment aggregation using ConceptNet ontology. In: In Proceedings of the Sixth International Joint Conference on Natural Language Processing. p. 570–8.
Morales, M., Alatriste Trujillo, A., & Guerra-Hernández, A. (2004). Concept lattice learning in analytic induction.
Najmi E, Hashmi K, Malik Z, Rezgui A, Khanz HU. In: ConceptOnto: An upper ontology based on Conceptnet. IEEE; 2014. p. 366–72.
Naz, S., Sharan, A., & Malik, N. (2018, 3-6 Dec. 2018). Sentiment Classification on Twitter Data Using Support Vector Machine. Paper presented at the 2018 IEEE/WIC/ACM International Conference on Web Intelligence (WI).
Obitko, M., Snasel, V., & Smid, J. (2004). Ontology Design with Formal Concept Analysis.
Orphanides, C., Akhgar, B., & Bayerl, P. S. (2017). Discovering knowledge in online drug transactions using conceptual graphs and formal concept analysis. Paper presented at the Proceedings - 2016 European Intelligence and Security Informatics Conference, EISIC 2016.
Pannala NU, Nawarathna CP, Jayakody JTK, Rupasinghe L, Krishnadeva K. In: Supervised learning based approach to aspect based sentiment analysis. IEEE; 2016. p. 662–6.
Pedregosa et al. Scikit-learn: machine learning in python. JMLR 2011;12:2825–30.
Raghunathan K, Lee H, Rangarajan S, Chambers N, Surdeanu M, Jurafsky D, et al. In: A multi-pass sieve for coreference resolution. Association for Computational Linguistics; 2010. p. 492–501.
Ramanathan J, Ramnath R. Context-assisted sentiment analysis. In: In The 25th Annual ACM Symposium on Applied Computing. p. 404–13.
Ruba KV, Venkatesan D. Building a custom sentiment analysis tool based on an ontology for Twitter posts. Ind J Sci Technol 2015;8(13):1.
Ruiz-Martínez JM, Valencia-García R, García-Sánchez F. An ontology-based opinion mining approach for the financial domain. In: In Extended Semantic Web Conference. p. 73–86.
Schouten K, Frasincar F, de Jong F. In: Ontology-enhanced aspect-based sentiment analysis. Cham: Springer; 2017. p. 302–20.
Shein KPP. Ontology based combined approach for sentiment classification. Paper presented at the Proceedings of the 3rd International Conference on Communications and information technology, 2009.
Ta, C. D. C., & Thi, T. P. (2012, 17-19 Aug. 2012). Improving the formal concept analysis algorithm to construct domain ontology. Paper presented at the 2012 Fourth International Conference on Knowledge and Systems Engineering.
Thaduri A, Kumar U, Verma AK. Computational intelligence framework for context-aware decision making. Int J Syst Assurance Eng Manage 2014:1–12.
Vanzo, A., Croce, D., & Basili, R. (2014). A context-based model for Sentiment Analysis in Twitter. In COLING (pp. 2345-2354).
Varghese R, Jayasree M. In: Aspect Based Sentiment Analysis Using Support Vector Machine Classifier. IEEE; 2013. p. 1581–6.
Weichselbraun A, Gindl S, Scharl A. Extracting and grounding contextualized sentiment lexicons. IEEE Intell Syst 2013;28(2):39–46.
Yergesh B, Bekmanova G, Sharipbay A, Yergesh M. In: Ontology-Based Sentiment Analysis of Kazakh Sentences. Cham: Springer; 2017. p. 669–77.
