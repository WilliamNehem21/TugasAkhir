Available online at www.sciencedirect.com


Electronic Notes in Theoretical Computer Science 308 (2014) 65–86
www.elsevier.com/locate/entcs

On Grainless Footprint Semantics for Shared-memory Programs
Stephen Brookes
Department of Computer Science Carnegie Mellon University Pittsburgh, USA

Abstract
We develop an improved grainless denotational semantics for shared-memory parallel programs, building on ideas from earlier trace-based models with local states and footprints [4]. The key new idea is a more refined approach to race detection, leading to a model with better abstraction properties. Rather than treat a race condition as a “global” catastrophe [3,4], we track information about variables whose value may be tainted by a race, and retain accurate information about unaffected variables. As in the prior work, we abstract away from state changes that occur in between synchronization points, in a manner consistent with Dijkstra’s Principle [5]. We obtain a model in which only synchronization operations (for locking and
unlocking binary semaphores) are deemed to be atomic, which matches the usual implementation of these constructs in an abstract manner. Apart from this, no other atomicity assumptions are made, so our model is truly grainless. Our semantics supports compositional program analysis based on “sequential” reasoning for sequential code fragments, even when this code occurs in parallel contexts, and yields a simple semantic characterization of race-free code. The semantics validates the static constraints on “critical variables” imposed in concurrent programming methodology [6,9] and serves as a foundation for reasoning about safe
partial correctness, as in concurrent separation logic [8]. The new treatment of race detection allows for more refined analysis of racy programs. By framing our ideas and concepts in a general manner we hope that our results may be applied in a wider setting.
Keywords: concurrency, shared memory, atomicity, granularity, partial correctness, race condition, denotational semantics


Introduction
Shared-memory programs are difficult to reason about, because of the potential for interference between concurrent processes when updating the same piece of shared state. Similar difficulties arise in constructing semantic models of shared-memory programs. Most traditional models have assumed a fixed granularity of execution, for example atomic assignments or atomic reads and writes [2,10]. Such assumptions

1 This research was sponsored by the National Science Foundation under grant no. CCF-1017011. The views and conclusions contained in this document are those of the author and should not be interpreted as representing the official policies, either expressed or implied, of any sponsoring institution, the U.S. government or any other entity.

http://dx.doi.org/10.1016/j.entcs.2014.10.005
1571-0661/© 2014 Elsevier B.V. All rights reserved.

may not hold in practice, and do not hold universally, so program analysis based on these models is only valid for a limited range of implementations. In contrast, in the sequential setting it is safe to ignore granularity, so traditional semantic models for sequential programs focus simply on the initial and final states of program execution, interpreting a program as a state transformation. As is well known, this simple approach is inadequate for parallel programs [10]: the state transformation denoted by c1  c2 cannot be determined from the state transformations denoted by c1 and c2. Ideally we need to design a semantic model for parallel programs that enjoys the simplicity of state transformation semantics while retaining enough information about intermediate states to facilitate reasoning about concurrent interference, yet without making overly specific granularity assumptions.
Such concerns have stimulated an effort to design “grainless” semantic models for shared-memory concurrency, notably by John Reynolds [11] and this author [4]. Reynolds sought to avoid granularity by breaking atomic actions into instantaneous fragments, an approach that leads to a semantics based on very small steps, and therefore likely to suffer from combinatorial problems. This author developed a “footstep trace” model, a pre-cursor to the approach offered in this paper, but in retrospect we see now that this model is overly complex and fails full abstraction. Here we offer a more streamlined version of footstep trace semantics, with better abstraction properties. The main new idea involves a more refined account of race conditions, an apparently simple idea with deep ramifications in the construction of the semantics. We classify our semantic model as “grainless” because the model construction abstracts away from irrelevant information about what constitutes an atomic action, other than the usual (and reasonable) assumption that the primitive operations for synchronization (locking and unlocking resources) are atomic, and that resources behave like binary semaphores: at all stages in program execution each resource is held (having been locked and not yet unlocked) by at most one process. Our ideas should generalize to work with other atomic synchronization constructs (for instance Dijkstra-style P and V operations on semaphores) but we do not consider the details here.
We deal in this paper with a simple shared-memory language, omitting pointers. Our development builds on our prior work on trace models [2] and on concurrent separation logic [3,4], in which we combined mutable state with concurrency, so we expect to be able to adapt the new ideas presented here accordingly by working with states as stores paired with heaps. The extension to pointers and mutable state does introduce new features such as storage allocation and de-allocation, so we would need to adjust the technical details carefully. It is straightforward to incorporate locally scoped declarations, as in the block construct resource r in c which declares a local resource named r for use solely by c. For space reasons we defer these extensions and some semantic details and proofs to a fuller version of the paper.

Syntax and Static Semantics
We consider a simple shared-memory parallel language, while-programs extended with parallel composition and conditional critical regions. Identifiers (or program variables) i are assignable integer-valued variables, and region names (or resources) r take values 0 and 1, representing “available” and “unavailable”. The sets Ide of identifiers and Res of resource names are disjoint. It makes sense to keep resource names and identifiers apart, because of their different syntactic rˆoles (resources do not appear in assignment commands or in expressions) and the assumptions that we will make about their implementation (resources are only updated atomically, on entry and on exit from critical regions, whereas we make no assumptions about whether or not assignments are atomic).
The syntax of integer expressions e and boolean expressions b is standard, with the usual arithmetic and boolean constructs. For example, the abstract grammar for expressions includes:
e ::= n | i | e1 + e2 | ... 
b ::= true | false | e1 = e2 | ... 
where n ranges over integer numerals.
The static semantics of expressions is given as follows.
Definition 1
We deﬁne the sets free(e) and free(b) of identiﬁers with a free occurrence in e
and b, respectively, by structural induction:
free(n)= {}
free(i)= {i}
free(e1 + e2)= free(e1) ∪ free(e2)
free(true)= {}
free(false)= {}
free(e1 = e2)= free(e1) ∪ free(e2) The syntax of commands (or processes) c is given by:
c ::= skip | i:=e | c1; c2 | if b then c1 else c2 | while b do c |
c1  c2 | with r when b do c
A conditional critical region has the form with r when b do c. A process executing a critical region must lock the resource named r, then evaluate b; if the value of b is true the process can then “enter” the critical region and execute c, then finish by unlocking the resource. If b is false the process unlockes the resource and tries again.

Resources behave like binary semaphores with atomic operations for locking and unlocking, so conditional critical regions can be used to ensure mutually exclusive access to shared variables. We abbreviate with r when true do c as with r do c. The static semantics of commands is summarized in the following definitions.
Definition 2
We deﬁne the set res(c) of resource names with a free occurrence in c by structural induction:
res(skip)= {}
res(i:=e)= {}
res(c1; c2)= res(c1  c2)= res(if b then c1 else c2)= res(c1) ∪ res(c2)
res(while b do c)= res(c)
res(with r when b do c)= {r}∪ res(c)
Definition 3 We deﬁne the set free(c) of identiﬁers with a free occurrence in c
by structural induction:

free(skip)= {}
free(i:=e)= {i}∪ free(e)
free(c1; c2)= free(c1  c2)= free(c1) ∪ free(c2)
free(if b then c1 else c2)= free(b) ∪ free(c1) ∪ free(c2)
free(while b do c)= free(b) ∪ free(c)
free(with r when b do c)= free(b) ∪ free(c)

Dynamic Semantics
A program denotes a set of traces representing interactive computations in which the program and its environment make changes to the shared state. Each step in a trace represents the effect of a finite sequence of actions performed by the program, and records just the overall footprint. We detect the potential for race conditions, involving a write to a shared variable whose value is used in a concurrent update. A race condition can lead to unpredictable behavior, so we use T to represent the value of a variable whose value is race-dependent, a special value which taints all future computations involving that variable. In this sense we treat races as “locally” catastrophic, and we track accurately the values of variables unaffected by races.
Since we focus on footprints rather than global states we will give details of the basic definitions to be used in our development. Although these may seem unfamiliar at first, later we will establish links with more traditional semantic notions such as (global) state transformations.

States
States are finite partial functions from identifiers and resource names to values. For simplicity we let V be the set of integers and use values 0 (“available”) and 1 (“unavailable”) for resources. Let V T = V ∪ {T}. Let Var = Ide ∪ Res. We use ι to range over Var, i over Ide and r over Res. We use a list-like notation [ι1 : v1,..., ιk : vk] for states, and we may also use set-theoretic notation such as
{(ι1, v1),..., (ιk, vk)} for the same purpose.
Definition 4 The set Σ of states is given by:
Σ= {σ : Var ~fin V T | ∀r ∈ dom(σ) ∩ Res. σ(r) ∈ {0, 1}}.

We use σ and τ to range over states, and let res(σ) = dom(σ) ∩ Res be the set of resources used in σ. For a set X ⊆ Var we let σ\X = {(ι, v) ∈ σ | ι /∈ X} and σ T X = {(ι, v) ∈ σ | ι ∈ X}. When X is a singleton we write σ\ι for σ\{ι}.
Definition 5 A state σ is race-free if T /∈ rge(σ).
Definition 6 Two states σ and τ are consistent, σ ⇑ τ, iff they agree on the values of all relevant variables, i.e. ∀ι ∈ dom(σ) ∩ dom(τ ). σ(ι)= τ (ι).
Consistency of σ and τ is the same as requiring that σ T dom(τ ) = τ T dom(σ), or that σ ∪ τ is also a well-defined state. States with disjoint domains are always consistent.
Definition 7 We let [σ | ι : v] = (σ\ι) ∪ {(ι, vT)}, where vT = T if (ι, T) ∈ σ, and vT = v otherwise. This is the state obtained by updating σ with ι : v, unless σ(ι)= T, in which case the update has no effect.
We generalize this update operation to multiple updates, writing [σ | τ ] for the state obtained by updating σ with the updates in the state τ , i.e.
[σ | τ ]= (σ\dom(τ )) ∪ {(ι, vT) | (ι, v) ∈ τ}.
When τ is a singleton state [ι : v] we have [σ | ι : v]= [σ | [ι : v]], so the notations agree.
Updating is associative: when σ, τ and ρ are states we have
[[σ | τ ] | ρ]= [σ | [τ | ρ]],
so we can write [σ | τ | ρ] without ambiguity.
When X is a set of identifiers we write [σ | X '→ T] for the state obtained by updating σ with {(x, T) | x ∈ X}, i.e. (σ\X) ∪ {(ι, T) | ι ∈ X}.
Steps
Steps represent the effect of state changes, and to model footprints of programs we record just the portion of state relevant to a step, rather than the entire global state. So a step will involve a pair of states (σ, σj), where σ is the piece of state

read and σj is the piece of state written, and we decorate this pair with a flow relation R ⊆ dom(σ) × dom(σj) indicating in particular which reads influence the value of each write. We require that if (ι, T) ∈ σ & (ι, ιj) ∈ R then (ιj, T) ∈ σj, since an update based on a tainted value is also deemed to be tainted. Further, if ι ∈ dom(σj) we insist that (ι, ι) ∈ R, since a write can only be performed if its target is present in the initial state. Coupled with the previous requirement this means that once a variable has been involved in a race its value never “recovers”. Note that dom(σj) ⊆ dom(R—1): for every variable ι written in the step the set R—1(ι) ⊆ dom(σ) indicates the variables whose values in σ influence the update.
Definition 8 The set Λ of steps consists of all triples (σ, R, σj) with σ, σj ∈ Σ, such that:
R ⊆ dom(σ) × dom(σj).
For all ι ∈ dom(σj), (ι, ι) ∈ R.
If (ι, T) ∈ σ and (ι, ιj) ∈ R then (ιj, T) ∈ σj.
We use λ and μ to range over the set of steps.
Definition 9 For a step λ = (σ, R, σj), let reads(λ)= dom(σ), writes(λ)= dom(σj),
and res(λ)= dom(σ) ∩ Res. By assumption, writes (λ) ⊆ reads(λ).
For a step (σ, R, σj) and ι ∈ dom(σj), R—1(ι) is the set of variables used to compute the update for ι. Since R is surjective, we can specify the dependency relation by listing R—1(ι) for each ι ∈ dom(σj). We omit the flow relation when we intend the smallest relation satisfying the requirements, often the identity relation on dom(σj) or the empty relation when dom(σj)= {}. Where relevant we use U for the universal relation on dom(σ)×dom(σj). It is helpful to introduce names for some simple steps. In each case the intended flow relation is obvious:

lock (r) = ([r : 0], [r : 1])
unlock (r) = ([r : 1], [r : 0])
read (i, v) = ([i : v], [ ])
write(i, v, vj) = ([i : v], [i : vj])
δ = ([ ], [ ])

δ is an “idle” step, in which nothing is read and nothing is written. The other examples listed here each involve a single variable.
For steps in which multiple reads and writes occur, there may be several possible choices of flow relation, expressing different dependencies. For example, in the step ([x : 0,y : 0], {(y, y)}, [y : 1]) the update to y does not depend on the read of x, whereas in ([x : 0,y : 0], {(x, y), (y, y)}, [y : 1]) the update to y depends on both x and y. These two steps have the same overall effect, but different flow relations.
There are also racy steps such as ([x : 0], [x : T]) in which the presence of T
indicates tainting of the value of x. States (and steps) can contain both tainted

identifiers and untainted identifiers. For example ([x : T,y : 0], [x : T,y : 1]) is also a valid step; however ([x : T,y : 0], [x : 0,y : 1]) is not a valid step, because it violates the rule that a tainted variable stays tainted.
In our development, steps involving resources play a special rˆole because we interpret operations to lock and unlock resources as atomic actions. Steps with res(λ) = res(μ) = {} are resource-free, and (under certain conditions) may be composable, consecutively or concurrently, to produce a single step representing the composite effect. While it is possible to introduce more general forms of concurrent and sequential composition for actions, allowing resourced steps to be composed under reasonable compatibility conditions, we do not do so here. By limiting such composition to resource-free steps we obtain a model in which (only) locking and unlocking behave like atomic actions.
Executing steps
Although steps describe footprints, programs operate on a shared global state, and we need to characterize the effect on the global state of executing a step. Global states are also finite partial functions from variables to values, so Σ as defined before also represents the set of global states.
Given a state σ we can characterize the steps that are executable from σ, and their effect, with an enabling relation ⇒⊆ Σ × Λ × Σ. We write this as an infix relation, writing
σ =⇒λ  σj
when step λ is enabled from σ, and its execution causes the state to change to σj. The definition is intuitive: a step can only be executed from a state containing (as a subset) its start state, and its effect is to perform the updates specified in its write state, leaving all other variables unchanged. We say that the state σ enables step λ = (τ, R, τj) if σ satisfies the read properties expressed in λ, i.e. if τ ⊆ σ. When this holds, it is possible to execute this step from state σ, which produces the new state [σ | τ ].
Definition 10 The enabling relation ⇒⊆ Σ × Λ × Σ is given by:


(τ,R,τ′)
σ ======⇒ σ
iff τ ⊆ σ & σj
= [σ | τj].

Referring again to the examples introduced above, note the key facts that
read (i,v)
σ =======⇒ σ	iff i : v ∈ σ
write(i,v,v′)	j
σ ==========⇒ [σ | i : v ]	iff i : v ∈ σ
lock (r)
σ ======⇒ [σ | r : 1]	iff r :0 ∈ σ
unlock (r)
σ ========⇒ [σ | r : 0]	iff r :1 ∈ σ
Also note that lock (r) is not enabled in σ if σ(r) = 1, and unlock (r) is not enabled in σ if σ(r)= 0.

It is obvious that σ
=⇒δ
σ holds, as to be expected: one can always do nothing,

and doing nothing does not change the state.

In general when σ
=⇒λ
σj we have dom(σj) = dom(σ). Intuitively this reflects

the fact that programs in our simple language do not allocate fresh storage as they execute.
Consecutive steps
Two resource-free steps λ and μ are consecutive (or sequentially executable) if their effects are composable, λ then μ. This is the case when μ follows λ, i.e. μ can be enabled after λ, as characterized below.
Definition 11 For steps λ = (σ, R, σj) and μ = (τ, S, τj) we say that μ follows λ, written λ × μ, iff res(λ)= res(μ)= {} and τ ⇑ [σ | σj].
The requirement that τ ⇑ [σ | σj] says that the start state of μ is consistent with the effect of λ. This is equivalent to requiring that σ ⇑ (τ\dom(σj)) and τ ⇑ σj. Note that the sequential composition operation on steps is partial, only defined on steps that satisfy the imposed constraints. When λ × μ we define a single step λ; μ to represent the sequential composition (λ then μ).
Definition 12 When λ = (σ, R, σj) and μ = (τ, S, τj) and λ × μ, we deﬁne
λ; μ = (σ ∪ (τ\dom(σj)), R; S, [σj | τj | ρ]),
where ρ = {(ιj, T) | ∃(ι, T) ∈ σj. (ι, ιj) ∈ S}, and where R; S is the relation
{(ι, ιjj) | ∃ιj. (ι, ιj) ∈ R & (ιj, ιjj) ∈ S}
∪ {(ι, ιj) ∈ R | ιj /∈ dom(S)}
∪ {(ιj, ιjj) ∈ S | ιj /∈ rge(R)}

Each step specifies a (piece of) state deemed to be read and a (piece of) state to be written. The composite step λ; μ essentially reads the piece of state read by λ as well as those reads made by μ that were not affected by λ. Similarly the composite step accumulates the writes of λ and the writes of μ in the correct sequential order, adjusted as needed to preserve tainting. The term ρ here propagates the effect of racy updates from the first step. If λ is race-free ρ degenerates to the empty state, and the write effect of the cumulative step is [σj | τj] as expected. The flow relation of the composite step is R; S, obtained from the relational composition of R and S, bearing in mind that the first step may write to a variable not used in the second step, and the second step may read a variable not influenced by the first step.
Sequential composition of steps is associative, and δ is a unit.
Lemma 13 λ1 × λ2 & (λ1; λ2) × λ3 iff λ2 × λ3 & λ1 × (λ2; λ3). When these equations hold λ1; (λ2; λ3) = (λ1; λ2); λ3. Further, for all steps λ we have λ × δ, δ × λ and λ; δ = δ; λ = λ.

Proof: An easy calculation using the definitions. For all relations R, S, T we have (R; S); T = R; (S; T ), and R; {} = {}; R = R.
Examples
In each of the following cases, the two steps are sequentially executable and we show the resulting step. As usual the intended flow relations are obvious:
read (x, v); read (x, v)= read (x, v)
read (x, v1); read (y, v2)= ([x : v1,y : v2], [ ])
read (x, v); write(x, v, vj)= write(x, v, vj)
write(x, v, vj); read (x, vj)= write(x, v, vj)
write(x, v1, v2); write(x, v2, v3)= write(x, v1, v3)
write(x, v1, vj ); write(y, v2, vj )= ([x : v1,y : v2], [x : vj ,y : vj ])
1	2	1	2
write(x, v1, vj ); read (y, v)= read (y, v); write(x, v1, vj )= ([x : v1,y : v], [x : vj ])
1	1	1
In particular, reads and writes to distinct identifiers have the same effect in either sequential order. Writes to the same identifier are only sequentially composable if the value read by the second step agrees with the value written in the first step.
As expected, there is a simple relationship between sequential composition of steps and execution, the former dealing with footprint states and the latter with the global state.

λ;μ
Lemma 14 If λ × μ, then σ ===⇒ σ
iff ∃σj. (σ
=⇒λ  σj & σ
=⇒ σjj).


Concurrent steps
Resource-free steps λ and μ with compatible start states are concurrently executable, or concurrent for short. The steps conflict if one writes to an identifier on which the other one depends, in which case we record the value of the race-sensitive identifier as T. We obtain a composite step λ ⊗ μ describing the concurrent combination of λ and μ. Again this operation on steps is partial, only defined for concurrent steps.
Definition 15 Two steps λ = (σ, R, σj) and μ = (τ, S, τj) are concurrent, written
λ co μ, iff σ ⇑ τ & res(λ)= res(μ)= {}. When this holds we deﬁne
λ ⊗ μ = (σ ∪ τ, R ∪ S, [(σj ∪ τj) | X '→ T]),
where X is the set of identiﬁers whose value is susceptible to a race condition, i.e. those identiﬁers written by one of the steps with a value dependent on an identiﬁer affected by the other step:
X = {ι ∈ dom(σj) | R—1(ι) ∩ dom(τj) /= {}}
∪ {ι ∈ dom(τj) | S—1(ι) ∩ dom(σj) /= {}}.

Since σ and τ are assumed to be compatible (σ ⇑ τ ) the union σ ∪ τ is a partial function, hence a valid state. The flow relation R∪S combines the flow information from the two steps in the obvious way. Even though the union (σj ∪ τj) may not be a partial function when dom(σj) ∩ dom(τj) /= {}, performing the update X '→T does produce a partial function, hence a valid state, since X ⊇ dom(σj) ∩ dom(τj), dom(σj) ⊆ dom(R—1), and dom(τj) ⊆ dom(S—1).
We can paraphrase the above definition, perhaps in a more readable manner, as saying that λ ⊗ μ = (σ ∪ τ, R ∪ S, θ), where θ is the state with dom(θ) = dom(σj) ∪ dom(τj) and the following properties:
θ(ι)= σj(ι) if ι ∈ dom(σj) and R—1(ι) ∩ dom(τj)= {};
θ(ι)= τj(ι) if ι ∈ dom(τj) and S—1(ι) ∩ dom(σj)= {};
θ(ι)= T otherwise.
Concurrent combination of steps is an associative operation, and δ is again a unit.
Lemma 16 λ1 co λ2 iff λ2 co λ1, and when these hold λ1 ⊗λ2 = λ2 ⊗λ1. Further, (λ1 co λ2 and (λ1 ⊗ λ2) co λ3) iff (λ2 co λ3 and λ1 co (λ2 ⊗ λ3)), and when these hold (λ1 ⊗ λ2) ⊗ λ3 = λ1 ⊗ (λ2 ⊗ λ3). For all steps λ we have λ co δ and δ ⊗ λ = λ ⊗ δ = λ.
It is also obvious that λ co μ iff μ co λ, and λ ⊗ μ = μ ⊗ λ whenever both defined.
Examples
Reads and writes with compatible start states can be executed in parallel, and reads and writes to distinct variables x and y never conflict:
write(x, v1, vj ) ⊗ write(y, v2, vj )= ([x : v1,y : v2], [x : vj ,y : vj ])
1	2	1	2
read (x, v1) ⊗ read (y, v2)= ([x : v1,y : v2], [ ])
read (x, v1) ⊗ write(y, v2, vj )= ([x : v1,y : v2], [y : vj ])
2	2
read (x, v1) ⊗ read (y, v2)= ([x : v1,y : v2], [ ])
For steps affecting the same single variable, concurrent reads are benign but concurrent writes constitute a race:
read (x, v) ⊗ read (x, v)= read (x, v)= ([x : v], [ ])
write(x, v, vj) ⊗ read (x, v)= write(x, v, vj)= ([x : v], [x : vj])
write(x, v, vj ) ⊗ write(x, v, vj )= ([x : v], [x : T])
1	2
A write to x concurrent with a read of x only constitutes a significant race if the read influences the value of some identifier. The following examples show how races get handled, specifically that the correct identifiers get tainted, when the flow relations are non-trivial. To facilitate comparison with the above definition we enumerate the flow relations explicitly.

Consider a step that updates y and reads x but does not use the value of x in the update. If we concurrently write to x, the combined effect is to update both x and y as intended. For example,

([x : 1,y : 0], {(y, y)}, [y : 1]) ⊗ ([x : 1], {(x, x)}, [x : 2])
= ([x : 1,y : 0], {(x, x), (y, y), [x : 2,y : 1])
Now consider a step that updates y using a value obtained by reading x. If we concurrently write to x the value of y is tainted. For example,

([x : 1,y : 0], {(x, y), (y, y)}, [y : 1]) ⊗ ([x : 1], {(x, x)}, [x : 2])
= ([x : 1,y : 0], {(x, x), (x, y), (y, y)}, [x : 2,y : T])
In each case the concurrent composite step reflects the overall effect, and indicates tainting when relevant.
There is an obvious connection between concurrent composition and enabling. Again the former notion concerns footprint states and the latter involves the global state.
Theorem 17

λ⊗μ
When λ and μ have identity flow relations, λ co μ, and σ ====⇒ σ
there are states

λ	μ	j

σ1, σ2 such that σ
properties:
=⇒ σ1,σ =⇒ σ2, and σ
is uniquely determined by the following

σj(ι)= σ1(ι) for ι ∈ writes(λ) − reads(μ)
σj(ι)= σ2(ι) for ι ∈ writes(μ) − reads(λ)
σj(ι)= T for ι ∈ writes(λ) ∩ reads(μ) or writes(μ) ∩ reads(λ)
σj(ι)= σ(ι) for ι ∈ dom(σ) − (writes(λ) ∪ writes(μ)).
A more general relationship is derivable, involving R and S in a natural manner.

Traces
Traces are finite sequences of steps. We want to abstract away from intermediate states occurring between resource actions, in the spirit of Dijkstra’s Principle: pro- cesses should be regarded as independent, except when they synchronize [5]. Hence each step should be either an (atomic) resource action or a resource-free step repre- senting the cumulative effect of a finite computation, and we will work with traces in which adjacent resource-free steps are sequentially executable and get “mum- bled” together using sequential composition. This will indeed abstract away from the order of intermediate reads and writes occur, since a mumbled step only reports the cumulative reads and writes. We lose no generality when considering the effect on the shared state as viewed by other process running concurrently. The only way another process could be influenced by or affect an intermediate stage would be by reading or writing to a variable written by this step, causing a race condition. The

mumbled step also writes to this variable, so we would also get a race condition under these circumstances and nothing is lost by keeping only the mumbled step.
To build traces with this reduced structure we introduce a modified form of concatenation, a partial operation · that combines traces whose concatenation can be properly reduced by such mumbling, and implements this reduction.
Definition 18 λ precedes μ, written λaμ, if λ × μ or res(λ) ∪ res(μ) /= {}. When this holds we deﬁne λ · μ to be the step given by:
λ · μ = λμ if res(λ) ∪ res(μ) /= {}
= λ; μ if res(λ)= res(μ)= {} and λ × μ 

We refer to this operation from now on simply as concatenation. We extend to finite traces in the obvious inductive manner. Let ϵ be the empty trace.
Definition 19 For all α, β, λ, μ we have ϵa β, αa ϵ, and (αλ) a (μβ) iff λa μ. Further, ϵ · β = β, α · ϵ = α, and when λaμ we let (αλ) · (μβ)= α(λ · μ)β.
It is easy to verify that δ · δ = δ and that · is associative.
Theorem 20 For all traces α, β, γ, αaβ & (α · β) aγ iff β a γ & α a (β · γ) and when these hold, (α · β) · γ = α · (β · γ).
Examples
Clearly write(x, 0, 1) · write(x, 1, 2) = write(x, 0, 2), and
lock (r) · write(x, 0, 1) = lock (r) write(x, 0, 1)
lock (r) · write(x, 0, 1) · write(x, 1, 2) · unlock (r)= lock (r) write(x, 0, 2) unlock (r)
Reducing traces
We say that a trace α is reduced (or “mumbled”) iff for all pairs of successive steps
λμ in α either res(λ) /= {} or res(μ) /= {}. It is easy to see that any trace built using
· is reduced, because when αλ and μβ are reduced traces and λaμ, α(λ· μ)β is also a reduced trace. We say that α = λ1 ... λn is feasible iff its steps can be combined using ·, and when this happens we obtain the reduced trace red (α)= λ1 · ... · λn.
For example, the trace
α = lock (r) write(x, 0, 1) write(x, 1, 2) unlock (r) lock (r) write(x, 0, 1) unlock (r) is feasible, and red (α) is the trace
lock (r) write(x, 0, 2) unlock (r) lock (r) write(x, 0, 1) unlock (r).
However the trace write(x, 0, 2) write(x, 0, 1) is not feasible.
Every reduced trace α is also feasible and satisfies the equation red (α) = α.
Whenever α is feasible, red (α) is a reduced trace.

Executing traces
We extend the effect relation to traces in the obvious way:

σ ==λ=1=..=.λ=⇒n  σj iff ∃σ0,..., σn. σ = σ0 & σn = σj

& σ0
=λ=⇒1
σ1 =λ=⇒2
σ2 ··· σn—1
=λ=⇒n  σn



When n = 0 we get σ
=⇒є
σ. When σ
=α⇒ σj we say that α is enabled in σ, and σj

is the result of executing α from σj. A trace is executable if it is enabled by some state.
We are mainly interested in executable traces, yet our semantic construction deals with feasible traces, including both executable and non-executable traces. This is unavoidable, because a parallel program may have an executable trace that arises by interleaving of non-executable traces. For example, consider the traces α = lock (r) write(x, 0, 1) unlock (r) and β = lock (r) write(x, 1, 0) unlock (r). The trace αα is non-executable, but (αα)  β contains an executable interleaving αβα. As this example shows, the executable traces of a parallel program c1  c2 cannot always be determined from the executable traces of its component processes c1 and c2, i.e. executable traces are not compositional. However the executable traces of c1  c2 can be determined from the feasible traces of c1 and c2, and feasible traces can indeed be defined in compositionally. Note that in the above example αα is a feasible trace.
The claim that we lose no generality by dropping infeasible traces is validated

by the facts that: when α is infeasible there are no states σ such that σ
=α⇒ σj, and

there is no way to fill the gaps in α without concurrently writing to a variable read by α.

Parallel composition
We adapt the definition of resource-sensitive fair merge from our prior work, ad- justed to generate mumbled traces. For traces α and β, and disjoint finite sets of resources A and B, we define the set of feasible merges
α A  B β ⊆ Λ∗

by induction on trace length. This set consists of all traces in which a process holding resources A runs concurrently with a process holding resources B. We first

define the relation A
−→λ
Aj that characterizes when the process holding A can do

step λ in an environment holding B:


A −lo−c−k−(−r→)
A ∪ {r}	if r ∈/
A ∪ B

A −u−n−lo−c−k−(−r→)
A − {r} if r ∈ A

A −→λ
A	if res(λ)= {}

When one (or both) of the traces is empty we define:


α A  B ϵ = {α | A ϵ A  B β = {β | B
For the inductive case we define:
−→α
−→α
Aj}
Bj}



(λα) A  B (μβ) = {λ · γ | A
∪ {μ · γ | B
−→λ
−→μ
Aj & γ ∈ αA′  B (μβ) & λa γ} Bj & γ ∈ (λα) A  B′ β & μa γ}

∪ {(λ ⊗ μ) · γ | λ co μ, γ ∈ α A  B β & (λ ⊗ μ) a γ}
When A = B = {} we omit the subscripts and write α  β.
The first two terms produce interleavings in which one process does a step first; the third term allows concurrent combinations when enabled, and takes account of the potential for race conditions. Use of · ensures that we only include feasible traces. The reader can check that when α and β are feasible traces, every trace belonging to α  β is also feasible.
When λ and μ are concurrently enabled (so resource-free) steps, λ  μ = {λ⊗ μ}.
If in addition the steps are conflict-free, we have λ; μ = μ; λ = λ ⊗ μ.
When λ and μ are resource-free steps that are not consecutively executable in either order, and not concurrently executable, λ  μ = {}.
When at least one of λ and μ is a resource step, λ  μ = {λμ, μλ}.
Examples
In each of these examples the reader should check that we do obtain the set of all (reduced) feasible combinations. It is also worth noticing that several distinct interleavings may lead to the same reduced trace, showing the succinctness of our construction.
Concurrent writes to distinct variables: write(x, 0, 1)  write(y, 0, 1) yields three feasible interleavings:
write(x, 0, 1) · write(y, 0, 1)
write(y, 0, 1) · write(x, 0, 1)
write(x, 0, 1) ⊗ write(y, 0, 1)
and each of these reduces to the same trace ([x : 0,y : 0], [x : 1,y : 1]). So
write(x, 0, 1)  write(y, 0, 1) = {([x : 0,y : 0], [x : 1,y : 1])}.
Concurrently executable writes to the same variable:
write(x, 0, 1)  write(x, 0, 1)
= {write(x, 0, 1) ⊗ write(x, 0, 1)}
= {([x : 0], [x : T])}.

In this case the updates are not sequentially composable.
Non-concurrently executable writes to the same variable:
write(x, 0, 1)  write(x, 1, 2)
= {write(x, 0, 1) · write(x, 1, 2)}
= {write(x, 0, 2)}
because there is only one feasible interleaving. On the other hand,
write(x, 0, 1)  write(x, 2, 1) = {},
because the two steps cannot be composed sequentially or concurrently.
Semantics of expressions
Since our semantics is designed to detect race conditions involving concurrent access to shared variables, we can work with a very simple model for expressions. There is no need to keep track of the order in which reads occur during expression evaluation, provided we record the set of reads on which the expression value depends, so we can use a set of state-value pairs. For an integer expression e we will let [e]] ⊆ Σ×V , and for a boolean expression b we let [b]] ⊆ Σ × {true, false}. An entry (σ, v) ∈ [[e]] represents the fact that evaluation of e in any state τ such that τ ⊇ σ only reads the portion σ of the state and produces the integer value v, and similarly for boolean expressions. So each entry is a minimal piece of computational information about expression evaluation, in line with our desire to deal with footprints.
Definition 21 We deﬁne [[e]] and [[b]] by structural induction:
[[n]] = {([ ], n)}
[[i]] = {([i : v], v) | v ∈ V }
[[e1 + e2]] = {(σ1 ∪ σ2, v1 + v2) | (σ1, v1) ∈ [[e1]]& (σ2, v2) ∈ [[e2]] & σ1 ⇑ σ2}
[[true]] = {([ ], true)}
[[e1 = e2]] = {(σ1 ∪ σ2, v1 = v2) | (σ1, v1) ∈ [[e1]] & (σ2, v2) ∈ [[e2]]& σ1 ⇑ σ2}

We remark that when (σ, v) ∈ [[e ] the piece of state σ contains values for the identifiers occurring free in e whose values are used to compute v.
Theorem 22 For all expressions e, if (σ, v) ∈ [[e]] then dom(σ) ⊆ free(e). 2
Since we deal here with footprints these semantic clauses area little more involved than in traditional presentations, which usually assume that the entire global state is at hand.

2 For the clauses listed above one can prove the stronger property that if (σ, v) ∈ [[e]] then dom(σ)= free(e). This fails if we extend the expression language to include conditionals, whereas the weaker property continues to hold, and our development only relies on the weaker property as stated here.

Semantics of commands
Commands denote sets of feasible traces. To simplify the presentation we introduce the abbreviations [b]]true for {(σ, [ ]) | (σ, true) ∈ [[b]]} and similarly for [b]]false . Intuitively [b]]true and [b]]false are trace sets representing evaluation steps in which the truth value of b is calculated.
Definition 23 We deﬁne the trace set of a command, [[c]] ⊆ P(Λ∗), by structural induction:
[[skip]] = {δ}
[[i:=e]] = {(σ ∪ [i : v], U, [i : vj]) | (σ, vj) ∈ [[e]] & σ ⇑ [i : v]}
where U—1(i)= dom(σ) ∪ {i}
[[c1; c2]]= [[c1]] · [[c2]] = {α1 · α2 | α1 ∈ [[c1]], α2 ∈ [[c2]] & α1 a α2}
[[if b then c1 else c2]]= [[b]]true · [[c1]] ∪ [[b]]false · [[c2]]
[[while b do c]]= ( [b]]true · [[c]])∗ · [[b]]false
[[c1  c2]]= [[c1]]  [[c2]] = S{α1  α2 | α1 ∈ [[c1]] & α2 ∈ [[c2]]}
[[with r when b do c]] = {lock (r) β · γ unlock (r) | β ∈ [[b]]true , γ ∈ [[c]], β a γ}

Note the careful use of a and · to ensure that only feasible traces are included. It follows by an easy structural induction that for all commands c the set [c ] defined by these clauses is indeed a set of feasible traces. The implicit use of the sequencing and concurrent composition operations on steps in these clauses is designed to omit irrelevant (infeasible) traces, and to reduce (feasible) traces, and thus abstract away from the order of action occurrences in between resource steps. Hence our semantics truly embodies Dijkstra’s Principle. Note that the executable traces of c can be extracted from [c ] as a subset.
The clause for critical regions shows how entry and exit are modeled as lock (r) and unlock (r), and the resource-sensitive nature of interleaving ensures that c1  c2 correctly models concurrent execution while obeying the atomicity and mutual ex- clusion constraints on resources. Since we only care here about partial correctness behavior we do not include infinite traces to represent the busy-waiting caused by perpetually unavailable resources and/or the falsity of the entry condition b. Simi- larly the clause for while-loops does not include infinite iteration.
The semantic clause for assignment conceals a slight subtlety: commands do not allocate storage, so an assignment can only be executed from a state in which it target variable already has a value. So the footprint of i:=e needs a read state in which i has a value and from which e can be evaluated. To allow for cases where i is not relevant to the value of e as well as when e needs the value of i, we use σ ∪ [i : v] (with σ ⇑ [i : v]) as the read state in the footprint of i:=e, where (σ, vj) ∈ [[e]]).
When i ∈/  dom(σ), so that i is not needed by e, the consistency constraint holds
for all v; when i ∈ dom(σ), so the value of e may depend on i, the consistency

constraint only holds for v = σ(i) and the state σ ∪ [i : v] is the same as σ.

Examples
Our semantics deals properly with multiple assignments in sequence and in parallel, taking account of race conditions:

[[x:=1]] = {([x : v], [x : 1]) | v ∈ V }
[[x:=1; x:=2]] = [x:=2]] = {([x : v], [x : 2]) | v ∈ V }
[[x:=1; y:=1]] = [x:=1  y:=1]] = {([x : v1,y : v2], [x : 1,y : 1]) | v1, v2 ∈ V }
[[x:=1  x:=1]] = {([x : v], [x : T]) | v ∈ V }

In each of these cases the flow relation is the obvious identity relation.
When one assignment affects a variable used later, our semantics again makes the right distinctions:

[[x:=1; y:=x]] = {([x : v1,y : v2], R, [x : 1,y : 1]) | v1, v2 ∈ V }
[[y:=x; x:=1]] = {([x : v1,y : v2], R, [x : 1,y : v1]) | v1, v2 ∈ V },

where R = {(x, x), (y, y), (x, y)}. Here the flow relation is the same but the write effect differs.
When we run x:=1; y:=x in parallel with a command that writes to x there is a race condition involving x and y. For example:

[[(x:=1; y:=x)  x:=2]] = {([x : v1,y : v2], [x : T,y : T]) | v1, v2 ∈ V }.

From above we see that our semantics distinguishes between x:=1; y:=x and x:=1; y:=1. This is necessary because in the latter command the value of y is not influenced by the value of x, leading to different behavior in contexts that write to x. Indeed, we have
[[(x:=1; y:=1)  x:=2]] = {([x : v1,y : v2], [x : T,y : 1]) | v1, v2 ∈ V }.

A slightly more complex example shows how expression evaluation and control flow fit in: [if x > 0 then y:=1 else z:=1]] is the set

{([x : v1,y : v2], Uy, [y : 1]) | v1 > 0, v2 ∈ V }
∪ {([x : v1,z : v2], Uz, [z : 1]) | v1 ≤ 0, v2 ∈ V }

where U—1(y)= {x, y} and U—1(z)= {x, z}.
y	z

For a while-loop with no critical regions, our semantics abstracts away from the intermediate states generated by successive iterations:
[[while y > 0 do (x:=x + 1; y:=y − 1)]]
= {([x : v1,y : v2], U, [x : v1 + v2,y : 0]) | v2 > 0}∪ {([y : v], [ ]) | v ≤ 0}

where U—1(x)= {x, y}.
The only traces of the program (with r do x:=1)  (with r do x:=2) that are executable from a state in which the values of r and x are 0 are
lock (r) write(x, 0, 1) unlock (r) lock (r) write(x, 1, 2) unlock (r)
and lock (r) write(x, 0, 2) unlock (r) lock (r) write(x, 2, 1) unlock (r).

Consider the program (x:=1; x:=2)  with r do y:=x. Each of its traces arises by interleaving a trace ([x : v], [x : 2]) of x:=1; x:=2 with a trace of form lock (r) ([x : v1,y : v2], Uy, [y : v1]) unlock (r) for some v, v1, v2, where U—1(y)= 
{x, y}. The feasible interleavings are all traces of the following forms:
([x : v], [x : 2]) lock (r) ([x : v1,y : v2], Uy, [y : v1]) unlock (r)
lock (r) ([x : v1,y : v2], Uy, [x : 2,y : T]) unlock (r)
lock (r) ([x : v1,y : v2], Uy, [x : 2,y : v1]) unlock (r)
lock (r) ([x : v1,y : v2], Uy, [x : 2,y : 2]) unlock (r)
lock (r) ([x : v1,y : v2], Uy, [y : v1]) unlock (r) ([x : v], [x : 2])
There is no trace in which y gets set to 1; instead there is a racy trace in which y gets set to T. The remaining traces represent computations in which steps are taken sequentially.
Note also that the traces of (x:=1; x:=2)  with r do y:=x are identical to the traces of x:=2  with r do y:=x. This can be verified by construction, but it also follows by compositionality of the semantics, since [x:=1; x:=2]] is the same as [x:=2]].
Consider the program with r do (x:=x + 1; x:=x + 1). Our semantics does not distinguish this from with r do x:=x + 2. There is no need to distinguish them, because no other process can tell them apart without causing a race.
Semantic properties
We begin with an obvious fact connecting static semantics and dynamic semantics.
Theorem 24 If α(σ, R, σj)β ∈ [[c]] then dom(σ) ⊆ free(c), dom(σj) ⊆ writes(c),
R ⊆ dom(σ) × dom(σj), and res(σ) ⊆ res(c).
Together with the fact that trace sets are designed so that resource-free steps get composed together, this obvious fact implies the following noteworthy result.

Corollary 25 If c is resource-free, i.e. res(c) = {}, each trace of c consists of single step. Such a command determines a state transformation, expressible as
|c| = {(σ, σj) | ∃(τ, R, τj) ∈ [[c]]. σ ⊆ τ & σj = [σ | τj]}.
If in addition to this c has no free variables, the only possible non-empty trace for
c is ([ ], [ ]), and |c| is either the identity function on states or the empty function.
For example, |skip; skip| = {(σ, σ) | σ ∈ Σ} and |while true do skip| = {}. The next result validates a simple static law on commutativity of assignments.
Theorem 26 Suppose x /∈ free(e2) and y ∈/ free(e1). Then
[[x:=e1; y:=e2]] =
{(σ1 ∪ σ2, R, [x : v1,y : v2]) | (σ1, v1) ∈ [[e1]], (σ2, v2) ∈ [[e2]], σ1 ⇑ σ2,
R—1(x)= dom(σ1) & R—1(y)= dom(σ2)}
and [[x:=e1; y:=e2]]= [[y:=e2; x:=e1]]= [[x:=e1  y:=e2]].
Theorem 27
Sequential composition is associative, with skip as a unit.
Theorem 28
Parallel composition is symmetric and associative, with skip as a unit.
We define what it means for a command to be race-free from a given state.

Definition 29 c is race-free from σ iff ∀α ∈ [[c]].∀σj. (σ
=α⇒ σj implies T ∈/
rge(σj)).

When this holds for all states σ we say that c is race-free.
Theorem 30
skip and i:=e are race-free.
If c1 and c2 are race-free, so are c1; c2 and if b then c1 else c2.
If c is race-free, so are while b do c and with r when b do c.
If writes(c1) ∩ free(c2)= writes(c2) ∩ free(c1)= {}, and c1 and c2 are race-free, then c1  c2 is race-free.
Corollary 31 Every sequential program c is race-free.
A resource context Γ is a set of entries of form r(X), where r is a resource name and X is a finite set of identifiers, called a protection list. We say that c respects Γ iff every free occurrence in c of an identifier protected by r in Γ is inside a conditional critical region naming r. The next result shows that our semantics validates the Owicki-Gries static constraints on critical variables [9]. We let owned(Γ) be the set of identifiers occurring in the protection lists of Γ.

Theorem 32
Let c1 and c2 be race-free commands. If c1 and c2 respect Γ and

writes(c1) ∩ free(c2) ⊆ owned(Γ) & writes(c2) ∩ free(c1) ⊆ owned(Γ)

then c1  c2 is race-free.
The static constraints built into this theorem statement require that each “critical variable” of c1  c2 must be “protected” by resources and must only appear inside critical regions naming the relevant resources. In Owicki-Gries logic a variable is deemed “critical” if it has a write occurrence in c1 or c2 and is read or written by the other. Our result confirms that these constraints ensure race-freedom. Again, although this is a fairly obvious result, it is comforting to see that our semantics furnishes a straightforward proof.

Safe partial correctness
Let p and q be boolean-valued expressions in which identifiers may occur free. (We do not allow resource names to appear free in such expressions.) Let |p| be the set of states satisfying p. The safe partial correctness formula {p}c{q} is valid iff all finite executions of c from a state satisfying p are race-free and end in a state satisfying
q. We formalize this notion of validity as follows, using the trace semantics.
Definition 33 {p}c{q} is valid for all α ∈ [[c]], and all states σ such that dom(σ) ⊇

free(p, c, q), if σ ∈ |p| and σ
=α⇒ σj, then σj is race-free and σj ∈ |q|.

Since validity is defined in terms of trace sets it is immediate that programs with the same trace sets satisfy the same assertions.
Theorem 34 If [[c1]] = [[c2]] then c1 and c2 satisfy the same assertions in all pro- gram contexts, i.e. for all p and q, and all contexts C[−], {p}C[c1]{q} is valid iff
{p}C[c2]{q} is valid.
Corollary 35 If [[c1]]= [[c2]] then c1 and c2 satisfy the same assertions, i.e. for all
p and q, {p}c1{q} is valid iff {p}c2{q} is valid.

Observing the state
For a trace α, let |α| be the set of state sequences obtainable by executing α. When

α = λ1 ... λn we have |α| = {σ1 ... σn | σ1
=λ=⇒1
σ2 ··· σn—1
=λ=⇒n
σn}. When α is

non-executable this set is obviously empty. We define the set S(c) of state sequences observable during executions of c, to be S(c)= S{|α| | α ∈ [[c]]}. This is observing
the state at start and finish and at all synchronization points.
Theorem 36 If [[c1]]= [[c2]] then for all contexts C[−], S(C[c1]) = S(C[c2]).
This demonstrates that our semantics supports compositional program analysis.

Conclusions
Our more refined treatment of races yields a footprint trace semantics that supports compositional reasoning about safe partial correctness, tracking the variables whose values are immune to race conditions. The new model enjoys better abstraction properties than our earlier model [4]. We can pinpoint the differences by looking at the notions of semantic equivalence induced by the old semantics and the new. In the earlier model a race condition was a global catastrophe, leading to a special abort state. This earlier model gave the same meaning, namely
{([x : v1,y : v2], [x : 1,y : 1]) | v1, v2 ∈ V },
to (i) x:=1; y:=x and (ii) x:=1; y:=1, and hence the same meaning, namely
{([x : v1,y : v2], abort) | v1, v2 ∈ V },
to programs (i)  x:=2 and (ii)  x:=2. The new semantics distinguishes (i) from (ii), because they induce different flow relations: only in (i) is y dependent on x. (We made a similar comment in an example, earlier.) Moreover, this distinction is worth making, because when run in parallel with a program that (only) writes to x, for (i) the value of y gets tainted but for (ii) it does not. Thus there is a program context in which (i) and (ii) have different observable behavior. In particular, the new semantics distinguishes (correctly) between the programs (i)  x:=2 and (ii)  x:=2.
We refer to our semantics as “grainless”. This appellation is accurate, as the steps occurring in the traces of programs are obtained by “mumbling” that abstracts away from irrelevant details. We do still assume that resource actions lock (r) and unlock (r) are atomic. Further, we only include feasible traces, so we obtain a more succinct trace set that subscribes roughly speaking to the slogan: fewer traces, shorter traces, bigger steps. Thus our semantics strives to avoid the combinatorial explosion inherent in interleaving traces, by working with smaller trace sets and shorter traces. Our more localized account of races allows a more liberal view of safe partial correctness. We could say that {p}c{q} is valid iff for all states σ

satisfying p, and all α ∈ [[c]], if σ
=α⇒ σj then σj satisfies q. Assuming that we define

satisfaction so that σ ∈ |p| implies ∀i ∈ free(p). σ(i) /= T, this notion of validity does not imply absolute race-freedom of c from states satisfying the pre-condition, just that the state relevant to the post-condition is race-free. We plan to explore this idea further, perhaps leading to a new variant of concurrent separation logic that deals more flexibly with race conditions.
We dealt here with a simple shared-memory parallel language: no pointers or mutable state, no dynamic allocation of storage. We believe that the foundations laid in our prior development of action trace semantics for concurrent separation logic [3] and our earlier grainless model [4] can be adapted to combine the new approach to race-detection and tainting with mutable state, and we plan to investi- gate further. We plan to explore work using flow analysis in other settings, such as secure information flow and program analysis. Insights from related fields may help assess the scope and limitations of our work, and may suggest some improvements.

We have assumed that programs are executed on an architecture that provides sequential memory consistency [7]:
. . . the result of any execution is the same as if the operations of all the processors were executed in some sequential order, and the operations of each individual processor appear in this sequence in the order specified by its program.
This assumption leads naturally to the use of interleaving to represent parallel composition, as is common in denotational models of shared-memory dating back to Park [10]. We have not tried to deal with weak memory assumptions, supported by some modern concurrency architectures [1]. We argue that even in (perhaps especially in) dealing with more relaxed implementations it would be useful to have a semantics like ours, that yields a (machine-independent) characterization of race- free programs and predicts (semantically) to what extent a program’s behavior is susceptible to uncertainty about the values of variables.
Acknowledgement
Stephan van Staden made a number of helpful suggestions for clarification and improvement. We thank the referees for pointers to interesting related work.

References
S. V. Adve and K. Gharachorloo. Shared Memory Consistency Models: A Tutorial. IEEE Computer 29
(12): 66–76 (December 1996).
S. Brookes. Full abstraction for a shared-variable parallel language. Proc. 8th IEEE Symposium on Logic in Computer Science, IEEE Computer Society Press (1993), 98–109. Journal version in: Inf. Comp., vol 127(2):145-163, Academic Press, June 1996.
S. Brookes. A Semantics for Concurrent Separation Logic. Invited paper, CONCUR 2004, Philippa Gardner and Nobuko Yoshida (Eds.), Springer LNCS 3170, London, August/September 2004, pp. 16- 34.
S. Brookes. A Grainless Semantics for Parallel Programs with Shared Mutable State. Proc. 21st Conference on Mathematical Foundations of Programming Semantics (MFPS XXI). Birmingham, 17–21 May, 2005.
E. W. Dijkstra. Cooperating sequential processes. In: Programming Languages, F. Genuys (editor),
pp. 43-112. Academic Press, 1968.
C.A.R. Hoare. Towards a Theory of Parallel Programming. In Operating Systems Techniques, C.
A. R. Hoare and R. H. Perrott, editors, pp. 61-71, Academic Press, 1972.
L. Lamport. How to Make a Multiprocessor Computer That Correctly Executes Multiprocess Programs, IEEE Trans. Comput. C-28,9 (Sept. 1979), pp. 690-691.
P.W. O’Hearn. Resources, Concurrency, and Local Reasoning. Invited paper, CONCUR 2004, Philippa Gardner and Nobuko Yoshida (Eds.), Springer LNCS 3170, London, August/September 2004, pp. 49-67.
S. Owicki and D. Gries. Verifying properties of parallel programs: An axiomatic approach, Comm. ACM. 19(5):279-285, May 1976.
D. Park. On the semantics of fair parallelism. In: Abstract Software Specifications, Springer-Verlag LNCS vol. 86, 504–526, 1979.
J. C. Reynolds. Towards a Grainless Semantics for Shared-Variable Concurrency. Proc. 24th Conference on Foundations of Software Technology and Theoretical Computer Science (FSTTCS 2004), Chennai, India. Springer-Verlag, December 2004.
