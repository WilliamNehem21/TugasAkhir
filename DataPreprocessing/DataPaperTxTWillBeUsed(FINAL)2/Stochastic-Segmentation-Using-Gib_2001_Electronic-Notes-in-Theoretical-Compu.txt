Electronic Notes in Theoretical Computer Science 46 (2001)
URL: http://www.elsevier.nl/locate/entcs/volume46.html 12 pages


Stochastic Segmentation Using Gibbs Priors

Eilat Vardi 1,2
Department of Bioenginnering University of Pennsylvania Philadelphia, PA, USA

Gabor T. Herman 3
Center for Computer Science and Applied Mathematics Temple University
Philadelphia, PA, USA


Abstract
In earlier work, a fast stochastic method for reconstructing a certain class of two- dimensional binary images from projections using Gibbs priors was presented. In the present study, we introduce a stochastic segmentation of magnetic resonance gray-scale images of trabecular bone using Gibbs priors. We show some results as well as some post-processing that can be used to clean up segmentations of noisy gray-scale images.


Introduction
Segmentation deals with the problem of creating a binary image from a gray- scale image (where, in the binary image, 1 represents the presence and 0 represents the absence of the object which we wish to segment from the gray- scale image). A stochastic algorithm for the reconstruction of binary images from projections using Gibbs priors presented in [1], [5] gave good results. The main goal of the work reported here is to develop a segmentation algorithm using a similar approach.

1 The first author was supported by a U.S. National Institutes of Health (NIH) training grant T32 CA 74781. The second author was supported by the NIH grant HL28438, as well as by the U.S. National Science Foundation grant DMS9612077. We thank the Laboratory of Retinal Microcircuitry at the University of Pennsylvania for generously providing space and computer facilities to the first author.
2 Email: eilat@seas.upenn.edu
3 Email: gaborherman@netscape.net
◯c 2001 Published by Elsevier Science B. V. Open access under CC BY-NC-ND license.


In this paper, an image is a rectangular two-dimensional array of pixels. A gray-scale image is one where each pixel has a value inclusively between 0 and 255 (where 0 corresponds to black and 255 corresponds to white). A binary image is one where the value of each pixel is either 0 or 1. In the discussion of binary images that follows, we use black and 0, as well as white and 1, interchangeably.
Appropriate prior information regarding the class of images to be seg- mented may be useful for the segmentation process. In addition to the inher- ent information in the gray-scale image, local properties of the desired binary image can also provide useful information.
Local properties of a binary image ω, defined on (an arbitrary, but fixed array containing) H pixels (ω(h)is either black or white for each pixel indexed by an integer 1 h  H), can be characterized by a Gibbs distribution of the form

Q(ω)=  1 exp(γ Σ I
(ω)),

Z	h
h=1
where Q(ω) is the probability of occurrence of image ω, Z is the normalizing factor (which insures that Q is a probability function over the set of all binary images defined on the fixed set of H pixels), γ is a positive parameter defining the ”peakedness” of the Gibbs distribution, and Ih(ω) is the local potential at the pixel indexed by h in image ω. Since we take γ > 0, Q(ω)increases as the sum of the local potentials increases.
In this paper, we define the clique, C(h), centered at a pixel h to consist of the nine pixels in the 3 3 neighborhood of h. We restrict our attention to Gibbs distributions in which the local potential at a pixel h depends only on the values of the elements of C(h) in the binary image ω. (To make this and later definitions apply everywhere, we treat pixels near the edge of a binary image as if the image were extended by a boundary of two layers of pixels. In the experiment described here, we use a boundary that is all zeros.)
For all pixels h in an (actual; i.e., not the extended) binary image, the color of pixel h influences the values of the local potentials only at the pixels in C(h). These nine local potentials depend only on the values of the 25 pixels in the 5 5 neighborhood of h. Therefore, the change in the probability Q(ω)that results from switching the color of pixel h (in the binary image ω) depends only on the values of those 25 pixels in ω.
We assume that we are given a set of typical (to a given application area) gray-scale images and their corresponding gold-standard segmentations repre- sented as binary images. We refer to these images as the training set.
Appropriate definition of the local potentials plays an important role in the success of image segmentation. The definition should reflect the characteristics of a typical image of the particular application area. The local potential is defined in such a way that it encourages certain local configurations, such as uniform white or black clusters of pixels. There are many possible ways

of defining the local potentials. One simple approach is the following. We partition the set of 512 possible 3 3 binary clique configurations into 6 clique configuration types: 0) the all black configuration, 1) the all white configuration, 2)clique configurations in which the white pixels form an edge,
3) clique configurations in which the white pixels form a convex corner, 4) clique configurations in which the white pixels form a concave corner, and 5) any other clique configurations.
The working definition of the clique configurations types is as follows. A configuration is one of the first five types only if there are k consecutive white pixels and 8 k consecutive black pixels among the eight external pixels of the clique. If the central pixel is black, then the configuration is a black region, a convex corner, an edge, or a concave corner, if, and only if, k = 0, 1  k  2, k = 3, or 4  k  5, respectively. Similarly, if the central pixel is white, then the configuration is a convex corner, an edge, a concave corner or a white region, if, and only if, 3 k  4, k = 5, 6 k  7, or k = 8, respectively. Otherwise, the clique configuration is of type other.
Let th(ω) be the clique configuration type at pixel h in image ω (0 ≤ th(ω) < 6). (For more information on local potentials and clique configuration types, see [3].) We create the prior information from the binary training images in the following way. We create a table r of size 6. We store in its t’th location (0  t < 6) the number of internal cliques of configuration type t in the binary training images divided by the number of different clique configurations which are of type t. (By an internal clique we mean those cliques which are entirely included in the actual image, without the boundary discussed earlier.) The table value r(t)gives us the average number of appearances of cliques of a certain type t. The local potential Ih(ω) is defined as ln(r(th(ω)) + 1). These local potentials give us information about the frequency of occurrence of the different clique configuration types in the binary training images. The usefulness of the resulting distribution depends on the size of the collection of the training images and on how representative they are for the application area. As we further discuss in Section 3, we adjust the value of the parameter γ in the definition of the Gibbs distribution Q(ω) in such a way that the expected percent of white pixels in a random image of the Gibbs distribution will be the average percent of white pixels in the binary training images.
We also use the training images to correlate the characteristics of the binary images and the gray-scale images. Let g(h) be the mean of the gray-scale values in C(h). For each clique configuration type t (0  t < 6), we calculate the mean and standard deviation over all pixels h, of type t in the set of given binary images, of the corresponding values of g(h). We denote the mean and standard deviation for each type t by µt and σt, respectively. In this paper, we write µh(ω)for µth(ω) and σh(ω)for σth(ω).
The segmentation algorithm should find a binary image which is not only
statistically consistent with the gray-scale image, but which is also typical of the Gibbs distribution of the binary images. Thus, if q(g|ω)is the probability

of g (the image containing the values of g(h), 1  h  H), given a binary image ω, then Bayes’ theorem says that the posterior probability of ω (given g)is proportional to
M (ω)= {Q(ω)q(g|ω)}β,
where Q(ω) is the Gibbs distribution of the binary images as defined above and β = 1. Assuming that the g(h) (1 h H) of previous paragraph are independently and normally distributed, we have that

H
q(g ω)=	 
h=1	2πσh(ω)
exp( −(g(h) − µh(ω)) ).
2σ2(ω)

Since our task is to find the ω∗ which maximizes M (ω)and this ω∗ is indepen- dent of β (as long as β > 0), for algorithmic reasons we use the more general form of M (ω)with β > 0, rather than just with β = 1.
An annealing schedule is a schedule in which an initial inverse temperature, an incrementing schedule, and a stopping criterion are specified. Here, the parameter β is the inverse temperature. It is not held constant, instead it is incremented in the segmentation algorithm as described by the annealing schedule.
We use the iterative Metropolis Algorithm [4] to estimate the binary image ω∗ that maximizes M (ω). We start the algorithm with a completely white image. In the iterative step, the current image ω1 is changed into ω2 by randomly picking a single pixel h' and changing its color. Let p be defined by
p = M (ω2)
M (ω1)
= exp(β Σ {γ(Ih(ω2) − Ih(ω1))

h∈C(h')
2
σh(ω2)	(g(h) − µh(ω2))
(g(h) − µh(ω1))2

−(ln( σ
)+	−	)}).
(ω )	2σ2(ω )	2σ2(ω )

h	1	h	2	h	1
Image ω1 is replaced by ω2 if p is greater than or equal to one, and image ω1 is replaced by ω2 with probability p if p is less than one. This is equivalent to replacing image ω1 by ω2 with probability min(p, 1).
The program runs for 120, 000 cycles with varying values of β. In each cycle, the algorithm performs H iterations. The program outputs the image ω in the sequence with the highest value of M (ω).

Reducing Run-Time
We devised several ways to reduce the run-time of the segmentation program.

Create look-up tables:
Let ω be a binary image and let h' be a pixel. The value of p corresponding to changing the color of a pixel h' depends on the local potentials of pixels

whose cliques contain h'. Therefore, p depends (but not exclusively) on the twenty-five binary pixel values in the 5 × 5 neighborhood of h' in ω.
Consider the two images ω1 and ω2, where ω2 is obtained from ω1 by changing the color of a randomly chosen pixel h'. Note that a part of the term in the exponent of p can be written as

(g(h) − µh(ω2))2


h
2
(g(h) − µh(ω1))2 2σ2(ω1)
2

= g2(h) {σh(ω1) − σh(ω2)}
2σ2(ω1)σ2(ω2)
h	h
2	2
+g(h) {σh(ω2)µh(ω1) − σh(ω1)µh(ω2)}
σ2(ω1)σ2(ω2)
h	h
2	2	2	2
+ {σh(ω1)µh(ω2) − σh(ω2)µh(ω1)}.
2σ2(ω1)σ2(ω2)

We define
h	h


B ' (ω )=	Σ (γ{I (ω ) − I (ω )}− ln( σh(ω2))

h	1	h	2	h	1
h∈C(h')
σh(ω1)

2	2	2	2
{σh(ω1)µh(ω2) − σh(ω2)µh(ω1)} ).
2σ2(ω1)σ2(ω2)
h	h
Let B be the value of Bh' (ω1) and let B be the value of Bh' (ω2). It is easy to check that B = B'. Furthermore, the pair of values B, B' does not depend on the color of h'. If we are given the colors of the 24 pixels in the
5 5 neighborhood of h' (excluding the value of h'), we can calculate both B and B'. However, due to the equality B = B', we need to store only one of these two values (we discuss in the next paragraph how we do this).
Let ωb be the image ω with the color of h' changed to black (if need be) and ωw be the image ω with the color of h' changed to white (if need be). Let
T 0 (ω)= [α Σ (γ{I (ω ) − I (ω )}− ln( σh(ωw))

h'	h	w	h	b
h∈C(h')
σh(ωb)

2	2	2	2
{σh(ωb)µh(ωw) − σh(ωw)µh(ωb)} )],
2σ2(ωb)σ2(ωw)
h	h
where α is a large positive integer such that T 0 (ω) can be stored as a 4- byte integer for all clique configurations (it is used to increase accuracy of the value) and [ ] denotes rounding to the nearest integer. For all 24-element neighborhood configurations, we store the value of T 0 (ω) in a look-up table. The look-up table has 224 entries of type 4-byte integers, therefore it requires only 26 megabytes. Since the value T 0 (ω) does not depend on the color of the pixel h', note that in an iterative step of the Metropolis Algorithm we will
always have that T 0 (ω1)= T 0 (ω2).
h'	h'

We define two more variables,
σ2(ω )µ (ω )	σ2(ω )µ (ω )
T (ω)= [α h	h	 ],
h	σ2(ω1)σ2(ω2)
h	h
σ2(ω )	σ2(ω )
T (ω)= [α h	h	 ].
h	2σ2(ω1)σ2(ω2)
h	h
These values depend only on the values of th(ω1), th(ω2) (the clique configu- ration type of pixel h' in images ω1, ω2, respectively). We store the values of
T 1(ω)and T 2(ω)in two additional look up tables. These tables are relatively
h	h
small; they have 6 × 6 entries each of type 4-byte integer. Note that the values
of T 0(ω), T 1(ω), and T 2(ω)do not depend on the values of g(h),1 ≤ h ≤ H.

Create random number files:
We create the following random number tables: one table for row picking, one table for column picking, and one table for each value of β in the annealing schedule containing integers of type  α ln x , where x is a random number
uniformly distributed in the range (0, 1]. The size of these files will be further discussed in the Section 4.

Integer arithmetic:
The values of g(h) and g2(h) are used in every iteration several times. Therefore, the integer values of [g(h)] and [g(h)]2 for the gray-scale image to be segmented are calculated once at the beginning of the segmentation program and stored for future use. We save the table values introduced above and the values of [g(h)] and [g(h)]2 as integers, so that all arithmetic within the segmentation program is exact. This way, no rounding errors arise and no re-calibrations are necessary.

Reduce calculations:
We are interested in finding the binary image ω∗ which maximizes the function M (ω), not in the actual value of M (ω∗). Let ωW be the binary white image (ωW (h) = 1 for all 1  h  H). Notice that searching for the binary image ω∗ which maximizes the function M (ω) is equivalent to searching for
the binary image ω∧ which maximizes the function M∧(ω)=  M(ω) , which is

equivalent to searching for the binary image ω•
M (ωW )
which maximizes the function

1 ln M∧(ω), i.e. ω∗ = ω∧ = ω•. We therefore set out to maximize the function
1 ln M∧(ω), which does not depend on the value of β. The segmentation algorithm is initialized with the image ωW , for which  1 ln M∧(ωW ) = 0. By maximizing  1 ln M∧(ω)instead of M (ω), we do not have to calculate the initial value of M (ωW ).

Implementation
Assuming that we are given a training set, the first step of the implementation is to calculate the local potentials as described in Section 1. The second step is to find the appropriate value of γ for the given training set. Let f be the percent of foreground pixels (pixels with value 1) in the binary training images. (In trabecular bone images, f is the average bone volume fraction in the given training images.) We run a variant of the Metropolis Algorithm described above to produce random binary images from the distribution Q(ω). We keep track of the percent of foreground pixels in these random images. We search for the value of γ for which these percentages are close to f .
The third step is to calculate the values of µt and σt for 0 ≤ t < 6. This is done as follows: For a given clique configuration type t0, find all the pixels in all the binary training images whose clique configurations are internal and of type t0, calculate the corresponding values of g(h)from the gray-scale training images, and calculate the mean and standard deviation of the values of g(h).
Finally, we discuss how an iterative step of the segmentation algorithm can be carried out using the tables described in Section 2 and a 4-byte random integer of the form  α ln x . For any image ω and pixel h', we define two

integers
Sh' (ω)=	Σ {[g(h)] T (ω)+ [g(h)] T (ω)},

h	h
h∈C(h')


vh' (ω)= 
T 0 (ω) − Sh' (ω), if ω(h')= 0,

 −T 0 (ω) − Sh' (ω), if ω(h')= 1.
Using previously given definitions, it is easy to check that in the iterative step
∧
~ α	M (ω2)	α	M (ω2)
some rounding error), irrespective of the color of h'. It follows that, whenever it is decided to change the color of h', the resulting value of α ln M∧(ω2) can

be estimated by adding the integer vh' (ω1) to the known value
α ln M
∧(ω1).

(For a large value of α, vh' (ω)is a good approximation of the difference in the value of α ln M∧(ω). After many iterations, we cannot be sure how close the accumulated value is to the actual value of α ln M∧(ω), which mandates ex- perimental verification of the usefulness of the process that is being described here.)
Also, it is the case that a correct way to decide whether or not ω1 should be replaced by ω2 in the Metropolis Algorithm is to check whether or not α ln x  ≤ vh' (ω1). Indeed, since vh' (ω) is an integer, this is equivalent to
ln x ≤ αvh' (ω1), which is equivalent to
x ≤ exp( β v ' (ω)) ∼= M (ω2) = p,
α	M (ω1)
and the probability of this is p since x is uniformly distributed over the interval

(0, 1].
We create the random number files and look-up tables described in Section 2 before running the segmentation program. At the beginning of the segmen- tation program, we calculate and store the values of [g(h)] and [g(h)]2. We start the algorithm with the white image ωW . In each iteration, we
read a random row and a random column, which corresponds to randomly choosing a pixel h',
look-up the corresponding table value T 0 (ω1) and calculate the value of
Sh' (ω1),
calculate the value of vh' (ω1),
read a random integer  α ln x , and
if  α ln x ≤ vh' (ω1), then change the color of h' in ω1 and add vh' (ω1)to
α ln M∧(ω1)in order to obtain the value of α ln M∧(ω2).
β	β
The algorithm performs 120, 000 cycles, where each cycle is H iterations as described above. We start each of the 10, 000 cycles (except the first 10, 000 cycles which starts from a white image)with the image with the highest value of α ln M∧(ω) so far. The output is the image for which the highest value of α ln M∧(ω) was obtained (which is the image for which the highest value of
1 ln M∧(ω)was obtained since α > 0).

Experiment
As a preliminary experiment, we scanned with high resolution one 128 128 nuclear magnetic resonance (NMR)gray-scale image of trabecular bone (taken from [2]); see the left image in Figure 1. Using tools from Adobe Photoshop version 5.5 (Adobe System Inc., San Jose, CA) and The Image Processing Tool Kit version 3.0 (Reindeer Games Inc., Raleigh, NC)we created the “gold- standard” segmentation (this segmentation is obviously not perfect.); see the right image in Figure 1. In this experiment, the training set consists of only the one gray-scale image and its corresponding binary segmented image introduced here.
From our training set, we first calculate the values of the local potentials (9.37, 7.32, 4.12, 3.26, 3.31, 0.11), for 0  t < 6 respectively. The percent of foreground pixels (pixels with value 1) in the binary training image is f = 17.6%. We search for the value of γ (to two significant digits) for which the average number of foreground pixels in random images from the distribution Q(ω) is as close as possible to f . In this experiment, this was fulfilled by the value γ = 0.083.
We need approximately 2 billion rows/columns/integers each in 120, 000 cycles of one segmentation of a 128 128 trabecular bone image. We claim that a file of 50 million random rows/columns/integers each is large enough if

Fig. 1. The image on the left has been obtained by scanning from a printed article a NMR gray-scale image of trabecular bone (128 128 pixels). (In NMR images, bone gives off no signal and is therefore black.) The image on the right is the “gold-standard” segmentation.

a random starting position for reading 16.4 million numbers from each file is chosen every 1, 000 cycles.
We create the following random number tables of 50 million random num- bers each: one table of 1-byte unsigned characters for row picking, one table of 1-byte unsigned characters for column picking, and one table of 4-byte inte-
gers of type α ln x for each value of β in the annealing schedule, as described above. In this experiment, we choose the value α = 4, 500, 000. We use the following simple annealing schedule: start at β = 0.1, increase the value of β
by 0.1 every 10, 000 cycles for a total of 120, 000 cycles. (The smallest value that x can be is    1   . In our case RAND MAX= 231  1 and for the
value of β = 0.1, α ln x is approximately −1, 000, 000, 000, which can be stored as a 4-byte integer.)
We found the values of µt (112.27, 187.45, 164.64, 145.07, 174.93, 166.80)
and σt (32.07, 5.60, 16.06, 20.68, 12.85, 17.60), for 0  t < 6 respectively, from the gray-scale image and its corresponding binary image. We create the three look-up tables described in Section 2.
See the left image in Figure 2 for an example of the output of our segmen- tation algorithm. There are 8.6 percent pixels different between the segmented image shown here and the binary training image. The value of  1 ln M (ω)
(which does not depend on the value of β) for the binary training image is 75, 737, while it is	73, 124 for the segmented binary image. Notice that the segmentation method presented here produces an image for which the value
of  1 ln M (ω) is higher than for the binary training image. This is not sur- prising since the binary training image doesn’t pick up all the characteristics of the gray-scale image.
There are 23.6 percent foreground pixels in the binary training image, compared to 17.6 percent foreground pixels in the output of our segmentation. It is clear that the output of our algorithm contains many small (connected)

Fig. 2. The image on the left is an example of an output image of our segmentation algorithm. The image on the right is obtained by post-processing the image on the left using threshold values: threshold-black=30 and threshold-white=60 (see text).
components that are not part of the trabecular bone (trabecular bone is mostly a connected structure). These components seem to arise from the noisy gray- scale image which we tried to segment. Some post-processing is necessary in order to remove these components.

Post-Processing
The images that are output from our segmentation algorithm contain both small white and black connected-components that need to be removed (the color needs to be switched). Let threshold-white be the number of pixels in the largest 8-connected-component of white pixels that will be removed (color will be turned to black). Let threshold-black be the number of pixels in the largest 4-connected-component of black pixels that will be removed (color will be turned to white). Let the size of a connected-component be the number of pixels in the component.
We did the following experiment. We find and remove all the 8-connected components of white pixels whose size is less than or equal to threshold-white. Next, we find and remove all the 4-connected components of black pixels whose size is less than or equal to threshold-black. We came to the conclusion that removing the components in the manner described above during the segmentation algorithm was not necessary; it is sufficient to remove the small components from the output segmentation.
Having come to this conclusion, we had the task of finding good values for threshold-white and threshold-black. We found that in this particular application, using threshold-white=60 and threshold-black=30 gave good re- sults. Using larger threshold values resulted in losing parts of the bone, while using smaller threshold values resulted in some unwanted small connected- components in the binary image. For these threshold values, the percent of different pixels between the post-processed segmented image and the gold- standard segmentation is 4.6, compared to 8.6 percent different pixels be- tween the not post-processed segmented image and the gold-standard image,


 
Fig. 3. These are two-dimensional images of trabecular bone taken ex-vivo, which were processed to resemble in-vivo images.
see Figure 2. There are 19.7% foreground pixels in the post-processed seg- mented image (compared to 17.6% in the training image and 23.6% in the not post-processed segmented image).

Discussion
Encouraged by the preliminary results reported here, we plan to segment in-vivo NMR images of trabecular bone. In Figure 3 we show a couple of two- dimensional images of trabecular bone taken ex-vivo, which were processed to resemble in-vivo images. For the segmentation of such images to be successful, it is necessary to choose appropriate clique configuration types. It is clear the the configuration types used in the experiment described in Section 4 would not be a good choice for these images which contain much smaller detail. A suitable model for the posterior information must be found. After some preliminary experiment, it seems that a different type of posterior information than that proposed here would prove more useful in this case. Finally, some experimentation is necessary in order to determine what is a good annealing schedule for these segmentations.

Conclusion
Gibbs priors appear to be a potentially useful tool for segmentation of complex objects in noisy images.

References
Carvalho, B. M., G. T. Herman, S. Matej, C. Salzberg and E. Vardi, Binary Tomography for Triplane Cardiography, in Information Processing in Medical Imaging, A. Kuba, M. Samal, A. Todd-Pokropek (eds.), Springer, Berlin. (1999), 29–41.


Hwang, S. N., F. W. Wehrli, and J. L. Williams, Probability-based structural parameters from 3D NMR images as predictors of trabecular bone strength, Med. Phys. 24 (1997), 1255–1261.
Liao, H. Y., and G. T. Herman, Automated estimation of the parameters of Gibbs priors to be used in binary tomography, Electronic Notes in Theoretical Computer Science 46 (2001),
URL: http://www.elsevier.nl/locate/entcs/volume46.html.
Metropolis, N., A. W. Rosenbluth, M. N. Rosenbluth, A. H. Teller, and E. Teller, Equation of state calculations by fast computing machines, J. Chem. Phys. 21 (1953), 1087–1092.
Vardi, E., G. T. Herman and T. Y. Kong, Speeding up stochastic reconstruction of binary images from limited projection directions, Linear Algebra and its Applications: Special Issue on Discrete Tomography (to appear).
