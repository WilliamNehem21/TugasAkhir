Electronic Notes in Theoretical Computer Science 213 (2008) 75–94	
www.elsevier.com/locate/entcs


An Algorithm for Approximating the Satisfiability Problem of High-level Conditions

Karl-Heinz Pennemann1 ,2
Department of Computing Science University of Oldenburg
D-26111 Oldenburg, Germany


Abstract
The satisfiability problem is the fundamental problem in proving the conflict-freeness of speci- fications, or in finding a counterexample for an invalid statement. In this paper, we present a non-deterministic, monotone algorithm for this undecidable problem on graphical conditions that is both correct and complete, but in general not guaranteed to terminate. For a fragment of high- level conditions, the algorithm terminates, hence it is able to decide. Instead of enumerating all possible objects of a category to approach the problem, the algorithm uses the input condition in a constructive way to progress towards a solution. To this aim, programs over transformation rules with external interfaces are considered. We use the framework of weak adhesive HLR categories. Consequently, the algorithm is applicable to a number of replacement capable structures, such as Petri-Nets, graphs or hypergraphs.
Keywords: first-order satisfiability problem, high-level conditions, high-level programs, graph transformation, weak adhesive HLR categories.



1 This work is supported by the German Research Foundation (DFG), grants GRK 1076/1 (Graduate School on Trustworthy Software Systems) and HA 2936/2 (Development of Cor- rect Graph Transformation Systems). Thanks to Arend Rensink for the visit to the Univer- sity of Twente, during which the preliminary ideas for this work were discussed, to Annegret Habel for constructive remarks concerning this paper, and to the referees for their thorough reviews.
2  Email: Pennemann@Informatik.Uni-Oldenburg.de



1571-0661 © 2008 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2008.04.075

Introduction

(High-level) Conditions are a graphical formalism to specify valid objects as well as morphisms, i.e., they can be used to describe system or program states as well as specify matches for transformation rules. They provide an intuitive formalism for structural properties and are well suited for reasoning about the behavior of transformation systems.
For a given category C of objects, the satisfiability problem is the problem to decide for any given condition c, whether or not ∃G ∈ C. G |= c.


condition c	yes/no
	



The satisfiability problem can be used to show that a specification is conflict free or to prove that a statement is invalid, i.e. if the negated statement is sat- isfiable. If some object G is provided along with a positive answer, one yields a counterexample for the latter case, illustrating an invalid system state. In this sense, a satisfiability algorithm complements a first-order theorem prover, with the prover searching for proof and the satisfiability algorithm looking for a counterexample. For the category Graph of finite, directed, labeled graphs, conditions are expressively equivalent to first order logic on graphs [20,11]. Therefore the satisfiability problem for arbitrary conditions over arbitrary categories is not decidable, i.e., there does not exist an algorithm that decides the satisfiability of arbitrary conditions over arbitrary categories. Still, an approximation of this undecidable problem is possible, but necessarily either unsound, incomplete or not guaranteed to terminate.
In this paper, we present a sound and complete algorithm that works for conditions over a class of replacement capable categories. Instead of enumer- ating all possible objects of a category to approach the problem, the presented algorithm uses the input condition in a constructive way. Starting from the initial object, e.g. the empty graph, elements of positive statements are added if necessary, while the absence of forbidden patterns is checked. The result is a monotone (non-deleting) algorithm which non-deterministically progresses towards a satisfiable object. Technically, we generate for each condition a program SeekSat. As we need to handover information between computation steps, SeekSat works on morphisms of the considered category. To this aim,

programs over transformation rules with external interfaces are considered.

condition c	yes, G |= c/no/unsure



The paper is organized as follows. In Section 2, the definition of condi- tions is reviewed and programs over rules with external interfaces for high-level structures such as graphs are introduced. In Section 3, the satisfiability al- gorithm is presented, its correctness and completeness is shown, and for a fragment of conditions, its termination and hence its capability to decide is proved. In Section 4, practical aspects concerning a possible implementa- tion and optimization are discussed. We relate our results to other work in Section 5. A conclusion including further work is given in Section 6. A long version of this paper is available at [1] including detailed proofs.

Conditions and Rules
In this section, we review the definitions of conditions and introduce programs over rules with external interfaces for high-level structures such as graphs. We seek an algorithm for the satisfiability problem of conditions that is not concerned with a specific definition of a structure. Therefore, we use the framework of weak adhesive HLR categories introduced as combination of HLR systems and adhesive categories. A detailed introduction can be found in [9,8].
For a given category C, let Mor be the set of all morphisms.
Assumption. Assume that ⟨C, M⟩ is a weak adhesive HLR category [8] con- sisting of a category C of objects and a class M ⊆ Mor of monomorphisms. Additionally, we require
a M-initial object I, i.e., an object I ∈C such that for every object G ∈C there is a unique morphism iG: I → G in M, called the initial morphism to G,
epi-M-factorization, i.e., for every morphism there is an epi-mono- factorization with monomorphism in M,
a ﬁnite length of M-decompositions, i.e., for every morphism m in M, the length of every decomposition mn ◦ ... ◦ m1 = m consisting of non- epimorphisms mj in M (1 ≤ j ≤ n) is finite,
a ﬁnite number of M-matches, i.e. for every morphism l: K ‹→ L in M and every object G, there exist only a finite number of morphisms m: L ‹→ G in M s.t. ⟨l, m⟩ has a pushout complement, and

the pullback-pushout-M property, i.e., for every pair of M-morphisms B ‹→ D ←› C, the unique morphism D' → D of the pushout ⟨B ‹→ D' ←› B⟩ of the pullback ⟨B ←› A ‹→ C⟩ of B ‹→ D ←› C is in M.
A  C

Notation. A morphism m with domain A and codomain B is denoted by m: A → B. m: A ‹→ B indicates that m is a morphism in M. For an object G, let idG: G ↔ G be the identity on G and let iG: I → G be the initial morphism to G. For a morphism, the actual mapping is conveyed by indices, if necessary.
Example 2.1 The category Graph of finite, directed, labeled graphs [8] to- gether with the class M of all injective graph morphisms constitutes a weak adhesive HLR category that satisfies the assumptions. The empty graph ∅ is the M-initial object.
Conditions are nested constraints and application conditions generalizing the corresponding notions in [14,7] along the lines of [20].
Definition 2.2 (conditions) A (nested) condition over an object P is of the form ∃a or ∃(a, c), where a: P → C is a morphism and c is a condition over C. Moreover, Boolean formulas over conditions over P yield conditions over P , i.e., true, ¬c and ∧j∈J cj are (Boolean) conditions over P , where J is a finite index set and c, (cj)j∈J are conditions over P . Additionally, ∀(a, c) abbreviates ¬∃(a, ¬c), false abbreviates ¬true, ∨j∈J cj abbreviates ¬∧j∈J ¬cj and c ⇒ d abbreviates ¬c ∨ d.
P	a	C
=
G

An object G satisﬁes a condition ∃a [∃(a, c)], if the condition is over the initial object I and the initial morphism iG: I → G satisfies the condition. A morphism p satisﬁes a condition ∃a [∃(a, c)] if there exists a morphism q in M such that q ◦ a = p [and q satisfies c]. The satisfaction of conditions by objects [by morphisms] is extended onto Boolean conditions in the usual way. We write G |= c [p |= c] to denote that object G [morphism p] satisfies c.
In the context of objects, conditions (over the initial object I) are also called constraints. In the context of rules, conditions are also called application

conditions.
Notation. For a morphism a: P → C in a condition, we just depict the codomain C, if the domain P can be unambiguously inferred, i.e. for applica- tion conditions over some left-hand side L of a rule and for constraints. For instance, the constraint ∀(∅ → 1, ∃( 1 → 1   2)) with the meaning “Every
node has an outgoing edge to another distinct node” can be represented by

∀( , ∃(
1	2)).

A condition is in M-normal form (MNF), if for every subcondition ∃a and
∃(a, c) the morphism a is in M.
Fact 2.3 (M-normal form) Every condition c over P can be transformed into a condition c' in MNF such that, for all morphism p: P ‹→ G in M, p |= c if and only if p |= c'.
Proof Substitute every subcondition ∃a and ∃(a, c), a /∈ M, with false (see [11]).	 

For the definition of rules with external interfaces, we define partial mor- phisms.
Definition 2.4 (partial morphisms) For a given category C, a partial morphism from A to B, denoted by A ~ B, is a span of morphisms
⟨A ←› K → B⟩, consisting of morphisms K ‹→ A in M and K → B in Mor. Two partial morphism a, b: A ~ B are commutative, denoted by a = b, if there is an isomorphism Ka ↔ Kb such that the resulting triangles commute. The set of all partial morphisms is denoted by PMor.
Fact 2.5 (closure under composition) Partial morphism are closed under composition, i.e., A ~ B and B ~ C can be composed to A ~ C.
Proof By pullback construction. The result is unique up to ismorphism. 
Fact 2.6 Every morphism is also a partial morphism: M⊆ Mor ⊆ PMor.
We require rule applications restricted to a certain context. Therefore, we con- sider rules with external interface and declare transformations of morphisms instead of objects. In this paper, we consider only matches in M.
Definition 2.7 (rules with external interface) A rule ρ = ⟨⟨X ~ L ←› K ‹→ R⟩, acL⟩ consists of a partial morphism x: X ~ L, the external interface, two M-morphisms l: K ‹→ L, r: K ‹→ R, and a (left) application condition

acL over L.

X	x	L	l
=

K	r	R

m'  m
d
m∗

G	l∗	D  r∗  H
A direct derivation from a (partial) morphism m' toa morphism m∗, denoted by m' ⇒ρ,m m∗, is defined by a M-morphism d: K ‹→ D and two pushouts
⟨m, l∗⟩ and ⟨r∗, m∗⟩, if m' = m◦x and m |= acL. We will often refer to the mor- phisms m' and m∗ as the input and the result of the derivation, respectively. As the match m: L → G is in M, we speak of M-matching.
External interfaces may be seen as a kind of input/output types. They can be used to control the location of rule applications. Rules with external interface object I correspond to usual transformation rules. For now, to con- catenate rule applications, an external interface object X has to coincide with the right-hand side of the predecessing rule. The external interface may be a partial morphism to selectively use the interface information it provides, see Example 2.9. The input may be a partial morphism, if programs over rules with external interfaces are considered.
Remark 2.8 Intentionally, we only consider an interface on the left-hand side, as a rule author should just have to care about the “input” interface. In case of external interfaces for left- and right-hand side, it suffices to consider total interface morphisms. However, one may have to write a set of similar rules, depending on rules that follow in sequential composition.
Notation. As every span ⟨L ←› K ‹→ R⟩ of morphisms in M can be seen as a partial morphism, we write ⟨⟨X ~ L ⇒ R⟩, acL⟩. If acL = true, we omit the left application condition and write ⟨X ~ L ⇒ R⟩. In case the external interface is the initial object, i.e. X = I, we just write ⟨L ⇒ R⟩.
Example 2.9 (rule with external interface) Consider the graph rule


ρ = ⟨


1	2	2	2	3

that, for a graph morphism 1   2 → G, adds an edge from the image of node 2 to a newly created node. With an external interface, it becomes possible to hand over information between derivation steps without the use of additional
elements. In this example, the external interface expresses that a given chain of nodes in a graph, represented by the last two nodes, must be extended. We will make use of similar handover effects in our satisfiability algorithm. As X = R, this rule is iterable. Note, the indices do not correspond with the

identities of the nodes, but convey their mappings.

		

1	2	2
2	2	3
m∗


	
1	2	1	2	1	2	3
For modeling transactions, we consider programs [13,19,12] on transformation rules with external interface.
Definition 2.10 (programs) (High-level) Programs are inductively defined: Abort, Skip and every rule ρ with external interface are programs. For pro- grams P, Q and a condition c, every finite set S of programs, Fix(P), (P; Q), if c then P fi, P∗, P↓ and while c do P od are programs.
While Fix(P) is an interface manipulation, a program S denotes the (demonic) nondeterministic choice, (P; Q) is the sequential composition, if c then P fi is the conditional execution, P∗ is the reflexive, transitive closure, P↓ is the as long as possible iteration, and while c doP od is the conditional iteration of programs.
To reflect the presence of rules with external interface, the semantics of a program P is a ternary relation on partial morphisms, denoted by P) ⊆ PMor3, instead of a binary relation on objects. The first two morphisms represents input and result while the last morphism is an “interface relation” from the domain of the input to the domain of the result morphism.
 Abort)	= ∅
 Skip)	= {⟨m', m', id⟩| m' ∈ PMor}
 ρ)	= {⟨m', m∗, mρ⟩| m' ⇒ρ,m m∗}
 Fix(P))	= {⟨m', m∗ ◦ mP, id⟩| ⟨m', m∗, mP⟩∈  P)}
 (P; Q))	= {⟨m', m∗, mQ ◦ mP⟩| ⟨m', m, mP⟩∈ P), ⟨m, m∗, mQ⟩∈ Q)}
 S)	=	 P)
 if c then P fi) = {⟨m', m∗, mP⟩∈ P) | m' |= c}∪ {⟨m', m', id⟩| m' |= ¬c}
 P∗)	= {Skip, (Fix(P); P∗)})
 P↓)	= {⟨m', m∗, id⟩∈ P∗) | ∄m.⟨m∗, m, id⟩∈ Fix(P))}
 while c do P od) = {⟨m', m∗, id⟩∈ if c then P fi∗) | m∗ |= ¬c}
where mρ: X ~ R is the partial ρ-induced morphism X ~ L ←› K ‹→ R and id is the identity on the domain of m' (and m∗).
Remark 2.11 Programs of the form (P; (Q; R)) and ((P; Q); R) can be proved to be equal; by convention, both can be written as P; Q; R.

Fact 2.12 Every program P in the sense of [13,12] can be seen as a program over rules with the initial object as external interface: ⟨G, H⟩ ∈ P) in the sense of [12] if and only if ⟨iG, iH, idI⟩ ∈ P'), where P' is yielded from P by substituting every elementary program ⟨L ⇒ R⟩ with Fix(⟨I → L ⇒ R⟩).
Example 2.13 (Fix operator) The Fix operation is not a true computation step, but an interface manipulation, mainly used for normalization and in con- text of sequential composition. For the rule AddNode : ⟨∅ → ∅ ⇒ ⟩, the use of Fix is illustrated in Figure 1: We will find ⟨m', m∗, mAddNode⟩∈ AddNode) if and only if ⟨m', m∗ ◦ mAddNode, id∅⟩∈ Fix(AddNode)). The different semantics are emphasized by bold morphisms.

mAddNode

∅	1
m'	m∗
mAddNode

∅	∅	1
m'	m∗

G  G+ 1	G	G+ 1
Figure 1. AddNode and Fix(AddNode)

Example 2.14 (sequential composition) We distinguish two uses of the sequential composition: with and without handover. Consider the rules
AddNode :  ⟨∅ → ∅ ⇒  ⟩ DeleteNodeN : ⟨  →  ⇒ ∅ ⟩ DeleteNode : ⟨∅ →  ⇒ ∅ ⟩
The program AddNode; DeleteNodeN has no observable effect: a node is added in the first step and deleted in the second step (sequential composition with handover). The program Fix(AddNode); DeleteNode also adds a node in the first step; in the second step however, a nondeterministically chosen, isolated node is deleted (sequential composition without handover). The bold mor- phisms in Figure 2 mark the differences in the external interface condition of the second rule application.
∅  ∅ 	 ∅	∅	 ∅
 		
'
G	G+ 1	G	G
Figure 2. Sequential composition with and without handover

In the following, we will consider only non-deleting rules with external interface in M. For a morphism a: A → B, let dom(m)= A and codom(m)= B.

Fact 2.15 (every morphism in M) For non-deleting rules with external interface in M, i.e. rules of the form ρ = ⟨X ‹→ L ↔ K ‹→ R⟩, the ρ-induced morphism mρ: X ‹→ R is in M. For every derivation m' ⇒ρ,m m∗, the mor- phism m∗ ◦mρ is in M and there is a morphism m∗: codom(m') ‹→ codom(m∗) in M such that m∗ ◦ m' = m∗ ◦ mρ. Consequently, for every program computa- tion ⟨m', m∗, mP⟩∈ P), the morphism mP: dom(m') ‹→ dom(m∗) is in M and
there is a morphism m∗: codom(m') → codom(m∗) with m∗ ◦ m' = m∗ ◦ mP.
P	P
Furthermore m' in M implies m∗ in M.

The Satisfiability Problem
After we give a formal definition of the satisfiability problem of high-level con- ditions, we will present a construction that, for any given condition, will yield a program over rules with external interface, trying to construct a satisfiable object.
Definition 3.1 (satisfiability problem) For a given category C, the satis- ﬁability problem is the problem to decide for any given condition c, whether or not ∃G ∈ C. G |= c.
Like the satisfiability problem of first-order logic on graphs and on finite structures in general [21,5], the satisfiability problem of graph conditions and high-level conditions in general is undecidable [11]. We seek a correct and com- plete algorithm, not always guaranteed to terminate. The algorithm answers yes, as soon a result is found, answers no, if it terminates without results, and does not answer in case of non-termination.
condition c	yes/no/no answer
	

The idea of our algorithm is to use the given condition in a constructive way by adding elements of positive statements if necessary while checking the absence of forbidden elements. The result is a monotone algorithm which non- deterministically progresses towards an object satisfying the input condition.

Theorem 3.2 (SeekSat) For  each  condition  c,  there  is  a  program
SeekSat(c) that is correct and complete, i.e.,
⟨idI, iM , idI⟩∈  SeekSat(c))  implies M |= c,
(∃H ∈ C. H |= c) implies ∃M ∈ C. ⟨idI, iM , idI⟩∈ SeekSat(c)).

Satisfaction of conditions by objects is defined by presence (or absence) of morphisms. For each condition c, we define two programs Sat(c) and Sat(c), that for a given input p': P ‹→ G in M are supposed to deliver some results p∗: P ‹→ H in M, with the properties p∗ |= c and p∗ |= c, respectively.
Construction. (SeekSat) For a condition c over the initial object I in MNF, define SeekSat(c)= Fix(Sat(c)). For a condition over P in MNF, define Sat and Sat as follows:

Sat(∃a)	= if ¬∃a then	'
'∼ {⟨P ‹→ C' ⇒ C⟩} fi

P ‹→C ‹→C=a,C /=C
Sat(∃(a, c)) =	P ‹→C'‹→C=a{⟨P ‹→ C' ⇒ C⟩}; Sat(c)
Sat(∧j∈J cj)= while (¬∧j∈J cj) do ;j∈J if ¬cj then Fix(Sat(cj)) fi od
where ;j∈{1,...,n}Pj = ((P1; P2); ... ; Pn).
Sat(∃a)	= if ∃a then Abort fi
a
Sat(∃(a, c)) = while ∃(a, c) do ⟨⟨P ‹→ C ⇒ C⟩, c⟩; Sat(c) od



Sat(∧j∈J cj)= 

j∈J
{Sat(cj)}

Sat(true) = Skip, Sat(true) = Abort, Sat(¬c) = Sat(c), and Sat(¬c) =
Sat(c).
In the case of Sat, existential statements correspond to an expansion of ex- isting substructures (if necessary): Given a morphism P ‹→ G, the program Sat(∃a) non-deterministically extends any partial occurrence C' to C, pro- vided ∃a is not already satisfied. Similarly, given a morphism P ‹→ G, the program Sat(∃(a, c)) non-deterministically extends any partial occurrence C' to C and subsequently applies Sat(c) on that occurrence. Moreover, conjunc- tion corresponds to an iterated random sequentialization until a solution is found (this iteration may not terminate). The completeness of Fix(Sat(c)) implies that the execution order of the subprograms cj is irrelevant for the overall problem, and it suffices to consider just one sequentialization. Nega- tion corresponds to a switch to the complementary Sat, and no computation is necessary in the case of true.
For the complementary Sat, the (non)satisfiability of a basic existential statement ∃a is just checked: If ∃a is satisfied, the computation is ended and a depth-first interpreter would backtrack. For a nested existential statement
∃(a, c), an occurrence of C that does satisfy c is selected in the hope that a subsequent application of Sat(c) yields a result in which C does not satisfy c (this iteration may not terminate). Conjunction corresponds to nondetermin- istic choice between alternatives: only one subcondition has to be dissatisfied such that the negation of conjunction becomes satisfied. Negation corresponds to a switch to the complementary Sat, and the computation is ended in the

case of true.


Remark 3.3 For abbreviated conditions, the construction of Sat and Sat is extended as follows:

	

Sat(∀(a, c)) = Sat(∃(a, ¬c))
Sat(false)	= Abort
Sat(c ⇒ d) = Sat(¬c ∨ d)= {Sat(c), Sat(d)}
Sat(∨j∈J cj)= Sat(∧j∈J ¬cj)
Sat(∀(a, c)) = Sat(∃(a, ¬c))
Sat(false)	= Skip
Sat(c ⇒ d) = Sat(¬c ∨ d)
Sat(∨j∈J cj)= Sat(∧j∈J ¬cj)


Remark 3.4 Sat(c) is a program of finite size for every condition c in MNF: As we consider only finite conjunctions and disjunctions of conditions and the number of all decompositions P ‹→ C' ‹→ C is finite (a consequence of a finite number of M-matches), all program sets are finite and the sequentialization in case of Sat(∧j∈J cj) is of finite length.

Example 3.5 (satisfiable condition) Consider the following graph condi-

tion c = ∀(
, ∃(
)) ∧ ¬∃() ∧ ∃() expressing “All nodes have an

outgoing edge, there exists no cycle of length two and there is a node”. The program SeekSat(c) is:


Fix(while ¬c do if ∃( 1, ¬∃(

)) then // P1

Fix(while ∃(
, ¬∃(
)) do

⟨⟨∅ → 1 ⇒ 1⟩, ¬∃(
)⟩; // select a node

if ¬∃(
{⟨
) then
→	⇒

⟩, ⟨

→

⇒
⟩} // choice

fi od) fi
if ∃() then Fix(if ∃() then Abort fi) fi // P2 if ¬∃() then Fix({⟨∅→ ∅⇒ ⟩}) fi // P3
od)

A fragment of the semantics of SeekSat(c) is depicted below by represent- ing each morphism with its codomain (all depicted morphisms have I as do-

main/interface).





There exists some G ∈ Graph such that ⟨idI, iG, idI⟩ ∈  SeekSat(c)), hence
c is satisfiable.
The rule sets in the cases of Sat(∃a) and Sat(∃(a, c)) are minimal. For every rule left out, there is a satisfiable condition for which SeekSat is not complete anymore. We show this exemplarily for the cases P ∼= C' and C' ∼= C of Sat(∃(a, c))
Example 3.6 (minimality)   Assume,   it  is  possible  to exclude  the   case   C' =∼ C   for   Sat(∃(a, c)),   i.e.   redefine

Sat(∃(a, c)) =	'
'∼ {⟨P ‹→ C' ⇒ C⟩}; Sat(c).	Then the con-

dition
P ‹→C ‹→C=a,C /=C
0	1	0	1

c1 = ∃(, ∃( )) ∧ ∃(, ∃( )) ∧ ¬∃(  )
is satisfied by the graph 0	1, but there is no ⟨id , m∗, id ⟩∈  SeekSat(c )).
I	I	1
Assume, it is possible to exclude the case P ∼= C' for Sat(∃(a, c)), i.e. re-

define Sat(∃(a, c)) =	'
~ ' {⟨P ‹→ C' ⇒ C⟩}; Sat(c). Then the

condition
P ‹→C ‹→C=a,P /=C
0	1	0	1

c2 = ∃(, ∃( )) ∧ ∃(, ∃( )) ∧ ¬∃(  )
is satisfied by the graph	0	1, but there is no ⟨id , m∗, id ⟩∈ SeekSat(c )).
I	I	2

Fact 3.7 (monotonicity) Sat and Sat are monotone: for every condition c in MNF, for every ⟨m', m∗, id⟩∈ Fix(Sat(c)) [Fix(Sat(c))] there is a total morphism x: codom(m') → codom(m∗) in M from the codomain of m' to the codomain of m∗ such that x ◦ m' = m∗.
Proof As every condition c is in MNF, every morphism a: P → C in every subcondition ∃a and ∃(a, c) is in M. Consequently, Sat and Sat are programs over non-deleting rules with total interface (see Fact 2.15).	 
The proof of Theorem 3.2 is based on the following lemma.

Lemma 3.8 (Sat and Sat) Let id: P → P be the identity over P. For each condition c over an object P, Sat(c) and Sat(c) are programs that, with respect to the satisﬁability problem, are

(correct) ∀m', m∗ ∈ M. ⟨m', m∗, id⟩∈ Fix(Sat(c))) implies m∗ |= c,
∀m', m∗ ∈ M. ⟨m', m∗, id⟩∈ Fix(Sat(c))) implies m∗ |= c, (complete) ∀m',x ∈ M. x◦m' |= c implies ∃m∗, y,z ∈ M. ⟨m', m∗, id⟩∈ 
 Fix(Sat(c))), m∗ = z ◦ m' and x = y ◦ z.
∀m',x ∈ M. x◦m' |= c implies ∃m∗, y,z ∈ M. ⟨m', m∗, id⟩∈ 
 Fix(Sat(c))), m∗ = z ◦ m' and x = y ◦ z.
P
m 
 H
x
Completeness means, if a given M-morphism m' can be extended by a M-morphism x to satisfy c, there is a transition from m' to a M-morphism m∗ (m∗ = z ◦ m' for some M-morphism z) and m∗ lies exactly along the way to x ◦ m' (x = y ◦ z) preserving the possibility to eventually yield x ◦ m'. While this does not imply a guarantee to reach x ◦ m' at all, we can reach a possibly smaller morphism, namely m∗ that also satisfies the subcondition c (see correctness).
Proof of Lemma 3.8. See long version at [1].	 
Proof of Theorem 3.2. Without loss of generalization c is a condition over the initial object I in M-normal form (see Fact 2.3). As SeekSat(c) is defined as Fix(Sat(c)), the correctness and completeness of SeekSat(c) are special cases of the correctness and completeness of Fix(Sat(c)). More precisely, as m' = idI: I ↔ I and any morphism from the initial object is in M and c is a condition over I, the correctness of Fix(Sat(c)) reduces to
⟨idI, iM , idI⟩∈ Fix(Sat(c))) implies iM |= c implies M |= c, and the completeness of Fix(Sat(c)) reduces to
H |= c implies iH |= c implies ∃iM . ⟨idI, iM , idI⟩∈  Fix(Sat(c))).


I
idI
I




x


y
H

A consequence of the completeness of Theorem 3.2 is that termination implies a decision of the problem.
Corollary 3.9  If	SeekSat(c)	terminates	and	∄M.	⟨idI, iM , idI⟩	∈
 SeekSat(c)), then c is not satisﬁable.
SeekSat is guaranteed to terminate for a certain fragment of conditions.
Hence it is able to decide the satisfiability problem for this subclass.
Let Cond be the set of all conditions and let BCond be the ∃a-fragment of non-nested existential conditions, i.e. Boolean formulas over basic conditions
∃a.
Theorem 3.10 For the ∃a-fragment of Cond, SeekSat is guaranteed to ter- minate.
A consequence of Theorem 3.10 and Corollary 3.9 is the decidability of BCond.
Corollary 3.11 For the ∃a-fragment of Cond, SeekSat decides the satisﬁa- bility problem.
Let BCond\∧ be the set of all non-nested existential conditions without conjunction. The proof of Theorem 3.10 is based on the following property: For all conditions c ∈ BCond\∧ that do not contain conjunction, for all tuples
⟨m', m∗, id⟩ in the semantics of Fix(Sat(c)), the satisfiability of all conditions in BCond\∧ is preserved from m' to m∗, or the satisfiability of c is guaranteed from m∗.
Lemma 3.12 For all conditions c  ∈  BCond\∧, for all ⟨m', m∗, id⟩  ∈
 Fix(Sat(c))),
∀d ∈ BCond\∧. m' |= d implies m∗ |= d,
or	∀x ∈M with x ◦ m∗ ∈ M. x ◦ m∗ |= c.
Proof of Lemma 3.12. See long version at [1].	 
Proof of Theorem 3.10. Let c ∈ BCond in conjunctive normal form, i.e. c = ∧j∈J cj and cj ∈ BCond\∧ for each j ∈ J = {1,... , n}. The pro- gram SeekSat(c) terminates if the while iteration of Sat(∧j∈J  cj) termi-
nates. The iteration is guaranteed to terminate after at most n iterations, as in each iteration ⟨m1, mn+1, id⟩ ∈  ;j∈J if ¬cj then Fix(Sat(cj)) fi) with
⟨mj, mj+1, id⟩ ∈ if ¬cj then Fix(Sat(cj)) fi) for j ∈ J , there must be an
index k ∈ J in which the satisfiability of subcondition ck is established and guaranteed from m∗. If such a step does not exists, the satisfiability of each condition cl, l ∈ J , is be preserved in each step j ∈ J and for the whole

iteration. This case however can be excluded: by correctness of Fix(Sat(c)), this would mean ∧j∈J cj is already satisfied and contradict the test ¬∧j∈J cj at the begin of the while iteration.	 
In the following, we briefly state the implications of our results to the complementary tautology problem.
Definition 3.13 (tautology problem) For a given category C, the tautology problem is the problem to decide for any given condition c, whether or not
∀G ∈ C. G |= c.
Each instance of the tautology problem may be viewed as an instance of the satisfiability problem, by negating both the input condition, as well as the answer. However, in contrast to positives answers, negative answers of a satisfiability algorithm may only be lifted to the tautology problem in case of termination and completeness. Otherwise, the incompleteness of the algorithm would correspond to unsoundness in the case of the tautology problem. A consequence of Theorem 3.2, Theorem 3.10 is the following:
Corollary 3.14 For the ∃a-fragment of Cond, SeekSat decides the tautology problem.

Implementation and Optimization
In this section, we want to discuss practical aspects concerning an implemen- tation of SeekSat and further optimizations.
Neither a pure depth-first, nor a pure breadth-first evaluation of SeekSat is guaranteed to find a result for a satisfiable condition: A depth-first execution may take a wrong choice towards an infinite subtree of the transition system without results, a breadth-first evaluation is at least not possible on the level of programs, as the unfolded transition system tree may have an infinite degree at some points. Either a breadth-first evaluation on the level of transformation rules or a small results-first evaluation seems to be the best way to organize the search.
The main goals of any non-deterministic algorithm is to reduce the number of available choices and to minimize backtracking. Therefore, the number of “equivalent” matchings that lead to isomorphic results must be reduced. As application conditions restrict the number of matches, rules with interface K should be replaced by rules with smaller interface K' and a positive existential application condition, if possible. In context of external interfaces, however, this seems to be only viable for the case Sat(∃a). Moreover, isomorphism checks should be applied to avoid unnecessary recomputations and seem ap-

propriate especially in context of a breadth-first or size-based evaluation.
In case of conjunction, disjunction and for all program sets in general, the order in which subprograms are executed is free to choose. Known heuristics
[15] should be applied here to determine an order in which viable choices are tried first and while others are suppressed until a later point. The proposi- tional structure of conditions may be even used to rule out certain choices and to prune whole branches of the search tree. For the rule sets in case of
∃a and ∃(a, c), at least an initial idea is to order the rules by the number of elements they will introduce, with the aim to try to introduce as few elements as possible.
Before SeekSat is constructed for a condition c, the condition should be brought into normal form and optimized by a set of straightforward substitu- tions, e.g., ∃(a, ∃b) may be substituted by ∃(b ◦ a).
In general, the information flow within programs should be improved, e.g., to avoid subsequent double checks of conditions. E.g., in case of Sat(∧j∈J cj), the use of variables would bring some improvement:
while ∧j∈J varj do foreach j ∈ J do
if ¬cj then Fix(Sat(cj)); foreach j ∈ J do varj := false od fi;
varj := true
od od
For practical purposes, artificial bounds may be introduced to yield a correct and terminating, but incomplete algorithm such that for every condition c, a positive answer will imply the satisfiability of c for some object G ∈ C, but a negative answer will not always imply the absence of such an object. These restrictions could be based on CPU time, object’s sizes, or the length or width of the search tree, and should preferably apply only for nested conditions c /∈ BCond.
condition c	yes/no/unsure
	


Related Concepts
In this section, we try to relate SeekSat to algorithms for the satisfiability problem (SAT) of first-order formulas. Before that, we briefly review the connection of first-order formulas and high-level conditions and discuss the

main differences between SAT algorithms on high-level conditions and first- order formulas.
In [11], transformations between graph conditions and first-order logic on graphs are considered, similar to [20]. For directed, labeled graphs, both con- cepts are expressively equivalent. The proof is based onto two steps: First, there are transformations between M-satisfiable conditions (this definition) and A-satisﬁable conditions [10], i.e. conditions with a semantics in which the morphisms required to be present or absent (p, q in the definition) are arbitrary. Second, there are transformations between A-satisfiable graph con- ditions and graph formulas, relating the semantics of formulas and conditions: on the one hand assignments of variables to a structure representing a graph, on the other hand arbitrary morphisms from the graphs in the condition to a tested graph. Note, the transformations of the first step are high-level, those of the second step are graph-specific.
[10,11]	[11]


SeekSat [this	SAT tools [23,22,17,4,2]

In case of directed, labeled graphs, the translation into first-order formulas allows to use existing tools to solve the satisfiability problem of conditions, and may form the basis of an evaluation of SeekSat and its implementation. Still, the point of SeekSat is to make a translation of the problem unnecessary by providing an implementation of a SAT algorithm for any category satisfying the assumptions of Section 2.
The main differences between algorithms on high-level conditions and for- mulas are the following: high-level algorithms become structure-specific once they are “instantiated” for a given category. While SAT algorithms for general first-order logic necessarily consider arbitrary structures (and have to be re- stricted by a set of axioms to a target structure, which adds to the complexity of the problem), SeekSat will, by definition, only consider objects of the given category C. Another difference is represented by M- and A-satisfiability: dis- tinct elements in M-satisfiable conditions are mapped onto distinct elements in the domain. In formulas, it remains open if the values of variables are equal or distinct, unless it is explicitly stated. Finally, an algorithm on conditions can and should use the fact that conditions make quantifications and state- ments in bulks. In this sense, conditions may have a lower logical complexity when compared to their translations in first-order logic.

Most first-order SAT solvers, including the most successful ones [18] such as Darwin [2] and Paradox [4] are based on ﬁnite model building, like their idols Mace2 [16], Mace4 [17], Falcon [22] and SEM [23]. Most of these tools (except Darwin) approach the satisfiability problem by translating it, for a given domain size, into a decidable SAT problem of either propositional logic or at least ground clauses with equality. This has the advantage of using existing implementations of well-known (propositional) SAT algorithms, such as the dominating Davis-Putnam-Logemann-Loveland (DPLL) algorithm [6] and its derivatives, thus benefiting from years of experience and know-how. However, the translation phase is usually associated with a significant blow- up: Generating all ground instances over a domain of size n for a clause with v variables will yield nv instances alone [17]. Also, the problem has to be solved again and again for increasing domain sizes, while only few tools are capable to reuse earlier results.
In contrast, SeekSat contains no such translation. Nevertheless, SeekSat seems, to some degree, related to the family of enumeration algorithms that are based on tree search and splitting, like the DPLL algorithm. SeekSat is based on a tree search where internal nodes correspond to partial solutions (morphisms), branches are choices (partitioning the search space), and leaf nodes are complete results or deadends. Instead of splitting, i.e. the process of branching by selecting a propositional variable x from a formula and assigning true and false, respectively, SeekSat will either skip, modify the morphism by adding elements to its codomain (positive statement) or backtrack (negative statement), depending on the satisfaction of the considered subcondition by the current morphism. While currently not the case, SeekSat can be made aware of the propositional structure of a condition to exclude whole branches of the search tree without losing results, as discussed in Section 4. This should strenghten the above relation.
Recently, the Model Evolution Calculus [3,2] was described, which lifts the propositional DPLL procedure to first-order logic. Similar to SeekSat, the split rule of the ME calculus is restricted to positive literals (the model evolves only in case of positive statements). Where SeekSat uses morphisms to apply a rule, the ME calculus uses unification. Like SeekSat, the ME calculus is shown to be correct and complete. It is claimed that the ME calculus can decide the Bernays-Sch¨onfinkel (∃∀) fragment of first-order logic. The SAT solver Darwin is an implementation of the ME calculus [2] and was among the best solvers at the CADE 2007 [18].

Conclusion
We have presented a non-deterministic algorithm for the satisfiability prob- lem of high-level conditions. It was shown that the algorithm is correct and complete, thus it is not guaranteed to terminate in general. A fragment of con- ditions was identified, namely ∃a-fragment of conditions, for which the termi- nation of the algorithm was proved. Consequently, the algorithm can decide the satisfiability problem as well as the complementary tautology problem for this subclass. We have discussed certain aspects concerning an imple- mentation and its optimization. For practical purposes, the algorithm can be converted into a non-complete, but terminating algorithm. The algorithm was formally described by using programs over transformation rules with external interfaces.
Further topics include
	an investigation, whether or not the presented algorithm is (directly) portable to conditions with arbitrary satisfiability [10,11] (conditions can no longer assumed to be in MNF and one may require rules with K → R not in M),
a systematic study of rules with external interfaces,
	an algorithm for approximating the tautology problem (such an algorithm will yield results in some instances for which SeekSat does not terminate),
an implementation of SeekSat,
	further comparison with existing first-order satisfiability algorithms and tools, such as Darwin [2], Mace4 [17] and SEM [23].

References
http://formale-sprachen.informatik.uni-oldenburg.de/pub/eindex.html.
Baumgartner, P., A. Fuchs and C. Tinelli, Implementing the model evolution calculus, International Journal on Artificial Intelligence Tools 15 (2006), pp. 21–52.
Baumgartner, P. and C. Tinelli, The model evolution calculus, in: Proc. 19th International Conference on Automated Deduction (CADE), LNAI (LNCS) 2741 (2003), pp. 350–364.
Claessen, K. and N. S¨orensson, New techniques that improve MACE-style ﬁnite model ﬁnding, in: Proc. CADE-19 Workshop on Model Computation (MODEL), 2003.
Courcelle, B., Graph rewriting: An algebraic and logical approach, in: Handbook of Theoretical Computer Science, volume B, Elsevier, Amsterdam, 1990 pp. 193–242.
Davis, M., G. Logemann and D. Loveland, A machine program for theorem-proving, Commun. ACM 5 (1962), pp. 394–397.
Ehrig, H., K. Ehrig, A. Habel and K.-H. Pennemann, Theory of constraints and application conditions: From graphs to high-level structures, Fundamenta Informaticae 74 (2006), pp. 135– 166.

Ehrig, H., K. Ehrig, U. Prange and G. Taentzer, “Fundamentals of Algebraic Graph Transformation,” EATCS Monographs of Theoretical Computer Science, Springer-Verlag, Berlin, 2006.
Ehrig, H., A. Habel, J. Padberg and U. Prange, Adhesive high-level replacement systems: A new categorical framework for graph transformation, Fundamenta Informaticae 74 (2006), pp. 1–29.
Habel, A. and K.-H. Pennemann, Satisﬁability of high-level conditions, in: Graph Transformations (ICGT’06), LNCS 4178 (2006), pp. 430–444.
Habel, A. and K.-H. Pennemann, Correctness of high-level transformation systems relative to nested conditions, 2008, submitted.
Habel, A., K.-H. Pennemann and A. Rensink, Weakest preconditions for high-level programs, in: Graph Transformations (ICGT’06), LNCS 4178 (2006), pp. 445–460, a long version is available as technical report.
Habel, A. and D. Plump, Computational completeness of programming languages based on graph transformation, in: Proc. Foundations of Software Science and Computation Structures, LNCS 2030 (2001), pp. 230–245.
Heckel, R. and A. Wagner, Ensuring consistency of conditional graph grammars, in:
SEGRAGRA’95, ENTCS 2, 1995, pp. 95–104.
Kumar, V., Algorithms for constraint satisfaction problems: A survey, AI Magazine 13 (1992),
pp. 32–44.
McCune, W., MACE 2.0 reference manual and guide, Tech. Memo ANL/MCS-TM-249, Mathematics and Computer Science Division, Argonne National Laboratory, Argonne, IL (2001).
McCune, W., Mace4 reference manual and guide, Tech. Memo ANL/MCS-TM-264, Mathematics and Computer Science Division, Argonne National Laboratory, Argonne, IL (2003).
Pfenning, F., editor, “Proc. 21th International Conference on Automated Deduction (CADE),” LNAI (LNCS) 4603, Springer, 2007.
Plump, D. and S. Steinert, Towards graph programs for graph algorithms, in: Graph Transformations (ICGT’04), LNCS 3256 (2004), pp. 128–143.
Rensink, A., Representing ﬁrst-order logic by graphs, in: Graph Transformations (ICGT’04), LNCS 3256 (2004), pp. 319–335.
Trakhtenbrot, B. A., The impossibility of an algorithm for the decision problem on ﬁnite classes (In Russian), Doklady Akademii Nauk SSSR 70 (1950), pp. 569–572, english translation in: Nine Papers on Logic and Quantum Electrodynamics, AMS Transl. Ser. 2, 23:1–5, 1963.
Zhang, J., Constructing ﬁnite algebras with FALCON, Journal of Automated Reasoning 17
(1996), pp. 1–22.
Zhang, J. and H. Zhang, SEM: A system for enumerating models, in: Proc. International Joint Conferences on Artiﬁcial Intelligence (IJCAI), 1 (1995), pp. 298–303.
