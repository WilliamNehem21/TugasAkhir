Available online at www.sciencedirect.com


Electronic Notes in Theoretical Computer Science 336 (2018) 241–256
www.elsevier.com/locate/entcs

A Game Semantics of Concurrent Separation Logic
Paul-André Mellièsa Léo Stefanescob
a IRIF, CNRS, Université Paris Diderot
b École Normale Supérieure de Lyon

Abstract
In this paper, we develop a game-theoretic account of concurrent separation logic. To every execution trace of the Code confronted to the Environment, we associate a specification game where Eve plays for the Code, and Adam for the Environment. The purpose of Eve and Adam is to decompose every intermediate machine state of the execution trace into three pieces: one piece for the Code, one piece for the Environment, and one piece for the available shared resources. We establish the soundness of concurrent separation logic by interpreting every derivation tree of the logic as a winning strategy of this specification game.
Keywords: Concurrent separation logic, game semantics specification logic

Introduction
Concurrent separation logic (CSL) is an extension of Reynold’s separation logic [12] formulated by O’Hearn [10] to establish the correctness of concurrent imperative programs with shared memory and locks. This specification logic enables one to establish the good behavior of these programs in an elegant and modular way, thanks to the frame rule of separation logic. A sequent of concurrent separation logic
r1 : P1,..., rn : Pn ▶ {P } C {Q}
consists of a Hoare triple {P}C{Q} together with a context Γ= r1 : P1,..., rn : Pn which declares a number of resource variables rk (or mutexes) together with the CSL formula Pk which they satisfy as invariant. The validity of the program logic relies on a soundness theorem, which states that the existence of a derivation tree in concurrent separation logic	π
.

r1 : P1,..., rn : Pn ▶ {P } C {Q}
ensures (1) that the concurrent program C will not produce any race condition at execution time, and (2) that the program C will transform every initial state

https://doi.org/10.1016/j.entcs.2018.03.026 1571-0661/© 2018 Published by Elsevier B.V.
This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).

satisfying P into a state satisfying Q when it terminates, as long as each resource rk allocated in memory satisfies the CSL invariant Pk. The soundness of the logic was established by Brookes in his seminal papers on the trace semantics of concurrent separation logic [5,6]. His soundness proof was the object of great attention in the community, and it was revisited in a number of different ways, either semantic [13], syntactic [2] or axiomatic [7] and formalised in proof assistants. One main technical challenge in all these proofs of soundness is to establish the validity of the concurrent rule:
 Γ ▶ {P1} C1 {Q1}	Γ ▶ {P2} C2 {Q2}	Concurrent Rule
Γ ▶ {P1 ∗ P2} C1	C2 {Q1 ∗ Q2}
and of the frame rule:

Γ ▶ {P } C {Q}
Γ ▶ {P ∗ R} C {Q ∗ R}
Frame Rule

In this paper, we establish the validity of these two rules (and of CSL at large) based on a new approach inspired by game semantics, which relies on the observation that the derivation tree π of CSL defines a winning strategy [π] in a specification game. As we will see, the specification game itself is derived from the execution of the code C and its interaction with the environment (called the frame) using locks on the shared memory. The specification game expresses the usual rely-and-guarantee conditions as winning conditions in an interactive game played between Eve (for the code) and Adam (for the frame).
In the semantic proofs of soundness, two notions of “state” are usually considered, besides the basic notion memory state which describes the state of the variables and of the heap: (1) the machine states which are used to describe the execution of the code, and in particular include information about the status of the locks, and
(2) the logical states which include permissions and other information invisible at the execution level, but necessary to specify the states in the logic. In particular, the tensor product ∗ of separation logic requires information on the permissions, and it is thus defined on logical states, not on machine states. The starting point of the paper is the observation that there exists a third notion of state, which we call separated state, implicitly at work in all the semantic proofs of soundness. A separated state describes which part of the global (logical) state of the machine is handled by each component interacting in the course of the execution. It is defined as a triple (σC, σ, σF ) consisting of
the logical state σC ∈ LState of the code,
the logical state σF ∈ LState of the frame,
	a function σ : {r1,..., rn} → LState + {C, F} which tells for every resource variable r whether it is locked and owned by the code, σ(r)= C, locked and owned by the frame, σ(r)= F , or available with logical state σ(r) ∈ LState.
This leads us to a “span”

machine states
refines
separated states
refines
logical states
(1)

where the two notions of machine state and of logical state are “refined” by the notion of separated state, which conveys information about locks (as machine states) and about permissions (as logical states). Namely, every separated state
(σC, σ, σF ) ∈ SState
refines the logical state ②(σC, σ, σF ) defined by the separation tensor product

②(σC, σ, σF )	d=ef
σC ∗	②
r∈dom(σ)
σ(r) , ∗ σF	(2)

where dom(σ) denotes the set of resources available in σ, in the sense that σ(r) /= C, F . Similarly, every separated state (σC, σ, σF ) refines a machine state (μ, L) defined as the memory state μ underlying the logical state (2) just constructed, plus the set of locked resources L = domC(σ) domF(σ), see §8 for details. In the same way as the notion of logical state is necessary to define the tensor product
∗ of separation logic, and thus to specify the states, the shift from machine states to separated states is necessary to specify the code, and the way it interacts with its environment and with its resources. Our point here is that the formulas P and Q of separation logic in a Hoare triple Γ ▶ {P } C {Q} do not specify the logical state σ = ②(σC, σ, σF ) ∈ LState of the machine itself, but the fragment σC of this
logical state σ owned by the code C at the beginning and at the end of the execution.
The notion of separated state is thus at the very heart of the very concept of Hoare triple in separation logic.
We follow the following track in the paper. After discussing the related work, we formulate the two notions of machine states and of machine instructions in §3. This enables us to define the notion of execution traces on machine states in §4 and a number of algebraic operations on them. The trace semantics of concurrent programs, and their interpretation as transition systems, is then formulated in §5 and §6. Once the notion of machine state has been used to describe the trace semantics of the language, we move to the logical side of the span, and formulate the notions of logical state in §7 and the notion of separated state in §8. In §10, we explain how to associate to every execution trace t a specification game played on the paths of the graph of separated states, which is defined in §9. The moves of those games express the ownership discipline enforced by separation logic, and in particular the discipline associated to the locks in concurrent separation logic. Finally, we show in §11 that CSL is sound by proving that every derivation tree of the logic defines a strategy, which lifts each step of the Code of an execution trace into the graph of separated states.

Related Work
Several proofs of soundness have already been given for concurrent separation logic. The first proof of correctness was designed by Brookes in [5,6] using semantic ideas. In his proof, every program C is interpreted as a set of “action traces”, defined as finite or infinite sequences of “actions” that look like:

read 71 from x, read 36 from y, acquire lock r, .... 
An interesting feature of the model is that these action traces do not mention (at least explicitly) the machine states produced by the Code at execution time. The environment is taken into account through the existence of non sequentially consistent traces such as
write 89 in x, read 14 from x
in the model. The idea is that the Environment presumably changed the value of the variable x between the two actions of the Code. Separation in the logic enables one to decompose actions traces into local computations, in order to reflect the program’s subjective view of the execution.
Vafeiadis gave another proof of correctness [13] based on more directly operational intuitions. In his proof, the Code is interpreted as a transition system whose vertices are pairs (C, σ) consisting of the Code C and of the state σ of the memory, and where edges are execution steps. The core of the soundness proof is that each step of the execution preserves a decomposition of the heap into three parts, which correspond respectively to the Code, the resources, and the Frame. The proof is done by induction on the derivation tree π establishing the triple Γ ▶ {P } C {Q} in concurrent separation logic. The idea of using separated states thus comes from Vafeiadis’ proof, which is the closest to ours. One difference, however, besides the game-theoretic point of view we develop, is that we have a more intensional description of separated states, provided by the function σ which tracks the states of each of the available locks.
In contrast to the semantic proofs mentioned above, Balabonski, Pottier and Protzenko [2] developed a purely syntactic proof of correctness for Mezzo, a functional language equipped with a type-and-capability system based on concurrent separation logic. The soundness of the logic follows in their approach from a progress and a preservation theorem on the type system of Mezzo.
Our focus in this work is to develop a game-theoretic approach to concurrent separation logic. For that reason, we prefer to keep the logic as well as the concurrent language fairly simple and concrete. In particular, we do not consider more recent, sophisticated and axiomatic versions of the logic, like Iris [8,9].

Machine states and machine instructions
The purpose of this section is to introduce the notions of machine state and of machine instruction which will be used all along the paper. We suppose given countable sets Var of variable names, Val of values, Loc ⊆ Val of memory locations, and LockName of resources. In practice, Loc = N and Val = Z.
Definition 3.1 (Memory state) A memory state μ is a pair (s, h) of partial func- tions with finite domains s : Var ~fin Val and h : Loc ~fin Val called the stack s and the heap h of the memory state μ. The set of memory states is denoted State. The domains of the partial function s and of h are noted vdom(μ) and hdom(μ) respectively, and we write dom(μ) for their disjoint union.

Definition 3.2 (Machine state) A machine state s = (μ, L) is a pair consisting of a memory state μ and of a subset of resources L ⊆ LockName, called the lock state, which describes the subset of locked resources in s. The set of machine states is denoted MState.
A machine step is defined as a labelled transition between machine states, which can be of two different kinds:
s	m	sj	s	m	sj
depending on whether the instruction m ∈ Instr has been executed successfully (on the left) or it has produced a runtime error (on the right). We write m : s  sj when we do not want to specify whether the instruction has produced a runtime
error. The machine instructions which label the machine steps are defined below:
m ::= x := E | x := [E] | [E] := Ej | nop | x := alloc(E) | dispose(E) | P (r) | V (r)
where x ∈ Var is a variable, r ∈ LockName is a resource variable, and E, Ej are arithmetic expressions with variables. Typically, the instruction x := E assigns to the variable x the value E(μ) of the expression E in the memory state μ, the instruction P (r) locks the resource variable r when it is available, while the instruction V (r) releases it when it is locked, as described below:

E(μ)= v
r ∈/ L
r ∈/ L



(μ, L)
x:=E
(μ[x '→ v], L)
(μ, L)
P (r)
(μ, L  {r})
(μ, L  {r})
V (r)
(μ, L)

Thanks to the inclusion Loc ⊆ Val, an expression E may also denote a location. In that case, [E] refers to the value of the location E in memory. The instruction nop (for no-operation) does not alter the logical state, while x := alloc(E) allocates (in a non-deterministic way) some memory space on the heap, initializes it with the value of the expression E, and returns the address of the location to the variable x, while dispose(E) deallocates the location with address E.
It will be convenient in the sequel to write lock+(m) for the set of locks which are taken by an instruction m, that is, lock+(m)= {r} if m = P (r) and lock+(m)= ∅ otherwise; lock—(m) is the set of locks which are released by the instruction m, that is, lock—(m)= {r} if m = V (r) and lock—(m)= ∅ otherwise.

Execution traces
Now that the notion of machine state has been introduced, the next step towards the interpretation of programs is to define the notion of execution trace, with two kinds of transitions: the even transitions “played” by the Code, and the odd transitions “played” by the Environment.
Definition 4.1 (Traces) A trace t is a sequence of machine states

s  −e−n→v  s
−m−→1  s
−e−n→v
... −e−n→v  s	mp  s
−e−n→v  s

1	2	3
whose even transitions
mk
s
2p −−→
2p+1
2p+2

2k −−−→ s2k+1	1 ≤ k ≤ p

are labelled by an instruction mk ∈ Instr such that s2k

mk
s2k+1
and whose

last transition is played by the environment. The set of traces is denoted by Traces.
We write ∂0t = s1 and ∂1t = s2p+2 for the initial and the final states of a trace t ∈ Traces, respectively. The length len(t)= p is defined as the number of Code transitions in the trace, and

t[k]	=	s2k
m
−−−→
s2k+1

denotes the k-th even transition of the trace t, for 1 ≤ k ≤ len(t). Observe that a trace t always starts and stops by an Environment transition, and that its number of transitions is equal to 2 × len(t)+ 1. We point out the following fact which we will often use in our proofs and constructions:
Proposition 4.2 A trace t ∈ Traces is characterized by its initial state ∂0t and by its final state ∂1t, together with the sequence of Code transitions t[k] for 1 ≤ k ≤ len(t).
We introduce now a number of important algebraic constructions on execution traces, whose purpose is to reflect at the level of traces the sequential and parallel composition of programs.
Definition 4.3 (Sequential composition) Given two traces t1, t2 ∈ Traces such that ∂1(t1)= ∂0(t2), one defines t1 · t2 ∈ Traces as the trace of length len(t1)+ len(t2) with initial state ∂0(t1) and final state ∂1(t2), and with even transitions defined as
(t · t )[k]=  t1[k]	if 1 ≤ k ≤ p,
Definition 4.4 (Restriction) Let Tracesp denote the set of traces of length p.
Every increasing function f : {1, ..., p}→ {1, ..., q} induces a restriction function
f∗ : Traces q −→ Traces p
which transports a trace t of length q to a coinitial and cofinal trace f∗(t) of length p
∂0f∗(t)= ∂0t	∂1f∗(t)= ∂1t
defined by the instructions f∗(t)[k]= t[f (k)] for 1 ≤ k ≤ p.
Definition 4.5 (Shuﬄe) A shufle of two natural numbers p ∈ N and q ∈ N is a monotone bijection ω : {1,..., p} {1,..., q} → {1,...,p + q}. The set of shufles of p and q is denoted Shuﬄes(p, q).
Every shuffle ω ∈ Shuﬄes(p, q) induces a pair of increasing functions
ω1 : {1, ..., p}→ {1,...,p + q}	and	ω2 : {1, ..., q}→ {1,...,p + q}
defined by restricting ω to {1, ..., p} and to {1, ..., q}, respectively. From this follows immediately that
Proposition 4.6 Every shufle ω ∈ Shuﬄes(p, q) induces a function
ω∗ : Tracesp+q −→ Tracesp × Tracesq
which transports a trace t of length p + q to the pair (ω∗(t), ω∗(t)) ∈ Tracesp ×
1	2
Tracesq.

Definition 4.7 The parallel composition t1  t2 is the set of traces t ∈ Traces such that ω∗(t)= (t1, t2) for some shufle ω ∈ Shuﬄes(len(t1), len(t2)).
Note that every trace t in t1  t2 satisfies len(t) = len(t1)+ len(t2) and more importantly, that the parallel composition t1  t2 of two traces t1 and t2 is empty whenever the two traces t1 and t2 are not coinitial and cofinal.
The purpose of our last construction hide[r] is to “hide” the name of a resource variable r ∈ LockName in an execution trace.
Definition 4.8 The function hide[r]: Traces → Traces transforms every trace by applying the function
(μ, L) '−→ (μ, L \ {r})	:	MState −→ MState
to each machine state of the original trace, and the function

m '−→	nop	if m = P (r) or V (r)
m	otherwise
to the instructions of the trace.
:	Instr −→ Instr


Transition Systems
At this stage, we are ready to introduce the notion of transition system which we will use in order to describe the traces generated by a program of our concurrent language. Among these execution traces, one wishes to distinguish (1) the traces which terminate and return from (2) the other traces which are not yet finished or terminate and abort. This leads us to the following definition of transition system:
Definition 5.1 (Transition Systems) A transition system T = (T, T ) is a set of traces T ⊆ Traces closed under prefix, together with a subset T ⊆ T , whose traces are said to return.
We explain below how to lift to transition systems the algebraic operations defined on traces in the previous section §4.
Definition 5.2 The sequential composition of two transition systems T and Tj, is defined as the transition system T; Tj below:
T ; T j  = T ∪ {t · tj | t ∈ T , tj ∈ T j and ∂1t = ∂0tj}

Definition 5.3 The parallel composition of two transition systems T and Tj, is defined as the transition system T  Tj below:

T1  T2 =	 
t1  t2	 T1  T2  =	 
t1  t2
 

ti∈Ti
ti∈ Ti 

Definition 5.4 The transition system hide[r](T) associated to a transition system T
and to a lock r ∈ LockName is defined as follows:

Note that every instruction m ∈ Instr induces a transition system Jm) defined in the following way:

Jm)  = {s1 −e−n→v  s2 −m→ s3 −e−n→v  s4 | s2
m	env
 Jm) = {s1 −−→ s2 −→ s3 −−→ s4 | s2
m	s3 }
m	s3 }


the environment has made the transition s1 −e−n→v  s2 and returns when the machine
step s2 −m→ s3 is succesful, and does not abort. The following algebraic operation on transition systems reflects the computational situation of a program taking a lock r before executing, and releasing the lock r in case the program returns.
Definition 5.5 The transition system inside[r](T) associated to a transition sys- tem T and to a lock r ∈ LockName is defined as follows:
inside[r](T)= JP (r)); T; JV (r)).
The following operation on transition systems will enable us to interpret conditional branching on concurrent programs.
Definition 5.6 The transition system whentrue[P ](T) associated to a transition system T = (T, T ) and a predicate P : MState → {true, false, abort} on memory states is defined as follows:
whentrue[P ](T) = {t ∈ T | P (∂0t)= true}
whentrue[P ](T) = {t ∈ T | P (∂0t)= true}

where ∂0t = s2 denotes the first state played by Code in the trace t.
The transition system whenfalse[P ](T) is defined similarly, by replacing true by false in the definition. A subtle but important aspect of the interpretation of conditional branching in the language is that the evaluation of a boolean expression B may not succeed, typically because one of its variables x ∈ Var is not allocated. In that case, the evaluation produces an exception which is then handled by the operating system. This abort case is handled in our trace semantics by the definition of a dedicated transition system called whenabort[P, C], whose construction is detailed in the Appendix[1].





Trace semantics of the concurrent language

Now that we have defined the basic operations on transition systems, we are ready to define the operational and interactive semantics of our concurrent language. The language is constructed with Boolean expressions B, arithmetic expressions E and

commands C, using the grammar below:
B ::= true | false | B ∧ Bj | B ∨ Bj | E = Ej E ::= 0 | 1 | ... | x | E + Ej | E ∗ Ej
C ::= x := E | x := [E] | [E] := Ej | C; Cj | C1  C2 | skip
| while B do C | resource r do C | with r when B do C
| if B then C1 else C2 | x := alloc(E) | dispose(E)
The parallel composition operator C1  C2 enables the two programs C1 and C2 to interact concurrently through mutexes called resources. A resource r is declared using resource r and acquired using with r when B do C, which waits for the Boolean expression B to be true in order to proceed. Of course, a mutex can be held by at most one execution thread at any one time.
In the semantic approach we are following, every command C is translated into a transition system JC) which describes the possible interactive executions of C, and whether they return.

Code C
translation
Transition system JC)

The interpretation JC) is defined by structural induction on the syntax of the command C. To each leaf node C, one associates an instruction m ∈ Instr
x := E | x := [E] | [E] := [Ej] | nop | x := alloc(E) | dispose(E)
which defines the transition system JC) d=ef Jm). The semantics of non-leaf commands is then defined using the algebraic operations on transition systems introduced in §5:
JC  Cj) d=ef JC)  JCj),	JC; Cj) d=ef JC); JCj),
Jresource r do C) d=ef hide[r] JC) ,
Jwith r when B do C) d=ef whentrue[B] inside[r] JC)  ∪ whenabort[B, Cj]
where Cj = with r when B do C in the last part of the definition, and finally
Jif B then C1 else C2)  d=ef  whentrue[B] Jnop) ; JC1) ∪ whenfalse[B] Jnop) ; JC2)
∪ whenabort[B, if B then C1 else C2],
and the while loop

Jwhile B do C) d=ef


n ≥0
Fn(∅)

is defined as the least fixpoint of the continuous function F : Trans → Trans below:
F (T)	=	whentrue[B] Jnop) ; JC); T ∪  whenfalse[B] Jnop)	∪
whenabort[B, while B do C].

Logical States
As we explained in the introduction, reasoning about concurrent programs in sep- aration logic requires introducing an appropriate notion of logical state, including

σ ▶ Ownp(x) ⇐⇒ ∃v ∈ Val, σ(x)= (v, p)
σ ▶ E1 = E2 ⇐⇒ JE1) = JE2) ∧ fv(E1 = E2) ⊆ vdom(h)
σ ▶ P ⇒ Q ⇐⇒ (σ ▶ P ) ⇒ (σ ▶ Q) σ ▶ P ∧ Q ⇐⇒ σ ▶ P et σ ▶ Q
σ ▶ P ∗ Q ⇐⇒ ∃σ1σ2, σ = σ1 ∗ σ2 et σ1 ▶ P et σ2 ▶ Q
Figure 1. Semantics of the predicates of concurrent separation logic

information about permissions. The version of concurrent separation logic we consider is almost the same as in its original formulation by O’Hearn and Brookes [10,5]. One difference is that we benefit from the work in [3,4,11] and use the permissions and the Ownp(x) predicate in order to handle the heap as well as variables in the stack. So, we suppose given an arbitrary partial cancellative commutative monoid Perm that we call the permission monoid, following [3]. We require that the permission monoid contains a distinguished element T which does not admit any multiple, ie.
∀x ∈ Perm, T· x is not defined. The idea is that the permission T is required for a program to write somewhere in memory. The property above ensures that a piece of state cannot be written and accessed (with a read or a write) at the same time by two concurrent programs, and therefore, that there is memory safety and no data race in the semantics. The set LState of logical states is defined in a similar way as the set State of memory states, with the addition of permissions:
LState = (Var ~fin Val × Perm) × (Loc ~fin Val × Perm)
One main benefit of permissions is that they enable us to define a separation tensor product σ ∗ σj between two logical states σ and σj. When it is defined, the logical state σ ∗ σj is defined as a partial function with domain
dom(σ ∗ σ)= dom(σ) ∪ dom(σj)
in the following way, for a ∈ Var M Loc:
⎧⎪⎨σ(a)	if a ∈ dom(σ) \ dom(σj)
(v, p · pj)  if σ(a)= (v, p) and σj(a)= (v, pj)
The tensor product σ∗σj of the two logical states σ and σj is not defined otherwise. In other words, if the tensor product is well defined, then the memory states underlying σ and σj agree on the values of the shared variables and heap locations. The syntax and the semantics of the formulas of Concurrent Separation Logic is the same as in Separation Logic. The grammar of formulas is the following one:
P, Q, R, J ::= emp | true | false | P ∨ Q | P ∧ Q | ¬P | ∀X.P | ∃X.P
| P ∗ Q | Ownp(x) | E1 '→p E2
The semantics of the formulas is expressed as the satisfaction predicate σ ▶ P defined in Figure 1. The proof system underlying concurrent separation logic is a sequent calculus on sequents defined as Hoare triples of the form
Γ ▶ {P } C {Q},

where C ∈ Code, P , Q are predicates, and Γ is a context, defined as a partial function with finite domain from the set LockName of resource variables to predicates. Intuitively, the context Γ= r1 : J1,..., rk : Jk describes the invariant Ji satisfied by the resource variable ri. The purpose of these resources is to provide the fragments of memory shared between the various threads during the execution. The inference rules are given in Figure 2. The inference rule Res associated to resource r do C moves a piece of memory which is owned by the Code into the shared context Γ, which means it can be be accessed concurrently inside C. However, the access to said piece of memory is mediated by the with construct, which grants temporary access under the condition that one must give it back (rule With). Notice that in the rule Conj, the context Γ= r1 : J1,..., rk : Jk is required to be precise, in the sense that each of the predicates Ji is precise.
Definition 7.1 (Precise predicate) A predicate P is precise when, for any σ ∈
LState, there exists at most one σj ∈ LState such that ∃σjj, σ = σj ∗σjj and σj ▶ P.



Γ ▶ {OwnT(x) ∗ X = E} x := E {OwnT(x) ∗ x = X}
Aff

Γ ▶ {E '→ —} [E] := E′ {E '→ E′}
Store

x ∈/ fv(E)
Γ ▶ {E '→p v ∗ OwnT(x)} x := [E] {E '→p v ∗ OwnT(x) ∗ x = v}
Γ ▶ {P} C {Q} Γ ▶ {Q} C′ {R}

Load

Γ ▶ {P} C; C′ {R}
Seq

 P ⇒ def(B) Γ ▶ {P ∧ B} C1 {Q}  Γ ▶ {P ∧ ¬B} C2 {Q} If
Γ ▶ {P} if B then C1 else C2 {Q}

 Γ is precise  Γ ▶ {P1} C {Q1}  Γ ▶ {P2} C {Q2}
Γ ▶ {P1 ∧ P2} C {Q1 ∧ Q2}

Conj
Γ,r : J ▶ {P} C {Q}
Γ ▶ {P ∗ J} resource r do C {Q ∗ J}

Res

P ⇒ def(B)  Γ ▶ {(P ∗ J) ∧ B} C {Q ∗ J}
Γ,r : J ▶ {P} with r when B do C {Q}

With
Γ ▶ {P1} C1 {Q1}  Γ ▶ {P2} C2 {Q2} Par

Γ ▶ {P} C {Q}
Γ ▶ {P ∗ R} C {Q ∗ R}

Frame


Figure 2. Inference rules of Concurrent Separation Logic




Separated states
We now introduce our third notion of state, which display which region of (logical) memory belongs to the Code, which region belongs to the Frame, and which region is shared. We suppose given a finite set LockName of resource variables.
Definition 8.1 The separated states are the triples
(σC, σ, σF ) ∈ LState × (LockName → LState + {C, F}) × LState

such that the state below is defined:
σC ∗	②
r∈dom(σ)

σ(r) , ∗ σF

where	dom(σ)= {r ∈ LockName | σ(r) ∈ LState},
domC(σ)= {r ∈ LockName | σ(r)= C},
domF(σ)= {r ∈ LockName | σ(r)= F}.
We say that a separated state (σC, σ, σF ) combines into a machine state s = (μ, L) precisely when both L = domC(σ) domF(σ) and the memory state μ ∈ State is equal to the image of

σC ∗	②
r∈dom(σ)
σ(r) , ∗ σF	∈	LState	(3)

under the function U : LState → State which forgets the permissions. Note that by definition, every separated state (σC, σ, σF ) combines into a unique machine state, which we write for concision (μ, L)= ②(σC, σ, σF ).

The graphs of machine and separated states
In this section, we introduce the two labeled graphs G(MState) and G(SState) of machine states and of separated states, and construct a graph homomorphism
② : G(SState) −→ G(MState)	(4) which maps every separated state (σC, σ, σF ) to its combined machine state (σ, L), in the way described in the introduction.
Definition 9.1 The graph of machine states G(MState) is the graph whose vertices are the machine states s ∈ MState and whose edges are either Code or Environment transitions of the following kind:

a Code transition s −m→ sj for every machine step s	m
sj ,

an Environment transition s −e−n→v
sj for every pair s, sj ∈ MState of machine

states, and where env is just a tag indicating that the transition has been fired by the Environment.
Note that a trace t ∈ Traces (see Def. 4.1) is the same thing as an alternating path starting and ending with an Environment edge in the graph G(MState).
Definition 9.2 The graph of separated states G(SState) is the graph whose vertices are the separated states and whose edges are either Eve moves or Adam moves of the following kind:
Eve moves of the form
(σC, σ, σF ) −−m→ (σj , σj, σF )
labeled by an instruction m ∈ Instr such that
②(σC, σ, σF )	m	②(σj , σj, σF )

between machine states, and such that the following conditions on locked resources are moreover satisfied:
∀r ∈/ lock(m), σ(r)= σj(r),
∀r ∈ lock+(m), r ∈ dom(σ) ∧ r ∈ domC(σj),
∀r ∈ lock—(m), r ∈ domC(σ) ∧ r ∈ dom(σj);
Adam moves of the form
(σC, σ, σF ) −−en−v→ (σC, σj, σj )
where env is just a tag, and moreover
domC(σj)= domC(σ).
The definition of the vertices and of the edges of the graph of separated states G(SState) is designed to ensure that there exists a graph homomorphism (4) which maps every Eve move to a Code transition, and every Adam move to an Environment transition. The graph homomorphism (4) enables us to study how an execution trace t ∈ Traces defined as a path in G(MState) may be “refined” into a separated execution trace p living in the graph of G(SState) of separated states, and such that t = ② p. In that situation, we use the following terminology:
Definition 9.3 We say that a path p in the labeled graph G(SState) combines
into a trace t ∈ Traces in the labeled graph G(MState) when t = ② p.
Note that a path p which combines into a trace t ∈ Traces is alternated between Eve and Adam moves, and that it starts and stops with an Adam move.
Separation games
In this section, we explain how to associate to every trace t ∈ Traces a separation game SGame(t) on which Eve and Adam interact and try to “justify” every transition played in the execution trace t by the Code or by the Environment, by lifting it to a separated execution trace p which combines into t.
Definition 10.1 (Game) A game A is a triple A = (BoardA, PolA, PlaysA) consist- ing of a graph BoardA = (V, E, ∂0, ∂1) with source and target functions ∂0, ∂1 : E → V , and whose edges are called moves: of a function PolA : E → {−1, +1} which assigns a polarity +1 to every move played by Eve (Player) and −1 to every move played by Adam (Opponent); of a prefix-closed set PlaysA of finite paths, called the plays of the game A. One requires moreover that every play of the game

x1 −e→1
x2 −e→2
· · · −→ xn −e→n
xn+1

is alternating in the sense that PolA(ei)= (−1)i for 1 ≤ i ≤ n, and that it starts and stops with an Adam move.
A vertex in a game A is called initial when there exists a play s ∈ PlaysA with x = ∂0(s) as source. The set of initial vertices of a game A is noted InitA. We take below the most general and liberal definition of a strategy. In particular, a strategy in that sense does not need to be deterministic.

Definition 10.2 (Strategy) A strategy of a game is a prefix-closed set of plays.
Every execution trace t ∈ Traces induces a game defined below, called the separation game associated to t and noted SGame(t).
Definition 10.3 (Separation Game) The game SGame(t)= (Board, Pol, Plays)
is defined as the graph Board = G(SState) with plays in Plays defined as the paths
p	:	(σC, σ, σF ) −∗→ (σj , σj, σj )
C	F
in G(SState) which combine into a path in G(MState)
②p	:	②(σC, σ, σF ) −∗→ ②(σj , σj, σj )
prefix of the trace t ∈ Traces. The polarity Pol of the moves is derived from the polarity Eve (+1) and Adam (−1) of the edges of the graph Board = G(SState) of separated states.
A play of the separation game SGame(t) may be thus seen as a “psychoanalysis” or rather a “couple therapy” where Eve and Adam try and justify a posteriori what has just happened in the execution trace t ∈ Traces played by the Code (on the side of Eve) and the Environment (on the side of Adam). At each transition m : (σ, L) → (σj, Lj) performed by the Code in the execution trace t ∈ Traces starting from a machine state (σ, L) = ②(σC, σ, σF ), Eve has to play a move
m : (σC, σ, σF ) → (σj , σj, σj ) which “justifies” the transition by decomposing the
C	F
machine state (σj, Lj) into a separated state (σj , σj, σj ). And symmetrically for
C	F
Adam and the Environment.
Soundness theorem
At this stage, we establish our soundness theorem for concurrent separation logic, by interpreting every derivation tree as a winning strategy in a specific separation game. We suppose given a Hoare triple Γ ▶ {P } C {Q}. We start by describing the winning condition on the separation game SGame(t) associated to an execution trace t ∈ JC) in the operational semantics of C.
Definition 11.1 A separated predicate is a triple P = (P, Γ, Q) consisting of two predicates P and Q and of a context Γ= r1 : J1,..., rk : Jk of variable resources.
Definition 11.2 We write
(σC, σ, σF ) ▶ (P, Γ, Q)
and say that the separated state (σC, σ, σF ) satisfies the separated predicate P = (P, Γ, Q) precisely when σC ▶ P and σF ▶ Q and ∀r ∈ dom(σ), σ(r) ▶ Δ(r).
We suppose from now on that the execution trace t ∈ JC) is of length p, and introduce the sequence P1,..., P2p+2 of separated predicates, defined as:
P1 = (P, Γ, true)	Pi = (true, Γ, true)	P2p+2 = (Q, Γ, true)
for 1 < i < 2p +1 when the execution trace t ∈ JC)  is returning; and defined as
P1 = (P, Γ, true)	Pi = (true, Γ, true)	P2p+2 = (true, Γ, true)

for 1 < i < 2p +2 when the execution trace t /∈ JC) is not returning. Here, we write true for the constant predicate which is true for every logical state.
Definition 11.3 (Winning condition) A play
(σ1 , σ1, σ1 ) −−en−→v  (σ2 , σ2, σ2 ) −m−→1  (σ3 , σ3, σ3 ) −→ · · · −→ (σ2q+2, σ2q+2, σ2q+2)
C	F	C	F	C	F	C	F
in the separation game SGame(t) is declared winning when
∀i ∈ {1,..., 2q + 2},	(σi , σi, σi ) ▶ Pi.
C	F
Note that the notion of winning play is closed under prefix.
Definition 11.4 A strategy strat of the separation game SGame(t) is winning when it contains only winning plays, and moreover:
the strategy strat contains every empty and winning play of the separation game,
	for every play p in the strategy strat, which can be extended by a move a played by Adam into a winning play p · a of the separation game SGame(t), there exists a move e played by Eve such that p · a · e defines a play in the strategy strat.
Note that an empty and winning play of the separation game consists of a separated state (σC, σ, σF ) satisfying the predicate (P, Γ, true), and in the very special case when the trace t ∈ JC) is empty and returns, the predicate (Q, Γ, true).
We are now able to state the soundness theorem of concurrent separation logic, which is established by structural induction on the derivation tree π of the Hoare triple Γ ▶ {P } C {Q}.
Theorem 11.5 (Soundness) Every derivation tree π of Γ ▶ {P } C {Q} defines for every execution trace t ∈ JC) a winning strategy strat(π, t) in the separation game SGame(t) determined by the Hoare triple Γ ▶ {P } C {Q} and t.
The proof of the theorem is in the Appendix[1]. This statement is inspired by game semantics, and the idea of a Curry-Howard correspondence between proofs (derivation trees) and winning strategies. This interpretation of proofs implies the soundness of concurrent separation logic in the traditional sense [5,13,2] by considering the case when the context Γ is empty, and the environment is passive, in the following sense.
Definition 11.6 The environment is passive in a trace

s  −e−n→v  s  −m−→1 s
−e−n→v
... −e−n→v  s	mp  s
−e−n→v  s

1	2	3
2p −−→
2p+1
2p+2

when every transition s2i+1 −e−n→v
s2i+2 by the environment does not alter the logical

state, and is thus the identity s2i+1 = s2i+2, for 0 ≤ i ≤ p.
Corollary 11.7 Suppose that the triple ∅▶ {P } C {Q} has been proved by a deriva- tion tree π of concurrent separation logic, and that t ∈ JC) is an execution trace

s  −i→d  s  −m−→1 s
−i→d
... −i→d  s	mp  s
−i→d  s

1	1	3
2p −−→
2p+1
2p+1

in which the Environment is passive, and such that s1 ▶ P ∗ true. Then, the execution trace t produces no error, in the technical sense that every machine step mi : s2i+1  s2i+3 executed by the Code, for 0 ≤ i ≤ p − 1 is of the form

m
s2i+1

s2i+3
and thus does not produce any error at run-time. Moreover,

when t ∈ C  returns, one has that:
∂1t ▶ Q ∗ true .
Note that the predicate P ∗ true means that the logical state σ taken as input by the Code C contains a fragment σC which satisfies the predicate P . The winning strategy associated to π ensures that when the trace t returns, the Code C ends with
a fragment σj of the logical state σj returned as output.

References
Appendix to a game semantics of concurrent separation logic.
URL http://stefanesco.com/documents/mfps17.pdf

	Balabonski, T., F. Pottier and J. Protzenko, Type soundness and race freedom for mezzo, in: FLOPS, 2014.
Bornat, R., C. Calcagno, P. O’Hearn and M. Parkinson, Permission accounting in separation logic, in:
POPL, 2005.
Bornat, R., C. Calcagno and H. Yang, Variables as resource in separation logic, ENTCS 155 (2006),
pp. 247–276.
Brookes, S., A semantics for concurrent separation logic, in: CONCUR, 2004.
Brookes, S., A revisionist history of concurrent separation logic, ENTCS 276 (2011), pp. 5 – 28.
	Dinsdale-Young, T., L. Birkedal, P. Gardner, M. J. Parkinson and H. Yang, Views: compositional reasoning for concurrent programs, in: POPL, 2013.
	Jung, R., D. Swasey, F. Sieczkowski, K. Svendsen, A. Turon, L. Birkedal and D. Dreyer, Iris: Monoids and invariants as an orthogonal basis for concurrent reasoning, in: POPL, 2015.
	Krebbers, R., R. Jung, A. Bizjak, J.-H. Jourdan, D. Dreyer and L. Birkedal, The essence of higher-order concurrent separation logic, in: ESOP, 2017.
OHearn, P. W., Resources, concurrency, and local reasoning, TCS 375 (2007), pp. 271–307.
	Parkinson, M. J., R. Bornat and C. Calcagno, Variables as resource in hoare logics, in: LICS, 2006, pp. 137–146.
Reynolds, J. C., Separation logic: A logic for shared mutable data structures, in: LICS, 2002.
Vafeiadis, V., Concurrent separation logic and operational semantics, ENTCS 276 (2011), pp. 335–351.
