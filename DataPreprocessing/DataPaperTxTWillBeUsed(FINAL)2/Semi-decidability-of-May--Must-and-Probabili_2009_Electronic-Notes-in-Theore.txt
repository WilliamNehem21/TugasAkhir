

Electronic Notes in Theoretical Computer Science 249 (2009) 219–242
www.elsevier.com/locate/entcs
Semi-decidability of
May, Must and Probabilistic Testing in a Higher-type Setting
Mart´ın Escard´o
School of Computer Science, University of Birmingham, UK

Abstract
We show that, in a fairly general setting including higher-types, may, must and probabilistic testing are semi- decidable. The case of must testing is perhaps surprising, as its mathematical definition involves universal quantification over the infinity of possible outcomes of a non-deterministic program. The other two involve existential quantification and integration. We also perform first steps towards the semi-decidability of similar tests under the simultaneous presence of non-deterministic and probabilistic choice.
Keywords: Non-deterministic and probabilistic computation, higher-type computability theory and exhaustible sets, may and must testing, operational and denotational semantics, powerdomains.

Introduction
We consider a non-deterministic higher-type language, in the style of PCF [38,32,17], which includes angelic, demonic and probabilistic choice. The types are closed under finite products and function spaces, and certain powertype constructors, interpreted as powerdomain monads, which capture various kinds of non-determinism. Choices can only be performed at powertypes, and the different powertypes have different operational interpretations of choice.
We show that (i) may, (ii) must and (iii) probabilistic testing are semi-decidable for this language. The idea is that, given a semi-decidable property u, one can semi-decide whether a given non-deterministic program (i) has some outcome sat- isfying u, (ii) has all outcomes satisfying u, and (iii) has all outcomes satisfying u with probability bigger than a given number. The proofs exploit recent results on exhaustible sets in higher-type computation [13,8], and older results on exact computability and definability of integrals in PCF-like languages [6,41,39].
Even at ground types, the claim for must testing may seem suspicious: for example, it implies that for any non-deterministic program of natural number type,

1571-0661 © 2009 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2009.07.092

possibly including subterms of arbitrarily high types, it is semi-decidable whether the outcome of the program must be a prime number. The semi-decision procedure is expected to answer yes if all possible outcomes are prime numbers, and to diverge if the outcomes include composite numbers or divergent computations. Of course, it is also semi-decidable whether all outcomes are not prime, as primality is decidable and hence non-primality is semi-decidable. However, it doesn’t follow that it would be decidable whether all outcomes are prime, and in fact this is not the case because some outcomes can be divergent computations.
From the point of view of computability theory, we have an extensional procedure that operates on programs, but that is not definable directly on the observable input-output behaviour of programs, and hence the Rice-Shapiro theorem [34] fails for non-deterministic programming systems. This leads us to extend the language with may, must and probabilistic testing primitives. It is interesting that these tests define basic open sets of the Scott topology of powerdomains that are not definable in the original language. The resulting language has an operational semantics and is regarded as an executable program logic for semi-decidable properties, which plays the role of a sort of “Rice-Shapiro completion” of the programming language (although we don’t have at present a precise formulation of such a concept).
Our semi-decision procedures are defined using operational semantics, and their correctness is proved using domain-theoretic denotational semantics. Perhaps sur- prisingly, may testing is harder than must testing in a sense: inclusion of the former to the language leads to definability of parallel-convergence (even on programs of deterministic type), but the latter can be defined without parallel features. Proba- bilistic testing also requires parallel features.
Our results on may, must and probabilistic testing are very general, but have restrictions, discussed in the body of the paper, due to open problems in domain theory involving the probabilistic powerdomain [27].
We also perform first steps towards the semi-decidability of similar tests under the simultaneous presence of probabilistic choice and non-deterministic choice [29,46,47]. We develop semi-decision procedures for this, but their correctness is a conjecture and their scope is open (Section 7.4).
This work is related to Abramsky’s work on logic of observable properties [1], going back to Smyth [44], but we take a different approach and also account for probabilistic computation. The relationship between the two approaches certainly deserves more scrutiny.

Organization. 2. A programming language for non-determinism and probability.
3. Logical types. 4. An executable program logic. 5. Operational semantics of the executable logic. 6. Denotational semantics of the executable logic. 7. Discussion and questions.

Acknowledgements. A preliminary version of this work, with more conjectures than results, was presented in 2005 at a workshop in McGill University Bellairs research institute, organized by Prakash Panangaden. I thank him and the other participants

for discussions, in particular Vincent Danos, Achim Jung, Klaus Keimel, Jimmie Lawson, Gordon Plotkin, Steve Vickers. I also had useful discussions with Alex Simpson, Dan Ghica and Paul Levy, and detailed comments by one of the referees, which are addressed in this revised version.

A programming language for non-determinism and probability
We consider a language with a type system that makes an explicit distinction be- tween deterministic and various kinds of non-deterministic types. Any term of deterministic type has only one outcome, including the possibility of divergence. A term of non-deterministic type has one or more runs, in general continuum many, each of which either produces a single outcome, again including the possibility of divergence, but different convergent runs may produce different outcomes. We take the ground types to be deterministic, and the product- and function-type construc- tions to preserve determinism.

An extension of PCF
We consider an extension of the programming language PCF [32] so that PCF remains deterministic when it is embedded into the extension. Non-deterministic and probabilistic terms have to be explicitly typed as such. Types that admit non- deterministic and probabilistic terms are obtained via “powertype” constructors.

Types. The ground types, ranged over by γ, are those of PCF:

γ := Bool | Nat.

General types are ranged over by σ and τ and are given by

σ, τ ::= γ | σ × τ | σ → τ | F σ,

where F ranges over type constructors defined by

F ::= H | S | P | V .

The three constructors H, S, P (Hoare, Smyth and Plotkin powertypes) are for non- deterministic computation. They respectively allow may, must and both testings. The constructor V (probabilistic powertype) is for probabilistic computation.
Example 2.1 The type σ × τ → V τ can be used to code labeled Markov processes with label space A = σ, state space S = τ and transition function t : A × S → V S.

Terms. We extend the inductive definition of PCF terms with the following rules.

Choice rules. The Hoare, Smyth and Plotkin powertypes have a binary choice operator ❽. The idea is that the runs of a term M ❽ N are those of the term M together with those of the term N . The probabilistic powertype has a binary choice operator ⊕. Again the runs of a term M ⊕N are those of the term M together with those of the term N . However, the choice M ❽ N is angelic or demonic, whereas the choice M ⊕ N is probabilistic, with equal probability for both branches.
Non-deterministic choice rule. For each type σ and F ∈ {H, S, P}, we have a constant (❽σ): Fσ × Fσ → F σ,
written in infix notation.
Probabilistic choice rule. For each type σ, we have an infix constant
(⊕σ): V σ × V σ → V σ.

Monad rules. Let F ∈ {H, S, P, V} be a unary type constructor.
Functor rule. If f : σ → τ is a term, then so is
Ff : Fσ → Fτ.

This amounts to the fact that any deterministic function can be considered as a non-deterministic function. To compute Ff : Fσ → Fτ at a given input x : Fσ, we first compute an outcome of x and then feed it to f , which in turn gives one of the possible outcomes of Ffx.
Unit rule. For each type σ, we have a term
ησ : σ → F σ,
where in practice we often omit one or both super- and subscripts from η (and from other terms that have similar decorations). This amounts to the fact that any deter- ministic computation can be regarded as a possibly non-deterministic computation which just happens to be able to produce precisely one outcome.
Multiplication rule. For each type σ, we have a constant
μσ : FFσ → F σ.

This amounts to the fact that a non-deterministic computation, each of whose possible outcomes is another non-deterministic computation of an element of σ, can be seen simply as a non-deterministic computation of an element of σ. To compute an outcome of the term μX, we first compute an outcome x : Fσ of X : FFσ, and then compute an outcome of x in σ.
Strength rule. For all types σ, we have a (for the moment nameless) constant of type σ × Fτ → F (σ × τ ). This is needed to get terms Fσ1 ×· · ·× Fσn → Fτ from

terms σ1 ×···×σn → τ and functoriality. An important example is the construction of various non-deterministic and probabilistic conditionals from the deterministic one.
Example 2.2 In this language, the terms η(λx.0) ❽ η(λx.1) and λx.η(0) ❽ η(1) are distinguishable from their types F (σ → Nat) and σ → F Nat respectively, for any type constructor F ∈ {H, S, P}. The first defines, non-deterministically, a function, whereas the second defines a single function with non-deterministic output. In languages that omit the type distinction we are making, and hence omit the coercion η, the terms (λx.0) ❽(λx.1) and λx.(0 ❽ 1) are indistinguishable under call by name, as discussed e.g. by Sieber [40]. Here the two terms are distinguishable in terms of their behaviour too. In the first case, once we see a zero in the output for some given input, we’ll always see zeros afterwards, no matter what the input is, whereas in the second we’ll be able to get zeros and ones even for the same input.
Example 2.3 The idea behind the above example can be illustrated in imperative style as follows. The term η(λx.0) ❽ η(λx.1) corresponds to the non-deterministic algorithm
(repeat for ever (print 0))
or
(repeat for ever (print 1))
If a run of this algorithm prints 0 first, then it must print 0 the second time as well.
The term λx.η(0) ❽ η(1) corresponds to the algorithm
repeat for ever ((print 0) or (print 1))
If this prints 0 first, it may print 1 the second time, and hence the two algorithms can be distinguished by may and must testing.
Example 2.4 Think of the elements of the type Cantor = (Nat → Bool) as se- quences of booleans. Then cons: Bool → Cantor → Cantor defined by

cons ps = λi. if i == 0 then p else s(i − 1),

adds p as a first new element of the sequence s, shifting the original elements to the right. Define, using functoriality, a term prefix: Bool → V Cantor → V Cantor by

prefix p = V(cons p).

Then the following term random: V Cantor is intended to randomly choose a total element of Cantor with uniform distribution:

random = (prefix False random) ⊕ (prefix True random).
Example 2.5 For any type σ, recursively define a term

(s, v, w) '→ (v ⊕s w): Cantor × V σ × V σ → V σ

by
(v ⊕s w) = if s(0) then v ⊕ (v ⊕tl s w) else (v ⊕tl s w) ⊕ w
where tl s = λi.s(i + 1) is the tail map. If s : Cantor is a term encoding the binary expansion of a real number p ∈ [0, 1], where False encodes zero and True encodes 1, then it is intended that v ⊕s w chooses v with probability p, and w with probability 1 − p.
More generally, using the same idea, it is possible to define an n-ary term weighted-choice that chooses among n branches with given probabilities p1,..., pn that add up to 1.

Operational semantics
We extend the big-step operational semantics of PCF with the following rules. Firstly, we stipulate that if v : σ is a value (or weak head normal form) then so is η(v): Fσ. Then, omitting types and contexts, we add the rules:


M ⇓ v M ❽ N ⇓ v
N ⇓ v M ❽ N ⇓ v
M ⇓ v M ⊕ N ⇓ v
N ⇓ v M ⊕ N ⇓ v

M ⇓ η(v)	f (v) ⇓ w


Ff (M ) ⇓ η(w)
M ⇓ v η(M ) ⇓ η(v)
M ⇓ η(V )	V ⇓ η(W )


μ(M ) ⇓ η(W )

Thus, all choice operators have the same meaning under this semantics: this seman- tics only says what the possible outcomes of a term are, if any, and hence doesn’t fully capture the intended meaning (cf. [21]). The following is easy to establish (see e.g. [40]):
Proposition 2.6 There is a computable partial function
M ⇓s v,

with inputs M and s, and output v, where s ranges over the Cantor space of inﬁnite binary sequences, such that
M ⇓ v iff there is some s with M ⇓s v.
The idea is that s is a scheduler that dictates which branches the choice operators have to take during evaluation. Once the scheduler is chosen, the evaluation is completely deterministic. For a term term M , we can say that
M must converge iff for every s there is v with M ⇓s v. M may converge iff there are s and v with M ⇓s v.
Despite the universal quantification over an uncountable set, we can prove that must convergence is semi-decidable for closed terms. The reason is that the Cantor space is compact and computable functions are continuous [13,8]. However, we don’t know how to define probabilistic testing and a more general must testing in the big-step style in an elegant and algorithmic way. Hence we instead translate our language

into a deterministic language, using Proposition 2.6 above as the guiding idea, in Section 5. Moreover, rather than performing the tests externally to the language, we incorporate the tests into the language, obtaining an executable logic.

Logical types
The may, must and probabilistic testing operators of the executable program logic defined in Section 4 below will have values in the types S (Sierpinski space) and I (vertical unit interval), and in this section we extend PCF with such base types as a preparation for that section. The Sierpinski type S is for results of observations or semi-decisions, with an element T (observable true) and divergence (unobservable false), and hence is interpreted as the Sierpinski domain {⊥, T}. The type I is for observations of probabilities, and is interpreted as the set [0, 1] ⊆ R under the natural order (hence zero is bottom and one is top).

The Sierpinski type
We have the following term formation rules for the Sierpinski type S:
T : S is a term.
If M : S and N : σ are terms then (if M then N ): σ is a term.
If M, N : S are terms then so is M V N : S.
The only value (or canonical form) of type S is T. Notice that there is no “else” clause in the above construction, and (V) is intended to be parallel convergence (or weak parallel or). For future use, we define
p Λ q = if p then q.

The big-step operational semantics for these constructs is given by the following evaluation rules:

M ↓T	N ↓ V
if M then N ↓ V
M ↓T 


M V N ↓T 
N ↓T 
.
M V N

↓T 
Recall that computational adequacy of the Scott model of PCF amounts to the statement that:
If M is a closed term of ground type and v is a value then M ) = v iff M ↓ v.
Standard proofs of adequacy, e.g. Streicher [45], easily apply to this extension of PCF with the type S.

The vertical unit-interval type
Because we are concerned with semi-decision procedures, our computations of terms M of type I are set-up so that, for any rational number p ∈ [0, 1], it is possible to semi-decide the condition p < M , uniformly in M and p, but not the

conditions M = p or M < p in general. Hence the intended interpretation of the type I is the set [0, 1] ⊆ R under its usual order. This is naturally regarded as a sub-dcpo of the unit-interval domain [11], by thinking of x ∈ I as the interval [x, 1]. Thus, if M denotes x, then all we know about M from an operational (and constructive) point of view is the set of rational numbers p with p < x (and so x is a lower real number from a constructive point of view).
We take the primitive operations for I as those of the interval type of Real PCF [11] (or the alternative version [7]), restricted to intervals of the form discussed above, with the same operational rules.
These primitive operations include simple unary arithmetic functions, a partial inequality test p < (—) with p rational, and a parallel conditional. Because the value False doesn’t arise in our semi-decisions, we replace the boolean type of terms of the form p < M by the Sierpinski type S. Similarly, we use the Sierpinski type
for the parallel conditional, obtaining a weak parallel conditional wif : S × I × I → I
so that
wif T then x else y = x
wif ⊥ then x else y = x H y = min(x, y).
We omit the discussion of computational adequacy for closed terms M of type I, referring the interested reader to the references [11,7]. For our purposes, it is enough to know that this can be reduced to the computational adequacy of terms of type S, by considering the term (p < M ): S, as follows:
 M ) = x iff for every rational number p, we have that p < x ⇐⇒ (p < M ) ↓ T.

Basic deﬁnability results. Using the programming techniques developed in the ref- erences [11,15], in fact with essentially the same programs, it is easy to see that the average (or midpoint or mediation) operation, defined by
x ⊕ y = (x + y)/2,
and the multiplication and binary minimum and maximum operations are definable in this language.
Quantiﬁcation and integration over the Cantor space. For the operational semantics defined in Section 5 below, we need quantification and integration over the Cantor type
Cantor = (Nat → Bool).
As in Example 2.4, we think of this as a type of sequences of booleans, where we are mostly concerned with total sequences, which will play the role of schedulers.
For the operational semantics of may and must testing we need two terms
E, 6 : (Cantor → S) → S.
For definability of the existential quantifier one needs parallel-convergence, but the universal quantifier is sequentially definable [13]:

E(p)= p(⊥) V (E(λs.p(cons False s)) V E(λs.p(cons True s))) ,
6(p)= p(if 6(λs.p(cons False s)) Λ 6(λs.p(cons True s)) then c),
where c is an arbitrary total term of type (Nat → Bool), e.g. λi. True, and where cons is defined in Example 2.4.
For probabilistic testing, we need a term
∫ : (Cantor → I) → I,

where we take the uniform distribution on the total elements of Cantor. This can be defined as
∫ f = max f (⊥), ∫ λs.f (cons False s) ⊕ ∫ λs.f (cons True s) .

The idea is the same as that applied for integration in Real PCF for the unit interval domain [6].
In Section 7.4, we also need supremum and infimum operators

inf, sup: (Cantor → I) → I,

which can be defined along the same lines [6].
For the sake of clarity, we use the following notation for writing terms, where the letter s ranges over the Cantor type:
Es.p[s] = E(λs.p[s]),	6s.p[s] = 6(λs.p[s]),	∫ f [s] ds = ∫ (λs.f [s]), and likewise for sup and inf.
An executable program logic
None of the powertypes can be distinguished on the basis of the possible outcomes that their terms have (cf. [21]). The powertypes become observably different when one considers may, must and probabilistic testing, which describe whether choice is interpreted as angelic, demonic or probabilistic. Rather than having these tests external to the language, we extend the language with them, obtaining an executable program logic, which we refer to as MMP. Interestingly, and perhaps counter- intuitively, we shall have terms defined on non-deterministic or probabilistic types with values on deterministic types, which hence will produce deterministic outputs from non-deterministic or probabilistic inputs. These arise from the introduction of may, must and probabilistic testing constructs to the language.
The Hoare powertype admits only may testing, the Smyth powertype admits only must testing, and the Plotkin powertype admits both. And, of course, the probabilistic powertype admits probabilistic testing.

May and must testing
The S-valued terms are characteristic functions of open sets and hence we define a type of opens
0 σ = (σ → S).
May and must testing can be seen as ways of obtaining open sets of Fσ from open sets of σ, for certain non-deterministic type constructors, and hence we postulate corresponding constants 0 (may) and  (must):
0σ : 0 σ →0 H σ,
  σ : 0 σ →0 S σ,
0σ : 0 σ →0 P σ,
  σ : 0 σ →0 P σ.
The idea in the case of the Plotkin powertype is that if u : 0 σ and N : P σ, then
0(u)(N ) = T if and only u(x) = T for some outcome x of a run of N , and
 (u)(N ) = T if and only u(x) = T for all outcomes x of runs of N . This is made precise later, when we consider the (operational and denotational) semantics of the language. The idea for the Hoare and Smyth powertypes is the same, but only one kind of test is made available for each of them, as discussed above.
Example 4.1 Suppose one wants to semi-decide whether the outcome of a term n : F Nat must be prime. Then one first writes a semi-decision term prime: Nat → S and then runs, in the executable logic, the ground term prime n of type S. Of course, considering a term Nat → S for semi-deciding non-primeness, one can semi- decide whether n must be non-prime. However, it doesn’t follow that primeness of all outcomes of n is decidable: if n has at least one non-divergent run, then both must tests diverge. (Cf. the discussion in Section 7.3, which considers the possibility of replacing the Sierpinski space by the type of booleans.)
Example 4.2 Recursively define a term f : Nat → P Nat by

f (n) = η(n) ❽ f (n + 1),

and let converge: Nat → S be a term such that converge(n) = T iff n /= ⊥. Then we intend that
0 converge(f (0)) = T	(“f (0) may converge”)
and that
 converge(f (0)) = ⊥	(“it is not the case that f (0) must converge”), but
  converge(η(0) ❽ η(1)) = T.
Example 4.3 Parallel-convergence is definable from may testing. In fact, taking
converge: S → S as the identity function, the function (V): S × S → S is character-

ized by the equation

(p V q) = 0 converge(η(p) ❽ η(q)).

However, it cannot be defined from must testing, because must testing can be defined without parallel features (as we do). Notice that (p Λq) =  converge(η(p) ❽ η(q)).
Probabilistic testing
This time, from an open set of σ we get an expectation on V σ, where an expectation on σ is an I-valued function:
s σ = (σ → I).
By virtue of the vertical nature of the unit-interval type I, any Sierpinski-valued term amounts to an I-valued term with values 0 (bottom) and 1 (top) by compo- sition with a coercion function S → I that maps ⊥ to 0 and T to 1 (definable as λp. if p then 1). Hence expectations generalize open sets. For probabilistic testing, we include a constant
◯σ : s σ →s V σ.
For a term u : 0 σ seen as a term of type s σ, as discussed above, and a term x : V σ, the idea is that ◯(u)(x): I is the probability that u holds for outcomes of runs of a term x : V σ.
Example 4.4 Cf. Example 4.2. Recursively define a term g : Nat → V Nat by

g(n) = η(n) ⊕ g(n + 1),

Then we intend that
◯ converge(g(0)) = 1	(“the probability that g(0) converges is 1”), and
◯ convergen(g(0)) = 2−n−1	(“the probability that g(0) converges to n is 2−n−1”),
where convergen : Nat → S is a term such that convergen(x) = T iff x = n.
Example 4.5 Parallel-convergence is definable from probabilistic testing (cf. Ex- ample 4.3 and the references [10,6,30]):
(p V q) = 0 < ◯ converge(η(p) ⊕ η(q)).
Example 4.6 Cf. Example 2.4. Define a term prefix: I → VI → VI by

prefix x = V(λy.x ⊕ y),

where here (⊕): I × I → I is the average operation. Then the term random: VI defined below is intended to randomly choose a real number with uniform distribu- tion:
random = (prefix 0 random) ⊕ (prefix 1 random).

Hence for example ◯(λx.p < x) random = 1 — p for any p ∈ I. That is, the probability that a uniformly chosen random number x satisfies p < x is 1 — p. This is generalized to invariant measures of iterated function systems in Example 5.1 below.
Operational semantics of the executable logic
We define the operational semantics of the executable logic MMP by compositional compilation into its deterministic sub-language PCF+S+I introduced in Section 3, where the translation is the identity on this sub-language. The compilation map
φ : MMP → PCF + S + I

acts on both terms and types (like a functor): for every source term M of type σ, the translation produces a target term φ(M ) of type φ(σ).
The idea is to reduce may, must and probabilistic testing in MMP to quantifi- cation and integration in PCF + S + I. In principle, as discussed in Section 5.1, the quantifications and integrations are over sets of possible outcomes. For the trans- lation, we further reduce them to quantifications and uniform integrations over the Cantor space in Section 5.3, and Section 5.1 is intended as a motivation for this, which anticipates the denotational semantics given in Section 6 below.
Quantiﬁcation and integration over sets of possible outcomes
Consider the may testing operator
0 : 0 σ →0 H σ
and recall that 0 σ = (σ → S). By uncurrying this operator, then twisting the product, and currying again, we get a term that will be natural to denote by
E : H σ → ((σ → S) → S).

That is,
E(C)(u) = 0(u)(C).
For C : H σ, we write EC rather than E(C).  Moreover, for a term u[x]: σ → S
possibly including a free syntactic variable x, we write
Ex ∈ C.u[x] = E(C)(λx.u[x]).

With this notation, we have
0(u)(C) = Ex ∈ C.u(x).
Similarly, from the must testing operator  : 0 σ →0 S σ, we get a term
6 : S σ → ((σ → S) → S),

for which analogous notational conventions are adopted. For the Plotkin powertype, we get both quantifiers.
For the probabilistic powertype, recalling that s σ = (σ → I), from the proba- bilistic testing operator


we get a term


defined by
◯ : s σ →s V σ
∫ : V σ → ((σ → I) → I)



where ν : V σ and u : σ → I.
u = ◯(u)(ν).
ν

Example 5.1 Generalizing Example 4.6, if (σ, f1,..., fn, p1,..., pn) is an iterated function system with probabilities [25,24], then its invariant measure ν : V σ can be defined as
ν = weighted-choice(p1,..., pn)(V(f1)(ν),..., V(fn)(ν)),
where weighted-choice is the term discussed in Example 2.5. Scriven developed a PCF program for computing integrals of functions u : σ → I with respect to the invariant measure [39]. Here we get the alternative algorithm ν u = ◯(u)(ν) in the program logic MMP instead. Notice that the underlying space can be a function space (as in Example 2.4).

Translation of types
This is defined by induction:
φ(γ)= γ,
φ(σ × τ )= φ(σ) × φ(τ ),
φ(σ → τ )= φ(σ) → φ(τ ),
φ(Fσ)= Cantor → φ(σ),	for F ∈ {H, S, P, V}.
Recall from Section 3 that Cantor is the type (Nat → Bool). As in Proposition 2.6, the idea here is that the Cantor type plays the role of a type of schedulers. To run a non-deterministic program, one non-deterministically comes up with a scheduler, and then deterministically runs the program with respect to that scheduler, where the scheduler is used in order to decide which branches of the choice constructs are taken (think e.g. of false as left and of true as right). To run a probabilistic program, one first comes up with a scheduler, where the choice of scheduler is performed with uniform distribution over the Cantor space.

Translation of terms
This is also defined by induction. The translation of a syntactic variable is a variable with the same name but its type modified appropriately for powertypes. In order to

be precise here, one needs some more-or-less evident syntactic bureaucracy which can be safely omitted for our purposes. For PCF constants, the translation is the identity. It is also the identity on all fixed-point combinators, including those of the non-deterministic and probabilistic types, with a suitable change of types for the latter. Moreover, we stipulate that the translation is a congruence:
φ(MN ) = φ(M )φ(N ),
φ(λx.M ) = λφ(x).φ(M ).
This takes care of the deterministic fragment of the language, for which the trans- lation is then the identity.
For  ∈ {❽, ⊕}, we define, where k0 and k1 range over φ(Fσ) = Cantor → φ(σ),
φ( ) = λ(k0, k1).λs. if hd(s) then k0(tl(s)) else k1(tl(s)).
Here hd and tl are the head and tail maps on sequences, defined by hd(s) = s(0) and tl(s)(i) = s(i + 1). As discussed above, the idea is that the first element of the scheduler s dictates which branch is chosen, and the remainder of the scheduler then acts on the corresponding branch.
For the translation of the testing operators, recall that the type of may and must testing is
(σ → S) → (Fσ → S),
and hence their translations are to have type
(φ(σ) → S) → ((Cantor → φ(σ)) → S).

Similarly, the translation of probabilistic testing is to have type
(φ(σ) → I) → ((Cantor → φ(σ)) → I).

All quantifications and integrals in the following definitions are over the Cantor type (as introduced in Section 3.2), and we let the variable k range over the type φ(Fσ) = Cantor → φ(σ):
φ(0)= λu.λk.Es.u(k(s)),
φ( )= λu.λk.6s.u(k(s)),
φ(◯)= λu.λk. ∫  u(k(s)) ds.
For the functor and units of the monads, we define
φ(Ff )= λk.λs.f (k(s)), φ(ηF )= λx.λs.x.
For the multiplication, we consider PCF terms
evens, odds: Cantor → Cantor

that take subsequences at even and odd indices, and define:
φ(μF ) = λk.λs.k(evens(s))(odds(s)).

That is, we split the scheduler into two schedulers and pass each one to a different subcomputation. In the target language, the monad laws fail for the translations (both denotationally and operationally), but they will hold modulo the appropriate notion of testing. The strength is translated in a similar, mechanical, manner.

Semi-decision procedures for may, must and probabilistic testing
Given a semi-decidable property coded as a term u : σ → S and a non-deterministic program n : P σ, in order to semi-decide may and must testing we evaluate the terms

φ( (u)(n)),	φ(0(u)(n))

of ground type S in the deterministic language PCF + S + I. Similarly, to compute the probability that outcomes of n satisfy u one evaluates the term

φ(◯(c ◦ u)(n))

of type I where c : S → I is the coercion defined by c(p) = if p then 1. To semi-decide whether the probability that outcomes of n satisfy u is bigger than a definable real number r : I, one evaluates the term

φ(r < ◯(c ◦ u)(n)).

Ground evaluation
For MMP terms M : σ with γ /= I ground, it is convenient to define

M ↓ v ⇐⇒ φ(M ) ↓ v.

Denotational semantics of the executable logic
In this section we apply domain theory to prove the correctness of the semi-decision procedures for may, must and probabilistic testing developed in Section 5.
We work in the category of dcpos and continuous maps to give the semantics, but eventually need to consider continuous dcpos to prove the correctness of the semi-decision procedures. As discussed in Section 3, for the sub-language PCF, we consider its Scott model, and we interpret the type S as the Sierpinski domain
{⊥, T} and I as the unit interval [0, 1] ⊆ R with its natural order, getting an interpretation of the sub-language PCF+ S + I as in Section 3. We then interpret the powertypes as the Hoare, Smyth, Plotkin and probabilistic powerdomains [2,26].

Computational adequacy
To establish semi-decidability of may, must and probabilistic testing, we first prove
computational adequacy of the model:

Lemma 6.1 For any closed term M in the executable logic MMP of ground type other than I, and all syntactical values v,
 M ) = v) ⇐⇒ M ↓ v.
In particular, this will imply, for M : I closed and r ∈ Q, that
r < M ) ⇐⇒ r < M ↓ T.
Because the model is already known to be computationally adequate for the de- terministic sub-language PCF + S + I, we have the following purely denotational formulation of computational adequacy for the full language MMP:
Lemma 6.2 Computational adequacy holds if and only if M ) = φ(M )) for every closed term M of ground type.
To prove computational adequacy using this, we rely on the description of the powerdomains as free algebras for the (interpretations of) the choice operators ❽ and ⊕. The axioms for the operations can be found in [26,35,2]. Then the semantics of the test operators 0,  , ◯ are uniquely determined by the conditions that 0(u),
 (u) and ◯(u) are algebra homomorphisms:
0(u)(η(x)) = u(x),	0(u)(X0 ❽ X1) = 0(u)(X0) V 0(u)(X1),
  (u)(η(x)) = u(x),	  (u)(X0 ❽ X1) =  (u)(X0) Λ  (u)(X1),
◯(u)(η(x)) = u(x),	◯(u)(ν0 ⊕ ν1) = ◯(u)(ν0) ⊕ V(u)(ν1),

where we are using the fact that S and I are algebras when endowed with the operations(V), (Λ): S × S → S and (⊕): I × I → I. This completes our proof sketch for computational adequacy.
Correctness proofs of the semi-decision procedures
An alternative, also well-known [26,35,2], definition of the powerdomains is in terms of non-empty subsets and of valuations. The elements of the Hoare power domain are the closed subsets, that of the Smyth powerdomain are the compact upper sets, that of the Plotkin powerdomain are the lenses, and that of the probabilistic pow- erdomain are the continuous valuations with total mass 1. The non-deterministic choice constants are interpreted as the union operation, and the probabilistic choice constant is interpreted as the convex-combination operation (ν0, ν1) '→ ν0 ⊕ν1. The logical constants are interpreted so that, as expected,
0(u)(X) = T iff u(x) = T for some x ∈ X,
(u)(X) = T iff u(x) = T for all x ∈ X,
◯(u)(ν) =  ν u.
More usually, 0 and  are seen as open-set constructors: The Scott topologies of the Hoare, Smyth, and Plotkin powerdomains have the following bases of open sets:

Hoare: 0 U , where U ranges over open sets, and X ∈ 0 U ⇐⇒ U ∩ X /= ∅.
Smyth:  U , where U ranges over open sets, and X ∈  U ⇐⇒ X ⊆ U .
Plotkin: Both 0 U and  U , but restricted to lenses.
Hence, writing 0 D for the lattice of open sets of a domain D, we have that 0 and
  are functions:
0 : 0 D →0 H D.
: 0 D →0 S D.
(a) 0 : 0 D →0 P D.
(b)  : 0 D →0 P D.
Now 0 D ~= (D → S) via characteristic functions, and hence 0 and  can be seen as the functions discussed earlier. Moreover, it is clear that the condition U ∩X /= ∅ amounts to existential quantification over X and the condition X ⊆ U amounts to universal quantification. We have to show that these functions are continuous, but this is straightforward.

Obstacles
It may seem that the above observations, together with computational adequacy, would conclude the proof of semi-decidability of may, must and probabilistic test- ing. Unfortunately, this is not the case, because the abstract descriptions of the powerdomains given in Section 6.1 (in terms of universal properties) coincide with the concrete descriptions given in Section 6.2 (in terms of subsets and valuations) for restricted classes of domains only.
For the Hoare powerdomain, the abstract description given in Section 6.1 al- ways agrees with the concrete one given in Section 6.2 (see [35]). But for the Smyth, Plotkin and probabilistic powerdomains, the two descriptions agree only for continuous domains [35,26,2]. However, not all continuous domains are closed under function spaces and the Plotkin powerdomain, as is also well known, and there is no known cartesian closed category of continuous domains closed under the proba- bilistic powerdomain [27]. Hence we cannot expect all the types of our language to have continuous interpretations, unless further progress is made in domain theory.
Remark 6.3 These and similar issues led the authors of [4] to propose an alterna- tive form of domain theory, called topological domain theory, that would overcome these and other kinds of obstacles in semantics. We plan to investigate its use to the resolution of the problems explained here, but, for the moment, we establish very general, albeit partial, results using classical domain theory.

Partial results
The following theorem summarizes the above discussion, where the adjectives to types refer to their domain interpretations defined above:

Theorem 6.4
For any type σ, may testing on terms of type H σ is semi-decidable.
For any continuous type σ, must testing on terms of type S σ is semi-decidable.
For any RSFP type σ, may and must testing on terms of type P σ are semi- decidable.
For any continuous type σ, probabilistic testing on terms of type V σ is semi- decidable.
Remark 6.5 The smallest collection of types containing the ground types and closed under finite products, function spaces, and the Hoare, Smyth and Plotkin powertypes consists entirely of RSFP types [2]. Hence if we hadn’t included the probabilistic powertype in our language, we wouldn’t have had any of the above difficulties, and may and must testing would be semi-decidable for all types. What causes the restrictions is the presence of the probabilistic powertype.
But still the restrictions are not severe in practice: for example, probabilistic computations on any PCF type of any order have semi-decidable probabilistic test- ing. More generally, we can syntactically capture a large class of types for which the above theorem applies, as follows. Inductively define collections of types S, R, C as follows, where γ ranges over ground types:
S ::= γ | S × S | (C → S) | H C | S C, R ::= S | R × R | (R → R) | P R,
C ::= R | C × C | V C.

By a continuous Scott domain we mean a bounded complete continuous dcpo.
Proposition 6.6
The interpretation of an S type is a continuous Scott domain.
The interpretation of an R type is an RSFP domain.
The interpretation of a C type is a continuous dcpo.
Proof The ground types are continuous Scott domains. Continuous Scott domains are RSFP domains, and RSFP domains are continuous domains [2]. Plotkin showed that the category RSFP is cartesian closed, and closed under the Plotkin power- domain [2]. Scott showed that the continuous Scott domains are densely injective spaces, and the densely injective spaces are an exponential ideal [16]. Schalk showed that the continuous dcpos are closed under the Hoare and Smyth powerdomains, and it is immediate that they are bounded complete [35]. Jones showed that the continuous domains are closed under the probabilistic powerdomain [26].	 
Discussion and questions
Of course, the purpose of the algorithms developed here is to show that may, must and probabilistic testing are semi-decidable in principle, and not to attempt to

provide usable algorithms for that purpose.

Programming with closed sets, compact sets and distributions
We have considered the full language as an executable logic for semi-decidable properties, with a sub-language singled out as a programming language for non- deterministic and probabilistic computation. From a different point of view, com- patible with the denotational model, the full language can also be regarded as a deterministic programming language for computation with closed sets, compact sets, lenses, and probability distributions.

Turing universality
Can (a suitable extension of) our language define all computable elements of all types? For the case of the Smyth powertype, this is not unlikely because every compact upper set is a continuous image of the Cantor space, at least in the case of continuous Scott domains. What we need is to show that every computable ele- ment of the Smyth powerdomain is a computable image of the Cantor space. For the probabilistic powerdomain, one would have to show that every computable proba- bilistic continuous valuation is a computable image of the uniform distribution on the Cantor space, in the sense that for every ν ∈ V σ there is a term f : Cantor → σ such that ν = V(f )(u) where u : V Cantor is the uniform distribution (cf. Exam- ple 2.4). Of course, one first needs to define suitable effective presentations of the domains of interpretation of the language [42]. This in itself stumbles on the fact that it is not known whether, in the presence of the probabilistic powertype, all types are interpreted as continuous domains, as discussed in Section 6.3, and that the notion of effective presentation for domains is not well understood beyond the continuous case. Again, it may be worth looking at the ideas of the reference [4] (cf. Remark 6.3). Moreover, to achieve Turing universality, one has to take the dis- cussion of Section 7.3 into account, and hence perhaps extend the language. Notice
also that, denotationally, I ~= V S. Is this isomorphism definable? The techniques
discussed in [12,15] applied to establish Turing-universality of PCF extended with real numbers [11] may prove useful here.

Categorical universality revisited
For simplicity, in this discussion we restrict our attention to the RSFP types that exclude probabilistic powertypes. As discussed above, from the point of view of our denotational semantics, the may testing operator 0 : 0 σ → 0 H σ constructs, from any given u : σ → S, the unique H-algebra homomorphism u¯ : H σ → S ex- tending u along η : σ → H σ, namely u¯ = 0 u. The structure map of an algebra is uniquely determined by its underlying domain, because H is a K¨ock-Z¨oberlein monad [28,48,14], and amounts to the non-deterministic choice operator ❽ for H σ and parallel convergence for S. In general, not every type is the underlying object of a Hoare algebra, because the Hoare structure, when it exists, amounts to binary join in the domain-theoretic order [35].

A similar observation applies to the Smyth power domain, but things get more interesting. The monad is again of the Ko¨ck-Z¨oberlein type, and, additionally, all types are (interpreted as) underlying objects of algebras (with domain-theoretic meet as the structure map). Moreover, if one postulates generalized must testing terms : (σ → τ ) → (S σ → τ ), for τ ground, then one gets, by structural induction on types, generalized must testing programs for all PCF types τ , which articulates the universal property of the Smyth powerdomain construction within the language. In connection with the discussion of Section 5.1, by currying, twisting and currying, we get a term of type S σ → ((σ → τ ) → τ ), whose denotation is the functional Q '→ (f '→ inf f (Q)), cf. [35]. Applying this to the ground case τ = Bool, one gets a semi-decision procedure for must testing that answers True or False, and diverges if and only if some outcome of the given non-deterministic computation is divergent (cf. Example 4.1).
The Plotkin powerdomain is not of the Ko¨ck-Z¨oberlein type, and domains admit zero, one or more structure maps, and Hoare and Smyth structures are always Plotkin structures. Hence domains in the interpretation of PCF types have at least one Plotkin structure, namely the Smyth structure. For example, the may operator on the Plotkin powerdomain gives the universal property for the Hoare structure on S, and the must operator for the Smyth structure.
Combination of probability with non-determinism
A number of authors have considered powerdomains that simultaneously account for probability and non-determinism [29,46,47]. Here we discuss first steps in this direction, closely following the ideas of [46]. A major difference is that this reference considers non-negative real-valued valuations rather than unit-interval valued valu- ations with total mass 1. To prove the correctness of the semi-decision procedures discussed here, we would need a theory based on the latter.
Recall that the Hoare powerdomain can be defined as the set of non-empty closed sets, and hence HV D is the collection of closed sets of valuations. Tix, Keimel and Plotkin [46] consider a powerdomain VH D consisting of the geometri- cally convex, closed sets of valuations. Similarly, they consider powerdomains VS D, consisting of geometrically convex, compact upper sets of valuations, and VP D, consisting of geometrically convex lenses of valuations. Using our notations ❽ and
⊕ for non-deterministic and probabilistic choice, the equational theories for these
powerdomains are given by the following distributive law
x ⊕ (y ❽ z) = (x ⊕ y) ❽ (x ⊕ z),
for VP, and where ❽ has to additionally satisfy the semi-lattice equations plus:
x ❽ y ± x for VH (❽ is the binary join operation w.r.t. the information order),
x ❽ y ± x for VS (❽ is the binary meet operation w.r.t. the information order).

Non-deterministic/probabilistic powertypes. We now consider the extension of the above programming language and logic with powertypes corresponding to these

powerdomains, using the same notation for them, where now each of them has both constructs (❽) and (⊕), as discussed above. Moreover, the functor, unit, multiplication, and strength rules are defined in the same way as for the other powertype constructors.

May-probabilistic and must-probabilistic rules. We need four constants
σ : s σ →s VH σ, σ : s σ →s VS σ, σ : s σ →s VP σ, σ : s σ →s VP σ.
Continuing the discussion of Section 5.1, for the Hoare probabilistic powertype, from the may-probabilistic operator 0 : s σ →s VH σ we get a term of type VH σ → ((σ → I) → I) written supν∈C ν u = 0(u)(C). The fictitious bound variable ν is included to make the notation suggestive of the denotational semantics discussed above. What we mean by this notation is that the application of the nameless term VH σ → ((σ → I) → I) to a term C : VH σ followed by an application to a term :	is written sup	. For the Smyth probabilistic powertype, we get a similar term, but we instead write infν∈Q ν u. For the Plotkin probabilistic powertype we get both.

Translation of types. For non-determinism combined with probability, we propose that two schedulers are needed: one to perform the non-deterministic choices and the other to perform the probabilistic choices. The first one is chosen in an angelic or demonic way, but the second one with uniform distribution. We thus extend the definition of the translation φ defined in Section 5 by stipulating that

φ(Gσ) = Cantor × Cantor → φ(σ),	for G ∈ {VH, VS, VP}.


Operational semantics. The translations of the non-deterministic choice operators consume tokens from the first scheduler:
φ(❽)= λ(k0, k1).λ(s, t). if hd(s) then k0(tl(s), t) else k1(tl(s), t).
Those of probabilistic choice operators consume tokens from the second scheduler:
φ(⊕)= λ(k0, k1).λ(s, t). if hd(t) then k0(s, tl(t)) else k1(s, tl(t)).
The translations of may and must probabilistic testing have type (φ(σ) → I) → ((Cantor × Cantor → φ(σ)) → I),
and are given as follows, where we emphasize that the infima, suprema and integrals are over the Cantor type as above:

φ(0)= λu.λk. sup(∫ u(k(s, t)) dt),

φ(  )= λu.λk. inf(	u(k(s, t)) dt).
s

For the monad structure, we define:
φ(Gf )= λk.λ(s, t).f (k(s, t)), φ(ηG)= λx.λ(s, t).x,
φ(μG)= λk.λ(s, t).k(evens(s), evens(t))(odds(s), odds(t)).
For the technical reasons discussed above, we leave the correctness of this proposed translation open.

References
S. Abramsky. Domain theory in logical form. Ann. Pure Appl. Logic, 51(1-2):1–77, 1991.
S. Abramsky and A. Jung. Domain theory. In S. Abramsky, D.M. Gabbay, and T.S.E. Maibaum, editors, Handbook of Logic in Computer Science, volume 3, pages 1–168. Oxford science publications, 1994.
T. Anberr´ee. On the non-sequential nature of domain models of real-number computation. Elec. Notes in Theoret. Comp. Sc., 173:41–46, 2007.
I. Battenfeld, M. Schr¨oder, and A. Simpson. A convenient category of domains. Electron. Notes Theor. Comput. Sci., 172:69–99, 2007.
P. Di-Gianantonio. A Functional Approach to Computability on Real Numbers. PhD thesis, Universit`a Degli Studi di Pisa, Dipartamento di Informatica, 1993.
A. Edalat and M.H. Escard´o. Integration in Real PCF. Inform. and Comput., 160:128–166, 2000.
M. Escard´o. Mathematical foundations of functional programming with real numbers. Course notes for a course delivered at the Midlands Graduate School in the Foundations of Computer Science, Leicester, http://www.cs.bham.ac.uk/~mhe/papers/mgs.pdf, April 2003.
M. Escard´o. Exhaustible sets in higher-type computation. Log. Methods Comput. Sci., 4(3):3:3, 37, 2008.
M. Escard´o and W. K. Ho. Operational domain theory and topology of sequential programming languages. Information and Computation, 207:411–437, 2009.
M. Escard´o, M. Hofmann, and T. Streicher. On the non-sequential nature of the interval-domain model of real-number computation. Math. Structures Comput. Sci., 14(6):803–814, 2004.
M.H. Escard´o. PCF extended with real numbers. Theoret. Comput. Sci., 162(1):79–115, 1996.
M.H. Escard´o. Real PCF extended with ∃ is universal. In A. Edalat, S. Jourdan, and G. McCusker, editors, Advances in Theory and Formal Methods of Computing: Proceedings of the Third Imperial College Workshop, April 1996, pages 13–24, Christ Church, Oxford, 1996. IC Press.
M.H. Escard´o. Synthetic topology of data types and classical spaces. Electron. Notes Theor. Comput. Sci., 87:21–156, 2004.
M.H. Escard´o and R.C. Flagg. Semantic domains, injective spaces and monads. Electron. Notes Theor. Comput. Sci., 20, 1999.
M.H. Escard´o and Th. Streicher. Induction and recursion on the partial real line with applications to Real PCF. Theoret. Comput. Sci., 210(1):121–157, 1999.
G. Gierz, K.H. Hofmann, K. Keimel, J.D. Lawson, M. Mislove, and D.S. Scott. Continuous Lattices and Domains. Cambridge University Press, 2003.
C.A. Gunter. Semantics of Programming Languages—Structures and Techniques. The MIT Press, 1992.


R. Heckmann. An upper power domain construction in terms of strongly compact sets. Lecture Notes in Comput. Sci., 598:272–293, 1992.
R. Heckmann. Power domains and second order predicates. Theoret. Comput. Sci., 111:59–88, 1993.
R. Heckmann. Spaces of valuations. In Papers on general topology and applications (Gorham, ME, 1995), volume 806 of Ann. New York Acad. Sci., pages 174–200. New York Acad. Sci., New York, 1996.
M. Hennessy and R. Milner. On observing nondeterminism and concurrency. Lecture Notes in Comput. Sci., 85:299–309, 1980.
M. Hennessy and R. Milner. Algebraic laws for nondeterminism and concurrency. J. Assoc. Comput. Mach., 32(1):137–161, 1985.
M. C. B. Hennessy and E. A. Ashcroft. A mathematical semantics for a nondeterministic typed λ- calculus. Theoret. Comput. Sci., 11(3):227–245, 1980.
S.G. Hoggar. Mathematics for Computer Graphics. Cambridge Tracts in Theoretical Computer Science. Cambridge University Press, 1992.
J.E. Hutchinson. Fractals and self-similarity. Indiana University Mathematics Journal, 30:713–747, 1981.
C. Jones. Probabilistic Non-determinism. PhD thesis, Laboratory for Foundations of Computer Science, University of Edinburgh, January 1990. .
A. Jung and R. Tix. The troublesome probabilistic powerdomain. Electron. Notes Theor. Comput. Sci., 1997.
A. Kock. Monads for which structures are adjoint to units (version 3). Journal of Pure and Applied Algebra, 104:41–59, 1995.
A. K. McIver and C. Morgan. Partial correctness for probabilistic demonic programs. Theoret. Comput. Sci., 266(1-2):513–541, 2001.
D. Normann. Exact real number computations relative to hereditarily total functionals. Theoret. Comput. Sci., 284(2):437–453, 2002.
C.-H. L. Ong. Non-determinism in a functional setting (extended abstract. In In Proceedings 8th LICS, pages 275–286, 1993.
G.D. Plotkin. LCF considered as a programming language. Theoret. Comput. Sci., 5(1):223–255, 1977.
P.J. Potts, A. Edalat, and M.H. Escard´o. Semantics of exact real arithmetic. In Proceedings of the Twelveth Annual IEEE Symposium on Logic In Computer Science, Warsaw, Polland, Jun 1997.
H. Rogers. Theory of Recursive Functions and Effective Computability. McGraw-Hill, New York, 1967.
A. Schalk. Algebras for Generalized Power Constructions. PhD thesis, Technische Hochschule Darmstadt, July 1993. ftp://ftp.cl.cam.ac.uk/papers/as213/diss.dvi.gz.
M. Schr¨oder and A. Simpson. Probabilistic observations and valuations (extended abstract). Electron. Notes Theor. Comput. Sci., 155:605–615, 2006.
M. Schr¨oder and A. Simpson. Representing probability measures using probabilistic processes. J. Complexity, 22(6):768–782, 2006.
D.S. Scott. A type-theoretical alternative to CUCH, ISWIM and OWHY. Theoret. Comput. Sci., 121:411–440, 1993. Reprint of a 1969 manuscript.
A. Scriven. A functional algorithm for exact real integration with invariant measures. Electron. Notes Theor. Comput. Sci., 218:337–353, 2008.
K. Sieber. Call-by-value and nondeterminism. Lecture Notes in Comput. Sci., 664:376–390, 1993.
A. Simpson. Lazy functional algorithms for exact real functionals. Lec. Not. Comput. Sci., 1450:323– 342, 1998.
M.B. Smyth. Effectively given domains. Theoret. Comput. Sci., 5(1):256–274, 1977.
M.B. Smyth. Power domains. Journal of Computer and Systems Sciences, 16:23–36, 1977.
M.B. Smyth. Power domains and predicate transformers: a topological view. Lec. Not. Comput. Sci., 154:662–675, 1983.

T. Streicher. Domain-theoretic Foundations of Functional Programming. World Scientific, 2006.
R. Tix, K. Keimel, and G. Plotkin. Semantic domains for combining probability and non-determinism.
Electron Notes in Theor. Comput. Sci., 129, 2005.
D. Varacca and G. Winskel. Distributing probability over non-determinism. Math. Structures Comput. Sci., 16(1):87–113, 2006.
S. Vickers. Locales are not pointless. In C. Hankin, I. Mackie, and R. Nagarajan, editors, Theory and Formal Methods 1994: Proceedings of the Second Imperial College Department of Computing Workshop on Theory and Formal Methods, Møller Centre, Cambridge, 11–14 September 1994. IC Press. 1995.
