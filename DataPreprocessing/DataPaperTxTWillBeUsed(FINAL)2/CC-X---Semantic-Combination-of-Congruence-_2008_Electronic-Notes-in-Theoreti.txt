Electronic Notes in Theoretical Computer Science 198 (2008) 51–69	
www.elsevier.com/locate/entcs

CC(X): Semantic Combination of Congruence Closure with Solvable Theories

Sylvain Conchon 1 ,2	Evelyne Contejean 1 ,2	Johannes Kanig 1 ,2
Stéphane Lescuyer 1 ,2
LRI, Univ. Paris-Sud, CNRS, Orsay F-91405 & INRIA Futurs, ProVal, Orsay, F-91893
FRANCE

Abstract
We present a generic congruence closure algorithm for deciding ground formulas in the combination of the theory of equality with uninterpreted symbols and an arbitrary built-in solvable theory X. Our algorithm CC(X) is reminiscent of Shostak combination: it maintains a union-find data- structure modulo X from which maximal information about implied equalities can be directly used for congruence closure. CC(X) diverges from Shostak’s approach by the use of semantic values for
class representatives instead of canonized terms. Using semantic values truly reflects the actual
implementation of the decision procedure for X. It also enforces to entirely rebuild the algorithm since global canonization, which is at the heart of Shostak combination, is no longer feasible with semantic values. CC(X) has been implemented in Ocaml and is at the core of Ergo, a new automated
theorem prover dedicated to program verification.
Keywords: decision procedures, equality theory, congruence closure, verification


Introduction
Combining decision procedures for the quantifier-free theory of equality over uninterpreted function symbols (E) and other theories is at the core of a number of verification systems. For instance, problem divisions of the SMT competition [10] include the combinations of E and the linear arithmetics over the integers; E and the theory of arrays etc.

1 Work partially supported by A3PAT project of the French ANR (ANR-05-BLAN-0146- 01).
2 Email: {conchon,contejea,kanig,lescuyer}@lri.fr



1571-0661 © 2008 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2008.04.080

There are two main paradigms for combining theories: The Nelson-Oppen combination procedure [5] and the Shostak’s algorithm [12,11]. The former procedure is very general: it applies to disjoint stably-infinite theories that communicate by an equality propagation mechanism between shared variables. However, quoting Shankar from [11], this method “has some disadvantages”. Indeed, the theory E has no particular status in this approach and its combi- nation amounts to implementing a specific decision procedure with the ability to infer and communicate new implied equalities, which can be very expensive. On the contrary, Shostak’s method has been specifically designed for com- bining E with (a smaller class of) solvable and canonizable theories. Again quoting Shankar [11], “Shostak’s algorithm tries to gain efficiency”, when it is applicable. It is based on an extension of a congruence closure algorithm that maintains a partition of terms within a table (reminiscent of a union-find data structure) mapping terms to representatives. Roughly speaking, a run of this algorithm consists in transforming equations into substitutions using solvers, then applying substitutions to representatives and reducing the latter to normal forms by the use of canonizers so that new equations can be directly
drawn from the table.
A central point for Shostak method and its extensions [9] to be effective is that representatives have to be themselves terms. As a consequence, the main operations of the algorithm, substitution application, normal form re- duction and equation resolution, have to be directly implemented on term data structures, which is not the best efficient way of implementing a decision procedure 3 (e.g. a term data structure is obviously not optimal to manipulate polynomials). However, relaxing this constraint has strong impacts on the design of the method. Indeed, bringing a representative into a normal form amounts to traversing its syntactic structure for applying the canonizers on interpreted subterms. This global canonization is at the heart of the method and it also guarantees the incrementality of the algorithm.
In this paper, we present an algorithm, called CC(X) (for congruence clo- sure modulo X), which combines the theory E with an arbitrary built-in solv- able theory X without using canonizers. This algorithm uses abstract values as representatives allowing efficient data structures for the implementation of solvers. CC(X) is presented as a set of inference rules whose description is low-level enough to truly reflect the actual implementation of the combination mechanism of the Ergo [1] theorem prover. Unlike Shostak’s algorithm, global canonization is no longer possible with abstract values. As a consequence, incrementality of CC(X) is not obtained for free and extra rules are added in our inference system to make our algorithm incremental.

3 It is also worth noting that this constraint is not imposed by the Nelson-Oppen approach.

Congruence Closure Modulo X
In this section, we present an extension of a congruence closure algorithm ca- pable of combining the theory of equality with uninterpreted function symbols and another theory X that underlies certain restrictions. In the rest of this pa- per, Σ denotes the set of all symbols, including interpreted and uninterpreted symbols.

Solvable Theories
While solvers and canonizers of Shostak theories operate on terms directly, the theory X we are about to introduce works on a certain set R, whose elements are called semantic values. The main particularity is that we don’t know the exact structure of these values, only that they are somehow constructed of interpreted and uninterpreted (foreign) parts. To compensate, we dispose of two functions [·]: T (Σ) →R and leaves : R→ P∗(R) which are reminiscent of the variable abstraction mechanism found in Nelson-Oppen method. [·] constructs a semantic value from a term; leaves extracts its uninterpreted parts in abstract form.
Definition 2.1 We call a solvable theory X a tuple (ΣX, R, =X ), where ΣX ⊆ Σ is the set of function symbols interpreted by X, R is a set (of semantic values) and =X is a congruence relation over terms, =X ⊆ T (Σ) × T (Σ). Additionally, a theory X has the following properties:
There is a function [·] : T (Σ) → R to construct a semantic value out of a term. For any set E of equations between terms we write [E] for the set
{[x]= [y] | x = y ∈ E}.
There is a function leaves : R → P∗(R), where the elements of P∗(R)
f	f
are finite non-empty sets of semantic values. Its role is to return the set
of maximal uninterpreted values a given semantic value consists of. Its behaviour is left undefined, but is constrained by axioms given below.
There is a special value 1 ∈ R which we will use to denote the leaves of pure terms’ representatives.
There is a function subst : R×R ×R → R. Instead of subst(p, P, r) we write r {p '→ P }. The pair (p, P ) is called a substitution and subst(p, P, r) is the application of a substitution to r.
There is a (partial) function solve : R× R → R × R.
Let ER be the set of equations between elements of R. There is a relation
|=⊂ P(ER) ×R× R whose meaning is the following: if r1 equals r2 can be deduced, in the model R, from the equalities e1,... , en ∈ ER, we write

{e1,... , en} |= r1 = r2. In particular, when ∅ |= a = b, this means that the semantic values a and b are equal, which we write a ≡ b.
In the remaining of this paper, we simply call theory a solvable theory. An example of such a theory is given in Section 3.
In the following, for any set S, we write S∗ the set of finite sequences of elements of S. If s ∈ S∗ is such a sequence and a is an element of S, we write a; s for the sequence obtained by prepending a to s. The empty sequence is denoted •. As we will often talk about successive substitutions, we define an auxiliary function that does just that:
Definition 2.2 There is a function iter : (R× R)∗ ×R → R that applies
subst successively in the following way:
iter(•, r) = r
iter((r1, r2); S, r3) = r' {p '→ P } where r' = iter(S, ri) and (p, P )= solve(r' , r' ).
3	i	1	2
In addition to definition 2.1, a theory X must fulfill the following axioms:
Axiom 2.3 For any r1, r2, p,P ∈ R, solve(r1, r2) = (p, P ) ⇒ r1 {p '→ P } ≡ 
r2 {p '→ P }.
Axiom 2.4 [E] |= [u]= [v] ⇒ u =E,X v, where =E,X denotes the equational theory defined by E ∪ =X .
Axiom 2.5 For any S ∈ (R×R)∗ and any r ∈ R, we have S |= iter(S, r)= r
where S is seen as a set on the left-hand side of |=.
Axiom 2.6 For any r, p, P ∈R such that r /≡ r{p '→ P },
p ∈ leaves(r)
leaves(r{p '→ P })= (leaves(r) \ {p}) ∪ leaves(P )
Axiom 2.7 For any pure term t ∈ T (ΣX), leaves([t]) = {1}.
Let us explain this a little bit. First of all, as we will see in section 2.2, the algorithm establishes and maintains equivalence classes over semantic values. Every equivalence class is labeled by an element of the set R; a function Δ: R→ R is maintained that for each value returns its current label. Together with the [.] function, this function can be used to maintain equivalence classes over terms. The function solve is capable of solving an equation between two elements of R, that is, it transforms an equation r1 = r2 for r1, r2 ∈R into the substitution (p, P ), with p, P ∈ R, where the value p is now isolated. Axiom
2.3 makes sure that such a substitution renders equal the two semantic values r1 and r2, which are at the origin of this substitution. Finally, R comes also with a notion of implication of equalities, the relation |=. Axiom 2.4 just states

that, if a set [E] of equations between semantic values implies an equation
[u] = [v], then u =E,X  v, that is, an equality on the theory side implies an equality between corresponding terms. Axiom 2.5 states that iterated substitution iter behaves well with respect to this implication relation: if r' has been obtained from r by iterated substitution, then the equations at the origin of these substitutions imply the equality r' = r (axiom 2.5). Axiom 2.6 ensures that substituting P to p in a semantic value only has effect if p is a leaf of this value, and that the new leaves after the substitution are leaves coming from P . Finally, the last axiom describes why we introduced a special value 1 in R: representatives of pure terms do not have leaves per se, but it is convenient for the algorithm that the set leaves(r) be non-empty for any semantic value r. To that purpose, we arbitrarily enforce that leaves([t]) is the singleton {1} for any pure term t.
As a last remark, we have given the interface of a theory X in a slightly less general fashion as was possible: depending on the theory, the function solve may as well return a list of pairs (pi, Pi) with pi, Pi ∈ R. It becomes clear why we call this a substitution: the pi can be seen as variables, that, during the application of a substitution, are replaced by a certain semantic value. However, for the example presented in the next section, solve always returns a single pair, if it succeeds at all. Thus, we will stick with the simpler forms of solve and subst.
The following proposition is a simple, but useful, consequence of the axioms stated above. It will be used in the soundness proof. It simply states that, if semantic values constructed with [·] are equal, the original terms were already equal with respect to X.
Proposition 2.8 For any terms x, y ∈ T (Σ), [x] ≡ [y] ⇒ x =X y.
In order to prove the completeness, we need to make a few more assump- tions about the theory X, or rather about the interpretation of symbols in ΣX.
Axiom 2.9 For each interpreted symbol f ∈ ΣX of arity n, we assume there exists a function f X from Rn to R such that:
∀t ,...,t ∈ T (Σ), [f (t ,... ,t )] ≡ f X([t ],... , [t ])
1	n	1	n	1	n
Note, though, that these functions need not be implemented for the algo- rithm to work: only their existence matters to us, [.] could be computed in any other conceivable way and our algorithm CC(X) will never need to use one of these functions explicitly. The last axiom simply state that substitutions happen at the leaves level of semantic values.
Axiom 2.10 For any interpreted symbol f , given terms t1,... , tn and two

semantic values p and P ,

f X([t ],... , [t ]){p '→ P }≡ f X([t ]{p '→ P },... , [t
]{p '→ P })

1	n	1	n

The Algorithm CC(X)
The backtracking search underlying the architecture of a lazy SMT solver enforces an incremental treatment of the set of ground equations maintained by the solver. Indeed, for efficiency reasons, equations are given one by one by the SAT solver to decision procedures which prevents them from realizing a global preliminary treatment, unless restarting the congruence closure from scratch. Therefore, CC(X) is designed to be incremental and deals with a sequence of equations and queries instead of a given set of ground equations.
The algorithm works on tuples (configurations) ⟨ Θ | Γ | Δ | Φ ⟩, where:
Θ is the set of terms already encountered by the algorithm;
Γ is a mapping from semantic values to sets of terms which intuitively maps each semantic value to the terms that “use” it directly. This structure is reminiscent of Tarjan et al.’s algorithm [2] but differs in the sense that it traverses interpreted symbols (as expressed in Proposition B.6 in the appendix). This information is used to efficiently retrieve the terms which have to be considered for congruence;
Δ a mapping from semantic values to semantic values maintaining the equiv- alence classes over R as suggested in Section 2.1: it is a structure that can tell us if two values are known to be equal (it can be seen as the f ind function of a union-find data structure);
Φ a sequence of equations between terms that remain to be processed.

Given a sequence E of equations and a query a =?
b for which we want

to solve the uniform word problem, CC(X) starts in an initial configuration

K = ⟨∅ | Γ | Δ | E ; a =?
b ⟩, where Γ0(r)= ∅ and Δ0(r)= r for all r ∈ R.

In other words, no terms have been treated yet by the algorithm, and the partition Δ0 corresponds to the physical equality ≡.
In Figure 1, we describe our algorithm CC(X) as four inference rules op- erating on configurations. The semantic value Δ(r), for r ∈ R is also called representative of r. When t is a term of T (Σ), we write Δ[t] as an abbreviation for Δ([t]), which we call the representative of t. Figure 1 also uses several other abbreviations: we write →u for u1,... , un, where n is clear from the context ; we also write Δ[→u] ≡ Δ[→v] for the equivalences Δ[u1] ≡ Δ[v1],... , Δ[un] ≡ Δ[vn]. If t ∈ Γ(r) for t ∈ T (Σ),r ∈ R, we also say r is used by t, or t uses r.
We now have all the necessary elements to understand the rules. There are actually only two of them, namely Congr and Add, which perform any



⟨  Θ  |  Γ  |  Δ  |  a = b ; Φ  ⟩
Congr ⟨  Θ |  Γ  Γ'  |  Δ'  |  Φ' ; Φ ⟩ a, b ∈ Θ, Δ[a] /≡ Δ[b]
where,
(p, P )= solve(Δ[a], Δ[b])


Γ' =
l∈leaves(P )
l '→ Γ(l) ∪ Γ(p)

∀r ∈ R, Δ'(r) := Δ(r) {p '→ P }


Φ' =
(f (→u)= f (→v)
Δ'[→u] ≡ Δ'[→v], f (→u) ∈ Γ(p)
˛ f (→v) ∈ Γ(p) ∪ St∈Θ|p∈leaves(Δ[t]) Tl∈leaves(Δ'[t]) Γ(l)



Remove
⟨  Θ  |  Γ  |  Δ  |  a = b ; Φ  ⟩


⟨  Θ  |  Γ  |  Δ  |  Φ  ⟩
a, b ∈ Θ,  Δ[a] ≡ Δ[b]

Add 	⟨ Θ |  Γ |  Δ |  C[f(→a)] ; Φ ⟩	 ( f (→a) /∈ Θ

where C[f (→a)] denotes an equation or a query containing the term f (→a)

8> Γ' =	[
l '→ Γ(l) ∪ {f (→a)}

with ><>
l∈LΔ(→a)
<	˛
\	9=

Φ' =
f (→a)= f (→b) Δ[→a] ≡ Δ[→b], f (→b) ∈
˛
Γ(l)

:	:S	˛
l∈LΔ(→a)	;




Query
⟨  Θ  |  Γ  |  Δ  |  a =? b ; Φ  ⟩


⟨  Θ  |  Γ  |  Δ  |  Φ  ⟩

a, b ∈ Θ,  Δ[a] ≡ Δ[b]



Fig. 1. The rules of the congruence closure algorithm CC(X)
interesting tasks. The other two are much simpler: Remove just checks if the first equation in Φ is already known to be true (by the help of Δ), and, if so, discards it. The Query rule is analogous to the Remove rule but deals with a query.


The rule
Congr
is more complex.	It also inspects the first equation

in Φ, but only when it is not already known to be true.  This equation a = b with a, b ∈ Θ is transformed into an equation in R, Δ[a] = Δ[b], and then solved in the theory X, which yields two semantic values p and P . The value p is then substituted by P in all representatives. The map Γ is updated according to this substitution: the terms that used p before now also use all the values l ∈ leaves(P ). Finally, a set Φ' of new equations is calculated, and appended to the sequence Φ of the equations to be treated

(the order of the equations in Φ' is irrelevant). The set Φ' is computed in the following way: the left hand side of any equation in Φ' is a term that used p, and the right hand side is either a term that used p, or a term that used every l ∈ leaves(Δ'(r)) for a value r such that p ∈ leaves(Δ(r)). This rather complicated condition ensures that only relevant terms are

considered for congruence.	As the name implies, the
Congr
rule will

only add equations of the form f (t1,... , tn) = f (t' ,... , t' ), where the cor-
1	n
responding subterms are already known to be equal: Δ'[ti] ≡ Δ'[t'], 1 ≤ i ≤ n.


The rule
Add
is used when the first equation of Φ contains at least a

term f (→a) that has not yet been encountered by the algorithm (f (→a) ∈/ Θ).
Its side condition ensures that all proper subterms of this term have been added before ; in other words, new terms are added recursively. The first task that this rule performs is of course to update the map Γ by adding the information that f (→a) uses all the leaves of its direct subterms. However, this is not sufficient: we lose the completeness of the algorithm if no equation is
added during the application of an Add rule. Indeed, suppose for instance
that Φ is the sequence f (a)= t; a = b; f (b)= u. Then, we would fail to prove that t = u since the equality a = b is processed too early. At this point, f (b) has not been added yet to the structure Γ, thus preventing the congruence equation f (a)= f (b) to be discovered in the Congr rule. For this reason, the Add rule also performs congruence closure by looking for equations involving the new term f (→a): this is the construction of the set Φ' of equations, where the restrictive side condition over f (→b) ensures that only relevant terms are considered.
Soundness and completeness proofs of CC(X) are given in appendices A and
B. Since no new terms are generated during CC(X)’s execution, the number of potential equations to be handled is quadratically bounded by the input problem size.

Example
In this section, we present the theory A of linear arithmetic over the rationals as an interesting example of instantiation of CC(X). This theory consists of the following elements:
The interpreted function symbols are +, −, /, ×, succ and 0.
The semantic values are polynomials of the form
n

c0 +	ci ri ,	ci ∈ Q, 
i=1
∈ T (Σ), ci /= 0.

From an implementation point of view, these polynomials can be represented as pairs where the left component represents c0 and the right component is a map from foreign values (not handled by linear arithmetic; these are surrounded by a box in this example) to rationals that represents the sum

n
i=1
ci ri . Note that in semantic values, + is not the interpreted func-

tion symbol but just notation to separate the different components of the
polynomial.
• =A is just the usual equality of linear arithmetic over rationals. The functions needed by the algorithm are defined as follows:
The function [·] interprets the above function symbols as usual and con- structs polynomials accordingly.
The function leaves just returns the set of all the foreign values in the polynomial:

leaves

c0 +
Σi=1

ci ri

= { ri | 1 ≤ i ≤ n} .

For the value foreign value
and the polynomials p1, p2, subst( r , p1, p2) replaces the by the polynomial p1 in p2, if r occurs in p2.

For two polynomials p1, p2 ∈ R, solve(p1, p2) is simply the Gauss algorithm that solves the equation p1 = p2 for a certain foreign values occurring in p1 or p2.
|= is again just the entailment relation in linear arithmetic.
If we admit the soundness of the [·] function and the Gauss algorithm used in solve, the axioms that need to hold are trivially true.
Theorem 3.1 The functions defined above satisfy the axioms 2.3 - 2.5.
We now want to show the execution of the non-incremental algorithm by an example in arithmetic. Consider therefore the set of equations
E = {g(x + k)= a, s = g(k),x = 0}
and we want to find out if the equation s = a follows. The algorithm starts in

the initial configuration K = ⟨∅ | Γ | Δ | E ; s =?
a ⟩, as defined in section

2.2. In the following, components of the configuration with the subscript i de- note the state of the component after complete treatment of the ith equation.
Before being able to treat the first equation g(x + k)= a using the Congr rule, all the terms that appear in the equation have to be added by the Add rule. This means in particular that the components Γ and Θ are updated according to Fig. 1. No new equations are discovered, so Φ and Δ remain unchanged. Now we can apply the Congr rule to the first equation g(x +

k) = a. This yields an update of Γ and Δ, but no congruence equations are discovered. This is the configuration after the treatment of the first equation:

Γ1 =	x '→ {x + k, g(x + k)} ,
 
	
'→ {x + k, g(x + k)} } ∪ Γ0

The second equation is treated similarly: The terms s and g(k) are Added and the representative of g(k) becomes s . These are the changes to the structures Γ and Δ:
Γ2 = k '→ {x + k, g(x + k), g(k)} } ∪ Γ1
	
The most interesting part is the treatment of the third equation, x = 0, be- cause we expect the equation g(x + k)= g(k) to be discovered. Otherwise, the algorithm would be incomplete. Every term in the third equation has already
been added, so we can directly apply the Congr rule. solve(Δ2 [a] , Δ2 [b])
returns the substitution (x, 0), which is applied to all representatives. The value 0 is a pure arithmetic term, so leaves(0) returns {1}. We obtain the following changes to Γ3 and Δ3:
Γ3 = {1 '→ {x + k, g(x + k)}} ∪ Γ2
Δ3 = x '→ 0, x +	'→ k } ∪ Δ2
It is important to see that the representative of x + k has changed, even if the term was not directly involved in the equation that was treated.
To discover new equations, the set Φ3 has to be calculated. To calculate this set, we first collect the terms that use x:
Γ2( x )= {x + k, g(x + k)} .
The elements of Γ2(x) are potential lhs of new equations. To calculate the set of potential rhs, we first construct the set of values r corresponding to terms in Θ2 such that the representative of r contains x:
{r | x ∈ leaves(Δ2(r))} =  x, x + k
Now, for every value r in this set, we calculate leaves(Δ3(r)) and construct their intersection:



l∈le aves(0)
Γ2(l)= Γ2(1)= ∅



l∈leav es„
Γ2(l)= {x + k, g(x + k), g(k)}
«

The union of the two sets and the set Γ2( x ) is the set of potential rhs
{x + k, g(x + k), g(k)}. If we cross this set with the set Γ2( x ) and filter the equations that are not congruent, we obtain three new equalities

Φ = x + k = x + k ; g(x + k)= g(x + k) ; g(x + k)= g(k); s =? a.
The first two equations get immediately removed by the Remove rule. The third one, by transitivity, delivers the desired equality which permits to dis-
charge the query s =? a.
Implementation
An efficient Ocaml implementation of CC(X) exists and is at the heart of the Ergo automated theorem prover [1]. This implementation uses only purely functional data-structures and directly follows the inference rules presented in Section 1.
In order to check the scalability of our algorithm, we benchmarked Ergo on our test suite: 1450 verification conditions automatically generated by the VCG Caduceus/Why from 69 C programs [8]. These goals make heavy use of equalities over uninterpreted function symbols and linear arithmetic. Figure 2 shows the results of the comparison between Ergo and four other provers: Z3, Yices, Simplify and CVC3. The five provers were run with a fixed timeout of 20s on a machine with Xeon processors (3.20 GHz) and 2 Gb of memory. For this benchmark, CC(X) is instantiated with the theory of linear arithmetic.

Fig. 2. Comparison between Ergo, Simplify, Yices, CVC3 and Z3 on 1450 verification conditions.
The column valid shows the percentage of the conditions proved valid by the provers 4 . The column timeout gives the percentage of timeouts whereas unknown shows the amount of problems unsolved due to incompleteness. Finally, the column avg. time gives the average time for giving a valid answer.
As shown by the results in Figure 2, the current experimentations are very promising with respect to speed and to the number of goals automatically

4 All conditions of our test suite are proved valid at least by one prover.

solved. However, the benchmarks also contain logical connectives and quan- tifiers, not handled by CC(X). So, strictly speaking, Figure 2 only proves that CC(X) is sufficiently fast to let Ergo compete with state-of-the-art SMT solvers.

Conclusion and Future Work
We have presented a new algorithm CC(X) which combines the theory of equal- ity over uninterpreted function symbols with a solvable theory. Our method is reminiscent of Shostak’s algorithm [12,11,3]. Its main novelty rests on the use of abstract data structures for class representatives that allows efficient implementations of crucial operations. Our approach is also higly modular: contrarily to ad-hoc extensions of congruence closure [6,7], CC(X) can be in- stantiated with an arbitrary solvable theory underlying the restrictions de- scribed in Section 2.1.
CC(X) has been implemented in Ocaml as a functor parameterized by a theory module whose signature is the one given in section 2.1. CC(X) is at the core of the Ergo theorem prover. Since practice often arrives before theory, a number of extra features of CC(X) have already been implemented in Ergo. We leave for future work their formalization and correctness proofs:
A functor CombineX(X1,X2) combines two theory modules X1 and X2, al- lowing CC(X) to combine several solvable theories. As shown in [4], solvers for first order theories almost never combine. However, while this is out of the scope of this paper, we claim that solvers for typed theories (under certain restrictions) can be combined.
Predicate symbols are already handled by CC(X). Their treatment smoothly integrates to the overall framework.
CC(X) has been instrumented to produce explications so that the SAT solver part of Ergo can benefit from them for its backjumping mechanism.
Another direction is to “prove the prover” in a proof assistant. Indeed, Ergo uses only purely functional data-structures, is highly modular and very concise (∼ 3000 lines of code). All these features should make a formal certification feasible.

References
S. Conchon and E. Contejean. The Ergo automatic theorem prover. http://ergo.lri.fr/.
P. J. Downey, R. Sethi, and R. E. Tarjan. Variations on the common subexpressions problem.
J. ACM, 27(4):771–785, 1980.

J.-C. Filliâtre, S. Owre, H. Rueß, and N. Shankar. ICS: Integrated Canonization and Solving (Tool presentation). In G. Berry, H. Comon, and A. Finkel, editors, Proceedings of CAV’2001, volume 2102 of Lecture Notes in Computer Science, pages 246–249. Springer, 2001.
S. Krstić and S. Conchon. Canonization for disjoint unions of theories. Information and Computation, 199(1-2):87–106, May 2005.
G. Nelson and D. C. Oppen. Simplification by cooperating decision procedures. ACM Trans. on Programming, Languages and Systems, 1(2):245–257, Oct. 1979.
G. Nelson and D. C. Oppen. Fast decision procedures based on congruence closure. J. ACM, 27(2):356–364, 1980.
R. Nieuwenhuis and A. Oliveras. Fast Congruence Closure and Extensions. Inf. Comput., 2005(4):557–580, 2007.
ProVal Project. Why Benchmarks. http://proval.lri.fr/why-benchmarks/.
S. Ranise, C. Ringeissen, and D. K. Tran. Nelson-oppen, shostak and the extended canonizer: A family picture with a newborn. In ICTAC, pages 372–386, 2004.
S. Ranise and C. Tinelli.  The Satisfiability Modulo Theories Library (SMT-LIB), 2006.
http://www.smtcomp.org.
H. Rueß and N. Shankar. Deconstructing Shostak. In LICS ’01: Proceedings of the 16th Annual IEEE Symposium on Logic in Computer Science, page 19, Washington, DC, USA, 2001. IEEE Computer Society.
R. E. Shostak. Deciding combinations of theories. J. ACM, 31:1–12, 1984.

Soundness Proof of CC(X)
We now proceed to prove the soundness of the algorithm. Let E be a set of equations between terms of T (Σ) and X a theory in the sense of Definition 2.1. For the proof, we need an additional information about the run of an algo- rithm, that is not contained in a configuration: the set O of equations that have already been treated in a Congr rule.
The first proposition shows that the equations that are already treated are never contradicted by Δ.
Proposition A.1 For any configuration  ⟨ Θ | Γ | Δ | Φ ⟩ and for all
t1, t2 ∈ T (Σ) we have: t1 = t2 ∈ O ⇒ Δ[t1] ≡ Δ[t2].
The next proposition shows that Δ coincides with the function iter, applied to the equations that have already been treated.
Proposition A.2 For any configuration  ⟨ Θ | Γ | Δ | Φ ⟩ and for all
t ∈ T (Σ) we have: Δ[t]= iter([O] , [t]).
The next proposition states that the evolution of the representative of a term is always justified by the equations that have been treated:
Proposition A.3 For any configuration  ⟨ Θ | Γ | Δ | Φ ⟩ and for all
t ∈ T (Σ) we have: [O] |= Δ0[t]= Δ[t].

This is the main lemma: It basically states the soundness of Δ, crucial for the soundness of the whole algorithm.
Lemma A.4 For any configuration ⟨ Θ | Γ | Δ | Φ ⟩ and for all t1, t2 ∈ T (Σ), we have:
Δ[t1] ≡ Δ[t2] ⇒ t1 =X,O t2.
We are now ready to state the main soundness theorem: whenever two terms have the same representative, they are equal w.r.t. the equational theory defined E and X, and every newly added equation is sound as well. For the soundness of the algorithm, we are only interested in the first statement, but we need the second to prove the first, and the statements have to be proved in parallel by induction.
Theorem A.5 For any configuration ⟨ Θ | Γ | Δ | Φ ⟩, we have:
∀t1, t2 ∈ T (Σ) :  Δ[t1] ≡ Δ[t2] ⇒ t1 =X,E t2
∀t1, t2 ∈ T (Σ) :   t1 = t2 ∈ Φ ⇒ t1 =X,E t2.


Proof. We prove the two claims simultaneously by induction on the applica- tion of the rules Congr,Remove, Add and Query. First, we observe that both claims are true for the initial configuration K0: The second claim is trivial as Φ= E, and the first claim is true because of proposition 2.8.
In the induction step, consider the last rule applied to the configuration
⟨ Θ | Γ | Δ | Φ ⟩, and show that the claims still hold in the configuration obtained by application of that rule. For the rules Remove and Query this is actually trivial, as Δ does not change and Φ does not get any new equalities added. For the rule Add, the first claim is trivial, as Δ remains unchanged. The second claim is established as follows. If t1 = t2 ∈ Φ,we can conclude by induction hypothesis. If t1 = t2 ∈ Φ', then t1 ≡ f (→a) and t2 ≡ f (→b), for f with arity n. The conditions in figure 1 guarantee that Δ[→a] ≡ Δ[→b]. By the first claim, we can state that ai =X,E bi (1 ≤ i ≤ n) and by the congruence

property of =

X,E
we have f (→a) =X,E
f (→b), which proves the second claim.

We finally assume that the last rule applied was a Congr rule. To prove the first claim, we assume Δ'[t1] ≡ Δ'[t2]. By lemma A.4, we have t1 =X,O,a=b t2. Now, a = b is obviously an element of the set {a = b}∪ Φ, so that, by induction hypothesis, a =X,E b. By the induction hypothesis and proposition A.1, for any ai = bi ∈ O we have also ai =X,E bi. As =X,E is a congruence relation, we can conclude t1 =X,E t2. The second claim can be proved as in the case of the Add rule, by the aid of the first claim.	 

Completeness Proof of CC(X)
We finally proceed to the completeness of the algorithm. In opposition to the correctness proof, we are now interested in the fact that every possible equation on the terms of the problem can be deduced by the algorithm, and in particular we are interested in its termination.
Termination and congruence closure of Δ

In the following, we assume the set E and the query a =?
b are fixed and we

denote the successive configurations by ⟨ Θn | Γn | Δn | Φn ⟩ with n = 0 the initial configuration (as defined in Section 2.2). Let TΠ be the set of terms and

subterms that appear in E; a =?
b, in particular, TΠ is closed by subterm. At

any stage n in the algorithm, we write On for the set of equations that have been treated by the algorithm so far through the rule Congr.
The first property we are interested in is the fact that all the equations inferred, and thus all the terms added, are only using terms from TΠ.
Proposition B.1 For any n, Im(Γn) ⊆ TΠ, Φn ⊆ TΠ × TΠ and Θn ⊆ TΠ.
Theorem B.2 (Termination) The algorithm terminates on any input prob- lem Π.
Proof. To prove that this system terminates, it is sufficient to consider the measure defined as (|TΠ \ Θn|, |Δn/ ≡| , |Φn|), where the second component represents the number of equivalence classes over TΠ in Δn. In particular, Proposition B.1 ensures that all the terms added are in TΠ, and thus that the first component of the measure decreases through the rule Add.

Now, we know there exists a final configuration, for n = ω. At this stage, all the equations from the original problem have been treated, and every term in TΠ has been encountered :
Proposition B.3 Oω ⊇ E.
Corollary B.4 At the end of the algorithm, Θω = TΠ.
Proposition B.5 The function n '→ Γn is nondecreasing, i.e.	Γn(r) ⊆
Γn+1(r) for all r and n.
The following proposition gives the true “meaning” of the map Γn. It shows that a term in Θn uses all the leaves of the representatives of its direct subterms.
Proposition B.6 For any term f (t1,... , tm) in Θn, if there exists i ≤ m
such that p ∈ leaves(Δn[ti]), then f (t1,... , tn) ∈ Γn(p).

Proof. The proof proceeds by induction on n. The result holds trivially for the initial configuration since Θ0 is empty. If the result holds after n steps, we proceed by case analysis on the rule used to get to the n + 1-th step. The rules Remove, Query do not change Θn, Γn or Δn, so if one of these rules is used the result still holds at n + 1. We detail both remaining rules :

Congr:
Let f (t1,... , tm) ∈ Θn+1 = Θn, and i and p such that p  ∈

leaves(Δn+1[ti]). If (v, R) is the substitution applied, by definition of Δn+1,
p ∈ leaves(Δn[ti]{v '→ R}). Now, we distinguish two cases :
if p  ∈ leaves(Δn[ti]), then by induction hypothesis, we know that
f (t1,... , tn) ∈ Γn(p), and thus f (t1,... , tn) ∈ Γn+1(p) by B.5.
if p ∈/ leaves(Δn[ti]), then Δn[ti] has been changed by the substitution
and the axiom 2.6 tells us that v ∈ leaves(Δn[ti]) and p ∈ leaves(R). Therefore, by applying the induction hypothesis to v and the definition of Γn+1, we can conclude that :
f (t1,... , tn) ∈ Γn(v) ⊆ Γn(p) ∪ Γn(v)= Γn+1(p)

Add:
If f (t1,... , tm) was already in Θn, then it is straightforward to check

that for all p ∈ leaves(Δn+1([ti])), p was already in Δn[ti] and the induction
hypothesis together with the monotonicity of Γn gives us the wanted result.
If f (t1,... , tm) is in fact the new term f (→a) added by the rule, then let p ∈ leaves(Δn+1[ti]). Again, p was already in Δn[ti] and since ti is a direct subterm of the new added term f (→a), we have by definition that f (→a) ∈ Γn+1(p)= Γn(p) ∪ {f (→a)}.	 

The next proposition is the central property ensuring the completeness of the algorithm, and states that Δω indeed represents a congruence relation.
Proposition B.7 The restriction of Δω to TΠ is congruence-closed, i.e.
∀f (→a),f (→b) ∈ TΠ, Δω[→a] ≡ Δω[→b] ⇒ Δω[f (→a)] ≡ Δω[f (→b)].
Proof. Let k the smallest integer such that both f (→a) and f (→b) belong to Θk. Because terms can only be added to Θ by the rule Add, we know the rule applied at the previous step was Add. We can safely assume the term added was f (→a), by switching →a and →b if necessary. If f (→a) and f (→b) are equal, the result is obvious. Otherwise, f (→a) /= f (→b) and f (→b) had been added before and was in Θk−1. Now there are two cases, depending on whether Δk−1[→a] ≡ Δk−1[→b] or not.
if Δk−1[→a] ≡ Δk−1[→b], we will prove that f (→a)= f (→b) has been added to Φk, that is to say we need to establish that : ∀i, ∀l ∈ leaves(Δk−1[ai]),f (→b) ∈ Γk−1(l). For any such i and l, we know that l is in leaves(Δk−1[ai]), and therefore in leaves(Δk−1[bi]). By Proposition B.6, this means that f (→b) ∈

Γk−1(l), which is exactly what we wanted.
if on the contrary, [→a] and [→b] were not equal in Δk−1, then let j ≥ k be the smallest integer such that Δj[→a] ≡ Δj[→b]. The rule applied at the previous

step must be
Congr since only
Congr changes Δ. Thus, a substitution

{p '→ P } has made Δj−1[→a] and Δj−1[→b] equal: there exists an i, such that
Δj−1[ai] /≡ Δj−1[bi] ∧ Δj−1[ai]{p '→ P }≡ Δj−1[bi]{p '→ P }.
This means that at least one of these values, say Δj−1[ai], has been changed by the substitution and by Axiom 2.6, that p ∈ leaves(Δj−1[ai]). Proposi- tion B.6 ensures that f (→a) ∈ Γj−1(p).
We still have to prove that f (→b) verifies the conditions in the rule Congr,

namely that f (→b) ∈ Γj−1(p)∪	t|p∈leaves(Δ
we distinguish two cases :


j−1
(t))  l∈leaves(Δj (t)) Γj−1(l). Again,

if Δj−1[bi] /≡ Δj[bi], then by the same argument as above for f (→a), f (→b) ∈
Γj−1(p) and f (→b) has the desired property.
if Δj−1[bi] ≡ Δj[bi], then leaves(Δj[ai]) = leaves(Δj[bi]) = leaves(Δj−1[bi]) and by applying Proposition B.6 once again, we de- duce that for every l in leaves(Δj[ai]), f (→b) ∈ Γj−1(l).  Since p ∈
leaves(Δj−1[ai]), this means indeed that :
f (→b) ∈ t|p∈leaves(Δ	(t))  l∈leaves(Δ (t)) Γj−1(l).
j−1	j
So far, we have established that the equation f (→a) = f (→b) has been added when the rule Congr was applied at the step j −1, and thus that f (→a)= f (→b) belongs to Φj. At the end of the algorithm, this equation must have been treated. Thus, by A.1, we know that the representatives of f (→a) and (→b) are equal in Δω.

The axioms 2.9 and 2.10 introduced in Section 2.1 are used to prove that the Δω component of the final configuration is coherent with the theory X, that is to say :
Proposition B.8 Let f (t1,... , tn) a term in TΠ where f is an interpreted
symbol. Then, Δω[f (t ,...,t )] ≡ f X(Δ [t ],... , Δ [t ]).
1	n	ω  1	ω  n
Proof. We will prove this result by proving it (by simple induction) for Δn
for every N between 0 and the final configuration.
First, we observe that the result is true for the initial configuration, ie.

Δ [f (t ,... ,t )] ≡ f X(Δ [t ],... , Δ [t
]) because it directly follows from Ax-

0	1	m	0 1	0 m
iom 2.9 and the definition of Δ0.
Now, it is sufficient to show that if the equality holds for Δn, it still holds in Δn+1. Since the only rule that changes Δn where it is already defined is

Congr, the result is obvious for any other rule. In the case of a Congr rule, let p, P be the substitution applied to Δn :
Δn+1[f (t1,... , tm)] = Δn[f (t1,... , tm)]{p '→ P } by definition
≡ f X(Δn[t1],... , Δn[tm]){p '→ P } by induction
≡ f X(Δn[t1]{p '→ P },... , Δn[tm]{p '→ P }) by 2.10
≡ f X(Δn+1[t1],... , Δn+1[tm]) by definition
which proves the result.	 
In other words, this property means that Δ actually represents a union- find structure modulo X, that is, it behaves correctly with respect to the interpreted symbols.
Completeness
The completeness expresses the fact that if the query is entailed by the set of equations E and the theory X, it is proved true by CC(X). In other words, using standard model-theoretic notations, we need to prove that:
E, =X |= a = b  ⇒  Δω[a] ≡ Δω[b].
The first step of the proof is to build a Σ-structure M which models E and =X , and such that the interpretation in M coincides with Δω on [a] and [b].
Definition B.9 Let M be the structure defined in the following way :
the domain of M is the set R of semantic values
for each symbol f ∈ Σ of arity n, we distinguish whether f is interpreted in X or not :
if f ∈ ΣX, then f M def f X
if f ∈/ ΣX, and r1,... , rn ∈ R, then the idea is to use Δω wherever we can
:
f M(r ,...,r )	def	Δ [f (t ,...,t )]	if f (t ,...,t ) ∈ T

1	n	=	ω	1	n
1	n	Π


f M(r ,...,r )	def
and ∀i, ri ≡ Δω[ti],
1	otherwise.

1	n	=
Here, we use 1, but we could use any element in R, since we will see that it does not matter how we define interpretations in this case.
Proof. The very first thing we have to do is to prove that the definition we just gave is indeed a definition. In the case where f M is defined in terms of Δω, there may be several ways to pick the terms ti and we have to show that the result does not depend on this choice. Let t1,... , tn, u1,... , un be terms

such that Δω[ti] ≡ ri ≡ Δω[ui] for all i. By Proposition B.7, we know that Δω[f (t1,... , tn)] ≡ Δω[f (u1,... , un)], which means exactly that the definition of f M(r1,... , rn) does not depend on the choice of the ti.	 
Now that M is a well-defined Σ-structure, we will first show that on all the terms in TΠ, the interpretation in M is exactly the function Δω[.].
Lemma B.10 For any term t ∈ TΠ, M(t) ≡ Δω[t].
Proof. We proceed by structural induction on terms.
Let t = f (t1,... , tn) ∈ TΠ, we can apply the induction hypothesis to all the ti because TΠ is closed by subterm. Thus, for all i, M(ti) ≡ Δω[ti].
Now, if f /∈ ΣX,
M(f (t1,... , tn)) = f M(M(t1),... , M(tn))
≡ f M(Δω[t1],... , Δω[tn]) by IH
≡ Δω[f (t1,... , tn)] by definition of f M for f ∈/ ΣX
If f ∈ ΣX, then
M(f (t1,... , tn)) = f M(M(t1),... , M(tn))
≡ f M(Δω[t1],... , Δω[tn]) by IH
≡ f X(Δω[t ],... , Δ [t ]) by definition of f M
≡ Δω[f (t1,... , tn)]	by B.8 since f (t1,... , tn) ∈ TΠ
which concludes the proof.	 
Finally, we show that M is a model of =X and E.
Lemma B.11 M |= E, =X
Proof. Since M is a structure whose domain R is the domain of semantic values of X, and since the interpretation in M of every interpreted symbol f
is precisely its interpretation in X, namely f X, M is a model of = .
Moreover, let t = u be an equation in E. Since t and u are in TΠ, the preceding lemma tells us that M(t) ≡ Δω[t] and M(u) ≡ Δω[u]. By propo- sition B.3, we know that since t = u is in E, it has been treated at the end and Δω[t] ≡ Δω[u]. Thus, M(t) ≡ M(u) for any equation t = u in E, and M |= E.	 
Theorem B.12 (Completeness) E, =X |= a = b ⇒ Δω[a] ≡ Δω[b].
Proof. By lemma B.11, M is a model of E and  =X  .  Therefore, since E, =X |= a = b, it must be the case that M is also a model of a = b, in other words, that M(a) ≡ M(b). Hence, by lemma B.10, Δω[a] ≡ Δω[b].	 
