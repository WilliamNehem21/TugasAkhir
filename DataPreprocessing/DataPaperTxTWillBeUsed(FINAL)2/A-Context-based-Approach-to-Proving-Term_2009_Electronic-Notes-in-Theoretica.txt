

Electronic Notes in Theoretical Computer Science 249 (2009) 169–192
www.elsevier.com/locate/entcs
A Context-based Approach
to Proving Termination of Evaluation
Ma-lgorzata Biernacka 1  Dariusz Biernacki 2
Institute of Computer Science University of Wrocl-aw
Wroc-law, Poland

Abstract
We present a context-based approach to proving termination of evaluation in reduction semantics (i.e., a form of operational semantics with explicit representation of reduction contexts), using Tait-style reducibility predicates defined on both terms and contexts. We consider the simply typed lambda calculus as well as its extension with abortive control operators for first-class continuations under the call-by-value and the
call-by-name evaluation strategies. For each of the proofs we present its computational content that takes the form of an evaluator in continuation-passing style and is an instance of normalization by evaluation.
Keywords: reduction semantics, evaluation context, weak head normalization, control operators, normalization by evaluation


Introduction
In the term-rewriting setting, a typical presentation of the lambda calculus as a prototypical programming language relies on the grammar of terms and a reduction relation defined on these terms. Felleisen et al. have introduced the notion of reduc- tion/evaluation contexts [15–17] that proved useful in expressing various reduction strategies concisely, building on the notion of context as a term with a hole [2]. Felleisen’s contexts represent “the surrounding term” of the current subterm, or “the rest of the computation”, and they directly correspond to continuations: the latter can be seen as functional representations of contexts. More precisely, Danvy ob- served that reduction contexts arise as defunctionalized continuations of a one-step reduction function whereas evaluation contexts arise as defunctionalized continua- tions of an evaluation function (i.e., big-step) [11, 12]. Since these defunctionalized representations of continuations are in both cases the same, the terms “evaluation

1 Email: mabi@ii.uni.wroc.pl
2 Email: dabi@ii.uni.wroc.pl

1571-0661 © 2009 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2009.07.090

context” and “reduction context” are usually used interchangeably, and we will adhere to this practice in the remainder of this article.
Because of their close relation to continuations, the benefits of using contexts can be seen perhaps most prominently in languages with control operators, i.e., syntactic constructs that manipulate the current continuation/context [15]. More- over, as shown by Wright and Felleisen [27], context-based reduction semantics of a programming language provide a convenient formalism for expressing and proving type soundness properties.
In this article we present yet another application of contexts: we give novel proofs of termination of evaluation in the simply typed lambda calculus under the call-by-value and call-by-name reduction strategies where reduction contexts play a major role. Subsequently we extend the simply typed lambda calculus with common
abortive control operators: callcc, abort and Felleisen’s C and we use the same
approach as for the pure lambda calculus to prove termination for the extended language, using its standard context-based reduction semantics.
The method of proof we apply in this work—using context-based variant of Tait- style reducibility predicates [25]—is a modification of the method considered in a previous work of Biernacka et al. that used “direct-style” reducibility predicates [9]. In effect, we obtain direct, simple proofs of termination that take advantage of the context-based formulation of the reduction semantics. In contrast, many of the existing proofs of normalization properties for typed lambda calculi with control operators are indirect and they use a translation to another language already known to be normalizable [1, 18, 24]. This line of work on proof-theoretic properties of typed control operators was originated by Griffin who gave a type assignment to
Felleisen’s C operator, abort and callcc, and who proved termination of evaluation
for his language using a translation to the simply typed lambda calculus akin to Plotkin’s colon translation [18].
On the other hand, the method of proving normalization using Tait-style re- ducibility predicates has been applied to the pure lambda calculus, both for weak and strong normalization [5,25,26] as well as for weak head normalization under call by name (essentially due to Martin-Lo¨f) and call by value (due to Hoffmann) [9]. An extension to control operators has been considered by Parigot who modified Girard’s reducibility candidates to prove strong normalization for his second-order λμ-calculus corresponding to classical natural deduction [21]. Berger and Schwicht- enberg identified the computational content of their constructive proof of strong normalization that uses the reducibility method to be an instance of normalization by evaluation, and subsequently this observation has been applied to proofs of weak head normalization by Coquand and Dybjer for combinatory logic [10] and by Bier- nacka et al. for the lambda calculus [9]. Some of the proofs have been formalized in proof assistants and normalizers have been extracted from them in the form of func- tional programs [4, 6]. Not surprisingly, the computational content of our proofs are instances of normalization by evaluation; the extracted programs are evaluators in continuation-passing style, whose continuations arise by extraction from a context reducibility predicate. Thus the present article provides a logical confirmation of

the connection between continuations and contexts, previously observed and inves- tigated by Danvy [11, 12].

The simply typed lambda calculus
In this section we present two proofs of weak head normalization for the simply typed lambda calculus using context-based reducibility predicates a` la Tait. We consider closed terms and two strategies: call by value (i.e., applicative order) and call by name (i.e., normal order). Contrary to previous work, we use a different formulation of logical predicates: instead of a type-indexed family of reducibility predicates on terms, we define two such families: one for terms and one for eval- uation contexts. This formulation relies on the fact that we define programs as pairs consisting of a term and an evaluation context, and evaluation contexts are part of the syntax of the language. The specificity of this approach is that the definition of reducibility predicates differs for each evaluation strategy. The proofs themselves seem to be even easier to carry out than the proofs using the standard reducibility predicates. Finally, an—expected—consequence of this approach is that the computational content of the proofs (i.e., the extracted program) are evalua- tors in continuation-passing style. These CPS evaluators can be otherwise obtained by CPS-translating the evaluators extracted from the standard proofs (in both the call-by-value and call-by-name strategies).

Terms: syntax and typing
We introduce terms and reduction contexts as two syntactic categories, where the syntax of terms is standard:
(terms) t ::= x | λx.t | tt 
and the syntax of reduction contexts depends on the strategy we choose for reduction (in fact, the grammar of reduction contexts reflects the reduction strategy). Because of that, we postpone the actual definitions of reduction contexts for call by value and call by name to Section 2.2 and Section 2.3, respectively.
We define the set of free and bound variables in a term in the usual way, and we distinguish closed terms, i.e., terms with no free variables. As is also standard, we identify terms that differ only in the names of their bound variables.
Next, we define a typing relation for terms, again in the standard way. Types are either base types, or arrow types:
(types) A ::= b | A → A
and the typing relation on terms is given by the following inference system, where Γ is the usual typing environment associating free variables with their types:
Γ, x : A ▶ t : B
Γ, x : A ▶ x : A	Γ ▶ λx.t : A → B

Γ ▶ t0 : A → B	Γ ▶ t1 : A Γ ▶ t0 t1 : B
The call-by-value reduction strategy
Contexts
Given the grammar and the typing of terms from Section 2.1, we now define call- by-value reduction contexts as follows:
(CBV contexts) E ::= • | v E | E t
(values)	v ::= λx.t
where values form a subcategory of terms and are used to denote normal forms.
Contexts are part of the syntax and not just a metarepresentation of “terms with a hole”. They are represented inside-out, i.e.: • represents the empty context, v E represents the “term with a hole” E[v [ ]] (in an informal notation), and E t represents the “term with a hole” E[[ ] t]. We say a reduction context is closed, if its constituent terms are all closed.
In order to formalize the meaning of contexts, we define the function plug map- ping a term and a context to the term such a pair represents:
plug (t, •) = t
plug (t, v E) = plug (v t, E)
plug (t0, E t1) = plug (t0 t1, E)
We write the result of plugging the term t in the context E in the usual way: E[t].
Given the grammar of terms and contexts, we now define a program in the call-by-value language as a pair of a term and a call-by-value reduction context:
(programs) p ::= ⟨t, E⟩
The program ⟨t, E⟩ represents the term obtained by plugging the term t into the context E, i.e., the term E[t]. This representation allows us to represent all lambda terms (and only lambda terms) in such a way that we explicitly state the “boundary” of a program (or, top level); note that we do not have a way to compose programs, so we cannot obtain a bigger program by plugging one program into another reduction context—which is possible if we treat terms as programs in the usual way. While this choice of representation does not matter for the pure lambda calculus, it will play a significant role later on, when we extend the language with abortive control operators (cf. Section 3).
Of course, according to the definition of program, various pairs of a term and a context can represent the same “plugged term”, i.e., the application of the function plug to different pairs may give the same lambda term as a result. From the point of
view of computation, all such pairs will be regarded as various representations of the same program. Therefore, from now on, we will consider programs as abstraction classes of the equivalence relation between well-typed pairs defined as follows:
⟨t0, E0⟩∼ ⟨t1, E1⟩ := E0[t0] = E1[t1]

where the equality on the right-hand side denotes syntactic equality modulo alpha renaming. For example, the program ⟨(λx.r) s, •⟩ can be otherwise represented by another program ⟨λx.r, (• s)⟩ or by ⟨s, ((λx.r) •)⟩. All these representations correspond to different decompositions of the same term.
Next, we introduce a typing relation on reduction contexts in a way consistent with the standard typing of lambda terms.
Types of contexts are defined using the following syntax:
(context types) T ::= cont A
and the typing relation on contexts is defined by the following inference system:
Γ ▶ t : A	Γ ▶ E : cont B
Γ ▶ • : cont A	Γ ▶ E t : cont (A → B)

Γ ▶ v : A → B	Γ ▶ E : B Γ ▶ v E : cont A
It is not difficult to see that function plug ensures and preserves well-typedness of terms in the way formalized by the following lemma.
Lemma 2.1 The following hold:
If Γ ▶ t : A and Γ ▶ E : cont A, then there exists a type B such that
Γ ▶ E[t] : B.
If Γ ▶ E[t] : B, then Γ ▶ t : A and Γ ▶ E : cont A for some type A.
Proof. The proof is done by induction on the structure of E.	 
The type of the program ⟨t, E⟩ can naturally be defined to be the type of the term E[t]; the following rule for typing programs is well defined (it does not depend on the choice of a particular pair from an abstraction class):
Γ ▶ E[t] : A
Γ ▶ ⟨t, E⟩ : A
The type cont A could be interpreted as in Griffin’s work [18], i.e., as ¬A (A → ⊥), if we included ⊥ in the grammar of types (interpreted as formulas through the Curry-Howard isomorphism [20]). However, according to the above rule, ⊥ would play no role in typing programs.
Finally, we observe that the class of well-typed programs defines exactly the set of simply typed lambda terms.
Reduction
The grammar of contexts defined in the previous subsection determines the call-by- value reduction strategy for evaluation. We define a one-step reduction relation on programs as follows:
⟨(λx.r) v, E⟩ →v ⟨r{v/x}, E⟩

where v is a value and the notation r{v/x} stands for the usual metaoperation of capture-avoiding substitution of v for variable x in r. Terms of the form (λx.r) v are the familiar call-by-value β-redexes.
Thanks to the unique-decomposition property of the lambda calculus under call by value, the relation →v is deterministic and it is a function on abstraction classes.
Property 1 (Unique decomposition (CBV)) For all terms t, t either is a value, or it decomposes uniquely into a CBV reduction context E and a redex 3 r, i.e., t = E[r].
Next, we define the evaluation relation as the reflexive-transitive closure of one- step reduction (→∗). The result of the evaluation is a (program) value of the form
pv := ⟨v, •⟩.
It is easy to see that there is an exact correspondence between reductions of programs in this sense and reductions of terms in the usual sense, according to the following lemma.
Lemma 2.2 For each program p := ⟨t, E⟩, p reduces to another program p' :=
⟨t', E'⟩ if and only if the simply typed lambda term E[t] reduces to the term E'[t']
under the standard CBV reduction strategy.
The reduction relation preserves types of programs, because of the subject re- duction property for simply typed lambda terms: the type of a β-redex is preserved after the reduction.
Corollary 2.3 (Progress and Preservation) For each program p, p either is a value or it reduces uniquely to another program p' such that if Γ ▶ p : A, then Γ ▶ p' : A.
Termination
We now give a proof of termination for call-by-value evaluation that uses logical predicates in the style of Tait but based on contexts as well as on terms rather than on terms only. From now on, for simplicity, we only consider closed programs, although the method generalizes to open well-typed terms.
We first introduce two mutually inductive logical predicates: RA is defined on closed values of type A, and Ccont A is defined on closed contexts of type cont A as follows:
Rb(v) := True
RA→B(v0) := ∀v1. RA(v1) → ∀E. Ccont B(E) → N (⟨v0 v1, E⟩)




where
Ccont A(E) := ∀v. RA(v) → N (⟨v, E⟩)

N (p) := ∃v. p →∗ ⟨v, •⟩



3 More precisely, a decomposition is in general a context and a potential redex, i.e., a proper redex that can be contracted, or a “stuck” term. We ignore this issue here, since the languages considered in this article do not contain stuck terms.

In the standard approach, the reducibility predicate on well-typed terms ex- presses the property that whenever a reducible term is applied to another reducible term of the right type, the resulting term has also this property. Moreover, if a term is reducible, then it normalizes. The proof of termination consists in showing that all well-typed terms are reducible, from which it follows that all well-typed terms normalize.
Here, we prove normalization using a modified version of the reducibility pred- icate, noted RA. First of all, we only need to define this property on well-typed values (we could extend it to all well-typed terms, but it is not necessary for the proof). A reducible value is such that, when applied to another reducible value,
and paired with a reducible context, normalizes as a program. Simultaneously, we define a reducibility predicate on well-typed reduction contexts, Ccont A, saying that any reducible value in a reducible context normalizes as a program. The typing
properties ensure that the programs occurring in the definitions of the predicates are all well typed, but we do not need to know their type in order to prove the normalization theorem.
Lemma 2.4 Let t be a well-typed term such that x1 : B1,..., xn : Bn ▶ t : A. Next, let →v be a sequence of closed well-typed value terms such that ▶ vi : Bi and RBi (vi) for 1 ≤ i ≤ n. Then for all closed well-typed reduction contexts E such that ▶ E : cont A and Ccont A(E), the program ⟨t{→v/→x}, E⟩ normalizes, i.e., N (⟨t{→v/→x}, E⟩) holds. (Notation t{→v/→x} stands for the simultaneous substitution of each value term vi for the free variable xi in t.)
Proof. The proof is done by induction on the structure of t.
Case x. By assumption x is one of the variables xi and t{→v/→x} = vi. Hence, by assumption RA(vi) and for any E such that Ccont A(E) holds, unfolding the definition of Ccont A entails that N (⟨vi, E⟩) holds.
Case λx.r. Because λx.r is well typed, its type A must be an arrow type; let A = A' → A''. Taking r' = r{→v/→x}, we have (λx.r){→v/→x} = λx.r'. We will show that RA(λx.r') holds, and from this fact it follows that the required N (⟨(λx.r){→v/→x}, E⟩) holds as in the previous case. In order to prove RA(λx.r'), let us assume that v is a value of type A' and such that RA' (v) holds. Next, let E be a well-typed context of type A'' and such that Ccont A'' (E) holds. We have to prove that N (⟨( λx.r')v, E⟩) holds. By the reduction rule, ⟨(λx.r') v, E⟩ reduces in one step to program ⟨r{→v/→x, v/x}, E⟩. By induction hypothesis, N (⟨r{→v/→x, v/x}, E⟩) holds and hence also N (⟨(λx.r') v, E⟩) holds.
Case t0 t1. Since t0 t1 is well typed, then x1 : B1,..., xn : Bn ▶ t0 : C → A
and x1 : B1,..., xn : Bn ▶ t1 : C for some type C. Taking t' = t0{→v/→x} and
t' = t1{→v/→x}, we have (t0 t1){→v/→x} = t' t' . By definition, the program ⟨t' t' , E⟩ is
1	0 1	0 1
the same as the program represented by ⟨t' , E t' ⟩. Since t0 is a subterm of t0 t1,
0	1
we can apply the induction hypothesis to deduce N (⟨t' , E t' ⟩) provided that E t'
0	1	1
is well typed and that Ccont (C→A)(E t' ) holds. The former is easy to see, and for the latter let us unfold the definition of Ccont (C→A). Let v be a value of type
C → A and such that RC→A(v) holds. We need to show that N (⟨v, E t' ⟩) holds.

Here again we can use another representative of the class of programs equal to
⟨v, E t' ⟩, such as ⟨t' ,v E⟩. Now we can apply the induction hypothesis again, this
1	1
time for t1, provided that v E is well typed and Ccont C(v E) holds. And again, the
former property is easy to see, and for the latter we again unfold the definition of Ccont C: let v' be a value of type C and such that RC(v') holds. We now need to show that N (⟨v',v E⟩) holds. But this is equivalent to showing that N (⟨v v', E⟩) holds, and this property follows from the fact that RC→A(v) holds by an earlier assumption.


Theorem 2.5 (Termination of CBV evaluation) If t is a closed well-typed term, then N (⟨t, •⟩) holds.

Proof. It is straightforward to see that the empty context satisfies Ccont A for any type A. From Lemma 2.4 it follows that if we take a closed well-typed term t and put it in the empty context, then the resulting program evaluates to a value program.	 

It follows that all closed well-typed terms evaluate to a value in the standard sense.

Extracted evaluator
The specification of the normalization problem and the proof of Theorem 2.5 can be formalized in a number of ways and its computational content can be extracted in the form of a lambda term that can be interpreted as an evaluator for the object language [3–6, 9]. In this work, our interest lies not in completely formalizing the problem—it can easily be done, e.g., along the lines of the work cited above—but in showing another way of proving normalization using a context-based approach. Therefore we conduct the development on an informal level and we only outline the program that can be extracted from the proof of Theorem 2.5. The basic idea of program extraction relies on the Curry-Howard correspondence between proofs and programs: roughly, we can view the proof of Theorem 2.5 as a lambda term (the proof is constructive). In this proof term, some parts represent logical inferences and some parts can be seen as computations (here, these computations serve to build the normal form of a given term). Erasing the logical parts, we obtain a lambda term that only contains computationally relevant parts of the original proof, and it is this term that we call the “extracted” program—in our case, an evaluator, i.e., a program computing weak head normal forms of lambda terms. This is essentially what the modified realizability interpretation does to a proof term to extract its computational content [3, 9].
If we apply this method of extraction to the proof term for Theorem 2.5, we obtain a program that normalizes simply-typed lambda terms into values according to the call-by-value strategy. The program extracted from the proof of Lemma 2.4

is in continuation-passing style and its structure is the following:
eval→x xi	= λ→v→uκ.κ vi ui
eval→x λx.t = λ→v→uκ.κ ((λx.t){→v/→x}) (λvuκ.eval→xx t (→vv) (→uu) κ)
eval→x t0 t1 = λ→v→uκ.eval→x t0 →v→u (λv0u0.eval→x t1 →v→u (λv1u1.u0 v1u1 κ))
The evaluator is parameterized by the vector of free variables occurring in a term (→x) and it uses two environments: one (→v) containing values to be substituted for the free variables →x in the evaluated term, and one (→u) containing functions (these functions arise as the computational content of the relations RA for appropriate
A). The substitutions are needed in the final step of computation when we have to return a value as a closed term—this is the only place where the first environment plays a role. But whenever a lambda abstraction in the object language is applied to a value, instead of substitution, we apply the suitable function from the second environment and evaluate the body of the lambda abstraction with the given ar- gument. (Note that apart from supplying the argument as a syntactic value, the function evaluating the body of an abstraction expects another function that knows how to evaluate the body of the supplied argument—a value—in case it becomes applied in the future.) Therefore, this evaluator is an instance of normalization by evaluation—normalization (reduction) in the source language is done by evaluation on the metalevel.
Continuations (κ) in the evaluator arise as the computational content of the relations Ccont A for appropriate A. The syntactic representations of contexts we used in the proof can be optimized away (i.e., simply erased) since they do not play any role in the evaluator. This optimization is not arbitrary—it is prov- ably correct and it corresponds to Berger’s optimization to eliminate unused object variables, based on distinguishing between computationally relevant and irrelevant variables [3]. Without this optimization, the extracted evaluator would thread an additional argument—the context—which is never used. 4
The function eval is the computational content of the proof of Lemma 2.4. In the proof of Theorem 2.5, we apply Lemma 2.4 with the empty sequence of values and with the empty context to obtain the proof of N (⟨t, •⟩). Thus the program extracted from the proof of the fact Ccont A(•) is the initial continuation with which we activate the eval function. It is easy to observe that this initial continuation is the function λvu.v; as expected, this initial continuation immediately returns the value it is passed as argument (here, it is also passed a function associated with the value which is ignored).
The complete evaluator therefore can be written as follows:
norm t = evalє t ϵϵκinit
where κinit = λvu.v and ϵ denotes the empty sequence.
According to the normalization-by-evaluation nomenclature, the eval function “reflects” object-level terms at the metalevel (as functions accepting two environ-

4 In contrast, the representations of contexts are essential in the evaluators for control operators presented in Section 3.

ments and a continuation) and the application to the initial (empty) environments and the initial continuation is the “reification” of metaobjects at the object level.
The evaluator extracted from the proof is in continuation-passing style, i.e., all computations are sequentialized and their intermediate results are named. In this case, the order of evaluation imposed by using continuations is call by value.

The call-by-name reduction strategy
The development for the call-by-name reduction strategy is done along the same lines as the one for call by value, modulo necessary adjustments. In this subsection, we only give a brief account of call by name, pinpointing the main differences with the previous subsection.

Syntax and typing
The terms are the same as in call by value, but reduction contexts have to be defined differently:
(CBN contexts) E ::= • | E t
In call by name, we do not have the context v E and so the plug function has fewer cases. The typing relation for CBN contexts is a subset of the inference rules for CBV contexts.
The notion of program and its typing are defined as in the CBV case, using the equivalence relation on pairs of terms and CBN contexts. All the typing properties stated in Section 2.2.1 hold for call by name as well.

Reduction and termination
The one-step reduction relation for the call-by-name strategy differs in that a lambda abstraction can be applied to an arbitrary term instead of to a value:
⟨(λx.r) t, E⟩ →n ⟨r{t/x}, E⟩
All the above adjustments are standard and the properties analogous to those of Section 2.2.2 hold for call-by-name as well. Next we need to define the logical relations needed for the proof of termination for the call-by-name case:
Rb(v) := True
RA→B(v) := ∀t. QA(t) → QB(v t)
QA(t) := ∀E. Ccont A(E) → N (⟨t, E⟩)
Ccont A(E) := ∀v. RA(v) → N (⟨v, E⟩)
where
N (p) := ∃v. p →∗ ⟨v, •⟩
Here, we also define two main logical predicates: RA on closed values of type A
and Ccont A on closed contexts of type cont A. The auxiliary predicate QA is defined

on closed terms of type A and it expresses the property that a term in any context satisfying Ccont A normalizes (as a program).
We are now ready to state the main result of this section.

Lemma 2.6 Let t be a well-typed term such that x1 : B1,..., xn : Bn ▶ t : A. Next, let →t be a sequence of closed well-typed terms such that ▶ ti : Bi and QBi (ti) for 1 ≤ i ≤ n. Then for all closed well-typed reduction contexts E such that ▶ E : contA and Ccont A(E), the program ⟨t{→t/→x}, E⟩ normalizes, i.e., N (⟨t{→t/→x}, E⟩) holds.

Proof. The proof is done by induction on the structure of t.
Case x. By assumption x is one of the variables xi and t{→t/→x} = ti. Hence, by as- sumption QA(ti) and for any E such that Ccont A(E) holds, unfolding the definition of QA(ti) entails that N (⟨ti, E⟩) holds.
Case λx.r. Because λx.r is well typed, its type A must be an arrow type; let A = A' → A''. Taking r' = r{→t/→x}, we have (λx.r){→t/→x} = λx.r'. We will show that RA(λx.r') holds, and from this fact, by unfolding the definition of Ccont A(E), it follows that the required N (⟨(λx.r){→t/→x}, E⟩) holds. In order to prove RA(λx.r'), let us assume that s is a well-typed term of type A' and such that QA' (s) holds. Next, let E be a well-typed context of type A'' and such that Ccont A'' (E) holds. We have to prove that N (⟨(λx.r') s, E⟩). By the reduction rule, ⟨(λx.r') s, E⟩ reduces in one step to program ⟨r{→t/→x, s/x}, E⟩. By induction hypothesis, N (⟨r{→t/→x, s/x}, E⟩) holds and hence also N (⟨(λx.r') s, E⟩) holds.
Case t0 t1. Since t0 t1 is well typed, then x1 : B1,..., xn : Bn ▶ t0 : C → A
and x1 : B1,..., xn : Bn ▶ t1 : C for some type C. Taking t' = t0{→t/→x} and
t' = t1{→t/→x}, we have (t0 t1){→t/→x} = t' t' . By definition, the program ⟨t' t' , E⟩ is
1	0 1	0 1
the same as the program represented by ⟨t' , E t' ⟩. Since t0 is a subterm of t0 t1,
0	1
we can apply the induction hypothesis to deduce N (⟨t' , E t' ⟩) provided that E t'
0	1	1
is well typed and that Ccont (C→A)(E t' ) holds. The former is easy to see, and for the latter let us unfold the definition of Ccont (C→A). Let v be a value of type
C → A and such that RC→A(v) holds. We need to show that N (⟨v, E t' ⟩). Here again we can use another representative of the class of programs equal to ⟨v, E t' ⟩, such as ⟨v t' , E⟩. From the definition of RC→A(v), it is sufficient to show that
QC(t' ). By induction hypothesis on t1, we obtain that N (⟨t' , E'⟩) for any context
1	1
E' such that Ccont C(E'), which proves that QC(t' ).


Theorem 2.7 (Termination of CBN evaluation) If t is a closed well-typed term, then N (⟨t, •⟩) holds.

Proof. Since the empty context satisfies Ccont A for any type A, the theorem follows from Lemma 2.6.	 

Extracted evaluator
The program we obtain by extraction from the proof of Lemma 2.6 is as follows:
eval→x xi	= λ→t→uκ.ui κ
eval→x λx.t = λ→t→uκ.κ ((λx.t){→t/→x}) (λsuκ.eval→xx t (→ts) (→uu) κ)
eval→x t0 t1 = λ→t→uκ.eval→x t0 →t→u (λvu.u (t1{→t/→x}) (λκ.eval→x t1 →t→u κ))
As in call by value, the evaluator is in continuation-passing style (but here, the use of continuations imposes the call-by-name evaluation order) and it threads two envi- ronments: →t with unevaluated closed terms to be substituted in the final value, and →u with delayed computations, i.e., thunks, waiting to be activated with a continuation (κ).
The complete evaluator for call by name, extracted from the proof of Theo- rem 2.7, can be written as follows:

norm t = evalє t ϵϵκinit

where κinit = λvu.v.

Comparison with the standard approach
In a previous work by Biernacka et al. the authors formalized the problem of weak head normalization for the simply typed lambda calculus using standard, “direct- style” logical predicates `a la Tait [9]. By extraction using modified realizability, they obtained two evaluators for the two reduction strategies. Not surprisingly, the evaluators obtained in the present work are closely related to those “direct-style” evaluators. In the call-by-name case, the evaluator we obtained here is a CPS- translated counterpart of the call-by-name evaluator from the cited work (using the standard call-by-name CPS transformation [22]). In the call-by-value case, the evaluator is also in CPS but obtained by the standard call-by-value translation from the call-by-value direct-style evaluator. Both evaluators obtained here differ slightly from literal CPS translations because here we used slightly optimized logical predicates: we defined them on values only and therefore we did not need to include the condition that they normalize in the empty context in the definition of the predicate RA, because it is trivially satisfied for values. If we had defined the logical predicates on terms, in each case we would have obtained an evaluator that would be exactly the CPS-translated version of the respective direct-style evaluator (but it would contain redundancies.)

Abortive control operators
In this section, we extend the simply typed lambda calculus with abortive control operators for first-class continuations and we prove termination of evaluation in the extended language under the call-by-value and call-by-name reduction strategies.

The call-by-value reduction strategy
Terms and contexts: syntax and typing
The language we consider here is the simply typed lambda calculus extended with the binder version of the operator callcc (Kk.t), introduced by Reynolds [23], and with a construct to apply a captured continuation (k ←› t) akin to the operator throw known from Standard ML of New Jersey [19]. When evaluated, the expression Kk.t captures the current continuation (in some representation, e.g., as a reduction context), binds it to k and evaluates t with the current continuation. If at some point a value is thrown to k, the then-current continuation is discarded and the continuation bound to k becomes the current continuation. Hence, abortive control operators model jumps.
In the reduction semantics for callcc that we consider, captured continuations will be represented syntactically by reduction contexts. Therefore, we extend the syntax with applications of a captured context to a term (E ←› t), an expression that may arise in the process of evaluation of programs containing callcc. The extended grammar of terms reads as follows:
(terms) t ::= x | λx.t | tt | Kk.t | k ←› t | E ←› t 
where context variables (or, continuation variables) k are drawn from a separate set than object variables x, i.e., a continuation variable can only be used in the binder Kk.t or in a context application expression k ←› t.
In accordance with the description above, the construct E ←› t is never used in writing actual programs in languages with callcc and throw. Therefore, we distin- guish terms that do not contain any subterm of the form E ←› t and we call such terms plain terms.
In addition to the standard call-by-value reduction contexts, the language con- tains contexts of the form E' E representing “the term with the hole” E[E' ←› [ ]], whereas functions remain the only values:
(CBV contexts) E ::= • | v E | E t | E' ←› E (values)	v ::= λx.t
The plugging function is defined as before, with the new context handled as follows:

plug (t, E' E) = plug (E' ←› t, E)

As for the simply typed lambda calculus, we define programs as pairs consisting of a term and a reduction context and we equate such pairs if they represent the same plugged term. We say a term, a context or a program is closed if none of its object variables or continuation variables occur free.
Besides plain terms, we also distinguish plain contexts and plain programs. In the sequel, we will show that plain programs have the strong type soundness prop- erty (not guaranteed if we consider arbitrary terms) and we will prove termination of evaluation for plain programs.

The grammar of types of terms and contexts remains unchanged. However, in the presence of continuation variables (k) the typing judgments use an additional typing context Δ that associates continuation variables with their types. Terms are assigned types according to the following inference rules:
Γ, x : A;Δ ▶ t : B



Γ, x : A;Δ ▶ x : A
Γ; Δ ▶ t0 : A → B	Γ; Δ ▶ t1 : A Γ; Δ ▶ t0 t1 : B
Γ; Δ, k : cont A ▶ t : A


Γ; Δ, k : cont A ▶ k ←› t : B


Γ; Δ ▶ λx.t : A → B
Γ; Δ, k : cont A ▶ t : A


Γ; Δ ▶ Kk.t : A
Γ; Δ ▶ E : cont A	Γ; Δ ▶ t : A


Γ; Δ ▶ E ←› t : B

We can see that these rules agree with the standard typing for first-class contin- uations both from the semantics and logic viewpoints [1, 19, 27]. In particular, if we interpret them through the Curry-Howard correspondence, we obtain a natu- ral deduction system for minimal classical logic, i.e., minimal logic + Peirce’s law. Indeed, we have λy.Kk.y (λx.k ←› x) : ((A → B) → A) → A.
We also need to define a set of rules for typing contexts:
Γ; Δ ▶ v : A → B	Γ; Δ ▶ E : cont B

Γ; Δ ▶ • : cont A
Γ; Δ ▶ t : A	Γ; Δ ▶ E : cont B


Γ; Δ ▶ E t : cont (A → B)
Γ; Δ ▶ v E : cont A
Γ; Δ ▶ E' : cont A	Γ; Δ ▶ E : cont B


Γ; Δ ▶ E' ←› E : cont A

Finally, the rule for typing a complete program refers to the type of the term represented by that program:
Γ; Δ ▶ E[t] : A
Γ; Δ ▶ ⟨t, E⟩ : A
Reduction
The one-step reduction relation of our language is given by the following rules:
⟨(λx.t) v, E⟩ →v ⟨t{v/x}, E⟩
⟨Kk.t, E⟩ →v ⟨t{E/k}, E⟩
⟨E' ←› v, E⟩ →v ⟨v, E'⟩
Besides the usual βv rule modeling function applications, we have the rule for cap- turing the current continuation (represented as a reduction context) and the rule for applying a previously captured context. Terms of the form (λx.t) v, Kk.t and E' ←› v are redexes. Note, however, that the two new reductions are context sen- sitive, because—unlike in β-reduction—the reduction step alters not only redexes themselves, but also the surrounding context [8]. This is the reason why we need to be able to clearly state the boundary of the entire program.

Before proceeding to the proof of termination of evaluation of well-typed plain programs, let us discuss some of the typing properties of the presented type sys- tem. We base our presentation on Wright and Felleisen’s work who considered type soundness of a polymorphic functional language with callcc and abort [27].
Because of the typing and reduction rules for context application, if we allow for non-plain programs, our language enjoys only weak type soundness, i.e., well-typed programs reduce to well-typed programs, but the type may not be preserved. The reason for the violation of the subject reduction property is the abortive character of the expression E' ←› v in the reduction rule ⟨E' ←› v, E⟩ →v ⟨v, E'⟩. In general, the answer types of E and E' do not have to be the same. 5 Nevertheless, since the language satisfies the unique-decomposition property and weak type soundness (the proofs of both properties are routine), we can state the following proposition:
Proposition 3.1 (Progress) For each program p, p either is a value or it reduces uniquely to another program p' such that if Γ; Δ ▶ p : A, then Γ; Δ ▶ p' : B for some type B.
Though it is impossible to prove a stronger type soundness property in the general case, we can obtain such a property if we consider only plain programs. As we will see, plain programs can be shown to satisfy the strong type soundness property stating that the type of a plain program and of its final value are the same, which in general is sufficiently strong and together with the termination theorem of Section 3.1.3 ensures that any well-typed plain program evaluates to a unique value of the same type. However, even in the case of plain programs, we cannot hope for a standard subject reduction property of our type system, since, in the course of computation, contexts get captured and are substituted for continuation variables, which leads to non-plain programs.
We shall prove strong type soundness for the above type system by relating it to a more restrictive one, namely an annotated type system that allows for applications of contexts of one fixed answer type. In the annotated type system the annotation on the turnstyle specifies the type of the entire program, of which the given phrase can be a part. Only contexts of that answer type are allowed to be captured and applied later on.




Γ, x : A;Δ ▶B x : A
Γ; Δ ▶C t0 : A → B	Γ; Δ ▶C t1 : A Γ; Δ ▶C t0 t1 : B
Γ; Δ ▶C E : cont A	Γ; Δ ▶C t : A Γ; Δ ▶C E ←› t : B
The contexts are typed as follows:
 Γ, x : A; Δ ▶C t : B 
Γ; Δ ▶C λx.t : A → B
Γ; Δ, k : cont A ▶B t : A Γ; Δ ▶B Kk.t : A
  Γ; Δ, k : cont A ▶C t : A	
Γ; Δ, k : cont A ▶C k ←› t : B



5 The answer type of a context is the top-level type of the program obtained by pairing the context with any term of the correct type.



Γ; Δ ▶A • : cont A
Γ; Δ ▶C t : A	Γ; Δ ▶C E : cont B Γ; Δ ▶C E t : cont (A → B)
Γ; Δ ▶C v : A → B	Γ; Δ ▶C E : cont B


Γ; Δ ▶C v E : cont A
Γ; Δ ▶C E' : cont A	Γ; Δ ▶C E : cont B


Γ; Δ ▶C E' ←› E : cont A


The type annotation is introduced by the rule for typing programs:
Γ; Δ ▶A E[t] : A
Γ; Δ ▶A ⟨t, E⟩

Since all the contexts occurring in a program as terms must have the same answer type (given by the annotation), the subject reduction property for the annotated type systems can be proved in the standard way [27]:
Proposition 3.2 If Γ; Δ ▶A p and p →v p', then Γ; Δ ▶A p'.
Next, we state a few lemmas that establish the relationship between the unanno- tated and annotated type systems. First, proved by rule induction is the following lemma:
Lemma 3.3  (i) If t is plain and Γ; Δ ▶ t : A, then Γ; Δ ▶C t : A for any type
C.
(ii) If E is plain and Γ; Δ ▶ E : cont A, then Γ; Δ ▶C E : cont A for some type
C.
As a direct corollary from Lemma 3.3 we obtain:
Lemma 3.4 If p is plain and Γ; Δ ▶ p : A, then Γ; Δ ▶A p.
From Lemma 3.4 and Proposition 3.2, we can see that plain programs capture and subsequently apply contexts only of one fixed answer type.
Conversely, by rule induction, we obtain that we can erase type annotations from typing judgments for terms and contexts:
Lemma 3.5	(i) If Γ; Δ ▶C t : A then Γ; Δ ▶ t : A.
(ii) If Γ; Δ ▶C E : cont A, then Γ; Δ ▶ E : cont A.
As a corollary, we can remove the type annotations from typing judgments for programs:
Lemma 3.6 If Γ; Δ ▶A p, then Γ; Δ ▶ p : A.
Combining Lemmas 3.4 and 3.6 and Proposition 3.2, we obtain strong type soundness for the unannotated type system [27]:
Proposition 3.7 (Preservation) If p is plain, Γ; Δ ▶ p : A and p →∗ pv, then
Γ; Δ ▶ pv : A.

Termination
Our goal in this section is to prove termination of call-by-value evaluation of well- typed plain programs (hence, of well-typed plain terms). The logical predicates for the language with callcc are exactly the same as for the simply typed lambda calculus and we state a termination theorem analogous to that of Section 2.2.3.
In the statement of the theorem we have to keep track not only of the terms that are to be substituted for free object variables, but also of the contexts to be substituted for free continuation variables.
Lemma 3.8 Let x1 : B1,..., xn : Bn; k1 : cont C1,..., km : cont Cm ▶ t : A and t
be a plain term. Next, let →v be a sequence of closed well-typed value terms such that
▶ vi : Bi and RBi (vi) for 1 ≤ i ≤ n, and let E→ be a sequence of closed well-typed
contexts such that ▶ Ei : cont Ci and Ccont Ci (Ei) for 1 ≤ i ≤ m. Then for all closed well-typed reduction contexts E such that ▶ E : cont A and Ccont A(E), the program ⟨t{→v/→x}{E→ /→k}, E⟩ normalizes, i.e., N (⟨t{→v/→x}{E→ /→k}, E⟩) holds.
Proof. The proof proceeds exactly as in Section 2.2.3, by induction on the structure of terms. We will show only the two cases for the two new syntactic constructs.
Case Kk.t. Because Kk.t is well typed, k is of type cont A and t is of type A. Taking t' = t{→v/→x}{E→ /→k}, we have (Kk.t){→v/→x}{E→ /→k} = Kk.t'. We have to show that N (⟨Kk.t', E⟩) holds. But this program reduces in one step to program
⟨t'{E/k}, E⟩. In turn, this program normalizes by induction hypothesis, because t is a subterm of Kk.t and we know by assumption that E is well typed and that Ccont A(E), so we can use it for substitution in t in the induction step.
Case ki ←› t. By assumption, ki is a continuation variable of type cont Ci and (ki ←› t){→v/→x}{E→ /→k} = Ei ←› t{→v/→x}{E→ /→k}. Let t' = t{→v/→x}{E→ /→k}. We have to show that N (⟨Ei ←› t', E⟩) holds. But the program ⟨Ei ←› t', E⟩ can be represented also as ⟨t', Ei ←› E⟩. We can now apply the induction hypothesis for t provided that the context Ei ←› E is well typed and that Ccont (Ci→A)(Ei ←› E) holds. The former is easy to see, and for the latter we unfold the definition of Ccont (Ci→A). Let v be a value of type Ci → A and such that RCi→A(v) holds. We need to show that N (⟨v, Ei ←› E⟩) holds. The program ⟨v, Ei ←› E⟩ can be
represented by ⟨v ←› Ei, E⟩ and this program reduces in one step to program
⟨v, Ei⟩. But we know that N (⟨v, Ei⟩) by the assumption that Ccont Ci (Ei) which concludes the proof in this case.
 
Theorem 3.9 (Termination of CBV evaluation) If t is a plain, closed, well- typed term, then N (⟨t, •⟩) holds.
Proof. Since the empty context satisfies Ccont A for any type A, the theorem follows from Lemma 3.8.	 

Extracted evaluator
The computational content of the proof of Lemma 3.8 can be written as follows:

eval→x,→k x	= λ→v→uE→ →κEκ.κ v u
eval→x,→k λx.t	= λ→v→uE→ →κEκ.κ (λx.t') (λvuEκ.eval→xx,→k t (→vv) (→uu)E→ →κ Eκ)

eval→x,→k t t
= λ→v→uE→ →κEκ.eval→x,→k t
→v→uE→ →κ(E t' )

(λv u .eval→x,→k t →v→uE→ →κ(v E) (λv u .u v u E κ))
eval→x,→k Kk.t	= λ→v→uE→ →κEκ.eval→x,→kk t →v→u(E→ E)(→κκ)Eκ
eval→x,→k k ←› t = λ→v→uE→ →κEκ.eval→x,→k t →v→uE→ →κ(E ←› E)(λvu.κ vu)

where λx.t' = (λx.t){→v/→x}{E→ /→k} and t' = t1{→v/→x}{E→ /→k}.
The extracted function eval is parameterized by a vector of free object variables (→x) and by a vector of free continuation variables (→k). It uses two additional en- vironments: one for keeping track of contexts to be substituted in the final value (E→ ) and one for storing continuations associated with these contexts (→κ)—these continuations are waiting to be activated by a throw construct.
The first three clauses of the function eval are similar to those of the call-by-value evaluator for the plain lambda calculus (cf. Section 2.2) except that they thread the two new context environments and the current context (E). Evaluation of Kk.t consists in capturing the current context E and its functional representation κ in the appropriate environments and then evaluating t in the current context, using the modified environments. Whenever a captured context is thrown a value using the throw construct κi ←› t, the right context Ei is fetched from the environment E→ and its functional representation κi becomes the continuation with which evaluation of t is invoked. Syntactic representations of contexts E are only used in substitutions for free continuation variables in the final value.
The complete evaluator, extracted from the proof of Theorem 3.9, can be written as follows:
norm t = evalє,є t ϵϵϵϵ • κinit

where κinit = λvu.v.



The call-by-name reduction strategy
In the call-by-name reduction strategy, reduction contexts and values coincide with those in the call-by-name language without control operators considered in Sec- tion 2.3. The types of terms and contexts as well as the typing rules for terms are identical with the call-by-value case of Section 3.1, whereas the typing rules for contexts take into account the environment Δ, but are otherwise the same as those for the standard call-by-name contexts. The reduction rules ensure that arguments to functions and continuations are not evaluated:

⟨(λx.r) t, E⟩ →n ⟨r{t/x}, E⟩
⟨Kk.t, E⟩ →n ⟨t{E/k}, E⟩
⟨E' ←› t, E⟩ →n ⟨t, E'⟩
Analogously to the call-by-value case, it can be shown that the plain language with the call-by-name reduction strategy satisfies both the weak and strong type soundness properties. Moreover, using the logical predicates defined for the simply typed call-by-name lambda calculus in Section 2.3.2, we prove termination of call- by-name evaluation for the language augmented with callcc.
Lemma 3.10 Let x1 : B1,..., xn : Bn; k1 : cont C1,..., km : cont Cm ▶ t : A and t
be a plain term. Next, let →t be a sequence of closed well-typed value terms such that
▶ vi : Bi and QBi (ti) for 1 ≤ i ≤ n, and let E→ be a sequence of closed well-typed
contexts such that ▶ Ei : cont Ci and Ccont Ci (Ei) for 1 ≤ i ≤ m. Then for all closed well-typed reduction contexts E such that ▶ E : cont A and Ccont A(E), the program ⟨t{→t/→x}{E→ /→k}, E⟩ normalizes, i.e., N (⟨t{→t/→x}{E→ /→k}, E⟩) holds.
The proof proceeds in the expected way, and the evaluator we extract from it is analogous of that in Section 3.1.4, except it uses the call-by-name strategy:
eval→x,→k x	= λ→t→uE→ →κEκ.u E κ
eval→x,→k λx.t	= λ→t→uE→ →κEκ.κ (λx.t') (λsuEκ.eval→xx,→k t (→ts) (→uu)E→ →κ Eκ)

eval→x,→k t t
= λ→t→uE→ →κEκ.eval→x,→k t
→t→uE→ →κ(E t' )

(λvu.u t' (λEκ.eval→x,→k t eval→x,→k Kk.t	= λ→t→uE→ →κEκ.eval→x,→kk t →t→u(E→ E)(→κκ)Eκ eval→x,→k k ←› t = λ→t→uE→ →κEκ.eval→x,→k t →t→uE→ →κE κ
→t→uE→ →κ Eκ)E κ)

where λx.t' = (λx.t){→v/→x}{E→ /→k} and t' = t1{→v/→x}{E→ /→k}.
Operationally, callcc and throw are handled in the same way under call by name and call by value (cf. Section 3.1.4). The only significant difference is that under call by value a new form of context (Ei ←› E) is created and passed when evaluating the throw construct—this context representation is then used only in substitutions for the appropriate continuation variable in the final value of the program.
From Lemma 3.10, we have:
Theorem 3.11 (Termination of CBN evaluation) If t is a plain, closed, well- typed term, then N (⟨t, •⟩) holds.
From the proof of Theorem 3.11, we obtain a complete call-by-name evaluator:

norm t = evalє,є t ϵϵϵϵ • κinit
where κinit = λvu.v.

Other control operators
Besides the well known abortive control operator callcc, several others have been considered in the literature on continuations. One of them is abort (A) [27], which discards the current continuation and can be defined in our setting by the following reduction (here, in call by value) and typing rules:
Γ; Δ ▶ t : B

⟨A t, E⟩ →v ⟨t, •⟩


Γ; Δ ▶ A t : A

Another control operator widely studied in the literature is Felleisen’s variant of callcc—the control operator C [15] (contrary to callcc, it captures and discards the current continuation), for the uniformity of the presentation accompanied here by the throw construct, whose dynamic and static semantics are as in Section 3.1.2. The reduction semantics of C and its type assignment are defined by the rules:
Γ; Δ, k : cont A ▶ t : B

⟨Ck.t, E⟩ →v ⟨t{E/k}, •⟩


Γ; Δ ▶ Ck.t : A

It is a matter of some minor adjustments in the proofs of termination for the language with callcc under call by value or call by name, in order to obtain the same result for abort and C. For example, in the call-by-value setting the extracted evalua- tor contains the following clauses defining normalization of the A and C expressions:


eval→x,→k At	= λ→v→uE→ →κEκ.eval→x,→k t →v→uE→ →κ • k
eval→x,→k Ck.t = λ→v→uE→ →κEκ.eval→x,→kk t →v→u(E→ E)(→κκ) • k

It is easy to see that the presented typing rules for A and C are too liberal to ensure type preservation by reduction (because of the completely unconstrained type B in the premises). So even though the evaluation in the simply typed language with A and/or C always terminates, the type of the program may change in the course of computation. If we wanted to ensure type preservation under the given reduction rules (which are standard), we could use a more restrictive type system that is an extension of the annotated type system of Section 3.1.2 with the rules:

 Γ; Δ ▶B t : B 
Γ; Δ ▶B A t : A
Γ; Δ, k : cont A ▶B t : B Γ; Δ ▶B Ck.t : A


Conclusion and future work
We have shown an approach to proving termination of evaluation in reduction se- mantics using context-based reducibility predicates a` la Tait. In particular, we have presented short and direct proofs of termination of evaluation for the simply typed lambda calculus extended with control operators callcc, abort and Felleisen’s C for

the call-by-value and the call-by-name reduction strategies. We have also presented evaluators extracted from each of the proofs. These evaluators are instances of nor- malization by evaluation. Moreover, they are in continuation-passing style and the continuations arise as the computational content of the reducibility predicates for reduction contexts. This latter fact shows a logical connection between continua- tions and contexts; the correspondence between them has previously been observed and investigated by Danvy in the setting of program transformations [11, 12].
The method of proof developed in this paper relies on the formalism of reduction semantics and is therefore fitted for languages with context-sensitive notion of re- duction. In such languages a single computation step takes into account the redex as well as its surrounding context; this context may be captured and discarded or oth- erwise changed by the reduction step. Hence, the way of representing and reducing programs proposed in this article seems to be particularly useful in the context- sensitive world. We have shown one example of such a language: the simply typed lambda calculus with abortive control operators. Another prominent example are delimited-control operators where—unlike for abortive control operators—captured contexts are delimited and can be composed [7, 13, 14]. For example, the delimited- control operators shift and reset admit a context-sensitive reduction semantics with two layers of reduction contexts. It is possible to adapt the method of reducibility predicates to this more general reduction semantics and the authors are currently working on this problem. Furthermore, it is interesting to investigate how the pro- posed approach can be adapted to other context-sensitive languages [8] as well as to proofs of strong normalization and to languages with a form of polymorphism.

Acknowledgement
We are grateful to Olivier Danvy for his willingness to proof-read the article at a short notice, and for his helpful, comprehensive comments. Thanks are also due to the anonymous reviewers of MFPS XXV for their comments.

References
Zena M. Ariola, Hugo Herbelin, and Amr Sabry. A proof-theoretic foundation of abortive continuations.
Higher-Order and Symbolic Computation, 20(4):403–429, 2007.
Henk Barendregt. The Lambda Calculus: Its Syntax and Semantics, volume 103 of Studies in Logic and the Foundation of Mathematics. North-Holland, revised edition, 1984.
Ulrich Berger. Program extraction from normalization proofs. In Marc Bezem and Jan Friso Groote, editors, Typed Lambda Calculi and Applications, number 664 in Lecture Notes in Computer Science, pages 91–106, Utrecht, The Netherlands, March 1993. Springer-Verlag.
Ulrich Berger, Stefan Berghofer, Pierre Letouzey, and Helmut Schwichtenberg. Program extraction from normalization proofs. Studia Logica, 82(1):25–49, 2006.
Ulrich Berger and Helmut Schwichtenberg. An inverse of the evaluation functional for typed λ-calculus. In Gilles Kahn, editor, Proceedings of the Sixth Annual IEEE Symposium on Logic in Computer Science, pages 203–211, Amsterdam, The Netherlands, July 1991. IEEE Computer Society Press.
Ma-lgorzata Biernacka. Formalization of the proof of weak head normalization for System T and its extracted evaluator (an instance of normalization by evaluation), 2007. Available online at http:
//www.ii.uni.wroc.pl/~mabi/nbe/cbn-system-T-church.


Ma-lgorzata Biernacka, Dariusz Biernacki, and Olivier Danvy. An operational foundation for delimited continuations in the CPS hierarchy. Logical Methods in Computer Science, 1(2:5):1–39, November 2005. A preliminary version was presented at the Fourth ACM SIGPLAN Workshop on Continuations (CW’04).
Ma-lgorzata Biernacka and Olivier Danvy. A syntactic correspondence between context-sensitive calculi and abstract machines. Theoretical Computer Science, 375(1-3):76–108, 2007. Extended version available as the research report BRICS RS-06-18.
Ma-lgorzata Biernacka, Olivier Danvy, and Kristian Støvring. Program extraction from proofs of weak head normalization. In Martin Escard´o, Achim Jung, and Michael Mislove, editors, Proceedings of the 21st Annual Conference on Mathematical Foundations of Programming Semantics(MFPS XXI), volume 155 of Electronic Notes in Theoretical Computer Science, pages 169–189, Birmingham, UK, May 2005. Elsevier Science Publishers. Extended version available as the research report BRICS RS-05-12.
Thierry Coquand and Peter Dybjer. Intuitionistic model constructions and normalization proofs.
Mathematical Structures in Computer Science, 7:75–94, 1997.
Olivier Danvy. On evaluation contexts, continuations, and the rest of the computation. In Hayo Thielecke, editor, Proceedings of the Fourth ACM SIGPLAN Workshop on Continuations (CW’04), Technical report CSR-04-1, Department of Computer Science, Queen Mary’s College, pages 13–23, Venice, Italy, January 2004. Invited talk.
Olivier Danvy. Defunctionalized interpreters for programming languages. In Peter Thiemann, editor, Proceedings of the 2008 ACM SIGPLAN International Conference on Functional Programming (ICFP’08), SIGPLAN Notices, Vol. 43, No. 9, Victoria, British Columbia, September 2008. ACM Press. Invited talk.
Olivier Danvy and Andrzej Filinski. Abstracting control. In Mitchell Wand, editor, Proceedings of the 1990 ACM Conference on Lisp and Functional Programming, pages 151–160, Nice, France, June 1990. ACM Press.
Matthias Felleisen. The theory and practice of first-class prompts. In Jeanne Ferrante and Peter Mager, editors, Proceedings of the Fifteenth Annual ACM Symposium on Principles of Programming Languages, pages 180–190, San Diego, California, January 1988. ACM Press.
Matthias Felleisen and Daniel P. Friedman. Control operators, the SECD machine, and the λ-calculus. In Martin Wirsing, editor, Formal Description of Programming Concepts III, pages 193–217. Elsevier Science Publishers B.V. (North-Holland), Amsterdam, 1986.
Matthias Felleisen, Daniel P. Friedman, Eugene Kohlbecker, and Bruce Duba. A syntactic theory of sequential control. Theoretical Computer Science, 52(3):205–237, 1987.
Matthias Felleisen and Robert Hieb. The revised report on the syntactic theories of sequential control and state. Theoretical Computer Science, 103(2):235–271, 1992.
Timothy G. Griffin. A formulae-as-types notion of control. In Paul Hudak, editor, Proceedings of the Seventeenth Annual ACM Symposium on Principles of Programming Languages, pages 47–58, San Francisco, California, January 1990. ACM Press.
Robert Harper, Bruce F. Duba, and David MacQueen. Typing first-class continuations in ML. Journal of Functional Programming, 3(4):465–484, October 1993. A preliminary version was presented at the Eighteenth Annual ACM Symposium on Principles of Programming Languages (POPL 1991).
W. A. Howard. The formulae-as-types notion of construction. In J. P. Seldin and J. R. Hindley, editors, To H.B. Curry: Essays on Combinatory Logic, Lambda-Calculus and Formalism, pages 470–
490. Academic Press, 1980.
Michel Parigot. Proofs of strong normalisation for second order classical natural deduction. Journal of Symbolic Logic, 62(4):1461–1479, 1997.
Gordon D. Plotkin. Call-by-name, call-by-value and the λ-calculus. Theoretical Computer Science, 1:125–159, 1975.
John C. Reynolds. Definitional interpreters for higher-order programming languages. In Proceedings of 25th ACM National Conference, pages 717–740, Boston, Massachusetts, 1972.
Helmut Schwichtenberg. Proofs, lambda terms and control operators. In Helmut Schwichtenberg, editor, Logic of Computation, volume 157 of Series F: Computer and Systems Sciences, Proceedings of the NATO Advanced Study Institute on Logic of Computation, Marktoberdorf, Germany, July 25 - August 6, 1995, pages 309–347. Springer Verlag, 1997.
William W. Tait. Intensional interpretation of functionals of finite type I. Journal of Symbolic Logic, 32:198–212, 1967.
Anne S. Troelstra, editor. Metamathematical Investigation of Intuitionistic Arithmetic and Analysis, volume 344 of Lecture Notes in Mathematics. Springer-Verlag, 1973.
Andrew K. Wright and Matthias Felleisen. A syntactic approach to type soundness. Information and Computation, 115:38–94, 1994.

An implementation of the evaluators
Below we present example OCaml implementations of the evaluators from Sec- tion 3.1.4 and Section 3.2. These implementations can be seen as desired effects of a program extraction tool but they have not been obtained in that way (in fact, automatic tools usually produce much less readable code).
In the code, we use a function lookup that fetches an item from an environment and a function subst all that performs substitutions of values for object variables and substitutions of contexts for continuation variables. (This function may produce non-plain terms with the constructor Throw’.) We state only signatures of these two functions and omit their implementations:
lookup : ’a -> (’a * ’b) list -> ’b
subst_all : term -> (ide_v * term) list -> (ide_k * ctxt) list -> term

Call by value
type term =
| Var of ide_v
| Lam of ide_k * term
| App of term * term
| Callcc of ide_k * term
| Throw of ide_k * term
| Throw’ of ctxt * term
and ctxt =
| Mt_c
| App_c of ctxt * term
| Val_c of term * ctxt
| Ctx_c of ctxt * ctxt
type func = F of (term -> func -> ctxt -> cont -> term) and cont = term -> func -> term
(*
eval : term ->
(ide_v * term) list -> (ide_v * func) list -> (ide_k * ctxt) list -> (ide_k * cont) list -> ctxt -> cont -> term
*)
let rec eval t vs us cs ks c k = match t with
| Var x ->
k (lookup x vs) (lookup x us)
| Lam(x, t) ->
k (subst_all (Lam(x,t)) vs cs)
(F (fun v u c k -> eval t ((x,v)::vs) ((x,u)::us) cs ks c k))
| App(t0, t1) ->
eval t0 vs us cs ks (App_c(c, subst_all t1 vs cs)) (fun v0 u0 -> eval t1 vs us cs ks (Val_c(v0, c))
(fun v1 u1 -> match u0 with F f -> f v1 u1 c k))
| Callcc(xk, t) ->
eval t vs us ((xk,c)::cs) ((xk,k)::ks) c k
| Throw(xk, t) ->
eval t vs us cs ks (Ctx_c(lookup xk cs, c)) (lookup xk ks)
(*
norm : term -> term
*)
let norm t = eval t [] [] [] [] Mt_c (fun v u -> v)

Call by name
type term =
| Var of ide_v
| Lam of ide_v * term
| App of term * term
| Callcc of ide_k * term


| Throw of ide_k * term
| Throw’ of ctxt * term
and ctxt =
| Mt_c
| App_c of ctxt * term
type func = F of (term -> thunk -> ctxt -> cont -> term) and thunk = ctxt -> cont -> term
and cont = term -> func -> term
(*
eval : term ->
(ide_v * term) list -> (ide_v * thunk) list -> (ide_k * ctxt) list -> (ide_k * cont) list -> ctxt -> cont -> term
*)
let rec eval t ts us cs ks c k = match t with
| Var x ->
(lookup x us) c k
| Lam(x, t) ->
k (subst_all (Lam(x,t)) ts cs)
(F (fun s u c k -> eval t ((x,s)::ts) ((x,u)::us) cs ks c k))
| App(t0, t1) ->
let t1’ = subst_all t1 ts cs
in eval t0 ts us cs ks (App_c(c, t1’)) (fun v u -> match u with
F f -> f t1’ (fun c k -> eval t1 ts us cs ks c k) c k)
| Callcc(xk, t) ->
eval t ts us ((xk,c)::cs) ((xk,k)::ks) c k
| Throw(xk, t) ->
eval t ts us cs ks (lookup xk cs) (lookup xk ks)
(*
norm : term -> term
*)
let norm t =
eval t [] [] [] [] Mt_c (fun v u -> v)
