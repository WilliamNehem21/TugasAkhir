Available online at www.sciencedirect.com


Electronic Notes in Theoretical Computer Science 344 (2019) 83–100
www.elsevier.com/locate/entcs


A Concrete Categorical Semantics of Lambda-S
Alejandro Díaz-Caroa,b,1,3  Octavio Malherbec,d,2,4
a Universidad Nacional de Quilmes, Bernal, Buenos Aires, Argentina
b Instituto de Ciencias de la Computación (CONICET-Universidad de Buenos Aires), Buenos Aires,
Argentina
c Departamento de Matemática y Aﬁnes, CURE, Universidad de la República, Maldonado, Uruguay
d IMERL, Facultad de Ingeniería, Universidad de la República, Montevideo, Uruguay

Abstract
Lambda- is an extension to first-order lambda calculus unifying two approaches of non-cloning in quantum lambda-calculi. One is to forbid duplication of variables, while the other is to consider all lambda-terms as algebraic linear functions. The type system of Lambda- have a constructor S such that a type A is considered as the base of a vector space while S(A) is its span. A first semantics of this calculus have been given when first presented, with such an interpretation: superposed types are interpreted as vectors spaces while non-superposed types as their basis. In this paper we give a concrete categorical semantics of Lambda- , showing that S is interpreted as the composition of two functors in an adjunction relation between the category of sets and the category of vector spaces over C. The right adjoint is a forgetful functor U, which is hidden in the language, and plays a central role in the computational reasoning.
Keywords: Quantum computing, algebraic lambda-calculus, categorical semantics


Introduction
The non-cloning property of quantum computing has been treated in different ways in quantum programming languages. One way is to forbid duplication of variables with linear types [1, 12], and hence, a program taking a quantum argument will not duplicate it (e.g. [3, 14, 17, 20, 22]). Another way is to consider all lambda-terms as expressing linear functions (e.g. [4–6,11]). The first approach forbids a term λx.(x x) (for some convenient definition of	), while the second approach distributes (λx.(x	x))( 0 + 1 ) to λx.(x	x) 0 + λx.(x	x) 1 , mimicking the way that linear operations act on vectors in a vector space. However, adding a measurement operator to a calculus following the linear-algebraic approach need to also add linear

1 Partially supported by PICT 2015 1208 and ECOS-Sud A17C03 QuCa.
2 Partially supported by MIA CSIC UdelaR.
3 Email: adiazcaro@icc.fcen.uba.ar
4 Email: malherbe@fing.edu.uy

https://doi.org/10.1016/j.entcs.2019.07.006
1571-0661/© 2019 The Author(s). Published by Elsevier B.V.
This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).

types: indeed, if π represent a measurement operator, (λx.πx)( 0 + 1 ) should not reduce to (λx.πx) 0 + (λx.πx) 1 but to π( 0 + 1 ). Therefore, the functions taking a superposition have to be marked in some way and ensure that they will not use their arguments more than once (i.e. ensure linearity in the linear-logic sense).
The calculus Lambda-  has been introduced in [9] and slightly modified later in [18], as a first-order fragment of Lineal [6], extended with measurements. In linear logic we would write A the types of terms that cannot be duplicated while
!A types duplicable terms. In Lambda-  instead A are the types of the terms that
cannot be superposed, while S(A) are the terms that can be superposed, and since superposition forbids duplication, A means that we can duplicate, while S(A) means that we cannot duplicate. So the S is not the same as the bang “!”, but somehow the opposite. This can be explained by the fact that linear logic is focused on the possibility of duplication, while here we focus on the possibility of superposition, which implies the impossibility of duplication.
In [9] a first denotational semantics (in environment style) is given where the type B is interpreted as  0 , 1  while S(B) is interpreted as Span( 0 , 1 )= C2, and, in general, a type A is interpreted as a basis while S(A) is the vector space generated
by such a basis. In this paper we go beyond and give a categorical interpretation of Lambda- where S is a functor of an adjunction between the category Set and the category Vec. Explicitly, when we evaluate S we obtain formal finite linear combinations of elements of a set with complex numbers as coefficients and the other functor of the adjunction, U , allows us to forget the vectorial structure.
The main structural feature of our model is that it is expressive enough to de- scribe the bridge between the quantum and the classical universes explicitly by controlling its interaction. This is achieved by providing a monoidal adjunction. In the literature, intuitionistic linear (as in linear-logic) models are obtained by a comonad determined by a monoidal adjunction (S, m) (U, n), i.e. the bang ! is interpreted by the comonad SU (see [8]). In a different way, a crucial ingredient of our model is to consider the monad US for the interpretation of S determined by a similar monoidal adjunction. This implies that on the one hand we have a tight control of the Cartesian structure of the model (i.e. duplication, etc) and on the other hand the world of superpositions lives in some sense inside the classical world,
i.e. determined externally by classical rules until we decide to explore it. This is given by the following composition of maps:

US(B) × US(B) −n→ U (S(B) ⊗ S(B)) U(m) US(B × B)

that allows us to operate in a monoidal structure representing the quantum world and then to return to the Cartesian product.
This is different from linear logic, where the classical world lives in some sense inside the quantum world i.e. (!B) ⊗ (!B) is a product inside a monoidal category.
Another source of inspiration for our model has been the work of Selinger [19] and Abramsky and Coecke [2] where they captured the notion of scalars and inner product in a more abstract categorical setting, i.e. a category in which there is an

abstract notion of a dagger functor. It is envisaged that this approach will provide the basis for an abstract model in future work.
The paper is structured as follows. In Section 2 we recall the definition of Lambda- and give some examples, stating its main properties. Section 3 is di- vided in three subsections: first we define the categorical constructions needed to interpret the calculus, then we give the interpretation, and finally we prove its sound-
ness and adequacy properties. Finally, we conclude in Section 4. An appendix with detailed proofs can be found in the pre-print in arXiv 5 .

The calculus Lambda-S
We give a slightly modified presentation of Lambda-S, based on [18]. In particular, instead of giving a probabilistic rewrite system where t pk rk means that t reduces with probability pk to rk, we introduce the notation t   p1r1    pnrn, this way, the rewrite system is deterministic and the probabilistic distribution is internalized in the syntax.
The syntax of terms and types is given in Figure 2. We write Bn for B×· · ·×B n-
times, with the convention that	1	, and may write n¨	, for	· · ·
p t	p t

i i
i=1
1 1	pntn

with the convention that
¨1
i=1
1t = t
.  We use capital Latin letters (
A, B, C, . . . )

for general types and the capital Greek letters Ψ, Φ, Ξ, and Υ for qubit types.
= Bn  n  N ,  is the set of qubit types, and  is the set of types (  Ç  Ç  ). In the same way, Vars is the set of variables, B is the set of basis terms, V the set of values, Λ the set of terms, and D the set of probabilistic distributions on terms. We have Vars Ç B Ç V Ç Λ Ç D.

Fig. 1: Syntax of types and terms of Lambda-S.
The terms are considered modulo associativity and commutativity of the syn- tactic symbol +. On the other hand, the symbol  is used to represent a real probabilistic distribution of terms, not as a syntactic symbol, and so, it is not only associative and commutative, we also have that pt  qt is the same as (p + q)t and pt  0r = pt 6 .

5 http://arxiv.org/abs/1806.09236.
6 As a remark, notice that  can be seen as the + symbol of the algebraic lambda calculus [], where the equality is confluent since scalars are positive, while our + symbol coincides with the + from Lineal [6]

There is one atomic type B, for basis qubits |0⟩ and |1⟩, and three constructors:
×, for pairs, ⇒, for first-order functions, and S(·) for superpositions.
The syntax of terms contains:
The three basic terms for first-order lambda-calculus, namely, variables, abstrac- tions and applications.
Two basic terms 0 and 1 to represent qubits, and one test ?r s on them. We may write t?r s for (?r s)t, see Example 2.1 for a clarification of why to choose this presentation.
A product × to represent associative pairs (i.e. lists), with its destructors head
and tail. We may use the notation |b1b2 ... bn⟩ for |b1⟩× |b2⟩×· · ·× |bn⟩.
Constructors to write linear combinations of terms, namely + (sum) and . (scalar multiplication), and its destructor πj measuring the first j qubits written as linear combinations of lists of qubits, and one null vector 0S(A) for each type S(A).
Two casting functions r and l which allows us to consider lists of superpositions as superpositions of lists (see Example 2.2).
The rewrite system has not been given yet, however the next examples give some intuitions and clarify the ?r·s and the casting functions.
Example 2.1 The term ?r s is meant to test whether the condition is 1 or 0 . However, defining it as a function, allows us to use the algebraic linearity to imple- ment the quantum-if [3]:
(?r·s)(α. |1⟩ + β. |0⟩)= (α. |1⟩ + β. |0⟩)?r·s −→∗ α.|1⟩?r·s + β.|0⟩?r·s −→∗ α.r + β.s
Example 2.2 The term ( √1 (|0⟩ + |1⟩)) × |0⟩ is the encoding of the qubit √1 (|0⟩ +
|1⟩)⊗|0⟩. However, while the qubit √1 (|0⟩+|1⟩)⊗|0⟩ is equal to √1 (|0⟩⊗|0⟩+|1⟩⊗|0⟩),
the term will not rewrite to the encoding of it, unless a casting	r is preceding the term:
1	∗  1
⇑r ( √2 (|0⟩ + |1⟩)) × |0⟩ −→ √2 (|0⟩× |0⟩ + |1⟩× |0⟩)
The reason is that we want the term ( √1 (|0⟩ + |1⟩)) × |0⟩ to have type S(B) × B,
highlighting the fact that the second qubit is a basis qubit, i.e. duplicable, while the term √1 (|0⟩× |0⟩ + |1⟩× |0⟩) will have type S(B × B), showing that the full term is
a superposition where no information can be extracted and hence, non-duplicable.
The rewrite system depends on types. Indeed, λx:S(Ψ).t follows a call-by-name strategy, while λx:B.t, which can duplicate its argument, must follow a call-by-base strategy [7], that is, not only the argument must be reduced first, but also it will distribute over linear combinations. Therefore, we give first the type system and then the rewrite system.
The typing relation is given in Figure 2. Contexts, identified by the capital Greek letters Γ, Δ, and Θ, are partial functions from Vars to T . The contexts assigning

(see [7] for a more detailed discussion on different presentations of algebraic lambda calculi).

only types in  are identified with the super-index B, e.g. ΘB. Whenever more than one context appear in a typing rule, their domains are considered pair-wise disjoint. Observe that all types are linear (as in linear-logic) except on basis types Bn, which can be weakened and contracted (expressed by the common contexts ΘB).














Fig. 2: Typing relation The rewrite relation is given in Figures 3 to 10.
The two beta rules (Figure 3) are applied according to the type of the argument. If the abstraction expects an argument with a superposed type, then the reduction follows a call-by-name strategy (rule (βn)), while if the abstraction expects a basis type, the reduction is call-by-base (rule (βb)): it β-reduces only when its argument is a basis term. However, typing rules also allow to type an abstraction expecting an argument with basis type, applied to a term with superposed type (cf. Example 2.3). In this case, the beta reduction cannot occur and, instead, the application must distribute using the rules from Figure 4: the linear distribution rules.
Figure 5 gives the two rules for the conditional construction. Together with the linear distribution rules (cf. Figure 4), these rules implement the quantum-if

Fig. 3: Beta rules

Fig. 4: Linear distribution rules



Fig. 5: Rules of the conditional construction

Fig. 6: Rules for lists












Fig. 7: Rules implementing the vector space axioms (cf. Example 2.1).
Figure 6 gives the rules for lists, (head) and (tail).
Figure 7 deals with the vector space structure implementing a directed version of the vector space axioms. The direction is chosen in order to yield a canonical form [6].
Figure 8 are the rules to implement the castings. The idea is that does not distribute with respect to +, unless a casting allows such a distribution. This way, the types B  S(B) and S(B  B) are different. Indeed, 0  ( 0 + 1 ) have the first type but not the second, while 0  0 + 0  1 have the second type but not
the first. This way, the first type give us the information that the state is separable, while the second type do not. We can choose to take the first state as a pair of qubits forgetting the separability information, by casting its type, in the same way as in certain programming languages an integer can be casted to a float (and so, forgetting the information that it was indeed an integer and not any float).
Figure 9 gives the rule for the projective measurement with respect to the basis
{|0⟩ , |1⟩}. In this rule, we use the following notations:

[α.]t may be either t or α.t j ≤ m
|k⟩ = |b1⟩×· · ·× |bj⟩ where b1 ... bj is the binary representation of k



Fig. 8: Rules for castings ⇑r and ⇑l

Fig. 9: Rule for the projection


|φk⟩ =
iΣ∈Tk ,⎝ Σ

αi
r∈Tk |αr|
2 ⎞⎠

h=Yj+1

|bhi⟩

Σ	|αi|2
Tk = {i ≤ n | |b1i⟩×· · ·× |bji⟩ = |k⟩}

This way, pk |k⟩× |φk⟩ is the normalized k-th projection of the term.
Finally, Figure 10 give the contextual rules implementing the call-by-value and call-by-name strategies.
Example 2.3 The	term	λx:B.x		x		does	not	represent	a	 cloning machine,	but	a		CNOT		with	an		ancillary		qubit	0 .		Indeed,
(linα)

(λx:B.x × x) √1 .(|0⟩ + |1⟩) −→r
(lin+)
−→
√1 .(λx:B.x × x)(|0⟩ + |1⟩)
√1 .((λx:B.x × x) |0⟩ + (λx:B.x × x) |1⟩)

−→ √1 .(|0⟩× |0⟩ + (λx:B.x × x) |1⟩)
−→ √1 .(|0⟩× |0⟩ + |1⟩× |1⟩)


Fig. 10: Contextual rules The type derivation is as follows:

	 Ax		 Ax
x : B ▶ x : B	x : B ▶ x : B ×I
Ax|0⟩
▶ |0⟩ : B	S
Ax|1⟩
▶ |1⟩ : B	S

x : B ▶ x × x : B2	⇒
▶ λx:B.x × x : B ⇒ B2
▶ |0⟩ : S(B)	▶ |1⟩ : S(B) +I
  ▶ |0⟩ + |1⟩ : S(B)	 α

SI
▶ λx:B.x × x : S(B ⇒ B2)
▶ √1 .(|0⟩ + |1⟩): S(B)
I

⇒ES

▶ (λx:B.x × x) √1 .(|0⟩ + |1⟩): S(B2)
Example 2.4 The term π2 measures the first two qubits of its argument (in Ex- ample 3.7 we give a more detailed explanation of its reduction):
π (|001⟩ + 2. |110⟩ + 3. |000⟩) (proj) 10 00⟩× ( √1  . |1⟩ + √3  . |0⟩)   4 |11⟩× (1. |0⟩)
The typing derivation is the following:

  	  



  
▶ |0⟩ : B  ▶ |0⟩ : B  ▶ |1⟩ : B ×
▶ |001⟩ : B3


▶ |1⟩ : B  ▶ |1⟩ : B  ▶ |0⟩ : B ×
▶ |110⟩ : B3


▶ |110⟩ : S(B3)

▶ 2. |110⟩ : S(B3)
▶ |0⟩ : B  ▶ |0⟩ : B  ▶ |0⟩ : B ×
▶ |000⟩ : B3


▶ |000⟩ : S(B3)

▶ 3. |000⟩ : S(B3)

▶ |001⟩ : S(B3)
▶ 2. |110⟩ + 3. |001⟩ : S(B3)
▶ |001⟩ + 2. |110⟩ + 3. |001⟩ : S(B3)


▶ π2(|001⟩ + 2. |110⟩ + 3. |001⟩): B2 × S(B)

Example 2.5 A Hadamard gate can be implemented by H = λx : B.x?|−⟩·|+⟩, where |+⟩ = √1 . |0⟩ + √1 . |1⟩ and |−⟩ = √1 . |0⟩− √1 . |1⟩. Therefore, H : B ⇒ S(B)
and we have H |0⟩ −→∗ |+⟩ and H |1⟩ −→∗ |−⟩.
Correctness has been established in previous works for slightly different versions of Lambda- , except for the case of confluence, which have only been proved for Lineal. Lineal can be seen as an untyped fragment without several constructions (in particular, without πj). The proof of confluence for Lambda- is delayed to future work, using the development of probabilistic confluence from [10]. The proof

of Subject Reduction and Strong Normalization are straightforward modifications from the proofs of the different presentations of Lambda-S.
Theorem 2.6 (Confluence of Lineal, [6, Thm. 7.25]) Lineal, an untyped frag- ment of Lambda-S, is confluent.	2
Theorem 2.7 (Subject reduction on closed terms, [9, Thm. 2]) For any closed terms t and u and type A, if t −→ ¨i piui and ▶ t : A, then ▶ ¨i piui : A.  2
Theorem 2.8 (Strong normalization, [18, Thm. 5.16]) If Γ t : A then t is strongly normalizing.	2
3	Denotational semantics
Even though the semantic of this article is about particular categories i.e. the cat- egory of sets and the category of vector spaces, from the start our approach is categorical in an abstract way. The idea is that the concrete situation exposed in this article will pave the way to a more abstract formulation, and that is why we give the constructions as abstract as general as possible. A more general treatment, using a monoidal adjunction between a Cartesian closed category and a monoidal category with some extra conditions, remains a topic for future publication.
Definition 3.1 A concrete categorical model for Lambda- is given by the following data:
A monoidal adjunction

(Vec, ⊗,I)
where
Set is the category of sets with 1 as a terminal object. Vec is the category of vector spaces over C, in which I = C.
S is the functor such that for each set A, S(A) is the
vector space whose vectors are the formal finite linear

(S,m)	E	(U,n)
combinations of the elements of A with coefficients in C, and given a function f : A → B we define S(f ) : S(A) → S(B) by evaluating f in A.

(Set, ×, 1)
U is the forgetful functor such that for each vector space V , U (V ) is the underlying set of vectors in V and for each linear map f , U (f ) forgets of its linear property.
· m is a natural isomorphism defined by
mAB : S(A) ⊗ S(B) → S(A × B)

( Σ αaa) ⊗ ( Σ βbb) '→	Σ	αaβb(a, b)

a∈A
b∈B
(a,b)∈A×B

· n is a natural transformation defined by nAB : U (V ) ×
U (W ) → U (V ⊗ W ) such that (v, w) '→ v ⊗ w.
There is a subcategory of Vec such that for every morphism f : V → W one associates a morphism f† : W → V , called the dagger of f , such that for all

f : V → W and g : W → U we have
Id†V = IdV	(g ◦ f )† = f† ◦ g†	f†† = f
A Kleisli category defined with the following monad, called the distribution monad, (D, ηˆ, μˆ):
n	n
D : Set → Set	D(A)= {Σ piχai | Σ pi = 1, ai ∈ A, n ∈ N}
where χa is the characteristic function of a, and ηˆ and μˆ are defined as follows:
ηˆ : A → D(A)	μˆ : D(D(A)) → D(A)
n	n  mi

a '→ 1χa
Σ piχ mΣi	'→ Σ Σ piqijχaij


Remark 3.2
i=1
(
j=1
qij χaij )
i=1 j=1

For dealing with the probabilistic effect of the measurement our semantics requires the notion of a distribution monad (see [13, 16]). In order to give a more abstract categorical description we consider the Kleisli category given by this monad where a morphism f : A  B in the Kleisli category is really a morphism f : A  D(B) in the category Set and corresponds to a computation of type B.
There exists an object B and maps i1, i2 in Set such that for every t : 1  A and r : 1  A, here exists a unique map [t, r] such that the following diagram commutes

1	i1
B	i2	1
A
This object B is the Boolean set, and such a map will allow us to interpret the if con- struction (Definition 3.5).

There exists a map +: US(A)	US(A)	US(A) in Set, given by (a, b)	a + b
in which we use the sum defined in S(A).
To have an adjunction means that each function g : A → U (V ) extends to a unique
f : S(A)	V	f (	i αixi)=	i αig(xi)
that is, formal linear combinations in S(A) to actual linear combinations in V
(see [15] for details).
For every A  Set , Vec(I, S(A)) is an abelian group with the sum defined point-wise.
Set is a Cartesian closed category where ηA is the unit and εA is the counit of A [A, ], from which we can define the curryfication (curry) and un- curryfication (uncurry) of any map.
The adjunction in Definition 3.1 gives rise to a monad (T, η, μ) in the category Set, where T = US, η : Id → T is the unit of the adjunction, and using the counit ε, we obtain μ = U εS : TT → T , satisfying unity and associativity laws (see [15]).

Definition 3.3 Types are interpreted in the category Set, as follows:
 B) = B   Ψ ⇒ A) = Ψ) ⇒ A)   S(A)) = US A)   Ψ × Φ) = Ψ) × Φ)
Remark 3.4 To avoid cumbersome notation, we will use the following convention: We write directly US(A) for S(A) = US( A ) and A for A , when there is no ambiguity.
Before giving the interpretation of typing derivation trees in the model, we need to define certain maps which will serve to implement some of the constructions in the language.
To implement the if construction we define the following map.
Definition 3.5 Given t, r ∈ [Γ, A] there exists a map B ft,r [Γ, A] in Set defined
by ft,r = [tˆ, rˆ] where tˆ : 1 → [Γ, A] and rˆ : 1 → [Γ, A] ar−e→given by tˆ = λx.t and
sˆ = λx.s. Concretely this means that i1( ) '→ t and i2( ) '→ r.
Example 3.6 Consider t = i1 and r = i2, with t, r	[1, B], where B =
i1( ), i2( ) .  To make the example more clear, let us consider i1( ) = 0  and
ft,r
i2( ) = |1⟩, hence B = {|0⟩ , |1⟩}.  The map B −→ [1, B] in Set is defined by
ft,r = [λx.i1, λx.i2], where λx.ik : 1	[1, B], for k = 1, 2. Therefore, we have the
following commuting diagram

1	i	B	i	1
f
[1, B]
Hence, we have
ft,r |0⟩ = ft,r(ii(٨)) = (ii ◦ ft,r)٨ = (λx.i1)٨ = i1 = t ft,r |1⟩ = ft,r(i2(٨)) = (i2 ◦ ft,r)٨ = (λx.i2)٨ = i2 = r
Therefore, ft,r is the map |0⟩ '→ t and
|1⟩ '→ r.


A projection πjk acts in the following way: first it projects the first j components of its argument, an n-dimensional vector, to the basis vector k in the vector space of dimension j, then it renormalizes it, and finally it factorizes the first j compo- nents. Then, the projection πj takes the probabilistic distribution between the 2j projectors πjk, each of these probabilities, calculates from the normalized vector to be projected.
Example 3.7 Let us analyse the Example 2.4:
π (|001⟩ + 2. |110⟩ + 3. |000⟩) (proj) 10 00⟩× ( √1  . |1⟩ + √3  . |0⟩)   4 |11⟩× (1. |0⟩)
We can divide this in four projectors (since j = 2, we have 22 projectors), which are taken in parallel (with the symbol  ). The four projectors are: π2,00, π2,01, π2,10 and π2,11. In this case, the probability for the projectors π2,01 and π2,10 are 0, and hence these do not appear in the final term.
The projector π2,00 acts as described before: first it projects the first 2 compo- nents of |ψ⟩ to the basis vector |00⟩, obtaining |001⟩ + 3. |000⟩. Then it renormalizes it, by dividing it by its norm, obtaining √1  . |001⟩ + √3  . |000⟩. Finally, it factorizes

the vector, obtaining |00⟩× ( √1  . |1⟩ + √3  . |0⟩). Similarly, the projector π2,11 gives

|11⟩× (1. |0⟩).
10	10

Finally, the probabilities to assemble the final term are calculated by p0 =

|1|2+|3|2
|1|2+|2|2+|3|2
= 10 and p1
=	|2|2	 4
|1|2+|2|2+|3|2	14

Categorically, we can describe the operator πjk (Definition 3.11) by the compo- sition of three arrows: a normalizing arrow Norm (Definition 3.8), a projector arrow to the k basis vector, and a factorizing arrow ϕj (Definition 3.9). Then, the pro- jection πj (Definition 3.14) maps a vector to the probabilistic distribution between the 2j basis vectors |k⟩, using a distribution map (Definition 3.12).
In the following definitions, if |ψ⟩ is a vector of dimension n, we write |ψ⟩ : I →
S(Bn) to the map 1 '→ |ψ⟩.
Definition 3.8 The normalizing arrow Norm is defined as follows:


Norm : US(Bn) → US(Bn)	|ψ⟩ '→
⎧⎪⎨ ,

|ψ⟩
†
(|ψ⟩ ◦|ψ⟩)(٨)
if |ψ⟩ /= 0

|0⟩	otherwise
Definition 3.9 The factorizing arrow ϕj is defined as any arrow making the fol- lowing diagram commute:

Bj × US(Bn−j)
Id
Bj × US(Bn−j)
η×Id
US(Bj) × US(Bn−j)


ϕj
 U (S(Bj) ⊗ S(Bn−j))
U(m)
US(Bn)= US(Bj × Bn−j)

Example 3.10 For example, take ϕj as the following map:
ϕj : US(Bn) → Bj × US(Bj−n)


a '→
⎧⎪⎨ j

|bh⟩× 
n i=1

αi.
n h=j+1

|bih⟩

if a =
n i=1

αi.

j

h=1

|bh⟩× 
n h=j+1

|bih⟩

|0⟩n	otherwise
Definition 3.11 For each k = 0,..., 2j	1, the projection to the k basis vector,
πjk, is defined as any arrow making the following diagram commute:
	†
US(Bn) ∼= U (S(B)⊗n) U((|k⟩◦|k⟩ )⊗I) U (S(B)⊗n) ∼= US(Bn)

πjk

Bj × US(Bn−j)	ϕ
Norm
US(Bn)

where the isomorphism US(Bn) ∼= U (S(B)⊗n) is obtained by composing n	1 times the mediating arrow m and then applying the functior U .
The following distribution map will allow to assemble the final distribution of projections in Definition 3.14.

Definition 3.12 Let {pi}n	be a set with pi ∈ [0, 1], and Σn
pi = 1. Then, we


define d{pi}i as the arrow d{pi}i
: An → D(A) such that (a1,..., an) '→ Σn	piχa .
i

Example 3.13 Consider d{ 1 , 1 , 1 } : B3 → D(B3) defined by d{ 1 , 1 , 1 }(b1 × b2 × b3)= 

1 χb  + 1 χb  + 1 χb .
2 3 6
2 3 6

2	1	3	2	6	3
Then, for example, d{ 1 , 1 , 1 } |101⟩ = 1 χ|1⟩ + 1 χ|0⟩ + 1 χ|1⟩.
Definition 3.14 πj is the arrow πj : US(Bn) → D(Bj ×US(Bn−j)) such that |ψ⟩ '→

Σ2j −1 p χ
, where p
= Norm(|ψ⟩)† ◦ P
Norm(|ψ⟩) with P
= (|k⟩◦ |k⟩†) ⊗ Id

and πjk is the arrow given in Definition 3.11.
Example 3.15 Consider the set B2 and the vector space S(B2). We can describe the projection π1 as the map π1 : US(B2) → D(B × US(B)) such that |ψ⟩ '→ p0χπ10|ψ⟩ + p1χπ11|ψ⟩, where, if |ψ⟩ = α1. |00⟩ + α2. |01⟩ + α3. |10⟩ + α4. |11⟩, then

p = √|α1|2+|α2|2
and p
= √|α3|2+|α4|2 .

0	4
i=1
1
|αi|2
4
i=1
|αi|2

The Norm arrow is the arrow Norm : US(B2) → US(B2) such that


	α1	

	α2	

	α3	

	α4	

α1. |00⟩+α2. |01⟩+α3. |10⟩+α4. |11⟩ '→ qΣ4
|α |2 . |00⟩+ qΣ4
|α |2 . |01⟩+ qΣ4
|α |2 . |10⟩+ qΣ4
|α |2 . |11⟩


The factorisation arrow is the arrow ϕ1 : US(B2) → B × US(B) such that



α1. |00⟩ + α2. |01⟩ + α3. |10⟩ + α4. |11⟩ '→
|1⟩× (α3. |0⟩ + α4. |1⟩) if α1 = α2 =0 
,,, |00⟩	otherwise

Finally, π10 and π11 are defined as π10 : US(B2) → B × US(B) and π11 :
US(B2) → B × US(B) such that

π10 = ϕ1 ◦ Norm ◦ U (|0⟩◦ |0⟩† ⊗ Id)	π11 = ϕ1 ◦ Norm ◦ U (|1⟩◦ |1⟩† ⊗ Id)
We write (US)m(A) for US(...US(A)), where m > 0 and A = US(B). The arrow sum on (US)m(A) will use the underlying sum in the vector space S(A). Therefore, in order to implement this sum, we need the following map.
Definition 3.16 The map gk : (US)k+1(A)  (US)k+1(A)   (US)k(US(A)
US(A)) is defined by
gk = (US)k−1U (m) ◦ (US)k−1(n) ◦ (US)k−2U (m) ◦ (US)k−2(n) ◦· · · ◦ U (m) ◦ n
Example 3.17 We can define the sum on (US)3(A) (US)3(A) by using the sum on S(A) as g2 (US)2(+), where g2 = USU (m) US(n) U (m) n. This gives the following diagram


USUSUS(A) × USUSUS(A)
sum
n	U (m)
U(SUSUS(A) ⊗ SUSUS(A))	US(USUS(A) × USUS(A))
US(n)

USUSUS(A)
USUS(+)
USUS(US(A) × US(A))
USU (m)
USU(SUS(A) ⊗ SUS(A))

Using all the previous definitions, we can finally give the interpretation of a type derivation tree in our model. If Γ ▶ t : A with a derivation T , we write it generically

T as Γ —→ A. On the following definition, we write S m > 0 and A /= S(B).
m(A) for S(... S(A)), where

Definition 3.18 If T is a type derivation tree, we define T ) inductively as follows,
r B	Ax = ΓB × Ψ !×Id 1 × Ψ ≈ Ψ where Id is the identity in Set

rΓB

▶ 0S(A) : S(A)
Ax0  = ΓB  !
λx.0
−→ US(A)

rΓB

▶ |0⟩ : B
Ax|0⟩  = ΓB  !
λx.|0⟩
1 −→ B

rΓB

▶ |1⟩ : B
Ax|1⟩  = ΓB  !
λx.|1⟩
1 −→ B

  Γ ▶ t : Sm(A)


t	m	(US)m−1 U (λ)
m−1

Γ ▶ α.t : S
(A)
(US)m−1 U (Id⊗α)

m−1
(US)m−1 U (λ−1 )	m

−→	(US)
U(S(A) ⊗ I)
−→	(US) (A)

 Γ, ΞB ▶ t : Sm(A)  Δ, ΞB ▶ r : Sm(A)




B Id×δ

B	B Id×σ×Id	B	B

Γ, Δ, Ξ
▶ t + r : S
(A)
t×r	m
m	gm−1
m−1

−→ (US) (A) × (US) (A) −→ (US)
(US(A) × US(A))

(US)m−1 (+)	m


  Γ ▶ t : A  SI  =Γ t

η
A	US(A)
−→	(US)
(A)

Γ  t : S(A)
	Γ ▶ t : Sk (Bn)
−→	−→
	t



μk−1	πj

Γ ▶ πj t : Bj × S
Bn−j
  SE
=Γ −→ (US)k (Bn) −→ US(Bn) −→ D(Bj × S
Bn−j )

Γ ▶ ?t·r : B ⇒ A	−→


⇒I
Γ ▶ λx:Ψ.t :Ψ ⇒ A
=Γ −→ [Ψ, Γ × Ψ] −→ [Ψ, A]

Δ, ΞB ▶ u :Ψ Γ, ΞB ▶ t :Ψ ⇒ A


Δ, Γ, ΞB ▶ tu : A
=Δ × Γ × Ξ
u×t
Id×δ
−→ Δ × Γ × Ξ × Ξ
εΨ
Id×σ×Id
−→  Δ × Ξ
× Γ × Ξ

−→ Ψ × [Ψ, A] −→ A

 Δ, ΞB ▶ u : S(Ψ) Γ, ΞB ▶ t : S(Ψ ⇒ A)

B Id×δ

B	B Id×σ×Id	B	B

Δ, Γ, ΞB ▶ tu : S(A)
⇒ES
=Δ × Γ × Ξ
u×t
−→ Δ × Γ × Ξ × Ξ
n
−→  Δ×Ξ ×Γ×Ξ

−→ US(Ψ) × US([Ψ, A]) −→ U(S(Ψ) ⊗ S([Ψ, A]))

U (m)
−→ US(Ψ × [Ψ, A])
US(εΨ)
−→  US(A)

 Γ, ΞB ▶ t :Ψ Δ, ΞB ▶ u :Φ 

B Id×δ

B	B Id×σ×Id	B

B t×u

Γ, Δ, ΞB ▶ t × u :Ψ × Φ
×I  =Γ × Δ × Ξ −→ Γ × Δ × Ξ × Ξ	−→ Γ × Ξ × Δ × Ξ −→ Ψ × Φ

Γ ▶ t : Bn

Γ ▶ head t : B

×Er
 =Γ t
−→ B  where head is the projector of the first component in Set

Γ ▶ t : Bn
Γ ▶ tail t : Bn−1
×El
=Γ t  B
tail
−→ B
n−1
where tail is the projector of the n − 1 last components

 Γ ▶ t : S(S(Ψ) × Φ) ⇑	t
U (Id×η)
US(n)

Γ ▶⇑r
t : S(Ψ × Φ)
r  =Γ −→ US(US(Ψ) × Φ)
USU (m)
−→  US(US(Ψ) × US(Φ))
μ
−→ US(U(S(Ψ) ⊗ S(Φ)))

−→  USUS(Ψ × Φ) −→ US(Ψ × Φ)

 Γ ▶ t : S(Ψ × S(Φ)) ⇑  =Γ t
U (η×Id)	US(n)
US(Ψ × US(Φ))	US(US(Ψ) × US(Φ))	US(U(S(Ψ) ⊗ S(Φ)))

Γ ▶⇑Æ
l
t : S(Ψ × Φ)
−→	−→	−→
USU (m)	μ

Σ		−→  USUS(Ψ × Φ) −→ US(Ψ × Φ)
		
Proposition 3.19 (Independence of derivation) If Γ ▶ t : A can be derived with two diﬀerent derivations T and T j, then T ) = T j)

Proof. Without taking into account rules E, ES and SI, the typing system is syntax directed. In the case of the application (rules E and ES), they can be interchanged only in few specific cases.
Hence, we give a rewrite system on trees such that each time a rule SI can be applied before or after another rule, we chose a direction to rewrite the three to one of these forms. Similarly, we chose a direction for rules  E and  ES. Then we prove that every rule preserves the semantics of the tree. This rewrite system is clearly confluent and normalizing, hence for each tree T we can take the semantics of its normal form, and so every sequent will have one way to calculate its semantics: as the semantics of the normal tree.	2
Remark 3.20 Proposition 3.19 allows us to write the semantics of a sequent, in- dependently of its derivation. Hence, from now on, we will use Γ t : A , without ambiguity.
Lemma 3.21 (Substitution) If Γj,x : Ψ, Γ t : A and r : Ψ, then the following diagram commutes:

Γj × Γ
≈
(r/x)t
 A
t

Γj × 1 × Γ Id×r×Id Γj × Ψ × Γ
That is, Γj, Γ ▶ (r/x)t : A) = Γj,x : Ψ, Γ ▶ t : A) ◦ ( ▶ r : Ψ) × Id).
Proof. By induction on the derivation of Γj,x : Ψ, Γ ▶ t : A.	2
Theorem 3.22 (Soundness) If ▶ t : A, and t —→ r, then ▶ t : A) = ▶ r : A).
Proof. By induction on the rewrite relation, using the first derivable type for each term.	2

In order to prove adequacy (Theorem 3.26), we use an adaptation to Lambda- of Tait’s proof for strong normalization.

Definition 3.23 Let A, B be sets of closed terms. We define the following operators on them:

Closure by antireduction: A = t t	∗ r, with r	A and FV (t)=	.
Closure by parallelism: A  = { i piti | ti ∈ A and	i pi = 1}
Product: A × B = {t × u | t ∈ A and u ∈ B}.
Arrow: A ⇒ B = {t | ∀u ∈ A, tu ∈ B}.
Span: SA = {Σi αiri | ri ∈ A} where αr is a notation for α.r when α /= 1, or 1.r

Error: EA = A ∪ {error}, where error is any term containing a subterm πj0S(Bn).

The set of computational closed terms of type A (denoted CA), is defined by


CB = {|0⟩ , |1⟩ , error}
CA×B = E(CA × CB)
CΨ⇒A = E(CΨ ⇒ CA)	
CS(A) = ESCA ∪ {0S(B) | S(B) ≤ S(A)}

Where ≤ is defined as S(S(A)) ≤ S(A) and A ≤ S(A).
A substitution σ is valid with respect to a context Γ (notation σ ▶ Γ) if for each
x : A ∈ Γ, σx ∈ CA.
Lemma 3.24 For any type A, we have error ∈ CA.
Proof. By induction on A.	2
Lemma 3.25 If Γ ▶ t : A and σ ▶ Γ, then σt ∈ CA.
Proof. By induction on the derivation of Γ ▶ t : A.	2
Theorem 3.26 (Adequacy) If ▶ t : B = ▶ v : B , where v ∈ {|0⟩ , |1⟩}, then either t —→∗ v or t —→∗ error.
Proof. By Lemma 3.25, t ∈ CB = {|0⟩ , |1⟩ , error} , therefore, t —→∗ ¨n	piri where
ri ∈ {|0⟩ , |1⟩ , error}.
Since ▶ t : B = ▶ v : B = λx. |0⟩ or λx. |1⟩, we have that n = p1 =1 and so
t —→∗ v, or t —→∗ error.	2

4	Conclusion
In this paper we have given a concrete categorical semantics of Lambda- and proved that it is sound (Theorem 3.22) and adequate (Theorem 3.26). Such a semantics highlights the dynamics of the calculus: The algebraic rewriting (linear distribution, vector space axioms, and typing casts rules) emphasize the standard behaviour of vector spaces, and the natural transformation n takes these arrows from the Cartesian category Set to the tensorial category Vec, where such a behaviour occur naturally, and then are taken back to the Cartesian realm with the natural transformation m. This way, rules such as (lin+): t(u + v) —→ tu + tv, are simply considered as U (m) ◦n producing (u + v, t) '→ (u, t)+(v, t) in two steps: (u + v, t) '→ (u + v) ⊗t = u⊗t + v⊗t '→ (u, t)+(v, t), using the fact that (u + v) ⊗t = u⊗t + v⊗t
Vec
We have constructed a concrete mathematical semantic model of Lambda- based on a monoidal adjunction with some extra conditions. However, the con- struction depends crucially on inherent properties of the categories of set and vector spaces. In a future work we will study the semantics from a more abstract point of view. Our approach will be based on recasting the concrete model at a more ab- stract categorical level of monoidal categories with some axiomatic properties that are now veiled in the concrete model. Some of these properties, such as to consider an abstract dagger instead of an inner product, were introduced in the concrete

model from the very beginning, but others are described in Remark 3.2 and Defi- nitions 3.5, 3.8, 3.9, 3.11, 3.12, and 3.14. Another question we hope to address in future work is the exact categorical relationship between the notion of amplitude and probability in the context of the abstract semantics. While some research has been done in this topic (see, for example, [2, 19]) it differs from our point of view in some important aspects: for example to consider a notion of abstract normalization as primitive.

References
Abramsky, S., Computational interpretations of linear logic, Theoretical Computer Science 111 (1993),
pp. 3–57.
Abramsky, S. and B. Coecke, A categorical semantics of quantum protocols, in: Proceedings of the 19th Annual IEEE Symposium on Logic in Computer Science (LICS) (2004), pp. 415–425.
Altenkirch, T. and J. Grattage, A functional quantum programming language, in: Proceedings of the 20th Annual IEEE Symposium on Logic in Computer Science (LICS) (2005), pp. 249–258.
Arrighi, P. and A. Díaz-Caro, A System F accounting for scalars, Logical Methods in Computer Science
8(1:11) (2012).
Arrighi, P., A. Díaz-Caro and B. Valiron, The vectorial lambda-calculus, Information and Computation
254 (2017), pp. 105–139.
Arrighi, P. and G. Dowek, Lineal: a linear-algebraic lambda-calculus, Logical Methods in Computer Science 13(1:8) (2017).
Assaf, A., A. Díaz-Caro, S. Perdrix, C. Tasson and B. Valiron, Call-by-value, call-by-name and the vectorial behaviour of the algebraic λ-calculus, Logical Methods in Computer Science 10(4:8) (2014).
Benton, N., A mixed linear and non-linear logic: Proofs, terms and models, in: L. Pacholski and
J. Tiuryn, editors, Computer Science Logic (CSL 1994), Lecture Notes in Computer Science 933
(1994), pp. 121–135.
Díaz-Caro, A. and G. Dowek, Typing quantum superpositions and measurement, in: Theory and Practice of Natural Computing (TPNC 2017), Lecture Notes in Computer Science 10687 (2017), pp. 281–293.
Díaz-Caro, A. and G. Martínez, Confluence in probabilistic rewriting, Preproceedings of LSFA 2017. To appear in ENTCS. Preprint at arXiv:1708.03536. (2017).
Díaz-Caro, A. and B. Petit, Linearity in the non-deterministic call-by-value setting, in: L. Ong and
R. de Queiroz, editors, Logic, Language, Information and Computation, Lecture Notes in Computer Science 7456 (2012), pp. 216–231.
Girard, J.-Y., Linear logic, Theoretical Compututer Science 50 (1987), pp. 1–102.
Giry, M., A categorical approach to probability theory, in: Categorical Aspects of Topology and Analysis, Lecture Notes in Mathematics 915 (1982), pp. 68–85.
Green, A. S., P. L. Lumsdaine, N. J. Ross, P. Selinger and B. Valiron, Quipper: a scalable quantum programming language, ACM SIGPLAN Notices (PLDI’13) 48 (2013), pp. 333–342.
Lane, S. M., “Categories for the Working Mathematician,” Springer, 1998, 2 edition.
Moggi, E., Computational lambda-calculus and monads, Technical Report ECS-LFCS-88-66, Lab. for Foundations of Computer Science, University of Edinburgh (1988).
Pagani, M., P. Selinger and B. Valiron, Applying quantitative semantics to higher-order quantum computing, ACM SIGPLAN Notices (POPL’14) 49 (2014), pp. 647–658.
Rinaldi, J. P., “Demostrando normalización fuerte sobre una extensión cuántica del lambda cálculo,” Master’s thesis, Universidad Nacional de Rosario (2018).


Selinger, P., Dagger compact closed categories and completely positive maps, in: 3rd International Workshop on Quantum Programming Languages (QPL 2005), Electronic Notes in Theoretical Computer Science 170, 2007, pp. 139–163.
Selinger, P. and B. Valiron, A lambda calculus for quantum computation with classical control, Mathematical Structures in Computer Science 16 (2006), pp. 527–552.
Vaux, L., The algebraic lambda calculus, Mathematical Structures in Computer Science 19 (2009),
pp. 1029–1059.
Zorzi, M., On quantum lambda calculi: a foundational perspective, Mathematical Structures in Computer Science 26 (2016), pp. 1107–1195.
