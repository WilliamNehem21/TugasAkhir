

Electronic Notes in Theoretical Computer Science 259 (2009) 165–176
www.elsevier.com/locate/entcs

Data Refinement with Probability in Mind
T.M. Rabehaja1 ,2	J.W. Sanders1 ,3
International Institute for Software Technology United Nations University
Macao, SAR China

Abstract
The definition of data refinement between datatypes is expressed in terms of all programs that invoke procedures of the types. As a result it is laborious to check. Simulations provide sound conditions that, being ‘static’, facilitate checking; but then their soundness is important. In this paper we extract a technique from the heart of the theory and show it to be equivalent to data refinement; it plays a key role in establishing properties about simulations in any of the computational models. We survey the difficulties confronting the theory when the procedures and invoking programs may contain probabilistic choices, and show that then each of the two simulation conditions is alone not complete as a rule for data refinement, even if the datatypes are deterministic (in contrast to the standard case). The last part of the paper discusses work in progress.
Keywords: Data refinement, simulations, probability, incompleteness


Introduction
The results in this paper arose from an investigation into data refinement in the context of probabilistic programs. Here they have been grouped into results that do not concern probability and those that do.

Standard data reﬁnement
For standard (i.e. non probabilistic) programs the relational model of Hoare et al.
[6] consists of binary relations (between initial and final states) made ‘healthy’ to ensure that nontermination and nondeterminism interact so as to provide a sound development methodology. For example a nondeterministic choice, from a given

1 The authors acknowledge assistance from the Macao Science and Technology Development Fund under the PEARL project, grant number 041/2007/A3.
2 Email: tahiry@iist.unu.edu
3 Email: jeff@iist.unu.edu

1571-0661 © 2010 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2009.12.023

initial state, between nontermination and termination in a given subsequent state is deemed equivalent to nontermination
abort H P  = abort .

With such a methodological principle, error in the form of nontermination occurs only if it is the only option: the design calculus is ‘pessimistic’ and hence is reliable. A simple semantic model is obtained by augmenting program states with a ‘virtual’ state ⊥. Then the corresponding healthiness condition for the relational
denotation [P ]R of computation P is, using infix notation for binary relations,
x [P ]R ⊥ ⇒	∀y · x [P ]R y. 

(Although it is not our concern here, we recall that the setting for a systematic study of the relationship between laws and semantic healthiness conditions is ‘Uni- fying Theories of Programming’ [7].) Refinement P ± Q between computations is modelled as containment of semantic relations: [P ]R ⊇ [Q]R.
The more comprehensive predicate-transformer model of Dijkstra [1] contains the relational model via the Galois embedding wp: for relational denotation [P ]R, postcondition q and initial state x,
wp.[P ]R.q.x := ∀y · x [P ]R y ⇒ y /= ⊥∧ q.y .

Notice that termination is ‘built in’ to that (total correctness) definition which as a result does not need a virtual element. Refinement between computations is captured by the lifted implication ordering; writing [P ]T for the transformer denotation of computation P ,
[P ]T ± [Q]T := ∀q, x · [P ]T .q.x ⇒ [Q]T .q.x .

Such refinement between computations suffices for the incremental derivation of implementations from specifications over the same state space. But to incorporate data representations, ‘data refinement’ is required. One datatype is reﬁned by an- other iff use (by method invocation) of the former by any program P is refined by that program P ' which instead uses the corresponding methods of the second type. Though that definition is theoretically simple, its verification requires an induction over all ‘uses’ of the type. So simulation conditions are used in practice [14].
In the relational model downwards and upwards simulations are readily shown to be sound methods for data refinement. The reason is that those definitions ‘encapsulate’ the induction required by the definition of data refinement. In Section 2 we study techniques that facilitate the proof of properties of data refinement by bridging the gap between the ‘dynamic’ definition of data refinement and the ‘static’ definition of simulations. A condition is extracted from the heart of the theory and shown to be equivalent to data refinement. It appears to play a key role in establishing properties of simulations in any of the computational models.

In the relational model, neither type of simulation by itself provides a complete rule for data refinement, although together they do so [5,14].
In the transformer model the two forms of simulation are again sound, but this time upwards simulation is by itself complete. The reason is that downwards simulation is able to be expressed by a Galois connection. That is the basic technique used here. The proof in the relational setting that the two simulations generate all data refinements reduces in the transformer setting to the stronger statement that a composition of upwards simulations (again an upwards simulation) does so.


Probabilistic data reﬁnement
Probabilistic programs consist of standard programs augmented with a binary choice
P r⊕Q which chooses P with probability r and Q with the deficit probability r := 1−
r. In that setting, the counterpart of the relational model is the distributional model of He et al. [4] and that of the transformer model is the expectation-transformer model of Morgan et al. [12]. Again there is a Galois connection between them [9].
In the probabilistic setting, datatype procedures and invoking programs all may contain probabilistic choices. The definition of data refinement is similar but now simulation computations are in general probabilistic. For examples we refer to ‘the steam boiler’ in [9], Chapter 4 and to the proof of Theorem 3.
In Section 3 we consider data refinement for probabilistic programs. We begin by establishing structure on the spaces of simulations then show that in the distri- butional model, neither kind of simulation is alone complete for data refinement. Further progress is beset by the weakened laws of probabilistic programming. We conclude with a discussion.
The explicit contributions of the paper are:
A characterisation of data refinement, that spans the divide between the ‘static’ definition (of simulation) and its ‘dynamic’ role in achieving data refinement and so captures an essential proof technique.
A summary of the structures, in the probabilistic model, of the spaces of up- wards and downwards simulations. Those determine what can be said of data refinement in the probabilistic setting.
An example to show that in the distributional model of probabilistic programs, neither upwards nor downwards simulation is complete, even if the abstract datatype is deterministic. Approaches to the open question of completeness are discussed.


Data refinement
The topic of this section is standard (non-probabilistic) programs with the predicate- transformer model.

Preliminaries
The conjunctivity of standard programs x,
6y, z · x ; (y H z) = x ; y H x ; z	(1)
is a remarkably strong property, supporting the definition of a Galois connection (provided x terminates) in the predicate-transformer model.
Lemma 1 For any terminating computation x the function y '→ x ; y is universally
(±, ±)-junctive and so possesses an adjoint α.x satisfying
skip ± x ; α.x
α.x ; x ± skip
α.(x ; y)= α.y ; α.x .
The proof is routine, using the fact that the adjoint of a universally (±, ±)- junctive map is unique and the composition sp ◦ rp satisfies Lemma 1 where rp is the adjoint of wp and sp stands for the ‘strongest post-condition’ in the relational- transformer translation.
Data reﬁnement
Recall that a datatype T = (L; in, 0,fin) has type L of states, family 0 of named procedures (each, in general, with input and output), an initialisation in and a finalisation f in [5]. Each procedure O : 0 is assumed to be terminating. We let L denote the space of computations written in the guarded-command language, on some global state space which we leave implicit, that invoke procedures of type T . Datatypes T = (L; in, 0,fin) and T ' = (L'; in', 0',fin') are conformal iff the function O '→ O' from 0 to 0' is a signature-preserving bijection from 0 to 0'. If P : L invokes procedures from T , then P ' : L' denotes the program that corre-
spondingly invokes O' when P invokes O.
A datatype T is data-refined by a conformal type T ' iff
6P ∈L · in ; P ; f in ± in' ; P ' ; f in' .

Data reﬁnement characterised
In this section we use Lemma 1 to characterise data refinement in the predicate- transformer model, reasoning as follows. If P is a computation then [P ] denotes its semantic denotation, in this case a predicate transformer.
If P, Q : L are terminating uses of T then P ; Q is also a terminating use of T
for whose corresponding use P ' ; Q' of T ' we have
[in ; P ] ; [Q ; f in] ± [in' ; P '] ; [Q' ; f in']
$	monotonicity of ; and Lemma 1.ii.
α.[in' ; P '] ; [in ; P ] ; [Q ; f in] ± [Q' ; f in']
$	monotonicity of ; and Lemma 1.i.
α.[in' ; P '] ; [in ; P ] ± [Q' ; f in'] ; α.[Q ; f in] .


The left and right hand sides of the last refinement are functions, respectively, of P
and Q which we denote by I and F

I(P ) := α.[in' ; P '] ; [in ; P ]
F (Q) := [Q' ; f in'] ; α.[Q ; f in]
6P, Q : L · I(P ) ± F (Q) .
Equivalently I and F satisfy, with maximum H and minimum H taken pointwise in
L,
HI ± HF .	(2)
Therefore, with each pair (T, T ') of conformal datatypes is associated a pair (I, F ) of functions. We now see that refinement (2) is in fact strong enough to characterise data refinement between the types.
Theorem 1 For conformal datatypes T and T ', reﬁnement T ± T ' holds iff the pair (I, F ) of functions satisﬁes (2).
Proof. The forward implication has been established. For the converse, if P : L
then
I(skip) ± HI ± HF  ± F (P )
and so we reason
α.[in'] ; [in] ± [P ' ; f in'] ; α.[P ; f in]
$	monotonicity of ; and Lemma 1.ii.
α.[in'] ; [in ; P ; f in] ± [P ' ; f in']
$	monotonicity of ; and Lemma 1.i.
[in ; P ; f in] ± [in' ; P ' ; f in']
which completes the proof.	 
The following representation of (I, F ) indicates the relationship between data refinement and simulations.
α.[Q ; fin]
P	Q
in	fin
±

in'
α.[in' ; P ']	P
fin'
Q'

Fig. 1. Depiction of the pair (I, F ) of functions characterising data refinement.


Simulations
Recall the definitions of simulations. An upwards simulation between T and T ' is a continuous (nonhomogeneous and possibly nondeterministic) computation u with

initial state of type L' and final state of type L such that
in ± in' ; u	(3)
6O : 0· u ; O ± O' ; u	(4)
u ; f in ± f in' .	(5)
A downward (or forward ) simulation is defined dually without the requirement of being continuous. The set of upwards (respectively downwards) simulations between T and T ' is denoted usim(T, T ') (respectively dsim(T, T ')). A bisimulation is an element of bsim := usim ∩ dsim.
Upwards (and dually downwards) simulations are complete within the predicate transformer model [3,14]. In other words, the existence of a simulation is a necessary and sufficient condition for data-refinement. (By comparison, a combination of both kinds of simulation is required for completeness in the less comprehensive relational model.)
The pair (I, F ) enjoys further properties. For instance HI and HF bound up- wards simulation. For convenience we write [HI, HF ] for the set of functions satis- fying refinement (2) (with no intention to imply that it is totally ordered).
Lemma 2 If u ∈ usim(T, T ') then u ∈ [HI, HF ].
Proof. For any P : L
u ∈ usim(T, T ')
$
[in ; P ] ± [in' ; P '] ; u
$	monotonicity of ; and Lemma 1.ii.
α.[in' ; P '] ; [in ; P ] ± u
≡
I(P ) ± u, 
so HI ± u. The refinement u ± HF is analogous.	 
Theorem 1 in fact supplies the soundness of upwards simulations. Its converse is also of interest since then usim(T, T ')= [HI, HF ] and so in particular completeness in the predicate-transformer model is a simple consequence, since the last set is empty when HI ± HF does not hold. As we shall see, any such u satisfies the simulation laws (3) and (5) for initialisation and finalisation.
Lemma 3 If u ∈ [HI, HF ] then equations (3) and (5) hold.
Proof. For initialisation, [in'] ; u
±	u ± HI and definition of I
[in'] ; H{α.[in' ; P '] ; [in ; P ] | P ∈ L}
±	skip ∈L and associativity
([in'] ; α.[in']) ; [in]

±	Lemma 1.i.
[in] .
Similarly for finalisation,
u ; [f in]
±	u ± HF and definition of F
H{[P ' ; f in'] ; α.[P ; f in] | P ∈ L} ; [f in]
±	skip ∈L and associativity
[f in'] ; (α.[f in] ; [f in])
±	Lemma 1.ii.
[f in']
which completes the proof.	 
The upper bound HF has been shown [3] to be an upwards simulation. A similar proof shows HI ∈ usim(T, T ') (in particular, HI is well defined and sound).

Theorem 2 If T ± T ' then HI ∈ usim(T, T ').
Proof. By Theorem 1, HI is well defined and HI ± HF . Therefore HI satisfies equations (3) and (5). It remains to verify (4), which includes soundness. But
HI ; [P ]
=	definition of I
H{α.[in' ; Q'] ; [in ; Q] | Q ∈ L} ; [P ]
=	pointwise definition on transformers: (Ht).q := H(t.q)
H{α.[in' ; Q'] ; [in ; Q] ; [P ] | Q ∈ L}
±	Lemma 1.i.
H{[P '] ; α.[P '] ; α.[in' ; Q'] ; [in ; Q] ; [P ] | Q ∈ L}
=	Lemma 1.iii.
H{[P '] ; α.[in' ; Q' ; P '] ; [in ; Q ; P ] | Q ∈ L}
=	definition of I
H{[P '] ; I(Q ; P ) | Q ∈ L}
±	[P '] is monotonic and H{[P '].b | b ∈ B} ± [P ']. H B
[P '] ; H{I(Q ; P ) | Q ∈ L}
±	{P ; Q | P ∈ L} ⊆ L
[P '] ; H{I(Q) | Q ∈ L}
=
[P '] ; HI. 
The result follows by taking a procedure O ∈ 0 instead of P . On the other hand, using the expression of α as sp ◦ rp, one shows that α.t is universally disjunctive (in particular ±, ±- continuous) and then α.t ; t is also continuous for continuous

t. Therefore HI is continuous since for any bounded, ±-directed family (pi)i of predicates one shows a = HI.(Hipi)= Hi(HI.pi)= b by simply proving a ≤ q ≡ b ≤ q for any predicate q.	 
Does a similar result hold for downward simulation? The problem requires the existence of a dual adjoint map β satisfying
skip ± β.x ; x	and	x ; β.x ± skip
and so is a little delicate; it would imply that the pair (α, β) forms a Galois con- nection between the spaces (7 , ±) and (7 , ±). Thus it suffices to decide universal (±, ±)-junctivity of α. This is a current work.

Probabilistic data refinement
In this section we consider probabilistic computations by enlarging L to include the operator p⊕ for probabilistic choice. We study the extent to which the previous approach to data refinement applies, concluding with a negative result that is of interest also because it differs from the corresponding negative result in the standard case.
Spaces of simulations
An attempt to replay the previous approach to data refinement with probabilistic computations immediately confronts failure of identity (1): left distributivity fails
[9] and is replaced by
6x, y, z · x ; (y H z) ± x ; y H x ; z.	(6)
That is interesting because probabilistic choice p⊕ does not even appear there ex- plicitly. Inequality may be revealed, however, by considering an x that makes a fair choice (i.e. with 1 ⊕) between 0 or 1 to some variable, letting y be assignment
2
of 0 to a second variable and letting z be assignment of 1 to that second variable.
Straightforward reasoning then shows that the greatest expectation of the two vari- ables having the same value is on the left 0 and on the right 1 . Of course refinement in that law is to be expected by monotonicity, so that argument shows strictness.
We infer that nondeterministic choice is restricted so that it is unable to guess in advance the outcome of a probabilistic choice. Otherwise the right-hand side, with its immediate resolution of the nondeterministic choice, would be no more constrained than the left-hand side and equality would hold. At run time the resolution of nondeterminism is allowed to depend on only the computation history, which includes its present knowledge. Therefore, the map α is no longer well defined. In fact, it is defined only for conjunctive computations (i.e. those computations x satisfying (1)). That means the previous results characterising data refinement and bounding upwards simulations no longer hold, and other techniques are needed to study probabilistic data refinement.
We begin by estabilishing structure on the sets of simulations.

Lemma 4 The space usim(T, T ') of upwards simulations between datatypes T and T ' is stable under probabilistic choice p⊕. The space dsim(T, T ') of downwards simulations is stable under nondeterministic choice H.
Proof. For the first claim, if u, v : usim(T, T ') then properties (3), (4) and (5) must be established for the probabilistic choice u p⊕ v. We are allowed to use
x ; (y p⊕ z) ± x ; y p⊕ x ; z	(7)
(x p⊕ y) ; z = x ; z p⊕ y ; z	(8)
as well of course as other laws of probabilistic programming [9]. For u, v ∈ usim(T, T '), we reason as follows. For initialisation,
in
=	law P = P p⊕ P
in p⊕ in
±	Law (3) since u, v : usim(T, T ')
in' ; u p⊕ in' ; v
±	Law (7)
in' ; (u p⊕ v) . For invocation, (u p⊕ v) ; O
=	Law (8)
u ; O p⊕ v ; O
±	Law (4) since u, v : usim(T, T ')
O' ; u p⊕ O' ; v
±	Law (7)
O' ; (u p⊕ v) . For finalisation, (u p⊕ v) ; f in
=	Law (8)
u ; f in p⊕ v ; f in
±	Law (5) since u, v : usim(T, T ')
f in' ; u p⊕ f in' ; v
±	Law (7)
f in' ; (u p⊕ v) .
The second claim, for downwards simulation, is similar using instead left sub- distributivity.	 
The methodology of incremental refinement relies on transitivity of simulations. Lifting sequential composition ; to sets of computations, we have the following result.

Lemma 5 For datatypes T , T ' and T '',
usim(T ',T '') ; usim(T, T ') ⊆ usim(T, T '')
and similarly for dsim.
Proof. The proof is based on calculations that are by now familiar. For u : usim(T, T ') and v : usim(T ',T ''), use of associativity and monotonicity of ; es- tablishes the three required conditions:
initialisation:			in ± in' ; u ± in'' ; v ; u invocation:	v ; u ; O ± v ; O' ; u ± O'' ; v ; u finalisation:		v ; u ; f in ± v ; f in' ± f in'' .
Dual reasoning establishes the analagous result for dsim.	 

Incompleteness
Just as neither simulation is alone complete for data refinement in the standard relational model, so in the distributional model of probabilistic programs. However we have a stronger result, applying even if the datatypes are deterministic.
Theorem 3 Neither upwards nor downwards simulation is alone complete for data reﬁnement in the distributional model of probabilistic programs, even when restricted to deterministic types.
Proof. Consider the ‘fork and spade’ example of Figure 2. Indeed (writing δx for the point mass as x) the computation
d = {(0, δa), (1, 1 δb + 1 δc), (2, δd), (3, δe)}
is a sound downward simulation [9] (the simulation does not modify the global state), so T ± T '. But there is no upwards simulation from T to T ' although T and T ' are both deterministic.
In fact, if u is one such upwards simulation, necessarily u.b = δ1 but u ; O.b =
{ 1 δ3 + 1 δ4} and O' ; u.b = {δb} ¢ { 1 δb + 1 δc}.	 

2	2	2

0



a
2
y =1	2

3
d


e


Fig. 2. The fork and spade example for the proof of Theorem 3, in which the usual nondeterministic choice from state a is replaced by a fair choice.

Discussion

The difficulty of data refinement in the probabilistic setting lies with the resolution of non-deterministic choice. That poses problems for both soundness and complete- ness.
For soundness of upwards simulation we need to establish that if (4) holds for two procedures it also holds for their nondeterministic choice. But
u ; (A H B) ± (A' H B') ; u
=	law of probabilistic programs
u ; (A H B) ± (A' ; u) H (B' ; u)
at which point we are stuck because Law (6) does not support the distribution we seek on the left. More must be assumed about the interrelationship between u and the programs A and B. Recalling the example at the start of Section 3.1, presumably the meaning of the data invocation ought not to depend on where in the program text the datatype is defined. So either we assume that the simulation contains no probabilistic choice (not very helpful), or further assumptions must be imposed on the datatype’s semantics, providing tighter control of interference between distinct variables that is possible with the usual current models [8].
For completeness, recall that in the standard case, if T is deterministic (i.e. its procedures are all deterministic) then data refinement of T by T ' yields construction of a simulation (constructed, in fact, using the inductive method encapsulated in Theorem 1). That suggested [5] interpolation of a deterministic datatype U bisimilar to T but in which nondeterminism of T is removed entirely. For that reason datatype U is called the power-set type. In that case there is an upwards simulation (in fact bisimulation) from T to U . But since U is deterministic and U is data refined by T ', there is a downwards simulation from U to T '. And so in sequence the two simulations are complete [5,14].
That result depended on the completeness of downward simulation for determin- istic datatypes. In the presence of probability, ‘deterministic’ again means maximal- ity in the refinement ordering. But now the ‘fork and spade’ example has shown that each simulation is alone incomplete, even for deterministic probabilistic programs.
In proposing a complete technique for data refinement in the probabilistic set- ting, much remains to be done. What might play the role of the power-set construc- tion in the probabilistic case? Theorem 3 shows that, unlike the standard case, it does not suffice to consider deterministic datatypes. Moreover the result is crucially dependent on the semantic model of computations and even on the manner in which the semantics of a module is cast. The former is inherited from the standard case but the latter is new.
Constructions that combine probability and nondeterminism include the follow- ing. Varacca and Winskel [16] show that there is no idempotent and distributive operator over a power set construction; in their proof non-deterministic choice is represented by ‘straight’ set union rather than convex closure of the union. The constructions of Tix et al. [15] and of Mislove et al. [10,11] provide domains combin-

ing probability with nondeterminism. Finally, to impose a systematic relationship on the semantic models, the span construction of Clare Jones et al. [2] has been considered for probabilistic models.
This is an area of continuing work.

References
E. W. Dijkstra. A Discipline of Programming. Prentice-Hall International, 1974.
P. H. B. Gardiner, C. E. Martin and O. de Moor. An algebraic construction of predicate transformers. In Mathematics of Program Construction, LNCS, 669:100-121, Springer-Verlag, 1993.
P. H. B. Gardiner and Carroll Morgan. A single complete rule for data refinement. Formal Aspects of Computing, 5(4):367–382, 1993.
J. He and K. Seidel and A.K. McIver. Probabilistic models for the guarded command language. Science of Computer Programming, 28(2):171–192, 1997.
C. A. R. Hoare, He Jifeng and J. W. Sanders. Prespecification in data refinement. Information Processing Letters, 25:71–76, 1987.
C. A. R. Hoare, I. J. Hayes, Jifeng He, C. C. Morgan, A. W. Roscoe, J. W. Sanders, I. H. Sørensen,
J. M. Spivey and B. A. Sufrin. The laws of programming. Communications of the ACM, 30(8):672– 686, 1987.
C. A. R. Hoare and He Jifeng. Unifying Theories of Programming. Prentice Hall, 1998.
A. K. McIver and C. C. Morgan. A probabilistic approach to information hiding. In A. K. McIver and
C. C. Morgan, editors, Programming Methodology, Monographs in Computer Science, Springer Verlag, 2003.
A. K. McIver and C. C. Morgan. Abstraction, Refinement and Proof for Probabilistic Systems. Springer Verlag, 2005.
M. Mislove, J. Ouaknine and J. Worrell. Axioms for probability and nondeterminism. ENTCS, 96:7–28, 2004.
M. W. Mislove. On combining probability and nondeterminism. ENTCS, 162:261–265, 2006.
C. C. Morgan, A. K. McIver and K. Seidel. Probabilistic Predicate Transformers. ACM TOPLAS,
18(3):325–353, 1996.
T. M. Rabehaja and J. W. Sanders. Refinement algebra with explicit probabilism. In The 3rd IEEE Theoretical Aspects of Software Engineering Conference, Tianjin, China, 2009.
W.-P. de Roever and K. Engelhardt. Data Refinement: Model-Oriented Proof Methods and their Comparison. Cambridge Tracts in Theoretical Computer Science, Cambridge University Press, 1998.
R. Tix, K. Keimel and G. Plotkin. Semantic domains for combining probability and non-determinism.
ENTCS, 222(1571-0661):3–99, Elsevier, 2009.
D. Varacca and G. Winskel. Distributing probability over non-determinism. Mathematical Structures in Computer Science, 16(1):87–113, 2006.
