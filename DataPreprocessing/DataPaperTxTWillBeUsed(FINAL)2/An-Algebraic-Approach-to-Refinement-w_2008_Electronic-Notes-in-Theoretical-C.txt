Electronic Notes in Theoretical Computer Science 214 (2008) 51–79	
www.elsevier.com/locate/entcs


An Algebraic Approach to Refinement with Fair Choice
Emil Sekerinski1
Department of Computing and Software McMaster University
Hamilton, Ontario, Canada

Abstract
In the analysis and design of concurrent systems, it can be useful to assume fairness among pro- cesses. Action systems model a process by a set of atomic actions. Typically, actions are combined by nondeterministic choice, which models minimal progress among processes rather than fairness. Here we define an operator for the fair choice among a set of actions. A refinement rule for action systems with fair choice is derived and applied to the development of the alternating bit protocol. The novelty is the algebraic style in which the fair choice operator is defined and in which formal reasoning is carried out; it avoids an appeal to the operational understanding of fairness.
Keywords: Refinement, fairness, action systems, alternating bit protocol


Introduction
In the action system model, a concurrent system is described through a set of atomic actions. Concurrency is modeled through interleaving: two actions that can be executed in any order, can be executed concurrently, and thus can belong to different processes. A concurrent system is understood through the repeated selection and execution of atomic actions. Fairness is a property that restricts this selection: weak fairness requires that a continuously enabled ac- tion is infinitely often taken. This is a useful assumption. If two continuously enabled actions belong to different processes, fairness implies that the sched- uler must give each process a chance, without specifying the scheduling policy;

1 Email: emil@mcmaster.ca

1571-0661 © 2008 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2008.06.004

by contrast, the minimal progress assumption would only ensure that either one makes progress. If two continuously enabled actions are to be executed on different processors, fairness expresses that each processor is working, with- out quantifying the relative speed. If two continuously enabled actions model possible behavior of the environment, like successful and failed transmission over a medium, then fairness implies that each behavior is possible, without quantifying the probability. Fairness has become a common assumption in the analysis and development of concurrent systems. Programming theories involving fairness are well worked out, e.g. [8,10,11].
This work is on the stepwise refinement of action systems with fair choice. We define an operator for the fair choice among actions and define an action system as a loop with a body composed by fair choice, following the approach of defining an action system as a loop with a body composed by nondetermin- istic choice. In particular, we make use of strong and weak iteration constructs of [1,3,7] for defining loops and fair choice, resulting in an algebraic treatment of fairness. No appeal to operational reasoning in terms of traces of executions is needed. A theorem for the data refinement of action systems with fair choice is derived and applied to the development of the alternating bit protocol.
This paper extends the binary fair choice of [14] to an n-ary fair choice and provides refinement rules to complement the verification rules studied there. The rule for data refinement of fair action system is similar to that is suggested in [4]; this paper presents a justification of this rule by reduction to the standard data refinement rule for action systems.
In [15] refinement rules that preserve temporal (leads-to) and fixpoint (ter- mination) properties are studied for fair transitions systems (action systems). Here we restrict ourselves to terminating action systems but consider local variables, allowing a more general notion of refinement.
The approach of [17] is to augment action systems with an explicit speci- fication of unfair non-terminating computations, rather than assuming a fair choice among actions, and to study refinement of such augmented action sys- tems; this allows a wider range of fairness constraints to be expressed compared to the (weak) fairness considered here, though in a different style.
In [13] Dijkstra’s calculus (action systems) is extended by a fair choice op- erator. The approach relies on temporal predicate transformers like “always” and “eventually” and on syntactic substitutions of fair choice by angelic choice, neither of which is needed here.
In [6] Dijkstra’s calculus is also extended by a fair choice operator in terms of the dovetail operator q that models fair parallel execution. The definition of dovetail requires the distinction between possible and definite nontermi- nation, which is done by additionally considering weakest liberal precondi-

tions. The expressiveness of the dovetail operator leads to problems with non-monotonicity and to the need for two ordering relations, both of which is avoided here.
Predicate transformers are used as the model of statements because of their generality. The next section reviews the predicate transformer model of statements and iteration statements defined by fixed points. Data refinement of statements follows common treatment [2,12].

Statements
We use typed, higher-order logic for defining statements, following [2]. Func- tion application is written as f x and binds tighter than any other operator. Equivalence (≡) has the same meaning on boolean expressions as equality (=), except that =, like ≤ bind tighter than ∧, ∨, which in turn bind tighter than
≡.
State Predicates
State predicates of type PΣ are functions from elements of type Σ to Bool ,
i.e. PΣ = Σ → Bool . On state predicates, conjunction ∧, disjunction ∨, implication ⇒, and negation ¬ are defined by the pointwise extension of the corresponding operations on Bool . Likewise, universal and existential quan- tification of pi : PΣ are defined by (∀ i ∈ I • pi ) σ ≡ (∀ i ∈ I • pi σ) and (∃ i ∈ I • pi ) σ ≡ (∃ i ∈ I • pi σ). The entailment ordering ≤ is defined by universal implication. The state predicates true and false represent the uni- versally true and false predicates, respectively.

Predicate Transformers
Predicate transformers of type Δ '→ Ω are functions from predicates over Ω, the postconditions, to predicates over Δ, the preconditions, Δ '→ Ω= PΩ → PΔ. A predicate transformers S is called monotonic if p ≤ q implies Sp ≤ Sq for any (state) predicates p and q . We use monotonic predicate transformers to model statements.
The sequential composition of predicate transformers S and T is defined by their functional composition:


(S ; T ) q	=^
S (T q )

The guard [p] skips if p holds and establishes “miraculously” any postcondition if p does not hold (by blocking execution). The assertion {p} skips if p holds

and establishes no postcondition if p does not hold (the system crashes):


[p] q	=^
{p} q	=^
p ⇒ q p Λ q

We define skip = [true] = {true} as the identity predicate transformer, magic = [false] as the predicate transformer which always establishes any postcondition, and abort = {false} as the predicate transformer which always aborts.
The demonic (nondeterministic) choice H establishes a postcondition only if both alternatives do. The angelic choice H establishes a certain postcondi- tion if at least one alternative does.


(S H T ) q	=^
(S H T ) q	=^
S q Λ T q S q V T q

Relations of type Δ — Ω are functions from Δ to predicates over Ω. The relational updates [R] and {R} both update the state according to relation R. If several final states are possible, then [R] chooses one demonically and {R} chooses one angelically. If R is of type Δ — Ω, then [R] and {R} are of type Δ '→ Ω:


[R] q δ	=^
{R} q δ	=^
(6 ω • R δω ⇒ q ω) (E ω • R δω Λ q ω)

The predicate transformers [p], {p}, [R], {R} are all monotonic and the oper- ators ;, H, H preserve monotonicity. A predicate transformer S and is called conjunctive if S (6 i ∈ I • qi ) = (6 i ∈ I • S qi ) for any indexed set pi , i ∈ I of predicates and non-empty set I . All conjunctive predicate transformers are monotonic. The predicate transfomers [p], {p}, [R] are all conjunctive (but not {R}) and the operators ;, H preserve conjunctivity (but not H). For the distributivity of ; over H we have:

Other statements can be defined in terms of the above ones. For example the guarded statement p → S is defined by [p]; S and the conditional by:


if p then S else T
=^	(p → S ) H (чp → T )

The enabledness domain of a statement S is defined as en S = чS false and its termination domain as tr S = S true. We have that:
S = [en S ]; S	(4)
en(S H T )= en S V en T	(5)
en T = true	⇒	en(S ; T )= en S	(6)

Reﬁnement Ordering
The refinement ordering ± is defined by universal entailment:


S ± T
=^	(6 q • S q ≤ T q )

With this ordering, the monotonic predicate transformers form a complete boolean lattice, with top magic, bottom abort, meet H, and join H. Intuitively, refinement can increase the termination domain, decrease the enabledness do- main, decrease demonic nondeterminism, and increase angelic nondetermin- ism. According to the Theorem of Knaster-Tarski, any monotonic function f from predicate transformers to predicate transformers has a unique least fixed point μ f and a unique greatest fixed point ν f , also written as μ x • f x and ν s • f s, respectively.

Iterations
Iteration of a statement S is described through solutions of the equation X = S ; X H skip. We define two fundamental iteration constructs, the strong iteration S ω and the weak iteration S ∗ as the smallest and largest such solution (both of which exist as ; and H are monotonic in both operands). We use the convention that ; binds tighter than H:


S ω	=^
S ∗	=^
(μ X • S ; X H skip) (ν X • S ; X H skip)

Both define a demonically chosen number of repetitions of S . However, with S ∗ the number of repetitions is always finite whereas with S ω it can be infinite, which is equivalent to abortion. For example, if S is a := a + 1, then the equation X = a := a +1 ; X H skip has two solutions, abort and skip H a := a +1 H a := a +2 H   The least solution is given by their demonic choice.
As abort H Q = abort for any Q , we have that (a := a + 1)ω = abort. The greatest solution is given by their angelic choice. As abort H Q = Q for any Q , we have that (a := a + 1)∗ = skip H a := a +1 H a := a +2 H ... .

From the fixed point definitions we get the following laws for unfolding iterations:
S ω	=	S ; S ω H skip	(7)
S ∗	=	S ; S ∗ H skip	(8)
Since S ω and S ∗ are defined as the smallest and largest solutions, we have following induction principles:
S ; X H skip ± X	⇒	S ω ± X	(9)
X ± S ; X H skip	⇒	X ± S ∗	(10)
Both weak and strong iteration are monotonic in the sense that S ± T implies
S ω ± T ω and S ∗ ± T ∗. Both S ω and S ∗ are refined by S itself:
S ω	±	S	(11)
S ∗	±	S	(12)
Furthermore, from the two unfolding laws we get immediately (as S = T H U
implies S ± T for any S , T ) that both are refined by skip:
S ω	±	skip	(13)
S ∗	±	skip	(14)
For the nested application of weak and strong iteration we have:
(S ω)∗	±	S ω	(15)
(S ∗)∗	±	S ∗	(16)
However, we note that (S ω)ω = abort and (S ∗)ω = abort. Intuitively, the inner iteration is refined by skip, which then makes skipω = abort. For the sequential composition with weak iteration we have [3]:
S ∗ ; S ∗	=	S ∗	(17)
S ∗ ; S	=	S ; S ∗	(18)
We introduce a derived iteration construct, the positive weak iteration S +:
S +	=^	S ; S ∗
Positive weak iteration is also monotonic in the sense that S ± T implies S + ±
T +, which follows from the monotonicity of weak iteration and sequential

composition (in both arguments). Furthermore, S + is refined by S itself:
S +	±	S	(19)
This follows from the definition of S + and (14). Weak iteration can also be expressed in terms of positive weak iteration:
S ∗	=	S + H skip	(20)
This follows immediately from the unfolding law (8) and the definition of S +. A consequence of this is that S ∗ is refined by S +:
S ∗	±	S +	(21)
For the nested applications of positive weak iterations with weak iteration and strong iteration we get:
(S +)∗	=	S ∗	(22)
(S +)ω	=	S ω	(23)
We show the first one by mutual refinement: (S +)∗ ± S ∗ holds by (19) and monotonicity of weak iteration. For the refinement S ∗ ± (S +)∗ we note that the left side is equal to (S ∗)∗ by (16), hence this is implied by (21). For the sequential composition with positive weak iteration we have:
S + ; S	=	S ; S +	(24)
This follows directly from the definition of S + and (18). For the enabledness domain of the iteration constructs we get:

The first two follow immediately from the unfolding laws (7) and (8) as en skip = true. The last one follows easily from the definition of S +, (26) and (6). For the weak iteration of guards and asserts we have:


We prove the first two by mutual refinement. The direction [p]∗ ± [p] H skip
follows from (12). For [p] H skip ± [p]∗ we have:
[p] H skip ± [p]∗
⇐	⟨(10)⟩
[p] H skip ± [p]; ([p] H skip) H skip
≡	⟨[p] conjunctive⟩
[p] H skip ± [p]; [p] H [p]; skip H skip
≡	⟨for any p: [p]; [p]= [p]⟩
true
The proof of (29) is analogous. Property (27) follows from the definition of
S + and (27), and (31) follows similarly.
The following property is known as decomposition [3]. Let S , T be mono- tonic predicate transformer assume T is conjunctive:

A statement S disables itself if executing it once leads to a state in which S is disabled, formally S (ч en S ) = true. This can be also expressed “more algebraically” without referring to pre- and postconditions:
S (ч en S )= true  ≡  S ; [en S ]= magic	(34) We prove this in an equational style:
S ; [en S ]= magic
≡		⟨equality of functions, definition of ;⟩ 6q • S ([en S ]q )= magicq
≡		⟨definitions of magic, guard⟩ 6q • S (en S ⇒ q )= true
≡	⟨as S monotonic⟩
S (ч en S )= true
If S disables itself, then S ω and S ∗ execute S at most once, and S + executes
S exactly once. Assume S is continuous:

For the proof of (35) we assume S ; [en S ]= magic and continue:

S ω
=	⟨(7) twice⟩
S ; (S ; S ω H skip) H skip
=	⟨S continuous, ; distributes over H, skip unit of ;⟩
S ; S ; S ω H S H skip
=	⟨(4)⟩

S ; [en S ]; S ; S ω H S H skip
=	⟨assumption⟩
magic ; S ; S ω H S H skip
=	⟨for any S : magic ; S = magic, lattice property⟩
S H skip
The proof of (36) is analogous. For the proof of (37) we assume S ; [en S ]= 
magic and continue:
S +
=		⟨definition of S +⟩ S ; S ∗
=	⟨assumption, (36)⟩
S ; (S H skip)
=	⟨S continuous, ; distributes over H, skip unit of ;⟩
S ; S H S
=	⟨(4)⟩
S ; [en S ]; S H S
=	⟨assumption⟩
magic ; S H S
=	⟨for any S : magic ; S = magic, lattice property⟩
S
A statement S is always enabled if its guard is always true, formally true = en S . This can be also expressed “more algebraically” without referring to pre- and postconditions:

en S = true	≡	S ; abort = abort	(38)

Intuitively, as magic is a left zero of ;, abort can be a right zero only if the left operand is not miraculous. This is shown by:

S ; abort = abort
≡		⟨equality of functions, definition of ;⟩ 6q • S (abortq )= abortq
≡	⟨definition of abort⟩
S (false)= false
≡	⟨definition of en⟩
en S = true
A variation of above observation arises when considering that statement S
does not disable itself, formally S (ч en S )= false:
S (ч en S )= false	≡	S ; {ч en S } = {ч en S }	(39)
The proof is:
S ; {ч en S } = {ч en S }
≡		⟨equality of functions, definition of ;⟩ 6q • S ({ч en S }q )= {ч en S }q
≡	⟨definition of {p}, en⟩
6q • S (S false Λ q )= S false Λ q
≡	⟨(*)⟩
S (S false)= false
≡	⟨definition of en⟩
S (ч en S )= false
The step (*) is shown by mutual implication: for “⇒” we instantiate q with false, which gives S false = false, and we instantiate q with true, which gives S (S false)= S false, which together give S (S false)= false. For “⇐” we show that S false = false assuming S (S false) = false. Without loss of generality, we let S false = r . With the assumption, we have S (r ) = false. Now, by monotonicity of S , from false ≤ r we get r ≤ false, and hence r = false and therefore S false = false, from which 6q • S (S false Λ q )= S false Λ q follows. The loop do S od executes its body as long as it is enabled, possibly not terminating (i.e. aborting). This is formally expressed as a strong iteration, followed by a guard which ensures that the guard of the body will not hold at
exit:

do S od
=^	S ω ; [ч en S ]

Strong iteration S ω and weak iteration S ∗ are the same if S eventually disables itself [3]:
S ω = {tr (do S od)} ; S ∗	(40)

Our interest is in terminating loops; all non-terminating loops are equal to
abort. In particular, if the body is always enabled, the loop is aborting:
S ; abort = abort	⇒	do S od = abort	(41)
A generalization of above observation arises if the loop body does not disable itself. In that case, if the body of the loop is initially disabled, the loop terminates immediately. If the body is initially enabled, the loop does not terminate:
S ; {ч en S } = {ч en S }	⇒	do S od = {ч en S }	(42)
Assuming S ;{ч en S } = {ч en S }, we show the consequence by mutual refine- ment. For {ч en S }± do S od we make a case analysis: if en S holds initially, then {ч en S } = abort and the refinement holds as abort is the bottom of the lattice. If ч en S holds initially, then {ч en S } = skip and by definition of do S od and (7) the loop also simplifies to skip, hence refinement holds. For the other direction we assume S ; {ч en S } = {ч en S } and continue:
do S od ± {ч en S }
≡	⟨definition of do S od⟩
S ω ; [ч en S ] ± {ч en S }
⇐	⟨monotonicity of ;, for any p: {p} ; [p]= {p} ⟩ 
S ω ± {ч en S }
⇐	⟨(9)⟩
S ; {ч en S }H skip ± {ч en S }
≡	⟨assumption⟩
{ч en S }H skip ± {ч en S }
≡	⟨lattice structure⟩
true
Refining the body of a loop leads to the loop being refined, provided that the enabledness domain is not decreased, as this would otherwise lead to nontermination that was not originally present:
S ± T	Λ	en S ≤ en T	⇒	do S od ± do T od	(43)
This follows from the definition of do S od, monotonicity of S ω, and the prop- erty that [p] ± [q ] ≡ p ≥ q . The while loop while b do S can be defined as do b → S od, provided S is always enabled. An action system is loop of the form:
do S1 H ··· H Sn od

The statements Si are called the actions and are typically of the form gi → Bi , where gi is the guard and Bi is the (always enabled) body. In this form, the choice among the actions is nondeterministic (demonic); no fairness in the selection of the actions is guaranteed.

Program Variables
The state space is made up of a number of program variables. Thus the state space is of the form Γ = Γ1 × ... × Γn and states are tuples γ = (x1,... , xn). The variable names serve for selecting components of the state. Guards and assertions can be written with boolean expressions, like [x > 0], instead of state predicates, if the state space is understood from the context:


[b]	=^
{b}	=^
[p]	where	p γ ≡ b
{p}	where	p γ ≡ b

The assignment x := e updates x and leaves all other variables unchanged. The nondeterministic assignment x :∈ q assigns x an arbitrary element such that qx holds and leaves all other variables unchanged. For example, if x , y are the only program variables, then:


x := e	=^
x :∈ q	=^
[R]	where	R (x , y ) (x , y ) ≡ x = e Λ y = y
[R]	where	R (x , y ) (x ', y ') ≡ q x ' Λ y ' = y

The declaration of a local variable y : Δ with boolean expression b extends the state space and sets y to any value for which b holds. Suppose the state space consists only of x : Γ:


var y | b • S
=^	[Enter ]; S ; [Exit ] where Enter x (x ', y ') ≡ x = x ' Λ b[y \y ']
and Exit (x , y ) x ' ≡ x = x '

Leaving out the initialization predicate as in var y • S means initializing the variable arbitrarily, var y | true • S , and var y = y0 • S means setting y ini- tially to y0. For brevity, we leave out the type of the introduced variable. Since Γ × (Δ × Ω) is isomorphic to (Γ × Δ) × Ω, we can always find functions which transform an expression of one to the other type. Hence we simply write Γ × Δ × Ω. For example, if Γ = Γ1 × ···× Γn then S above would have the type Γ1 × ··· × Γn × Δ '→ Γ1 × ··· × Γn × Δ.
We use following properties to move guards and assertions over assignments and to eliminate local variable declarations; f [x \e] stands for expression f with

variable x substituted by expression e:

Data Reﬁnement
Data refinement S ±R T generalizes (algorithmic) refinement by relating the initial and final state of S and T with relation R. We allow R to refine only part of the state, i.e. if the (initial and final) state space of S can be partitioned into Δ × Γ and R to relates values of Δ to values of Ω, then the state space of T is Ω × Γ. We write Id for the identity relation and × for the parallel composition of relations:


S ±R T
=^	S ; [R × Id ] ± [R × Id ]; T

Sequential composition and nondeterministic choice preserved data refinement in the following sense:

Strong, weak, and positive iteration preserve data refinement. Let S and T
be conjunctive predicate transformers:
S ±	T	⇒	S ω ± T ω	(49)
S ±	T	⇒	S ∗ ± T ∗	(50)
S ±R T	⇒	S + ±R T +	(51)
The image of predicate p under relation R is denoted by R[p]. We have for any R, p, q :
R[p] ≤ q	≡	Rx y Λ px ⇒ qy	(52) (53)
For the data refinement of guards and asserts we have:
[p] ±R [q ]	≡	R[чp] ≤ чq	(54)
{p} ±R {q }	≡	R[p] ≤ q	(55)
We give selected theorems about data refining assignments; they naturally generalize when only a specific component of a larger state space is refined.

Assume that relation R relates X to Y and the state space includes Z . Vari- ables x , y , z refer to the corresponding state components:

b → x , z := e, g ±R c → y , z := f , h	≡	c Λ Rx y ⇒ b Λ Re f Λ g = h
(56)
skip ±R c → y := f	≡	c Λ Rx y ⇒ Rx f	(57)


Binary Fair Choice

For statements S and T , the loop do S T od repeatedly executes S or T , whichever is enabled, and terminates when neither one is enabled. If both S and T are enabled, the choice is arbitrary, except that if one is continuously enabled, it will be repeatedly taken, a criterion known as weak fairness. The loop do S D T od is only fair only to T : if T is continuously enabled, it will be repeatedly taken, and S may be neglected forever. Both , read “fair choice” and D, read “right fair choice” are defined in isolation, such that the meaning of a loop containing those is given in a compositional manner.
We introduce an operator S , read “try S ”, for a predicate transformer S . If S is enabled, S behaves as S , otherwise as skip:




S	=^
S H [ч en S ]


In the fair choice between S and T we may take S or T arbitrarily but finitely often, and then have to give T and S a chance, respectively. This is expressed in terms of positive weak iterations:


S T S D T

	
=^	S + ; T H T + ; S
=^	S + ; T H T +


The “left fair choice” operator S T is defined by T D S . For reasons of symmetry, we continue only with S D T . To support our confidence in these definitions, we study two examples. The first one is an abstract view of trans- mission over an unreliable medium. The specification calls for copying data in to variable out . The implementation tries to do that repeatedly, and will either succeed or fail, with success given a fair chance. We assume that we

can detect successful reception and indicate this by setting variable r to true:





T0	=^
T1	=^
out := in
var r • r := false ;
do чr → skip
D чr → out , r := in, true
od






We prove that T0 = T1 by first simplifying the body of the loop:


чr → skip D чr → out , r := in, true
=		⟨definition of →, skip unit of ;⟩ [чr ] D[чr ]; out , r := in, true
=	⟨definition of D⟩

[чr ]+ ; [чr ]; out , r := in, true H ([чr ]; out , r := in, true)+
=	⟨[чr ]; out , r := in, true disables itself, (37)⟩

[чr ]+ ; [чr ]; out , r := in, true H [чr ]; out , r := in, true
=	⟨(27)⟩

[чr ]; [чr ]; out , r := in, true H [чr ]; out , r := in, true
=		⟨definition of S and en([чr ]; out , r := in, true)= чr by (6)⟩ [чr ]; ([чr ]; out , r := in, true H [r ]) H [чr ]; out , r := in, true
=		⟨; distributes over H, for any p, q : [p]; [q ]= [p Λ q ]⟩ [чr ]; out , r := in, true H [false] H [чr ]; out , r := in, true
=		⟨definition of magic, magic top of lattice, H idempotent⟩ [чr ]; out , r := in, true

We continue:

var r • r := false ; do чr → чr → skip D out , r := in, true od
=	⟨above calculation⟩
var r • r := false ; do [чr ]; out , r := in, true od
=	⟨definition of do S od and en([чr ]; out , r := in, true)= чr by (6)⟩
var r • r := false ; ([чr ]; out , r := in, true)ω ; [r ]
=	⟨[чr ]; out , r := in, true disables itself, (35)⟩
var r • r := false ; [чr ]; out , r := in, true ; [r ]
=	⟨(44) twice⟩
var r •[true]; r := false ; [true]; out , r := in, true
=	⟨definition of skip and skip unit of ;⟩
var r • out , r := in, true
=	⟨(46)⟩
out := in
Thus we have T0 = T1. On the other hand, if we replace the right fair choice by nondeterministic choice, as in T2 below, the second alternative may be continuously selected, leading to nontermination.


T2	=^
var r • r := false ;
do чr → skip
Н чr → out , r := in, true
od


Formally, we note that the body of the loop is enabled when чr holds. The body of the loop does not disable itself. Hence by (42) the loop is equal to
{чr }. From (45) we get that r := false ;{чr } = abort. We have var r • abort =
abort, therefore T2 = abort.
The second example illustrates that the fair choice operator ensures only weak fairness, not strong fairness. Consider a loop with two boolean variables, b and c:


U0	=^
do b → c := чc
  b Λ c → b := false
od


If the first alternative is continuously taken, the second alternative is repeat- edly enabled and disabled, but is not continuously enabled. With strong fairness it, will eventually be taken, with weak fairness not. Hence we expect U0 = {чb}. We sketch the proof. Consider the body of the loop:

b → c := чc  b Λ c → b := false
=	⟨definition of  ⟩

(b → c := чc)+ ; b Λ c → b := false H (b Λ c → b := false)+ ; b → c := чc
=   ⟨b Λ c → b := false disables itself, (37)⟩

(b → c := чc)+ ; b Λ c → b := false H b Λ c → b := false ; b → c := чc
=   ⟨(b → c := чc)+ simplifies to b → c := true H b → c := false⟩

b → c := true ; b Λ c → b := false H b → c := false ; b Λ c → b := false H b Λ c → b := false ; b → c := чc
=   ⟨definition of S , simplifications⟩
b → c := true ; b := false H b → c := false H b Λ c → b := false ; c := чc

Due to b → c := false, the action in the last line does not disable itself, hence U0 = {чb} by (42). Intuitively, b → c := false arises from repeated executions of b → c := чc in U0.
Following theorem, taken from [14], states that nondeterministic choice can be implemented by symmetric and asymmetric fair choice.
Theorem 3.1 Let S and T be monotonic predicate transformers:


Generalized Fair Choice
Consider the fair choice among tree alternatives, expressed using binary fair choice in two different ways:
L = (S  T )  U	R = S  (T  U )
Assume that S , T , U are always enabled. If L starts with repeating T a finite number of times, S will be tried and taken. If R starts with repeating T a finite number of times, U will be tried and taken. Hence the sequence T ; U is impossible for L but possible for R, and dually for the sequence T ; S . Thus L and R are different and  is not associative. This necessitates a more general fair choice operator over a set of alternatives. It also implies that we will not consider nested applications of fair choice.
We intend to allow combinations of unfair and fair actions. As nondeter- ministic choice H is associative, several unfair alternatives can be combined to a single one. It is sufficient to consider an operator with a single unfair

and an number of a fair alternatives, which we write as S D i ∈ I • Si for a finite and non-empty set I . The idea of the definition is that no matter which combinations of statements Sj is selected, each statement Si has to be tried; which Si is tried at the end is arbitrary:


S D i ∈ {j } • Si	=^
S D i ∈ I • Si	=^
S D Sj

H i ∈ I •(S D j ∈ I − {i } • Sj )+ ; Si	if |S | > 1

If there are only fair alternatives, we write simply  i ∈ I • Si , defined by:
  i ∈ I • Si	=^	magic D i ∈ I • Si
Binary fair choice emerges as a special case of general fair choice, in the sense that for k /= j we have  i ∈ {j , k } • Si = Sj  Sk . Given a fixed finite index set I = {1, .., n}, we write S D S1 S2 ··· Sn. The order in which the alternatives appear does not matter by definition. We also allow a mixture of notations as in S D i ∈ I • Si j ∈ J • Tj . To illustrate the definition, for the choice among three alternatives we have:

We state some basic properties of fair choice. Fair choice is enabled when any one of the alternatives is:
Theorem 4.1 Let I be a non-empty index set and S , Si for i ∈ I be mono- tonic predicate transformers:
en(S D i ∈ I • Si )	=	en S V (Vi ∈ I • en Si )
Proof. The proof proceeds by induction over the size of I . For |I | = 1, the base case, we have:
en(S D T )
=	⟨definition of D⟩

en(S + ; T H T +)
=	⟨(5), (27), (6), for any S : en S = true ⟩
en S V en T
Now assume en(S D i ∈ J • Si )= en S V(Vi ∈ J • en Si ) for set J with |J |≥ 1. We show that en(S D i ∈ I • Si )= en S V (Vi ∈ I • en Si ) holds for set I with
|I | = |J | + 1:

en(S D i ∈ I • Si )
=	⟨definition of generalized D⟩

en(Hi ∈ I •(S D j ∈ I − {i } • Sj )+ ; Si )
=		⟨for any Si : en(Hi ∈ I • Si )= Vi ∈ I • en Si ⟩ Vi ∈ I • en((S D j ∈ I − {i } • Sj )+ ; Si )

=		⟨(27), (6), for any S : en S = true⟩ Vi ∈ I • en(S D j ∈ I − {i } • Sj )
=	⟨induction assumption⟩
Vi ∈ I • en S V (Vj ∈ I − {i } • en Si )
=	⟨logic⟩
en S V (Vi ∈ I • en Si )

Nondeterministic choice H is monotonic in both operands. By comparison, fair choice is monotonic provided that additionally the enabledness of each fair alternative is not decreased.
Theorem 4.2 Let I be a non-empty index set and S , T , Si, Ti for i ∈ I be monotonic predicate transformers. If
S ± T,	Λi ∈ I • Si ± Ti ,
Λi ∈ I • en Si ≤ en Ti then:
S D i ∈ I • Si	±	T D i ∈ I • Ti
Proof. The proof proceeds by induction over the size of I . For |I | = 1, the base case, we have to show that S ± T , U ± V , and en U ≤ en V imply S D U ± T D V . Assuming S ± T , U ± V , and en U ≤ en V we have:
S D U
=	⟨definition of  ⟩

S + ; U H U +
±	⟨monotonicity of S +, (*) below, monotonicity of ; and H⟩

T + ; V H V +
=	⟨definition of  ⟩
T D V
The step (*) relies on the property that U ± V Λ (en U ≤ en V ) implies U ± V . This follows from the definition of S , monotonicity of H and the fact that [p] ± [q ] ≡ p ≥ q . For the induction step, the hypothesis is that S ± T , Λi ∈ J • Si ± Ti , and Λi ∈ J • en Si ≤ en Ti imply S D i ∈ J • Si ± T D i ∈

I • Ti for set J with |J | ≥ 1. We show that the theorem holds for set I with
|I | = |J | + 1. Assuming S ± T , Λi ∈ I • Si ± Ti , and Λi ∈ I • en Si ≤ en Ti ) we have:
S D i ∈ I • Si
=	⟨definition of D, |I | > 1⟩

Hi ∈ I •(S D j ∈ I − {i } • Sj )+ ; Si
±		⟨hypothesis, monotonicity of S +, (*) above, monotonicity of ; and H⟩ Hi ∈ I •(T D j ∈ I − {i } • Tj )+ ; Ti
=	⟨definition of  ⟩
T D i ∈ I • Ti

To see that enabledness in the fair operand must not be decreased, consider the statements:


S0	=^
b → b := false  b → skip	S1	=^
magic  b → skip

Clearly we have b → b := false ± magic, but if S0 were refined by S1, then do S0 od would be refined by do S1 od according to (43), as en S0 = en S1. However, do S0 od always terminates, by setting b to false it if is true initially, but do S1 od does not terminate if b is true initially.
We study further basic properties. Nondeterministic choice has abort as zero, as does fair choice:
Theorem 4.3 Let I be a non-empty index set and S , Si for i ∈ I be mono- tonic predicate transformers:

Proof. The proofs are straightforward by induction over the size of I . We only give the base case of (a):
abort D S
=	⟨definition of D⟩
abort+ H S + ; abort
=	⟨abort+ = abort, abort zero of H⟩
abort
 
Nondeterministic choice has magic as unit, S H magic = S and is idem- potent, S H S = S .	For fair choice we have instead S D magic = S +,



magic D S = S +, and S  S = S + ; S . However, in the context of a loop, fair choice has magic as unit and is idempotent. For simplicity, we formalize this only for binary choice:

Theorem 4.4 Let S be a monotonic predicate transformer:

do S  magic od	=	do S od	(a)
do S  S od	=	do S od	(c)

Proof. For (a) we have:
do S  magic od
=	⟨definition of do S od⟩
(S  magic)ω ; [ч en(S  magic)]
=	⟨Theorem 4.1, en magic = false⟩
(S  magic)ω ; [ч en S ]
=	⟨definition of  ⟩

(S + ; magic H magic+ ; S )ω ; [ч en S ]
=	⟨magic = skip, magic+ = magic⟩
(S + ; skip H magic ; S )ω ; [ч en S ]
=	⟨for any S : magic ; S = magic, S H magic = S , S ; skip = S ⟩
(S +)ω ; [ч en S ]
=		⟨(23), definition of do S od⟩ do S od
For (b) we have:
do S  S od = do S od
=		⟨definition of do S od, Theorem 4.1⟩ (S  S )ω ; [ч en S ]= S ω ; [ч en S ]
=		⟨definition of , simplifications⟩ (S + ; S )ω ; [ч en S ]= S ω ; [ч en S ]
This is shown by mutual refinement. For brevity, we give only the proof in one direction:



(S + ; S )ω ; [ч en S ] ± S ω ; [ч en S ]
⇐	⟨(23), monotonicity of ;, S ω⟩

S + ; S ± S +
⇐	⟨definition of S , distributivity⟩
S + ; S H S + ; [ч en S ] ± S +
⇐	⟨property of H⟩
S + ; S ± S + Λ S + ; [ч en S ] ± S +
From the definition of S + and (8) we have that S + = S ; S + H S . Hence the left conjunct can be rewritten as S + ; S ± S ; S + H S , which follows from (24). 

Data Refinement
We state theorems that allow additional alternatives to be introduced when data refining a loop. First we give a theorem for nondeterministic choice among the alternatives, then a theorem for both nondeterministic and fair choice.
Theorem 5.1 Let S , T , H be conjunctive predicate transformers and R a re- lation. If
S ±R T,	skip ±R H
R[en S ] ≤ en T V en H
R[true] ≤ tr (do H od)
then:
do S od	±R	do T H H od
Condition (a) requires that concrete action T data refines abstract action S and that H is a stuttering action, i.e. it’s effect is not observable abstractly. Condition (b) requires that T and H must be enabled whenever S is, i.e. the concrete loop will not terminate if the abstract loop does not. Condition (c) requires that H eventually disables itself, provided R[true], the concrete in- variant, holds. That is, H cannot introduce nontermination. The proof is given in [3].
Theorem 5.1 is applied to loops with multiple actions by taking S = S1 H
... H Sn and T = T1 H ... H Tm. For S ±R T it is sufficient that each Tj data refines some Si , formally Si ±R Tj . In general, each Tj can refine any subset of S1 H ... H Sn and not each Si needs to be refined. Likewise, multiple stuttering actions can be introduced by taking H = H1 H ... H Hk . Actions Ti and Hj are called the main and auxiliary actions.

For extending above theorem to fairness, we allow refinement to intro- duce both fair and unfair stuttering actions. All unfair actions can again be “merged” into one action.
Theorem 5.2 Let S , H , G be conjunctive predicate transformers and let R be a relation. If
S ±R T,	skip ±R H,	skip ±R G
R[en S ] ≤ en T V en H V en G
R[true] ≤ tr (do H D G od)
then:
do S od	±R	do T H H D G od

Condition (a) requires that the concrete unfair action data refines the ab- straction action and that the introduced actions are stuttering actions. Condi- tion (b) requires that the body of the concrete loop must be enabled when the body of the abstract loop is, according to Theorem 4.1. Condition (c) requires that the auxiliary computation, consisting of all auxiliary actions, eventually disables itself.
Proof. Assuming (a), (b), and (c), we have:
do S od ±R do T H H D G od
≡	⟨definition of do S od, Theorem 4.1⟩
S ω ; [ч en S ] ±R (T H H D G )ω ; [ч en T лч en H л чG ]
⇐	⟨(47), (54), (b)⟩
S ω ±R (T H H D G )ω
≡	⟨definition of D⟩

S ω ±R ((T H H )+ ; G H G +)ω
≡	⟨(23), definition of S +, distributivity⟩

(S +)ω ±R (T ; (T H H )∗ ; G H H ; (T H H )∗ ; G H G +)ω
⇐	⟨(47), (a), S + ±R T ; (T H H )∗ ; G ⟩
(S +)ω ±R (H ; (T H H )∗ ; G H G +)ω
≡	⟨(33), definition of S +⟩
(S +)ω ±R (H + ; (T ; H ∗)∗ ; G H G +)ω
≡	⟨(20), distributivity⟩
(S +)ω ±R (H + ; G H H + ; (T ; H ∗)+ ; G H G +)ω



⇐	⟨(47), (a), S + ±R H + ; (T ; H ∗)+ ; G ⟩
(S +)ω ±	(H + ; G H G +)ω
⇐	⟨(23), definition of D⟩
S ω ±	(H D G )ω
⇐	⟨(40)⟩
S ω ±	{tr (do H D G od)} ; (H D G )∗
⇐	⟨(c), (55), {true} = skip⟩
S ω ±	(H D G )∗
⇐	⟨S ω ± S , (a), skip∗ = skip⟩
true	 


A further generalization is to allow the abstract action system to have both unfair and fair actions and an arbitrary numer of fair stuttering actions to be introduced.

Theorem 5.3 Let I , J be non-empty index sets, let S , Si, T , Ti , H , Hj for i ∈
I , j ∈ J be conjunctive predicate transformers, and let R be a relation. If
S ±R T,	лi ∈ I • Si ±R Ti ,	skip ±R H,	лj ∈ J • skip ±R Hj
R[en S V (Vi ∈ I • en Si )] ≤ en T V en H V (Vi ∈ I • en Ti ) V (Vj ∈
J • en Hj ),
лi ∈ I • R[en Si ] ≤ en Ti
R[true] ≤ tr (do H D j ∈ J • Hj od)
then:
do S D i ∈ I • Si od	±R	do T H H D i ∈ I • Ti  j ∈ J • Hj od


Condition (a) requires that the concrete actions data refine the abstraction actions and that the introduced actions are stuttering actions. However, there has to be a one-to-one correspondence among the fair actions, Si ±R Ti for all i ∈ I and every Si has to be refined; the unfair actions S , T , and H can be decomposed as previously. Condition (b) requires that the body of the concrete loop must be enabled when the body of the abstract loop is. Addi- tionally, each concrete fair action Ti must be enabled when the corresponding abstract action Si . Condition (c) requires that the auxiliary computation, con- sisting of all auxiliary actions, eventually disables itself. The proof proceeds by induction over the size of both I and J ; it is left out for brevity.

Alternating Bit Protocol
The alternating bit protocol [5], a protocol for reliable communication over unreliable channels, has been repeatedly formalized. Our treatment is inspired by that of [8,16]. Channels are modeled as variables, as in [9], rather than as sequences. Let a, b be sequences of data items. We write |a| for the length of a sequence, a[i ] for the i -th element, and a[i ..j ) for the subsequence starting at index i of length j −i . We develop the alternating bit protocol as a refinement of A in a sequence of steps.

Speciﬁcation
In its most abstract form, a transmission copies sequence a to sequence b:


A	=^
b := a


Copying Data Items Successively
The first refinement step introduces a loop that copies the data items succes- sively. Its body is:
S	=^	k < |a|→ b, k := b ^⟨a[k ]⟩, k +1 
The whole program, B , initializes index k to zero. The refinement A ± B can be shown using standard refinement rules:


B	=^
var k • b, k := ⟨⟩, 0; do S od


Splitting into Sender and Receiver
The second refinement steps decomposes S into an abstract sender, T1, and an abstract receiver, T2. Sender and receiver communicate via common variable
s. They synchronize by a common boolean variable m in a ping-pong fashion:


T1	=^
T2	=^
m л x < |a|→ m, s, x := false, a[x ], x +1 
чm → b, m := b ^⟨s⟩, true

The whole program, C , initializes m such that the sender starts:


C	=^
var m, s, x • m, x := true, 0; do T1 H T2 od

To establish the correctness of this refinement, we show do S od ±P do T1 H
T2 od by Theorem 5.1 using as the refinement relation:


P (k )(m, s, x )	=^
0 ≤ x ≤ |a|л b[0..k )= a[0..k ) л
((m л x = k ) V (чm л k = x − 1 л s = a[x − 1]))

That is, this refinement step replaces k by m, s, x and keeps s. As T2 modifies variable b, as S does, T2 is the main action and T1 the auxiliary action. The resulting conditions are:
S ±P T2,	skip ±P T1
P [en S ] ≤ en T1 V en T2
P [true] ≤ tr (do T1 od)
The first part of condition (a) follows by (56) and the second part by (57). Condition (b) follows by (52). For condition (c) we observe that T1 always disables itself, hence do T1 od always terminates.

Introducing Faulty Channels
In the third refinement step faulty channels are placed between the sender and receiver. The sender keeps one private bit, c, that is attached to every trans- mission and flipped on that occasion, such that messages of the sender have alternating bits. Variable t is used to start and stop the data transmission. The sender becomes:


U1	=^
c = g л x < |a|→ c, s, t , x := чc, a[x ], true, x +1 

Once data transmission is started, the data channel may successfully transmit the bit and the data by copying c, s to f , p and stop; we assume that the correct transmission of the bit and the data can be detected. The channel may also keep transmitting c, s, or may loose the message, i.e. do nothing. These three possibilities are given by:


U2	=^
U3	=^
U4	=^
t → f , p, t := c, s, false t → f , p := c, s
t → skip

The receiver keeps a bit with the “parity” of the expected message. If the received message matches, the data is appended to b and the bit is flipped. The transmission of an acknowledgement message, consisting of a single bit,

g , is initiated by setting u to true.
U5	=^	d = f → b, d , u := b ^⟨p⟩, чb, true
The acknowledgement channel may either transmit the bit properly and stop, may keep transmitting the bit, or may loose the message:


U6	=^
U7	=^
U8	=^
u → g , u := чd , false u → g := чd
u → skip

The sender detects proper transmission by comparing the received bit, g , with the expected on c. The initialization of the protocol allows the sender to start. This protocol copies a to b provided that correct transmission of data, action U2, and correct transmission of acknowledgements, action U6, have a fair chance:


D	=^
var s, d , f , g , p, s, t , u, x •
c, d , f , g , t , u := true, false, true, true, false, false ;
do U1 H U3 H U4 H U5 H U7 H U8 D U2  U6 od

The correctness of the refinement of the loops is established by Theorem 5.3 with refinement relation:


Q (m)(c, d , f , g , p, t , u)	=^
(c = g ⇒ m) Λ (m ⇒ u V c = g ) Λ
(d = f ⇒ чm) Λ (чm ⇒ t V d = f ) Λ
(c = g ⇒ g /= d ) Λ (d = f ⇒ f = c Λ p = s)

The first line states that if the concrete sender, U1, is ready to transmit, c = g , the abstract sender, T1 must be ready as well; on the other hand, if T1 is ready to transmit, then either U1 must be ready to transmit or the actions of the acknowledgement channel, U6, U7, U8, are enabled. The second line states an analogous property about the receiver. The third line is the concrete invariant and expresses what the sender, U1 and the receiver, U5, can expect: if U1 is ready to transmit, the receiver must have had acknowledged and if U5 is ready to receive, the data must have been correctly transmitted. The refinement replaces m and keeps s and x . The data channel actions and the acknowledgement channel actions modify only the introduced variables and become auxiliary actions. The resulting conditions are:
T1 H T2 ±Q U1 H U5,	skip ±Q U3 H U4 H U7 H U8,	skip ±Q U2,
skipQ ± U6

Q [en T1 V en T2] ≤ en U1 V ... V en T8
Q [true] ≤ tr (do U3 H U4 H U7 H U8 D U2  U6 od)
The first part of condition (a) can be split into T1 ±Q U1 and T2 ±Q U5, each of which follows by (56). The remaining parts follow by (57), after splitting the second one into four parts. Condition (b) follows by (52). For condition (c) we observe that U3 H U4 H U7 H U8 D U2  U6 always disables itself, hence the loop always terminates.

Discussion
Theorem 5.3 is similar to the forward simulation of fair action systems in [4], but differs in three ways. First, the condition for the auxiliary computation in [4] is weaker as the auxiliary computation either has to terminate or has to enable and execute a main action. The second difference is that a more general mapping between abstract and concrete main actions is considered, compared to the one-to-one correspondence that is assumed here for simplicity. The third difference is that only unfair auxiliary actions can be introduced, whereas Theorem 5.3 gives the conditions for both unfair and fair auxiliary actions. The development of the alternating bit protocol relies on fair auxiliary actions being introduced for representing unreliable channels.
Theorem 5.3 has a stronger condition for fair actions than for unfair ac- tions, as fair actions have to be refined individually but unfair actions can be refined jointly, suggesting that unfair actions are to be preferred. On the other hand, introducing fair auxiliary actions compared to unfair auxiliary actions makes the condition for the termination of the auxiliary computation weaker. Thus the methodological consequence is that the introduction of fair actions should be postponed until needed for ensuring the termination of the aux- iliary computation. The development of the alternating bit protocol follows this scheme.
It would be interesting to see if strong fairness can also be treated using iteration statements. If binary fair choice were associative, the formalism could be significantly simplified. The definition of an associative binary fair choice operator has remained elusive is left as an open problem.

References
C. Aarts, R. Backhouse, E. Boiten, H. Doorndijk, N. van Gasteren, R. van Geldrop,
P. Hoogendijk, T. Voermans, and J. van der Woude. Fixed-point calculus. Information Processing Letters, 53(3):131–136, 1995.
R.J.R. Back and J. von Wright. Reﬁnement Calculus–A Systematic Introduction. Springer- Verlag, 1998.

R.J.R. Back and J. von Wright. Reasoning algebraically about loops. Acta Informatica, 36(4):295–334, 1999.
R.J.R. Back and Q. Xu. Refinement of fair action systems. Acta Informatica, 35(2):131–165, 1998.
K. A. Bartlett, R. A. Scantlebury, and P. T. Wilkinson. A note on reliable full-duplex transmission over half-duplex links. Communications of the ACM, 12(5):260–261, 1969.
M. Broy and G. Nelson. Adding fair choice to Dijkstra’s calculus. ACM Transactions on Programming Languages and Systems, 16(3):924–938, 1994.
M. J. Butler and C. C. Morgan. Action systems, unbounded nondeterminism and infinite traces. Formal Aspects of Computing, 7(1):37–53, 1995.
K. Mani Chandy and Jayadev Misra. Parallel Program Design: A Foundation. Addison-Wesley, 1988.
W. H. J. Feijen and A. J. M. van Gasteren. On a Method of Multiprogramming. Springer- Verlag, 1999.
N. Francez. Fairness. Texts and Monographs in Computer Science. Springer-Verlag, 1986.
Leslie Lamport. The temporal logic of actions. ACM Transactions on Programming Languages and Systems, 16(3):872–923, 1994.
Carroll C. Morgan. Programming from Speciﬁcations. Prentice Hall, 2nd edition, 1994.
J. M. Morris. Temporal predicate transformers and fair termination. Acta Informatica, 27(4):287–313, 1990.
E. Sekerinski. On guarded commands with fair choice. In R. Backhouse and J. Oliveira, editors, 5th International Conference on the Mathematics of Program Construction, MPC 2000, Lecture Notes in Computer Science 1837, pages 127–139, Ponte de Lima, Portugal, 2000. Springer- Verlag.
A. K. Singh. Program refinement in fair transition systems. Acta Informatica, 30:503–535, 1993.
A. Wabenhorst. A stepwise development of the alternating bit protocol. Technical Report PRG-TR-12-97, Oxford University Computing Laboratory, March 1997.
A. Wabenhorst. Stepwise development of fair distributed systems. Acta Informatica, 39:233271, 2003.
