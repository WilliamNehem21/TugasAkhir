Available online at www.sciencedirect.com


Electronic Notes in Theoretical Computer Science 298 (2013) 427–440
www.elsevier.com/locate/entcs

Approximating Bisimilarity for Markov Processes 1
Chunlai Zhou2
Computer Science Department School of Information
Renmin University of China Beijing, CHINA

Abstract
In this paper we investigate bisimilarity for general Markov processes through the correspondence between sub-σ-algebras and equivalence relations. In particular, we study bisimulations from the perspective of fixed- point theory. Given a Markov process M = ⟨Ω, Σ,τ⟩, we characterize its state bisimilarity as the greatest fixed point of a composition of two natural set operators between equivalence relations on Ω and sub-σ- algebras of Σ. Moreover, we employ a Smith-Volterra-Cantor-set-construction to obtain an example to show that state bisimilarity is beyond ω iterations of these two operators alternately from event bisimilarity and hence the composite operator is not continuous. This process of iteration illustrates the gap between event bisimilarity (or logical equivalence) and state bisimilarity, and hence provides insights about the Hennessy- Milner property for general Markov processes. At the end of this paper, we also study approximation of Markov processes related to filtration.
Keywords: Markov processes, state bisimilarity, event bisimilarity, fixed point, Hennessy-Milner logic


Introduction
Markov processes with continuous state spaces are important mathematical models in different physical sciences such as physics, biology, finance and computer sciences. The dynamics of the processes is governed by the present state rather than by the past history of the processes. With the ever-growing computer technology, we need to develop a theory of computational grip of this kind of important structures. If one is interested in computing them, we must build a machinery to approximate Markov processes with continuous state space and also make sure that the approximating

1 I want to thank Professor Ernst-Erich Doberkat, Ingo Battenfeld, Yuan Feng and Pedro S´anchez Terraf for helpful discussions at different stages of this research. This work is partly supported by NSF of China (Grant Number: 60905036), by the Key Project for basic research from the Ministry of Science and Technology of China (Grant Number: 2012CB316205), by the Basic Research Funds in Renmin University from the Central Government (Grant No. 201230005 ) and by German Academic Exchange Service (DAAD Codenumber:
A/10/00803).
2 Email: chunlai.zhou@gmail.com

1571-0661 © 2013 Published by Elsevier B.V. Open access under CC BY-NC-ND license.
http://dx.doi.org/10.1016/j.entcs.2013.12.007

processes preserve all the essential properties especially the dynamic aspects of the original processes.
The limit of the approximating processes is usually not the original approximated process but instead the quotient process with respect to some bisimilarity. There are two totally different notions of bisimilarities for Markov processes in the literature. The first one is called state bisimilarity. Intuitively, two states are state bisimilar in the process if they match transition probabilities for the same moves. And the other one is called event bisimilarity. Two states are event bisimilar if they are indistinguishable by any sub-σ-algebra of events that respects the dynamics in the process. For any general Markov process, event bisimilarity coincides with logical equivalence and is a superset of state bisimilarity [4]. For Markov processes on analytical spaces or Polish spaces [5][7], these three kinds of equivalences are the same, which is the well-known Hennessy-Milner property. However, a general Markov process does not necessarily satisfy the Hennessy-Milner property [12].
Conceptually, there is a mismatch between approximating Markov processes and bisimilarities in the literature. Most approaches to approximate Markov processes [6][15][3][13] employ similar syntactic machineries. The limit of the approximating Markov processes is the quotient Markov process with respect to event bisimilarity (or logical equivalence). However, it is the quotient Markov process with respect to state bisimilarity that preserves the dynamics of the original Markov process.
In order to understand better the approximation of Markov processes, we study in this paper approximating bisimilarity for general Markov processes. There are two approaches for approximating bisimilaries: bottom-up and top-down. The ap- proximation according to the bottom-up approach is essentially syntactic and con- sists of a sequence of n-bisimilarities, which corresponds to logical equivalence up to depth n. So this approach is about event bisimilarity and is in spirit closely related to those of approximating Markov process in the literature. The second and top-down approach is semantical and studies state bisimilarity from the perspective of fixed-point theory. Given a Markov process M = ⟨Ω, Σ,τ⟩, we characterize its state bisimilarity as the greatest fixed point of a composition O of two natural set operators between equivalence relations on Ω and sub-σ-algebras of Σ (Section 4). Not only may state bisimilarity be obtained from the universal relation on Ω by iterating α times the composite operator O for some ordinal α, but also it can be reached top-down from event bisimilarity by iterating β times O for some ordinal β. This top-down approach is actually reflected in many algorithms of computing bisimilarity in the literature [5] [6]. In this paper, we employ the above ordinal β to measure the gap from event bisimilarity to state bisimilarity. S´anchez Terraf
[12] constructed an example and showed that the gap there is at least one. In this paper, we employ a Smith-Volterra-Cantor set (so-called fat Cantor set) to build an example and show that the gap is beyond the limit ordinal ω. This implies that the operator O is not continuous and the gap between state and event bisimilarities is very big. Also the example illustrates the gap between the above two approaches for approximating bisimilarities: bottom-up and top-down.
At the end of the paper, we present a general theory about filtration as an ap-

proach of approximating Markov processes and discuss its relations to the above approaches to approximate bisimilarities. In particular we provide another charac- terization of the Hennessy-Milner property through ﬁltration. Essentially, a filtra- tion of a Markov process Mj through a sublanguage Lj of the whole language L for Markov processes is its quotient that respects the satisfiability of all formulas in Lj. We show (Theorem 5.4) that a Markov process satisfies the Hennessy-Milner property iff it has only one filtration through the language L.

Preliminaries
Let A be a (Boolean) algebra on a set X, i.e. a non-empty collection of subsets of X closed under complements and binary unions. A is a σ-algebra if it is also closed under countable unions. If A is a σ-algebra, then X = ⟨X, A⟩ is a measurable space and the elements of A are usually called events or measurable subsets of X. We write σ(A0) for the smallest σ-algebra containing a given set A0 of subsets of A. When σ(A0) = A, we usually say that A0 generates A. A measurable function f : ⟨X, A⟩ → ⟨Xj, Aj⟩ is a function f : X → Xj such that, for any Aj ∈ Aj,f—1(Aj) ∈ A where ⟨Xj, Aj⟩ is also a measurable space. A set function μ : A→ [0, ∞] on A in X is ﬁnitely additive if μ(A1 ∪A2)= μ(A1)+μ(A2) whenever A1 and A2 are disjoint elements of A. μ is called a (countably additive)measure if it satisfies the following conditions:
μ(∅)= 0;
μ(S∞  Ai) = Σ∞  μ(Ai) where {Ai}∞	is a pairwise disjoint sequence of
events of A.
The second property is usually called the countable additivity. The measure μ is ﬁnite or inﬁnite as μ(X) < ∞ or μ(X) = ∞. If μ(X) ≤ 1, then μ is called a subprobability measure. If μ(X) = 1, then μ is called a probability measure. A metric space ⟨X, ρ⟩ is complete if any Cauchy sequence has a limit in X, and ρ is called a complete metric. A topological space ⟨X, τ⟩ is called separable if it has a countable dense subset. A Polish space ⟨X, τ⟩ is a separable topological space which is metrizable through a complete metric. The Borel σ-algebra B(X, τ ) for the topology τ is the smallest σ-algebra that contains τ . An analytical space is the image of a Polish space under a continuous function from one Polish space to another. The interested reader may refer to [1] for the basics about measure theory.
A transition (sub)probability function T on a measurable space X = ⟨X, A⟩ is a function from X ×A to [0, 1] satisfying the following two conditions:
for each x ∈ X, T (x, ·) is a (sub)probability measure, and
for each A ∈ A, T (·, A) is a measurable function.
T is also called a Markov kernel. A Markov process M is a structure ⟨X, A,T⟩, where ⟨X, A⟩ is measurable space and T is a subprobability transition function. A function f : ⟨X, A,T⟩ → ⟨Xj, Aj,Tj⟩ is a zigzag morphism if it is surjective, measurable, and the following equality holds:

T (x, f—1(Aj)) = T j(f (x), Aj), for any x ∈ X, Aj ∈ Aj.
The two Markov processes ⟨X, A,T⟩ and ⟨Xj, Aj,Tj⟩ are probabilistically bisimilar if there is a Markov process ⟨Xjj, Ajj,T jj⟩ with two surjective zigzag morphisms hj : Xjj → Xj, and h : Xjj → X.
One important result about Markov processes is that there is a Hennessy-Milner logic to characterize the above probabilistic bisimulation. A formula φ of the logic is formed by the following sytax:
φ := Т| ¬φ | φ1 ∧ φ2 | Lrφ(r ∈ Q ∩ [0, 1])
where Q is the field of rationals. L denotes the language of this simple syntax. The depth dp(φ) of formulas φ is defined inductively as in modal logic. Ln denotes the sublanguage of L of formulas of depeth ≤ n (n = 0, 1, 2, ··· ). The interpretation of formulas in the Markov process M = ⟨S, A,T⟩ is straightforward except the following crucial clause:
M, w |= Lrφ iff T (w)([[φ]]M ) ≥ r, where [φ]]M := {w ∈ S : M, w |= φ}.
A formula φ is called satisfied at w in M if M, w |= φ. Two states in S are called logical equivalent if they satisfy the same set of formulas in L. The following is the well-known theorem about the Hennessy-Milner property or expressivity of Markov processes [5][7][8].
Theorem 2.1 Let ⟨S, A,T⟩ be a Markov process in which S is a Polish space and A is a Borel σ-algebra. Two states are probabilistically bisimilar iff they satisfy the same set of formulas of L.
Before moving to the main part, we first fix some notations. Let ⟨Ω, Σ⟩ be a measurable space and R be an equivalence relation on Ω. For E ⊆ Ω, E/R denotes the set {[s]R : s ∈ E} and, for Σj ⊆ Σ, Σj/R = {Ej/R : Ej ∈ Σj}. It is easy to see that ⟨Ω/R, Σ/R⟩ is also a measurable space. Conversely, for B ⊆ Ω/R, B∪ denotes
S B and, for Σjj ⊆ Σ/R, Σjj denotes the set {B∪ : B ∈ Σjj}. In particular, 2Ω/R
denotes the set {A ∈ 2Ω : A = C for some C ∈ 2Ω/R} 3 . For the equivalence relation R on Ω, elements of Σ are called R-closed if they are also unions of R- equivalence classes. Σ(R) denotes the sub-σ-algebra of R-closed events in Σ, i.e.,
Σ ∩ 2Ω/R . Let Σ(·) denote this mapping from equivalence relations on Ω to sub- σ-algebras of Σ. Conversely, for any sub-σ-algebra Σj of Σ, R(Σj) denotes the equivalence relation:
sR(Σj)sj if, for any Aj ∈ Σj (s ∈ Aj ⇔ sj ∈ Aj).
Let R(·) denote this mapping from sub-σ-algebras of Σ to equivalence relations on Ω. It is easy to check that, given the space (Ω, Σ), these two maps Σ(·) and R(·) form a Galois connection [4]:
for any sub-σ-algebra B of Σ, B⊆ Σ(R(B));
for any equivalence relation Rj on S, Rj ⊆ R(Σ(Rj)).

3 In topology, it is usualy denoted as (Ω/R)∪.

For a Markov process M = ⟨Ω, Σ,τ⟩ on ⟨Ω, Σ⟩, we define a relation RT (M ) as follows: any s and t in Ω,
(s, t) ∈ RT (M ) whenever τ (s, E)= τ (t, E) for all E ∈ Σ.
Whenever τ is clear, we also write RT (M ) as RT (Σ). Let RT (·) denote this mapping from sub-σ–algebras of Σ to equivalence relations on Ω. RT (·) and Σ(·) don’t generally form a Galois connection (Example 3.3). Let Σj be a sub-σ-algebra of Σ. We say that Σj is stable with respect to M = ⟨Ω, Σ,τ⟩ if, for all E ∈ Σj, r ∈ [0, 1],
{w ∈ Ω: τ (w, E) > r}∈ Σj.
It is easy to see that Σj is stable iff τ (·, E) is Σj-measurable for each E ∈ Σj,i.e.,
⟨Ω, Σj,τ⟩ is a Markov process [4].
Lemma 2.2 Let R be an equivalence relation on Ω and Σj be a sub-σ-algebra of Σ
such that Σj is stable.
⟨Ω, Σ(R),τ⟩ is a Markov process if and only if τ (·, E) is constant on R-classes for all E ∈ Σ(R).
R(Σj) ⊆ RT (Σj).
Note that, generally, Part 2 does not hold if Σj is not stable.
Lemma 2.3 Let ⟨Ω, Σ,τ⟩ be a Markov process, Σ1 and Σ2 be two sub-σ-algebras of
Σ, and R1 and R2 be two equivalence relations on Ω.
If Σ2 ⊆ Σ1, then RT (Σ2) ⊇ RT (Σ1) and R(Σ2) ⊇ R(Σ1).
If R1 ⊆ R2, then Σ(R1) ⊇ Σ(R2).
If Σ2 ⊆ Σ1, then Σ(RT (Σ2)) ⊆ Σ(RT (Σ1)).
If R1 ⊆ R2 , then RT (Σ(R1)) ⊆ RT (Σ(R2)).
Fixed-point characterization of state bisimilarity
In the following sections, we consider a given Markov process M = ⟨S, A,τ⟩ and study relationships between sub-σ-algebras of A and equivalence relations on S.
Definition 3.1 An equivalence relation R on Markov process M := ⟨S, A,τ⟩ is called a state bisimulation if R ⊆ RT (A(R)), namely,
for any s, t ∈ S, sRt implies that τ (s, E)= τ (t, E) for every E ∈ A(R).
In other words, R is a state bisimulation if it is a post-ﬁxpoint of the composite operator RT (A(·)). From Part (1) of Lemma 2.2, we know that R is a state bisimu- lation iff ⟨S, A(R),τ⟩ is a Markov process. Two sates s and t in S are state bisimilar if there is a state bisimulation R such that (s, t) ∈ R. An equivalence relation Rj on M is called an event bisimulation if it is defined through a Markov process with a sub-σ-algebra Aj in the sense that
Rj = R(Aj), i.e., for any s, t ∈ S, sRjt iff s and t are indistinguishable in Aj;
⟨S, Aj,τ⟩ is a Markov process.

Two states s and t are event bisimilar if there is an event bisimulation Rj such that (s, t) ∈ Rj.
The classes of both state and event bisimulations are closed under the following operation: for arbitrary index set I,
i∈I Ri := (Si∈I Ri)∗ where (Si∈I Ri)∗ denotes the transitive closure of the rela-

Thus state bisimilarity is the union of all state bisimulations, and event bisimilarity that of state bisimulations. ≈M and ∼M denote state and event bisimilarities on M , respectively. When the context is clear, we usually drop the subscript M .
Originally, Danos et. al. [4] would like to present event bisimulation as a weak- ening of state bisimulation. However, from the following example (adapted from Example 4.11 in [4]), we know that a state bisimulation R is not in general an event bisimulation although a closely-related bigger state bisimulation R(A(R)) is indeed an event bisimulation (part 4 of the following proposition, which is from [4]).
Proposition 3.2 Let R be a state bisimulation.
R ⊆ R(A(R));
If Λ is a sub-σ-algebra of A, R(Λ) = R(A(R(Λ))) and Λ ⊆ A(R(Λ));
R is an event bisimulation iff R = R(A(R));
R(A(R)) is both a state bisimulation and an event bisimulation.
Example 3.3 Let S = [0, 1] and B be the σ-algebra of Borel sets on S. A non- Lebesgue-measurable subset N of [0, 1] and its complement Nc as equivalence classes define an equivalence relation R on S. Note that B(R) = {∅, S}. Now we define a Markov kernel τ on ⟨S, B⟩ such that R is a state bisimulation but not an event bisimulation. Let λ be the usual Lebesbegue measure. Assume that s1 and s2 are two points in N and t in Nc. Define τ j as
τ j(s, E)= λ(E) for any s ∈ S and E ∈ B.
It is easy to see that τ j is a Markov kernel on ⟨S, B⟩. Now we obtain τ from τ j by modifying the measures only at s1 and s2 as follows:
τ (s1, {s})=1= τ (s2, {t}).
Such τ is alsoaa Markov kernel on ⟨S, B⟩. So ⟨S, B(R),τ⟩ is a Markov process and hence R is a state bisimulation. Since R Ç {(s, sj): s, sj ∈ S} = R(B(R)), R is not an event bisimulation according to Proposition 3.2. Moreover, B(RT (B)) Ç B and hence RT (·) and B(·) don’t form a Galois connection.
In the remainder of this section, we will investigate state (event) bisimulation from the perspective of ﬁxed-point theory. From the above Proposition 3.2, we know that, if an equivalence relation R on S is both a state bisimulation and an event bisimulation, it is a fixed point of the operator R(A(·)) on the class of equivalence relations on S.

Theorem 3.4 Both state bisimilarity and event bisimilarity are ﬁxed points of the composite operator R(A(·)). So state bisimilarity ≈ is also an event bisimulation and hence ≈ ⊆ ∼.
Proof. From Proposition 3.2, we know that ≈⊆ R(A(≈)) and R(A(≈)) is a state bisimulation. Since ≈ is the union of all state bisimulations, ≈ = R(A(≈)). The proof for event bisimilarity is similar.	2
However, event bisimilarity ∼ is not the greatest fixed point of the operator, since the universal relation S × S is also a fixed point. In the next section, we will show that generally the above containment in Theorem 3.4 is strict.
Theorem 3.5 The state bisimilarity ≈ is the greatest ﬁxed point of the composite operator RT (A(·)).
Proof. We know from Theorem 3.4 that, for state bisimilarity ≈, ≈ = R(A(≈)). Since ⟨S, A(≈),τ⟩ is a Markov process, ≈= R(A(≈)) ⊆ RT (A(≈)) (according to Lemma 3.2). Let Rj denote RT (A(≈)). It follows that A(Rj) ⊆ A(≈) and hence τ (·, E) is constant on Rj-classes for all E ∈ A(≈) and hence is constant on Rj- classes for all E ∈ A(Rj). It follows from Lemma 2.2 that Rj is a state bisimulation. Since we have shown ≈⊆ Rj and ≈ is the greatest state bisimulation, the state bisimilarity ≈ is the same as Rj. In other wors, ≈ is also the fixed point of the operator RT (A(·)). It is also the greatest fixed point. Indeed, each fixed point R of RT (A(·)) is also a state bisimulation and hence is contained in the state bisimilarity
≈.	2
One may also appeal directly to the well-known Tarski-Knaster Theorem (Chap- ter 1 of [11]) to show that state bisimilarity is the greatest fixed point of the compos- ite operator RT (A(·)). Desharnais et.al. [6] also studied state bisimilarity from the perspective of fixed point but did not consider its relationship with other bisimilar- ities. The main purpose of our above presentation of state bisimilarity by detouring to transition bisimilarity is to characterize both the relationships among different bisimulations and the gaps among them through the operator RT (A(·)).
Gap between state and event bisimilarities
For simplicity, we use O to denote the composite operator RT (A(·)). For a relation
R, we construct by transfinite induction a chain of equivalence relations on M =
⟨S, A,τ⟩ as follows:
Oα+1(R)= O(Oα(R));
Oλ(R)= Sα<λ Oα(R) if λ is a limit ordinal. According to Lemma 2.3, O is monotonic.
Theorem 4.1 For the above operator O,
The greatest ﬁxed point exists and is Oα(Ru) for some ordinal α. So state bisimilarity can be obtained by iterating the operator O α times from the uni-

versal relation Ru for some ordinal α whose cardinality is no larger than that of S.
state bisimilarity ≈ can be obtained from event bisimilarity ∼ by iterating α
times O for some ordinal α; in other words, ≈ = Oα(∼).
Proof. The first part follows trivially from Tarski-Knaster’s fixed point Theorem and the second from Theorem 3.5 and Lemma 2.3.	2
The above theorem tells us that the ordinal α in the equation ≈ = Oα(∼) may be employed to “measure” the gap between state bisimilarity and event bisimilar- ity. In the following, we employ a Smith-Volterra-Cantor set (or simply SVC set) to construct an example to show that state bisimilarity can not be obtained by iterating ω times the operator O from event bisimilaity. This example illustrates the gaps between these two bisimilarities and further between the two approaches for approximating bisimilarity: top-down and bottom-up. Also this example shows that O is not downward continuous (Corollary 4.7). But, if ⟨S, A⟩ is analytical or discrete, then state bisimilarity and event bisimilarity coincide and the operator O is continuous ([4] and [9]).
Example 4.2 (SVC-set-construction) We define a sequence of partitions Πi(i ≥ 0) and corresponding equivalence relations Ri(i ≥ 0) of S = [0, 1] inductively as follows. For an interval I of S, let B(I) denote the σ-algebra of Borel sets in I, C(I) the countable subclass that generates the σ-algebra and M(I) the Lebesgue completion. There is a non-Lebesgue-measurable subset E0 of [ 1 , 1]. Let B0 denote σ(C[ 1 , 1]) ∪ {[0, 1 ], E0}). The construction will proceed in steps. At the first step,
2	2
let I1,1 denote the open interval ( 1 · 3 , 1 · 5 ). Thus I1,1 is the open middle of the
2	8 2	8
interval I0 := [0, 1 ] of length 1 ·  1  . The second step involves performing the first
2	2	22·1
step on each of the two remaining closed intervals of I0 \ I1,1. That is, we produce
two open intervals I2,1 and I2,2, each being the open middle with length 1 ·  1  of
2	22·2
one of the two intervals compromising I0 \ I1,1. At the i-th step we produce 2i—1
open intervals, Ii,1, Ii,2, ··· ,I  i−1 , each of length 1 ·  1 . The (i + 1)-th step consists
i,2	2 22i
of producing open middles of length 1 ·   1	 of each of the intervals of

2
I \ Si
22(i+1)
S2j−1 I	.

D denotes [0, 1 ]. For any natural number i, let D
denote the set I \Si
S2j−1 I	.

With Dω denoting the SVC set with respect to [0, 1 ], we define its complement by

I0 \ Dω
∞
j=1
2j−1
k=1
j,k

D0 0	1
2	E0
D1
I1,1	E0
D2 							 
I2,1	I2,2	E0
D3  
I3,1	I3,2	I3,3	I3,4
E0
···	··· 
Dω
E0
There are some facts about this SVC set Dω that we need for the following construction.
Dω is a closed set and has a positive measure 1 . In fact, the total sum of the
lengths of the deleted open intervals is Σ∞ 1 4 1	= 1 .
Dω contains a non-Lebesgue-measurable subset Dω+1, since Dω has a positive measure.
Dω is totally disconnected,i.e., all connected components are singletons. That is to say, each connected component in Dω is a singleton.

Set R0 := {(x, x) : x ∈ ( 1 , 1]}∪ {(x, y) : x, y ∈ [0, 1 ]}. Next we define another
2	2
equivalence relation R1 on [0, 1] which refines R0 by simulating the trisection process
in the construction of the SVC set Dω.
1
R1 := {(x, x): x ∈ ( 2 , 1]}
∪{(x, y): x, y ∈ I1,1}
∪{(x, y): x, y ∈ I0 \ I1,1}
More generally, we define, for i ≥ 1,
1
Ri := {(x, x): x ∈ ( 2 , 1]}

i
∪	{(x, y): x, y ∈
j=1
2j−1
Ij,k}
k=1



∪{(x, y): x, y ∈ I0 \ 
2j−1
Ij,k}

j=1 k=1
Rω denotes the intersection of all Ri’s, i.e., Rω =	i Ri. Actually Rω can be expressed as follows:

1
Rω = {(x, x): x ∈ ( 2 , 1]}
∞
∪	{(x, y): x, y ∈
j=1




2j−1
Ij,k}
k=1
∞ 2j−1

∪{(x, y): x, y ∈ I0 \ 
  Ij,k}



Note that I0


∞
j=1



2j−1
k=1



j,k
j=1 k=1

is precisely the SVC set Dω


with respect to [0, 1 ].

Define Bn := σ(C[ 1 , 1] ∪ {[0, 1 ], E0}∪ {Dj : j ≤ n}) for n ≤ ω +1 where ≤ is the
2	2
ordinal relation.
Let Cω+1 denote C[ 1 , 1] ∪ {[0, 1 ], E0}∪ {Di : i = 1, 2, ···} ∪ {Dω+1}, B—i the
2	2
σ-algebra σ(Cω+1 \ {Di})(i = 1, 2, ··· ) and B—(ω+1) the σ-algebra σ(Cω+1 \ {Dω+1}).
Note that all the events in Cω+1 are Lebesgue-measurable except Dω+1 and E0. So Bω+1 = σ(Cω+1) and is countably generated. The following Extension Theorem is the most important “weapon” that we will use to construct our Markov kernel τ .


Proposition 4.3 (Theorem 1.12.14 in [2]) Assume that
μ is a ﬁnite nonnegative measure on the measurable space ⟨Ω, Σ⟩; and
A is a subset of Ω such that μ∗(A) < μ∗(A) where μ∗ and μ∗ are the inner and outer measures of μ, respectively.
Then, for any r such that μ∗(A) ≤ r ≤ μ∗(A), there is a countably additive measure μj on the σ-algebra σ(Σ ∪ {A}) such that μj(A)= r and μj = μ on Σ.


By appealing to the above theorem, we obtain a measure λω on Bω such that λω is an extension of the Lebesgue measure on the sub-σ-algebra generated by C \ {E0, Dω+1}. It is easy to see that, since Dω+1 is a non-Lebesgue-measurable subset of [0, 1 ], (λω)∗(Dω+1) < (λω)∗(Dω+1). According to the above Extension Theorem, for any r such that (λω)∗(Dω+1) ≤ r ≤ (λω)∗(Dω+1), there is a countably

additive extension λr
such that λr
= λω on Bω and λr
(Dω+1) = r.  Let

Iω+1 = {r : (λω)∗(Dω+1) ≤ r ≤ (λω)∗(Dω+1)}. There is an injective and increasing
f from C to the set Iω+1. For each x ∈ C, if f (x) = r, then we also use λf(x) to
denote λr	. Especially, we simply use λω+1 to denote the “last” such extension
f ( 1 )	f (x)
λ  2 . Note that λ	is a measure on Bω+1 for all x ∈ C.
ω+1	ω+1
It is easy to check that, for each Di(i = 1, 2, ··· ),
(λω+1 T5−i )∗(Di)= λ(Di+1) < λ(Di—1)= (λω+1 T5−i )∗(Di)
Similarly, according to Theorem 4.3, there is a measure λ—i on Bω+1 such that
λ—i(Di) /= λω+1(Di) and λ—i = λω+1 on B—i.

Now we define a Markov kernel on the measurable space ⟨S, Bω+1⟩.
⎧⎪ x · λω+1(E) if x ∈ [ 1 , 1],

	

⎪⎪⎩
2	ω+1
1 · λ
2
(E) if x ∈ S2i−1 I

Lemma 4.4 The above deﬁned M := ⟨S, Bω+1,τ⟩ is a Markov process.
Proof. The crucial part is to show that τ (·, Dω+1) is Bω+1-measurable. This follows from the fact that f is injective and increasing.	2
Lemma 4.5 [[L]]M := {[[φ]]M : φ ∈ L}⊆ {E : E = E1 ∪ [0, 1 ] for some E1 ∈ B[ 1 , 1]}.
2	2
And the logical equivalence or event bisimilarity ∼M is
R0 = {(x, x): x ∈ ( 1 , 1]}∪ {(x, y): x, y ∈ [0, 1 ]}
2	2
Theorem 4.6 (Main Theorem) For simplicity, let A denote the reference σ-algebra Bω+1. For the above sequences of σ-algebra Bi and of equivalence relations Ri, they satisfy the interrelations illustrated as follows:

5ω+1 ¸˛
≥	σ(∪i5i)
RT (·)
··· ¸¸
≥	51 ¸¸
RT (·)
≥	50 ¸˛
RT (·)
≥	σ([[L]]M
R(·)
RT (·)

A(·)
A(·)
A(·)
A(·)
z_J 

···	⊆	Rω
···	Ç	R2
Ç	R1
Ç	R0(=~M )

Corollary 4.7 A(Rω)= Bω+1 and RT (Bω+1)  Rω. So	i O(Ri) ≥ O( i Ri) and hence O is not downward continuous.
Proof. The first part is straightforward. The second one follows from the fact

RT (B
)= {(x, x): x ∈ [ 1 , 1] ∪ C}∪ S∞
S2j−1 I

and hence RT (Bω+1) Ç Rω.	2

Filtration and Hennessy-Milner property
In this section, we simulate Goldblatt’s work in [10] to develop a general theory about the relationship among bisimilarity, filtration and Hennessy-Milner property by providing another characterization of the Hennessy-Milner property through fil- tration (Theorem 5.4). The following proposition from [4] tells us that event bisim- ilarity is characterized by the simple logic L.
Theorem 5.1 For the Markov process M = ⟨S, A,τ⟩,
⟨S, σ([[L]]M ),τ⟩ is a Markov process;
R(A(∼)) =∼;
σ([[L]]M ) is the smallest stable sub-σ-algebra Aj that deﬁnes ∼, i.e., R(Aj) =∼.
From the above proposition, we know that A(∼) is the biggest σ-algebra that defines ∼ but is generally not the biggest stable σ-algebra that defines ∼ because

otherwise ∼ = ≈ (Theorem 5.4).
However, the biggest stable σ-algebra that defines ∼ always exists. Let F = {B : A(∼) ⊇B ⊇ σ([[L]]M ), ⟨S, B,τ⟩ is a Markov process }. F is a complete lattice under the following lattice operations: for (Bi)i∈I ⊆ F,
i Bi =  i Bi;
i Bi =  {B ∈ F : B⊇ Bi for all i ∈ I}.
Let F denote  F. It follows immediately that ⟨S, F,τ⟩ is a Markov process and is the biggest stable sub-σ-algebra that is contained in A(∼) and defines event bisimilarity ∼.
In the following, we give a general definition of filtration. Essentially, a filtration of a Markov process Mj through a sublanguage Lj is its quotient that respects the satisfiability of all formulas in Lj. Let Lj be a subset of language of L which is closed under subformulas. In other words,
Т∈ Lj;
if Lrφ ∈ Lj, φ ∈ Lj;
if φ ∧ ψ ∈ Lj, φ ∈ Lj and ψ ∈ Lj.
Lj defines an equivalence relation ∼L′ on S: s ∼L′ t if they satisfy the same set of

formulas in Lj. Any Markov processes M
~L′
= ⟨S/~L′
, Aj,τ A′
L
⟩ on the set S/~L′

of equivalence classes where Aj ⊆ A/~ ′ is called a ﬁltration of M through the
sub-language Lj if it satisfies the following property: for any s ∈ S and φ ∈ Lj,
M, s |= φ if and only if M~L′ , [s]L′ |= φ
When the context is clear, we simply call M~L′ a filtration. For the measurable

σ([[L]]M )/∼L′
j S	j

[s]L′ and E ∈ σ([[L]]M )/~L′ . From Proposition 2.2, we know σ([[L]]M )/~L′ is stable.

Theorem 5.2 ⟨S/
σ([[L]]M )/∼L′
, σ([[L]] )/	⟩ is a ﬁtration.

~L′
M	~L′ , τ~L′

It is clear that, for any filtration M~ ′ = ⟨S/~ ′ , Aj, τ~ ′ ⟩, Aj ⊇ σ([[Lj]]M∼
) and

⟨S/~ ′ , σ([[Lj]]M∼
L	L	L	L′
), τ~L′ ⟩ is a filtration.

In the following, we employ the idea of averaging in [3] to show that, for any
σ-algebra Aj such that A/~ ′ ⊇ Aj ⊇ σ([[Lj]]M∼  ), there is always a filtration
⟨S/~ ′ , Aj, τ~ ′ ⟩ with Aj as its σ-algebra of events. The main task is to find a
L	L
Markov kernel τ~ ′ such that ⟨S/~ ′ , Aj, τ~ ′ ⟩ is a Markov process.
L	L	L
In order to apply averaging here, we assume that there is a prior probability
measure P on the measure space ⟨S, A⟩. Note that any ∼L′ -equivalence class [s]~L′

′
is A-measurable. We define a mapping τ~L′ : S~′
× Aj → [0, 1] as follows: for any

L′ ∈ S~′
and Aj ∈ Aj,
∫	τ (s,  Aj)dP (s)

τ~L′ ([s]L′ ,A ) :=
From [3] and Proposition 2.2, we know that
P ([s]L′ )	.

Theorem 5.3 For such deﬁned τ A′ ,
L

⟨S/~L′
, Aj,τ A′
L
⟩ is a Markov process and hence is a ﬁltration of M through the

sub-language Lj.
⟨S, Aj ,τ⟩ is a Markov process if and only if the natural mapping from M
j	A∼	j	j
to ⟨S/~L , A ,τ	⟩ is a zigzag morphism, i.e., for any s ∈ S and A ∈ A ,

A′
~L′
([s]

~L′
, Aj)= τ (s, S Aj).
j



σ([[L′]]M )/∼ ′

For the language L , ⟨S/~ ′ , σ([[L]]M )/~ ′ , τ~ ′	L ⟩ is called the smallest ﬁltra-
L	L	L

tion and ⟨S/
, A/
A/∼L′ ⟩ the greatest ﬁltration on S/
. Note that gen-

~L′	~L′ , τ~L′
~L′

erally the natural mapping from M to ⟨S/~L′
, Aj,τ A′
L
⟩ is not a zigzag morphim

because τ A′
L
may be different from τ . That is to say, generally we don’t have

A′
~L′
([s]
~L′
, Aj) = τ (s, S Aj) for s ∈ S and Aj ∈ Aj. But, for Aj ∈ σ([[L]]M
), we

always have that, for any s ∈ S, τ A′
L
([s]

~L′
, Aj)= τ (s, S Aj).

In [15], we provides a sequence of filtrations through a sequence of ﬁnite lan-

guages (Li)∞
, which are closed under subformulas, to approximate the original

Markov process M . This is a kind of approximation based on the so-called bottom- up approximating (event ) bisimilarity.
The following theorem is a generalization of Theorem 15 in [10] and provides another characterization of the Hennessy-Milner property through filtration.
Theorem 5.4 For the whole language L,

the natural mapping from M to ⟨S/~L
, A/~
,τ A(~)⟩ is a zigzag morphism if and

only if A(≈) = A(∼) or equivalently ≈ = ∼, i.e., M satisﬁes the Hennessy-
Milner property.
A(∼) = σ([[L]]M ) iff there is only one ﬁltration through the language L iff ≈ =
∼.
Proof. For the second part, we note that there is only one filtration through the language L iff, for each Aj ∈ A(∼), τ (·, Aj) is constant on [s]~ for every s ∈ S. 2
The following is about the position of filtration in a general picture of interre- lationships among different σ-algebras and equivalence relations.


filtration	→	A/,∼ ,
(·)/∼
≥	7/,∼ ,
(·)/∼
≥	σ([[L,]])/∼,
(·)/∼



A,,
A(·) R(·)
J 
RA
≥	A,≈ ,
A(·) R(·)
⊆	≈J 
≥	A∼


⊆
7	≥	σ([[L]])


Conclusion
In this paper, we study the difference between event and state bisimilarities from the perspective of fixed point theory. We quantify this difference by counting the

iteration times of the operator O from event bisimilarity to state bisimilarity. Our work provides insights about the Hennessy-Milner property for general Markov pro- cesses. At the end of this paper, we provide another characterization of this prop- erty through filtration. Approximate bisimilarity [14] is another important notion to reason about approximate equivalence of processes. It is a subject for future work to study approximating bisimilarity for Markov processes from the perspective of approximate bisimilarity.

References
P. Billingsley. Measure and Probability. John Wiley & Sons, Inc., third edition, 1995. Wiley Series in Probability and Mathematical Statistics.
V.I. Bogachev. Measure Theory. Springer-Verlag Berlin Heidelberg, 2007.
P. Chaput, V. Danos, P . Panangaden, and G. D. Plotkin. Approximating markov processes by averaging. In ICALP (2), pages 127–138, 2009.
V. Danos, Josee Desharnais, Fran¸cois Laviolette, and Prakash Panangaden.	Bisimulation and cocongruence for probabilistic systems. Inf. Comput., 204(4):503–523, 2006.
J Desharnais, A. Edalat, and Panangaden P. Bisimulation for labeled markov processes. Inf. and Compt., 179:163–193, 2002.
J. Desharnais, V. Gupta, R. Jagadeesan, and P. Panangaden. Approximating labeled markov processes.
Inf. and Comp., 184:160–200, 2003.
E. E Doberkat. Stochastic relations: congruence, bisimulations and the hennessy-milner theorem. SIAM
J. Computing, 35(3):590–626, 2006.
E. E Doberkat. Stochastic Coalgebraic Logic. EATCS Mongraphs in Theoretical Computer Sciences. Springer, 2010.
E. E Doberkat. Lattice properties of congruences for stochastic relations. Ann. Pure Appl. Logic, 163(8):1016–1029, 2012.
R. Goldblatt. Saturation and the hennessy-milner property. In M. de Rijke A. Ponse and Y. Venema, editors, Modal Logic and Process Algebra, pages 107–129. CSLI Publications, Stanford, CA, 1995.
D. Harel, D. Kozen, and J. Tiuryn. Dynamic Logic. Foundation of Computing Series. MIT Press, Cambridge, 2000.
P. Terraf. Unprovability of the logical characterization of bisimulation. Inf. Comput., 209(7):1048– 1056, 2011.
F. van Breugel and Worrell J. Approximating and computing behavioural distances in probabilistic transition systems. Theor. Comput. Sci., 360(1-3):373–385, 2006.
M. Ying and M. Wirsing. Approximate bisimilarity. In AMAST, pages 309–322, 2000.
C. Zhou and M. Ying. Approximation of markov processes through filtration. Theoretical Comput. Sci., 446:75–97, 2012.
