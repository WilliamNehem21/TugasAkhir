	Electronic Notes in Theoretical Computer Science 190 (2007) 147–166	
www.elsevier.com/locate/entcs

Probabilistic π-Calculus and Event Structures1
Daniele Varaccaa Nobuko Yoshidab
a PPS - Universit´e Paris 7 & CNRS, France
b Imperial College London, UK

Abstract
This paper proposes two semantics of a probabilistic variant of the π-calculus: an interleaving semantics in terms of Segala automata and a true concurrent semantics, in terms of probabilistic event structures. The key technical point is a use of types to identify a good class of non-deterministic probabilistic behaviours which can preserve a compositionality of the parallel operator in the event structures and the calculus. We show an operational correspondence between the two semantics. This allows us to prove a “probabilistic confluence” result, which generalises the confluence of the linearly typed π-calculus.
Keywords: Event structures, probabilistic processes, π-calculus, linear types


Introduction and motivations
Probabilistic models for concurrency have an extensive literature: most of the stud- ies concern interleaving models [21,27,10], but recently, true concurrent ones have also been studied [20,14,1,30,33]. This paper presents an interleaving and a true concurrent semantics to a probabilistic variant of the π-calculus. The variant we consider is similar to the ones presented in [16,7], yet contains important differences. The main difference, which motivates all the others, is the presence of types.
The various typing systems for mobile processes have been developed in order to provide disciplines to control non-deterministic behaviours statically and compo- sitionally. In probabilistic concurrency, a restriction of non-determinism becomes more essential, for example, for preservation of the associativity of parallel com- position or to guarantee freedom from any specific scheduling policies [30]. This paper performs an initial step towards a “good” typing discipline for probabilistic

1 Work partially supported by EPSRC grant GR/T04724/01, and ANR project ParSec ANR-06-SETI-010- 02.

1571-0661 © 2007 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2007.07.009

name passing, which can preserve expressiveness and can harmonise with existing probabilistic concurrent semantics and programming languages [24,11,8].
We present a typing system for the probabilistic π-calculus, inspired from a linear typing systems for the π-calculus [4,37]. The linearly typed π-calculus can embed a family of λ-calculi fully abstractly. Linearly typed processes enjoy several interesting properties. In particular they are guaranteed to be confluent, that is the computation they perform is deterministic. In the true concurrent setting, confluence can be viewed as absence of conflicts, or conflict freeness. In a conflict free system, one can have different partial runs, for instance because one chooses to execute different subsystems. However, under some basic fairness assumptions, and if we abstract away from the order in which concurrent events happen, the system will always produce the same run.
In [32], we extend the linear π-calculus by adding a nondeterministic choice. The typing system no longer guarantees conflict freeness, but the more general be- havioural property of confusion freeness. This property has been studied in the form of free choice Petri nets [25,9]. Confusion free event structures are also known as concrete data structures [5], and their domain-theoretic counterpart are the con- crete domains [19]. In a confusion free system, all nondeterministic choices are localised and are independent from any other event in the system. In the prob- abilistic setting [30], the intuition is that local choices can be resolved by a local coin, or die. The results in [30] show that probabilistic confusion free systems are probabilistically confluent. We have argued that confluence entails the property of having only one maximal computation, up to the order of concurrent events. It is then reasonable to define probabilistic confluence as the property of having only one maximal probabilistic computation, where a probabilistic computation is defined as a probability measure over the set of computations.
We provide an interleaving and a true concurrent semantics to this probabilistic π-calculus. The interleaving semantics is given as Segala automata [27], which are an operational model that combine probability and nondeterminism. The nonde- terminism is necessary to account for the different possible schedulings of the inde- pendent parts of a system. The true concurrent semantics is given as probabilistic event structures [30]. In this model, we do not have to account for the different schedulings, and that leads to the probabilistic confluence result (Theorem 6.2), one of the main original contributions of this work.
In order to relate the two semantics, we show how a probabilistic event structure generates a Segala automaton. This allows us to show an operational correspon- dence between the two semantics.
Types play an important role for a compositional semantics, which is given as a clean generalisation of Winskel’s original event structure semantics of CCS [34] to the π-calculus. In this sense, this work offers a concrete syntactic representation of the probabilistic event structures as name passing processes, closing an open issue in [30,32]. The work opens a door for event structure semantics for probabilistic λ-calculi and programming languages, using the probabilistic linear π-calculus as an intermediate formalism.

In the initial state x0 there are three possible transi- tion groups, corresponding to its three hollow children.
The left-most transition group is x0{   ai  x } 
pi	i i∈I
where I = {1, 2}, a1 = a, a2 = b and p1 = p2 = 1/2.
The right-most transition group is x {   aj  x }
0	pj	j j∈J
where J = {0, 5}, a0 = a, a5 = b and p0 = ε, p5 = 1 − ε.




Fig. 1. A Segala automaton

The proofs and the key definitions can be found in Appendix; and some non- probabilistic materials are left to [32,31].

Segala automata
To give an operational semantics to the probabilistic π-calculus we use Segala au- tomata, a model that combines probability and nondeterminism. Segala automata can be seen as an extension both of Markov chains and of labelled transition sys- tems. They were introduced by Segala and Lynch [28,27]. A recent presentation of Segala automata can be found in [29]. The name “Segala automata” appears first in [3]. It is non standard in the literature, but we prefer it to the more common, but ambiguous, “probabilistic automata”.

Notation
A probability distribution over a finite or countable set X is a function ξ : X → [0, 1] such that Σx∈X ξ(x) = 1. The set of probability distributions over X is denoted by V (X). By P(X), we denote the powerset of X. A Segala automaton over a set of
labels A is given by a finite or countable set of states X together with a transition
function t : X → P(V (A × X)). This model represents a process that, when it is in a state x, nondeterministically chooses a probability distribution ξ in t(x) and then performs action a and enters in state y with probability ξ(a, y).
The notation we use comes from [16]. Consider a transition function t. Whenever a probability distribution ξ belongs to t(x) for a state x ∈ X we will write

x{   ai  x }
(1)

pi	i i∈I
where xi ∈ X, i /= j =⇒ (ai, xi) /= (aj, xj), and ξ(ai, xi)= pi. Probability distribu- tions in t(x) are also called transition groups of x.
A good way of visualising probabilistic automata is by using alternating graphs [15]. In Figure 1, black nodes represent states, hollow nodes represent tran- sition groups.

Runs and schedulers
An initialised Segala automaton, is a Segala automaton together with an initial state x0. A ﬁnite path of an initialised Segala automaton is an element in (X × V (X ×A)×A)∗X, written as x0ξ1a1x1 ... ξnanxn, such that ξi+1 ∈ t(xi). An inﬁnite path is defined in a similar way as an element of (X × V (X × A) × A)ω.
The probability of a finite path τ := x0ξ1a1x1 ... ξnanxn is defined as

Π(τ )= 
1≤i≤n
ξi(ai, xi) .

The last state of a finite path τ is denoted by l(τ ). A path τ is maximal if it is infinite or if t(l(τ )) = ∅.
A scheduler for a Segala automaton with transition function t is a partial func- tion S : (X × V (X × A) × A)∗X → V (X × A) such that, if t(l(τ )) /= ∅ then S (τ ) is defined and S (τ ) ∈ t(l(τ )). A scheduler chooses the next probability distribu- tion, knowing the history of the process. Using the representation with alternating graphs, we can say that, for every path ending in a black node, a scheduler chooses one of his hollow sons.
Given an (initial) state x0 ∈ X and a scheduler S for t, we consider the set B(t, x0, S ) of maximal paths, obtained from t by the action of S . Those are the paths x0ξ1a1x1 ... ξnanxn such that ξi+1 = S (x0ξ1a1x1 ... ξiaixi).  The set of maximal paths is endowed with the σ-algebra generated by the finite paths. A scheduler induces a probability measure on such σ-algebra as follows: for every finite path τ , let K(τ ) be the set of maximal paths extending τ . Define ζS (K(τ )) := Π(τ ), if τ ∈ B(t, x0, S ), and 0 otherwise. It can be proved [27] that ζS extends to a unique probability measure on the σ-algebra generated by the finite paths.
Given a set of labels B ⊆ A we define ζS (B) to be ζS (Z), where Z is the set of all maximal paths containing some label from B.

A probabilistic π-calculus
Syntax and Operational Semantics
We assume the reader is familiar with the basic definitions of the π-calculus [23]. We consider a restricted version of the π-calculus, where only bound names are passed in interaction. This variant is known as πI-calculus [26]. In the typed setting, it has the same expressiveness as the full calculus [36]. The labelled transition semantics of the πI-calculus is simpler than that of the full calculus and its labels more naturally correspond to those of event structures. Syntactically, the πI-calculus is obtained by restricting the output to be of the form (ν y˜)x⟨y˜⟩.P (where names in y˜ are pairwise distinct), which we write x(y˜).P .
We extend this framework to a probabilistic version of the calculus, where output is endowed with probabilities. As in the non probabilistic case, input is similar to the “case” construct and selection is “injection” in the typed λ-calculi. The formal grammar of the calculus is defined below with pi ∈ [0, 1].





x	p in (y˜ ).P {   x¯ini⟨y˜j ⟩	 P }
x Φ	in (y˜ ).P {	xinj ⟨y˜j ⟩

 P }

!x(y˜).P {  x⟨y˜⟩ P | !x(y˜).P }	x(y˜).P {  x⟨y˜⟩  P }

1
P {   βi  P }	subj(β ) /= x
1
P {   βi  P }

pi	i i∈I	i
pi	i i∈I


	
(ν x)P {   βi  (ν x)P }	P | Q{   βi  P | Q}

pi	i
i∈I
pi	i
i∈I

P {   αi  P }
Q{   βi  Q } obj(α )= y˜
P ≡ P '	P {   βi  Q }

pi	i
i∈I	1
i	α	pi
i i∈I

P | Q{ 	αi•βi	 (ν y˜)(P | Q )}
'   βi  
pi	i i∈I


Fig. 2. Segala automaton for the probabilistic πI-Calculus


P ::= x Φi∈I ini(y˜i).Pi | x  i∈I pi ini(y˜i).Pi | P | Q | (ν x)P | 0 | !x(y˜).P
The process x Φi∈I ini(y˜i).Pi is a branching input, and no probability is attached to its events. The process x  i∈I piini(y˜i).Pi is a probabilistic selecting output, and the events are given probability denoted by the p , with the requirement that
Σi∈I pi = 1. Finally, P | Q is a parallel composition, (ν x)P is a restriction and
!x(y˜).P is a replicated input. When the input or output indexing set is a singleton we use the notation x(y˜).P or x(y˜).P ; when the indexing set finite, we can write x(in1(y˜1).P1 & ... & inn(y˜n).Pn) or x(p1in1(y˜1).P1 ⊕ ... ⊕ pninn(y˜n).Pn). We omit the empty vector and 0: for example, a stands for a().0. The bound/free names are defined as usual. We assume that names in a vector y˜ are pairwise distinct. We use ≡α and ≡ for the standard α and structural equivalences [23,17].
The operational semantics is given in terms of Segala automata, using the no- tation defined in (1) in Section 2. The labels we use are of the following form:
α, β ::=	xini⟨y˜⟩	|	xini⟨y˜⟩	| x⟨y˜⟩ |	x⟨y˜⟩	|	τ
(branching)	(selection)	(offer)	(request)	(synchronisation) With the notation above, we say that x is the subject of the label β, denoted

as subj(β), while
y˜ = y1,... , yn are the object names, denoted as obj(β). For

branching/selection labels, the index i is the branch of the label. The notation “ini” comes from the injection of the typed λ-calculus.
The rules for deriving the transitions are presented in Figure 2. The partial operation • on labels is the standard composition of dual labels. That is, an input synchronises with its dual output and produces a silent action. Formally • is defined as follows: xini⟨y˜i⟩• xini⟨y˜i⟩ = x⟨y˜⟩• x⟨y˜⟩ = τ, and undefined otherwise. 2
In particular, the selecting output synchronises with the branching input, and a synchronisation step takes place, with the probability chosen by the output process.

2 To be more precise, and in order to carry out the proofs, synchronisation labels should keep track of which synchronisation they represent. This would only complicate an already difficult presentation and we omit it here - see [32] for more explanations.

Linear types for the probabilistic π-calculus
This subsection outlines a basic idea of the linear types for a probabilistic π-calculus. The linear type discipline [4,37] controls a composition of processes in two ways: first, for each linear name there are a unique branching input and a unique selecting output; and secondly, for each replicated name there is a unique stateless replicated
input (offer, or server) with zero or more dual outputs (request, or client).
Let us consider the following example where branching and selection provide probabilistic behaviour, preserving linearity:


Q1 d=ef


a.(pin1.b ⊕ (1 − p)in2.c) | a.(in1.d & in2.e)

Q is typable, and we have either Q  τ  (b | d) or Q  τ  (c | e) . The following

1
process is also typable:
Q2 d=ef
p	1−p


a.(pin1.b ⊕ (1 − p)in2.b) | a.(in1.d & in2.e)

since whichever branch is selected, b is used once. However a.b | a.c | a is untypable as linear output a appears twice. As an example of the offer-request constraint, let us consider the following process:
Q3 d=ef ! a(x).x.(pin1 ⊕ (1 − p)in2) | a(x)x.(in1.d & in2.e) | a(x)x.(in1.f & in2.g)
Q3 is typable since, while output at a appears twice, a replicated input at a appears only once. Note that x under the replication preserves the linearity after each invocation at a. On the other hand, ! b.a | ! b.c is untypable because b is associated with two replicators.
Channel types are inductively made up from type variables and action modes: the input modes ↓, !, and the dual output modes ↑, ?. Then the syntax of types is given as follows:
τ ::= Φi∈I (τ˜i)↓ |  i∈I (τ˜i)↑ | (τ˜)!	|	(τ˜)?	|	‡
(branching)	(selection)	(offer)	(request)	(closed) where τ˜ is a tuple of types.
Branching types represent the notion of “environmental choice”: several choices
are available for the environment to choose. Selection types represent the notion of “process choice”: some choice is made by the process, possibly probabilistically. In both cases the choice is alternative: one excludes all the others. Offer types represent the notion of “available resource”: I offer to the environment something that is available regardless of whatever else happens. Request types represent the notion of “concurrent client”: I want to use an available resource. The closed type is used to represent a channel that cannot be composed further.
We write MD(τ ) for the outermost mode of τ . The dual of τ , written τ , is the result of recursively dualising all action modes, with ‡ being self-dual. A type

environment Γ is a finite mapping from channels to channel types. Sometimes we will write x ∈ Γ to mean x ∈ Dom(Γ).
Types restrict the composability of processes: if P is typed under environment Γ1, Q is typed under Γ2 and if Γ1, Γ2 are “compatible”, then a new environment Γ1 ⊙ Γ2 is defined, such that P | Q is typed under Γ1 ⊙ Γ2. If the environments are not compatible, Γ1 ⊙ Γ2 is not defined and the parallel composition cannot be typed. Formally, we introduce a partial commutative operation ⊙ on types, defined as follows 3 :
Φi∈I (τi)↓ ⊙  i∈I (τi)↑ =‡
(τ )? ⊙ (τ )! = (τ )!
(τ )? ⊙ (τ )? = (τ )?
Then, the environment Γ1 ⊙ Γ2 is defined homomorphically. Intuitively, the rule
(i) says that once we compose input-output linear channels, the channel becomes uncomposable. The rule (ii) says that a server should be unique while rule (iii) says that an arbitrary number of clients can request interactions. Other compositions are undefined.
The rules defining typing judgements P d Γ (where Γ is an environment which maps a channel to a type) are identical to the affine π-calculus [4] except a straight- forward modification to deal with the generative output, which is defined by the same rule for confusion free processes in [32], without any additional complexity due to the probability. The rules are presented in Figure 3. In (Par), Γ1 ⊙ Γ2 guar- antees the consistent channel usage like linear inputs being only composed with linear outputs, etc. In (Res), we do not allow ↑, ? or ↓-channels to be restricted since they carry actions which expect their dual actions to exist in the environ- ment. (WeakOut) and (WeakCl) weaken with ?-names or ‡-names, respectively, since these modes do not require further interaction. (LIn) and (LOut) ensure that x occurs precisely once. (RIn) is the same as (LIn) except that no free linear chan- nels are suppressed. This is because a linear channel under replication could be used more than once. (ROut) is similar with (LOut). Note that we need to apply (WeakOut) before the first application of (ROut).
We then obtain a typed version of the operational semantics by restricting the actions that are not allowed by the type environment. Informally an action is allowed by an environment if the subject of the action has a branching, selection or server type. Formally, for a label β, the predicate Γ allows β is defined as follows:
for all Γ, Γ allows τ;
if MD(Γ(x)) =↓, then Γ allows xini⟨y˜⟩;
if MD(Γ(x)) =↑, then Γ allows xini⟨y˜⟩;
if MD(Γ(x)) = !, then Γ allows x⟨y˜⟩;
if MD(Γ(x)) = ?, then Γ allows x⟨y˜⟩.
As an example, the output transition at a in a | a.0 is not allowed since a is linear

3 To simplify the notation we omit the ˜ that denotes polyadicity.





P d Γ,a : τ	a /∈ Γ	MD(τ )= !, ‡
(ν a)P d Γ	Res	0 d ∅ Zero
P d Γ	x /∈ Γ
P d Γ,x :‡	WeakCl

Pi d Γ, y˜i : τ˜i	a /∈ Γ	P d Γ	x /∈ Γ

a	p in (y˜ ).P
d Γ,a : 
(τ˜ )↑ LOut
P d Γ,x : (τ˜)? WeakOut



Pi d Γ, y˜i : τ˜i	a /∈ Γ
Pi d Γi	(i = 1, 2)

a Φ	in (y˜ ).P
d Γ,a : Φ
(τ˜ )↓ LIn
P | P
d Γ ⊙ Γ
Par



P d Γ, y˜ : τ˜ 
a /∈ Γ	6(x : τ ) ∈ Γ. MD(τ ) =?
!a(y˜).P d Γ,a : (τ˜)!	RIn
P d Γ,a : (τ˜)?, y˜ : τ˜ 
a(y˜).P d Γ,a : (τ˜)? ROut


Fig. 3. Linear Typing Rules


so that a is assumed to interact with only a.0, not with the external observer.

The typed automaton, P d Γ{  βi  P d Γ }
, is defined by adding the follow-

ing constraint:
pi	i
i i∈I

if P {  βi  P }
and Γ allows β
for all i ∈ I	then	P d Γ{  βi  P d Γ }

pi	i
i∈I	i
pi	i
i i∈I

The nature of the typing system is such that for every transition group, either all actions are allowed, or all are not, and therefore the above semantics is well defined.

Example of a probabilistic process
We consider the model of traffic lights from [24]. Let a be a driver, and let inred, inyell, ingreen represent colours of the traffic light. The process ainred(y) represents the traffic light signalling to the driver it is red, at the same time com- municating the name y of the crossing. The behaviour of the driver at the crossing is either braking, staying still, or driving ( inbrake, instill, indrive).
A cautious driver is represented by the process:

Da = a Φi∈{red,yell,green} ini(y).Pi with Pred = y(0.2inbrake ⊕ 0.8instill)
Pyell = y(0.9inbrake ⊕ 0.1indrive)
Pgreen = y(indrive)

A cautious driver watches what colour the light is and behaves accordingly. If it is red, she stays still, or finishes braking. If it is yellow, most likely she brakes. If it is green, she drives on.

A driver in a hurry is represented by the process
Da = a Φi∈{red,yell,green} ini(y).Qi with Qred = y(0.3inbrake ⊕ 0.6instill ⊕ 0.1indrive )
Qyell = y(0.1inbrake ⊕ 0.9indrive )
Qgreen = y(indrive )

This is similar to the cautious driver, but he is more likely to drive on at red and yellow. In fact, both have the same type, they check the light, and they choose a behaviour:

Da, Da da : Φi∈{red,yell,green} ( 
()↑)↓

where Φi∈I (τi)↓ is a branching type which inputs a value of type τi and  i∈I (τi)↑ is a selection type which selects a branch i with a value of type τi. Note that the type actually states that the driver chooses the behaviour after seeing the light. We can represent two independent drivers:

D2= (νa, a')(ainred


(y).R | Da | a'ingreen
(y).R | Da' )

where R = y Φi∈{brake,still,drive} ini() represents the traffic light accepting the be- haviour of the driver. We have that D2 has two transition groups, corresponding to the two drivers. Note that the typing system guarantees that each driver can perform only one of three actions, i.e. either brake, still or drive at any one time.

Probabilistic event structures
We now present the model of probabilistic event structures, that we use to give an alternative semantics to the probabilistic π-calculus. Probabilistic event structures were first introduced by Katoen [20], as an extension of the so called bundle event structures. A probabilistic version of prime event structures was introduced in [30]. In this paper we use prime event structures as we think they are the simplest and easiest to understand of all variants of event structures. Moreover the confluence theorem uses results of [30].
Below we start from basic definitions without probability.
Basic deﬁnitions
An event structure is a triple E = ⟨E, ≤, ×⟩ such that
E is a countable set of events;
⟨E, ≤⟩ is a partial order, called the causal order ;
for every e ∈ E, the set [e) := {e' | e' < e}, called the enabling set of e, is finite;
× is an irreflexive and symmetric relation, called the conflict relation, satisfying the following: for every e1, e2, e3 ∈ E if e1 ≤ e2 and e1 × e3 then e2 × e3.
The reflexive closure of conflict is denoted by =. We say that the conflict e2 × e3 is inherited from the conflict e1 × e3, when e1 < e2. If a conflict e1 × e2 is not inherited from any other conflict we say that it is immediate, denoted by e1 ×μ e2. The reflexive closure of immediate conflict is denoted by =μ. Causal dependence

and conflict are mutually exclusive. If two events are not causally dependent nor in conflict they are said to be concurrent. A labelled event structure is an event structure E together with a labelling function λ : E → L, where L is a set of labels. We introduce an interesting class of event structures where every choice is lo- calised. To specify what “local” means, we need the notion of cell, a set of events
that are pairwise in immediate conflict and have the same enabling sets.
Definition 4.1 A partial cell is a set c of events such that e, e' ∈ c implies e =μ e' and [e)= [e'). A maximal partial cell is called a cell. An event structure is confusion free if its cells are closed under immediate conflict.
Equivalently, in a confusion free event structure, the reflexive closure of imme- diate conflict is an equivalence with cells being its equivalence classes.

Probabilistic event structures
Once an event structure is confusion-free, we can associate a probability distribution with some cells. Intuitively it is as if, for every such cell, we have a die local to it, determining the probability with which the events at that cell occur.
We can think of the cells with a probability distribution as generative, while the other cells will be called reactive. Reactive cells are awaiting a synchronisation with a generative cell in order to be assigned a probability.
Definition 4.2 Let E = ⟨E, ≤, ×⟩ be a confusion free event structure, let G be a set of cells of E and let G' be the set of events of the cells in G. The cells in G are called generative. The cells not in G are called reactive. A cell valuation on (E , G)
is a function p : G' → [0, 1] such that for every c ∈ G, we have Σe∈c p(e) = 1. A
partial probabilistic event structure is a confusion free event structure together with a cell valuation. It is called simply probabilistic event structure if G' = E.
This definition generalises the definition given in [30], where it is assumed that G' = E. Note also that a confusion free event structure can be seen as a probabilistic event structure where the set G is empty.

Operators on event structures
Several operations can be defined on event structures.
prefixing a.E . This is obtained by adding a new minimum event, labelled by a. Conflict, order, and labels remain the same on the old events.
prefixed sum Σi∈I ai.Ei. This is obtained by disjoint union of copies of the event
structures ai.Ei, where the order relation is the disjoint union of the orders, the labelling function is the disjoint union of the labelling functions, and the conflict is the disjoint union of the conflicts extended by putting in conflict every two events in two different copies. It is a generalisation of prefixing, where we add an initial reactive cell, instead of an initial event.

probabilistic prefixed sum Σi∈I piai.Ei, where Ei are partial probabilistic event structures. This is obtained as above, but with the condition that the initial cell is generative, and that the probability of the new initial events are pi.
restriction E \ X where X ⊆ A is a set of labels. This is obtained by removing from E all events with label in X and all events that are above one of those. On the remaining events, order, conflict and labelling are unchanged.
relabelling E [f ]. This is just composing the labelling function λ with a function
f : L → L. The new event structure has thus labelling function f ◦ λ.
parallel composition. The parallel composition of event structures is not so simple to define, due to the possibility of synchronisation among events. We skip the technical details, that can be found in [35,31,32].
Intuitively, events in the parallel composition are the events of the two event structures, plus some new event representing synchronisation. For a labelled event structure with labels in L, the labels of the synchronisation events are obtained via a synchronisation algebra S, a partial binary operation •S defined on L. If the labels of the two synchronising event are l1, l2, the synchronisation event will have label l1 •S l2, if defined, or else it will be restricted away. The simplest synchronisation algebra is always undefined and represents the absence of synchronisation. In this case the parallel composition can be represented as the disjoint union of the sets of events, of the causal orders, and of the conflict. This can be also generalised to an arbitrary family of event structures (Ei)i∈I . In such a case we denote the parallel composition as  i∈I Ei.
All constructors above, except the parallel composition, preserve the class of partial probabilistic event structures. In the next section we present a typing system, which is designed to allow parallel composition to preserve that class.

Typed event structures
In this section we recall the notion of type for an event structure, which was defined in [31]. Types and type environments for event structures are inspired by those of the π-calculus, but they recursively keep track of the names communicated along the channels. They are generated by the following grammar:
Γ, Δ ::=	y1 : σ1,... , yn : σn
τ, σ ::=	Φi∈I Γi	|   i∈I Γi	|  i∈I Γi |  i∈I Γi  |	‡
(branching)  (selection)  (offer)  (request)  (closed type)
A type environment Γ is well formed if any name appears at most once. Only well formed environments are considered for typing event structures. The intuition behind the types is similar to the π-calculus. The main difference is that offer is not restricted to a replicated server, but represents different concurrent resources.
Given a labelled confusion free event structure E on π-calculus labels (defined in Section 3), we can define when E is typed in the environment Γ, written as



x1inp1
¸¸˛¸˛x˛1inp2
x2inq1
¸˛¸¸˛¸x˛2˛inq2	z1

1 ¸¸¸	2
¸¸¸¸
1 ¸¸¸	2
¸¸¸¸

¸¸¸	¸¸¸

τ ¸¸¸¸
¸¸¸¸¸¸¸
¸¸¸¸¸¸¸
b⟨z1⟩

ain1⟨x1⟩
b⟨z1⟩

¸˛¸˛¸˛¸¸˛˛¸a˛¸in˛¸2⟨x˛¸2⟩˛



Fig. 4. A typed event structure

E d Γ. Informally, a confusion free event structure E has type Γ if cells are par- titioned in branching, selection, request, offer and synchronisation cells, all the non-synchronisation events of E are represented in Γ, and the causality in E refines the name causality implicit in Γ. This means that if name y appears inside the type of a name x, any event whose subject is y must be causally related with an event whose subject is x.
The types are designed so that the parallel composition of typed event structures will also be typed. To define the parallel composition, we use the same synchronisa- tion algebra used in Section 3: xini⟨y˜i⟩• xini⟨y˜i⟩ = x⟨y˜⟩• x⟨y˜⟩ = τ, and undefined otherwise. The parallel composition of two typed event structures E1 d Γ1 and E2 d Γ2 is defined only when the environment Γ1 ⊙ Γ2 is defined, and in such a case the parallel composition has type Γ1 ⊙ Γ2. The formal definition of ⊙ is sim- ilar to the corresponding notion for the π-calculus, but it is recursively applied to the object names. It is designed to preserve the well formedness (linearity) of the environment. The details can be found in [31,32].
To type a partial probabilistic event structure, we type it as a non probabilistic event structure. We also make sure that only the branching cells are reactive, as they are waiting to synchronise with a dual selection cell.
Definition 4.3 Let E = ⟨E, ≤, ×, λ, G, p⟩ be a partial probabilistic event struc- ture. We say that E d Γ, if the following conditions are satisfied:
E d Γ as for the non-probabilistic case;
G includes all cells, except the branching ones.
From the fact that the parallel composition of typed event structures is typed, one can easily derive that the parallel composition of typed probabilistic event structures [31] is still a probabilistic event structure, and that it is typed.
The distinction between reactive branching input and generative selecting output is akin to the one in [2].

Example of typed event structure
Figure 4 represents a typed (partial) probabilistic event structure E d Γ, where

Γ = a : Φi∈{1,2}(xi :  k∈{1,2}()), b :  i∈{1}(zi :  k∈{1}())
Immediate conflict is represented by curly lines, while causal order proceeds upwards along the straight lines. The selection cells x1in1, x1in2 and x2in1, x2in2 are generative. The branching cell ain1⟨x1⟩, ain2⟨x2⟩ is reactive. Every other cell is generative, and contains only one event, that has probability 1. We can see that the causality in E refines the name causality in Γ: for instance, Γ forces the labels with subject xi to be above the label aini⟨xi⟩, but does not force the causal link between the events labelled by aini⟨xi⟩ and b⟨z1⟩. Note also that the synchronisation event is not represented in the type.

Event structure semantics	of the probabilistic π- calculus
This section presents the event structure semantics of the π-calculus and its prop- erties. As in [32], the semantics is given by a family of partial functions [−]]ρ, parametrised by a “choice function” ρ, that take a judgement of the π-calculus and return an event structure. The “choice function” ρ assigns to every bound name a set (possibly a singleton) of fresh distinct names. The parametrisation is necessary because π-calculus terms are identified up to α-conversion, and so the identity of bound names is irrelevant, while in typed event structures, the identity of the object names is important. Also, since servers are interpreted as infinite parallel compo- sitions, every bound name of a server must correspond to infinitely many names in the interpretation.
In order to make this work, we have to use the convention that all bound names in the π-calculus are distinct, and different from the free names. In this way ρ cannot identify two different bindings.
We define the interpretation by induction on the derivation of the typing judge- ment. Without loss of generality, we will assume that all the weakenings are applied to the empty process. The interpretation is defined in Figure 5, essentially in the same way as the non probabilistic case [31]. The notation has to be explained. The notation ρ, y → S denotes the function ρ extended on a name y not already in the domain of ρ, and such that all names in S are fresh and distinct from any other name in the range of ρ. In the interpretation of the server, we use Y to denote the set of confidential names of the interpretation of P . We also use the choice function ρ[K] defined as follows: assume the range of ρ are only singletons, say for every name x in the domain, ρ(x) = {y}. Then ρ[K](x) = {yk | k ∈ K}, where yk are obtained by a function FK : Names → P(Names) as in [31,32]. In the interpretation of the parallel composition, S denotes the set of names that are in the range of both ρ1 and ρ2.
Once past the rather heavy notation, the interpretation is rather simple. Note the way ρ fixes a choice for the bound variables. Observe also that the server is interpreted into an infinite parallel composition.
The interpretation is not always typable. In particular, for the wrong choice of


[[0 d xi : (τi)?, yj :‡]]ρ = ∅

[[(ν x)P d Γ]]ρ = [[P d Γ,x : τ ]]ρ \ x

[[P1  P2 d Γ1 ⊙ Γ2]]ρ1 ∪ρ2 =
([[P1 d Γ1]]ρ1  [[P2 d Γ2]]ρ2 ) \ S

[[x  i∈I ini(y˜i).Pi d Γ,x :  i∈I (τ˜i)↑]]ρ,(y˜i→z˜i)i∈I =
Σi∈I xini⟨z˜i⟩.[[Pi[z˜i/y˜i] d Γ, z˜i : τi]]ρ

[[x Φi∈I piini(y˜i).Pi d Γ,x : Φi∈I (τ˜i)↓]]ρ,(y˜i→z˜i)i∈I =
Σi∈I pixini⟨z˜i⟩.[[Pi[z˜i/y˜i] d Γ, z˜i : τi]]ρ

[[!x(y˜).P d Γ,x : (τ˜)!]]ρ[K],y˜→{y˜k }k∈K =
  k∈K x⟨y˜k⟩.[[P d Γ]]ρ[y˜k/y˜][Y k/Y ]

[[x(y˜).P d Γ,x : (τ˜)?]]ρ,y˜→w˜ =
x⟨w˜⟩.[[P d Γ,x : (τ˜)?[w˜/y˜]]]ρ

Fig. 5. Event Structure Semantics of the probabilistic π-Calculus

ρ1, ρ2, the parallel composition may not be typed because the choices for the bound names may not match. However it is always possible to find suitable ρ1, ρ2.
Theorem 5.1 For every judgement P d Γ in the π-calculus, there exist a choice function ρ and a type environment Δ such that [[P d Γ]]ρ d Δ. Moreover, for every injective fresh renaming ρ', if [[P d Γ]]ρ d Δ then [[P d Γ]]ρ'◦ρ d Δ[ρ'].
Theorem 5.2 Let P be a process and Γ an environment such that P d Γ. Suppose that [[P d Γ]]ρ is deﬁned. Then there is a environment Δ such that [[P d Γ]]ρ d Δ.
This theorem means that all denoted event structures are indeed partial probabilistic event structures. Note that the set of generative cells includes all synchronisation cells. Therefore a closed process denotes a probabilistic event structure.
Corollary 5.3 The event structure [[P d ∅]]ρ is a probabilistic event structure.
This implies that there exists a unique probability measure over the set of max- imal runs [30]. In other words, for closed processes, the scheduler only influences

the order of independent events, in accordance with the intuition that probabilistic choices are local and not influenced by the environment.

Event structures and Segala automata
In this section we show a formal correspondence between Segala automata and probabilistic event structures.

From event structures to Segala automata
Definition 6.1 Let E = ⟨E, ≤, ×, λ⟩ be a labelled event structure and let e be one of its minimal events. The event structure E [e = ⟨E', ≤', ×', λ'⟩ is defined by: E' = {e' ∈ E | e' /= e}, ≤'=≤|E', ×'=×|E' , and λ' = λ|E' .
Roughly speaking, E [e is E minus the event e, and minus all events that are in conflict with e. We can then generate a Segala automaton on event structures as follows:
E { 	ai  E [ ei}i∈I
if there exists a minimal generative cell c = {ei | i ∈ I}, such that p(ei) = pi and
λ(ei)= ai. We also put
E {   a  E [e}
if there exists an event e belonging to a minimal reactive cell, such that λ(e) = a. The initialised Segala automaton generated by an event structure E is the above automation initialised at E .
A probabilistic event structure (where every cell is generative) generates a some- what “deterministic” Segala automaton. The general formalisation of this property requires several technicalities (see [30], for instance). Here we state a simplified result.
Let E be a probabilistic event structure, and consider the Segala automaton (t, x0), generated as above. Consider a scheduler S for such a Segala automaton. We say that S is fair if for every path τ ∈ B(t, x0, S ), there does not exist a generative cell c of the event structure, and an index j, such that for all i > j, the transition group corresponding to c is enabled but it is not chosen by S .
Theorem 6.2 Let E be a probabilistic event structure, and consider the correspond- ing Segala automaton. For all sets of labels B, and for all fair schedulers S , T , we have ζS (B)= ζT (B).
In a non-probabilistic confluent system, all (fair) resolutions of the nondeter- ministic choices give rise to the same set of events, possibly in different order. In this sense we can see Theorem 6.2 as expressing probabilistic confluence.
Figure 6 shows an example of a (partial) probabilistic event structure. The generative cells are {α', α''}, {β'', γ''} and the probability is indicated as superscript



β'   ¸        ¸˛¸¸˛˛¸˛¸¸˛¸˛¸ц˛'˛¸˛¸˛
β''1/4 ¸¸˛¸˛ц˛''3/4	δ''

¸¸¸¸
¸¸¸
¸¸¸¸
¸¸¸
¸

α'1/3
¸˛¸˛
¸˛¸˛¸˛¸˛¸¸˛¸˛¸˛¸α˛¸˛''2˛/¸3 ˛¸˛¸˛¸˛¸˛



Fig. 6. A probabilistic event structure

β′
1
ц′
1
δ′′	1
	  



Fig. 7. The corresponding Segala automaton

of the label. Figure 7 shows the Segala automaton corresponding to the event structure of Figure 6.

The adequacy theorem
There is a correspondence between the two semantics of the π-calculus. It is for- malised by the following theorem, which shows the correspondence between the Segala automata semantics defined in Section 3, and the Segala automaton derived from the event structure semantics, as described above.
Theorem 6.3 Let ∼= denote isomorphism of probabilistic event structures.

Suppose P d Γ{ 	βi  P d Γ }
in the π-calculus. Then there exist ρ, ρ
such

pi	i
i i∈I	i

that [[P d Γ]]ρ is deﬁned and [[P d Γ]]ρ{  βi  ∼= [[P d Γ ]]ρi }	.
Conversely, suppose [[P d Γ]]ρ{  βi  E }	, for some ρ. Then there exist P ,ρ 
pi	i i∈I	i	i

such that P d Γ{  βi  P d Γ \ β }
and [[P
d Γ \ β ]]ρi ∼= E , for all i ∈ I.

pi	i
i i∈I
i	i	i

The proof is analogous to the one for the non-probabilistic case [31] by induction on the operational rules, the difficult case being the parallel composition.

Example of probabilistic confluence
Theorem 6.3 and Theorem 6.2 together show that the linearly typed probabilistic
π-calculus is “probabilistically confluent”. Note that Theorem 6.2 applies only to

fully probabilistic event structures, that is event structures which do not contain reactive cells. In particular, in light of Corollary 5.3, it applies to closed processes. More generally it applies to processes whose free names do not include linear inputs. To exemplify the confluence theorem, consider a process P such that P d a :
  i∈I ∅. This is a process that emits only one visible action, whose subject is a. For every j ∈ I we can define the probability P emits ainj as pS (ainj) for some fair scheduler S . By Theorem 6.2, we have that this probability is independent from the scheduler, so we can define it as p(ainj). This independence from the scheduling policy is what we call probabilistic confluence.
Note also that it can be shown that Σi∈I p(aini) ≤ 1. When the inequation is
strict, the missing probability is the probability that the process does not terminate. This reasoning relies on the typing in that there exist untyped processes that are not probabilistically confluent. For instance consider

(νb)(b | b.a  i∈{1,2} piini | b.a  i∈{1,2} qiini)
The above process also emits only one visible action, whose subject is a. The probability of ain1 is p1, or q1, depending on which synchronisation takes place, i.e. depending on the scheduler. Note, however, that this process is not typable.

Related and future work
Related work
This paper has provided an event structures semantics for a probabilistic version of the π-calculus. It is the first true concurrent semantics of a probabilistic π-calculus. Related work with true concurrency models for the π-calculus and (confusion-free) event structures are already discussed in [32,31]. There, the importance of confusion freeness and the use of types in event structures is also discussed in depth. Another recent event structure semantics of the π-calculus was presented in [6].
The natural comparison is with the probabilistic π-calculus by Herescu and Palamidessi [16]. Their and our calculi both have a semantics in terms of Segala automata, while we also provide an event structure semantics. The key of our construction is the typing system, which allows us to stay within the class of prob- abilistic event structures.
Our typing system is designed to provide a “probabilistically confluent” calculus, and therefore their calculus is more expressive, as it allows non-confluent computa- tions. At the core of their calculus, there is a renormalisation of probabilities, which is absent in our setting, i.e. in our calculus, all probabilistic choices are local, and are not influenced by the environment.
A simpler calculus, without renormalisation, is presented in [7]. This version is very similar to ours, in that all choices are local; in fact, the protocol example presented in [7] (via an encoding into our calculus) is linearly typable. We believe we could apply a typing system similar to ours to the calculus in [7], prove the same results in this paper and identify a good class of probabilistic name-passing behaviours.

Future work
We have shown a correspondence between event structures and Segala automata. We would have liked to extend this correspondence to a categorical adjunction be- tween two suitable categories, ideally extending the setting presented in [35]. It is possible to do so, by a simple definition of morphisms for Segala automata, and by extending the notion of probabilistic event structures. Unfortunately neither cate- gory has products, which are used in [35] to define parallel composition. The reason for this is nontrivial and it is has to do with the notion of stochastic correlation, a phenomenon already discussed in [30] in the context of true concurrent models. This issue needs to be investigated further.
The linearly typed π-calculus is the target of a sound and complete encodings of functional language [4,36]. Our traffic light example in Section 5 suggests that our calculus captures the core part of the expressiveness represented by the Stochastic Lambda Calculus [24]. We plan to perform similar encodings in the probabilistic ver- sion, notably the probabilistic functional language [24], probabilistic λ-calculus [11] and Probabilistic PCF [8]. Since the linear type structures are originated from game semantics [18], this line of study would lead to a precise expressive analysis between the probabilistic event structures, Segala automata, probabilistic programming lan- guages and probabilistic game semantics [8], bridged by their representations of or encodings into probabilistic π-calculi. Finally, there are connections between event structures, concurrent games [22], and ludics [12,13] that should be investigated also in the presence of probabilities.

References
Samy Abbes and Albert Benveniste. Probabilistic models for true-concurrency: branching cells and distributed probabilities for event structures. Information and Computation, 204(2):231–274, 2006.
Alessandro Aldini, Mario Bravetti and Roberto Gorrieri. A process-algebraic approach for the analysis of probabilistic noninterference. Journal of Computer Security, 12(2):191–245, 2004.
Falk Bartels, Ana Sokolova, and Erik de Vink. A hierarchy of probabilistic system types. In Proceedings of 6th CMCS, volume 82(1) of ENTCS. Elsevier, 2003.
Martin Berger, Kohei Honda, and Nobuko Yoshida. Sequentiality and the π-calculus. In Proceedings of TLCA’01, volume 2044 of LNCS, pages 29–45, 2001.
G´erard Berry and Pierre-Louis Curien. Sequential algorithms on concrete data structures. Theoretical Computer Science, 20(265–321), 1982.
Roberto Bruni, Hern´an Melgratti, and Ugo Montanari. Event structure semantics for nominal calculi. In Proceedings of 17th CONCUR, volume 4137 of LNCS, pages 295–309. Springer, 2006.
Kostas Chatzikokolakis and Catuscia Palamidessi. A framework to analyze probabilistic protocols and its application to the partial secrets exchange. In Proceedings of Symposium on Trustworthy Global Computing, 2005, volume 3705 of LNCS. Springer, 2005.
Vincent Danos and Russell S. Harmer. Probabilistic game semantics. ACM Transactions on Computational Logic, 3(3):359–382, 2002.
J¨org Desel and Javier Esparza. Free Choice Petri Nets. Cambridge University Press, 1995.
Jos´ee Desharnais, Abbas Edalat, and Prakash Panangaden. Bisimulation for labelled Markov processes.
Information and Computation, 179(2):163–193, 2002.

Alessandra Di Pierro, Chris Hankin, and Herbert Wiklicky. Probabilistic lambda calculus and quantitative program analysis. Journal of Logic and Computation, 15(2):159–179, 2005.
Claudia Faggian and Fran¸cois Maurel. Ludics nets, a game model of concurrent interaction. In
Proceedings of 20th LICS, pages 376–385, 2005.
Claudia Faggian and Mauro Piccolo. A graph abstract machine describing event structure composition. In Proceedings of the GT-VC workshop, 2006. Short paper.
Harald Fecher, Mila E. Majster-Cederbaum, and Jinzhao Wu. Action refinement for probabilistic processes with true concurrency models. In PAPM-PROBMIV, volume 2399 of LNCS, pages 77–94. Springer, 2002.
Hans Hansson. Time and Probability in Formal Design of Distributed systems. PhD thesis, Uppsala University, 1991.
Mihaela Herescu and Catuscia Palamidessi. Probabilistic asynchronous π-calculus. In Proceedings of 3rd FoSSaCS, volume 1784 of LNCS, pages 146–160. Springer, 2000.
Kohei Honda and Nobuko Yoshida. On reduction-based process semantics. Theoretical Computer Science, 151(2):385–435, 1995.
J. Martin E. Hyland and C.-H. Luke Ong. On full abstraction for PCF: I, II, and III. Information and Computation, 163(2):285–408, 2000.
Gilles Kahn and Gordon D. Plotkin. Concrete domains. Theoretical Computer Science, 121(1-2):187– 277, 1993.
Joost-Pieter Katoen. Quantitative and Qualitative Extensions of Event Structures. PhD thesis, University of Twente, 1996.
Kim G. Larsen and Arne Skou. Bisimulation through probabilistic testing. Information and Computation, 94(1):1–28, 1991.
Paul-Andr´e Melli`es. Asynchronous games 2: The true concurrency of innocence. In Proceedings of 15th CONCUR, pages 448–465, 2004.
Robin Milner. Communicating and Mobile Systems: The Pi Calculus. Cambridge University Press, 1999.
Norman Ramsey and Avi Pfeffer. Stochastic lambda calculus and monads of probability distributions. In Proceedings of 29th POPL, pages 154–165, 2002.
Grzegorz Rozenberg and P.S. Thiagarajan. Petri nets: Basic notions, structure, behaviour. In Current Trends in Concurrency, volume 224 of LNCS, pages 585–668. Springer, 1986.
Davide Sangiorgi. π-calculus, internal mobility and agent passing calculi. Theoretical Computer Science, 167(2):235–271, 1996.
Roberto Segala. Modeling and Verification of Randomized Distributed Real-Time Systems. PhD thesis, M.I.T., 1995.
Roberto Segala and Nancy Lynch. Probabilistic simulations for probabilistic processes. Nordic Journal of Computing, 2(2):250–273, 1995. An extended abstract appears in Proceedings of 5th CONCUR, LNCS 836, pages 481–496, 1994.
Mari¨elle Stoelinga. An introduction to probabilistic automata. Bulletin of the European Association for Theoretical Computer Science, 78:176–198, 2002.
Daniele Varacca, Hagen V¨olzer, and Glynn Winskel. Probabilistic event structures and domains. TCS, 358(2-3):173–199, 2006. Full version of the homonymous paper in CONCUR 2004.
Daniele Varacca and Nobuko Yoshida. Event structures, types and the π-calculus. Technical Report 2005/06, Imperial College London, 2005. Available at www.doc.ic.ac.uk/˜varacca.
Daniele Varacca and Nobuko Yoshida. Typed event structures and the π-calculus. In Proceedings of XXII MFPS, volume 158 of ENTCS, pages 373–397. Elsevier, 2006.
Hagen V¨olzer. Randomized non-sequential processes. In Proceedings of 12th CONCUR, volume 2154 of LNCS, pages 184–201, 2001. Extended version as Technical Report 02-28 - SVRC - University of Queensland.
Glynn Winskel. Event structure semantics for CCS and related languages. In Proceedings of 9th ICALP, volume 140 of LNCS, pages 561–576. Springer, 1982.


Glynn Winskel and Mogens Nielsen. Models for concurrency. In Handbook of logic in Computer Science, volume 4. Clarendon Press, 1995.
Nobuko Yoshida, Martin Berger, and Kohei Honda. Strong Normalisation in the π-Calculus. In Proceedings of LICS’01, pages 311–322. IEEE, 2001. The full version in Journal of Information and Computation, 191 (2004) 145–202, Elsevier.
Nobuko Yoshida, Kohei Honda, and Martin Berger. Linearity and bisimulation. In FoSSaCs02, volume 2303 of LNCS, pages 417–433. Springer, 2002.

A  Appendix: Proof of Theorem 6.2
Before proving Theorem 6.2, we need a lemma. Consider the Segala automaton (t, x0) generated by a probabilistic event structure E . Transition groups correspond to certain sets of events. A path of the Segala automaton can be seen as performing a sequence of events.
Recall that a conﬁguration of an event structure is a set of events that is conflict free and downward closed.
Lemma A.1 The set of events along a path of (t, x0) form a conﬁguration of E . The probability of a path is the same as the probability of the corresponding conﬁg- uration.
A scheduler creates paths, and therefore configurations. A infinite path cannot be extended further, but the corresponding configuration is not maximal in general. However this is the case for fair schedulers.
Lemma A.2 The set of events along a path in B(t, x0, S ), for S fair, is a max- imal conﬁguration. Conversely, given a fair scheduler S and a maximal conﬁgura- tion, there exists a corresponding path in B(t, x0, S ).
Proof of Theorem 6.2. Consider a fully probabilistic event structure E . Accord- ing to Theorem 4.2 in [30], there exists a unique probability distribution μ over the set of maximal configurations. Consider a label a. We define p(a) := μ(Xa), where Xa is the set of maximal configurations that contain the label a (it is easy to show this set is indeed measurable).
We want to prove that, given a fair scheduler S for the Segala automaton generated by E , we have pS (a) = p(a), and therefore it is independent from S . Consider the set of paths in B(t, x0, S ) that contain a label a. This is the disjoint union of the paths that contain the first a at the i-th position, for i > 0. Let Bi be such sets. The measure of Bi is the sum of the probabilities of the finite paths of length i that contain the label a in the last position. Let such paths form the set Fi. The configurations corresponding to the paths in Fi have the same probability. Using Lemma A.2, we show that every maximal configuration containing an event labelled by a is above a unique configuration in some Fi. This shows that the measure of the set of maximal configurations containing an a coincides with the set of infinite paths in B(t, x0, S ).
