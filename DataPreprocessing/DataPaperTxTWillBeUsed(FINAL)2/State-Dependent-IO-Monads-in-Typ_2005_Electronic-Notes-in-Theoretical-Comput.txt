Electronic Notes in Theoretical Computer Science 122 (2005) 127–146 
www.elsevier.com/locate/entcs


State Dependent IO-Monads in Type Theory

Markus Michelbrink1 ,2
Department of Computer Science University of Wales Swansea Swansea, United Kingdom

Anton Setzer3 ,4
Department of Computer Science University of Wales Swansea Swansea, United Kingdom


Abstract
We introduce the notion of state dependent interactive programs for Martin-L¨of Type Theory. These programs are elements of coalgebras of certain endofunctors on the presheaf category S → Set. We prove the existence of final coalgebras for these functors. This shows as well the consistency of type theory plus rules expressing the existence of weakly final coalgebras for these functors, which represents the type of interactive programs. We define in this type theory the bisimulation relation, and give some simple examples for interactive programs. A generalised monad operation is defined by corecursion on interactive programs with return value, and a generalised version of the monad laws for this operation is proved. The correctness of the monad laws has been verified in the theorem prover Agda which is based on intensional type theory.
Keywords: Dependent type theory, Martin-L¨of type theory, intensional type theory, monad, weakly final coalgebras, interactive programs.



1 Supported by EPSRC grant GR/S30450/01.
2 Email: m.michelbrink@swansea.ac.uk
3 Supported by Nuffield Foundation,  grant ref. NAL/00303/G and EPSRC grant
GR/S30450/01.
4 Email: a.g.setzer@swansea.ac.uk



1571-0661 © 2005 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2004.06.055


Martin-Lo¨f’s type theory [9] can be seen as a programming logic for a func- tional programming language. The judgement a ∈ A can especially be read as:
a is a program with type A
a is a program which satisfies the specification A
a is an implementation of the abstract data type specification A.
The above relies on the identification of sets, proposition, and specifications. With this identification dependent type theory gives us the ability to express with full precision any extensional property of a program, which can be defined mathematically. We can check the type of a program mechanically, and type correctness carries full assurance that it satisfies its specification. Versions of type theory have been implemented e.g. in G¨oteborg [4,13], Cornell [3], Cambridge [12], Edinburgh [8,14], and INRIA [2].
In type theory running a program means normalising an expression. Every program terminates, and there is no interaction with the environment. This model is adequate for a large class of programs which compute a result from its input. It is however not adequate for the whole class of programs, which interact with their environment and possibly never terminate.
In this article we continue work of Peter Hancock and Anton Setzer [5,6]. We generalise the notion of interfaces (worlds) and IO-programs to state de- pendent interfaces and state dependent programs. In [6] a world is a pair (C, R), where C : Set and R : C → Set. c : C is interpreted as a com- mand, and Rc is the set of possible responses (from a user, a device or an- other program) to the command c. For every set A the set of programs IO A : Set (we keep the world fixed) has constructors leaf : A → IO A and do : (c : C, p : Rc → IO A) → IO A. The program leaf a terminates and returns value a, whereas do (c, p) issues command c, and after receiving response r : Rc continues as pr : IO A.
We generalise this by giving every program a state s : S. Now the set of executable commands, the responses, as well as the function giving us the next program depend on the state s : S. The resulting notion is better suited for real world applications. One of our key examples is a window system. The client may request a server to open a window. The states now represent the open windows.
The generalisation leads us naturally to an endofunctor F on the presheaf category S → Set. We show that this functor has a final coalgebra elim : IO → F(IO). We enrich type theory by rules for a weak version of this final coalgebra


(weak because we do not demand uniqueness of µ(α), as seen below). The elimination rule corresponds to the morphism elim, the introduction rules to the requirement that there is a morphism µ(α): A → IO for every coalgebra α : A → FA, and the equality rule expresses that the associated diagram commutes. The formation rule simply reflects the fact that there is a coalgebra IO.
We define bisimulation for interactive programs. After introducing rules for interactive programs with return value, we define a monad operation ∗ by corecursion, and show that the monad laws for this operation hold with respect to bisimulation.
We work in extensional Type Theory. However, the results can be achieved in intensional Type Theory as well. Intensional versions of the results of Sec- tion 6 are verified in Agda [4]. The code is available online at the URL http://www.cs.swan.ac.uk/~csmichel/. This is in contrast with the con- struction of non-well-founded sets by Ingrid Lindstro¨m [7], which is essentially the construction of a weakly final coalgebra. That construction makes heavily use of extensional equality.

Overview.
In Section 2 we motivate our basic definitions. In Section 3 we relate our basic ideas from Section 2 to an endofunctor on S → Set, and show that this functor has a final coalgebra. In Section 4 we introduce the new rules for IO-programs, and define bisimulation. In Section 5 we give some simple examples for IO-programs. In Section 6 we introduce the rules for IO-programs with return values, define a monad operation for this programs, and show the monad laws with respect to bisimulation.
Besides Section 3 we work in a standard dependent type theory (e.g. [11]) with the usual formation, introduction, elimination, and equality rules, ex- tended by our rules.

Acknowledgement
Many ideas for this article are due to P. Hancock, Edinburgh. He could well have been a third author for this article, but preferred to publish his slightly different point of view separately.

Interfaces, Programs
An interface is a quadruple (S, C, R, n) s.t.
S : Set
C : S → Set
R : Πs : S.C(s) → Set
n : Πs : S.Πc : C(s).R(s, c) → S
S is the set of states, C(s) the set of commands in state s : S, R(s, c) the set of responses to a command c : C(s) in state s : S, and n(s, c, r) the next state of the system after this interaction. Continuing our example above, in a window system the server performs the requests (commands) for its clients, and sends them back replies (responses). The possible requests depend on the state of the client, the replies depend on the state of the server and the state of the shared resources: the drawing area and the input channel.
We can view an interface as a generalised transition system, where we have a transition (s, c, r, s') between states s : S and s' : S iff c : C(s), r : R(s, c) and s' = n(s, c, r). The picture visualises a part of an interface:
  s ¸¸¸¸¸¸¸¸¸
c1 ¸¸c2 ¸¸¸¸

  c0
J  ¸¸¸
¸¸¸¸¸

,s 
¸¸¸¸
z• 
,z	,z
.z. .˛

r01
¸r¸02
,,zz
,,zz

 , sr00
00
'J 
01
¸¸z 
02
,z	,z
z	z 

There are two canonical ways to view an ordinary transition system as inter- face:
Take C(s)= {Transition starting from s} and R(s, t) as singletons.
Take C(s) as singletons and R(s, ∗)= {Transition starting from s}.
Let (S, C, R, n) be an interface. A program for this interface starting in state
s : S is a quadruple (A, c, next, a) s.t.
A : S → Set
c : Πs : S.A(s) → C(s)
next : Πs : S.Πa : A(s).Πr : R(s, c(s, a)).A(n(s, c(s, a), r))
a : A(s)
A(s) is the set of programs starting in state s, c(s, a) the command issued by the program a : A(s), and next(s, a, r) is the program that will be executed, after having obtained for command c(s, a) the response r : R(s, c(s, a)). In the


example the program would be an client. It should be noted, that this is the client version of a program. If we interchange in the functor below products and sums, we get server side programs.
The picture visualises a part of a program in relation to its interface.
Dashed lines belong to the program:
,,,,, s ¸¸¸¸¸¸

,,,,
 c1
¸c¸2¸¸

, c0
s,
˛r
 J 
 • ¸
	¸
¸¸¸¸z• ˛
,z
02

˛˛rr
˛˛rr
 r 00
  s
r01
J 
¸r ¸
¸ ¸z˛
,,zz
,,zz

 j s'	s'	s'	zz
  00 ¸¸¸	 01 ¸¸¸	 02 ¸ ¸

¸¸¸¸
¸¸¸¸	¸ ¸

,s J	z, s 
J	z, s J	z 



IO as Final Coalgebra

If we view the set S as a discrete category (with only arrows ids for s : S), the presheaf category S → Set has objects X : S → Set and morphism f : Πs : S.X(s) → Y (s), where X, Y : S → Set. The composition g◦f : Πs : S.X(s) → Z(s) of two morphism f : Πs : S.X(s) → Y (s) and g : Πs : S.Y (s) → Z(s) is defined by
(g ◦ f )(s, x)= g(s)(f (s, x))
for s : S, x : X(s). idX : Πs : S.X(s) → X(s) is given by idX (s)= idX(s).
We look at the functor F : (S → Set) → (S → Set) defined by
FX(s)= Σc : C(s).Πr : R(s, c).X(n(s, c, r)) for X : S → Set and
for f : Πs : S.X(s) → Y (s)

Ff (s): FX(s) → FY (s),

Ff (s)(c, g)= (c, λr.f (n(s, c, r), g(r))).
One easily sees that F is a Functor.
A final coalgebra in a category C for an endofunctor G : C → C is an object G∞ together with a morphism elim : G∞ → G(G∞) s.t. for any object A and morphism g : A → GA there is exactly one morphism f : A → G∞


making the following diagram commute:
G∞ 	elim	 G (G∞)

,, 
 
 
f 
 
 
A
,, 
 
 
 Gf
 
 
g	 G A

We will show in this section that the previous defined functor has a final coalgebra. This result can also be achieved by the observation that the functor is ω-continuous. So the final sequence of F stabilises at ω. The proof of ω- continuity makes heavily use of extensional equality. Therefore we prefer our proof, since it can be used for proofing the existence of weakly final coalgebras in Martin-Lo¨f Type Theory. This will be done in a forthcoming paper. For simplicity, we argue in ZF for the rest of this section. To get the final coalgebra we first define by induction sets CT0(s) and functions firstS, lastS : CT0(s) → S, firstC, lastC : CT0(s) → C(s), length : CT0(s) → N and pd(s) for s : S. In this section ∗ denotes the concatenation of two lists.
Definition 3.1 CT0(s) has as elements lists
(s0, c0, r1, ..., rn, sn, cn)
for 0 ≤ n with s0 = s, ci ∈ C(si), ri+1 ∈ R(si, ci) and si+1 = n(si, ci, ri+1), and we define
length((s, c))	:= 1
length(l' ∗ (r, s, c))	:= length(l')+1 
firstS((s0, c0, r1, ..., rn, sn, cn)) := s0
lastS((s0, c0, r1, ..., rn, sn, cn)) := sn
firstC((s0, c0, r1, ..., rn, sn, cn)) := c0
lastC((s0, c0, r1, ..., rn, sn, cn)) := cn
pd((s, c))	:= (s, c)
pd(l' ∗ (r, s, c))	:= l'
If l ∈ CT0(s) we write R(l) for R(lastS(l)lastC(l)) and if r ∈ R(l) we write n(l, r) for n(lastS(l), lastC(l), r). We are now able to define the domain of the final coalgebra:
Definition 3.2 For s ∈ S and T ⊆ CT0(s) let

ϕ(T, s) := (∃!c ∈ C(s).(s, c) ∈ T )
&(∀l ∈ T.∀r ∈ R(l).∃!c ∈ C(n(l, r)).l ∗ (r, n(l, r), c) ∈ T )
&∀l ∈ T.pd(l) ∈ T
We define CT : S → Set by:
CT (s) := {T ⊆ CT0(s)|ϕ(T, s)}.
We can interpret the elements of CT (s) as computation trees for a program p : IO(s). Part (1) of ϕ(T, s) says that there is exactly one root (s, c) in each T ∈ CT (s). Part (2) of ϕ(T, s) ensures that for l ∈ T and every r ∈ R(l) there is exactly one successor l ∗ (r, s', c') in T and part (3) of ϕ(T, s) says that T is closed under predecessors. Note that
firstC(l)= firstC(l') for l, l' ∈ T ∈ CT (s).
Sets T, T ' ∈ CT (s) have a nice property:
Lemma 3.3 For T, T ' ∈ CT (s)
T ⊆ T ' ⇔ T = T '.
Proof. Induction on length(l). Let l ∈ T '.
If l = (s', c'), then s' = firstS(l)= s because T ' ⊆ CT0(s).
By the definition of CT (s) there is exactly one c ∈ C(s) with (s, c) ∈ T ⊆
T '. Again by the definition of CT (s) follows c = c' and therefore l = (s, c) ∈ T . If l = l' ∗ (r', s', c'), then l' = pd(l) ∈ T '.
By I.H. follows l' ∈ T . By l' ∈ T ⊆ CT0(s) follows r' ∈ R(l'), s' = n(l', r') and c' ∈ C(s').
By the definition of CT (s) there is again exactly one c'' ∈ C(s') with
l' ∗ (r', s', c'') ∈ T ⊆ T '. T ' ∈ CT (s) implies c' = c'' and so l ∈ T .	 
Definition 3.4 For T ∈ CT (s) let
elim(s, T )= (c, h),
where for some l ∈ T
c = firstC(l)
h : Πr : R(s, c) → CT (n(s, c, r))
h(r)= {l ∈ CT0(n(s, c, r))|(s, c, r) ∗ l ∈ T }.
h(r) is an element of CT (n(s, c, r)) and therefore the equations define a morphism elim : CT → F(CT ). h(r) gives us the subtree of T on position r.


Theorem 3.5 The previous deﬁned Functor F : (S → Set) → (S → Set) has a ﬁnal coalgebra in the category S → Set.
Proof. We claim that (CT, elim) is a final coalgebra for F.
Let g(s) : A(s) → FA(s) for s : S. We write g = (g0, g1), where g0(s) = 
π0(g(s)) ∈ C(s), and g1(s)= π1(g(s)) ∈ Πr : R(s, g0(s)).A(n(s, g0(s), r)).
We have to show that there is a unique morphism T : A → CT such that the diagram on page 6 with G = F, G∞ = CT and f = T commutes. For this purpose, we define simultaneously sets T (s, a) ∈ CT (s) for s ∈ S, a ∈ A(s) and elements nextS(l, r) ∈ S, nextA(l, r) ∈ A(nextS(l, r)) for l ∈ T (s, a),r ∈ R(l) by
T 0(s, a)	:= {(s, g0(s, a))}
nextS((s, g0(s, a)), r) := n(s, g0(s, a), r)
nextA((s, g0(s, a)), r) := g1(s, a, r)
T i+1(s, a)	:= {l ∗ (r, s', c')| l ∈ T i(s, a) & r ∈ R(l)& s' = n(l, r) & c' = g0(s', nextA(l, r))}
nextS(l ∗ (r, s', c'), r'):= n(s', c', r')
nextA(l ∗ (r, s', c'), r'):= g1(s', nextA(l, r), r') T (s, a)	:=  i∈N T i(s, a)
It follows easily by induction on i that T (s, a) ∈ CT (s) for s ∈ S, a ∈ A(s)
and that
T i(n(s, c, r), g1(s, a, r)) = {l ∈ CT0(n(s, c, r))|(s, c, r) ∗ l ∈ T i+1(s, a)} (∗) for i ∈ N, s ∈ S, a ∈ A(s),c = g0(s, a),r ∈ R(s, c).
T : A → CT makes the diagram commute:
π0(elim(s, T (s, a))) = g0(s, a) =: c
π1(elim(s, T (s, a)))(r)= {l ∈ CT0(n(s, c, r))|(s, c, r) ∗ l ∈ T (s, a)}
= T (n(s, c, r), g1(s, a, r)) ,
where the last equation follows by (∗).
It remains to show that T is unique. Let T ' : A → CT be a morphism making the diagram commute. We show T i(s, a) ⊆ T '(s, a) for all i ∈ N by induction:
i =0 : We have
π0(elim(s, T '(s, a))) = π0(g(s, a)) = g0(s, a),


and so T 0(s, a) ⊆ T '(s, a).
Let T i(s, a) ⊆ T '(s, a) for all s ∈ S, a ∈ A(s) and (s, c, r) ∗ l ∈ T i+1(s, a).
Then

and
c = g0(s, a)= π0(elim(s, T '(s, a))),

l ∈ T i(n(s, c, r), g1(s, a, r)) ⊆ T '(n(s, c, r), g1(s, a, r))
= π1(elim(s, T '(s, a)))(r)
= {l ∈ CT0(n(s, c, r))|(s, c, r) ∗ l ∈ T '(s, a)},

and therefore (s, c, r) ∗ l ∈ T '(s, a).
The claim follows by lemma 3.3.	 

Rules for IO-programs
We enrich our type theory by the following rules:


Formation Rule


Elimination Rule

 S : Set	s : S  IO(s): Set

S : Set	s : S	p : IO(s)

elim(s, p): Σc : C(s).Πr : R(s, c).IO(n(s, c, r))


Introduction Rule




Equality Rule
`	F(I˛O¸,s)	x


S : Set
A : S → Set
g : Πs : S.A(s) → F(A, s)


µ(A, g): Πs : S.A(s) → IO(s)

S : Set
A : S → Set
g : Πs : S.A(s) → F(A, s)
s : S a : A(s)


where


elim(s, µ(A, g)(s, a)) = onestep(g(s, a)) : F(IO, s)
onestep((c, h)) = (c, λr.µ(A, g, n(s, c, r), h(r))) .

Furthermore, we define

~ : (n : N, S : Set,s : S, p, q : IO(s)) → Set
≈ := (S : Set,s : S, p, q : IO(s)) → Set
by the following equations:
p ∼0 q := T
p ∼n+1 q := Id(C(s), c, c') ∧
∀r ∈ R(s, c).π1(elim(s, p))(r) ∼n π1(elim(s, q))(r) p ≈ q : ∀n ∈ N.p ∼n q,

where

c := π0(elim(s, p)), c' := π0(elim(s, q)).

Note that the introduction rule for the IO-Sets looks more complicated than the elimination rule. As for inductively defined sets the introduction rule says what our canonical elements are. However, whereas for inductive sets in the premises of the introduction rule only appear certain sets here we can have any family of sets to introduce a new element in IO(s). Otherwise the elimination rules say how to define a function on these sets. However, whereas for inductive sets the range can be any set here it is the fixed set Σc : C(s).Πr : R(s, c).IO(n(s, c, r)). Note that we make use of extensional equality.

Examples
Mini Editor
We define two versions of a mini editor. Their interface is not state-dependent, so we ignore the arguments referring to S and don’t need to define n(c, r).
Interface:
C= {getchar, writechar(c : Char), beep},
R(n, getchar)= Char,
R(n + 1, writechar)= R(n + 1, beep)= {Ok},
Our first editor reads one character after the other from the keyboard and writes it to the screen. In ”Haskell”-like pseudocode:
InOut : IO
InOut = getChar >>= writeChar >> InOut
In our Type Theory the program is defined by:
A = {∗} ∪ Char, g(∗)= (getchar, λc.c), g(c)= (writechar,λ .∗)
InOut = µ(A, g, ∗).


The second editor has an additional state parameter, namely the number of characters read. It reads a character. If it is a normal character, it proceeds as before. If it is the backspace character, then it deletes the last character, if there is one character left. If there is no character left, it signals a beep.
Pseudocode:
DelInOut : Int -> IO DelInOut n = do c=getChar
if c=backspace then do if n==0 then
do beep
DelInOut n
else
do writeChar c DelInOut (n-1)
else
do writeChar c DelInOut (n+1)
Type Theory:

A	= N × ({∗} ∪ Char),
g((n, ∗))	= (getchar, λc.(n, c)),
g((0, backspace))	= (beep,λ .(0, ∗)),
g((n + 1, backspace)) = (writechar(backspace),λ .(n, ∗))
g((n, c))	 = (writechar(c),λ .(n + 1, ∗)) for c /= backspace DelInOut	= µ(A, g, (0, ∗)).

Window System
A simple windowing interface is defined as follows:
S = N. The state denotes the number of windows currently open.
C(n)= {open, writestring(k :: n)(s :: String), getchar(c :: Char)}.
open opens a new window. writestring(k, s) writes the string s into the window with number k :: n = {1,... ,n − 1} and getchar reads a character.
R(n, open)= R(n, writestring(n, s)) = {Ok},
R(n, getchar)= Char,
n(n, open, Ok)= n + 1,

n(n, c, r)= n otherwise.
The following program opens a window and types into it the string written so far.
Pseudocode:
Win::N->String->IO Win n s = do open
c <- getchar writestring n (s ++ c) Win n+1 (s ++ c)
Type Theory:
A(0)	= {∗1}× String,
A(n + 1)	= {∗1, ∗2, ∗3}× String, g(n, (∗1, s))	 = (open,λ .(∗2, s)),
g(n + 1, (∗2, s)) = (getchar, λc.(∗3,s ++ c)),
g(n + 1, (∗3, s)) = (writestring(n, s),λ .(∗1, s)) W in	= µ(A, g, (0, ””))
IO Programs with Return Value
Until now the only way to terminate for our programs is that R(s, c) is empty for some s, c. If a program reaches this situation, there is never any response, and the program is locked up. We want our programs to terminate and to give back some value, which we can see as value for the function calculated by the program. Therefore, we give our programs the ability to terminate in a state s with a certain value a from a set A(s).
For X : Πs : S.Set and A : Πs : S.Set, let FA(X, s) be
A(s)+ Σc : C(s).Πr : R(s, c).X(n(s, c, r)).
inl a means that the program terminates with value a. inr (c, h) corresponds to (c, h) from Section 4.
Formation Rule



Elimination Rule
 S : Set	s : S	A : S → Set 
IOA(s): Set
S : Set	s : S	p : IOA(s)


elimA(s, p): FA(IOA, s)



Introduction Rule




Equality Rule
S : Set
A, B : S → Set
g : Πs : S.B(s) → FA(B, s)


µ(B, g): Πs : S.B(s) → IOA(s)
S : Set
A, B : S → Set
g : Πs : S.B(s) → FA(B, s)
s : S
b : B(s)


where
elimA(s, µ(B, g)(s, b)) = onestep(g(s, b)): FA(IOA, s)

onestep(inl a)= inl a,
onestep(inr (c, h)) = inr (c, λr.µ(B, g)(n(s, c, r), h(r))).

Furthermore, we define
~ : (n : N, S : Set,s : S, p, q : IO(s)) → Set
≈ : (S : Set,s : S, p, q : IO(s)) → Set
by the equations
p ∼0 q	:=	T
p ∼n+1 q	:=	Case elim(s, p) of
inl a	: Case elim(s, q) of
inl b	: Id(A(s), a, b)
inr (c', h') : ⊥
inr (c, h): Case elim(s, q) of
inl b	: ⊥
inr (c', h') : Id(C(s), c, c') ∧ ∀r ∈ R(s, c).h(r) ∼n h'(r)
p ≈ q	= ∀n ∈ N.p ∼n q
We also write coitg for µ(A, g), p ~ a for elim(s, p) = inl a, p ~ (c, h) for
elim(s, p)= inr (c, h), and sometimes omit indices and superscripts 5 .
Note that ≈ gives us bisimulation since our programs are image finite processes in terms of process algebra: For every p there is at most one q s.t.
p →r  q, namely q = h(r), if p ~ (c, h).
The concept of a monad plays an important role in functional programming
(e.g. [15]). There a monad is a triple (M, η, ∗) consisting of a type constructor
M and a pair of polymorphic functions

5 In functional programming literature the operation elim is also called out and the opera- tion µ is called unfold.


η : A → MA	∗ : MA → (A → MB) → MB
satisfying the following laws:
η(a) ∗ k = k(a)	m ∗ η = m	m ∗ (λa.k(a) ∗ h)= (m ∗ k) ∗ h
We are going to define a monad operation
∗s : IOA(s) → (Πs : S.A(s) → IOB(s)) → IOB(s)
and show the monad laws with respect to bisimulation 6 . This proof has been carried out in intensional Type Theory. Note that this result can also be obtained by reformulation of an result of Lawrence Moss [10] that gives a Kleisli triple for a parametric corecursion system 7 . We don’t know whether this result can be achieved in intensional Type Theory. Assume p : IOA(s) and q : Πs : S.A(s) → IOB(s), then (we suppress s) p ∗ q : IOB(s) is the program, which runs as p, until it terminates with a value a : A(s'), and then continues as q(a): IOB(s'). We start by defining a canonical translations canl:

Definition 6.1 Let X, Y, A : Πs : S.Set.
canl(s): FA(X, s) → FA(X + Y, s) be given by
canl = FA(inl),
i.e.
canl(s, inl a)	= inl a
canl(s, inr (c, h)) = inr (c, λr.inl h(r))
In category theory, if elim : G∞ → G(G∞) is a final coalgebra, then exists
for every f : A → G(G∞ + A) a unique arrow corecf such that the following diagram commutes:
G∞ 	elim	 G (G∞)

,, 
 
 
corecf 
 
 
A
,, 
 
 
 G[idG∞ ,corecf ]
 
 
 G (G∞ + A)

This motivates the following definitions in type theory:

6 We retain the notations ∗, η instead of bindM and unitM to stay in accordance with [5,6].
7 We would like to thank an anonymous referee for this advice.


Definition 6.2 For g : Πs : S.A(s) → C(s) and h : Πs : S.B(s) → C(s) we define
[g, h]: Πs : S.(A(s)+ B(s)) → C(s)
by
[g, h](s, o) := [g(s), h(s)](o) := Case o of
inl a : g(s, a)
inr b : h(s, b)
For f : Πs : S.A(s) → FB(IOB + A, s) let

coitf := coit[canl◦elim,f ] = µ(IOB + A, [canl ◦ elim,f ])
∈ Πs : S.(IOB(s)+ A(s)) → IOB(s),
and corecf : Πs : S.A(s) → IOB(s) with
corecf (s, p)= coitf (s, inr p) .
Definition 6.3 For q : Πs : S.A(s) → IOB(s) let q∗ : Πs : S.IOA(s) →
FB(IOB + IOA, s) be defined by
q∗(s, p) = Case elim(s, p) of
inl a	: canl(s, elim(s, q(s, a)))
inr (c, h) : inr (c, λr.inr h(r))
We define now ∗ : IOA(s) → (Πs : S.A(s) → IOB(s)) → IOB(s) by
p ∗ q := ∗(p, q) := corecq∗ (s, p),
and
ηA := coitη˘ : Πs : S.A(s) → IOA(s),
where η˘ : Πs : S.A(s) → FA(A, s) with η˘(s, a)= inl a.
If h : Πr : R(s, c).IOA(n(s, c, r)) and q(s): A(s) → IOB(s) for s : S, define
h ∗ q = λr.h(r) ∗ q : Πr : R(s, c).IOB(n(s, c, r)).
Lemma 6.4 Let o : IOA1 (s), p(s): A0(s) → IOA1 (s) for s : S. Then
coitp∗ (s, inl o) ≈ o.
Proof. Let p¯ = coitp∗ . We show p¯(s, inl o) ∼n o by induction on n.
We have p¯(s, inl o) ∼0 o. Assume p¯(s, inl o) ∼n o for all o.

First case: elim(s, o)= inl a. Then we have
[canl ◦ elim, p∗](s, inl o)= canl(s, elim(s, o)) = inl a,
and so by equality
elim(s, p¯(s, inl o)) = inl a = elim(s, o).
Therefore, p¯(s, inl o) ∼n+1 o.
Second case: elim(s, o)= inr (c, h). Then we have [canl ◦ elim, p∗](s, inl o)= canl(s, elim(s, o))
= inr (c, λr.inl h(r)),
so by equality
elim(s, p¯(s, inl o)) = inr (c, λr.inl p¯(n(s, c, r), inl h(r))).
Then by I.H. p¯(s', inl h(r)) ∼n h(r) and the claim.	 
We are now able to prove the first monad law:
Theorem 6.5 Let p : IOA(s) and q : Πs : S.A(s) → IOB(s). If elimA(s, p)= inl a, then
p ∗ q ≈ q(s, a).
Proof. I. elimB(s, q(s, a)) = inl b. Then we get canl(s, elim(s, q(s, a)) = inl b,
and therefore by elimA(s, p)= inl a
[canl ◦ elim, q∗](s, inr p)= q∗(s, p)= inl b.
And by the equality rule
elimB(s, coitq∗ (s, inr p))= inl b = elimB(s, q(s, a)).
`	=˛p¸∗q	x
II. elimB(s, q(s, a)) = inr (c, h).
Then we get canl(s, elim(s, q(s, a))) = inr (c, λr.inl h(r)), and therefore by
elimA(s, p)= inl a
[canl ◦ elim, q∗](s, inr p)= q∗(s, p)= inr (c, λr.inl h(r)).
By the equality rule,
elimB(s, coitq∗ (s, inr p))= inr (c, λr.coitq∗ (n(s, c, r), inl h(r))).
`	=˛p¸∗q	x


By Lemma 6.4 follows
h(r) ≈ coitq∗ (n(s, c, r), inl h(r))
for r : R(s, c), and therefore p ∗ q ≈ q(s, a) .	 
Corollary 6.6 (First monad law) If q : Πs : S.A(s) → IOB(s), then
η(s, a) ∗ q ≈ q(s, a).
Unless otherwise noted, let in the rest of the article for s : S



o : IOA0 (s), p(s): A0(s) → IOA1 (s), q(s): A1(s) → IOA2 (s),
Lemma 6.7 If o ~ (c, h), then
p¯ = coitp∗ .

o ∗ p ~ (c, h ∗ p).
Proof. By elim(s, o) = inr (c, h) follows p∗(s, o) = inr (c, λr.inr h(r)). By equality, we get
elim(s, p¯(s, inr o)) = inr(c, λr.p¯(n(s, c, r), inr h(r))).
We have o ∗ p = corecp∗ (s, o)= p¯(s, inr o), and
h(r) ∗ p = corecp∗ (n(s, c, r), h(r)) = p¯(n(s, c, r), inr h(r))
for r : R(s, c). Therefore, elim(s, o ∗ p)= inr(c, λr.h(r) ∗ p).	 
Theorem 6.8 (Second monad law) If p : IOA(s), then p ∗ η ≈ p.
Proof. We show p ∗ η ∼n p by induction on n.
elimA(s, p)= inl a. Then we have
elimA(s, p ∗ η)= elimA(s, η(s, a)) = inl a = elimA(s, p)
elimA(s, p)= inr (c, h). By Lemma 6.7 we get
elimA(s, p ∗ η)= inr (c, λr.h(r) ∗ η),
and by I.H. follows the claim.	 
Lemma 6.9 If o ~ (c, h), then (o ∗ p) ∗ q ~ (c, (h ∗ p) ∗ q).
Proof. By Lemma 6.7.	 
Lemma 6.10 If o ~ (c, h), then o ∗ (λs, a.p(s, a) ∗ q) ~ (c, h ∗ (λs, a.p(s, a) ∗
q)).


Proof. By Lemma 6.7.	 
Lemma 6.11 If o ~ a0 and p(s, a0) ~ a1, then o ∗ p ~ a1.
Proof. By elim(s, o)= inl a0 follows
p∗(s, a0)= canl(s, elim(s, p(s, a0))) = canl(s, inl a1)= inl a1.
Therefore, [canl ◦ elim, p∗](s, inr o)= p∗(s, a0)= inl a1.
By equality we get
elim(s, p¯(s, inr o)) = inl a1.
o ∗ p = corecp∗ (s, o)= p¯(s, inr o), and therefore elim(s, o ∗ p)= inl a1.	 
Lemma 6.12 If o ~ a and p(s, a) ~ (c, h), then o ∗ p ~ (c, h').
with h'(r)= p¯(n(s, c, r), inl h(r)).
Proof. By elim(s, o)= inl a follows
p∗(s, o)= canl(s, elim(s, p(s, a))) = canl(s, inr (c, h)) = inr (c, λr.inl h(r)).
Therefore, [canl ◦ elim, p∗](s, inr o)= p∗(s, a)= inr (c, λr.inl h(r)). By equality we get elim(s, o ∗ p)= elim(s, p¯(s, inr o)) = inr (c, λr.p¯(n(s, c, r), inl h(r))).	 
Lemma 6.13 Let o' = p¯(s, inl o). Then o ∗ q ≈ o' ∗ q.
Proof. We show o ∗ q ∼n o' ∗ q by induction on n.
First case: elim(s, o) = inl a. We have [canl ◦ elim, p∗](s, inl o) = inl a, and therefore elim(s, p¯(s, inl o)) = inl a.
First subcase: elim(s, q(s, a)) = inl b. By Lemma 6.11 we get elim(s, o' ∗ q)= 
inl b = elim(s, o ∗ q).
Second subcase: elim(s, q(s, a)) = inr (c, h). By Lemma 6.12 we get elim(s, o∗ q) = inr (c, h') = elim(s, o' ∗ q), where h'(r) = q¯(n(s, c, r), inl h(r)). Second case: elim(s, o)= inr (c, h). By Lemma 6.7 we get
elim(s, o ∗ q)= inr (c, λr.h(r) ∗ q).
We have [canl ◦elim, p∗](s, inl o)= inr (c, λr.inl h(r)), and therefore elim(s, o')= 
inr (c, h'), where h'(r)= p¯(n(s, c, r), inl h(r)). By Lemma 6.7 we get
elim(s, o' ∗ q)= inr (c, λr.h'(r) ∗ q),
and by I.H. the claim.	 
Lemma 6.14 If o ~ a and p(s, a) ~ (c, h), then
(o ∗ p) ∗ q ≈ o ∗ (λs, a.p(s, a) ∗ q).


Proof. By Lemma 6.12 follows elim(s, o ∗ p) = inr (c, h'), where h'(r) =
p¯(n(s, c, r), inl h(r)). By Lemma 6.7 follows
elim(s, (o ∗ p) ∗ q)= inr (c, λr.h'(r) ∗ q).
By elim(s, p(s, a)) = inr (c, h) and Lemma 6.7 we get
elim(s, p(s, a) ∗ q)= inr (c, λr.h(r) ∗ q).
By Lemma 6.12 we get
elim(s, o ∗ (λs, a.p(s, a) ∗ q)) = inr (c, λr.h''(r)),
where h''(r) = f¯(n(s, c, r), inl h(r) ∗ q), f¯ = coitf∗ , f = λs, a.p(s, a) ∗ q. By Lemma 6.4 follows h''(r) ≈ h(r) ∗ q, and by Lemma 6.13 h(r) ∗ q ≈ h'(r) ∗ q. 
Lemma 6.15 If o ~ a0, p(s, a0) ~ a1 and q(s, a1) ~ (c, h), then
(o ∗ p) ∗ q ≈ o ∗ (λs, a.p(s, a) ∗ q).
Proof. By Lemma 6.11 and Lemma 6.12 we get elim(s, o ∗ p) = inl a1 ,
elim(s, (o ∗ p) ∗ q)= inr (c, h'), where h'(r)= q¯(n(s, c, r), inl h(r)).
Furthermore, by Lemma 6.12
elim(s, p(s, a0) ∗ q)= inr(c, h'),


and again
elim(s, o ∗ (λs, a.p(s, a) ∗ q)) = inr (c, h'') ,

where h''(r)= f¯(n(s, c, r), inl h'(r)), f¯ = coitf∗ , f = λs, a.p(s, a) ∗ q.
By Lemma 6.4 follows h''(r) ≈ h'(r) ≈ h(r).	 
Theorem 6.16 (Third monad law)
(o ∗ p) ∗ q ≈ o ∗ (λs, a.p(s, a) ∗ q).
Proof. We show (o ∗ p) ∗ q ∼n o ∗ (λs, a.p(s, a) ∗ q) by induction on n.
Case I: elim(s, o)= inr (c, h). Then by Lemma 6.9
elim(s, (o ∗ p) ∗ q)= inr (c, λr.(h(r) ∗ p) ∗ q) ,
and by Lemma 6.10
elim(s, o ∗ (λs, a.p(s, a) ∗ q)) = inr (c, λr.h(r) ∗ (λs, a.p(s, a) ∗ q)).
The claim follows by the I.H.

Case II: elim(s, o) = inl a0 . This case follows by Lemmata 6.11, 6.15,
6.14.	 

Conclusion
We have introduced state dependent interactive programs in Martin-L¨of type theory. We have given a model of the corresponding final coalgebras in set the- ory, and added corresponding rules introducing operations IO : (S → Set) → (S → Set) to Martin-Lo¨f type theory. Using these rules we have introduced the bisimulation relation ≈, and operations ∗, η, and have shown that (IO, ∗, η) is a state-dependent monad w.r.t. ≈.

References
Andrea Asperti, Guiseppe Longo. Categories, Types and Structures. An Introduction to Category Theory for the working computer scientist. Foundations of Computing Series. M.I.T. Press, 1991.
C.  D.  Team.   The Coq proof assistant.  reference manual.   Available  from
http://coq.inria.fr/doc/main.html , 2003.
Robert L. Constable et. al. Implementing Mathematics with the Nuprl Proof Development System. Prentice-Hall, Englewood Cliffs, NJ, 1986.
Catarina Coquand. Agda. http://www.cs.chalmers.se~catarina/agda/ .
P. Hancock and A. Setzer. The IO monad in dependent type theory. In Electronic proceedings of the workshop on dependent types in programming, Go¨teborg, 27-28 March 1999, 2000. Available via http://www-sop.inria.fr/oasis/DTP00/Proceedings/proceedings.html .
Peter Hancock, Anton Setzer. Interactive programs in dependent type theory. In: P. Clote, H. Schwichtenberg: Computer Science Logic. 14th international workshop, CSL 2000. Springer Lecture Notes in Computer Science, Vol. 1862, pp. 317 - 331, 2000.
Ingrid Lindstr¨om. A Construction of non-well-founded Sets within Martin-Lo¨f ’s Type Theory.
The Journal of Symbolic Logic, Volume 54, Number 1, 1989.
Z. Luo. Computation and reasoning. Clarendon Press, Oxford, 1994.
Per Martin-Lo¨f. Intuitionistic Type Theory. Bibliopolis, Napoli, 1984.
Lawrence S. Moss. Parametric corecursion. In: Theoretical Computer Science 260, 2001.
Bengt Nordstr¨om, Kent Peterson, Jan M. Smith. Programming in Martin-Lo¨f ’s Type Theory: An Introduction. Clarendon Press, Oxford, 1990.
Lawrence C. Paulson. Natural Deduction Proof as Higher-Order Resolution. Technical report 82, University of Cambridge Computer Laboratory, Cambridge, 1985.
Kent Peterson. A Programming System for Type Theory. PMG Memo 21, Chalmers University of Technology, S-412 96 Go¨teborg, 1982.
R. Pollack. The theory of LEGO. A proof checker for the extended calculus of constructions. PhD thesis, LFCS, Edinburgh, 1994.
Philip Wadler. The essence of functional programming. In: 19th Symposium on Principles of Programming Languages, Albuquerque, volume 19. ACM Press, January 1992.
