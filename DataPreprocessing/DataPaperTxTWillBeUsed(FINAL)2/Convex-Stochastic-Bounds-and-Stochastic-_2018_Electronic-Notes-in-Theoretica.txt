Available online at www.sciencedirect.com


Electronic Notes in Theoretical Computer Science 337 (2018) 23–44
www.elsevier.com/locate/entcs

Convex Stochastic Bounds and Stochastic Optimisation on Graphs
J. Cohen
LRI, CNRS, Universit´e de Paris Sud, Universit´e Paris Saclay, Orsay, France

A. Fauquette
LRI-CentraleSupelec, CNRS, Universit´e de Paris Sud, Universit´e Paris Saclay, Orsay, France

J.M. Fourneau
DAVID, UVSQ, Universit´e Paris Saclay, Versailles, France

G.C. Noukela
LACL, Univ. Paris Est Cr´eteil, France et
LRI, CNRS, Universit´e de Paris Sud, Universit´e Paris Saclay, Orsay, France

N. Pekergin
LACL, Univ. Paris Est, Cr´eteil, France


Abstract
This paper presents an approach to provide stochastic bounds for a large class of optimisation problems on graphs when the parameters (i.e. costs, weights or delays) for links are random variables. We consider the class of problems which are based on convex operators and whose complexity is polynomial, when the parameters are deterministic. Here, the parameters (for instance the delay of a link) are discrete random variables. Such an assumption drastically changes the complexity of the problem (typically, the problems turn out unfortunately to be NP-complete). We propose to give stochastic bounds (both upper and lower bounds) based on convex order. First, we prove how we can simplify a discrete distribution to obtain bounding distributions which are easier to deal with, leading to a tradeoff between the computation complexity and the accuracy of the bounds. Second, we design a polynomial time algorithm to compute an upper bound. The approach is illustrated by the computation of the execution time of a task graph.
Keywords: Stochastic Convex Ordering, Discrete Distributions, Optimisation on Graphs, Stochastic PERT.


https://doi.org/10.1016/j.entcs.2018.03.032
1571-0661/© 2018 The Author(s). Published by Elsevier B.V.
This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).

Introduction

In most optimisation problems on graphs, it is assumed that the edge or node costs or weights are deterministic, but this is not realistic in many cases. In a commu- nication network, links or networking elements may malfunction due to congestion, accidents, weather conditions, DDOS attacks, ... Thus, one may associate with each edge and node a probability that this element will be fully or only partially avail- able. Typically, we assume that each element (node or edge) has several capacity levels (that we can denote as states) with associated probabilities. Our aim is to analyze the distribution of the results of the optimisation problem knowing the dis- tributions of probabilities on the edges and the nodes. We consider a large class of optimisation problems : Max-Flow, Shortest Path, Reliability, Minimum Spanning Tree, Completion Time. These problems are built upon convex or concave opera- tors. These problems have received a lot of attention due to their practical interest and their rich theoretical context (see for instance [5] for the complexity issue).
Many methods only consider approximations or bounds for the expectation and are based on the graph properties which are relevant for the problem. For instance, in [14], the authors study the properties of the trees and the cuts associated with them to bound the distribution of the total weights in a spanning tree where the edges’ weights are random.
A completely different approach was used in [18] to bound the execution time of a task graph where the delays are independent and exponentially distributed. The authors obtain stochastic upper and lower bounds of the distributions of the completion time. The stochastic order they used is the strong stochastic bound and the comparison takes advantage of the association (i.e. positive correlation) of the random variables describing the delays experienced on a path between the source and the destination.
Unlike most traditional approaches for this problem, our approach is based on the distributions of probability on the edges or the nodes and the properties of the operators rather than the structure of the graph. As the operators are convex, we advocate that we can use stochastic convex order on the distributions of probability for the inputs to bound the distribution of the result.
The distribution of probability for the edges is a discrete distribution, for in- stance obtained from some measurements. We do not assume that we obtain a density from these measurements through a fitting algorithm such as [7]. We di- rectly deal with the measurements and we obtain bounds with a tradeoff between computation complexity and accuracy. The main transformation (or actions) is the fusion of atoms (like in [8]) in the input distribution of the problems.
The technical part of the paper is as follows. In Section 2 we give a brief introduction to strong stochastic order and convex order and we define the family of optimisation problems we want to study. We show that these problems are based on the same set of operators which are increasing and convex (or concave). Section 3 is devoted to the elementary actions to design upper and lower bounds. In Section 4, we present an optimal algorithm for the upper bound and in Section 5

an algorithm for the lower bound. Finally in Section 6, we illustrate the approach with an example: the computation of the distribution of the completion time for a task graph.

Optimisation on Graphs and Stochastic Convex Or- dering
Optimisation on graphs
Let us consider the following simple optimisation problem for a directed graph to illustrate our approach. As our approach is not based on the graph properties but on the operators used in the optimisation process, and on stochastic ordering, the approach can deal with many optimisation problems which looks distinct at first glance. However, these problems are all built with the same operators. Thus, our approach can be used to provide stochastic bounds for all of them.
To illustrate our approach, we consider a general Directed Acyclic Graph (V, E) with number of edges M . We assume that the DAG is not a serie-parallel directed graph as this family of graphs allows for a recursive computation. Thus we exclude such an algorithm based on recursion. We assume that the nodes are labelled using a topological ordering. Thus, if (i, j) ∈ E then i < j.
The nodes are labelled with positive random delays (wi)i∈V . A directed edge from i to j means that j needs the results of i to be executed and must wait until all the preceding nodes have completed their own work.


Fig. 1. Task graph.

Let bi (resp. ei) be the time when node i begins (resp. completes) its work. We have ei − bi = wi where wi is the execution time of task i. It is well-known (see for instance [18]) that the time to complete the last node of the graph eM can be

recursively computed by the following sequence:
ei = wi + maxj∈Γ−(i)(ej)
where Γ−(i) is the set of predecessors of i and the sequence is initialized with
e1 = b1 + w1, and b1 = 0. And the Completion-time of the task graph is eM .
The operators ”Max”, ”Min” and ”+”, are used to define many optimization problems on graphs. Thus, the methodology we develop here is useful to address many practical discrete problems. Let us illustrate the generality of the approach with a small list of well-known problems (see the reference book [2] for more precise statements):
Shortest Path: the length of a path is the sum of the length of the edges and we need the path with the minimal length.
Maximum Flow : as ”Max Flow = Min Cut”, we have to compute the minimum of the capacities of the cuts in the networks. A cut is a subset of edges which disconnect the source and the destination. The capacity of a cut is the sum of the capacity of the edges inside the cut. Again the problem is defined with operators ”Min” and ”+” on structures which only depend on the graph.
”s-t” Reliability: the probability that there is an operating path from ”s” to ”t” in the network when each link may fail (in that case, the distributions have two atoms 0 and 1 to represent DOWN and UP links) is also the expectation for the maximum flow with edge capacity equal to 0 and 1.
Minimum Spanning Tree: the cost of a spanning tree is the sum of the costs of the edges of the tree. And we take the minimum over all these costs. Again we use the ”Min” and ”+” operators.
Completion Time (or Critical Path Method) makes use of the ”Max” and ”+” operators as seen previously.
We assume independence of the various random variables acting as inputs in the model. We denote by Ω the state space. Under the independence assumption, the probability of (d1,,,, dM ) is given by:
Pr(d1, ..., dM )= Y Pr(Xi = di),
i
and Ω is the Cartesian product of the support of the input distributions. All these problems are polynomial when the inputs are deterministic. Unfortunately, it is not true anymore when the nodes are associated with random variables. Ball et al. have surveyed in [5] various methods to evaluate network reliability and some performability problems. They stated that calculating the distribution of the results is NP-hard for various shortest path and flow problems for networks or graphs with random costs. Note that it is still possible to solve the problem for small instances where the sizes of the supports are small (i.e. in a naive point of view, the distributions are almost deterministic). It is sufficient to use the Total Probability Theorem after conditioning on the states of all the random variables.  We will

illustrate this approach on the ”Completion Time” problem.
Without loss of generality we now assume that the random variables are as- sociated with the nodes. Assume that the state of the network (or the graph) is a vector with size M called X = X1, ...XM where Xi is the state of the random variable associated with node i (i.e. it is an atom as the distributions are discrete). First let us formally define CompletionTime(D1, ..., DM ) as the random variable equal to the completion time of the graph where the delays on node i is distributed according to Di. CT (d1, ..., dM ) will be the value (in R+) of the completion time when the input random variables are equal to d1,...,dM . CT (.) can be computed in a linear time as the variables are now deterministic. Consider again the digraph (V, E). Let Di be the distribution of the delay in node i. Conditioning on the value
of the random variables, we obtain:

Pr(CompletionTime(D1, ..., DM )= T )=	Σ
(d1...dM )∈Ω
Pr(d1, ..., dM )1CT (d1,...,dM )=T

Thus, a naive approach consists in conditioning on all the random variables to obtain a problem with deterministic inputs which is solved in a linear time in the size of the graph. However, we have to deal with all the possible values of the random variables leading to a number of deterministic problems to solve, which is equal to the product of the number of atoms (i.e. the size of Ω). Assume that all the distributions have the same size (equal to N ), the complexity of this naive approach is:
NM B(M ),
where B(M ) is the complexity in the deterministic case for a graph with size M . All the problems mentioned previously have a polynomial complexity and CT (.) has a linear complexity. Note that we still have to group these elements in a distribution (several conditionings may give the same value for CT (.)). This may add an extra logarithmic term if we need to sort the data to merge all the configurations of random variables with the same value for CT (.).
Also note that we do not claim that such an approach is optimal. However, as the complexity of this family of problems with random variables as inputs is NP, there is no polynomial time algorithm (unless NP = P ) for general instances of these problems.
Stochastic ordering and its application to reduce the complexity
Here, we propose to reduce the number of atoms while keeping some qualitative information on the results. This is obtained through the use of various stochastic orders. We do not establish new complexity results. We just prove that we can reduce the size of the problems when it is too large and keep some bounds according to some stochastic orders [17].
Definition 2.1 [increasing convex ordering] Let X and Y be two random vari- ables, X ≤icx Y if for all increasing convex function φ, E[φ(X)] ≤ E[φ(Y )] if the expectations exist.

Definition 2.2 [stochastic convex ordering] Let X and Y be two random variables,
X ≤cx Y if E[X]= E[Y ] and X ≤icx Y [13,17].
Definition 2.3 [strong stochastic ordering] Let X and Y be two random variables,
X ≤st Y if for all increasing function φ, E[φ(X)] ≤ E[φ(Y )] if the expectations exist.
Corollary 2.4 Thus, we have:
X ≤cx X and X ≤st X.
If X ≤st Y , then for all k, E[Xk] ≤ E[Y k].
If X ≤cx Y , then for all k > 1, E[Xk] ≤ E[Y k]. As E[X] = E[Y ], we get
V ar[X] ≤ V ar[Y ].
These orders differ considerably when we consider the expectations of the ran- dom variables.
Proposition 2.5 Let X and Y be two random variables, such that X ≤st Y . If
E[X]= E[Y ] then X = Y .
Proposition 2.6 (Expectation) Let X be a random variable with ﬁnite expecta- tion, then E[X] ≤cx X and E[X]+ X ≤cx 2X.
Finally we add some well-known properties which will be useful to prove our algorithms. Their proofs and more results on these stochastic orderings can be found in the literature [15,16].
Proposition 2.7 (Stop Loss) Let X and Y be two random variables, X ≤cx Y if and only if E[X]= E[Y ] and, for all d we have, E[(X − d)+] ≤ E[(Y − d)+].
It is sometimes more convenient to use the following characterization.
Corollary 2.8 Let X and Y be two random variables, X ≤cx Y if and only if
E[X]= E[Y ] and, for all d we have, E[(d − X)+] ≤ E[(d − Y )+].
Theorem 2.9 (Theorem 3.A.44 of Shantikumar [16] page 133) Let X and Y be two random variables with equal means (E[X]= E[Y ]) and with respective cdf FX and FY . X ≤cx Y , if and only if the number of sign changes for the function FY −FX is equal to 1 and the sign change sequence is +, −. The cases FY −FX =0 are discarded (not considered as sign changes).
When we deals with the comparison of discrete random variables, distributions are step-functions. Both methods require to decompose the support into intervals where the expectation or the cumulative distribution function are constant. Thus, both methods of proof have roughly the same complexity. We use both in Section 3 and Section 4.
Proposition 2.10 (Mixing) Let X, Y and Θ be three random variables such that
[X|Θ= a] ≤ψ [Y |Θ= a] for all a in the support of Θ, then X ≤ψ Y with ≤ψ being
≤icx, ≤st or ≤cx.
Thus, using the convex ordering and the increasing convex ordering instead of

the strong stochastic ordering we keep constant the expectation and we hope that we only introduce a small bias when we deal with bounds instead of the measurements. The main characterization of the optimisation problems we consider in this paper is an extension of monotony related to various stochastic orderings. Let us define first the generic Ψ−monotony.
Definition 2.11 [Ψ−Monotony] A function f is Ψ−monotone if for all X and Y random variables such that X ≤ψ Y , then f (X) ≤ψ f (Y ), with ≤ψ being ≤icx, ≤st or ≤cx.
In this paper, we will prove that the problems we consider are monotone for the strong ordering or monotone for the increasing convex ordering. These properties are now illustrated for some well-known optimisation problems on graphs.
Proposition 2.12 The CompletionTime is monotone for the increasing convex or- dering.
Proof: Let us consider three random variables X, Y and Θ such that X ≤cx Y . Thus X ≤icx Y . Now consider an arbitrary increasing convex function f whose arguments are X and Θ (or Y and Θ) and taking value in R. For any real a, we have f (X, a) ≤icx f (Y, a). Thus, for all a, f (X, Θ)|Θ = a ≤icx f (Y, Θ)|Θ = a. Due to the mixing property 2.10, we have f (X, Θ) ≤icx f (Y, Θ). Thus one can replace each input random variables by a bounding distribution. Finally, we note that ”CompletionTime” problem is defined with the ”max” and ”+” operators which are increasing and convex. Clearly, the assumptions on function f hold for ”CompletionTime”.
Proposition 2.13 The CompletionTime is monotone for the strong stochastic or- dering.
The proof is similar.
Corollary 2.14 Consider the CompletionTime problem. Assuming that the dura- tions of the task are random. Replacing the random durations by their expectations introduces a systematic biais. The deterministic result is a lower bound for the in- creasing convex ordering for the distribution and a lower bound for the expectation.
Proof: Let Di be the distribution of the duration of task i. According to Prop. 2.6, we have for all node index i
E[Di] ≤cx Di.
As CompletionTime is monotone for the increasing convex ordering, we get:
CT (E[D1], E[D2], .., E[DM ]) ≤icx CompletionTime(D1, D2, .., DM ).
Taking the Expectation, we obtain:
E[CT (E[D1], E[D2], .., E[DM ])] ≤ E[CompletionTime(D1, D2, .., DM )].
As CT (.) is the result of the deterministic problem, it is equal to its expectation.

Thus:
CT (E[D1], E[D2], .., E[DM ]) ≤ E[CompletionTime(D1, D2, .., DM )].
Thus, one must be aware that replacing the input distributions by their expectations introduce a systematic biais (in fact we proved that it is a lower bound). Using stochastic bounds instead of this crude approximation will help to balance between the complexity and the accuracy of the results to derive a better approach for practical problems.
Proposition 2.15 Similarly, the Shortest-Path problem, the max-flow problem and the s-t reliability problem which are deﬁned with the ”min” and ”+” operators are monotone for the strong stochastic ordering as these operators are increasing.
Combining the Ψ−monotone property and the approach based on conditioning suggest to algorithmically simplify the distributions to get bounds on the inputs and obtain bounds of the outputs due to the monotone property. Some of us had already studied this approach for the strong stochastic ordering [4]. More precisely, for an arbitrary distribution D with size N and any positive increasing reward function r, we proved in [4] an algorithm to find the distributions D1 and D2 with size K < N such that
D1 ≤st D ≤st D2
D1 and D2 are optimal bounds according to the expectation of an arbitrary increasing function r.
The optimality of D1 means that if we found a distribution D3 such that D3 ≤  D and Σi r(i)D1(i) ≤ Σi r(i)D3(i) ≤ Σi r(i)D(i), then D3 = D1 or D3 = D. The optimality of D2 is defined in a similar manner. Note that, as function r is
increasing, D1 ≤st D implies that Σi r(i)D1(i) ≤ Σi r(i)D(i). Such an approach
was shown to be valuable for network performance modeling [3], operation research [4], reliability modeling [11,12].
In this paper, we investigate a similar problem for the convex order. More pre- cisely, for an arbitrary distribution D with N positive atoms, we prove an algorithm to find D2 such that
D ≤cx D2
D2 has size K < N .
D2 is an optimal bound according to the expectation of an arbitrary convex function φ(x) (i.e. for instance any moment).
Furthermore, we propose an algorithm to find a lower bound D1 with size K but we do not prove the optimality of our method.
Basic Operations on Atoms
The following lemma will help to deal with large distributions by allowing to ex- tract a part of them (by conditioning) and proving the algorithms on these smaller

distributions. We begin with a very simple technical lemma.
Lemma 3.1 Let x1, x2, x3, x4 be arbitrary positive values such that x1 < x2 < x3 < x4. Then we have:
(x3 − x2)(x4 − x1) < (x3 − x1)(x4 − x2).

Proof: x1 < x2 < x3 < x4. Thus, (x2 − x1)(x4 − x3) > 0. Thus, (x3 − x2)(x4 − x1) < (x4 − x2)(x3 − x1).

Indeed, and
(x3 − x2)(x4 − x1) = x3x4+ x1x2 − x4x2 − x1x3 (x4 − x2)(x3 − x1) = x3x4+ x1x2 − x2x3 − x1x4

Finally, (x3 −x2)(x4 −x1) + (x2 −x1)(x4 −x3) = (x4 −x2)(x3 −x1) and the result holds.
Lemma 3.2 We consider distribution D on support S. We deﬁne a true partition of S into S1 and S2. We now consider X an arbitrary random variable with dis- tribution D and the boolean random variable Θ = 1X∈S1. We will bound the two random variables [X|Θ= True] and [X|Θ= False].
Assume that one builds a new random variable (say Y ) on S as follows:
[X|Θ= False]= [Y |Θ= False],


and

then Y ≤cx X.

[Y |Θ= True] ≤cx [X|Θ= True],

Proof: it is a simple application of property 2.10.
Corollary 3.3 Similarly, if Y satisﬁes
[X|Θ= False]= [Y |Θ= False],
and,
[X|Θ= True] ≤cx [Y |Θ= True],
then X ≤cx Y . We obtain an upper stochastic bound for the convex ordering.
These last two properties are very important to simplify the proofs of the fol- lowing results on the comparison of distributions. They allow to decompose the distributions into two parts: the one which is not impacted by the action, and the one which contains the atoms which are modified. Therefore in the following lemmas, we only consider the atoms which are modified. We begin with a new formulation of the basic actions needed to design a strong stochastic bound.

Lemma 3.4 We consider an arbitrary discrete distribution (say D1) on two atoms a and b (without loss of generality we assume that a < b) deﬁned by the following positive probabilities pa and pb. Let us deﬁne by D2 and D3 the distributions with a single atom in a for D2 and in b for D3, with probability equal to 1 in both cases. Then, D2 ≤st D1 ≤st D3.
We now prove some lemmas on the basic operations of fusion of atoms to obtain lower bounds (Lemma 3.5) and upper bounds (Lemma 3.6) for the convex ordering.
Lemma 3.5 We consider an arbitrary discrete distribution (say D1) on two atoms a and b (without loss of generality we assume that a < b) deﬁned by the following positive probabilities pa and pb. Let us deﬁne by D2 the distribution with a single atom M equal to (a pa + b pb). Then, D2 is a lower bound for the convex stochastic ordering of D1: D2 ≤cx D1.


Fig. 2. Fusion of two atoms for a lower bound
Proof: it is a simple application of property 2.6.
Lemma 3.6 We consider an arbitrary discrete distribution (say D3) on three atoms a, b, c (without loss of generality we assume that a < b < c) deﬁned by the positive probabilities pa, pb and pc. Let us deﬁne by D4 the distribution of atoms a and c the probabilities of which (denoted as qa and qc) are deﬁned by
qa + qc =1 
and
aqa + cqc = apa + bpb + cpc.
Then, D4 is an upper bound for the convex stochastic ordering of D3: D3 ≤cx D4.


Fig. 3. Upper bounding distribution.

Proof: Two steps. First, we check that these two equations define a distribution of probability. Second, we prove that it is an upper bound for the convex ordering.
1 1 
As a /= c, determinant	is not equal to 0 and there exists a unique solution
a c 

to the system of equations. This solution is:
c − b	b − a
qa = pa + pb c − a	qc = pc + pb c − a
We now prove that D3 ≤cx D4 using the Stop Loss property (i.e. Property 2.7). We have to check that for all d, E[(X − d)+] ≤ E[(Y − d)+]). We decompose the proof according to the interval which contains d:
d ≥ c. Thus (X − d)+ and (Y − d)+ are equal to 0. Thus the equality holds.
b ≤ d < c. (X − d)+ is positive when d = c. And E[(X − d)+] = (c − d)pc. Similarly, E[(Y − d)+] = (c − d)qc. Clearly pc ≤ qc, and (c − d) is positive, therefore the relation holds.
a ≤ d < b. (X − d)+ is positive when d = c and d = b. Thus,
E[(X − d)+]= (c − d)pc + (b − d)pb
(Y − d)+ is positive when d = c. Thus,
E[(Y − d)+]= (c − d)qc

As qc = pc + pb b−a , after simplifications we have to compare (b−d) and (b−a)(c−d) .
c−a	c−a
And we apply Lemma 3.1 to prove that E[(X−d)+] ≤ E[(Y −d)+] for all d between
a and b.
d < a. (X − d)+ and (Y − d)+ are positive. Thus E[(X − d)+] = E[X − d] = 
E[X] −d. Similarly, E[(Y −d)+]= E[Y ] −d. As E[X]= E[Y ] the equality holds.
We have also proved another method to obtain a lower bound with less atoms. We have to consider two cases to remove one atom out of three. We just illustrate one of them in the following lemma.
Lemma 3.7 We consider an arbitrary discrete distribution (say D1) on three atoms a, b, c (without loss of generality we assume that a < b < c) deﬁned by

the positive probabilities pa, pb and pc. Assume that b > a pa+c pc
= M. Let us

deﬁne by D2 the distribution of atoms a and b the probabilities of which (denoted as qa and qb) are deﬁned by


and

Then, D2 ≤cx D1.
qa + qb = 1,

a qa + b qb = a pa + b pb + c pc.

The Lemma is not proved as we do not use this construction to obtain a lower bound in the following of the paper. It is just given here to show that we can obtain a lower bound according to the convex ordering based on a subset of atoms. We have a similar construction when b < a pa+c pc = M as illustrated by the following
a	c
example.




Fig. 4. Lower bound, first case.
Example 3.8 Let D1 be a discrete distribution defined on H1 = {1, 2, 4} (a=1,b=2,c=4) with following probabilities [0.2, 0.4, 0.4]. Thus E[D1] = 2.6, and the barycenter between 1 and 4 is M = 3. The lower bounding distribution D2 is defined on H2 = {2,4} with probabilities q2 = 0.7 et q4 = 0.3, thus one can check that E[D2]= 2.6 = E[D1]. One can check easily that there is 1 sign changes and the sequence of signs is +, −, it follows from Theorem 2.9 that
D2 ≤cx D1
.
Note that when b = a pa+c pc , the construction is equivalent to the one studied
a	c
in Lemma 3.5.
Algorithm for an optimal upper bound
Before proceeding with the algorithms, we prove a characterization of the atoms of the upper bound for the convex order.
Structure of an optimal solution for the convex ordering on a subset of atoms
Lemma 4.1 Let D1 a distribution on N atoms and D2 a distribution on K atoms, such that D1 ≤cx D2. Let x1, x2, ··· , xN be the atoms of D1 sorted in increasing order, each value xi is associated a probability pi. Similarly, let y1, y2, ··· , yK be the atoms of D2 sorted in increasing order, associated to probabilities qi. Then y1 = x1 and yK = xN .
Proof: it has two steps. First, we prove that x1 ≥ y1 and then, we show that x1 /= y1 does not hold. Let X (resp. Y ) be a random variable distributed following D1 (resp. D2).
Assume that x1 < y1. Then there exists some d between: x1 < d < y1. We compute E[(d − X)+] and E[(d − Y )+].
E[(d − X)+]= (d − x1)p1 > 0
E[(d − Y )+]=0 
Thus there is a contradiction with D1 ≤cx D2 and Corollary 2.8.
Now assume that y1 < x1. Consider d such that y1 < d < x1. E[(X − d)+] = 
E[X] −d as d < x1 and x1 is the smallest atom of D1. And E[(Y −d)+] < E[Y ] −d,

as d > y1. Taking into account that E[X]= E[Y ], we get E[(X−d)+] > E[(Y −d)+], again a contradiction. The proof that yK = xN is similar and is omitted for the sake of conciseness.
We now combine the basic actions we have studied in the previous section to obtain algorithms which reduce the complexity of the distributions while providing upper and lower bounds for the stochastic convex ordering. We first try to compare actions on distributions which share atoms to obtain an optimal action for the design of an upper bound.
Lemma 4.2 We consider distribution D with 4 atoms a, b, c, f such that (a < b < c < f ). Assume that pa, pb, pc, pf are positive. We apply Lemma 3.6 to atoms a, b et c to obtain an upper bound (i.e. say D2) on the support {a, c, f}. We also apply Lemma 3.6 to atoms a, b et f to obtain D3. This last distribution has also {a, c, f} as a support and D1 ≤cx D2 ≤cx D3.


Fig. 5. Comparing upper bounds.

Proof: Both distributions have the same support and the same expectations as they are both equal to the expectations of D. We already know due to Lemma
3.6 that D1 ≤cx D2 and D1 ≤cx D3. We now prove that D2 ≤cx D3 using the Stop-Loss property. Using Lemma 3.6 we know that D2 is:
c − b	b − a
qa = pa + pb c − a,  qc = pc + pb c − a,  qf = pf
as pb has been distributed among a and c while f was not modified. Similarly, D3
is:
f − b	b − a
ra = pa + pb f − a,  rf = pf + pb f − a,  rc = pc
because we distribute pb between a and f while c was kept unchanged. We consider an arbitrary d and we compare E[(X − d)+] and E[(Y − d)+] where X (resp. Y ) is distributed according to D2 (resp. D3). One must study 4 cases:
d ≥ f . We have, as usual, E[(X − d)+]=0= E[(Y − d)+].
c ≤ d < f . E[(X − d)+] = (f − d)pf and E[(Y − d)+] = (f − d)rf . As f > d
andrf > pf , the inequality holds.
a ≤ d < c. We compute the expectations:


E[(X − d)+]= (c − d)qc
+ (f − d)qf
= (c − d)pc
(c − d)(b − a)
+	pb
c − a
+ (f − d)pf ,

and
E[(Y − d)+]= (c − d)r


+ (f − d)r  = (c − d)p


+ (f − d)p


(f − d)(b − a)
+	p .

c	f	c


f	f − a	b

Lemma 3.1 implies that c−d < f−d . Therefore, E[(X − d)+] < E[(Y − d)+]
c−a	f−a
d < a. As usual, E[(X − d)+]= E[X] − d = E[Y ] − d = E[(Y − d)+].
This concludes the proof.
Let us now assume that we have selected K atoms out of N and we prove the structure of the optimal distribution which is an upper bound for the convex ordering.
Lemma 4.3 Let X be a random variable taking value on set S which contains N atoms, following distribution D. Consider an arbitrary subset S1 of S with K atoms xu1 , xu2 ... xuK .
Let Y be a random variable taking value on set S1, following distribution D1 which is an upper bounding distribution of D for the ≤icx ordering (i.e. D ≤icx D1. Moreover we assume that for all u in S1, we have E[(X − u)+] = E[(Y − u)+]. Consider an arbitrary upper bound (say D2) of D for this subset of K atoms. Then, we have: D1 ≤cx D2.
Proof: Consider a r.v. Z distributed following D2. By construction we have:
∀ d ∈ R,	E[(X − d)+] ≤ E[(Z − d)+]
And by assumption we also have for all u in S1:
E[(X − u)+]= E[(Y − u)+] ≤ E[(Z − u)+]
We now have to prove that E[(Y −d)+] ≤ E[(Z −d)+] for all d in R. We decompose the proof with respect to the values of d compared to the atoms in S1.
Consider two consecutive atoms xui and xui+1 in S1. We know that
E[(Y − xu )+] ≤ E[(Z − xu )+]


and

E[(Y − xu	)+] ≤ E[(Z − xu	)+].

Moreover, functions E[(Z − d)+] and E[(Y − d)+] are linear and decreasing func- tions of d on [xui , xui+1 ]. Therefore, for all d in [xui , xui+1 ],
E[(Y − d)+] ≤ E[(Z − d)+].
Now, assume that d > uK. We have:
E[(X − d)+]= E[(Y − d)+]= E[(Z − d)+]=0 

Similarly, assume that d < u1.
E[(X − d)+]= E[X] − d,	E[(Y − d)+]= E[Y ] − d,	E[(Z − d)+]= E[Z] − d.

And E[X]= E[Y ]= E[Z]. Therefore E[(Z − d)+]= E[(Y − d)+].
Finally
∀ d ∈ R, E[(Z − d)+] ≥ E[(Y − d)+],
This concludes the proof of the Lemma.
We now prove that this optimal distribution already exists and we give an explicit solution.
Theorem 4.4 Let D be a distribution with support S = {x1,..., xN }. The N atoms are sorted in increasing order, and probability pi denotes the probability of atoms xi. Consider an arbitrary subset S1 of S with K atoms ( xu1 , xu2 ... xuK ), sorted in increasing order, with u1 =1 and uK = N. Let D1 be a distribution on S1 associated with probabilities qui , deﬁned as follows for all 1 < i < K:

q	= p	+
ui—1
p xl − xui−1
ui+1—1
+	p
xui+1 − xl ,

ui	ui

l=ui−1+1
l xu
— xu

i−1
l=ui+1
l xu

i+1
— xui

and for the ﬁrst and last atom:


q = p
u2—1
+	p
xu2 − xl ,	q

= p	+
N—1
p xl − xuK−1

1	1
l=2
l xu
— x1
K	N
l=uK−1+1
l xN − xu

K−1

Then, D1 is a upper bounding distribution of D for the ≤cx ordering, with support S1, such that for all u in S1, we have E[(X − u)+]= E[(Y − u)+] where X (resp. Y ) is a random variable distributed following D (resp. D1).
Proof: We have to prove that the distribution is well-defined. In the following, index l describes the atoms of D and index i the atoms of D1. First, it is easy to
notice that qui ≥ 0, for all i, 1 ≤ i ≤ K. We now prove that Σ	qu = 1.
K
i

K	K	ui—1	K—1 ui+1—1	K

Σ q	= Σ
Σ	p xl − xui−1 + Σ
Σ p xui+1 − xl
+ Σ p

ui
i=1
i=2 l=ui−1+1 N—1
l xu

K
— xu

i−1
i=1 l=ui+1
l xu

i+1
— xui
ui
i=1

=	Σ
l=2,l/∈E1
pl + Σ pui =1 
i=1

Second, we prove that E[Y ]= E[X]

K	K	N—1
E[Y ]= Σ qui xui = Σ pui xui +	Σ	plxl = E[X]

i=1
i=1
l=2,l/∈E1

Third, we prove by induction that E[(X − xu )+]= E[(Y − xu )+], for all i,1 ≤ i ≤
K. Clearly the equality holds for uK. Let us consider now uK—1.
E[(Y − xu	)+]= qu  (xu  − xu	)
uK —1

= (x	− x
)	Σ	p
xl − xuK−1

uK	uK−1
l=uK−1+1
l xu
— xu

K−1

= E[(X − xu	)+]
Now, we will assume that E[(X−xu )+]= E[(Y −xu )+] is true for all j, i < j ≤ K.
j	j
We prove that E[(X − xu )+]= E[(Y − xu )+]
i	i
E[(Y − xu )+]= Σ qu (xu − xu )
j>i
= Σ quj (xuj − xui + xui+1 − xui+1 )
j>i
= E[(Y − xu	)+]+ (xu	− xu ) Σ qu .

i+1
i+1
i	j
j>i



By induction E[(Y − xu	)+]= E[(X − xu	)+] and after some algebraic manipu- lations, we get:

E[(Y − xu )+]= E[(X − xu	)+]+	Σ
ui<l≤ui+1
(xl − xui )pl + (xui+1 − xui ) Σ pl
l≥ui+1

= E[(X − xu )+].
This concludes the proof.
Building the graph
Now, we describe a polynomial time algorithm taking a distribution (say D) on N atoms as input. It will return an upper bound distribution D1 which has an included subset of size K (say xu1 , ··· , xuK ) as a support and which minimizes E[φ(Y )] − E[φ(X)] where φ is an arbitrary convex function chosen by the modeler.
From Lemma 4.1, we know that the smallest and largest atom of D must also be in D1. We build the weighted oriented graph G = (V, E) which contains all the paths associated to a final distribution. Its vertices are V = {1, 2, ··· ,N}. The set of the arcs is {(i, j) ∈ V 2|j > i}, and arc (i, j) is associated to weight wij. The weight of arc (i, j) corresponds to the increase of function φ when all atoms between xi and xj are deleted. Thus every distribution can be represent as a path passing by nodes (xuk )k∈[1,K]. Our algorithm is based on Bellman-Ford algorithm [6,9] to find
the path having K edges with the minimum weight. Now, finding the upper bound
distribution of K atoms with the minimal increase for function φ is equivalent to find the shortest path in G starting from vertex 1 to N with K − 1 arcs. This path

can be obtained by adapting the Bellman-Ford algorithm. Let OPT (i, k) be the shortest path starting from the vertex 1 to i using exactly k vertices. Then the recursion formula became
OPT (i, k)= minj<i (OPT (j, k − 1) + wji)


where w

= φ(x )
j—1
p xj − xl + φ(x )
j—1
p xl − xi − Σ φ(x )p

i,j
i
l=i+1
l xj − xi
j
l=i+1
l xj − xi
l  l
l=i

One can easily check that the difference of expectations is the sum of the weights on the path.

n	N
E[φ(Y )] — E[φ(X)] = Σ qui φ(xui ) — Σ pÆφ(xÆ)

i=1
n
Æ=1

n−1 ui+1 −1

= Σ φ(xui )(qui — pui ) — Σ  Σ pÆφ(xÆ)

i=1 n−1
=	φ(x

ui+1 −1
)
i=1 Æ=ui +1
 xui+1 — xÆ
p


i=1
ui
Æ=ui +1
Æ xu

i+1
— xui

n−1
ui+1 −1
n−1 ui+1 −1

+ Σ φ(x
) Σ p  xÆ — xui  + Σ
Σ p φ(x )

i=1
ui+1
Æ=ui +1
Æ xu

i+1
— xui
Æ	Æ
i=1 Æ=ui +1

nΣ−1 √
ui+1 −1

xui+1
— xÆ
ui+1 −1
xÆ — xui

=
i=1
⎝φ(xui )

Æ=ui +1
pÆ
xui+1
— xui
+ φ(xui+1 )

Æ=ui +1
pÆ
xui+1
— xui


—

n−1
ui+1 −1

Æ=ui +1
,
φ(xÆ)pÆ,

= Σ wui,ui+1
i=1




Complexity of the approach
Assume that the input distributions have size N and that the task graph has M
nodes. Thus, the initial problem has a complexity of NM M .
Our approach consists in two steps: first, bounding the inputs distributions and second, and then solving the problem with the new input distributions with size K. The second step (i.e. solving the completion time) has therefore a complexity equal to KM M .
Each upper bounding distribution is obtained with our algorithm which needs to build the associated graph and compute the bounds after K N 2 operations for the bounds and N 2 operations for the construction of the associated graph (see the following remark). We must compute the bound for M distributions which are, in general, all distinct. Therefore this first step has a complexity of N 2 M K operations and we obtain a bounding graph with M distributions with size K.

Remark 4.5 Computing the weights in the directed graph associated with a distri- bution of size N only requires O(N 2) operations. Indeed,


w	= φ(x

ui+1 −1
)

 xui+1 — xÆ
p

+ φ(x

ui+1 −1
)

p  xÆ — xui  —

ui+1 −1

φ(x )p

i,i+1
ui
Æ=ui +1
Æ xu

i+1
— xui
ui+1
Æ=ui +1
Æ xu

i+1
xui
Æ  Æ
Æ=ui +1

  φ(xui )   √
ui+1 −1
ui+1 −1
,	φ(xui+1 )
√uiΣ+1 −1
ui+1 −1 ,

=
xui+1
— xui
⎝xui+1

Æ=ui +1
pÆ —

Æ=ui +1
pÆxÆ, + x

ui+1
— xui
⎝Æ=ui +1
pÆxÆ — xui

Æ=ui +1
pÆ ,

ui+1 −1
—
Æ=ui +1
φ(xÆ)pÆ

=   φ(xui )  x	P
E	  +    φ(xui+1 )    E
x  P
p  — Φ


where
xui+1
xui
ui+1
ui,ui+1
ui,ui+1
xui+1
xui
ui,ui+1
ui  ui,ui+1 Æ
ui,ui+1

Φi,j =
j—1

l=i+1
φ(xl)pl,	Ei,j =
j—1

l=i+1
xlpl;	Pi,j =
j—1

l=i+1
pl.

These three variables are computed in an iterative way with a quadratic complexity (i.e. O(N 2)). From Φi,j, Ei,j, and Pi,j, we obtain wi,i+1 within O(1) operations. Therefore computing the graph requires O(N 2) operations.
Lower bound discrete distributions
For the lower bound, we do not have a result equivalent to Lemma 4.2 to obtain an optimal lower bound and we cannot obtain an optimal bound. Thus we propose the following heuristic to compute a lower bound for the convex order based on Lemma 3.5. To simplify the presentation we present the heuristic for a function φ associated with the second moment. Remember that the lower bound has a smaller variance than the initial distribution. Thus at each step of the heuristic, we replace two atoms by one new atom. And by construction we keep the same expectation and the second moment decreases. Let a and b two arbitrary atoms, and Δ the difference for the second moment.

Δ(a, b)= p a2 + p b2 − (p
+ p )( paa + pbb )2

a	b	a
b	pa + pb

After some cancellations, we get: Δ(a, b) = ( papb )(a − b)2. Thus, at each stage,
a	b
we search the couple of atoms a and b which minimizes this difference to keep the
second moment and the variance as high as possible. There is no proof of optimality for the whole process as the heuristic is myopic. The complexity is N 2 to prepare matrix Δ. We then have (N − K) fusions of atoms. The complexity of the fusion depends on the data-structure used to store Δ and to find the minimum and can be linear. Thus, the complexity of the heuristic is N 2.
Remark 5.1 One can modify the value of Δ to use any convex function φ and use the same heuristic. Δ is still the difference between the rewards:
paa + pbb
Δ(a, b)= p φ(a)+ p φ(b) − (p + p )φ(	).

a	b	a	b
pa + pb



Algorithm 1 Heuristic for a lower bound.
Input: input distribution D1, input size N , output size K
Output: Output distribution D2
1: D2 = D1.
2: for all atoms a do
3:	for all atoms b do
4:	Compute Δ(a, b) and store it in a data structure.
5:	end for
6: end for
7: for i = N down to K +1 do
8:	Search for the couple (a, b) which minimizes Δ(a, b).
9:	Make the fusion of a and b in D2. Let c be the atom created by the fusion.
10:	Update the matrix Δ(x, y) (remove the entries related to a and b, add the new entries related to c).
11: end for
Example
We consider the task graph decided in Fig. 1 associated with discrete distributions of the task durations to see how our algorithms perform. We have three generated instances for this graph. In the first instance, the processing time is a uniform distribution between 1 and 10. In the second (resp. third) instance, the processing time follows a Zipf’s distribution [1] with exponent equal to 1.4267 (resp. 2) having
{1,..., 10} as support. The random variables for the tasks are independent. We consider relatively small instances to be able to solve exactly the problem and compare the solutions with the upper bounds. Note that due to the size of the graphs and the number of atoms, the number of graph analysis is 108.
In Fig. 6, we have represented the distribution of the exact result for the com- pletion time of the task graph (on the left) and the upper bounding distribution for the convex order for distributions having only 5 atoms. The input distributions for the nodes are the Zipf distribution with an exponent equal to 1.4267.

Fig. 6. Distribution of the total delay for the execution of the task graph (left: exact result, right: upper bound with 5 atoms for the input distributions).

We depict in Fig. 7, the optimal bounds on 4 atoms and 3 atoms when the initial distribution is an uniform distribution on 7 atoms. The distributions show that it is

not possible to derive the optimal distribution on 3 atoms with only one action on one atom for the optimal distribution on 4 atoms. Thus a greedy approach will not work here. In Fig. 8, we report some examples for the lower bounds. Remember

Fig. 7. Input distributions (left: optimal bound with 4 atoms, right: optimal bounds with 3 atoms). The initial distribution is an Uniform with 7 atoms.

that this bound is not optimal and we do not characterize the support as me made for optimal upper bounding distribution. We evaluate the distribution computed

Fig. 8. Zipf with exponent 2 Input distributions (left) , lower bound with 5 atoms (right).

by the previous algorithm using the Kullback-Leibler divergence.
Definition 6.1 [Kullback-Leibler divergence] Let D1 and D2 two discrete proba- bility distributions, the KullbackLeibler divergence from D2 to D1 is defined as:



DKL
(P Q)=	P (i) log P (i) .
Q(i)
i


The divergence is a measure of how one probability distribution diverges from a second one. If the Kullback-Leibler divergence is equal to 0, then both distribu- tions are equal. In Figure 9, we draw this divergence from the bound to the exact distribution, versus the number of atoms we keep in the optimal upper bounding distribution. The similarity of the two distributions remains relevant when one half of the atoms are deleted.


	

Fig. 9. Kullback-Leibler divergence from the optimal upper bound to the exact distribution. For input distribution (left). For the task graph completion time (right).
Conclusion
Some questions are still open. The upper bound is optimal for any convex function
r. For the lower bound, we do not have proof of optimality and it is not clear that we can transform the minimization problem into a graph related algorithm such as the shortest path approach we use here like in [4]. But the theoretical results and the applications on the examples are promising and the approach proposes a bounding method for many practical optimization problems. Furthermore, replacing some measurements by their expectation in such an optimisation problem leads to systematic biais which must be understood. We have also proved such a relation for MaxFlow problem (in that case, we obtain an upper bound). We are also investigate how we can combine our approach and the various structure based approaches developed in the literature. The numerical methods will been implemented in a new version of XBorne [10], the software tool we develop to study stochastic bounds.
Acknowledgement
This work was partially supported by grant CNRS PEPS MASTODONS project ADOC 2017. The authors thank Y. Strozecki for many interesting remarks during this work.

References
L. A. Adamic and B. A. Huberman. Zipf’s law and the internet. Glottometrics, 3(1):143–150, 2002.
A. V. Aho, J. E. Hopcroft, and J. D. Ullman. Data Structures and Algorithms. Addison-Wesley, 1983.
F. A¨ıt-Salaht, H. Castel-Taleb, J. Fourneau, and N. Pekergin. Performance analysis of a queue by combining stochastic bounds, real traffic traces and histograms. Comput. J., 59(12):1817–1830, 2016.
F. At Salaht, J. Cohen, H. Castel Taleb, J. M. Fourneau, and N. Pekergin. Accuracy vs. complexity: the stochastic bound approach. In 11th International Workshop on Disrete Event Systems (WODES2012), number 8, 2012.
M. Ball, C. Colbourn, and J. Provan. Network reliability. Handbooks in Operation Research and Management Science, 7:673–762, 1995.
R. Bellman. On a routing problem. Quarterly of applied mathematics, 16(1):87–90, 1958.

A. Bobbio, A. Horvath, M. Scarpa, and M. Telek. Acyclic discrete phase type distributions: properties and a parameter estimation algorithm. Performance Evaluation, 54(1):1–32, 2003.
J. Elton and T. P. Hill. Fusions of a probability distribution. The Annals of Probability, 20(1):421–454, 1992.
L. R. Ford Jr. Network flow theory. Technical report, RAND CORP. SANTA MONICA CA, 1956.
J. Fourneau, Y. A. E. Mahjoub, F. Quessette, and D. Vekris. Xborne 2016: A brief introduction. In
T. Czachorski, E. Gelenbe, K. Grochla, and R. Lent, editors, Computer and Information Sciences - 31st International Symposium, ISCIS 2016, Krako´w, Poland, October 27-28, 2016, Proceedings, volume 659 of Communications in Computer and Information Science, pages 134–141. Springer, 2016.
J.-M. Fourneau and N. Pekergin. A numerical analysis of dynamical fault trees based on stochastic bounds. In 12th Int Conference on Quantitative Evaluation of Systems, QEST15. IEEE, 2015.
J.-M. Fourneau and N. Pekergin. Dynamic fault trees with rejuvenation: Numerical analysis and stochastic bounds. Electronic Notes in Theoretical Computer Science, 327:27 – 47, 2016. The 8th International Workshop on Practical Application of Stochastic Modeling, {PASM} 2016.
A. K. Gupta and M. A. S. Aziz.  Convex ordering of random variables and its applications in econometrics and actuarial science. EUROPEAN JOURNAL OF PURE AND APPLIED MATHEMATICS, 3(5):779–785, 2010.
K. Hutson and D. Shier. Bounding distributions for the weights of a minimum spanning tree in stochastic networks. Operation Research, 53(5):879–886, 2005.
A. Muller and D. Stoyan. Comparison Methods for Stochastic Models and Risks. Wiley, New York, NY, 2002.
M. Shaked and J. G. Shantikumar. Stochastic Orders and their Applications. Academic Press, San Diego, CA, 1994.
R. Szekli. Stochastic Ordering and Dependence in Applied Probability, volume 97. Springer Verlag, Lecture Notes in Statistics, 2012.
N. Yazici-Pekergin and J.-M. Vincent. Stochastic bounds on execution times of parallel programs.
IEEE Trans. Software Eng., 17(10):1005–1012, 1991.
