Electronic Notes in Theoretical Computer Science 82 No. 2 (2003)
URL: http://www.elsevier.nl/locate/entcs/volume82.html 17 pages


Classifying and Formally Verifying Integer Constant Folding

Sabine Glesner 1
Fakult¨at fu¨r Informatik Universit¨at Karlsruhe Karlsruhe, Germany

Jan Olaf Blech 2
Fakult¨at fu¨r Informatik Universit¨at Karlsruhe Karlsruhe, Germany



Abstract
Constant folding is a well-known optimization of compilers which evaluates con- stant expressions already at compile time. Constant folding is valid only if the results computed by the compiler are exactly the same as the results which would be computed at run-time by the target machine arithmetic. We classify different arithmetics by deriving a general condition under which a target-machine arithmetic can be replaced by a compiler arithmetic. Furthermore, we consider integer arith- metics as a special case. They can be described by residue class arithmetics. We show that these arithmetics form a lattice. Using the order relation in this lattice, we establish a necessary and sufficient criterion under which constant folding can be done in a residue class arithmetic that is different from the one of the target machine. Concerning formal verification, we have formalized our proofs in the Is- abelle/HOL system. As examples, we discuss the Java and C integer arithmetics and show which compiler arithmetics are valid for constant folding. This discussion reveals also potential sources of incorrect behavior of C compilers.


Keywords: integer and residue class arithmetic, constant folding, formal correctness, Isabelle/HOL formalization, Java and C integer arithmetic.

1 Email: glesner@ipd.info.uni-karlsruhe.de
2 Email: blech@ipd.info.uni-karlsruhe.de
◯c 2003 Published by Elsevier Science B. V. Open access under CC BY-NC-ND license.

Introduction

Most programming languages do not specify exactly how arithmetic compu- tations are performed. Instead they refer implicitly to the built-in arithmetic of the processor of the target machine. The advantage is better portability of source programs. Especially integer arithmetic is mostly used for counting tasks in small ranges which behave accurately as the ring Z of the integer numbers. The same source program may be translated into machine code for 16- as well as 32- or even 64-bit processors. This situation has implications on the optimizations allowed in a compiler. Constant folding is a well-known optimization in the intermediate representation of compilers which evaluates constant expressions already at compile time. Constant folding is valid only if the results computed by the compiler are exactly the same as the results which would be computed at run-time by the target machine arithmetic. In this pa- per, we classify integer and floating point arithmetics in a general framework. In particular, we state a sufficient criterion under which a target machine arithmetic may be replaced by a compiler arithmetic. Moreover, we describe sufficient and necessary conditions under which a given integer arithmetic may safely be replaced by some other integer arithmetic. These conditions are ef- ficiently decidable. We discuss the Java and C integer arithmetics and the implications on allowed compiler arithmetics with respect to our criterion of substitutability. Moreover, we present a formal proof of correctness for our criterion, stated in the Isabelle/HOL system.
As a rather amusing motivation for the importance of the compiler arith- metic consider the following presumably true story [Poo94]. In 1994, a major city bank in the UK wanted to find out which of their Pentium processors were afflicted with the Pentium bug. They compiled a test program and checked all their Pentium machines with it. Surprisingly, all of them had the bug. Just to double-check, they also tested their other machines and, even more surprisingly, discovered that they also showed the Pentium bug. After some confusion, they came up with this explanation. The compiler did constant folding, computing the expression intended to reveal the Pentium bug already at compile time. This compiling processor was a buggy Pentium which hard- wired the wrong result into the translated machine program. Hence, in turn, the mistake showed up in each run of the program, independently of the arith- metic of the executing processor. This story demonstrates that the arithmetic of the compiler is important and needs to behave exactly as the arithmetic of the target machine in order to guarantee that the optimized target program behaves exactly as the unoptimized target program would do.
With our results in this paper, we introduce a general framework for the substitutability relation between arithmetics. We specialize this general set- ting for integer arithmetics, yielding an efficiently decidable criterion for sub- stitutability between different integer arithmetics. In section 2, we recall some notations and results from universal and abstract algebra. In section 3, we

present our general framework for the substitutability relation among arith- metics. We consider integer arithmetics in section 4 and show that they can be arranged in a lattice. This lattice is isomorphic to the dual lattice of con- gruence relations of the ring Z of integer numbers. This classification gives us a necessary and sufficient criterion of substitutability between integer arith- metics, expressed by certain intuitive divisor properties. We discuss the integer arithmetics of Java and C in section 5 and show how they can be classified with our schema. This discussion reveals in particular the fundamental difference between Java and C arithmetics. In Java, the results of arithmetic expres- sions are determined by the Java semantics. In C programs, the results of arithmetic expressions are defined in terms of the target machine arithmetic. In section 6, we describe our Isabelle/HOL formalization. We discuss related work in section 7. In section 8, we conclude with aspects of future work.
Foundations
Ideally one may think of integer and floating-point arithmetics in programming languages as being equal to the ring Z of the integer numbers or to the field R of real numbers. Nevertheless, reality is different as nearly all arithmetics in programming languages are implemented by the available arithmetic oper- ations of the target processor. These operations are defined only for a finite number of possible input values and, hence, differ from Z or R. We describe these processor arithmetics as well as Z and R as universal algebras. This gen- eral setting allows us to view all of these arithmetics in a unified framework. In this section, we recall some standard notations and results from classical and universal algebra. For more details or proofs cf. [Lan79,Ihr88,BS00].
Universal Algebras
Definition 2.1 [Operations] For each n ∈ IN ∪ {0} and each nonempty set A, a mapping f : An −→ A is called n-ary operation on A. n is called the arity of f . The set of all n-ary operations on A is denoted by Opn(A).   ⬦
Definition 2.2 [Type of Algebras] A type of algebras is a set F of function symbols such that a nonnegative integer n ∈ IN ∪ {0} is assigned to each function symbol f ∈ F. n is the arity of f , f is an n-ary function symbol. ⬦
Definition 2.3 [Universal Algebra] A universal algebra A of type F is an ordered pair A = (A, F ) where A is a nonempty set and F = (fA | f ∈ F) is a family of operations of finite arity on A. Thereby an n-ary operation fA ∈ Opn(A) is assigned to each n-ary function symbol f ∈ F. A is called the universe of A = (A, F ). The elements in F are the fundamental operations of
A. If F = {f1,..., fk} is finite, we write (A, f1,..., fk) for (A, F ).	⬦
Throughout this paper, we write f instead of fA whenever this simplifica- tion is unambiguous.

Example 2.4 [Groups and Rings] Classical examples of algebras are groups and rings.	A group is an algebra G = (G, ·,−1 , 1) in which the following identities are true: (Abelian groups satisfy also commutativity: x · y = y · x.) x · (y · z)= (x · y) · z	(associativity)	e · x = x · e = x	(neutral element)
x · x−1 = x−1 · x = e (inverse elements)
A ring is an algebra (R, +, −, 0, ·) where + and · are binary operations, − is a unary and 0 is a nullary operation. A ring satisfies the following conditions: (R, +, −, 0) is an abelian group. · is an associative operation, and the two distributivity laws are fulfilled:
x · (y + z)= (x · y)+ (x · z)  and   (x + y) · z = (x · z)+ (y · z)   □
Given a set of variables V and a type of algebras F, the set of terms T (F ,V ) is defined inductively as usual: All variables v ∈ V are terms. If f is an n-ary function symbol and t1,..., tn are terms, then f (t1,..., tn) is a term.
Definition 2.5 Let F bea type of algebras and V be a set of variables. The term algebra T (V ) of type F over the set of variables V is the algebra T (V )= (T (F ,V ), F) such that for each f ∈ F, fT (V )(t1,..., tn)= f (t1,..., tn).   ⬦

Homomorphisms
Definition 2.6 [Homomorphism] Let A and B be two algebras of the same type F. A mapping α : A −→ B is called a homomorphism from A to B if α(fA(a1,..., an)) = fB(α(a1),..., α(an)). The kernel of α, ker(α), is defined by ker(α)= {(a, a') | a, a' ∈ A ∧ α(a)= α(a')}.	⬦
Theorem 2.7 (Concatenation) Let α : A −→ B and β : B −→ C be homomorphisms from A to B and from B to C. Then the concatenation of α and β, β ◦ α, with β ◦ α(a)= β(α(a)) for a ∈ A, is also a homomorphism.  ⬦
Example 2.8 [Modulo-Arithmetic Zn of Z] Consider the modulo-arithmetic Zn in Z, Zn = {0, 1,...,n − 1}. Addition is defined as follows: x +Zn y = (x +Z y)mod n. If x ∈ Zn, then −x = n −Z x. x −Zn y is an abbreviation for x +Zn (−Zny). Multiplication is defined analogously. (+Z and −Z denote addition and subtraction in Z, resp.) It is easy to verify that f : Z −→ Zn with f (x)= x mod n is a homomorphism from Z to Zn.	□

Congruence Relations and Quotient Algebras
Definition 2.9 A congruence relation θ on the algebra A = (A, F ) is an equivalence relation on A such that for all f ∈ F , if f n-ary and if (ti, t') ∈ θ, 1 ≤ i ≤ n, then (f (t1,..., tn),f (t' ,..., t' )) ∈ θ. The set of all congruence
1	n
classes is denoted by A/θ, the congruence class containing a by a/θ.	⬦
Theorem 2.10 Let α : A −→ B be a homomorphism from A to B. Then
ker(α) is a congruence relation on A.	⬦


Definition 2.11 [Quotient Algebras] Let A = (A, F ) be an algebra and θ be a congruence relation on A. The quotient algebra of A by θ, denoted A/θ, is the algebra whose universe is A/θ and whose fundamental operations satisfy: fA/θ(a1/θ,..., an/θ)= fA(a1,..., an)/θ.	⬦
Example 2.12 [Residue Classes of Z] The elements of Zn = {0, 1,...,n − 1}
can be viewed as standard representatives of the residue classes nZ+r,0 ≤ r ≤








standard
 representatives












n equivalence classes

Fig. 1. Residue Classes of Z

n−1, of Z, cf. figure 1. The residue classes are defined as follows (for arbitrary but fixed n ≥ 1 and all r with 0 ≤ r ≤ n−1): nZ+r = {x ∈ Z | x mod n = r}.
These residue classes are the congruence classes of the congruence relation θn on Z: xθny iff x mod n = y mod n. Clearly, θn is an equivalence relation on Z because it is reflexive, symmetric, and transitive. Moreover, it is a congruence relation because it is closed under the operations +Zn , −Zn , and
·Zn . Hence, we conclude that Z/θn = Zn is an algebra with well-defined operations as specified in definition 2.11. One can show that Zn is a ring (by Birkhoff’s theorem about equational classes being varieties and vice versa).
Ideals J of rings (R, +, −, 0, ·) are subsets of R. In commutative rings, they are defined by three properties: 0 ∈ J ; x, y ∈ J ⇒ x + y ∈ J ; and x ∈ J, a ∈ R ⇒ a · x ∈ J . Each ideal is the kernel of a homomorphism, and, vice versa, each kernel of a homomorphism is an ideal. Furthermore, in Z, the ideals are exactly the congruence classes nZ for n ∈ N+.	□
An important result from universal algebra states that the congruence relations of an algebra are a lattice (cf. [BS00]). We use this result when classifying integer arithmetics in section 4.
Theorem 2.13 Let A be an algebra and let Con A be the set of all congruence relations of A. The congruence lattice of A, denoted by Con A, is the lattice whose universe is Con A and meets and joins are calculated as follows:
θ1 ∧ θ2 = θ1 ∩ θ2

θ1 ∨ θ2 = θ1 ∪ (θ1 ◦ θ2) ∪ (θ1 ◦ θ2 ◦ θ1) ∪ (θ1 ◦ θ2 ◦ θ1 ◦ θ2) ∪· · · or, equivalently, (a, b) ∈ θ1 ∨ θ2 iff there is a sequence of elements a = c1, c2,..., cn = b such that (ci, ci+1) ∈ θ1 or (ci, ci+1) ∈ θ2 for 1 ≤ i ≤ n − 1.	⬦
General Classification of Arithmetics
At first sight, one might think that the integer and floating point arithmetics in programming languages are rings and fields, resp. For the modulo-arithmetic on integer numbers, this is true. But already for saturating integer arithmetic, we do not have arithmetic on rings any more. Analogously, floating-point arithmetic behaves like the arithmetic in a field only as long as no rounding errors or overflows occur. In this section, we define the notion of arithmetics and derive the notion of substitutability between algebras. Furthermore, we define substitutability with respect to one specific constant expression.
Definition 3.1 [Arithmetic] An arithmetic is an algebra A of type F such that the following function symbols are included in F: +, −, ·, 0. + and · are binary function symbols, − is a unary and 0 is a nullary function symbol.  ⬦
This definition captures the classical arithmetics like Z and R as well as Zn, saturating integer or floating point arithmetics implemented in micropro- cessors. We do not require any properties of the fundamental operations of the algebra as e.g. 0 · x = 0. Any algebra of the right type is accepted as arithmetic. We need to be able to compare arithmetics. Therefore we define a relation “more precise” which holds for two algebras A and B, denoted by A ≥ B, if A can be used instead of B to compute a constant expression. With Type(A), we denote the function symbols which are interpreted by the funda- mental operations of the algebra A. If Op ⊆ Type(A), then we denote with A |Op the following algebra (A, {fA | f ∈ Type(A) ∩ Op}) which has only a subset of the fundamental operations of A, those contained in Op.
Definition 3.2 [More Precise ≥] An algebra A = (A, FA) is more precise
than an algebra B = (B, FB), denoted by A ≥ B, iff
Type(B) ⊆ Type(A) and if
there exists a surjective homomorphism f : A|Op(B)→ B.	⬦
If A ≥ B, then A can be used instead of B to evaluate constant expressions. To formalize this, we need a formal definition of constant expressions of an algebra A = (A, F ). We define them as the term algebra of the same type over the set of “variables” A as T (A) = (T (Type(A), A), Type(A)). If f : A −→ B is a function defined on A, then we can lift this function to f : T (A) −→ T (B) by mapping each a ∈ A to f (a) and each term gA(t1,..., tn) to gB(f (t1),...,f (tn)). Furthermore, we need an evaluation function eval A which assigns each term t ∈ T (Type(A), A) an element of A. eval A : T (A) −→ A is defined inductively as follows: If t = a for some a ∈ A, then eval A(a)= a. If t = h(t1,..., tn), then eval A(t)= hA(eval A(t1),..., eval A(tn)).

Theorem 3.3 (Substitutability) Let A = (A, FA), B = (B, FB) be alge- bras, A ≥ B. Let f : A |Op(B)→ B be the corresp. homomorphism from A |Op(B) to B. Then there exists a function f−1 : T (Type(B), B) → T (Type(B), A) with f (eval A(f−1(t))) = eval B(t) for all t ∈ T (Type(B), B).	⬦
Proof. First we define a function f−1 : B −→ A |Op(B) which can be lifted to f−1 : T (Type(B), B) −→ T (Type(B), A). Then we show that f−1 has the desired properties. Define fˆ−1 : B −→ A such that fˆ−1(b) = {a | f (a) = b}. Because f is surjective (cf. definition 3.2), fˆ−1 /= ∅ for all b ∈ B. Let f−1(b) ∈ fˆ−1(b) (arbitrary but fixed). Then f (f−1(b)) = b holds independently of the choice of f−1(b) ∈ fˆ−1(b) (follows directly from the definition of fˆ−1).
Let t ∈ T (Type(B), B). We show that f (eval A(f−1(t))) = eval B(t) for all
t ∈ T (Type(B), B) by induction on the term structure of t.
Base Case: t = b for some b ∈ B. f (evalA(f−1(b))) = f (evalA(a')) = f (a')= 
f (f−1(b)) = b (with a' = f−1(b)).
Induction Case: f (evalA(f−1(h(t1,..., tn)))) =
= f (evalA(h(f−1(t1),...,f−1(tn))))	(lift f−1 to terms)
= f (h(evalA(f−1(t1)),..., evalA(f−1(tn))))	(definition of evalA)
= h(f (evalA(f−1(t1))),...,f (evalA(f−1(tn))))	(f is a homomorphism)
= h(evalB(t1),..., evalB(tn))	(induction assumption)
= evalB(h(t1,..., tn))	(definition of evalB) ✷
Theorem 3.3 states directly that whenever A ≥ B, we can evaluate con- stant expressions in A instead of in B because we have transfer functions between A and B. Definition 3.2 and theorem 3.3 capture the general case of substitutability between arithmetics in programming languages and target processors. They model not only the mathematical arithmetics Z and R but also the standard modulo-integer arithmetics as well as saturating arithmetics and floating-point arithmetics. Concerning constant folding, also rare cases are caught: Consider e.g. a compiler which evaluates constant integer expres- sions with a floating-point arithmetic. If we can state the transfer functions f and f−1, we can use the floating-point arithmetic to evaluate the integer expressions. In practice, one often faces the situation that a constant inte- ger expression is to be evaluated within one target modulo-arithmetic but the compiler has only a different modulo-arithmetic. Theorem 3.3 defines the proof obligations to be verified. Sometimes it is not important to ensure sub- stitutability between two arithmetics for arbitrary expressions but only for one specific constant term. This case is described in the following definition:
Definition 3.4 Let A = (A, FA) and B = (B, FB) be algebras such that Type(B) ⊆ Type(A). Let t ∈ T (Type(B), B). A is more precise than B with respect to t, denoted by A ≥t B, if there exists transfer functions f : A −→ B and f−1 : B −→ A such that f (eval A(f−1(t))) = eval B(t).	⬦
If algebra A is more precise than algebra B wrt. a constant term t, then we can evaluate t in A instead of in B with the transfer functions f and f−1.

Lattices of Integer Arithmetics
In this section, we concentrate on residue class arithmetics, i.e. modulo- arithmetics in Zn, n ∈ N+. These arithmetics are contained in programming languages typically in two variants, as signed and unsigned integers. Unsigned integers correspond directly with the set Zn = {0, 1,...n − 1}. The arithmeti- cal operations on unsigned integers are defined exactly as on Zn. Signed inte- gers represent numbers within the range of {−n/2,..., −1, 0, 1,..., (n/2)−1}, assuming that n is even, otherwise in the range {−(n − 1)/2,..., −1, 0, 1,..., (n − 1)/2}. If binarily coded in the two’s complement representation, numbers starting with a ‘1’ represent negative integers, those starting with ‘0’ represent nonnegative integers.
We can treat both variants, signed and unsigned arithmetics, in a uniform way. Therefore we regard the numbers {0, 1,...,n − 1} as standard represen- tatives of the congruence classes nZ + r of Z, 0 ≤ r ≤ n − 1. Furthermore, we observe that the numbers {−n/2,..., −1, 0, 1,..., (n/2) − 1} 3 denote the same congruence classes whereby nZ + r for r ∈ {(n/2),...,n − 1} is not represented by its standard representative r but by the representative r − n, cf. also figure 1. Each modulo-arithmetic Zn, n ∈ N+, is an arithmetic:
Theorem 4.1 Each modulo-arithmetic Zn of Z, n ∈ N+, is an arithmetic of type F = {+, −, ·, 0}.	⬦
Proof. Follows directly from definition 3.1.	✷
Theorem 4.2 (Substitutability of Residue Class Arithmetics) Let m, n ∈ N+. If n divides m, then Zm is more precise than Zn, Zm ≥ Zn.	⬦
Proof. We need to show that the two requirements of definition 3.2 are ful- filled. The first, Type(Zn) ⊆ Type(Zm), holds trivially.
To verifiy the second requirement, we define a function f : Zm −→ Zn and show that it is a surjective homomorphism. Let m = p ·Z n (p exists because n divides m). Each x ∈ {0,...,m − 1} can be expressed as x = r +Z l ·Z n for some l ∈ {0,...,p − 1} and 0 ≤ r ≤ n − 1. Define f (x) = r. Clearly, f is surjective because for x ∈ {0,...,n − 1}, f (x) = x holds trivially. Hence, each element in Zn is the image of at least one element in Zm. To verify that f is a homomorphism, we need to prove the following four equations:
f (0Zm )= 0Zn	3. f (−Zm x)= −Znf (x)
f (x +Zm y)= f (x) +Zn f (y)  4. f (x ·Zm y)= f (x) ·Zn f (y)
The first equation holds trivially, the remaining equations are proven below. Thereby we assume that x = r +Z l·Z n and y = r'+Z l'·Z n with 0 ≤ r, r' ≤ n−1 and l, l' ∈ {0,...,p − 1}.
Proof of f (x +Zm y)= f (x) +Zn f (y):

f (x +Zm
y) = f ((r +Z l ·Z n) +Zm
(r' +Z l' ·Z n)) =



3 For simplicity of notation, we only show the case for n being even.



= f ((r +Zm
l ·Zm
n) +Zm
(r' +Z
l' ·Z
n))	(because 0 ≤ x, y < m)

= f (r +Z  r' +Z  l ·Z  n +Z  l' ·Z  n)
	m	m	m	m	m	

=  r +Zm r	if r +Z  r ≤ n − 1 
'	'

= r +Zn
r' = f (x) +Z
f (y).

 r +Zm r −Z  n otherwise	
'
Proof of f (−Zm x)= −Znf (x):	f (−Zm x)= f (m −Z x)= 
f (m −Z (r +Z l ·Z n)) = f (m −Z (l ·Z n) −Z r)= f (m −Z r)= 
= f (p ·Z n −Z r)= f ((p −Z 1) ·Z n +Z n −Z r)= n −Z r = −Znr = −Znf (x).
Proof of f (x ·Zm y)= f (x) ·Zn f (y):

On one hand, we have f (x) ·Zn
f (y)= r ·Zn
r' = (r ·Z r')mod n. On the other

hand, we have f (x ·Zm
y) = f ((r +Z l ·Z n) ·Zm
(r' +Z l' ·Z n)) = f (r ·Z
r').

'	''	'	''	''	''	'
r ·Zm r = r  with r ·Z r = l ·Z m+Z r  and 0 ≤ r  ≤ m−1, and (r ·Z r )mod n =
r''' with r ·Z r' = l''' ·Z n +Z r''' and 0 ≤ r''' ≤ n − 1. Because n divides m, there exists q such that q ·Z l'' = l''' and r''mod n = r''' which completes the proof.✷
Theorem 4.3 Z is more precise than each Zn with n ∈ N+, Z ≥ Zn.
Proof. Follows directly from the facts about residue classes in Z stated in examples 2.8 and 2.12.	✷
Theorem 4.4 (Lattice of Integer Arithmetics) The residue class arith- metics Zn, n ∈ N+, and Z with the partial ordering ≥ form a lattice Int Arith = ({Z}∪ {Zn | n ∈ N+}, ≥).	⬦
Proof. We define inf(Zn, Z)= Zn and sup(Zn, Z)= Z according to the state- ment of theorem 4.3 above. Moreover, we need to show that for any two arithmetics Zn and Zm, inf(Zn, Zm) and sup(Zn, Zm) exist. Therefore we prove the following whereby “gcd” stands for greatest common divisor and “lcm” for least common multiple.
inf(Zn, Zm)= Zgcd(n, m)  and  sup(Zn, Zm)= Zlcm(n, m)
We only prove the case for inf(Zn, Zm) because the case for the supremum is analogous. Clearly, Zn ≥ Zgcd(n, m) and Zm ≥ Zgcd(n, m). Moreover, there exists no other Zk with k > gcd(m, n) such that Zn ≥ Zk and Zm ≥ Zk because then k cannot divide n and m.	✷
The top element of the lattice Int Arith is Z, the bottom element is Z1. The lattice Int Arith is a complete lattice because for every subset A of {Z}∪{Zn | n ∈ N+}, Inf(A) and Sup(A) exist. The next theorem states the connection of Int Arith with the lattice of congruence relations on Z, Con Z. This theorem follows from the fact that the residue classes nZ for n ∈ N+ are exactly the ideals on Z, as explained in example 2.12. Each ideal defines a congruence relation θn whose congruence classes are nZ + r, 0 ≤ r ≤ n − 1, cf. figure 1, with nZ + r = {x | x mod n = r}. Vice versa, each congruence relation on Z defines an ideal which is the congruence class containing 0.
Theorem 4.5 The lattice Int Arith is isomorphic to the dual of the lattice
Con Z of congruence relations on Z.

Proof. Let θn = {(x, y) | x mod n = y mod n}. We define the function f : Int Arith −→ Con Z with f (Zn)= θn and f (Z)= {(z, z) | z ∈ Z} =: θ∞ (i.e. the congruence relation where only identical integers are equivalent) and the function f−1 : Con Z −→ Int Arith with f−1(θn)= Zn and f−1(θ∞)= Z. Clearly, f and f−1 are surjective functions and f−1 is the inverse function of
f . We need to show that f is an isomorphism, i.e., Zm ≥ Zn iff θm ⊆ θn.
“⇒”: Assume Zm ≥ Zn and show θm ⊆ θn:
Assume Zm ≥ Zn. Then there is a surjective homomorphism f : Zm −→ Zn. Furthermore, the surjective homomorphisms g : Z −→ Zm and h : Z −→ Zn exist because Z ≥ Zn and Z ≥ Zm. h = f ◦g holds. Moreover, ker(g)= θm and ker(h)= θn. Assume that (x, y) ∈ θm = ker(g) exists but (x, y) /∈ θn = ker(h). This is a contradiction because all elements which are mapped to the same image by g must also be mapped to the same image by f ◦ g = h. Hence, θm ⊆ θn must hold.
“⇐”: Assume θm ⊆ θn and show Zm ≥ Zn:
Assume that θm ⊆ θn. To show that Zm ≥ Zn holds we prove that n divides
m. To prove this, we assume the contrary, n does not divide m, and show that this results in a contradiction: (m, 0) ∈ θm but (m, 0) /∈ θn because n does not divide m. But this is a contradiction to the assumption that θm ⊆ θn. Hence, we conclude that n divides m and that Zm ≥ Zn.	✷
From theorem 4.5, it follows directly that the condition stated in theorem
4.2 is not only a sufficient but also a necessary criterion:
Corollary 4.6 Let m, n ∈ N+. n divides m iff Zm ≥ Zn.	⬦
One might wonder why we did not include the integer operations “mod” and “div” which are available in many programming languages into the type of modulo arithmetics when stating theorem 4.1. The following counterexample shows that under this assumption, we would not be able to prove a criterion for substitutability similar to that in corollary 4.6: (4 +Z8 5) modZ8 7=1 but (4 +Z16 5) modZ16 7 = 2, and (4 +Z8 5) divZ8 2 = 0 but (4 +Z16 5) divZ16 2= 4.
Corollary 4.6 gives us an efficiently decidable criterion for the substitutabil-
ity of an integer arithmetic in a target processor by the integer arithmetic in a compiler. Constant expressions of the integer arithmetic Zn can be evaluated in the integer arithmetic Zm iff n divides m. In modern processor architec- tures, n and m are always a power of 2. For them, this criterion states that constant expressions can be evaluated if the representation of numbers in the compiler arithmetic is equal or larger than the representation of numbers in the target processor and if both compute values according to the modulo- arithmetic (which is not as clear as it may seem, cf. our discussion in the next section). In the following section, we discuss the C and Java integer arith- metics and show how this criterion can be applied to classify valid constant folding optimizations in their compilers. These considerations also reveal that the C language standard [ISO99] contains some dangerous definitions concern- ing integer arithmetic.


	
Fig. 2. Java and C Integer Data Types

Integer Arithmetics in Java and C
The Java language specification defines exactly how integer numbers are rep- resented and how integer arithmetic expressions are to be evaluated. This is an important property of Java as this programming language has been de- signed to be used in distributed applications on the Internet. A Java program is required to produce the same result independently of the target machine executing it. In contrast, C (and the majority of widely-used imperative and object-oriented programming languages) is more sloppy and leaves many im- portant characteristics open. The intention behind this inaccurate language specification is clear. The same C programs are supposed to run on a 16-bit, 32-bit, or even 64-bit architecture by instantiating the integer arithmetics of the source programs with the arithmetic operations built-in in the target pro- cessor. This leads to much more efficient code because it can use the available machine operations directly. As long as the integer computations deal only with numbers being “sufficiently small”, no inconsistencies will arise. In this sense, the C integer arithmetic is a placeholder which is not defined exactly by the programming language specification but is only completely instanti- ated by determining the target machine. In this section, we discuss both C and Java integer arithmetics. Thereby we show that the C integer arithmetic bears potential sources of incorrect arithmetic behavior.
Java precisely defines how integers are represented and how integer arith- metic is to be computed. The values of all signed integers are two’s com- plement representations of the length as listed in figure 2. Char is the only unsigned integer type. Its values represent Unicode characters, from ‘\u0000’ to ‘\uffff’, i.e. from 0 to 216 − 1. If an integer operator has an operand of type long, then the other operand is also converted to type long. Otherwise the op- eration is performed on operands of type int, if necessary shorter operands are converted into int. The conversion rules are exactly specified, cf. [ESGB00].
The exact specification of Java integer arithmetic determines exactly the values of constant integer expressions which are computed by the compiled

programs, independently of the target machine executing them. They are computed within the arithmetic Z64 if it is an operation on long integers, otherwise in Z32. Recall that two’s complement in Z2n is only the choice of non-standard representatives for the congruence classes nZ + r for r ≥ 2n−1, cf. our explanation at the beginning of section 4. From corollary 4.6, it follows that we can evaluate constant integer expressions in Java programs already at compile time iff one of the following two conditions holds:
The expression is to be evaluated in Z64 and the compiler uses an arith- metic Zn·64, n ∈ N+, or
the expression is to be evaluated in Z32 and the compiler uses an arith- metic Zn·32, n ∈ N+.
The C language specification [ISO99] does not define integer values and integer arithmetic as exactly as the Java specification. We do not give all details here but discuss only the most important characteristics and their im- plications on compiler arithmetics. C has two kinds of integer values, signed and unsigned ones, cf. figure 2. The C language specification defines a header file <limits.h> which determines the minimum and maximum values repre- sentable in the respective integer type. A given compiler is supposed to provide this file such that its specific ranges of integer values contains the ranges deter- mined in the C specification. The C specification requires that for each signed integer type, there is a corresponding but different unsigned integer type of the same size. Values of type integer have the “natural sizes suggested by the ar- chitecture of the execution environment (large enough to contain any value in the range Int Min to Int Max as defined in the header <limits.h>)” (cf. 6.2.5 of [ISO99]). Unsigned integers represent values in the range of 0,..., 2N − 1 where N is the length of representation. The header file <limits.h> deter- mines the minimum range of unsigned integers as 0,..., 2N − 1, where N is 8 for char, 16 for short and int, 32 for long int, and 64 for long long int. For signed integers, the ranges −(2N−1 − 1),..., 2N−1 − 1 are specified, N defined as for unsigned integers. E.g. the GNU C compiler [Pro02] redefines the ranges as −2N−1,..., 2N−1 − 1 according to Z2N , with N = 32 for int.
These definitions in the C specification, especially those in <limits.h>, bear two potential sources of unexpected behavior if constant folding is per- formed. The first concerns the incomplete specification of the target arith- metic. If the target architecture adheres exactly to the ranges in <limits.h>, then arithmetic is not computed according to Z2N because the element −2N−1 does not exist. It remains unclear whether the C specification intended to require a Z2N −1 or a Z2N arithmetic. Hence, the compiler arithmetic cannot evaluate arbitrary integer expressions at compile time. Only those can be computed for which the requirements stated in definition 3.4 can be verified. For example, if the integers in the constant expression are very small such that the distinction between Z2N −1 and Z2N does not matter, then the expression can be evaluated. The second source of incorrectness of constant folding arises

from the fact that the integer ranges can be extended arbitrarily by the target machine. E.g. it would be conform with the C specification to extend the ranges such that much more negative than positive numbers are contained. While this or similar extensions still fit into the residue class setting (we can choose the representatives of the equivalence classes arbitrarily), it might be- come a practical problem: The binary representation of integers would not have the well-known interpretation any more that numbers starting with a ‘1’ are negative and all others are non-negative. Compiler programmers might not expect non-standard interpretations of the integers. Hence, these allowed unsual interpretations are a potential source of errors.

Formalization in Isabelle/HOL
We have formalized our main result concerning substitutability of integer arithmetics within the Isabelle/HOL [NPW02] system. Isabelle is a generic theorem prover. It can be instantiated with different logics, whereas Is- abelle/HOL, simply typed higher order logic, is the one most widely used. Our main result is stated in theorem 4.2 and says that Zm is more precise than Zn if n divides m. If one wants to formally verify a compiler doing in- teger constant folding, then our Isabelle proof can become part of this overall correctness proof. Our Isabelle proof is generic as it does not instantiate the numbers n and m. In this section, we explain the main data structures and proof steps of our Isabelle formalization. An Isabelle proof document con- tains data type definitions, function and constant definitions and lemmata. A lemma can be verified by applying certain proof techniques as e.g. induction, case distinction, or the application of already verified lemmata.
We have modelled constant expressions as trees:
datatype Etree = Leaf int | Node operator Etree Etree datatype operator = Add | Sub | M ult
We have defined functions which evaluate constant expression trees. The function calc evaluates trees within the ring Z of the integer numbers. calcm evaluates in the arithmetic of Zm and calcmn in Zm·n. We give here only the definitions for calc and calcm. calcmn is analogously defined.

Our first lemma states that results of operations in Z mod m are the same as taking the operands mod m and then computing the result in Zm.
lemma ''(calc a)mod m = (calcm a (m :: int))''
The lemma can be verified by induction on a, ''apply (induct tac a)''. Isabelle creates these proof obligations:
1.	int. calc (Leaf int)mod m = calcm (Leaf int)
[|calc Etree1 mod m = calcm Etree1 m; calc Etree2 mod m = calcm Etree2 m|]
calc (Node operator Etree1 Etree2)mod m =
calcm (Node operator Etree1 Etree2) m
The base case of the induction can be verified directly using the definitions of calc and calcm. Isabelle does this step automatically by using the tactic ''apply auto''. The remaining proof obligations can be verified by a case distinction over the possible operators. First we pick the Add-operator and start a case distinction, ''apply (case tac ''operator = Add'')''. Isabelle produces this result (we omit the other case ''operator /= Add'' for space reasons):
Etree1 Etree2.
[|calc Etree1 mod m = calcm Etree1 m; calc Etree2 mod m = calcm Etree2 m|]
=⇒ (calc Etree1+ calc Etree2)mod m = (calcm Etree1 m + calcm Etree2 m)mod m
The following lemma (available in Isabelle) is used in the next proof step:
lemma ''(a + b)mod m = (a mod m + b mod m)mod (m :: int)''
Isabelle can completely prove this remaining proof obligation automatically. The two other cases are slightly more complicated because lemmata as the one used above need to be proved before. We have also verified that calcm can be replaced by calcmn.

Related Work
Correctness of compilers has been investigated in many research projects. Nev- ertheless, as to the authors’ knowledge, there has been no research investigat- ing and classifying different arithmetics with respect to their substitutability (except for the general requirement that the translated programs must show the same behavior as the source programs). A very early research considering correctness of compiling arithmetics is [MP67] which verifies the translation of arithmetic expressions into machine code, but without paying attention to the fact that the source and target arithmetic may be different.
The german Verifix project [GZ99] has the goal of constructing correct compilers. This project has achieved progress by establishing the claim that it is possible to build provably correct compilers within the standard frame- work of compiler construction. In [Nec00], it is shown how some backend optimizations of the GCC can be validated. Proof-carrying code [NL98] is

another weaker approach to the construction of correct compilers which guar- antees that the generated code fulfills certain necessary correctness conditions. Pnueli [PSS98,ZPL01] also addresses the problem of constructing correct com- pilers. [GGB02] investigates verification of compiler optimizations specific for embedded processors. None of these works addresses the problem of dealing with different arithmetics in programming languages and their compilers. In particular, none of these works establishes a general substitutability criterion between different arithmetics.



Conclusions
In this paper, we have stated a general sufficient criterion for substitutabil- ity of arithmetics. Therefore we defined arithmetics as universal algebras of certain types. Our substitutability criterion defines an order relation on the arithmetics. Concerning integer arithmetics, we have shown that the residue class arithmetics form a lattice which is isomorphic to the dual lattice of the congruence relations of Z. This characterization has given us a sufficient and necessary criterion for substitutability. We discussed and compared the integer arithmetics of Java and C. Their characteristics display the different intentions and purposes for using Java or C as implementation language. Java is designed for distributed applications on the internet. Java program behavior must be uniquely determined independently of the executing machine. In contrast, C is often used for system implementations close to the machine code level. These C programs must be as efficient as possible and therefore use the avail- able machine arithmetic. Hence, in C, the arithmetic operations are not fully specified and serve as a placeholder for various machine arithmetics. We have argued that this incomplete specification of C integer arithmetic is a potential source of incorrect compiler behavior. Nevertheless, our results state a simple criterion for substitutability and may help in reducing compiler mistakes. We have formalized our criterion for substitutability of integer arithmetics in the Isabelle/HOL system, an interactive higher-order theorem prover. This proof is generic as it does not specify the absolute sizes of the involved integer arith- metics. This formal proof may become part of a formal proof of correctness of a compiler performing constant folding.
In future work, we want to investigate further arithmetics as e.g. saturating integer arithmetic. Saturating arithmetic is not a ring any more but still an arithmetic in the sense of our formalization. We also want to consider floating- point arithmetics. It is an open question if there are different floating-point arithmetics being in the substitutability relation. Most probably we need to widen our definition of substitutability and parameterize it with the relative size of rounding errors to classify floating-point arithmetics adequately.

References
[BS00] Stanley Burris and H.P. Sankappanavar. A Course in Universal Algebra, 2000. Millenium Edition. Originally published by Springer in 1981.
[ESGB00] Bill Joy (Editor), Guy Steele, James Gosling, and Gilad Bracha. The Java Language Speciﬁcation, Second Edition. Addison-Wesley, 2000.
[GGB02] Sabine Glesner, Rubino Geiß, and Boris Boesler. Verified Code Generation for Embedded Systems. In Proc. COCV-Workshop, 2002. Electronic Notes in Theoretical Computer Science (ENTCS), Vol. 65.2.
[GZ99] Gerhard Goos and Wolf Zimmermann.  Verification of Compilers.  In
Correct System Design. Springer-Verlag, LNCS 1710, 1999. [Ihr88] Thomas Ihringer. Allgemeine Algebra. Teubner, 1988.
[ISO99] ISO/IEC. Int’l Standard ISO/IEC 9899:1999, Programming languages –
C. Ref. no. ISO/IEC 9899:1999(E), 1999. 2nd edition 1999-12-01.
[Lan79] S. Lang. Algebraische Strukturen. Vandenhoeck und Ruprecht, 1979. [MP67] John McCarthy and J. Painter. Correctness of a compiler for arithmetic
expressions. In Mathematical Aspects of Computer Science, Proc. Symp. in Appl. Math., Am. Math. Soc., 1967.
[Nec00] George C. Necula. Translation Validation for an Optimizing Compiler.
In Proceedings PLDI’00, 2000.
[NL98] George C. Necula and Peter Lee. The Design and Implementation of a Certifying Compiler. In Proc. PLDI’98, 1998.
[NPW02] T. Nipkow, L. C. Paulson, and M. Wenzel. Isabelle/HOL: A Proof Assistant for Higher-Order Logic. Springer, LNCS 2283, 2002.
[Poo94] Martin Poole.  Problems with compiler optimisation (Pentium related).  Forum on Risks to the Public in Computers and Related Systems, Volume 16: Issue 63, 1994. available at http://catless.ncl.ac.uk/Risks/16.63.html#subj8.
[Pro02] GNU Project. GCC Home Page. http://gcc.gnu.org/, 2002. Version gcc version 2.96 20000731 (Red Hat Linux 7.1 2.96-98).
[PSS98] A. Pnueli, O. Shtrichman, and M. Siegel. The code validation tool (cvt.).
Int’l Journal Software Tools for Technology Transfer, 2(2):192–201, 1998.
[ZPL01] L. Zuck, A. Pnueli, and R. Leviathan. Validation of Optimizing Compilers. Technical Report MCS01-12, Faculty of Mathematics and Computer Science, The Weizmann Institute of Science, August 2001.
