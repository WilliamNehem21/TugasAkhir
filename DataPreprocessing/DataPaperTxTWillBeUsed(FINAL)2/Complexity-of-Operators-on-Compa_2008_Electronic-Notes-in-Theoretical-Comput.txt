	Electronic Notes in Theoretical Computer Science 202 (2008) 101–119	
www.elsevier.com/locate/entcs
Complexity of Operators on Compact Sets
Xishun Zhao1,2,4
Institute of Logic and Cognition, Sun Yat-Sen University 510275 Guangzhou, P. R. China
Norbert Mu¨ller1,3,5
FB IV, Abteilung Informatik, Universita¨t Trier, D-54286 Trier, Germany

Abstract
Based on oracle Turing machines, we investigate the computational complexity of operators on compact sets. For the projection and convex hull we are able to show exponential upper and lower bounds as well as a connection to the P=NP problem for special settings.
Keywords: Oracle Turing machines, compact sets, operator complexity, projection, convex hull


Introduction
The computability of compact sets and of operators on compact sets has already been studied in the literature, cf. [13,15,16], also the complexity of some compact sets like Julia sets was analyzed in [2,12]. However, the complexity of operators on compact sets is less explored.
To define computability and complexity of operators on compact sets, essen- tially two versions of Turing machines can be used: Type-2 Turing machines (cf. [13]) or oracle Turing machines (cf. [8]). From the viewpoint of computability, the approaches are equivalent. From the viewpoint of complexity theory on the
real numbers, at least the notion of polynomial time complexity is invariant to the

1 The authors would like to thank Professor Klaus Weihrauch for his useful comments and suggestions to write this paper, and the anonymous referees for many valuable hints and corrections.
2 Email: hsszxs@mail.sysu.edu.cn
3 Email: mueller@uni-trier.de
4 Research was partially supported by the NSFC projects under Grant No. 60573011, 10410638 and a MOE project under grant number 05JJD72040122
5 Research was partially supported by the DFG project 446 CHV 113/240/0-1

1571-0661 © 2008 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2008.03.011

machine model. This changes, if we look at operators on the compact sets or on continuous functions (like differentiation or integration): A computation with a Type-2 machine up to a precision n involves that a full approximation with this precision has to be written onto the output tape (or has to be read from the input tape). For compact sets or continuous functions, such approximations already have exponential size, so studying polynomial time complexity is useless in that setting. Oracle Turing machines on the other hand have a direct, non-sequential access to their oracles, they might also just write ‘partial information’ about the output, so we can get interesting results here.
The paper is organized as follows: Using oracle Turing machines, we show that several basic operators like scaling or rotation have a polynomial time complexity. Then we concentrate on a less trivial example, the projection of two-dimensional sets onto one of the coordinates. Here exponential upper and lower bounds hold, additionally we are able to prove a connection to the P=NP question. Similar exponential lower bounds for operators were studied extensively by Traub’s school of Information-Based Complexity [10,11]. The embedding of problems of discrete complexity theory like P=NP into a real-valued context can already be found e.g. in [6,9].
On the other hand, for convex compact sets we present an algorithm working in polynomial time. It is not clear whether this result can already be derived from polynomial time algorithms for linear programming, as in our setting the compact sets can even have an empty interior.
In the last section of the paper we consider the question of computing the convex hull of a compact set. Here in general, the complexity of the operator is again exponential, and we are able to find a connection to the P=NP question even for compact sets that additionally are regular and simply connected. The proof of this connection is influenced by a simular construction in [6], where, among others, the question of finding the maximum value of a real function was considered.
Questions of the complexity of two-dimensional real sets have also been consid- ered e.g. in [4,5]. The equivalence of the underlying computational model to the definitions in [13] has been addressed in [3], the exact relation of computational complexity in the two settings still has to be considered.
Computability and complexity
We start with the basic definitions based on (or cited from) [13]. Results on com- putability using Type-2 machines can also be found in [13], but we will formulate our own results for oracle machines instead.
Definition 2.1
For k ∈ N let K(k) be the set of the non-empty compact subsets of Rk.
D :=  n∈N Dn denotes the dyadic numbers, Dn := {m · 2−n | m ∈ Z}.

For d = (d1,..., dk) ∈ Rk let Un(d) = {(x1,..., xk) | |di − xi| ≤ 2−n} be the
k-dimensional hypercube with center d and edge length 21−n.

We use a representation of arbitrary non-empty compact sets of real vectors based on definitions 5.2.1.3 and 7.4.1. of [13]:
Definition 2.2 A grid name ψ of a set K ∈ K(k) is a pair ψ = (h, b) with the following properties:
The first component h is a total function

h : {(n, d) | n ∈ N, d ∈ Dk }→ {0, 1}
This function h is called the grid indicator and defines a sequence Bh of sets

Bh(n) := {d ∈ Dk | h(n, d) = 1}
For each of the sets Bh(n) the Hausdorff distance between Bh(n) and K may not be greater than 2−n, i.e.

( ∀d ∈ Bh(n) ) ( ∃x ∈ K ) x ∈ Un(d)

( ∀x ∈ K ) ( ∃d ∈ Bh(n) ) x ∈ Un(d)
The second component b ∈ N is called the grid bound for h and must satisfy
Bh(0) ⊆ [−2b; 2b]k
Additionally, we require that b is minimal: If b > 0, then
Bh(0) /⊆ [−2b−1; 2b−1]k For an example of some sets Bh(n) see figure 1.













Fig. 1. Possible sets Bh(0) and Bh(1) for the circle {(x, y) | x2 + y2 = 2}. The corresponding regions Un(d) are drawn in light grey.
A few remarks concerning this definition are important for our further consid- erations:
The information contained in a grid name is redundant in the following sense: Knowing all elements from Bh(0) we are obviously able to deduce the grid bound b. Our approach uses the grid indicator h for the access to the Bh(n), i.e. there will be a ‘black box’ (= an oracle) just answering questions like ‘Does the vector

d ∈ Dk
belong to Bh(n)?’.  In this setting, it is necessary to know (an upper

bound for) b beforehand just to find all the vectors belonging to Bh(0) via h!

For a given compact set K, neither Bh nor b are uniquely determined; but only a ﬁnite number of such sets Bh(0) is possible for K. For each of these possible sets, b is then uniquely determined. So only finitely many b may exist for K!
Suppose that for a compact set K we are able to compute the grid indicator h at least for n = 0 and that additionally we know that K ⊆ [−2s, 2s]k for a given natural number s, though s might perhaps be much larger than the grid bound b. Then surely b ≤ s + 1 and it is sufficient to compute h(0, d) for all d ∈ Dk ∩ [−2s+1, 2s+1]k in order to find all elements from Bh(0) and to determine the correct value of b.
Here we do not need to evaluate h for any n with n > 0, which heavily influences our definition of computational complexity below!
Names for real vectors can be defined in a much simpler way: Similar to [8], we define a name for a real vector (x1, .., xk) ∈ Rk to be a function φ : N → Dk with φ(n) = (φ1(n), .., φk(n)) ∈ Dk and |φi(n) − xi|≤ 2−n.
In the following we specify our model of computability and define computational complexity. In order to be sufficiently general for our later considerations, we will use a version that allows a mix of compact sets and real numbers as inputs to our machines, as we want to investigate complexity of operators from Rk1 × K(k2) ×
K(k3)... to Rk' or K(k')
We start by describing how an oracle for K ∈ K(k), or more precisely for a name ψ = (h, b) of K, should work. There are two different types of queries for such an oracle:
Definition 2.3 An oracle for a compact set K ∈ K(k) given via a grid name ψ = (h, b) behaves as follows:

Queries are either empty or of the form ‘(n, d)?’ for n ∈ N and d ∈ Dk .
	
For a query ‘(n, d)?’ the oracle results in the value h(n, d) of the grid indicator h,
i.e. we see whether the vector d lies on the n-th grid defined by h (or not).
For the empty query the oracle returns the grid bound b for h.
Oracles for x ∈ Rk, or more precisely for a name φ of x, are much simpler, of course. There is just one type of queries:
Definition 2.4 An oracle for a real vector x = (x1, .., xk) given by a name φ
behaves as follows:
Queries are of the form ‘n?’ for n ∈ N.
Given a query ‘n?’, the oracle returns the vector φ(n), i.e. with φ(n) = (d1, .., dk) we have di ∈ Dn and |di − xi| ≤ 2−n, so we get approximations for each single component xi.
In many papers, the authors restrict their considerations to real vectors from [0; 1]k for the arguments and for the results as well. A similar approach would be to restrict ourselves to compact sets from [0; 1]k. Unfortunately, this restriction would imply to intersect the results with [0; 1]k, which in general is not a computable

operation.
Instead, we define computational complexity for arbitrarily large compact sets and/or vectors. We use a setting with two parameters n and s: n is used for the precision of the grid and the dyadic approximations; s depicts a bound for the ‘size’ of the arguments, where this size is defined as follows:
Definition 2.5
For compact sets K ⊆ K(k), let size(K) be the smallest s ∈ N with K ⊆ [−2s; 2s]k.
For vectors x ∈ Rk, let size(x) be the smallest s ∈ N with x ∈ [−2s; 2s]k
If size(ci) is already defined for all components of a tuple (c1, .., cm), then size(c1, .., cm) := max{size(c1), .., size(cm)}
Of course, the size defined above is not a computable function. Its only purpose is to simplify the definition below:
Definition 2.6 Let C1, C2, .., Cm be given such that each Ci is either a subset of K(ki) or a subset of Rki for some values ki ∈ N. Let C := C1 × ... × Cm and let t : N2 → N.
Consider an operator F : C → C' with domain C, where either C' = Rk' or
C' = K(k').
F is called computable in time t on C if and only if there is an oracle Turing machine M such that
M computes F on C, i.e. given oracles Ψi for the arguments ci ∈ Ci, M Ψ1,..,Ψm
behaves like an oracle for F (c1, .., cm) =: c' ∈ C':
· Case c' ∈ C' = Rk' : For inputs of form ‘n?’ the machine M Ψ1,..,Ψm produces
an output (d' , .., d' ' ) consistent with the real vector c', corresponding to defini-

1
tion 2.4.
'	'
k

(k')

· Case c ∈ C = K	: For inputs of form ‘(n, d1, .., dk' )?’ or the empty query
M Ψ1,..,Ψm produces h(n, d1, .., dk' ) or b such that (h, b) is consistent with the
compact set c', corresponding to definition 2.3.
If s is such that s ≥ size(c1, .., cm), then the number of steps of the oracle Turing machine must be restricted by t(n, s) for any of the inputs ‘n?’ or ‘(n, d1, .., dk)?’ and by t(0, s) for the empty query.
We will say that F is computable in polynomial (or linear) time, if there are a polynomial (or linear) p and an arbitrary(!) function q : N → N such that t(n, s) ≤ p(n) · q(s), i.e. the dependency on n is strictly polynomial (or linear) in n extended by a factor depending only on the size s. In other words: We mainly study polynomial complexity parameterized by the size of the arguments.
For studying the complexity of examples, it is important to add some remarks about the notation of the numbers used in the definition above. Similar to [8], n should be given in a unary notation, i.e. as a string of length n. Also the grid bound b should be returned in unary. Furthermore, oracle queries have to be written

to special query tapes and, using a query operation counting as a single step, the oracle erases the complete content of corresponding answer tapes and writes the answer to the queries onto them. Additionally, any d = m· 2−n ∈ D should be given as a string ‘u v1 • v2’: The single bit u ∈ {0, 1} indicates the sign of the number d; the binary strings v1, v2 ∈ {0, 1}∗ are such that v1 denotes the integer part of d and has no leading zeroes, and v2 denotes the fractional part of d and may not have trailing zeroes. So if d ∈ Dn, then the length of v2 is at most n, and if size(d) ≤ s, then the length of v1 is at most s.
To explain some details of the definition, we prove the following instructive exam- ples. The proofs are not difficult; the focus lies on the behavior of the parameterized complexity.
Lemma 2.7
The union operators	on compact sets are computable in linear time, where
k : K(k) × K(k) → K(k) (for k ∈ N) is deﬁned by  k(K1, K2) := K1 ∪ K2.
The crossproduct × of compact sets is computable in linear time, where
× : K(k) × K(k') → K(k+k') (for k, k' ∈ N) is deﬁned by ×(K ,K ) := K × K .
1	2	1	2
The operator Shift is computable in linear time, where
Shift : K(1) × R → K(1) is deﬁned by Shift(K, r) := {x + r | x ∈ K}.
The operator Scale is computable in polynomial time, where
Scale : K(1) × R → K(1) is deﬁned by Scale(K, r) := {x · r | x ∈ K}.
The operator Slant is computable in polynomial time, where
Slant : K(2) × R → K(2) is deﬁned by Slant(K, r) := {(x + ry, y) | (x, y) ∈ K}.
The operator Rotate is computable in polynomial time, where Rotate : K(2) ×
R → K(2) is deﬁned by
Rotate(K, r) := {(x cos(rπ) − y sin(rπ),x sin(rπ)+ y cos(rπ)) | (x, y) ∈ K}.
Proof. (1) For the union we have two compact sets as arguments, i.e. m = 2,
k1 = k2 = k' = k, and C1 = C2 = C' = K(k) (corresponding to definition 2.6).
We construct a two-oracle Turing machine M as follows: Let ψ1 = (h1, b1), ψ2 = (h2, b2) be oracles for two compact sets K1, K2 ∈ K(k). Given these oracles, we have to consider inputs of (n, d) with n ∈ N and d ∈ Dk as well as the empty input.
For the empty input, Mψ1,ψ2 calls each oracle once, both with the empty query, resulting in the grid bounds b1 and b2. Then Mψ1,ψ2 simply returns b := max{b1, b2}.
For non-empty input (n, d), the machine Mψ1,ψ2 again first determines b as above and tests whether d ∈ Dk ∩ [−2b; 2b]k. If not, Mψ1,ψ2 returns 0.
Otherwise, Mψ1,ψ2 calls each oracle once more, but now with the query (n, d).
Let v1 and v2 be the two resulting bits. Then Mψ1,ψ2 returns v := v1 ∨ v2.
Obviously, Mψ1,ψ2 computes the union of K1 and K2: b is the correct minimal bound for Bh1 (0) ∪ Bh2 (0) and v corresponds to correct values of the grid indicator for the union Bh1 (n) ∪ Bh2 (n).
Suppose s ≥ size(K1, K2). Then b1, b2 ≤ s + 1. The computation time of Mψ1,ψ2
for the empty input, i.e. for b, is dominated by the computation of the maximum,

so it is linear in s (because of the unary representation of b1, b2) and independent from n. For non-empty input the time is the sum of the time necessary to compute b, to test the input (linear in n + s) and then perhaps create the queries (again linear in n + s) and to compute v (constant time). Thus M runs in time O(n + s),
i.e. in ‘linear time’.
The result for the complexity of the crossproduct can be shown in a similar way: The only modification is that for an input (n, (d1, .., dk+k' )) we simply call the first oracle with (n, (d1, .., dk)) and the second one with (n, (dk+1, .., dk+k' )) instead of the identical queries mentioned above.
For the shifting we have two arguments and a one-dimensional, set-valued result, i.e. m = 2, k1 = k2 = k' = 1. We shall construct a two-oracle Turing machine M to compute the shifting operator. Let ψ = (h, b) be an arbitrary grid name for a compact set K, and let φ be a name of a number r ∈ R.
Mψ,φ has to compute the values h'(n, d) (for n ∈ N,d ∈ Dn) of a grid indicator
h' and a consistent grid bound b' ∈ N:
In any computation, Mψ,φ initially calls φ with query n = 0, yielding a result d'
with |r − d'|≤ 1. Then Mψ,φ calls the oracle ψ with the empty query to determine
b. Let β := b + log2 |d'| + 2. Then surely Shift(K, r) ⊆ [−2β, 2β ]
For a non-empty input (n, d), h'(n, d) is computed as follows:
If |d| > 2β , then h'(n, d) := 0.
In any other case, compute the following four values, all from Dn+2:
T (n, d) = {d + i · 2−n−2 − φ(n+2) | i ∈ {−1, 0, 1, 2}}
Then test whether h(n+2, d') = 1 for at least one d' ∈ T (n, d). If this is the case, then h'(n, d) := 1, otherwise again h'(n, d) := 0.
We show that h' characterizes a grid for Shift(K, r).
Suppose h'(n, d) = 1. Then h(n+2, d') = 1 for a value d' ∈ T (n, d). So there are x, i with x ∈ K and |i|≤ 2 such that |x−d'|≤ 2−n−2 and d' = d+i·2−n−2 −φ(n+2). Thus, |d − (x+r)| = |d' − i · 2−n−2 + φ(n+2) − (x + r)| ≤ |d' − x| + |i · 2−n−2| +
|φ(n + 2) − r|≤ 2−n. Please note x+r ∈ Shift(K, r) because x ∈ K.
On the other hand, consider any x+r ∈ Shift(K, r). Then x ∈ K, hence there is d' ∈ Dn+2 such that h(n+2, d') = 1 and |x − d'|≤ 2−n−2. Additionally there is a d ∈ Dn such that d' ∈ T (n, d). Thus, |d − (x+r)|≤ |d − (d' − φ(n+2))| + |d' − x| +
|r − φ(n+2)|≤ 2−n. Please note that h'(n, d) = 1.
For the empty query, M computes b' by explicit construction of B'(0). This is possible by testing all values d ∈ [−2β, 2β ] ∩ D0 whether h'(0, d) = 1.
Since the subtraction of dyadic numbers costs not more than linear time, it follows that Mφ,ψ runs time linear in n (but exponential in s because of the com- putation of b' ).
(4)-(6) These cases can be shown with a similar construction.	 
If in definition 2.6 we use the special case m = 0, i.e. we consider 0-ary operators, we get a notion of polynomial time complexity for real vectors and for compact sets.

For vectors, the definition is equivalent to the usual definition of polynomial com- putability, e.g. in [8,13]. For compact sets, the definition corresponds to definition 7.4.3(5) in [13]. The following lemma gives a few examples. As the results are quite obvious, we omit the proofs.
Lemma 2.8	(i) A vector x ∈ Rk is computable in polynomial time if and only if the singleton set K := {x} is also computable in polynomial time.
(ii) If a convex polygon K ⊂ R2 has vertices x1,..., xl ∈ R2 that all are computable in polynomial time, then K is computable in polynomial time, too.
A useful notion of computational complexity should be closed under composition. In the following we show that this is also true for our definition of parameterized complexity.
Theorem 2.9 Let F, G be two operators such that range(F ) ⊆ dom(G). Suppose F is computable on a set C, and G is computable on a set C' with F (C) ⊆ C', both in polynomial time. Then the operator H := G◦F is also computable in polynomial time on C.
Proof. Let M1, M2 be oracle Turing machines computing F and G, respectively, with (monotonic increasing) complexity bounds t1 and t2 valid on C and C'. Using appropriate values a, l ∈ N \ {0}, and q : N2 → N \ {0}, both t1(n, s) and t2(n, s) are bounded by a · nl · q(s) for n > 0 and by q(s) for n = 0.
We construct a machine N as usual for the composition of oracle machines: Given x ∈ C via an oracle Ψ for x and given some input w, N starts simulating M2. Whenever N needs to simulate an oracle call of M2, N simulates M1 with oracle Ψ instead, using the oracle query as input for M1. Obviously, N computes H in the sense of definition 2.6.
To show that N works in polynomial time, we need to consider how the depen- dency of the complexity on the size behaves under the composition. Essentially, we simply add the computation times, but we have to be careful about the length of the oracle queries that N has to simulate for M1. So let sx := size(x) and let pw be the precision necessary for input w (i.e. pw = 0 for the empty query, pw = n for queries of form ‘n?’ or ‘(n, d1, .., dk' )?’).
M Ψ must be able to answer the empty query as well as the query 0? in time t1(0, sx) ≤ q(sx). Because of the restrictions to the notation of the query results, we are able to conclude size(F (x)) ≤ q(sx).
The total computation time T Ψ(w) of N Ψ on w is bounded by the sum of
t2(pw, q(sx)) for the simulation of M2 (which is a bound for the number of queries to the oracle of M2, i.e. simulations of M1, and also for the length of those queries) and
t1(t2(pw, q(sx)), sx) for each single simulation of M1. This leads to a total of
T Ψ(w) ≤ t2(pw, q(sx)) · (1 + t1(t2(pw, q(sx)), sx))

≤ 2al+2 · pl2+l · (q(q(s ))l+1)q(s )
x
which is again polynomial in the precision parameter pw.

Complexity of Projection
We define the projection of a compact set K ∈ K(2) as:
Proj(K) := {x | (x, y) ∈ K for some y}.
Theorem 3.1 The operator Proj is computable. Its complexity has exponential upper and lower bounds.
Proof. (1) We first show that the projection is computable and has exponential upper bounds for its complexity. Construct an oracle Turing machine M computing Proj for any compact set K and any grid name ψ = (h, b) of K as follows:
For any query (n, d), Mψ first determines b and then searches whether there is a d' ∈ Dn ∩ [−2b, 2b] such that h(n, d, d') = 1 by calling the oracle ψ sufficiently often. If the search is successful, then Mψ returns 1, otherwise Mψ returns 0. Let h' be the function defined by this part of the computation.
To show that h' is a grid indicator of Proj(K), first consider (n, d) with h'(n, d) = 
1. Then there is d' such that h(n, d, d') = 1, so there is (x, y) ∈ K such that (x, y) ∈
Un(d, d'). Hence |d − x|≤ 2−n, ie. x ∈ Un(d). Please note that x ∈ Proj(K).
On the other hand, consider any x ∈ Proj(K). Then (x, y) ∈ K for some y. Thus, there are d, d' such that h(n, d, d') = 1 (hence h'(n, d) = 1) and (x, y) ∈ Un(d, d') (hence x ∈ Un(d)).
If, in the computation of h', the search is done in a exhaustive way for all possible d' ∈ Dn ∩ [−2b, 2b], we get an upper bound on the complexity of M that is obviously exponential in n.
The correct grid bound b' for h' may not be larger than b, so it can be determined using h' and b, as mentioned as a remark to definition 2.2.
(2) Now suppose there were a machine N such that the worst case for the run
time of N really were below 2n · q(s) ·   1  for a given q. Or as an alternative:
Suppose the run time were in o(2n) · q(s) for an arbitrary q.
Just consider compact sets ⊆ [−1, 1]2: Their size is 0, so there would be values
n such that N needs less than 2n−3 on the input (n, d) (for arbitrary d).
For such an n consider the special compact set K = {2·2−n} × [−1, 1] with Proj(K) = {2·2−n} and consider the corresponding grid name ψ = (h, b) where b := 0 and
⎧	'
h(n, d, d') := ⎨ 1 if d' ∈ [−1, 1] ∧ n ≥ n ∧ d = 2·2−n
⎪⎩ 0 else

In the following we want to define a different compact set K such that N is some-



times unable to distinguish between K and K. So let

Qn := {d' | there is a query (n, d, d') during one of the computations of

Nψ on (n, −1·2−n), (n, −2·2−n) or (n, −3·2−n) }

By construction of n, there may be at most 2n−3 queries to ψ for each input, hence #Qn ≤ 3 · 2n−3. As #(Dn ∩[−1, 1]) = 2n+1 +1, there must be a d ∈ Dn ∩[−1, 1]\Qn. Now consider the (compact) set K := K ∪ {(−2·2−n, d)} with Proj(K) =
{−2·2−n, 2·2−n}.  Here a grid name ψ = (b, h) valid for K is given by b := 0
and




h(n, d, d') :=
⎧ 1 if d' ∈ [−1, 1] ∧ n < n ∧ d = 0 
⎪⎪ 1 if d' ∈ [−1, 1] ∧ n ≥ n ∧ d = 2·2−n

1 if d' = d ∧ n ≥ n ∧ d = −2·2−n
⎪⎪⎩ 0 else

As Nψ is assumed to compute Proj(K), the output of Nψ must be 0 for any input of form (n, d) with d ≤ 0. By construction of h, the machine N is unable to distinguish between ψ and ψ at least for the three special inputs (n, −1·2−n), (n, −2·2−n) and (n, −3·2−n), i.e. Nψ must also be 0 for these three values. So the distance between
−2·2−n and Bh(n) would be at least 21−n, i.e. too big.	 
The construction in part (1) of the proof above shows a close connection to the classical problem whether P=NP:
Theorem 3.2 P=NP if and only if for every polynomial time computable K, the projection Proj(K) is again polynomial time computable.
Proof. (1) Consider a fixed polynomial time computable K and let N be a cor- responding Turing machine computing a grid name ψ = (h, b) of K in polynomial time. As the size of K is fixed, the set U := {(n, d, d') | d, d' ∈ Dn ∧ h(n, d, d') = 1} is computable in polynomial time according to the usual definition from discrete complexity theory.
So the set V = {(n, d) | (∃d' ∈ Dn) h(n, d, d') = 1} is in NP. The characteristic function of this set V is the function h' constructed at the beginning of the proof of theorem 3.1. So if NP=P, then Proj(K) is also polynomial time computable.
(2) Let A ⊂ {0, 1}+ be an NP-complete set. Without loss of generality, A can be chosen such that there is a corresponding polynomial time computable set U ⊆ {w#v | w, v ∈ {0, 1}+ ∧ len(w) = len(v)} with A = {w | (∃v) w#v ∈ U}, where len(w) denotes the length of a string w.
As an example for A we might use the satisfyability problem SAT: The number of different variables in a formula w is trivially bounded by the len(w), so U may simply consist of all pairs w#v, where the initial part of v describes an assignment of truth values to the variables in the formula w that satisfies w, while v is padded at the end with arbitrary bits until len(w) = len(v).

In the following we construct a compact set K such that A corresponds to
Proj(K). We will use a similar construction as in part (2) of the proof of theorem
: The strings w#v will be mapped to discrete points (w, v) ∈ D2, additionally there will be (many) straight lines dividing [−1, 1]2 into small subregions that can be treated independently.
For any string w ∈ {0, 1}+ define w, w , and w to be the dyadic numbers
w := 2−len(w) + 2−2len(w) · bin(w) w := w + 2−2len(w)−1
w := 2−len(w)−1 + 2−len(w) · bin(w)
where bin(w) ∈ N is the value of the string w using ordinary binary notation. For example, the string 101 corresponds to the three dyadic numbers 101 = +.001 101,
101 = +.001 101 1, and 101 = +.101 1.
Now consider the set K := K0 ∪ K1 ∪ K2 with

K0 := {(w, v) | w#v ∈ U}
K1 := {w | w ∈ {0, 1}+ }× {x ∈ R | 0 ≤ x ≤ 1}
K2 := {0, 1}× {x ∈ R | 0 ≤ x ≤ 1}


			


(0, 1)
⊂ K2
... 




... 
K1
... 



  
(0, 1^) (0, 0^)
(1, 1^)
(1, 0^)
(1, 1)
⊂ K2
candidates for points in K0


  

(0, 0)
... 00 01 10 11 0	1
Fig. 2. The sets K0, K1 and K2
(1, 0)

K0 encodes U into dyadic numbers, K1 separates points from K0 with different x coordinates, and the purpose of K2 is to add missing accumulation points to get a compact set and to get a proper enclosure to the set. So K is compact and

Proj(K) = {0, 1}∪ {w | w ∈ {0, 1}+}∪ {w | w ∈ A}

Although testing the inclusion of a point in a compact set is a non-computable operation in general, the situation is different for the well-structured set Proj(K): Let ψ = (h, b) be a grid name for Proj(K). To decide whether w ∈ A for an w ∈ {0, 1}+, let n = 2 · len(w) + 2 and check whether h(n, d) = 1 for at least one of the three dyadic values d ∈ {w − 2−n, w, w + 2−n}.

A valid grid name for K itself is ψ = (h, b) with b = 0 and



h(n, d, d') :=
⎪⎪ 1 if d' ∈ [0, 1] ∧ (∃w) d = w	(for K1) 1 if (∃w)(∃v) d = w, d' = v, w#v ∈ U (for K0)
⎪⎩ 0 else

for all n ∈ N and d, d' ∈ Dn. Please note that the existential quantifiers in the definition of h do not stand for a search but just for a syntactical check of the form of d and d'.
So obviously, if U is computable in polynomial time, then this also holds for K. Using the assumption that this implies polynomial time computability of Proj(K), A ∈ P would follow.	 
Theorem 3.2 shows that the usual impression that a compact set naturally has some kind of inner structure is rather wrong: In the previous proof we were able to code infinitely many points (almost arbitrarily chosen) into a compact set. So an interesting question is to ask what additional properties of the compact sets K are required such that theorem 3.2 or even theorem 3.1 can no longer be shown.
Obviously, we are able to extent theorem 3.1 to connected compact sets: In the proof, we only have to connect the set K with the constructed point (−2·2−n, d)
using the line segment (−2·2−n, d)(0, d). Unfortunately, this simple modification can not be used in the proof of theorem 3.2, as the resulting set would still not be a connected set.
The following lemma shows that for e.g. convex compact sets, we are able to compute the projection efficiently (which is interesting as we are also able to rotate compact sets).
Lemma 3.3 Restricted to convex sets, the operator Proj is computable in polyno- mial time.
Proof. Let K be a convex compact set given by a grid name ψ = (h, b). Because of the convexity, Proj(K) is a closed interval [lK, rK] with lK = min{x | (∃y) (x, y) ∈ K} and rK = max{x | (∃y) (x, y) ∈ K}. So to determine whether a d ∈ D is sufficiently near to the Proj(K), we only need to approximate lK and rK.
In the following we concentrate on lK. So let (lK, yK) ∈ K be an arbitrary point in K with first coordinate lK. We describe an iterative algorithm that, for any
n ∈ N, finds a point (d^' , d^n) with
h(n, d^' , d^n) = 1, so lK ≤ d^' + 2−n, and

n
lK > d^'
n
— 22−n.

Please note that it is not necessary that also |dn − yK| is small.
For the initial case n = 0, a suitable point (d' , d0) can be found using an ex- haustive search on all (d', d) ∈ D2 ∩ [−2b, 2b]2, simply taking the smallest d' such
that h(0, d', d) = 1.

Now consider the step from n−1 to n and suppose (d^'	, d^n−1) has already been
found.
First we construct a small rectangle containing (lK, yK): Using (i) and (ii), the
left edge can be chosen on the line {d^'	− 23−n} × R and an even closer right
edge on the line {d^'	+ 21−n}× R. The upper and lower edges we are looking for
should be such that the resulting rectangle is almost minimal: It should contain points from K near these upper and lower edges. In detail, the construction of the rectangle will be performed as follows (see figure 3):

Although h(n−1, d^'	, d^n−1) = 1, we do not know whether h(n, d^'
, d^n−1) = 1.

But there must be a point (d' , dn) such that h(n, d' , dn) = 1 and |d^'
−d' |≤ 3·2−n

n
as well as |d^n−1 − dn|≤ 3 · 2−n.
n	n−1	n

Let In = {d^'	+ i · 2−n | −8 ≤ i ≤ 4}. Then we search for two values dn and
dn such that

−2b ≤ dn ≤ dn ≤ dn ≤ 2b
h(d', dn) = 1 for at least one value d' ∈ In

h(d', dn) = 1 for at least one value d' ∈ In
h(d', d) = 0 for all values (d', d) ∈ In × {dn − i · 2−n | i ∈ {1, 2, 3}} 

h(d', d) = 0 for all values (d', d) ∈ In × {dn + i · 2−n | i ∈ {1, 2, 3}} 

As h(n, d' , dn) = 1, such values dn and dn do exist. The search for these values should be implemented as a binary search, where the initial borders of the search are dn and −2b for dn, and dn and 2b for dn. So the number of search steps is linear in b + n. Please note that we do not require dn or dn to be different from dn.
For the next step in the construction, we cut the rectangle into eight stripes using seven equally spaced horizontal lines. Due to the convexity of K and the minimality of the rectangle, each of these lines must (almost) intersect the border of K. Again due to the convexity of K, the leftmost intersection point must have an x-coordinate very close to lK.
In detail, we define nine almost equally spaced areas in In × {d ∈ Dn | dn ≤ d ≤ dn} (corresponding to the lower and upper edge of the rectangle and to the seven horizontal lines) where we want to search for the new approximation (d^' , d^n):

For 1 ≤ ν ≤ 7 consider d(ν) := the value ∈ Dn closest to(ν · dn + (8−ν) · d )/8
n
and let

Jn := {dn, dn}∪ {d(ν) + i · 2−n | ν ∈ {1, ..., 7}, i ∈ {−1, 0, 1}} 

So In × Jn consists of 13 · (2+7 · 3) = 299 points or less, in case that dn ≈ dn and the areas overlap.
Finally d^' := min{d' ∈ In | (∃d ∈ Jn) h(n, d', d) = 1} and as d^n we use one of
the values where h(n, d^' , d^n) = 1. By construction of dn and dn, such a pair (d^' , d^n)

Using the convexity of K, we know that dn − 2−n ≤ yK ≤ dn + 2−n and that within K there must exist straight lines from (lK, yK) to a point in K near In ×{dn}





In × {dn}
non-empty intersection with K
left bound for lK
right bound for lK



j
n−1
, d^n−1)


     
non-empty intersection with K


 




In × {dn}
area of (dj , dn)
non-empty intersection with K

empty intersection with K


Fig. 3. Projection of convex sets; constructing the enclosing rectangle from (db' , dbn).

as well as to a point in K near In ×{dn}. As the inner search areas are three points wide, any such line crossing a search area must correspond to least one point with h(n, d, d') = 1 in the search area and with a distance of at most 2−n from the crossing point.
But, as our nine search areas are equally spaced, there must be such a crossing point with an x-coordinate c such that |lK − c| is at most one fifth of the maximal difference of y coordinates under consideration, i.e. |lK − c| ≤ 1 · 14·2−n < 3 · 2−n. So in one of the search areas there must be a point (d', d) with h(d', d) = 1 and where lK > d' − 22−n, which concludes our construction.
Because of the linear number of the binary search steps in each iteration, the complexity of the construction of (d' , dn) is surely polynomial in n.
Finally, to compute a grid name ψ' = (h', b') for Proj(K), for query (n, d')
we may approximate lK using d^'	and a similar approximation d˜'	for rK:  If

'
n+3
— 2−n−1 ≤ d ≤ d˜'
+ 2−n−1, then we let h'((n, d') = 1. b' can be computed

as mentioned as a remark to definition 2.2.	 

Convex Hull of Compact Sets
In the previous section we have seen that the projection operator in general has exponential complexity, unless the underlying set is convex. So computing a convex hull of a compact set must also be a complicated operation. Now we have a deeper look into this, especially as we were unable to extend the results for the projection to connected sets.

The convex hull operator Chull : K(2) → K(2) is defined as follows: Chull(K) is the smallest convex set containing K.

Theorem 4.1 The operator Chull is computable. Its complexity has exponential upper and lower bounds.

Proof. (1) We construct an oracle Turing machine M to compute the convex hull of an arbitrary compact set given as an oracle: So let K be compact and let ψ = (h, b) be an arbitrary grid name for K.  For inputs n and d1, d2 ∈ Dn, the machine

Mψ checks (by an exhaustive search) whether there are points d(i) ∈ D2
(for



i ∈ {1, 2, 3}) such that h(n+2, d ) = 1 and that the distance from (d1, d2) to the triangle Δd(1)d(2)d(3) is not greater than 2−n−2. If so, return 1, otherwise return
0. Please notice that the check for the distance between a dyadic point and a triangle with dyadic corners can be computed in time polynomial in the length of the arguments. Thus, M runs in exponential time.
It is straightforward (so we omit details) to show that the grid indicator h' com- puted by Mψ corresponds to Chull(K): In the neighborhood of each of the points d(i) there is a point x(i) ∈ K (and vice versa), so for each point from Δd(1)d(2)d(3)
there is a nearby point in the triangle Δx(1)x(2)x(3) (and vice versa).  The latter
triangles again determine Chull(K).
(2) An exponential lower bound can be shown with a similar construction as in the proof for the projection: Now suppose N is a machine computing the convex hull. We are able to use the idea of construction of the set K from theorem 3.1 again: Let now n be such that, for K of with size 0, N needs less than 2n−5 steps on inputs (n, d, d') (for arbitrary d, d').

Again, let K be defined as K = {2·2−n}× [−1, 1] and use the same grid name
ψ = (h, b) as in theorem 3.1, but now consider the nine special inputs

In = { (n, d, d') | d ∈ {−1·2−n, −2·2−n, −3·2−n}∧ d' ∈ {−2−n, 0, 2−n} } 

Let

Qn := {d' | there is a query (n, d, d') to ψ during one
of the computations of Nψ on inputs from In }

By construction of n, there may be at most 2n−5 queries to ψ for each input, hence #Qn ≤ 9 · 2n−5. As #(Dn ∩ [−1, 0.5]) = 2n−1 + 1, now there must be d1 ∈ Dn ∩ [−1, 0.5] \ Qn and also d2 ∈ Dn ∩ [0.5, 1] \ Qn.
Clearly the point (−2·2−n, 0) is not in Chull(K), so now consider the (compact) set K := K ∪ {(−2·2−n, d1), (−2·2−n, d2)} with (−2·2−n, 0) ∈ Chull(K) and the


	 	
grid name ψ = (b, h) with b := b and
⎧ 1 if d' ∈ [−1, 1] ∧ n < n ∧ d = 0 

1 if d' ∈ [−1, 1] ∧ n ≥ n ∧ d = 2·2−n
h(n, d, d') := ⎨ 1 if d' = d1 ∧ n ≥ n ∧ d = −2·2−n



1 if d' = d2
⎪⎩ 0 else


∧ n ≥ n ∧ d = −2·2−n




Again, h and h do not differ on [−1, 1]×Qn, so Nψ and Nψ yield the same output for the inputs from In, i.e. Nψ has to behave in a wrong way for (−2·2−n, 0) ∈ Chull(K).	 
Lemma 4.2 Suppose P=NP. Then Chull(K) is poly-time computable for each poly-time computable K.
Proof. Consider part (1) of the proof of theorem 4.1: We had to examine the set

{(n, d ,d ) | ∃d(1), d(2)d(3) ∈ D2
...}. For a fixed, polynomial time computable K

1	2	n+2
this is obviously a problem in NP. So if P=NP, then Chull(K) even is in P. 
Theorem 4.3 If Chull(K) is polynomial time computable for each polynomial time computable K, then P=NP.
Proof. As in theorem 3.2, let A ⊂ {0, 1}+ be an NP-complete set such that there is a corresponding polynomial time computable set U ⊆ {w#t | w, t ∈ {0, 1}+ ∧ len(w) = len(t)} with A = {w | (∃t) w#t ∈ U}, where len(w) denotes the length of a string w.
We want to construct a compact set K (based on U ) such that A can be de- cided using Chull(K). K will be computable in polynomial time, and A would be polynomial time decidable if Chull(K) were also computable in polynomial time.


Fig. 4. Dividing the half circle into infinitely many parts.

To construct K, we divide the half circle with center (0, 0) and radius 1 into an infinite number of arcs, each corresponding to a string w ∈ {0, 1}+. To do this, we define a linear ordering w '→ w+ on the strings: For w = 1n let w+ := 0n+1, and for w /= 1n let w+ be the lexicographically next string. Similarly, for w /= 0 let w− be the string preceding w.
For w = 0, let uw = (—1, 0). For w /= 0, let uw be the point on the circle such
—
that ∠uw− Ouw = π · 2−2len(w ) where O = (0, 0). Figure 4 shows the first few steps
of this process.
Then, for each w with n := len(w), divide the arc from uw to uw+ into 2n equally sized parts, each corresponding to a string t ∈ {0, 1}n. That is, we use points uw,t given by uw,0n = uw, and ∠uw,tOuw,t+ = (π · 2−3n). For simplicity, let uw,(1n)+ := uw+ .


Each segment line Ouw,t has an intersection with the segment line uwuw+ , de- noted by vw,t. Please note that vw,0n = uw,0n = uw, vw,(1n)+ = uw,(1n)+ = uw+ . The case w = 00 is depicted in figure 5.



v00,00
= u00,00
= u00
u00,01	u00,10
v00,01
00,10

u00,11 v00,11
v00,11+
= u00,11+
= u01


Fig. 5. Subdividing the arc from u00 to u01 into 4 parts.

If w#t ∈ A holds, we define Aw,t to be the closed sector uw,tOuw,t+ ; otherwise,
Aw,t is the closed triangle Δvw,tOvw,t+ . An example for w = 00 is given in figure 6.
u00




Fig. 6. Defining Aw,t, here for 00#01, 00#11 ∈ U and 00#00, 00#10 /∈ U .
Finally we define K to be the closure of  w∈{0,1}+  t,len(t)=len(w) Aw,t. Obvi- ously, K is compact. Since U is polynomial time decidable and the functions sine and cosine are polynomial time computable [1], we conclude that also K is com- putable in polynomial time.
To see the connection between Chull(K) and A consider the following check-

points zw: With t' := 10len(w)−1 let u'
:= uw,t' and v' := vw,t' . Using the point

w
z' of intersection between the lines uwu
  w 
len(w) and Ou' , we let zw be the middle

w
point of the line v' , z' .
w,1	w

w	w
It is not hard to see that w ∈ A if and only if zw ∈ Chull(K): If w ∈ A, then the

border of Chull(K) intersects the line Ou'
between u'
and z' ; if w /∈ A, then the

point of intersection is v' . So the distance δw from zw  to the border of Chull(K) will always be at least half the length of the line v' , z' . By estimating the length
w	w

j  = u00,10
Fig. 7. Construction of the checkpoint zw , here for w = 00. The arc has been enlarged for better readability.
of all concerned line segments, we can see that there is a polynomial q(n) such that
δw > 2−q(n).
Now consider any grid name ψ = (h, b) for Chull(K). To test whether w ∈ A,
i.e. to test whether there is t such that w#t ∈ U holds, it is sufficient to see whether zw ∈ Chull(K) or not: So using m := q(n) + 2, we first determine (d' , dw) ∈ Dm such that zw ∈ Um(d' , dw), then we check whether h(m, d', d) evaluates to 1 for at
least one of the nine points in {(d', d) ∈ D2 | |d' — d' | ≤ 2−m, |d — dw| ≤ 2−m}.
With exception of the evaluation of h, all of the above steps can be performed in polynomial time.
Now suppose ψ = (h, b) were computable in polynomial time: Then also A would be polynomial time decidable, i.e. NP=P.	 
A similar construction with the embedding of NP -complete sets into real func- tions can be found already in [6], where, among others, the question of finding the maximum value of a function was considered.
The set K constructed in the previous proof is not only compact but also regular (i.e. K is the closure of its interior, K = K◦) and simply connected. So essentially we have even shown the following slightly sharper result:
Corollary 4.4 P=NP if and only if Chull(K) is polynomial time computable for each simply connected regular compact set K computable in polynomial time.

References
Brent, R.P., Fast Multiple-Precision Evaluation of Elementary Functions, Journal of the ACM, 23, No.2 (1976), 242-251.
Braverman, M., Computational Complexity of Euclidean Sets: Hyperbolic Julia Sets Are Poly-time Computable, Master Thesis, University of Toronto, 2004
Braverman, M., On the Complexity of Real Functions, Proceedings of the 46th Annual IEEE Symposium on Foundations of Computer Science (FOCS)(2005), 155 - 164
Chou, A.W. & K. Ko, Computational complexity of two-dimensional regions, SIAM Journal on Computing, 24:923-947, 1995
Chou, A.W. & K. Ko, , On the complexity of finding paths in a two-dimensional domain I: shortest paths, Math. Logic Quart. 50 (2004) 551-572; preliminary version in Proc. Internat. Conf. on Computability and Complexity in Analysis, Hagen, Germany, 2003
Friedman, H., The computational complexity of maximization and integration, Adv. in Math., 53 (1984) 80-98.
Ko, K., On Some Natural Complete Operators, Theor. Comput. Sci., 37(1985), 1-30
Ko, K., Complexity Theory of Real Functions, Birkh¨auser, Boston, 1991.


Ko, K., & H. Friedman, Computational complexity of real functions, Theoret. Comput. Sci. , 20 (1982) 323-352.
Traub, J.F. & G.W. Wasilkowski & H. Wozniakowski, Information, Uncertainty, Complexity, Addison-
Wesley, New York, 1983
Traub, J.F. & G.W. Wasilkowski & H. Wozniakowski, Information-Based Complexity, Academic Press,
New York, 1988
Rettinger, R. & K. Weihrauch, The Computational Complexity of Some Julia Sets, in STOC03, San Diego, California, USA, 2003.
Weihrauch, K., Computable Analysis: An Introduction, Springer, 2000.
Weihrauch, K., Computable Complexity on Computable Metric Spaces, Math. Logic Quarterly, 49, No.1 (2003), 3-21.
Ziegler, M., Computability on Regular Subsets of Euclidean Space, Math. Logic Quarterly, 48, Suppl. 1 (2002), 157-181.
Ziegler, M., Computable Operators on Regular Sets, Math. Logic Quarterly, 50, No. 4/5 (2004), 392- 404.
