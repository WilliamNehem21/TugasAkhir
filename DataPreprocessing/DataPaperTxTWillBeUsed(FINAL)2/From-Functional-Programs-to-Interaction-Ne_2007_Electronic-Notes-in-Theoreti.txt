Electronic Notes in Theoretical Computer Science 174 (2007) 39–56	
www.elsevier.com/locate/entcs

From Functional Programs to Interaction Nets via the Rewriting Calculus
Horatiu Cirsteaa, Germain Faurea, Maribel Ferna´ndezb,
Ian Mackieb,c,1 and Fran¸cois-R´egis Sinotc,1
a LORIA, BP 239, 54506 Vandœuvre-l`es-Nancy Cedex, France
b King’s College London, Department of Computer Science, Strand, London WC2R 2LS, U.K.
c LIX, E´cole Polytechnique, 91128 Palaiseau Cedex, France

Abstract
We use the ρ-calculus as an intermediate language to compile functional languages with pattern-matching features, and give an interaction net encoding of the ρ-terms arising from the compilation. This encoding gives rise to new strategies of evaluation, where pattern-matching and ‘traditional’ β-reduction can proceed in parallel without overheads.
Keywords: pattern-matching, interaction nets, rewriting calculus


Introduction
The λ-calculus is usually put forward as the abstract computational model un- derlying functional programming, and graph rewriting or environment machines are used to describe evaluation strategies and to derive concrete implementations (see for instance [26]). However, modern functional programming languages have pattern-matching features which cannot be directly expressed in the λ-calculus. To palliate this problem, pattern-calculi [23,22,4,6,8,13] have been introduced. The ρ- calculus [6,8] is a pattern calculus combining the expressiveness of pure functional calculi and algebraic term rewriting. It is an extension of the λ-calculus where we can abstract on patterns, not just on variables: abstractions are written (p d t) where p is a pattern and t is the body.

٨ Partially funded by the Alliance France-UK project “Implementation Techniques for the Rho Calculus”.
1 Projet Logical, Pˆole Commun de Recherche en Informatique du plateau de Saclay, CNRS, E´cole Poly- technique, INRIA, Universit´e Paris-Sud.

1571-0661 © 2007 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2007.02.046

The rule describing the dynamics of application introduces a matching con- straint :
(ρ)	(p d t) u → [p  u]t
and the (σ) rule solves this constraint and applies the matching solution σp u to t. (σ) [p  u]t → σp  u(t)
The ρ-calculus is parametric in the matching theory: we can use syntactic matching or any arbitrary matching theory, even without unique principal solutions. In the latter case, we can use a structure to deal with the multiple solutions.
As an intermediate language for the compilation of functional languages, the ρ-calculus has several advantages: patterns are an integral part of the framework, which allows us to reason about pattern-matching and to study the interaction between pattern-matching and β-reduction at an abstract level; and the ρ-calculus can be used to model not only functional behaviour but also imperative features [17], object-oriented features [7], etc.
In this paper we exploit the first point above: we use the ρ-calculus as an inter- mediate language to compile functional languages with pattern-matching features, and adapt the evaluation strategies developed for the ρ-calculus to the specific con- straints arising from typed functional programs. We then use interaction nets [15] to define and implement the evaluation strategies. This methodology gives rise to new, efficient strategies of evaluation for functional languages, which we describe below.
In [11] we defined two alternative encodings of the ρ-calculus in interaction nets. Interaction nets are graph rewrite systems which have been used for the implemen- tation of efficient reduction strategies for the λ-calculus [12,1,20]. Since interactions are local and strongly confluent, they can take place in any order, even in par- allel (see [24]), which makes interaction nets well-suited for the implementation of programming languages and rewriting systems [10]. The first encoding of the ρ-calculus in interaction nets given in [11] is simple and exploits the implicit paral- lelism of rules (ρ) and (σ): a term t with a matching constraint (generated by an application of ρ) can be applied to another term (again using ρ) while the matching constraint is being solved. However, this first encoding, which below is called the simple encoding, can only model a strict semantics (see [8]) where a ρ-calculus term with a blocked matching evaluates to ⊥ (fail). The second encoding of [11], which introduces a matching agent and will be called the explicit encoding, can implement either a strict or a non-strict semantics, but it looses parallelism.
In the case of typed functional languages with pattern-matching, the ρ-terms arising from the compilation of programs do not remain blocked. More precisely, a matching failure may occur only if the definitions by pattern-matching are non- exhaustive. We will show that, in this case, a combination of the simple interaction net encoding and the explicit encoding provides an implementation where pattern- matching and ‘traditional’ β-reduction can proceed in parallel, without additional overheads. For example, if we have a function with two branches (patterns), say cons x nil and nil, and the argument is a cons, this will compile into a net which,

after selecting the cons branch, will check that the nested nil pattern matches while the substitution for x is being performed. We give more examples in Section 4. This is the main contribution of this paper: indeed, the compilation of functional programs into the ρ-calculus, and the subsequent interaction net encoding, uncover a new strategy of evaluation which naturally exploits the implicit parallelism of the ρ and σ rules.

Overview of the paper
This paper is organised as follows: after giving some background (Section 2), in Section 3 we define a minimalistic functional language, and give a compilation into the ρ-calculus. Section 4 shows an interaction net encoding for this intermediate language and gives examples. We conclude in Section 5.

Background
The ρ-calculus
We assume familiarity with the λ-calculus [2], and start with a short presentation of the ρ-calculus; for more details see [6,8,3]. We write x, y,... for variables and f, g,... for constants. The set T of ρ-terms (or just terms, ranged over by t, u, v) is defined by:
t, u ::= x | f | p d t | [p  u]t | (t u) | ⟨t, u⟩
where P is an arbitrary subset of T (p ∈P are called patterns); p d t is a generalised abstraction (it can be seen either as a λ-abstraction on a pattern p instead of a single variable, or as a standard term rewriting rule); [p  u]t is a delayed matching constraint denoting a matching problem p  u whose solutions (if any) will be applied to t; (t u) denotes an application (we omit brackets whenever possible, and associate to the left); and finally, ⟨t, u⟩ is called a structure. Terms are always considered modulo α-conversion (later this will be realised for free in interaction nets).
As usual substitutions are mappings from variables to terms, with finite domain, written {x1 := t1,... , xn := tn}. We write substitutions postfix: tσ denotes the term obtained by applying the substitution σ to t.
The ρ-calculus is parameterised by the set P of patterns. In this paper we use
linear (i.e., each variable occurs at most once) algebraic patterns:
p ::= x | f p1 ... pn.
Example 2.1 The boolean function null that tests if its argument is the empty list can be defined in the ρ-calculus as follows:
null = l d (⟨N il d True, Cons x y d F alse⟩ l)
The following reduction rules give the dynamics of the calculus. We write the

reduction →i (for implicit) or simply → when there is no risk of confusion:

The rule (σ) asks for an external matching algorithm to find a solution of the matching of p with u, and applies the corresponding substitution σp u to t. In this paper we assume linear syntactic matching; under this assumption the calculus is confluent [8].
Explicit ρ-calculus with Structures
In order to implement the ρ-calculus we need to make explicit the specification of the matching algorithm. We recall the explicit ρ-calculus of [11] (see also [5]), and extend it with rules to customise structures. Substitution will remain implicit, but we introduce an explicit application symbol • in patterns.
We write reduction in the explicit ρ-calculus →x (for explicit) or simply → when there is no risk of confusion.
The rule (ρ) remains unchanged. We decompose the rule (σ) into a finite set of local rules:

A matching problem (p  u) may have no solution; this is called a blocked matching. We add rules to detect failure (i.e., a clash):

and rules to propagate ⊥. There are mainly two options:
Strict Semantics:
(strict)	C[⊥]	→	⊥	for any context C[·]

This rule corresponds to an exception-like semantics of matching failure, as in ML (e.g., even if the argument of an application is not used by the function, the result is ⊥). In this semantics, a higher priority is given to this rule than to any other applicable rule (i.e., this rule is tried before the others).
Non-Strict Semantics: The rule (strict) defined above can be weakened to a particular class C of strict contexts (for instance, C = {([ ] t),t ∈T }):
(non-strict)	C[⊥]	→	⊥	for any C[·] ∈C 

We now turn our attention to structures. Since we will focus on ρ-terms arising from functional programs, structures will only be created by the compilation of a function defined by cases. Hence, structures will have the form ⟨p1 d t1,... , pn d tn⟩. Using (δ) and (ρ), an application of such structure to an argument u produces
⟨[p1  u]t1,... , [pn  u]tn⟩ where only one branch will succeed. In our equational theory for structures ⊥ should be a neutral element. This is achieved by the rules:

(stk)	⟨t1,... , ti−1, ⊥, ti+1,... , tn⟩ → ⟨t1,... , ti−1, ti+1,... , tn⟩ 1 ≤ i ≤ n
(singleton)	⟨t⟩ → t

The rule (stk) was used previously (see [27,9]) to encode term rewriting systems in the ρ-calculus. We could be more specific and force evaluation from left to right for instance, but we prefer not to fix the strategy of evaluation yet.
Notice that a naive implementation of (δ) would copy the argument u, which is inefficient. Since our use of structures will be limited to the compilation of case constructs in typed programs, we will actually be able to use the information provided by the type system to avoid copying the argument, thus optimising the reduction of structures (see Section 4.4).
We finally give an example of reduction in the ρ-calculus.
Example 2.2 Following Example 2.1 and assuming that the constants Z and S are used to represent Peano integers, we show that the ρ-term null(Cons Z Nil) reduces to F alse as expected:

null (Cons Z Nil)
= (l d ⟨Nil d True, Cons x y d F alse⟩ l)(Cons Z Nil)
→ρ [l  (Cons Z Nil)]⟨Nil d True, Cons x y d F alse⟩l
→σv ⟨Nil d True, Cons x y d F alse⟩ (Cons Z Nil)
→δ ⟨(Nil d True)(Cons Z Nil), (Cons x y d F alse)(Cons Z Nil)⟩
2→  ⟨[Nil   (Cons Z Nil)]True, [Cons x y   (Cons Z Nil)]F alse⟩

∗
ac,aa
⟨[Nil   ((Cons • Z) • Nil)]True, [((Cons • x) • y)   ((Cons • Z) • Nil)]F alse⟩

→⊥2 ⟨⊥, [((Cons • x) • y)  ((Cons • Z) • Nil)]F alse⟩
→stk ⟨[((Cons • x) • y)  ((Cons • Z) • Nil)]F alse⟩
→singleton [((Cons • x) • y)   ((Cons • Z) • Nil)]F alse

∗
σc,σa
∗
[x  Z][y  Nil]F alse

→σv F alse

Example 2.3 [Fixpoints] A fixpoint operator is a term Y such that for all terms t, Y t →∗ t (Y t). It is easy to check that the following terms are fixpoint operators (the second has the advantage of being well-typed [27]):
YT = (y d x d x (yy x)) (y d x d x (yy x))
Yrec = x d ((z d z (rec z)) (rec f d (x (f (rec f ))))) where rec is a constant.

From a functional language to the ρ-calculus
The Language
We consider a simple functional language with terms built from variables x, y,.. ., functional abstraction, application, data constructors C (each with a fixed arity), and a case construct to define functions by pattern-matching on constructors. We abbreviate t1,... , tn as →t. Patterns are defined by the following grammar:
p ::= x | C(p→)
with the usual linearity constraint (each variable may occur at most once in a pattern). The syntax of terms is given by the grammar:
t, u ::= x | fn x.t | t u | C(→t)
| case t of (pi ~ ui)i∈I
| fix(fn f.t)
A case branch of the form (pi ~ ·) acts as a binder i.e., fv(pi ~ ui)= fv(ui) \
fv(pi) where fv(ui) denotes the set of free variables of ui.
We assume the language is typed. For simplicity, we consider a simply-typed system where each constructor is associated to a datatype. We will base this discus- sion on the following form of a datatype declaration, which introduces a datatype DT with constructors C1,... , Cn, using some predefined types α→i.
DT = C1(α→1) | ··· | Cn(α→n)
Example 3.1 In the sequel we will use the following datatypes for numbers and lists with elements of type α:

Int = Z | S(Int)
List α = N il | Cons(α, List α)

As usual, the type system ensures that in a case construct case t of (pi ~ ui)i∈I all the branches have the same type and t has the same type as the patterns pi (for all i ∈ I), that is, some datatype DT . We do not assume that the cases are exhaustive, but we do assume they are non-overlapping for simplicity. We use a strict matching
semantics, as in ML (i.e., an application of a function to an argument that is not

covered by the case definition will produce a runtime error). We omit the typing rules, which are standard.
The following reduction rules give the dynamics of the language. Reduction is denoted by →f or simply →. The first rule corresponds to the application of a function to an argument (the familiar β rule of the λ-calculus), where {x := u} denotes the substitution of x by u, the second rule deals with case constructs, and the last one is used to evaluate fixpoint operators.

(fn x.t) u → t{x := u}
case t of (pi ~ ui)i∈I → uk σ	(if t matches pk with substitution σ)
fix(fn f.t) → (fn f.t) fix(fn f.t)
Since the rewrite rules are left-linear and non-overlapping (that is, they define an orthogonal system [14]), the language is confluent. It is easy to see that it is not terminating, due to the presence of the fixpoint operator fix.
Programs in this language are well-typed, closed terms (i.e., terms with no free variables). We give now some simple examples.
Example 3.2  (i) Assuming that N il with arity 0, and Cons with arity 2, are used to define the datatype List as in Example 3.1, and that True and F alse are the boolean constants, we can define the boolean function null by pattern- matching as follows:
null  fn l.case l of (N il ~ True, Cons(x, y) ~ F alse)
(ii) Assuming that Z with arity 0, and S with arity 1 are used to define the datatype Int as in Example 3.1, the recursive function length can be defined by pattern-matching as follows:
length  fix(fn len.fn l.case l of (N il ~ Z, Cons(x, y) ~ S(len y)))
Notice that we have not included a conditional in the syntax of the language, but it can be easily encoded with a case over the booleans True, F alse. Also, we do not have named functions and letrec but these can be easily encoded using fix:

let x = t in u  (fn x.u)t
letrec f = t in u  let f = fix(fn f.t) in u
We can also define mutually recursive definitions by an encoding as follows:
letrec f = u and g = v in w 
letrec h = fn g.(let f = h g in u) in
letrec g = (let f = h g in v) in
let f = h g in w

Compilation
The following compilation function, defined by induction on terms, translates terms in the typed functional language into the ρ-calculus:
 x) = x
 fn x.t) = (x d t))
 t u) = t) u)
 C(t1,... , tn)) = C t1) ... tn)
 case t of (p1 ~ u1,... , pn ~ un)) = ⟨ p1) d u1),... , pn) d un)⟩ t)
 fix(fn f.t)) = Y fn f.t)
where Y is a fixpoint operator of the explicit ρ-calculus (see Example 2.3). We leave Y abstract because it is an implementation choice. In particular, this will enable us to use a more efficient translation into interaction nets.
Example 3.3 It is easy to check that, using the definition above, the compilation of the function null given in Example 3.2 produces the function null in the ρ-calculus as given in Example 2.1.
Note that case constructs case t of (p1 ~ u1,... , pn ~ un) are compiled into structures applied to an argument t), and can be reduced using the δ rule. The interaction net encoding will ensure that t) is not copied, and moreover it will allow matching to be carried in parallel with other reductions, if possible.
We define the compilation of σ = {x1 := u1,... , xn := un} to be the substitution
 σ) = {x1 := u1),... , xn := un)}.
We now state some soundness invariants.
Proposition 3.4	(i) For all terms t and all substitutions σ, tσ) = t) σ).
For all patterns p and all terms u:
The matching problem p  t has a solution iff the matching problem p)  t)
has a solution.
The substitution σ is a solution of the matching problem p  t iff the substi- tution σ) is a solution of the matching problem p)   t).

For all terms t and u, if t →f u, then  t) →∗
 u), where →f denotes the

reduction relation in the functional language, and →x denotes the reduction
relation in the explicit ρ-calculus (see Section 2.2).
One can notice that in the ρ-calculus the granularity of the reduction is finer than in the chosen functional language and thus, the intermediate ρ-terms obtained during the reduction of the translation of a program t do not necessarily correspond to a program. More precisely, for a reduction t) →x u we cannot always exhibit a term u' such that t →f u' and u') = u. Nevertheless, if the reduction of the term
u continues then the term u') is eventually reached.
Lemma 3.5 For all programs t and for all terms u such that t) →x u there exists
a program v such that u →∗ v) and t →∗ v.
x	f

The following proposition is a corollary of the previous results.
Proposition 3.6 (Correctness) Let t be a program and v be a normal form, then
t →∗ v iff t) →∗ v).
f	x
In the following section we give an interaction net implementation for the func- tional language defined above, which defines a strategy of evaluation based on the encodings of the ρ-calculus presented in [11] and the coding of datatypes discussed in [21]. Although we focus on implementation in this paper, the intermediate ρ- calculus compilation has also interesting applications for programming language design (for instance one could study the properties of a more general language in- cluding non-linear patterns, or non-syntactic matching theories) and could also be used to study program transformations (in the same way as, for instance, explicit substitution calculi) and to prove correctness of program optimisations.

Interaction Net Encoding
Preliminaries
We recall the main notions from interaction nets which we will need in the rest of the paper; we refer to [15] for more details and examples.
A system of interaction nets is specified by a set Σ of symbols with fixed ari- ties, and a set R of interaction rules. An occurrence of a symbol α ∈ Σ is called an agent. If the arity of α is n, then the agent has n +1 ports: a principal port depicted by an arrow, and n auxiliary ports. Such an agent will be drawn in the following way:
x1	···	xn
 ,/,
 vJ
Intuitively, a net N is a graph (not necessarily connected) with agents at the vertices and each edge connecting at most 2 ports. The ports that are not connected are free. There are two special instances of a net: a wiring (no agents) and the empty net; the extremes of wirings are also called free ports. The interface of a net is its set of free ports.
An interaction rule ((α, β) =⇒ N ) ∈R replaces a pair of agents (α, β) ∈ Σ × Σ connected together on their principal ports (an active pair or redex ) by a net N with the same interface. Reduction is local, and there may be at most one rule for each pair of agents.
The following diagram shows the format of interaction rules (N can be any net built from Σ).
xn ,,,/,y1	xn	y1
.  α )( β	.	=⇒	.	.

. J J.
x	y

x1 /
  ym
1	m

ϵ	,, ,,

 vJ
ϵ	···	ϵ

ˆ	=⇒	 vJ  vJ
,,	→z

/	 J
→z

u ˆ	v

u ,/,v
,,,ˆ,

δ	α	α

 vJ
,ˆ,
 J/ J
,/, ,,

α	δ	···	δ

/	 J
→z
 J J
→z

Fig. 1. Erasing and Copying

We show as an example the interaction rules of two ubiquitous agents, namely the erase (ϵ), of arity 0, which deletes everything it interacts with, and the duplicator (δ), of arity 2, which copies everything. These are given in Figure 1, where α is any node.
We use the notation =⇒ for the one-step reduction relation and =⇒∗ for its transitive and reflexive closure. If a net does not contain any active pairs then it is in normal form. The key property of interaction nets, besides locality of reduction, is strong confluence.
There are several implementations of interaction nets, see for instance [16] and [25]; the latter has been designed to take advantage of additional processors, thus giving a parallel implementation of interaction nets.

Implementing the Language
We will assume that the problems of binding and substitution can be solved as in any off-the-shelf interaction net encoding of the λ-calculus (see for instance [18,19]), and concentrate on the encoding of the explicit matching and structure rules given in Section 2.2. This methodology is justified by the fact that the terms p d t and x d [p  x]t are extensionally equivalent, so that we can safely precompile terms in order to abstract only on variables, as in the λ-calculus, and have explicit matching constraints from the beginning. Also, there is a standard, efficient way to encode recursion in interaction nets for the λ-calculus, which consists of building a cyclic structure which explicitly “ties the knot”. The idea corresponds exactly to an encoding of recursion in graph reduction (see Peyton Jones [23] for instance), and was adapted to interaction nets in [18]. We use this for the encoding of Y (see [20] for details).
We now define by induction a function T (·) to translate the ρ-terms arising from the compilation of functional programs into interaction nets, and we give the interaction rules that will be used to evaluate them. As in the simple interaction net encoding of the ρ-calculus described in [11], a ρ-term t with free variables fv(t) = {x1,... , xn} will be translated to a net T (t) with the root edge at the


x1	xn
Fig. 2. Translation of a ρ-term t with fv(t)= {x1, ... , xn}.


ˆ
z	z
 J
Fig. 3. Translation of constants (left) and matching constraints (right).
top, and n free edges corresponding to the free variables, as shown in Figure 2.
The translation function T (·) is defined by induction as follows:
Variable: If t is a variable then T (t) is just a wire.
Constant: For each constant f we introduce an agent as shown in Figure 3 (left).
Matching Constraint: A term of the form [p  u]t is encoded as shown in Fig- ure 3 (right) 2 which can be interpreted as the substitution in t of the (possible) solution of the matching (the left subnet corresponds to the matching problem p  u).
Structure: We will discuss the encoding of structures at the end of the section.
Abstraction: We assume that terms have been precompiled to abstract only on variables, as described above; hence we can reuse the abstraction of the λ-calculus.
Application: Similarly for application, we introduce an agent @ with its principal port oriented towards the left subterm, so that interaction with an abstraction is possible. To implement the rule (ρ), we define an interaction rule between abstraction and application as in the λ-calculus (see for instance [19]).
Matching Rules
The matching rules are inspired by the “simple” encoding of [11]. Assume we have just one matching constraint to solve (the general case of a structure with multiple branches will be treated below). The matching algorithm is initiated by connecting the root of a pattern with the term to match (see Figure 3, right). Thus, the rule (σv) which defines matching against a variable (see Section 2.2) is realised for free, as in the λ-calculus. To simulate (σa) and (⊥1), constants will interact: Two identical constants cancel each other to give the empty net, as indicated in Figure 4 (left). If the agents are not the same, then we introduce an agent fail, which represents a failure in the matching algorithm, as indicated in Figure 4 (right). We interpret a net containing an agent fail as an overall failure, thus implementing the strict matching semantics.

2 A dashed edge represents a bunch of edges (a bus).



,,,,
empty
,,,,
,ˆ,

f’ `f
=⇒	!
f’ `g
=⇒	fail

 J J
net
 J J	 J

Fig. 4. Matching of constants (success and failure)


,,	,ˆ,	,,
,ˆ,

•
  J =⇒
/s  J =⇒
/ J

,’,/s	 
,’/,/  J
,’/,
,’/,

	
 J	 J
/ J
/ J

Fig. 5. Rules to transform patterns


,ˆ,
ˆ
=⇒

/ J / J
Fig. 6. Matching applications

We need rules to convert a usual application (@) into a pattern application (•) when it is part of an algebraic pattern (or term), these are shown in Figure 5; and a rule to match applications, which is given in Figure 6, as well as interaction rules corresponding to the rules (⊥2) and (⊥4) which we omit. We do not need interaction rules corresponding to (⊥3) and (⊥5) since the language is typed.
We refer to [11] for a detailed description and correctness proofs for matching constraints. In particular, in [11] it is shown that with this encoding of matching we can only implement a strict ρ-calculus semantics, but, on the positive side, it allows us to obtain a strategy of evaluation with a good potential for parallelism. This is because matching interactions involving the constraint associated to an abstraction can take place in parallel with a traditional β/ρ reduction involving the same ab- straction, without introducing any ‘administrative’ agents (i.e., no overheads). We use this feature in the encoding of functional programs below, to derive an evalua- tion strategy with the same potential for parallelism. We give examples at the end of the section.

Structures
We now describe the encoding of structures and the rule (δ). First remark that structures only arise from the compilation of case constructs, more precisely, struc- tures can only occur in subterms of the form: ⟨l1 d r1,... , ln d rn⟩ t. The goal is to avoid making multiple copies of t in the implementation of (δ), and to permit matching to proceed in parallel with functional computation, whenever possible. For these reasons, we will not treat these terms as standard applications. Instead, for each structure ⟨l1 d r1,... , ln d rn⟩ t (with n > 1; if n = 1 we can treat it as an abstraction) occurring in the compilation of a program we will introduce an agent case as explained below, where we build a net that minimises the number

of selections necessary. To keep the diagrams simple, we show the compilation in stages.
First, we consider the case when each li is a different constant Ci. We can then encode the structure using a simple case agent as follows:
 (c,ase,
//	 J 
T (r1)··· T (rn)
with the following collection of rules which select the appropriate branch of the case, and erase all other options using ϵ agents.
,,)(c,ase,=⇒	ϵ	ϵ

 J/	 J
 /vJ
i
 /vJ

The top auxiliary port of a case agent represents the output; the interaction rule above selects the branch i corresponding to the constructor Ci and connects it to the output port (all other branches are erased). It is a straightforward exercise to verify that this indeed mimics the corresponding reduction rule. Note that we are assuming that all patterns are disjoint (non-overlapping) but they may be non- exhaustive. If a case agent gets connected to a constructor for which there is no branch, the interaction results in a failure.
Note also that garbage collection is explicit in interaction nets since interaction rules must preserve the interface of the net, hence the use of the erasing agent ϵ in the rules above.
Next we deal with deeper patterns, including variables. To give the idea we consider the case where there is just one pattern of depth greater than 1 (i.e., the root is an application), for instance: ⟨C1 d r1, C2 x y d r2⟩ t. The compilation and interaction rules are given in Figure 7. Again the top auxiliary port of case is the output; the first rule in Figure 7 corresponds to a pattern of depth 1 (as before). Note that in the second interaction rule, the right hand side has a wire to connect the net T (r2) to the output port of the case agent. In the compilation (top of Figure 7), the nets T (y) and T (C2 x) are there precisely to complete the pattern matching, even though the branch would have already been selected. Any resulting substitutions generated are connected to the free variables of T (r2).
The extension to the case where there are more branches with constant patterns is straightforward.
Next we examine the case when there are more than one application branches to consider. Again, to keep the diagrams simple, we will concentrate on this aspect, and ignore the patterns of depth one that were given previously (extra ports in the case agent would be needed). Consider the example: ⟨C1x d r1, C2 y z d r2⟩ t. Both patterns have an application at the root, so we cannot use a case to distinguish them. However, we can identify where the patterns disagree, and consume that part before using a case agent, as above. Once the common prefix has been consumed,

	(c,ase,	
//  J 
T (r1)	T (r2)	T (y) T (C2 x)


,  ,	,,,ϵ ,)

case	=⇒
ϵ	 J

,’,/s   J	 vJ,ϵ ,)
 J	 J
,,
case  =⇒
,’,/s   J	ϵ

•
/ J
 vJ


Fig. 7. Compilation and rules

then we are left with a situation which is exactly as explained in the previous case (i.e., constant and an application).
The following is the compilation, where the net p is the common prefix, with principal ports pointing towards T (t) (so the rules in Subsection 4.3 will apply). In the diagram below we assume that there is nothing else to the pattern, as this situation has already been dealt with previously.
p	/(,,
//  J /

T (t)
T (r1)
T (r2)



The interaction rules are now identical to the ones previously given for the case agent, except that in addition we must connect the additional bindings to the correct branch.
This completes the encoding of structures, which requires the combination of the above features. In addition, when the terms ri have common free variables we must use extra agents to allow these variables to be shared. The compilation for such a feature is standard and will be omitted here; we refer the reader to [21] for details.
Pattern matching is slightly more efficient if we use an alternative encoding for patterns, where a constructor of arity n in the functional language is represented by an agent of arity n (instead of a 0-ary constant). This has the advantage of avoiding interactions between case agents and the algebraic application agent.

In Section 4.5 below we give an example showing how the encoding of the ρ- calculus used here allows us to exploit the implicit parallelism between matching and functional computations.
The Parallel Strategy at Work
To illustrate the potential for parallelism, we give an example using a variant of the Ackermann function on coloured trees, which is based on the datatype:
Tree = N il | Red(Int, Tree, Tree) | Black(Int, Tree, Tree)
Let ack be the Ackermann function. The function ackt takes two trees and com- putes a new tree where the nodes contain integers obtained by applying ack to the corresponding nodes of the arguments, but only when the trees have the same alter- nating colours (it is undefined otherwise). This function is defined in our functional language as shown in Figure 8.
Consider two trees with Red roots. The compilation of the functional program defining ackt into the ρ-calculus and subsequent encoding in interaction nets pro- duces a net with an active pair between the agent case representing the first case in the program and an agent Red (the root of the first tree).
After the interaction between the first case agent and Red, the actual value of x1 gets connected to the multiplication agent in the first branch of the case, so that we can start computing 2 ∗ x1 in parallel with the rest of the matching. Then, after the interaction between the second case agent and Red, we also get the value of x2 connected to the net representing the Ackermann function and we can then compute in parallel the value of ack(2 ∗ x1, x2) while the rest of the pattern (i.e., Black, Black) is checked.

Conclusion
We have proposed to use the ρ-calculus as an alternative foundation for functional programming languages, and provided a compilation of a simple functional pro- gramming language into the ρ-calculus. This calculus is better adapted than the λ-calculus for representing features, specifically pattern matching, of functional lan- guages. One of the main features of our compilation is that we can experiment with different pattern-matching algorithms and matching strategies, in a modular way. We have thus a powerful formalism for programming language design, and for rea- soning about functional program implementation. Using this as an intermediate language, we have demonstrated that we can compile, also in a modular way, into interaction nets, and obtain new strategies of evaluation of programs with pattern- matching. Since the translation into interaction nets is modular, the strategy spec- ified here can be combined with any β-reduction strategy, including an optimal one.
The interaction net encoding, although derived from a strategy of evaluation in the ρ-calculus, could of course be defined directly on the functional programs,

ackt  fix(fn ackt.fn t1.fn t2.case t1 of
(
Red(x1, Black(y1, tL, tR), Black(z1, sL, sR)) ~
case t2 of
(
Red(x2, Black(y2, t' , t' ), Black(z2, s' , s' )) ~
L  R	L	R
Red(ack(2 ∗ x1, x2),
Black(ack(2 ∗ y1, y2), ackt(tL, t' ), ackt(tR, t' )),
L	R
Black(ack(2 ∗ z1, z2), ackt(sL, s' ), ackt(sR, s' )))
L	R
)
Black(x1, Red(y1, tL, tR), Red(z1, sL, sR)) ~
case t2 of
(
Black(x2, Red(y2, t' , t' ), Red(z2, s' , s' )) ~
L  R	L	R
Black(ack(2 ∗ x1, x2),
Red(ack(2 ∗ y1, y2), ackt(tL, t' ), ackt(tR, t' )),
L	R
Red(ack(2 ∗ z1, z2), ackt(sL, s' ), ackt(sR, s' )))
L	R
)
N il ~
case t2 of
(N il ~ N il)
)

Fig. 8. Ackermann

without the intermediate compilation. We hope that the compilation into the ρ- calculus will allow us to transfer other results into the functional language (e.g., extensions to accommodate imperative features).

Acknowledgement
We thank Gilles Dowek for useful discussions on the subject of this paper.

References
A. Asperti, C. Giovannetti, and A. Naletto. The Bologna optimal higher-order machine. Journal of Functional Programming, 6(6):763–810, Nov. 1996.
H. P. Barendregt. The Lambda Calculus: Its Syntax and Semantics. North-Holland, revised edition, 1984.
G. Barthe, H. Cirstea, C. Kirchner, and L. Liquori. Pure patterns type systems. In Principles of Programming Languages - POPL2003, New Orleans, USA. ACM, Jan. 2003.
V. Breazu-Tannen, D. Kesner, and L. Puel. A typed pattern calculus. In Proceedings of the 8th Annual IEEE Symposium on Logic in Computer Science (LICS’93), Montr´eal, Canada, 1993.
H. Cirstea, G. Faure, and C. Kirchner. A rho-calculus of explicit constraint application. In Proceedings of the 5th workshop on rewriting logic and applications. Electronic Notes in Theoretical Computer Science, 2004.
H. Cirstea and C. Kirchner. The rewriting calculus — Part I and II. Logic Journal of the Interest Group in Pure and Applied Logics, 9(3):427–498, May 2001.
H. Cirstea, C. Kirchner, and L. Liquori. Matching Power. In A. Middeldorp, editor, Proceedings of RTA’2001, Lecture Notes in Computer Science, Utrecht (The Netherlands), May 2001. Springer-Verlag.
H. Cirstea, C. Kirchner, and L. Liquori. Rewriting calculus with(out) types. In F. Gadducci and
U. Montanari, editors, Proceedings of the fourth workshop on rewriting logic and applications, Pisa (Italy), Sept. 2002. Electronic Notes in Theoretical Computer Science.
H. Cirstea, L. Liquori, and B. Wack. Rewriting calculus with fixpoints: Untyped and first-order systems. In Post-proceedings of TYPES, Lecture Notes in Computer Science. Springer-Verlag, 2003.
M. Fern´andez and I. Mackie. Interaction nets and term rewriting systems. Theoretical Computer Science, 190(1):3–39, January 1998.
M. Fern´andez, I. Mackie, and F.-R. Sinot. Interaction nets vs. the rho-calculus: Introducing bigraphical nets. In Proceedings of EXPRESS’05, satellite workshop of Concur, San Francisco, USA, 2005, Electronic Notes in Computer Science. Elsevier, 2005.
G. Gonthier, M. Abadi, and J.-J. L´evy. The geometry of optimal lambda reduction. In Proceedings of the 19th ACM Symposium on Principles of Programming Languages (POPL’92), pages 15–26. ACM Press, Jan. 1992.
C. B. Jay and D. Kesner. Pure pattern calculus. In Proceedings of the European Symposium on Programming (ESOP) LNCS 3924, 2006.
J.-W. Klop, V. van Oostrom, and F. van Raamsdonk. Combinatory reduction systems, introduction and survey. Theoretical Computer Science, 121:279–308, 1993.
Y. Lafont. Interaction nets. In Proceedings of the 17th ACM Symposium on Principles of Programming Languages (POPL’90), pages 95–108. ACM Press, Jan. 1990.
S. Lippi. in2 : A graphical interpreter for interaction nets. In S. Tison, editor, Rewriting Techniques and Applications (RTA’02), volume 2378 of Lecture Notes in Computer Science, pages 380–386. Springer, 2002.
L. Liquori. iRho: The Software (system demonstration). In Proceedings of Developments in Computational Models (DCM’05), Lisbon, Portugal, 2005, Electronic Notes in Theoretical Computer Science. Elsevier, 2005.
I. Mackie. The Geometry of Implementation. PhD thesis, Department of Computing, Imperial College of Science, Technology and Medicine, September 1994.
I. Mackie. YALE: Yet another lambda evaluator based on interaction nets. In Proceedings of the 3rd International Conference on Functional Programming (ICFP’98), pages 117–128. ACM Press, 1998.
I. Mackie. Efficient λ-evaluation with interaction nets. In V. van Oostrom, editor, Proceedings of the 15th International Conference on Rewriting Techniques and Applications (RTA’04), volume 3091 of Lecture Notes in Computer Science, pages 155–169. Springer-Verlag, June 2004.
I. Mackie. An interaction net implementation of additive and multiplicative structures. Journal of Logic and Computation, 15(2):219–237, April 2005.
V. van Oostrom. Lambda calculus with patterns. Technical Report IR 228, Vrije Universiteit, Amsterdam, November 1990.


S. L. Peyton Jones. The Implementation of Functional Programming Languages. Prentice Hall International, 1987.
J. S. Pinto. Sequential and concurrent abstract machines for interaction nets. In J. Tiuryn, editor, Proceedings of Foundations of Software Science and Computation Structures (FOSSACS), volume 1784 of Lecture Notes in Computer Science, pages 267–282. Springer-Verlag, 2000.
J. S. Pinto. Parallel evaluation of interaction nets with mpine. In A. Middeldorp, editor, RTA, volume 2051 of Lecture Notes in Computer Science, pages 353–356. Springer, 2001.
R. Plasmeijer and M. Eekelen. Functional Programming and Parallel Graph Rewriting. Addison Wesley, 1993.
B. Wack. Typage et d´eduction dans le calcul de r´e´ecriture. PhD thesis, Universit´e Henri Poincar´e - Nancy I, 2005.
