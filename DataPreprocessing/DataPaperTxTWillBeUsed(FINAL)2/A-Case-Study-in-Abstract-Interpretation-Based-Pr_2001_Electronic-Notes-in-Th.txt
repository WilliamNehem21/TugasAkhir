Electronic Notes in Theoretical Computer Science 45 (2001)
URL: http://www.elsevier.nl/locate/entcs/volume45.html 24 pages


A Case Study in Abstract Interpretation Based Program Transformation: Blocking Command Elimination 1
Patrick Cousot 2
D´epartement d’informatique E´cole Normale Sup´erieure 45 rue d’Ulm
75230 Paris cedex 05, France
Radhia Cousot 3
Laboratoire d’informatique, LIX CNRS & E´cole Polytechnique 91128 Palaiseau cedex, France


Abstract
We illustrate the design of correct semantics-based program transformations by abstract interpretation on blocking code elimination.


Introduction
Static program analysis is closely related to program transformation since a preliminary program analysis is necessary in order to collect information about the program runtime behaviors which is then used to decide which offline trans- formations are applicable [12,14]. Abstract interpretation [4,6,8,9] has been used as a formal basis for static program analysis. Abstract interpretation can also be used to define a semantics-based program transformation framework. This is a new approach to the formal design of program transformations and a

1 This work is dedicated to Neil D. Jones on the occasion of his 60th anniversary. It was presented as part of the invited talk at the “Special session honoring Neil D. Jones” of the Seventeenth Conference on the Mathematical Foundations of Programming Semantics,
˚Arhus, Denmark , May 23 – 27, 2001. It was supported in part by the european FP5 project
IST-1999-20527 Daedalus.
2 cousot@ens.fr, www.di.ens.fr/~cousot
3 rcousot@lix.polytechnique.fr, lix.polytechnique.fr/~rcousot
◯c 2001 Published by Elsevier Science B. V. Open access under CC BY-NC-ND license.


new application of the abstract interpretation theory. The idea is to formally design syntactic (that is source level) program transformations by abstrac- tion of transformations of the program semantics. Abstract interpretation is used to formalize the correspondence between semantic and syntactic transfor- mations. This yields the necessary formal basis for (hopefully mechanically) constructing correct program transformation tools and may be to systematize their design.
The framework is applied to blocking code elimination, which consists in eliminating blocking commands other than stop commands in imperative non- deterministic programs leaving non-terminating behaviors unchanged. The fi- nal algorithm is very simple and could have been designed empirically without error but this case study is simple enough to exemplify our approach.
We believe that this unified abstract interpretation based framework for reasoning on program transformation should be applicable to a wide variety of semantics-based program manipulations including constant propagation [15], transition compression [11], slicing [22], partial evaluation [13], continuation passing style transformation [18], call-by-name to call-by-value transformation [19], fold/unfold [3], deforestation [21], compilation [17], etc.

A Few Elements of Abstract Interpretation
Fixpoints

≤
We write lfp
F for the ≤-least fixpoint of F ≤-greater than or equal to ⊥,
≤

when it exists. We write lfp F and lfp F when ⊥ and ≤ are understood from
≤
the context. Dually, gfp F is the ≤-greatest fixpoint of F ≤-less than or equal
to T, when it exists.
Theorem 2.1 (Least fixpoint) Let po⟨L; ≤⟩ be a partially ordered set L with a binary relation ≤ which is a partial order (reflexive, antisymmetric and transitive). Assume that F is a monotone operator on po⟨L; ≤⟩. Assume that
⊥ ∈ L is such that ⊥ ≤ F (⊥). Let L ⊆ L be a subset of L such that ⊥ ∈ L,
∀x ∈ L : x ≤ F (x) ⇒ F (x) ∈ L and if ⟨xi, i ∈ ∆⟩ is an ≤-increasing chain of elements of L then the least upper bound (lub) ∨i∈∆xi exists in po⟨L; ≤⟩ and
≤
satisﬁes ∨i∈∆xi ∈ L. Then lfp F exists, is unique and belongs to L.
Proof. The proof easily derives from [7]. It is based on the iterative definition
of  fixpoints  in  the  tradition  of  Tarski  [20]  and  Kleene  [16]  F 0  =  ⊥,  F δ+1  =
F (F δ) for successor ordinals δ +1 ∈ O, F λ =∆ ∨	F δ for limit ordinal λ ∈ O.✷

≤
Most often, we express the semantics in least fixpoint form lfp
F where the

semantic transformer F ∈ L −−m→ L is a monotone operator on the complete partial order (cpo) cpo⟨L; ≤, ⊥, ∨⟩. Dually, we can also use a greatest fixpoint gfp≤ F of a monotone semantic transformer F ∈ L −−m→ L on the dual complete partial order (co-cpo) ccpo⟨L; ≤, T, ∧⟩.


Theorem 2.2 (Least fixpoint iterates) Under the hypotheses of Th. 2.1,

for all x ∈ L  such that ⊥ ≤ x  ≤ lfp≤ F, the iterates F 0  =
x, F δ+1  =
F (F δ)

for successor ordinals δ +1 ∈ O and F λ =∆
∨δ<λ
F δ for limit ordinal λ ∈ O are

ultimately stationary and converge to lfp≤ F 4 .
Proof. By monotony and transfinite induction, the iterates of F starting from x are sandwiched between the iterates of F starting from ⊥ which are
≤
ultimately stationary and converge to lfp F and the iterates of F starting

≤
from lfp
≤
F which are all equal to lfp
F by the fixpoint property, proving the

ultimate convergence of all the iterates to that fixpoint.	✷

Abstraction
An abstraction α(S) of a concrete semantics S is defined by a Galois connec-

tion po⟨L; ≤⟩ ←−γ −
α
po⟨L; ≤⟩ between the concrete domain po⟨L; ≤⟩ and the


abstract domain po⟨L; ≤⟩ which are both posets 5 . By definition, we have
	
∀X ∈ L : ∀Y ∈ L : α(X) ≤ Y ⇔ X ≤ γ(Y ). It follows that α preserves exist- ing lubs, by duality γ preserves existing greatest lower bounds (glbs) and one adjoint uniquely determines the other. We write po⟨L; ≤⟩ ←−−γ −− po⟨L; ≤⟩ when α is surjective (or equivalently γ is injective) and po⟨L; ≤⟩ ←←−γ−− po⟨L;
α
≤⟩ when α is injective (or equivalently γ is surjective).
∆
Given f ∈ A −−→ B, a standard example is α(X) = {f (x) | x ∈ X} so
that


(1)
po⟨℘(A); ⊆⟩ ←−γ −
α
po⟨℘(B); ⊆⟩


where γ(Y ) = {x ∈ A | f (x) ∈ Y }.

Fixpoint Coabstraction
We have the following sufficient condition for two fixpoints to have the same
≤	≤
abstraction α (lfp	F ) = α (lfp	F ) which is based on the iterative definition
of fixpoints [7] :
m
Theorem 2.3 (Fixpoint coabstraction) Let F1 ∈ L1 −−→ L  and F2 ∈
L −−m→ L  be respective monotone operators on the complete partial orders
cpo⟨L1; ≤1, ⊥1, ∨1⟩ and cpo⟨L2; ≤2, ⊥2, ∨2⟩. Let cpo⟨L; ≤, ⊥, ∨⟩ be a complete

partial order. Let α1
⊥,↑
∈ L1 −−→
L and α2
⊥,↑
∈ L2 −−→
L be ⊥-strict 6 Scott-



4 Note that the iterates starting from x need not be an increasing chain.
5 Other equivalent formalizations (e.g. using closure operators) are given in [8] and weaker ones, not assuming the existence of a best approximation, are provided in [9].
6 A function f is ⊥-strict, written f : D −−⊥→ E, if and only if f (⊥) = ⊥.


continuous 7 abstraction functions satisfying the following local coabstraction condition 8 :
∀x ∈ L1 : ∀y ∈ L2 : α1(x) = α2(y) ⇒ α1(F1(x)) = α2(F2(y)) .

Then α (lfp≤1 F ) = α (lfp≤2 F ).
Proof. Let F δ, δ ∈ O and F δ, δ ∈ O be the respective transfinite iterates for
1	2
F1 and F2 [7]. By monotony, they are increasing chains which are therefore well-defined in the respective complete partial orders cpo⟨L1; ≤1, ⊥1, ∨1⟩ and cpo⟨L2; ≤2, ⊥2, ∨2⟩.
α1 and α2 are ⊥-strict so that α1(⊥1) = ⊥ = α2(⊥2) hence F 0 = F 0.
1	2
Let δ + 1 be a successor ordinal such that α1(F δ) = α2(F δ) by induction
1	2
hypothesis. By the local coabstraction condition (2), we have α1(F δ+1) =
α1(F1(F δ)) = α2(F2(F δ)) = α2(F δ+1).
1	2	2
Let λ be a limit ordinal such that by induction hypothesis, ∀δ < λ: α1(F δ)
= α2(F δ). Then, by continuity of α1 and α2 and induction hypothesis, we have

2
λ	δ	δ
δ	δ	λ

α1(F1 ) = α1(	1 F1 ) =	δ<λ α1(F1 ) = 
δ<λ
δ<λ α2(F2 ) = α2(	2 F2 ) = α2(F2 ).
δ<λ

By transfinite induction, we conclude that ∀δ ∈ O: α1(F δ) = α2(F δ).

Let ϵ1
∈ O and ϵ2
∈ O be such that ϵ1
= lfp≤1 F
and ϵ2
1
= lfp≤2 F
2
[7]. We

have α (lfp≤1 F ) = α (F є1 ) = α (F max(є1,є2)) = α (F max(є1,є2)) = α (F є2 ) =
1	1	1	1	1	1	2	2	2	2
α (lfp≤2 F ).	✷
2	2

Locally Complete Fixpoint Abstraction
In particular when α1 = α and α2 is the identity, Th. 2.3 yields a suffi cient con-
≤	≤ 
dition for complete (or exact) fixpoint abstractions α(lfp F ) = lfp F , which
≤	≤
provides guidelines for designing lfp F from lfp F (or dually) in fixpoint form
[8, theorem 7.1.0.4(3)], [10, lemma 4.3], [2, fact 2.3] 9 :
Corollary 2.4 (Fixpoint transfer) Let F ∈ L −−m→ L be a monotonic op-
erator on the cpo⟨L; ≤, ⊥, ∨⟩, let F ∈ L −−m→ L be a monotone operator
⊥,↑ 
on the cpo⟨L; ≤, ⊥, ∨⟩ and let α ∈ L −−→ L be a ⊥-strict Scott-continuous
abstraction function satisfying the commutation condition F ◦ α = α ◦ F 10 .



7 A function f is Scott-continuous, written f :
↑
D −−→ E
, if and only if it preserves the lub

of any directed subset of D [1] (so that it is monotone).
8 As in Th. 2.1, it is sufficient to assume that αi is ⊥-strict, preserves the least upper bound of the iterates of Fi starting from ⊥i, i = 1, 2 and that the local coabstraction condition holds for these iterates or a given superset of the iterates.
9 The composition of relations r1 and r2 is r1 ◦ r2 =∆ {⟨x, z⟩| ∃y : ⟨x, y⟩∈ r1 ∧ ⟨y, z⟩∈ r2}
whence the composition of functions is f ◦ g(x) = f (g(x)).
10 As in Th. 2.1, it is sufficient to assume that α is ⊥-strict, preserves the least upper bound of the iterates of F starting from ⊥ and that the commutation condition holds for these iterates.

≤	≤
Then α(lfp F ) = lfp F.
Fixpoint Approximation
≤
Due to undecidability, it is often impossible to abstract a fixpoint α(lfp F )
≤	≤
= lfp F exactly and to require simultaneously the abstract fixpoint lfp F to
be effectively computable. In that case, abstract interpretation theory offers
≤	≤ 
fixpoint approximation methods so that α(lfp F ) ≤ lfp F [6,8,9]. Let us recall
these basic fixpoint approximation results in a generalized form:
Theorem 2.5 (Least fixpoint upper approximation) Let F ∈ L −−m→ L be a monotonic operator on the complete partial order cpo⟨L; ≤, ⊥, ∨⟩ and let F ∈ L −−m→ L be a monotone operator on cpo⟨L; ≤, ⊥, ∨⟩.
⊥,↑
Assume that the ⊥-strict Scott-continuous abstraction function α ∈ L −−→
L is such that for all x ∈ L such that x ≤ F (x) there exists y ≤ x such that
α(F (x)) ≤ F (α(y)).
≤	≤
Then α(lfp F ) ≤ lfp F.
Proof. Let F δ and F δ, δ ∈ O be the respective ordinal-termed ≤ and ≤-in- creasing ultimately stationary chains of transfinite iterates of F and F [7]. We have α(F 0) = α(⊥) = ⊥ = F 0 by strictness of α and definition of the iterates. Assume α(F δ) ≤ F δ by induction hypothesis. We have F δ ≤ F (F δ) = F δ+1 so that, by hypothesis, ∃y ≤ F δ such that α(F δ+1) ≤ F (α(y)). By monotony of F and α, F (α(y)) ≤ F (α(F δ)) whence by transitivity, induction hypothesis, monotony of F and definition of the iterates, α(F δ+1) ≤ F (α(F δ)) ≤ F (F δ) = F δ+1. Given a limit ordinal λ, assume α(F δ) ≤ F δ for all δ < λ. Then by definition of the iterates, continuity of α, induction hypothesis and definition of lubs, α(F λ) = α(  F δ) =  α(F δ) ≤  F δ = F λ.	By transfinite

δ<λ
δ<λ
δ<λ

induction, we conclude ∀δ ∈ O : α(F δ) ≤ F δ.
Let ϵ and ϵ' be the respective ordinals such that F є = lfp≤ F and F є' =
lfp≤ F . In particular α(lfp≤ F ) = α(F є) = α(F max{є,є'}) ≤ F max{є,є'} = F є' =
≤
lfp F .	✷
The dual of the above Th. 2.5 leads to the approximation of greatest ﬁx- points from below. We also need to approximate greatest fixpoints from above, as follows:
Theorem 2.6 (Greatest fixpoint upper approximation 1) Assume that F ∈ L −−m→ L is a monotonic operator on the co-cpo ccpo⟨L; ≤, T, ∧⟩ and that F ∈ L −−m→ L is a monotone operator on ccpo⟨L; ≤, T, ∨⟩.
↓	
Let the Scott-co-continuous abstraction function α ∈ L −−→ L be such
that for all x ∈ L such that F (x) ≤ x there exists y ≤ x such that α(F (x)) ≤
F (α(y)).

Then α(gfp
≤	 
F ) ≤ gfp
≤
F.
α(T)

Proof. Let F δ and F δ, δ ∈ O be the respective ordinal-termed ≤ and ≤-de- creasing ultimately stationary chains of transfinite iterates of F and F respec- tively starting from T and T [7].
We have α(F 0) = α(T) = F 0 by definition of the iterates.
Assume α(F δ) ≤ F δ by induction hypothesis. We have F δ+1 = F (F δ) ≤ F δ so that, by hypothesis, there exists y ≤ F δ such that α(F δ+1) ≤ F (α(y)). By monotony of F and α, F (α(y)) ≤ F (α(F δ)) whence by transitivity, in- duction hypothesis, monotony of F and definition of the iterates, α(F δ+1) ≤ F (α(F δ)) ≤ F (F δ) = F δ+1.
Given a limit ordinal λ, assume α(F δ) ≤ F δ for all δ < λ. Then by defini- tion of the iterates, co-continuity of α, induction hypothesis and definition of glbs, α(F λ) = α(  F δ) =   α(F δ) ≤   F δ = F λ.

δ<λ
δ<λ
δ<λ

By transfinite induction, we conclude that ∀δ ∈ O : α(F δ) ≤ F δ.
 Let ϵ and ϵ' be the respective ordinals such that F є = gfp≤ F and F є' =
gfp≤ F . In particular α(gfp≤ F ) = α(F є) = α(F max{є,є'}) ≤ F max{є,є'} = F є' =
≤
gfp F .	✷
A useful variant is:
Theorem 2.7 (Greatest fixpoint upper approximation 2) Assume that F ∈ L −−m→ L is a monotonic operator on the co-cpo ccpo⟨L; ≤, T, ∧⟩ and that F ∈ L −−m→ L is a monotone operator on ccpo⟨L; ≤, T, ∧⟩.
Let po⟨L; ≤⟩ ←−γ−− po⟨L; ≤⟩ be such that for all x ∈ L such that F (x) ≤ x
α
there exists y ≤ x such that α(F (x)) ≤ F (α(y)).

Then α(gfp
≤	 
F ) ≤ gfp


≤	
F.
α(T)

Proof. The proof is similar to that of Th. 2.6 except for limit ordinals. Given a limit ordinal λ such that α(F δ) ≤ F δ for all δ < λ, we have F δ ≤ γ(F δ) for all δ < λ, by definition of Galois connections. Since ⟨F δ, δ < λ⟩ and

δ
⟨F , δ < λ⟩ are decreasing chains and γ is monotone, ⟨γ(F
δ
), δ < λ⟩ is also

decreasing so that   F δ and   γ(F δ) on one hand and   F δ on the other

δ<λ
δ<λ
δ<λ

hand do exist respectively in the co-cpos ccpo⟨L; ≤, T, ∧⟩ and ccpo⟨L; ≤,
T, ∧⟩. By definition of glbs and γ preserving existing glbs, we have	F δ
δ<λ
≤	γ(F δ) = γ(  F δ ). By definition of Galois connections, it follows that
δ<λ	δ<λ
α(  F δ) ≤   F δ. By definition of the iterates, we conclude that α(F λ) = 
δ<λ	δ<λ
α(   F δ) ≤   F δ = F λ.	✷
δ<λ	δ<λ

The Syntax and Semantics of Programs
Let us consider imperative iterative programs acting on global variables. Pro- grams are assumed to be compiled in an intermediate form as shown by the following example:
X := ?;	a : X := ? → b;
while X > 0 do	b : (X > 0) → c;
b: ¬ (X > 0) → d;
X := X + 1;	c : X + 1 → b;
od;	d : stop;

Programs are nondeterministic. The intuition is that if execution is at some label L then one of the transitions L : A → L'; labeled with L is executed, provided the action A is not blocking and the execution can go on by branching to the next label L'. Otherwise the execution is blocked at L, which is the case for the stop command L : stop; intended to correspond to normally expected termination while other blocking commands are supposed to be erroneous.
Nondeterminism is modeled by having several actions be referenced by the same label. For example, the random assignment {L1 : X := ? → L2;} which is a shorthand for {L1 : X := z → L2; | z ∈ Z}, where Z is the set of integers, can be used to model interactive integer inputs.

Abstract Syntax of Programs


X : X	Program variables
E : E	Arithmetic expressions
B : B	Boolean expressions
A : A	Program actions
A ::= X := E	Assignment
|	X := ?	Random assignment
|	B	Test
|	¬ B	Negated test
|	skip	Null action
|	stop	Stop action

Programs are collections of labelled nondeterministic commands:

L	:	L	Program labels
C	:	C	Commands
∆	∆
C ::= L1 : A → L2;	label C) = L1, action C) = A,	Transition command
succ C) = {L2}
∆	∆
|	L1 : stop;	label C) = L1, action C) = stop,	Stop command




P	:	P =∆
succ C) = ∅
℘(C)	labels P) =∆ {label C) | C ∈ P}	Programs


Semantics of Program Actions
The commands of a program act on global variables X ∈ X which take their values in the semantic domain V.
An environment ρ ∈ E maps variables X to their value ρ(X) so E = X −−→
V. ρ[X := d] is the environment ρ where the variable X is assigned the value d:
∆	∆
ρ[X := d](X) = d and ρ[X := d](Y) = ρ(Y) when X /= Y.
The semantics of expressions is assumed to be given by A E) ∈ E −−→ V for arithmetic expressions E and by B B) ∈ E −−→ B where B = {tt, ff} for boolean expressions B.
The semantics S A)ρ of an action A defines the effect of executing this action on the environment ρ. Nondeterministic statements such as the random assignment X := ? have more than one possible successor environment so we define S ∈ A −−→ (E −−→ ℘(E)) as follows:
S B) = λ ρ • {ρ | B B)ρ = tt}	S X := ?) = λ ρ • {ρ[X := z] | z ∈ Z}
∆	∆
S ¬ B) = λ ρ • {ρ | B B)ρ = ff}	S skip) = λ ρ • {ρ}
∆	∆
S X := E) = λ ρ • {ρ[X := A E)ρ]}	S stop) = λ ρ • ∅
States
A state s ∈ S is a pair s = ⟨ρ, C⟩ where the environment ρ records the values of variables while C is the next command to be executed:
S = E × C
The set of states S P) of a program P ∈ P is defined as:

S P) = E × P

Transitional Semantics
The transitional semantics S P)s of a program P ∈ P specifies which successor states s' can follow state s during execution of program P:
S P) ∈ S P) −−→ ℘(S P))


S P)⟨ρ,  C⟩ =
{⟨ρ', C'⟩| ρ' ∈ S action C))ρ ∧ label C') ∈ succ C)}

Observe that by Def. (3) of S P), we have C ∈ P and C' ∈ P in (4). In particular
∀ρ ∈ E : S P)⟨ρ, L : stop;⟩ = ∅.


Example 3.1 The program:

P = {a, a', b, c}

which commands are defined as follows:


a = a : Y > 0 → b;	a' =∆
a : ¬ (Y > 0) → c;

b = b : Y := Y − 1 → a;	c = c : stop;

has the following transitional semantics:

S P)⟨ρ, a⟩ = {⟨ρ, b⟩| ρ(Y) > 0},	S P)⟨ρ, a'⟩ = {⟨ρ, c⟩| ρ(Y) ≤ 0},
S P)⟨ρ, b⟩ = {⟨ρ[Y := ρ(Y) − 1], a⟩},	S P)⟨ρ, c⟩ = ∅ .
✷

Sequences of States
Program executions are recorded in finite or infinite sequences of states over a given set C of commands. Formally, we define (→ϵ ∈ ∅ '−−→ S C) is the empty sequence of states, [n, m] = {k ∈ Z | n ≤ k ≤ m} so [n, m] = ∅ when m < n):


Σn C) =∆

Σ∗ C) =∆ Σ∞ C) =∆

[0,n − 1] −−→ S C),	Σ+ C) =∆

Σ+ C) ∪ {→ϵ},	Σω C) =∆
Σ+ C) ∪ Σω C),	Σ∝ C) =∆

  Σn C),
n>0
N −−→ S C),
Σ∞ C) ∪ {→ϵ} .

We define the length #σ of a sequence σ ∈ Σ∝ C) as 0 when σ = →ϵ, n > 0 when σ ∈ Σn C) and the first infinite limit ordinal ω when σ ∈ Σω C).
For short, we define (C is the set of commands defined in Sec. 3.1):


Σn =∆ Σω =∆
Σn C),	Σ+ =∆
Σω C),	Σ∞ =∆
Σ+ C),	Σ∗ =∆
Σ∞ C),	Σ∝ =∆
Σ∗ C),
Σ∝ C) .

Complete Trace Semantics of Programs
A ﬁnite complete execution trace σ ∈ Sn P) of a program P ∈ P is a finite sequence σ0 ... σn−1 ∈ Σn P) of states of length #σ = n such that:
each state σi,i = 1,...,n − 1 is the successor of the previous state σi−1 so
σi ∈ S P)σi−1, and
the last state σn−1 is a blocking state so S P)σn−1 = ∅.



The finite complete traces are not empty so S+ P) =∆ S∗ P) =∆ S+ P) ∪ {→ϵ} where →ϵ is the empty trace.

n>0
Sn P). We define

An inﬁnite execution trace σ ∈ Sω P) of a program P ∈ P is an infinite
sequence σ0 ... σi ... ∈ Σω P) of states of infinite length #σ = ω such that each state σi+1 ∈ S P)σi is the successor of the previous state σi, 0 ≤ i < ω.
The complete execution traces of a program P ∈ P are S∞ P) =∆ S+ P)∪Sω P)
and S∝ P) =∆ S∞ P) ∪ {→ϵ} = S∗ P) ∪ Sω P).
Formally, the trace semantics of a program P ∈ P is defined as follows:



S∞ P) =∆ S+ P) =∆
Sn P) =∆ Sω P) =∆
S+ P) ∪ Sω P),
  Sn P),
n>0
{σ ∈ Σn P) | ∀i ∈ [0,n − 2] : σi+1 ∈ S P)σi ∧
S P)σn−1 = ∅}	when n > 0,
{σ ∈ Σω P) | ∀i ≥ 0 : σi+1 ∈ S P)σi} .

Example 3.2 The trace semantics of program P defined by (5) is the follow- ing:
S∞ P) =  {⟨ρ[Y := n], a⟩⟨ρ[Y := n], b⟩⟨ρ[Y := n − 1], a⟩ ... 
... ⟨ρ[Y := 0], a'⟩⟨ρ[Y := 0], c⟩| ρ ∈ E ∧ n > 0}
∪ {⟨ρ[Y := n], a'⟩⟨ρ[Y := n], c⟩| ρ ∈ E ∧ n ≤ 0}
∪ {⟨ρ[Y := n + 1], b⟩⟨ρ[Y := n], a⟩⟨ρ[Y := n], b⟩⟨ρ[Y := n − 1], a⟩ ... 
... ⟨ρ[Y := 0], a'⟩⟨ρ[Y := 0], c⟩| ρ ∈ E ∧ n > 0}
∪ {⟨ρ[Y := n + 1], b⟩⟨ρ[Y := n], a'⟩⟨ρ[Y := n], c⟩| ρ ∈ E ∧ n ≤ 0}
∪ {⟨ρ, c⟩| ρ ∈ E} .
✷

Suﬃx-Closure
The suffix σ+ of a trace σ ∈ Σ∞ is defined by s+ = s for traces of length 1 and sσ+ = σ. Intuitively, σ+ describes an execution starting one step after σ, if possible. When necessary we let →ϵ+ = →ϵ.
The suffix of a set T of traces is T + =∆ {σ+ | σ ∈T }.
a set T of traces is the least suffix-closed superset T = lfp⊆ λ X • T ∪ X + of A set T of traces is suﬃx-closed whenever T + ⊆ T . The suﬃx-closure of T .


Lemma 3.3 (Suffix-closed trace semantics) The trace semantics (8) is suﬃx-closed.
Proof. For finite traces s ∈ S∞ P) of length 1, we have s+ = s ∈ S∞ P).
For finite traces sσ ∈ S∞ P), we have sσ+ = σ which belongs to S∞ P) since each state σi,i = 1,...,n − 1 is the successor of the previous state σi−1 and the last state σn−1 is a blocking state, by definition of sσ ∈ S∞ P).
The same way for infinite traces sσ ∈ S∞ P), we have sσ+ = σ which belongs to S∞ P) since each state σi+1 ∈ S P)σi is the successor of the previous state σi, 0 ≤ i < ω, by definition of sσ ∈ S∞ P).	✷

Complete Trace Semantics of Programs in Fixpoint Form (1)
The trace transformer F∞ P) of a program P ∈ P is defined as follows:
F∞ P) ∈ ℘(Σ∞ P)) −−→ ℘(Σ∞ P))


F∞ P)T =
{s | S P)s = ∅} ∪ {sσ | σ0 ∈ S P)s ∧ σ ∈T }



Example 3.4 The trace transformer of the program P defined by (5) is the following:
F∞ P)T =	{⟨ρ, c⟩| ρ ∈ E}
∪ {⟨ρ, a⟩⟨ρ, b⟩σ | ρ(Y) > 0 ∧ ⟨ρ, b⟩σ ∈T }
∪ {⟨ρ, a'⟩⟨ρ, c⟩σ | ρ(Y) ≤ 0 ∧ ⟨ρ, c⟩σ ∈T }
∪ {⟨ρ[Y := ρ(Y)+ 1], b⟩⟨ρ, a⟩σ | ⟨ρ, a⟩σ ∈T }
∪ {⟨ρ[Y := ρ(Y)+ 1], b⟩⟨ρ, a'⟩σ | ⟨ρ, a'⟩σ ∈T }
✷
We have the following fixpoint characterizations of the program trace se- mantics [5]:



S∞ P) = gfp⊆
Σ
F∞ P)

F∞ P) is ⊆-monotone which ensures the existence of the fixpoints [20].

Feasible Traces
Some finite or infinite sequences of states such as ⟨ρ, L : stop;⟩ω do not corre- spond to any execution of any program. In order to eliminate such infeasible sequences of states, we restrict traces to the finite or infinite sequences of states corresponding to potential program executions:





Tn =∆ Tω =∆
Sn C),	T+ =∆
Sω C),	T∞ =∆
S+ C),	T∗ =∆
S∞ C),	T∝ =∆
S∗ C),
S∝ C) .

Complete Trace Semantics of Programs in Fixpoint Form (2)
The trace transformer F∞ P) of a program P ∈ P can also be defined using feasible traces only or arbitrary state sequences containing only commands of P only, as follows:
Theorem 3.5 (Fixpoint complete trace semantics of programs) For all
T ∈ ℘(Σ∞) such that S∞ P) ⊆ T , we have

⊆
S∞ P) = gfp F∞ P) .
Proof. By (8) and the dual of Th. 2.2 since Σ∞ ⊇ T ⊇ S∞ P).	✷
Corollary 3.6



S∞ P) = gfp⊆
Σ  P)
F∞ P) = gfp⊆
T
F∞ P)



Proof. Obviously Σ∞ P) ⊆ gfp⊆
F∞ P) by (8) and Def. (6) of S∞ P) which

implies that all commands appearing along a trace of S∞ P) belongs to P
proving that this trace belongs to Σ∞ P).

⊆
By (8), gfp
Σ
F∞ P) contains only feasible traces so gfp⊆
Σ
F∞ P) ⊆ T∞.

Applying Th. 3.5, we conclude that S∞ P) = gfp⊆
Σ  P)
F∞ P) = gfp⊆
T
F∞ P).✷

Correspondence between Syntax and Trace Seman- tics of Programs
The trace semantics maps programs to sets of traces. Inversely, we map sets of traces to programs by collecting commands appearing along traces.
Trace-wide Command Collection
The abstraction	∞ collects all commands on all traces, as follows:
∞ ∈ ℘(T∞) −−→ P	∈ T∞ −−→ P	∈ S −−→ C


∞[T ] =∆
 

σ∈T
[σ]	[σ] =
{ [σi] | 0 ≤ i < #σ}	[⟨ρ, C⟩] = C

This correspondence is formalized by the following Galois connection:
Lemma 4.1
po⟨℘(T∞	S∞

Proof.	∞ and S∞ are obviously ⊆-monotone.
For all programs P ∈ P, we have S∞ P) ∈ (E×P)+ ∪(E×P)ω so	∞[S∞ P)] ⊆
P.
Inversely, for all C ∈ P, there may exist an environment ρ ∈ E such that
S P)⟨ρ, C⟩ = ∅ in which case the trace ⟨ρ, C⟩ belongs to S∞ P) et so C belongs to  ∞[S∞ P)]. Otherwise, ∀ρ ∈ E : S P)⟨ρ, C⟩ /= ∅. Let ⟨ρ0, C0⟩ = ⟨ρ, C⟩ and
⟨ρ1, C1⟩∈ S P)⟨ρ0, C0⟩. We have built a sequence σn = ⟨ρ0, C0⟩ ... ⟨ρn, Cn⟩ of states, up to n = 1, such that ∀i < n : ⟨ρi+1, Ci+1⟩∈ S P)⟨ρi, Ci⟩. Having built σn, we may have S P)⟨ρn, Cn⟩ = ∅ in which case σn ∈ S∞ P) and consequently C ∈  ∞[S∞ P)] by definition of  ∞.  Otherwise, we have ∃⟨ρn+1, Cn+1⟩ ∈
S P)⟨ρn, Cn⟩, so that σn can be extended to σn+1. If we can go on in this way for ever, we obtain a limit trace σ which nonempty prefixes are the σn,n ≥ 0. We have σ ∈ S∞ P) and σ starts with ⟨ρ, C⟩ so that C ∈ ∞[S∞ P)] by definition of  ∞. We conclude that P ⊆ ∞[S∞ P)].
By antisymmetry, we conclude that  ∞[S∞ P)] = P.
Let T ⊆ T∞ and σ ∈T . For all 0 ≤ i < #σ, let σi = ⟨ρi, Ci⟩. By definition of  ∞, we have {Ci | 0 ≤ i < #σ} ⊆  ∞[T ]. Moreover, if σ is finite so that n = #σ > 0, we have S C)σn−1 = ∅ = S  ∞[T ])σn−1 since Cn−1 ∈  ∞[T ].
Whether σ is finite or not, we have σi ∈ S C)σi−1 for all 0 ≤ i < #σ. But
Ci−1 ∈ ∞[T ] so σi ∈ S  ∞[T ])σi−1. It follows that σ ∈ S∞  ∞[T ]) proving that T ⊆ S∞  ∞[T ]).	✷

Trace First Command Collection
Let us define the ﬁrst command of a trace as:

∞ ∈ ℘(T∞) −−→ P	0 ∈ T∞ −−→ C


∞[T ] =∆ {
0[σ] | σ ∈T }
0[σ] =
[σ0]

Observe that if T is suffix-closed then	∞[T ] =	∞[T ]. It immediately follows
from (12) and (1) that:




where γ∞[Q] =∆ {σ ∈ T∞ |
γ∞
po⟨℘(T∞); ⊆⟩ ←−−0 −− po⟨P; ⊆⟩
0

0[σ] ∈ Q}.

Moreover, for transformations which eliminate commands from the subject programs, we can use the following correspondence between suffix-closed sets of traces and programs:
Corollary 4.2 For all programs P ∈ P, we have:


po⟨{T ⊆ Σ∞
 P) |T +
∞
= T }; ⊆⟩ −←−−−−−−→−→− po⟨℘(P); ⊆⟩
0

Proof. For all T ⊆ Σ∞ P) such that T + = T and Q ⊆ P, we have:


∞[T ] ⊆ Q
⇔	  ∞[T ] =	∞[T ] since T is suffix-closed3
∞[T ] ⊆ Q
⇔	 by Lem. 4.13
T ⊆ S∞ Q) .
✷

Blocking Command Elimination
In the following, we consider the blocking code elimination, which consists in eliminating blocking commands other than stop commands. The final iterative algorithm is trivial but this case study is simple enough to exemplify the design of correct program transformations by abstract interpretation. In particular the iterative nature of the blocking code elimination algorithm follows from the fixpoint definition (10) of the trace semantics.
Introduction to Blocking Command Elimination
A command C of the form L1 : A → L2; of a program P is semantically blocking if and only if it has no possible successor for all evaluation environments (for- mally S P)⟨ρ, C⟩ = ∅ for all environments ρ ∈ E that can be encountered when executing command C in program P). We have singled out a stop command L : stop; corresponding to a normally expected termination. Other blocking commands are considered as undesirable (for example they might correspond to some abnormal termination such as e.g. a runtime error freezing the com-
puter screen). The use of such undesirable semantically blocking commands may be considered as bad program design, and a removal function (prefer- ably an algorithm) tb[P] would be useful to eliminate blocking commands or to check that a program P = tb[P] is well designed according to this criterion. Non-terminating program behaviors should be left unchanged. Because of
tests and iteration, the problem is obviously undecidable so that any effective algorithm b is necessarily an approximation of function tb. For example:
 1 : false → 1; 

2 : skip → 3;
1 : false → 1;
=

b	3 : skip → 5;
4 : stop;
4 : stop;


since the command 3 : skip → 5; and therefore 2 : skip → 3; are blocking. The command 1 : false → 1; is also blocking but is not removed by the syntactic blocking command elimination algorithm b. This is because it is in general not decidable whether B is false in the command 1 : B → 1;. So the syntactic elimination algorithm b only gets rid of syntactically blocking


commands where a command C of the form L1 : A → L2; of a program P is syntactically blocking if L2 /∈ labels P). The command 1 : false → 1; would have been eliminated by the incomputable semantic elimination function tb. In that sense, b is an abstraction of tb.
Obviously a preliminary static program analysis could also be used to determine a larger subset of the semantically blocking actions by taking values of variables into account (e.g. by using the constant propagation static analysis [15]). We do not consider this more refined offline transformation because infinitely many such variants of b can be designed and we choose the simplest one to illustrate our purpose.

Semantic Blocking Trace Elimination
The semantic blocking trace elimination is:
t ∈ ℘(Σ∞) −−→ ℘(Σ∞)



tb[T ] =
Cb[σ] =
(T ∩ Σm) ∪ {σ ∈T | C [σ]}
σ ∈ Σ+ ∧ action last[σ]) = stop

where last[σ] denotes the command C = last[σ] in the last state ⟨ρ, C⟩ = σ#σ−1
of the finite trace σ ∈ Σ+ of length #σ.
We define:
γt ∈ ℘(Σ∞) −−→ ℘(Σ∞)


so that:
Lemma 5.1
γtb [Y] =
Y ∪ {σ ∈ Σ+ | ¬C [σ]}

po⟨℘(Σ∞
γtb
); ⊆⟩ −←−−−−→− po⟨℘(Σ∞
tb
); ⊆⟩

Proof.
tb[X ] ⊆Y 
⇔	 def. (14) of tb3
(X ∩ Σm) ∪ {σ ∈X | Cb[σ]}⊆Y 
⇔		 def. lubs, def. intersection and X ⊆ Σ∞3 (X ∩ Σm) ⊆Y ∧ (X ∩ {σ ∈ Σ∞ | Cb[σ]}) ⊆Y 
⇔	 Cb[σ] ⇒ σ ∈ Σ+ by def. (15) of Cb3
(X ∩ Σm) ⊆Y ∧ ((X ∩ Σ+) ∩ {σ ∈ Σ∞ | Cb[σ]}) ⊆Y 
⇔	 A ∩ B ⊆ C if and only if A ⊆ (¬B ∪ C)3
(X ∩ Σm) ⊆Y ∧ (X ∩ Σ+) ⊆ (¬{σ ∈ Σ∞ | Cb[σ]}∪ Y)


⇔	 (X ∩ B) ⊆ Y if and only if (X ∩ B) ⊆ (Y ∩ B)3
(X ∩ Σm) ⊆ (Y ∩ Σm) ∧ (X ∩ Σ+) ⊆ ((¬{σ ∈ Σ∞ | C [σ]}∪ Y) ∩ Σ+)
⇔	 def. complement3
(X ∩ Σm) ⊆ (Y ∩ Σm) ∧ (X ∩ Σ+) ⊆ (({σ | σ /∈ Σ∞ ∨ ¬C [σ]}∪ Y) ∩ Σ+)
⇔	 Σ+ ⊆ Σ∞ and def. intersection3
(X ∩ Σm) ⊆ (Y ∩ Σm) ∧ (X ∩ Σ+) ⊆ (({σ ∈ Σ+ | ¬C [σ]}∪ Y) ∩ Σ+)
⇔	 Σ+ ∩ Σm = ∅3
(X ∩ Σm) ⊆ (({σ ∈ Σ+ | ¬C [σ]}∪ Y) ∩ Σm) ∧ (X ∩ Σ+) ⊆ (({σ ∈ Σ+ |
¬C [σ]}∪ Y) ∩ Σ+)
⇔	 (X ∩ B) ⊆ Y if and only if (X ∩ B) ⊆ (Y ∩ B)3
(X ∩ Σm) ⊆ ({σ ∈ Σ+ | ¬C [σ]}∪Y) ∧ (X ∩ Σ+) ⊆ ({σ ∈ Σ+ | ¬C [σ]}∪Y)
⇔	 def. lubs3
(X ∩ Σm) ∪ (X ∩ Σ+) ⊆ ({σ ∈ Σ+ | ¬C [σ]}∪ Y)
⇔	 X ⊆ Σ∞ = Σ+ ∪ Σm 3
X ⊆ ({σ ∈ Σ+ | ¬C [σ]}∪ Y)
⇔	 def. (16) of γtb 3
X ⊆ γtb [Y]
✷
Intuitively Lem. 5.1 states that the transformed semantics is an abstrac- tion of the subject semantics. This corresponds to the idea that the program transformation looses some information on the original program. For exam- ple the elimination of blocking commands looses all behavior about blocking program behaviors, constant propagation looses all information about how constants are computed, partial evaluation looses all information on program computations for input values other than the ones for which the program is
specialized, etc.
Let 1S  = λ x ∈ S • x be the identity operator on a set S and tb[T ] =
{tb[σ] | σ ∈T } be the right image of T by tb. We have:
Lemma 5.2 If T ⊆ Σ∞ then:
po⟨℘(t [T ]); ⊆⟩ ←−−−tb−−−− po⟨℘(T ); ⊆⟩
b	−−−−−−−−→
1℘(tb[T ])
Proof. Observe that tb is a lower closure operator that is reductive (∀X ⊆ T : tb[X ] ⊆ X ), idempotent (tb ◦ tb = tb) and monotone (∀X , Y ⊆ T : (X ⊆ Y) ⇒ (tb[X ] ⊆ tb[Y])). It follows that for all X ⊆ tb[T ] and Y ⊆T , we have:
1℘(tb[T ])(X ) ⊆Y 
⇒    def. identity3


X ⊆ Y
⇒		 X ∈ ℘(tb[T ]) so that there exists Z ∈ ℘(T ) such that X = tb[Z]3 tb[Z] ⊆Y 
⇒	 tb is monotone3
tb[tb[Z]] ⊆ tb[Y]
⇒	 tb is idempotent3
tb[Z] ⊆ tb[Y]
⇒	 def. X = tb[Z]3
X ⊆ tb[Y]
⇒	 tb is reductive and ⊆ is transitive3
X ⊆ Y
⇒		 def. identity3 1℘(t [T ])(X ) ⊆Y 
proving that 1℘(t [T ])(X ) ⊆Y if and only if X ⊆ tb[Y]. Moreover 1℘(t [T ]) ∈
b	b
℘(tb[T ]) −−→ ℘(T ) is injective.	✷
It immediately follows from Lem. 5.2 with T = Σ∞ P) that:
po⟨℘(t [Σ∞ P)]); ⊆⟩ ←←−−−−t−b −−−−− po⟨℘(Σ∞ P)); ⊆⟩,

b


so that by duality:
−−−−−−−−−−→
1℘(tb[Σ∞ P)])




1℘(tb[Σ∞ P)])

po⟨℘(Σ∞ P)); ⊇⟩ ←−−−−−−−−−− po⟨℘(t [Σ∞ P)]); ⊇⟩ .
−−−−−−−−−−→→	b
b
The intuition is that tb is a dual abstraction which can be used to approximate greatest fixpoints from above.

Observational Abstraction
For a program transformation to be correct, the semantics of the subject and transformed programs should be equivalent at some level of observation. This observational equivalence can be formalized in the abstract interpretation framework by requiring that the abstraction of the semantics of the subject and of the transformed programs into an abstract observation domain should to be identical:
∀P ∈ P : α (S∞ P)) = α (S∞  P))) .
The specification of the observational abstraction αO must be considered as part of the problematics (in that it explicitly defines the chosen correctness criterion).


Observational Abstraction for Blocking Code Elimination
In the particular case of blocking code elimination, the observational abstrac- tion αO(T ) of traces T is tb[T ], in that:
all infinite behaviors of T are observed in tb[T ];
all complete finite behaviors of T terminating with a stop command are observed in tb[T ];
no other trace of T is observed in tb[T ] so none of the complete finite behaviors terminating of T with a non-stop blocking command is observed in tb[T ].

Transformation Design Strategy
Our objective is to constructively derive a blocking code elimination algorithm b transforming a subject program P into a transformed program b P) such that P and b P) have equivalent semantics for the tb observational abstrac- tion:
α (t [S∞ P)]) = α (S∞   P)))
this is
t [t [S∞ P)]] = t [S∞  P))] since αO = tb for blocking command elimination, hence
t [S∞ P)] = t [S∞   P))] .
since tb is idempotent.
Our design strategy is to first derive the non-blocking trace semantics of programs t [S∞ P)] by abstraction of the trace semantics S∞ P) and then to design the blocking command elimination algorithm b P) as an abstraction of t [S∞ P)].

Non-Blocking Trace Semantics of Programs
We define the non-blocking trace semantics of a program P as:



S∞ P) =∆
t [S∞ P)] .

We observe that S∞ P) is suffix-closed since, by (18) and (14), it contains all infinite execution traces of S∞ P) (which suffix is also an infinite execution trace of S∞ P)), the traces s of length 1 reduced to a stop command (such that s+ = s) and finite traces of the form sσ which are execution traces of S∞ P) which, by (15), end with a stop command so that their suffix sσ+ = σ is also a finite execution trace of S∞ P) ending with a stop command.

In order to express S∞ P) algorithmically as a fixpoint iteration, we can start from the fixpoint form (10) of the program execution trace semantics,
such that S∞ = t [gfp⊆	F∞ P)] where F∞ P)T = {s | S P)s = ∅} ∪{sσ | σ ∈
b	b	Σ∞ P)	0
S P)s ∧ σ ∈ T }. Then (17) leads to the idea of using the dual of Cor. 2.4 to

express S∞ P) in greatest fixpoint form
T-strictness
⊆
gfp
F∞ P). We have:

t [Σ∞ P)] is the ⊆-supremum of ℘(t [Σ∞ P)]); Scott co-continuity
By (17), tb is a complete ∩-morphism hence Scott co-continuous; For the commutation condition, we have:
t [F∞ P)T ]
=	 By def. (14) of tb3
(F∞ P)T ∩ Σm) ∪ {σ ∈ F∞ P)T | C [σ]}
=	 By def. (7) of F∞ P)3
({s | S P)s = ∅} ∪ {sσ | σ0 ∈ S P)s ∧ σ ∈ T } ∩ Σm) ∪ {σ ∈ {s | S P)s =
∅} ∪ {sσ | σ0 ∈ S P)s ∧ σ ∈T }| Cb[σ]}
=	 def. Σm and ∪3
{s | S P)s = ∅∧ C [s]}∪ {sσ | σ  ∈ S P)s ∧ σ ∈ T ∩ Σm}∪ {sσ | σ  ∈
S P)s ∧ σ ∈T ∧ Cb[σ]}
=	 def. (15) of Cb[σ]3
{s | S P)s = ∅ ∧ ∃ρ, L : s = ⟨ρ, L : stop;⟩ ∪ {sσ | σ0 ∈ S P)s ∧ σ ∈
(T ∩ Σm) ∪ {σ' ∈T | C [σ']}}
=	 def. (4) of S P) and (14) of tb3
{⟨ρ, L : stop;⟩| L : stop; ∈ P ∧ ρ ∈ E}∪ {sσ | σ0 ∈ S P)s ∧ σ ∈ tb[T ]}
= F∞ P) ◦ t [T ]
b	b
by defining:




F∞ P) =∆
λ T • {⟨ρ, L : stop;⟩| L : stop; ∈ P ∧ ρ ∈ E}∪ 
{sσ | σ0 ∈ S P)s ∧ σ ∈T } .



We conclude, by the dual of Cor. 2.4, that:




⊆
S∞ P) =∆ t [S∞ P)] = t [gfp
F∞ P)] = gfp⊆	F∞ P) .

b	b	b
Σ∞ P)
tb[Σ∞ P)]  b

Blocking Command Elimination Algorithm
We can now design the syntactic blocking command elimination algorithm b P) as an upper approximation of the non-blocking trace semantics of pro- grams:


 P) ⊇	∞[S∞ P)] =	∞[S∞ P)] =	∞[gfp⊆
F∞ P)]

b	b	0	b
0	tb[Σ∞ P)]  b

since S∞ P) is suffix-closed and by (20). Then (13) leads to the idea of using Th. 2.7 to constructively derive the algorithm  P). For all T ⊆ Σ∞ P), we have:
∞[F∞ P)T ]
0	b
=	 def. (12) of	∞3
{ 0[σ] | σ ∈ F∞ P)T} 
=	 def. (19) of F∞ P)3
{ 0[⟨ρ, L : stop;⟩] | L : stop; ∈ P ∧ ρ ∈ E}∪{ 0[sσ] | σ0 ∈ S P)s ∧ σ ∈T },
=	 def. (12) of	0 and (11) of	, s, σ0 ∈ S P) and def. (3) of S P) so that s = ⟨ρ, C⟩, σ0 = ⟨ρ', C'⟩ and σ = σ0σ'3
{L : stop; | L : stop; ∈ P}∪{ [⟨ρ, C⟩] | ∃ρ' ∈ E : ∃σ' ∈ Σ∞ P) : ∃C' ∈ C :
⟨ρ', C'⟩∈ S P)⟨ρ, C⟩∧ ⟨ρ', C'⟩σ' ∈T }
=	 def. (11) of	and (4) of S P)3
{L : stop; | L : stop; ∈ P}∪ {C ∈ P | ∃ρ' ∈ E : ∃σ' ∈ Σ∞ P) : ∃C' ∈ P :
ρ' ∈ S action C))ρ ∧ label C') ∈ succ C) ∧ ⟨ρ', C'⟩σ' ∈T }
⊆	 Ignoring the (maybe undecidable) condition ρ' ∈ S action C))ρ3
{L : stop; | L : stop; ∈ P}∪ {C ∈ P | ∃ρ' ∈ E : ∃σ' ∈ Σ∞ P) : ∃C' ∈ P :
label C') ∈ succ C) ∧ ⟨ρ', C'⟩σ' ∈T }
=	 def. (12) of	03
{L : stop; | L : stop; ∈ P}∪ 
{C ∈ P | ∃C' ∈ P : label C') ∈ succ C) ∧ C' ∈	0[T ]}
=	 def. ∩3
{L : stop; | L : stop; ∈ P}∪ 
{C ∈ P | {label C') | C' ∈	0[T ] ∩ P}∩ succ C) /= ∅}
=	 by def. of labels in Sec. 3.13
{L : stop; | L : stop; ∈ P}∪ {C ∈ P | succ C) ∩ labels  0[T ] ∩ P) /= ∅}
=	b P) ◦	0[T ]


by defining:
b P) = λ Q • {L : stop; | L : stop; ∈ P}∪ 
{C ∈ P | succ C) ∩ labels Q∩ P) /= ∅},
Moreover	0[t [Σ∞ P)]] = P so by (13) and Th. 2.7, we conclude that:



 P) =
⊆
gfp
 P) ⊇	∞[gfp⊆
F∞ P)] =	∞[S∞ P)] .

b	P	b
0	tb[Σ∞ P)]  b	b



⊆
All iterates of gfp
b P) are included in P so that we have



⊆
b P) = gfp
' P)

with
b P) = λ Q • {L : stop; | L : stop; ∈ Q} ∪
{C ∈Q| succ C) ∩ labels Q) /= ∅},
Observe that po⟨P; ⊆⟩ satisfies the descending chain condition so that the above fixpoint form of b P) immediately leads to an effective iteration algo- rithm, that we can describe informally as follows:


Correctness of the Blocking Command Elimination Algorithm
The correctness of the transformation is stated by the fact that the observation of the semantics of the subject and transformed programs by the observational abstraction α  = t is the same. Formally, α (S∞ P)) = α (S∞   P))), that is
t [S∞ P)] = t [S∞   P))] .
Proof. By Lem. 4.1, S∞ is monotone.  By (17), t is monotone.  By (22),
⊆
we have	b P) = gfp	b P) so	b P) ⊆ P. By monotony we conclude that
t [S∞   P))] ⊆ t [S∞ P)].
By Lem. 4.1, S∞ ◦	∞ is extensive so that tb[S∞ P)] ⊆ S∞  ∞[tb[S∞ P)]]).

By (22),	∞[S∞ P)] ⊆	 P). By Lem. 4.1, S∞ is monotone. So by monotony,

S∞  ∞[S∞ P)]) ⊆ S∞ 
 P)).	By  (18),  S∞ P)  =
t [S∞ P)] so that we have

S∞  ∞[t [S∞ P)]]) ⊆ S∞   P)).
By transitivity, t [S∞ P)] ⊆ S∞ P)). By Lem. 5.2, t is monotone and idempotent so t [S∞ P)] = t [t [S∞ P)]] ⊆ t [S∞  P))].
By antisymmetry, we conclude that t [S∞ P)] = t [S∞   P))].	✷

Conclusion
The general idea to formalize program transformation by abstract interpreta- tion is to define a semantic transformation as an abstraction of the subject program semantics. This transformation is an abstraction in that the trans- formed semantics has lost some information on the subject semantics (e.g. the existence of blocking traces). The correctness of the semantic transformation is proved using an observational abstraction specifying which details about the subject and transformed semantics should be abstracted away to consider them as equivalent. Then the syntactic – source to source – program trans- formation is constructively derived by abstraction of transformed semantics into a transformed program. This new approach has been illustrated on the simple case of blocking command elimination.
Many more complex examples such as transition compression, constant propagation, partial evaluation, slicing, etc. have to be treated similarly in order to convince that this point of view is quite general. This will probably require the generalization of the present program transformation framework, for example using weaker hypotheses on abstraction in absence of a best ap- proximation [9].

References

S. Abramsky and A. Jung. Domain theory. In S. Abramsky, Dov M. Gabbay, and T.S.E. Maibaum, editors, Semantic Structures, volume 3 of Handbook of Logic in Computer Science, chapter 1, pages 1–168. Clarendon Press, 1994.
K.R. Apt and G.D. Plotkin. Countable nondeterminism and random assignment. J. ACM, 33(4):724–767, Oct. 1986.
R.M. Burstall and J. Darlington. A transformation system for developing recursive programs. J. ACM, 24(1):44–67, Jan. 1977.
P. Cousot. M´ethodes it´eratives de construction et d’approximation de points fixes d’op´erateurs monotones sur un treillis, analyse s´emantique de programmes. Th`ese d’E´tat `es sciences math´ematiques, Universit´e scientifique et m´edicale de Grenoble, Grenoble, France, 21 Mar. 1978.
P.  Cousot.   Constructive  design  of  a  hierarchy  of  semantics  of a  transition  system  by  abstract  interpretation.   ENTCS,  6,  1997.


http://www.elsevier.nl/locate/entcs/volume6.html, 25 pages.
P. Cousot and R. Cousot. Abstract interpretation: a unified lattice model for static analysis of programs by construction or approximation of fixpoints. In 4th POPL, pages 238–252, Los Angeles, CA, 1977. ACM Press.
P. Cousot and R. Cousot. Constructive versions of Tarski’s fixed point theorems. Pacific J. Math., 82(1):43–57, 1979.
P. Cousot and R. Cousot. Systematic design of program analysis frameworks. In 6th POPL, pages 269–282, San Antonio, TX, 1979. ACM Press.
P. Cousot and R. Cousot. Abstract interpretation frameworks. J. Logic and Comp., 2(4):511–547, Aug. 1992.
J.W. de Bakker, J.-J.Ch. Meyer, and J.I. Zucker. On infinite computations in denotational semantics. Theoret. Comput. Sci., 26:53–82, 1983. (Corrigendum: Theoret. Comput. Sci. 29:229–230, 1984).
N. Jones, C.K. Gomard, and P. Sestoft. Partial Evaluation and Automatic Program Generation. Int. Series in Computer Science. Prentice-Hall, June 1993.
N.D. Jones. Abstract interpretation and partial evaluation in functional and logic programming. In M. Bruynooghe, editor, Proc. Int. Symp. ILPS ’1994, pages 17–22. MIT Press, 13–17 Nov. 1994.
N.D. Jones. An introduction to partial evaluation. ACM Comput. Surv., 28(3):480–504, Sep. 1996.
N.D. Jones. Combining abstract interpretation and partial evaluation (brief overview). In P. Van Hentenryck, editor, Proc. 4th Int. Symp. SAS ’97, Paris, France, 8–10 Sep. 1997, LNCS 1302, pages 396–405. Springer-Verlag, 1997.
G. Kildall. A unified approach to global program optimization. In 1st POPL, pages 194–206, Boston, MA, Oct. 1973. ACMpress.
S.C. Kleene.	Representation of events in nerve nets and finite automata.
Automata Studies, pages 3–42, 1956.
A. Pnueli, 0. Shtrichman, and M. Siegel. The code validation tool CVT: Automatic verification of a compilation process. STTT, 2(2):192–201, 1998.
J.C. Reynolds. The discoveries of continuations. Lisp and Symbolic Computation, 6(3/4):233–248, Nov. 1993.
P. Steckler and M. Wand. Selective thunkification. In B. Le Charlier, editor,
Proc. 1st Int. Symp. SAS ’94, Namur, Belgium, 20–22 Sep. 1994, LNCS 864,
pages 162–178. Springer-Verlag, 1994.
A. Tarski. A lattice theoretical fixpoint theorem and its applications. Pacific
J. Math., 5:285–310, 1955.
P. Wadler. Deforestation: Transforming programs to eliminate trees. Theoret. Comput. Sci., 73(2):231–248, 28 Mar. 1990.


M. Weiser. Program slicing. IEEE Trans. Software Engrg., SE-10(4):352–357, Jul. 1984.
