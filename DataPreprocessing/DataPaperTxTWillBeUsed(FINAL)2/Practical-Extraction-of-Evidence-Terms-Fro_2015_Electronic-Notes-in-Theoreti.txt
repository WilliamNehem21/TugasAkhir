Available online at www.sciencedirect.com


Electronic Notes in Theoretical Computer Science 312 (2015) 143–160
www.elsevier.com/locate/entcs

Practical Extraction of Evidence Terms From Common-knowledge Reasoning
Natalia Novak
Mathematics and Computer Science Department, Bronx Community College, CUNY,
Bronx NY 10453, USA
Natalia.Novak@bcc.cuny.edu


Abstract
Knowledge, belief, and evidence are fundamental notions which appear in a wide range of areas. Over the last decade epistemic reasoning with justifications has broadened even more the scope of applications of epistemic logic as agents gained the ability to not only reason about epistemic states of knowledge and belief of agents, but also to track their justifications and to sort those which are pertinent to given facts and sufficient for epistemic conclusions.
This paper extends realization algorithm for S4-to-LP case to S4J -to-S4nLP case. It converts cut-free deriva-
tions in S4J into derivations in the corresponding Justification Logic S4nLP where witnesses of knowledge, the justification terms, are recovered for all instances of justified common knowledge. The algorithm was implemented in the MetaPRL framework and was tested on several well-known epistemic puzzles, such as Muddy Children, Surprise Examination Paradox, etc.
Keywords: logic of proofs, logical puzzles, evidence terms, metaprl

Introduction
The study of epistemic reasoning, reasoning about knowledge and belief, is one of the core areas of Computer Science and Artificial Intelligence. The traditional systems of formal epistemology are based on modal logics and have been the sub- jects of intense research activity during the past decades [10; 15]. There are several computer-aided systems of modal and epistemic reasoning available (for an incom- plete list, see [17]).
A foundational effort in this area has enriched modal epistemic logic with the internalized notion of justification, which became part of the language of epistemic logic. This development substantially broadens the scope of applications of epis- temic logic. We now have the capability to not only reason about epistemic states of knowledge and belief of agents, but also to track their justifications and to sort those which are pertinent to given facts and sufficient for epistemic conclusions. The very notion of evidence has become the subject of rigorous studies.

http://dx.doi.org/10.1016/j.entcs.2015.04.009
1571-0661/© 2015 The Author. Published by Elsevier B.V.
This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).

The Artemov’s Realization Theorem [2; 3] is the fundamental result that reveals the robust evidence system behind traditional epistemic modal logic reasoning. It recovers evidence terms for each occurrence of epistemic modality in a given the- orem. We started with the implementation of improved Artemov’s Realization Theorem within the framework of the MetaPRL computer-aided reasoning system, then proceeded with test runs on a wide range of well-known epistemic problems.


Translation of S4J
cut-free proofs into S4nLP proof

Overview of S4nLP logic
S4nLP [4] is a multi-agent logic of evidence-based knowledge, with knowledge op- erators of n agents K1, K2, K3,..., Kn, acting as S4 modalities [10], and evidence assertions of the form t : A, where t is an evidence term and A is a formula, as in LP [3]. Evidence term t is built from constants a, b, c, . . . and variables x, y, z, . . . with the help of binary operators ‘·’ (application), ‘+’ (union), and unary operator ‘!’ (inspection).
Formulas of S4nLP are defined by the following grammar:
⊥ | S | A → B | A ∧ B | A ∨ B | ¬A | KiA | t : A, where t is an evidence and S is a sentence variable.
Evidence operation has highest precedence and all other connectives have stan- dard precedence order.
Hilbert-style axioms and rules of S4nLP contain classical propositional logic ax- ioms with the Modus Ponens rule along with
Knowledge principles
B1i. Ki(A → B) → (KiA → KiB) B2i. KiA → A
B3i. KiA → KiKiA		(positive introspection) R2i. A ▶ KiA	(knowledge generalization)
for each individual knowledge operator Ki.
Evidence Principles
E1. s : (A → B) → (t : A → (s · t): B)	(application)
E2. t : A →!t : (t : A)	(inspection)
E3. s : A → (s + t): A,	t : A → (s + t): A		(union) E4. t : A → A		(reflexivity )
R3. ▶ c : A, where A is an S4nLP axiom and c is a proof constant	(evidence for axioms).
Principle connecting evidence and knowledge
C1. t : A → KiA	(undeniability of evidence). All axioms are schemas in the language of S4nLP. Rules are applied across all sections. The system is closed under substitutions of evidence terms for evidence variables and formulas for propositional variables. Deduction theorem Γ,A ▶ B ⇒
Γ ▶ A → B holds, where Γ is a finite set of S4nLP formulas.

The following two lemmas will be used in the proof of realization algorithm presented later in the text:



Lemma 1.1 (Lifting Lemma) [3; 4] If A1,..., An, y1 : B1,..., ym : Bm ▶ F , then for some evidence term t = t(x1,..., xn, y1,..., ym),
x1 : A1,..., xn : An, y1 : B1,..., ym : Bm ▶ t(x1,..., xn, y1,..., ym): F.




Lemma 1.2 [5] For any proof variables xi and any formulas Bi, there exists a proof term s = s(x1,..., xn) such that
LP ▶ x1 : B1 ∧ ... ∧ xn : Bn → s(x1,..., xn): (x1 : B1 ∧ ... ∧ xn : Bn).









Overview of S4J
system


S4J [4; 5] is a forgetful evidence-based logic with n + 1 modalities K1,..., Kn,J .
JA reads as ‘A is justified’ and is a forgetful projection of evidence assertion t : A.
The dummy n + 1th agent corresponding to J plays the role of a skeptical and not logically omniscient S4-agent who accepts facts only if they are supplied with checkable evidence. This agent is trusted by all other agents and is capable of internalizing and inspecting any fact actually proven in the system.
The forgetful version of undeniability of evidence principle for S4J is JA → KiA,

for all i = 1,..., n.
Below we present a Gentzen-style formulation [18] of S4J
called S4J G.

A sequent is a pair of finite sets of S4J
formulas presented as Γ ⇒ Δ. Axioms

of Gentzen-style S4J
are the sequents S, Γ ⇒ Δ,S and ⊥, Γ ⇒ Δ, where S is a

propositional variable.
S4J is strictly weaker than system S4C [1], where common knowledge C is defined
n	n
using traditional fixpoint common knowledge [10]. Nevertheless, S4J seems sufficient

for all practical applications. At the same time, S4J
axiomatics allows standard

methods of proof theory, and allows to draw parallels with logic of explicit proofs
LP.

Gentzen style rules of S4J :
 Γ ⇒ Δ,A  (¬ ⇒)	 A, Γ ⇒ Δ (⇒ ¬)
¬A, Γ ⇒ Δ	Γ ⇒ Δ, ¬A

 A, B, Γ ⇒ Δ (∧ ⇒)	 Γ ⇒ Δ, A	Γ ⇒ Δ,B  (⇒ ∧)
A ∧ B, Γ ⇒ Δ	Γ ⇒ Δ,A ∧ B

 A, Γ ⇒ Δ	B, Γ ⇒ Δ (∨ ⇒)	 Γ ⇒ Δ, A, B  (⇒ ∨)
A ∨ B, Γ ⇒ Δ	Γ ⇒ Δ,A ∨ B

 Γ ⇒ Δ, A	B, Γ ⇒ A (→⇒)	 A, Γ ⇒ Δ, B  (⇒→)
A → B, Γ ⇒ Δ	Γ ⇒ Δ,A → B

and n + 1 pairs of modal rules:
 A, 2A, Γ ⇒ Δ (2 ⇒)		J Γ, 2Δ ⇒ A	 (⇒ 2)
2A, Γ ⇒ Δ	J Γ, 2Δ, Π ⇒ Σ, 2A
where 2 ∈ {K1,..., Kn,J} and 2{A1,..., Am} = {2A1,..., 2Am}.


Main Deﬁnitions and Facts for the Realization Procedure
The goal of this work was to replace justifiable knowledge J with explicit justifica- tions, i.e. proof polynomials (proof terms). In other words, instead of knowing that something is ‘justified,’ we would like to have its actual justification. An algorithm that accomplishes this is called realization procedure.

Definition 1.3 To realize a modal formula F from S4J
in S4nLP means to substi-

tute proof polynomials for all occurrences of J in F .
Definition 1.4 A realization r is called normal if all negative occurrences of J are realized by proof variables.
Realization theorem.
The first version of the realization theorem for S4 and LP, producing a Hilbert- style derivation, was established in [2]. Another version of the realization theorem, producing a Gentzen-style derivation, was presented in [3]. In both versions the produced evidence terms could be exponential in the length of a given cut-free proof of the theorem. A modified algorithm in [5] lowers the bound of produced evidence terms’ length to quadratic in the size of a given cut-free proof of an epistemic modal theorem.
In this work, we extend realization algorithm from [5] to S4J and S4nLP, imple- ment it, and test its performance on a number of paradigmatic epistemic problems. These tests show robust behavior of realization terms in which complexity stays firmly within theoretically predicted polynomial (quadratic) bounds.

Realization Algorithm
The realization procedure works by induction on the depth of the S4J
tree. It runs through the Gentzen-style proof of a formula F in S4J

derivation and simul-

taneously constructs a realization and Hilbert-style proof of the realized formula. We also keep track of all instances of the evidence for axiom rule R3 used in this Hilbert-style proof, i.e., of constant specification.
We start with definitions of positive and negative occurrences of modality J in a formula and in a sequent, as adapted from [2]:
An outer occurrence of J in JF is positive;
A corresponding occurrence of J in F and G → F , G∨F , G∧F , JF , and Γ ⇒ Δ,F 
has the same polarity;
Corresponding occurrences of J in F and ¬F , F → G, and F, Γ ⇒ Δ have opposite polarities.
In a cut-free derivation, the rules respect polarities. Occurrences of J introduced by (⇒ J) are positive:


J Γ ⇒ A J Γ, Π ⇒ Σ, JA
(⇒ J).

All occurrences of J-modality in a given derivation tree of ⇒ F are divided into families of related occurrences. Each occurrence of J in a side formula G (i.e., from Γ and Δ) in the premise of the rule is related only to the corresponding occurrence of J in G in the conclusion of the rule. Similarly, each occurrence of J in an active formula of the rule, i.e., in a formula in the premise that is transformed by the rule, is related only to the corresponding occurrence of J in the principal formula of the rule, i.e. in the result of transformation. For example, in the (J ⇒)-rule, formulas A and JA in the premise sequent are the active formulas, and formula JA in the conclusion sequent is the principal formula. This relationship is extended by reflexivity and transitivity. Therefore all related occurrences are naturally split into families of related occurrences.
Since rules in the cut-free Gentzen system respect polarities, each family consists of J’s of the same polarity. We call a family positive if it consists of positive J’s, and negative if it consists of negative J’s.
J modalities from the same family correspond to the same occurrence of J in the proof, so we realize them by the same proof polynomial that explicates this J. In addition, due to the normality condition, all J’s from a negative family have to be realized by the same proof variable.
Proofs (derivations) of formulas in a Gentzen system, S4J G in particular, can be viewed as derivation trees. Nodes are triples: the current sequent, name of the rule and the principal formulas, and axioms as leaves. It imposes a tree structure on each family of J’s, with leaves as those nodes where J ’s of a particular family are first introduced (at a leaf of the derivation tree or in a (⇒ 2) rule).
Comment: It is not necessary to carry sequents in every node - they can be

reconstructed from rule names, principle formulas, and full sequents at the root. Although for the realization algorithm full sequents in every node are needed.
A positive family of J ’s is essential if at least one of its leaves corresponds to a principal J in a (⇒ 2) rule, and is non-essential otherwise.
Realization algorithm:
(by recursion on the derivation tree structure)
In our system S4J G, there are only three ways of introducing new J-modalities:
by an axiom;
inside a formula by which a sequent is ‘weakened’ in a (⇒ 2) rule;
the outer J in the principal formula of a (⇒ 2) rule.
Let us enumerate all (⇒ J) rules in the derivation tree and associate provisional variable ui with the principal J of the i-th rule. All of the provisional variables will be replaced with proof polynomials by the end of the algorithm.
Stage 1 Every negative family and non-essential family of J’s is realized by a fresh proof variable. All J’s from such a family will be realized by a proof variable corre- sponding to that family.
Stage 2 Pick an essential positive family of J’s. Enumerate all the occurrences of (⇒ 2) rules that introduce J’s from this family as the principles: i1 < i2 < . . . < ik. All such J’s are initially realized by provisional term ui1 +ui2 +... uik , where addition is associated to the left and ui’s are fresh provisional variables.
We also initialize a substitution σ, which acts on these provisional variables, to be the empty substitution. At the end of the realization procedure, this substi- tution will assign a certain proof polynomial to each provisional variable. As a result, essential positive J’s will also be realized by proof polynomials that contain no provisional variables.

Next, each S4J
formula G occurring in the sequent derivation is translated into

an S4nLP formula Gr as follows: each occurrence of J in G is replaced by a proof
polynomial tσ that possibly contains provisional variables, where t is the term real- izing the family of that J, and σ is the current state of the substitution acting on provisional variables. This substitution is appended during the realization procedure, namely, during processing of (⇒ 2) rules.
Stage 3 For each sequent in the initial derivation we will construct
an S4nLP formula C that corresponds to that sequent,
a proof polynomial t that contains no provisional variables, and
a Hilbert-style derivation of t : C
recursively on the structure of the derivation tree of	⇒ F.
Kuznets and Brezhnev had the idea to use the polynomials t. They are used

while processing the (⇒ 2) rules of the initial S4J
derivation, and are a vital part

of eliminating exponential blow-up.

Base: Let C be a sequent formula. Any sequent formula Γ ⇒ Δ, where Γ =
{A1,..., An}, and Δ = {B1,..., Bm}, is translated into a formula (... (Ar ∧ Ar) ∧
1	2
.. .) ∧ Ar → (... (Br ∨ Br) ∨ .. .) ∨ Br .
n	1	2	m
The antecedent and the consequent of a sequent are multisets, so the order of
formulas is irrelevant in both, but normal Hilbert-style operations do not possess such freedom. Thus we need to force some order on Ar’s and on Br’s, so we can
i	i
use any ordering that allows efficient sorting. This ordering should be uniform for
all sequents. This is important for Cook and Reckhow’s idea [9] of implementing each step of Gentzen-style derivation by several steps of the corresponding Hilbert- style derivation, otherwise the formulas on different branches of the tree might not match. The lexicographical order is a natural one.
An empty consequent constitutes empty disjunction and is translated as ⊥. An empty antecedent constitutes empty conjunction and is translated as T. Therefore
⇒ F is translated as T→ Fr.
Translation of two axioms of S4J G:
A1,..., Ai—1, S, Ai,..., An ⇒ B1,..., Bj—1, S, Bj,..., Bm
is translated as
Ar ∧ ... ∧ Ar	∧ S ∧ Ar ∧ ... ∧ Ar → Br ∨ ... ∨ Br	∨ S ∨ Br ∨ ... ∨ Br ,
1	i—1	i	n	1	j—1	j	m
in particular, S ⇒ S is translated as Sr → Sr;
⊥, A1,..., An ⇒ B1,..., Bm
is translated as
⊥∧ Ar ∧ ... ∧ Ar → Br ∨ ... ∨ Br ;
1	n	1	m
in particular, ⊥⇒ is translated as ⊥→ ⊥.
(Assuming that Ak’s and Bl’s, Ar ’s and Br’s are already ordered alphabetically, and
k	l
⊥ is the first symbol of the alphabet, disjunctions and conjunctions are associated
to the left.)
Each translated implication C of this type is clearly derivable in S4nLP. After application of the Lifting Lemma to this derivation, we get a ground proof polyno- mial s and a derivation of s : C.
Induction Step:
Propositional rule with one premise:
Γ ⇒ Δ Γj ⇒ Δj .
Let C and Cj be translations of Γ ⇒ Δ and Γj ⇒ Δj respectively. By induction hypothesis, there is a term tC and a derivation lC of tC : C. By propositional reasoning, there is a derivation of C → Cj. Using the Lifting Lemma, we get a ground term tR and a derivation lR of tR : (C → Cj). Concatenating lC with lR and appending the result with the following sequence ... (derivation lR)
n.	tR : (C → Cj)
...  (derivation lC)
tC : C
m+1.  tR : (C → Cj) → (tC : C → tR · tC : Cj)	(axiom E1)

m+2.	tC : C → tR · tC : Cj	(MP from n and m+1)
m+3.	tR · tC : Cj	(MP from m and m+2) , we obtain the term tC′ = tR · tC and the derivation lC′ of tR · tC : Cj.
A case of a propositional rule with two premises are handled in a similar way. Let us consider (2 ⇒) rule for Γ = {B1,..., Bn}, and Δ = {D1,..., Dm}:
 A, JA, B1,..., Bn ⇒ D1,..., Dm  (2 ⇒) .
JA, B1,..., Bn ⇒ D1,..., Dm
Without loss of generality, let’s assume that the translation of the premise is
C = Br ∧ ... ∧ Br	∧ Ar ∧ Br ∧ ... ∧ Br	∧ x : Ar ∧ Br ∧ ... ∧ Br → D,
1	i—1	i	j—1	j	n


where D = Dr ∨...∨Dr
and x is the proof variable associated with the negative

1	m
family of the outer J-modality in JA. Then the translation of the conclusion is
Cj = Br ∧ ... ∧ Br	∧ x : Ar ∧ Br ∧ ... ∧ Br → D.
1	j—1	j	n
Since S4nLP ▶ x : Ar → Ar (reflexivity principle E4), it is easy to derive C → Cj. Then, using the Lifting Lemma, we obtain a ground term t(2⇒) and a derivation l(2⇒) of t(2⇒) : (C → Cj). The rest is the same as with the one-premise proposi- tional rules.
The only rule that is treated differently is (⇒ 2), which includes two cases: (⇒ Ki) and (⇒ J).  Let’s consider the first one: for Γ = {B1,..., Bn}, Δ =
{D1,..., Dm} , Σ = {E1,..., Eo}, and Π = {A1,..., Ar}


	J Γ, KiΔ ⇒ A	
(⇒ K ) .
J Γ, KiΔ, Π ⇒ Σ, KiA	i
Without loss of generality, let’s assume that the translation of the premise is
C = x : Γr ∧ KiΔr → Ar
and x = (x1,..., xn), where xi are distinct proof variables associated with the negative families of the outer J-modality in JΓ.
Then the translation of the conclusion is


Cj = x : Γr ∧ KiΔr ∧ Πr → Σr ∨ KiAr .
By induction hypothesis, we have a term tC and a derivation lC of
tC : (x : Γr ∧ Ki : Dr → Ar)

...  (derivation lC)
tC : (x : Γr ∧ KiΔr → Ar)
n+1.tC : (x : Γr ∧ KiΔr → Ar) → Ki(x : Γr ∧ KiΔr → Ar)(axiom C1)
n+2.Ki(x : Γr ∧ KiΔr → Ar)	(MP from n and n+1)

n+3.Ki(x : Γr ∧ KiΔr → Ar) → (Ki(x : Γr ∧ KiΔr) → KiAr)  (axiom B1i) n+4.Ki(x : Γr ∧ KiΔr) → KiAr	(MP from n+2 and n+3) n+5.  V Kixj : Br  ∧ (V KiKiDr) → Ki(x : Γr ∧ KiΔr)(simple S4nLP reasoning)
n+6.  V Kixj : Br  ∧ (V KiKiDr) → KiAr	(syllogism from n+4 and n+5)

j	l
n+7.xj : Br → Kixj : Br
(an easy S4nLP fact)

j	j
n+8.KiDr → KiKiDr
(axiom B3i)

l	l
n+9. V xj : Br ∧ (V KiDr) →  V Kixj : Br ∧ (V KiKiDr)
(propositional reasoning from n+7 and n+8)
n+10.  V xj : Br  ∧ (V KiDr) → KiAr	(syllogism from n+6 and n+9)
n+11.  V xj : Br  ∧ (V KiDr) ∧ Π → Σ ∨ KiAr
j	l
(propositional reasoning from n+10)
n+12. tn+11 : ( V xj : Br  ∧ (V KiDr) ∧ Π → Σ ∨ KiAr)
j	l
(Lifting Lemma from n+11).

We obtained the ground term tn+11 and a derivation of tn+11 : (C → Cj). Now, let us consider the (⇒ J) rule:
for Δ = {D1,..., Dm} , Σ = {E1,..., Eo}, and Π = {A1,..., Ar}

	JD1,..., JDm ⇒ A	
(⇒ J) .
JD1,..., JDm, A1,..., Ar ⇒ E1,..., Eo,JA
All J’s in JDi’s are negative and belong to different families, so they are realized by distinct proof variables xi’s. Let k be the number of this (⇒ J) rule and let its family be realized by us1 + ... + uk + ... usl . By induction hypothesis, we have a term tC and a derivation lC of
tC : (x1 : Dr ∧ ... ∧ xm : Dr → Ar).
1	m
By Lemma 2, we construct a term s = s(x1,..., xm) and a derivation l1 of
x1 : Dr ∧ ... ∧ xm : Dr → s : (x1 : Dr ∧ ... ∧ xm : Dr ).
1	m	1	m

Note that s does not contain any provisional variables. It is now easy to append derivations lC and l1 (we’ll use vector notation for conjunction):
...  (derivation lC)
n.	tC : (x : Dr → Ar)
...  (derivation l1)
m.  x : Dr → s : (x : Dr)
m+1.tC : (x : Dr → Ar) → (s : (x : Dr) → tC · s : Ar)		(axiom E1) m+2. s : (x : Dr) → tC · s : Ar		(MP from n and m+1) m+3. x : Dr → tC · s : Ar	(syllogism from m and m+2)
... (using axiom E3 several times)
k. x : Dr → (us σ + ... + tC · s + ... us σ): Ar.
Moreover this derivation is easy to append to obtain derivation l2 of a formula
Cj that (modulo permutations) looks like
x : Dr ∧ A → E ∨ (us σ + ... + tC · s + ... us σ): Ar (here x : Dr and A stand for conjunctions, and E for disjunctions).
We then use the Lifting Lemma to reproduce a ground term tC′ and a derivation
lC′ of
tC′ : (x : Dr ∧ A → E ∨ (us σ + ... + tC · s + ... us σ): Ar) .
While lifting l2 [5], there is no need to lift its initial part lC since the only formula we use for the second part is tC : (x : Dr → Ar); this formula is easily lifted by adding to lC the following two formulas:
tC : (x : Dr → Ar) →!tC : tC : (x : Dr → Ar), and
!tC : tC : (x : Dr → Ar),
the latter being the desired lifted version. This procedure produces a ground term because tC is ground. Also, this modification renders the whole procedure polynomial in the size of the original S4J -derivation. In the original algorithm [2], each time a (⇒ 2) rule is processed, most formulas in the initial derivation are replaced by three formulas in the lifted one, which leads to exponential growth in the number of (⇒ 2) rules. We then append σ by a new substitution: σ = σ + {uk → tC · s}, and apply this substitution throughout the derivation (S4nLP is known to be closed under substitutions). After that, there are no occurrences of uk remaining in the derivation. As a result, we eliminated one provisional variable.
Final Touch: At the end of the procedure, the entire derivation tree of ⇒ F is translated – all (⇒ 2) rules have been processed and there are no provisional variables remaining. Thus, Fr is simply an S4nLP formula. Moreover, we have a Hilbert-style derivation lt of t : (T → Fr) for some ground term t. To acquire Fr, we do the following:
... (derivation lt)
n.	t : (T→ Fr)
n+1.	t : (T→ Fr) → (T→ Fr)	(axiom E4)
n+2.	(T→ Fr)	(MP from n and n+1)

n+3. T
n+4.  Fr	(MP from n+2 and n+3).

Notes on implementation
The procedure was implemented in OCaml. Evaluation of box families, considered to be trivial on paper, was the biggest hurdle. Each box was assigned a unique family identifier. Proofs have branches, and families grow by transitive extension, thus the disjoint set of sets (families) of box identifiers that are related (belong to the same family) needs to be maintained. What actually occurs is that each box is replaced with Pr(Provisional, F ) where Provisional is this unique identifier. The algorithm recursively walks over the proof tree, assigns these identifiers, and collects information about which identifiers fall into which family. At each step representing application of a rule, we have to track how each formula above the line (of the rule) was transformed and then transform the formulas below the line accordingly.
For all classical reasoning that justifies a shift from rule assumptions to rule conclusion, we say that there is a (fresh) proof constant justifying the implication, and deduce such implications using the reflexivity axiom t : A → A.
At some point, we realized that the produced proofs were way too long, both in the number of steps and the length of produced formulas. We partially address both.
First of all, as suggested by Melvin Fitting, we introduced two one-step rules: Deduction and Lifting. After each application of the Lifting lemma or Deduction Theorem, we retain the full chain of reasoning for validation purposes, but collapse them for purposes of display. Therefore, one sees the following:
k.	A1,..., Am,..., An ▶ B
k + 1.	Am+1,..., An ▶ Am → ... → A1 → B (by Deduction)
and
k.	x1 : A1,..., xn : An ▶ B
k + 1. x1 : A1,..., xn : An ▶ c(x1,..., xn): B (by Lifting).
Second, we assigned fresh (shortcut) constants to each proof term appearing in the proof and with length more than 5. We list these assignments at the end of the proof and provide a hyperlink from each occurrence of such a constant to its definition.
We also inserted dummy steps to mark the boundaries between individual Gentzen proof steps and certain stages of ⇒ 2 rule realization. Such dummy steps are labeled with Gentzen rules or realization stage names instead of Hilbert rules or axioms. These dummy rules are also rendered with normal font size, and all intermediate steps with a smaller font.
This implementation was connected with the automatic prover for multi-agent

logic with justified knowledge S4J
in the MetaPRL logical framework [6; 7]. The

output of the S4J prover is a Gentzen-style cut-free proof, exactly what polynomial realization procedures need.

Experiments
The realization procedure was ran on several simple examples, as well as on several classical puzzles: the Wise Girls puzzle and the Wise Men Puzzle [16], which we will not cover in this article.
We present here the Muddy Children Puzzle and Surprise Examination paradox.

Graphs
Some of the experiments are accompanied with the three types of graphs.
The first graph shows the growth of the number of steps in a Hilbert-style proof as a function of the number of steps in the original Gentzen-style proof. According to [5] we should observe O(n2) - dependency on this graph.
The second graph shows the growth of the total length of all formulas in a Hilbert-style proof as a function of the total length of all formulas in the original Gentzen-style proof. According to [5] we should observe O(n6) - dependency on this graph.
And the last graph shows the growth of the external (outer) terms’ sizes in a Hilbert-style proof as a function of the number of steps in the original Gentzen-style proof. According to [5] we should observe O(n2) - dependency on this graph.
One can see the bumps on the graphs. The bumps are the result of (⇒ 2) rule realization. We observe that all other rules are linear in the number of steps. Therefore, it is possible that O(n6) bound can be improved by counting “expensive” and “inexpensive” rules separately.

Realization of the Muddy Children Puzzle
N children are playing together [10]. Their mother tells them that if they get dirty, there will be severe consequences. Now it so happens that during their play, some of the children, say k of them, get mud on their foreheads. Each can see mud on the others, but not on his own forehead, so no one says anything. Along comes their father who says, “At least one of you has mud on your forehead,” thus expressing a fact known to each of them before he speaks (if k > 1). The father then asks the following question repeatedly: “Do any of you know whether or not you have mud on your own forehead?” Assuming that the children are all perceptive, intelligent, truthful, and that they answer simultaneously, what will happen? There is a ‘proof’ that the first k − 1 times he asks the question, they will all answer “No,” but the kth time, the children with muddy foreheads will all answer “Yes.”
For this puzzle, a straightforward epistemic logic formalization can lead to in- consistent sets of hypotheses [7; 11; 12]. For example, let c1,..., cn be propositional variables reserved for N children, where ci encodes that ith child is muddy. J stand

for “it is a common knowledge”, and kw i a stand for “i knows whether a or чa”. Then, the set of formulae
J (c1 V c2 V ... V cn),	J (kw i Cj) for all i /= j,	Jч(kw i Ci) for all i,
is inconsistent for all n ≥ 2.
For the sake of observing the complexity of the realization process, one can find the complexities of this contradictory formalization for five children in the following graphs.



In [14] a version of logic similar to S4J
was used, with all modalities graded by

time, to present a model-based solution of Muddy Children. This solution has a model, hence it avoids introduction of a contradiction. For reference, it is presented it the Appendix of [16].
Here we present three of the possible formalizations of the Muddy Children puz- zle for three children, using McCarthy’s idea. Graphs for each complexity measure are given after the last formalization, we merged them for ease of comparison.
We use the following notation:
K-modality has two indices now: time and agent, i.e. Kt,aA stands for “At time
t, agent a knows A.”
EtA ::= Kt,a1 A Λ ... Λ Kt,an A stands for “Everybody knows A at time t.”
kwt,a A ::= Kt,aAVKt,aчA, i.e. “At the moment t agent a knows whether or not
A holds.”
We use McCarthy’s idea only, not his system. We stay in S4J , no new axioms or rules related to time are introduced, and Kt,a is just syntactic sugar for K(t—1)n+a, where n is the number of agents.
Without loss of generality, let us assume that the first and third children are dirty, and the second one is clean, i.e., c1, чc2, c3.
Longer version
Denotations: Child 1 stands for the first child, etc.
Hypotheses: (denotation: wmn stands for ‘were/was muddy or not’)
c1 Λ чc2 Λ c3
kw3,2 c1;	at moment 3, Child 2 knows if Child 1 is muddy or not
kw3,2 c3;	at moment 3, Child 2 knows if Child 3 is muddy or not
kw3,2 (kw2,1 c1); at moment 3, Child 2 knows if Child 1 at moment 2 knew he wmn
K3,2(	at moment 3, the second child knows that

(kw2,1 c3) Λ (kw2,1 c2)Λ at moment 2, Child 1 knew if Child 2 and Child 3 wmn, and
K2,1(	at moment 2, Child 1 knows that
	ч(kw1,1 c1)Λ ч(kw1,2 c2)Λ ч(kw1,3 c3)Λ at the 1st moment, nobody knew if they wmn, and
	(E1(c1 V c2 V c3))Λ at 1st moment, everybody knew that at least one of them was muddy, and
	(kw1,1 c2) Λ (kw1,1 c3)Λ at 1st moment, Child 1 knew if Child 2 and Child 3 wmn, and
	(kw1,2 c1) Λ (kw1,2 c3)Λ at 1st moment, Child 2 knew if Child 1 and Child 3 wmn, and
(kw1,3 c1) Λ (kw1,3 c2) )) at 1st moment, Child 3 knew if Child 1 and Child 2 wmn
K3,2((c1 Λ c2 Λ c3) → ч kw2,1 c1) at moment 3, Child 2 knows that if all of them are dirty, Child 1 at moment 2 did not know if he was muddy or not
Conclusion: kw3,2 c2	at moment 3, Child 2 knew if he was muddy or not
The last hypothesis cannot be relaxed because in situations where a child says that (s)he does not know if (s)he is muddy, (s)he cannot really derive it in S4J . So when the system performs case analysis, we have to help it with such implications.
A short version:
If we make the second, third, and fourth premises stronger, we then obtain a shorter version:
Hypotheses:
c1 Λ чc2 Λ c3
K3,2 c1
K3,2 c3
K3,2 (K2,1c1)
K3,2 ((c1 Λ c2 Λ c3) → чkw2,1 c1)
Conclusion: kw3,2 c2 .
A short version with J:
We would like to see some modalities realized as proof terms so we replaced all modalities that represent facts that everyone knows (due to public an- nouncements or general conditions of the puzzle) with J. We also strengthen the conclusion to state that at the third moment, everyone knows that everyone knows about themselves, so we have to add lines (6), (7) to bring the knowledge of the first and third children from step 2 to step 3, and we add (9) to reflect the fact that if the second child learns about himself, he will announce it. We did not perform this transformation with the longer version because the prover was overwhelmed by the complexity.
Hypotheses:
c1 Λ чc2 Λ c3
J (kw3,2 c1)
J (kw3,2 c3)
J (K2,1 c1)
J (K2,3 c3)

J (K2,1c1 → K3,1c1)
J (K2,3c3 → K3,3c3)
J ((c1 Λ c2 Λ c3) → ч(kw2,1 c1))
J (K3,2c2 → J (K3,2 c2))
Conclusion: J (K3,2чc2 Λ K3,1c1 Λ K3,3c3).
Here are the graphs for all three cases:


Formalization of the Surprise Examination Paradox
There is a famous epistemic Surprise Examination Paradox (SEP): A professor tells students in his class that there will be a surprise in-class exam during the next week. There are 5 weekdays and class meets every day. Can the professor give an exam? We assume that professor and students are truthful and smart. By the usual backward induction argument, students figure that the exam cannot be given at all. Indeed, the exam cannot be given on the last day, since it would not be a surprise. Therefore, the exam cannot be given the day before, etc. The paradox occurs when the professor gives an exam on day two, and it is a complete surprise for the students!
The are 12 pages of references on the subject in [8], and it was not our goal to become experts in this area. Here is a naive, straightforward formalization of SEP conditions: consider a very trustful student who, despite his or her intelligence, is very confused on the last day if the test has not yet happened. He/she “knows” that the professor never lies or makes mistakes, and at the same time it seems that there is no alternative option and the exam has to happen on this last day. Any certain answer, positive or negative, to the question “Do you think that the test will be given today?” will lead to a contradiction. Therefore, the natural answer is “I do not know,” which implies (just as a negative answer) that the student considers the possibility that there will be no test. This implicit additional outcome resolves the paradox.
In the formalization below we take a conservative approach and simply prove that full set of assumptions is contradictory or that the exam cannot happen on the last day of the week. We use different agent indices to represent different times

and different students, if needed. Knowledge relation between different moments of time for the same student have to be explicitly stated for individual formulae, as

S4J
has no built-in support for time.

di stands for “the exam took place on ith day.” For the case of one student, KiA means that the student will know A just before day i. With this setup, K1 has a somewhat special meaning because it describes what we know up front about this puzzle.


2-day week

1. J ((d1 Λ чd2) V (чd1 Λ d2))	2. K1(K2d1 V K2чd1)	3. K1чK2d2	4. чK1d1

⊥
The first assumption states that the exam will happen on either of the days. The second assumption states that after the first day, it will be known if the exam took place already. The third assumption is effectively our formalization of “surprise” - prior to the second day, we will not know if the exam will happen on second day. And the last assumption is also “surprise”, this time, for the first day. MetaPRL finds a proof for this theorem in a few seconds.


2-day week, many students
The same problem with 2 students is formulated trivially by duplicating relevant formulas and replacing modality indices:
J ((d1 Λ чd2) V (чd1 Λ d2))	5. K3(K4d1 V K4чd1)
K1(K2d1 V K2чd1)	6. K3чK4d2
K1чK2d2	7. чK3d1
чK1d1

⊥
Extending this theorem for 40 students has some, but little effect on proof search timing, still keeping it under one second; it seems to be linear or polynomial of low degree. This is expected, as conclusion of the theorem is independent of the number of students, and the first 4 assumptions are sufficient anyway.


3-day week
The first assumption states that exam will happen on either of the days. The 2nd, 3rd, and 4th assumptions say that we know the results of the previous days. The

5th to 8th assumptions are “surprise” conditions.
J ((d1 Λ чd2 Λ чd3) V (чd1 Λ d2 Λ чd3) V (чd1 Λ чd2 Λ d3))	5. K1чK2d2
J(K2d1 V K2чd1)	6. K1чK3d3
J(K3d1 V K3чd1)	7. K2чK3d3
J(K3d2 V K3чd2)	8. чK1d1

чd3
Note that this theorem only states the impossibility of the exam on the last day of the week and does not involve backward induction. So this is a simplified version, basically the first step in establishing the paradox.
If we unfold all disjunctions, MetaPRL has no problems completing the proof. But it was unable to find the proof in fully automatic mode in an hour. In this sense, this theorem is harder than Muddy Children puzzle for 4 children, which can be solved in 150-250 seconds. The reason why fully automatic mode fails is because all J-boxed assumptions have to be used twice in the reasoning and the prover works by first exhausting all proof matrices with modalities used at most once, then expanding the search space by allowing each modality to have two prefix interpretations; the resulting search space is big and the solution does not appear quickly. The Muddy Children puzzle also needs this search space expansion, but we get luckier there, although it is not clear exactly why.
The Muddy Children puzzle for 4 children can be sped up by an order of magni- tude by manually duplicating assumptions that will be used twice in the reasoning and avoiding automatic expansion of all modalities. We tried to apply the same technique to our problem at hand but it produced too big of a search space for the prover, and the search simply did not finish within a reasonable time.
This straightforward formalization of SEP results in contradiction as expected.
For more on SEP see [13].
Conclusion
Following [5] and [4], a polynomial realization algorithm for S4nLP was implemented in MetaPRL Logical Framework and connected with S4J prover [7]. This procedure was run on several interesting examples. Realization algorithm performed better

than expected, the bottleneck was always on the S4J
prover’s side. On the other

hand, even small S4J Gentzen-style proofs result in long S4nLP Hilbert-style proofs which are beyond human comprehension.
Though we abbreviate certain trivial segments of a proof, the result is too long to be readable. Therefore the instructive parts are the length of the resulting proof, the length of the outer term as functions of an incoming proof, and the realized formula itself.
The algorithm has been known for more than a decade, but this work is a first time it was applied to proofs longer than just few steps. We used famous Muddy

Children Puzzle and Surprise Exam Paradox for our experiments.
Future Work
Considering the complications that were met, it seems instrumental to modify or ex- tend the current implementation of S4nLP realizer to accept interactively/manually constructed proofs. This will allow to evaluate realization procedure performance on SEP for three and more days.

References
E. Antonakos. Comparing justified and common knowledge. The Bulletin of Symbolic Logic, 12, 2006. in: 2005 Summer Meeting of the ASL.
Sergei Artemov. Operational modal logic. Technical Report MSI 95-29, Cornell University, 1995.
Sergei Artemov. Explicit provability and constructive semantics. The Bulletin for Symbolic Logic, 6(1):1–36, 2001.
Sergei Artemov. Evidence-based common knowledge. Technical Report TR-2004018, CUNY Ph.D. Program in Computer Science Technical Reports, November 2004.
Vladimir Brezhnev and Roman Kuznets. Making knowledge explicit: how hard it is. Theoretical Computer Science, 357(1):23–34, 2006.
Yegor Bryukhov. Automatic proof search in logic of justified common knowledge. In Holger Schlingloff, editor, Proceedings of Methods for Modalities Workshop 2005. Humboldt University, 2005.
Yegor Bryukhov. Integration of Decision Procedures into High-Order Interactive Provers. PhD thesis, The Graduate School and University Center, CUNY, 2006.
Timothy Y. Chow. The surprise examination or unexpected hanging paradox. The American Mathematical Monthly, 105:41–51, 1998.
Stephen Cook and Robert Reckhow. On the lengths of proofs in the propositional calculus (preliminary version). In STOC ’74: Proceedings of the sixth annual ACM symposium on Theory of computing, pages 135–148, New York, NY, USA, 1974. ACM.
Ronald Fagin, Joseph Y. Halpern, Yoram Moses, and Moshe Y. Vardi. Reasoning About Knowledge. Massachusetts Institute of Technology, 1995.
Melvin Fitting. Modal logic notes, January 2006. First Indian Winter School on Logic and Its Relationship with Other Dsciplines, IIT Bombay.
Melvin Fitting. Modal proof theory. In P. Blackburn, J. F. K. van Benthem, and F. Walter, editors,
Handbook of modal logic, pages 85–138. Elsevier, 2007.
Paul Franceschi. A dichotomic analysis of the surprise examination paradox, 2002. http://www. univ-corse.fr/~franceschi/sep(gb).htm.
John McCarthy, Masahiko Sato, Takeshi Hayashi, and Shigeru Igarashi. On the model theory of knowledge. Technical report, Stanford, CA, USA, 1978.
John-Jules Ch Meyer and Wiebe Van Der Hoek. Epistemic Logic for AI and Computer Science. Cambridge University Press, New York, NY, USA, 1995.
Natalia Novak. Computer-aided reasoning about knowledge and justifications. Technical Report TR- 2014001, CUNY Ph.D. Program in Computer Science Technical Reports, January 2014.
Renate Schmidt. A list of computational tools useful for modal logics, and related logics, 2009. http:
//www.cs.man.ac.uk/~schmidt/tools/.
A. S. Troelstra and H. Schwichtenberg. Basic proof theory (2nd ed.). Cambridge University Press, New York, NY, USA, 2000.
