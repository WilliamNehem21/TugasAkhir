Available online at www.sciencedirect.com


Electronic Notes in Theoretical Computer Science 297 (2013) 3–25
www.elsevier.com/locate/entcs

Approximation Metrics Based on Probabilistic Bisimulations
for General State-Space Markov Processes: A Survey
Alessandro Abate ٨,1
Delft Center for Systems & Control Technische Universiteit Delft Mekelweg 2, 2628 CD Delft
The Netherlands

Abstract
This article provides a survey of approximation metrics for stochastic processes. We deal with Markovian processes in discrete time evolving on general state spaces, namely on domains with infinite cardinality and endowed with proper measurability and metric structures. The focus of this work is to discuss approxima- tion metrics between two such processes, based on the notion of probabilistic bisimulation: in particular we investigate metrics characterized by an approximate variant of this notion. We suggest that metrics between two processes can be introduced essentially in two distinct ways: the first employs the probabilistic conditional kernels underlying the two stochastic processes under study, and leverages notions derived from algebra, logic, or category theory; whereas the second looks at distances between trajectories of the two processes, and is based on the dynamical properties of the two processes (either their syntax, via the notion
of bisimulation function; or their semantics, via sampling techniques). The survey moreover covers the problem of constructing formal approximations of stochastic processes according to the introduced metrics.
Keywords: Markov Processes, Formal Approximations, Probabilistic Bisimulations, Metrics over Probability Measures, Lyapunov Theory, Stochastic Contractivity, Probabilistic Reachability, Randomized Methods.


Motivations and Objective
In order to cope with the increasing complexity of real-world engineering systems and with the intractability of their corresponding mathematical models, a number of studies have explored the development of techniques aimed at quantitatively

٨ This research is funded by the European Commission under the MoVeS project, FP7-ICT-2009-5 257005, by the European Commission under the NoE FP7-ICT-2009-5 257462, by the European Commission under Marie Curie grant MANTRAS PIRG-GA-2009-249295, and by NWO under VENI grant 016.103.020.
1 Email: a.abate@tudelft.nl

1571-0661 © 2013 Published by Elsevier B.V. Open access under CC BY-NC-ND license.
http://dx.doi.org/10.1016/j.entcs.2013.12.002

putting in relationship two models, a concrete one and an abstract one. The latter is generally obtained via a simplification of the first (e.g., by means of model reduction, low-order approximation, state-space clustering, or lumping and factorization) and represents a tractable version of it. Ideally, the abstract model should be, in a certain sense, equivalent to the concrete one. Equivalence between models is usually expressed with the notion of language correspondence, trajectory or trace equality, or with that of bisimulation relation between pairs of states of the two models. Unidirectional and thus less stringent versions of the notion of bisimulation are also used to express the idea of inclusion between the abstract model dynamics and that of the concrete one: in this sense, the abstract model represents a simulation of the concrete one.
From a different perspective, since frequently the exact notion of bisimulation translates into rather conservative requirements on the models under study, and because it is a notion that lacks robustness (against model parameter perturbations, for instance), the concept of approximate bisimulation has been introduced as a relaxed version of that of strict bisimulation. This approximate concept leads to the use of proper metrics (or pseudo-metrics) over the dynamics of the models. The use of approximate relations between models appears to be quite pertinent for models that are dynamically rich, such as models with continuous (uncountable) or even hybrid state spaces, as well as stochastic processes. For the latter in particular, the use of approximate notions allows the development of metrics that are robust to small perturbations of the models parameters, and accommodates quantitative correspondences between the realization likelihood of models trajectories.
This contribution focuses on probabilistic processes with general (continuous) state spaces and aims at surveying and discussing approximation metrics between pairs of such processes. In particular, we provide an overview of results in the literature that are based on the notion of approximate bisimulation. We decide to concentrate on approximate version of the notion of strong (rather than weak) bisimulation, and we only touch upon the concepts of (probabilistic) simulations.
This work suggests that metrics between processes, based on the concept of ap- proximate bisimulation, can be introduced essentially in two separate ways. The first approach employs the probabilistic conditional kernels underlying the stochas- tic processes under study – in this sense, the approximation comes from metrics between (marginals of) probability measures related to the two processes. The sec- ond procedure looks at distance metrics between trajectories of the two processes and utilizes the dynamical properties of the two processes to define such metrics: this can be done either by analyzing the models syntax, or by directly employing their semantics in order to compare realizations of the two models.
The two approaches are depicted in Figure 1. The blue and red dots represent realizations of two “similar” stochastic processes, which evolve over the Euclidean plane and are both initialized on the black dot (top right). The first approach refers to the magnified square at the bottom, which portrays the two corresponding con- ditional kernels. The second approach is pictorially represented by the top square, where the (point-wise) distance between the realization of the trajectories of the



Fig. 1. Approximation metrics for general state-space Markov processes: two approaches.
two processes is highlighted.
This work is structured as follows.
Section 2 provides a comprehensive coverage of the work on simulations, bisim- ulations and approximate versions thereof, with focus on probabilistic models living on general state spaces.
Section 3 introduces and discusses the models under study.
Section 4 presents the concept of exact and approximate (strong) probabilistic bisimulation, and provides related characterizations based on algebra, logic, and category theory.
Section 5 puts forward the definition and the characterization of the notion of probabilistic bisimulation function, which leads to the introduction of approxi- mate metrics between the trajectories of two processes.
Section 6 finally looks at semantic-based computations of distance metrics be- tween comparable probabilistic processes.
Section 7 discusses the surveyed techniques and looks forward at future research directions.

Review of Literature Background
The concept of strong probabilistic bisimulation over a discrete-time, finite-state Markov chain has been introduced in [46], based on earlier notions for non- probabilistic models [49,51]. The work in [36] uses similar notions for Markov decision processes with finite state spaces, and puts forward procedures for find- ing factored bisimilar models. The notion of weak bisimulation is discussed in [9,38,54] for a number of (finite-state) probabilistic processes. The contributions in [39,59] cover the notion of probabilistic simulation relations for classes of proba- bilistic automata. [10,11] provide a recapitulation and draw relationships between these notions. These concepts are of applicative interest and build on earlier work on approximation techniques, such as that of lumpability for Markov chains [13]

and in queuing theory [41].
The interesting work in [24] discusses approximate notions of bisimulations for finite state labeled Markov chains, and elaborates on this notions by using a log- ical approach as well as one based on games. The use of approximate notions is advocated in [32] and motivated by robustness issues related to the verification of specifications over probabilistic models. Furthermore, approximate notions appear much less restrictive than the exact one, particularly when applied over models with continuous state spaces – this is precisely what has been observed also for deterministic models, where notions of exact bisimulation have been developed only for limited classes of models, e.g. timed automata [7] (via the region graph con- struction), linear hybrid automata [37], o-minimal hybrid systems [45] and certain classes of linear (control) systems [50,61]. The introduction of approximate versions
[34] based on distance between trajectories of deterministic models has lead to the
study of approximate abstractions for nonlinear [55] and switched systems [35].
For continuous space processes (namely, discrete-time labeled Markov processes as in Section 3), [21] provides a relational and logical characterization of bisimu- lation (see Section 4). Alternatively, probabilistic bisimulations relations can be introduced via coalgebraic [20] or categorical arguments [64]. Building on these results, the material in [22] is relevant in that metrics for labeled Markov processes are discussed (see Section 4), whereas [23] proposes metrics via weak bisimulations, and the contributions in [29,30] discusses metrics for respectively finite- and infinite- state Markov decision processes.
Related to the notions above, [60] introduces exact bisimulations for communi- cating piecewise-deterministic Markov processes (which are models related to [38]),
[25] discusses bisimulation of continuous-time processes, [8] elaborates abstraction notions based on bisimulations for probabilistic process algebras, whereas [14] at- tempts definitions of bisimulations for stochastic hybrid models [12,17]. None of these works proposes approximate variants of the respective exact notions.
With focus on probabilistic models and on the development of metrics over systems trajectories (realizations) [34], the concept of probabilistic bisimulation functions (see Section 5) is introduced in [40] and elaborated in [1]. The recent work in [63] puts forward a reachability problem to find metrics between discrete- time stochastic processes.
From a different perspective, [5] puts forward an approach based on random- ization techniques to characterize approximation distances between processes over finite time horizons, with no assumptions on their dynamics (see Section 6). This approach also promises to provide model reduction or approximation techniques for classes of stochastic processes. Along this line of research, [26] introduces an ap- proximation for such processes. This approximation can be related to the work in [3,4] (which works with discrete-time stochastic hybrid systems), as well as to that in [62] (which uses Wasserstein Pseudometrics over continuous space processes) and to the classical reference in [43,44], which discusses weak approximations of stochas- tic processes, which has been applied on hybrid models in [42,56], but which offers no explicit approximation bound. Related to this works, [58] has proposed explicit

error bounds on a time and space discretization of a Markov process with certain ergodic properties.
Markov Processes over General State Spaces
We consider probabilistic processes defined over continuous spaces with Polish struc- ture [48]. We assume to be working on a topological space that is homeomorphic to a Borel subset of a complete (i.e., a metric space where every Cauchy sequence con- verges) and separable (i.e., which contains a countable dense subset) metric space. Furthermore, we assume that the space is endowed with a Borel σ-algebra, which is characterized by sets that are Borel measurable. The reference metric can be reduced to the usual Euclidean metric (more on this in the following).
The continuous state-space is denoted by S, whereas B(S) is the associated σ-algebra. Processes will be evolving in discrete time over the interval [0,N ] on a sample space ΩN+1 = SN+1, equipped with the canonical product σ-algebra B(ΩN+1). P is a probability measure defined on this event space.
We also introduce a control space U , which we assume to be Borel measurable
and in general continuous.
The following definition first appeared in [6], which focused on a rather rich state-space structure, namely a hybrid state space [12,17] – it can be shown [19] that a metric that is equivalent to the Euclidean one can be defined over this space. This model can be equivalently regarded as a Markov decision process [57] over a general state space with no rewards.
Definition 3.1 [Controlled Markov Process] Consider a discrete time controlled Markov processes (CMP) S = (S, T , U ) defined over the state space S, and characterized by T , a conditional stochastic kernel that assigns to each point s ∈ S and control u ∈ U a probability measure T (·|s, u). For any set A ∈ B(S), Ps,u(X(1) ∈ A) =  A T (ds|X(0) = s, u), where Ps,u denotes the conditional
probability P(·|s, u). Process S = (S, T , U ) is initialized according to a probability
distribution π : B(S) → [0, 1].	2
The syntax in Definition 3.1 leads to the following semantics for a trajectory
X(k) over the time horizon [0,N ]. Let us fixa control string {u0, u1,.  , uN−1; ui ∈ U}. Given an initial condition x ∈ S sampled from the probability distribution π, and given the control input u0 ∈ U , the value of the process at time k = 1 point is described by a probability law characterized by the conditional kernel T (·|x, u0). Likewise, for any k = {1,.  ,N − 1},X(k + 1) ∼T (·|X(k), uk).
Example 3.2 Consider the process S characterized as the solution X(k),k ∈ N, of the following stochastic difference equation:
X(k + 1) = X(k)+ a(X(k))u(k)+ b(X(k))w(k),
where X(·) ∈ Rn, u(·) takes values in a bounded set U , the functions a(·), b(·) are Lipschitz continuous and with linearly bounded growth, and w(k) ∼ N (0, 1) is

a standard normal random variable for any k ∈ N. Then, process S exists, is uniquely defined, and its dynamics can be characterized by the following kernel: T (·|x, u)= N (x + a(x)u,  b(x)).
An instance of a realization of this process can be either of the two traces depicted in Figure 1, which have a deterministic initialization (black dot) and evolve in discrete time according to (Gaussian) conditional kernels.	2
Let us now assume that U a ﬁnite set of labels (that is, elements taken from a finite alphabet). The following definition is derived from the work in [21,22,26] 2 .
Definition 3.3 [Labeled Markov Process] A labeled Markov process (LMP) S is a structure
(S, s0, B(S), {τu|u ∈ U}) ,
where S is the state space, s0 ∈ S is the initial state, B(S) is the Borel σ-field on
S, U is the set of labels, and
∀u ∈ U, τu : S× B(S) −→ [0, 1]
is a transition probability function, namely a set-valued function τu(s, ·) that is a probability measure on B(S) for each s ∈ S, and such that for each S ∈ B(S) the function τu(·, S) is measurable.	2
Definition 3.3 is generalized in [21,22,26] by allowing sub-probability measures τu. In this work, for the sake of consistency, we will only refer to complete probability measures. Notice that in general, unlike LMP, CMP do not specify the initial condition within the model definition, instead allowing for any choice of it within the state space.
If we semantically equate the labels of the LMP with the controls of the CMP, it is clear that labeled Markov processes in Definition 3.3 are a subclass of discrete time controlled Markov processes as in Definition 3.1, since the latter allows for a richer control structure. In fact the measure τu(s, ·) corresponds to the conditional kernel T (·|s, u). We thus proceed by utilizing the model with syntax in Definition
In the next sections we will come back to the differences in the semantical characterization of the control structure between LMP and CMP.

Exact and Approximate Probabilistic Bisimulations: Relations, Logics, and Categories
In the following we introduce exact and approximate notions of bisimulations for CMP. We emphasize that both concepts are to be regarded as strong notions, as opposed to weak versions as in [9,38,54] 3 . The definitions can be looked at from three different aspects: via relations, via logics, and via categories.

2 Some of these contributions work with analytic spaces, which are generalization of the Borel measurable ones that this work focuses on. However, since the properties of analytic spaces are not needed in this work and since Borel measurable sets are also analytically measurable, we have decided to focus on the latter.
3 Weak notions are introduced in order to abstract from “internal” moves that do not influence the future behaviour of a process.

Exact Characterization via Relations, Logics, and Categories
Recall that a relation over a given set is an equivalence relation if it is reflexive, symmetric, and transitive. (In this work we assume to be working with relations with finite or countable cardinality.)
Definition 4.1 [(Exact) Probabilistic Bisimulation] Consider two CMP S1 = (S1, T1, U ) and S2 = (S2, T2, U ). An equivalence relation R ⊆ S1 × S2 is a bisim- ulation relation on S1 × S2 if, whenever s1R s2 for any s1 ∈ S1, s2 ∈ S2, for given u ∈U and set S˜1 × S˜2 ∈ (S1 × S2)/R (which is Borel measurable), it holds that
T1(S˜1|s1, u)= T2(S˜2|s2, u).
A pair of states s1 ∈ S1, s2 ∈ S2 is said to be (probabilistically) bisimilar if ∃R, a bisimulation, such that sR t, whereas two CMP S1, S2 are said to be (probabilis- tically) bisimilar (denoted S1R S2) if there exists a bisimulation relation R that is total over respectively S1 and S2 4 .	2
Notice that the autonomous case, characterized by a labels set with a single element, can be obtained as a special case of the above definition.
Example 4.2 Consider two processes Si,i = 1, 2, characterized by the models (as per Example 3.2)
Xi(k + 1) = Xi(k)+ ai(Xi(k))ui(k)+ bi(Xi(k))wi(k),
where we assume ai(Xi)= −Xi, ui = 1 ∀k ≥ 0 (U = {1}), b1(X1)= 0.4X1, b2(X2)= 0.3X2, and where Xi ∈ R = Si. The dynamics are quite trivial, since a trajectory is reset at any point in time to a neighborhood of the origin according to a Gaussian kernel with state-dependent variance. The following simple relation
(−∞, 0] × (−∞, 0],
(−∞, 0] × (0, +∞),
R =
(0, +∞) × (−∞, 0],
⎪⎪ (0, +∞) × (0, +∞) ⎪⎪

induces an (exact) bisimulation relation between the two processes, since conditional on any pair of states in S1 × S2 = R2, the probability that either process Xi transitions to the respective projection of an element of R is equal to 0.5. Notice that R induces a partition of the composed state space R2.	2
A logic L can be defined, which allows to show that two states are bisimilar if and only if they satisfy the same formulas φ of the logic L [21]. This approach emphasizes the fact that bisimulation is an equivalence relation.

4 As a special case, if the initial conditions of S1, S2 are characterized by two given sets, then the relation should hold over pairs of states extracted from each of these sets respectively.

The work in [21] further characterizes probabilistic bisimulations via categori- cal notions (based on zigzag morphisms). Related to this approach, [20] employ coalgebraic notions to precisely relate probabilistic models. Similarly, probabilis- tic bisimulations relations over continuous-space processes can be introduced via categorical arguments, as discussed in [64].
Approximate Characterization via Metrics based on Functions
The exact relational and logical characterizations are formal, but have to be re- laxed in order to accommodate for computational robustness [65] and for real-world engineering applications.
Probabilistic bisimulation can be sufficiently characterized by a family of func- tional expressions [22]. More specifically, given a process S , consider a family Fc of real-valued functions fS : S → [0, 1], which are defined by a grammar (a set of operations). The operations induced by the grammar can be related to the rules of the logic L. The parameter c ∈ (0, 1] is utilized in the definition of an operator in order to rescale the computation of the expected value at successive times (notice that this operation also depends on the labels of the process), and is in practice put forward to discount the future. The introduction of the family Fc of functions further allows to define a metric on processes.
Definition 4.3 [Metric between processes] Consider two CMP Si = (Si, Ti, U ),i = 1, 2. A family Fc of functional expressions on Si induces a distance as follows:
dc(S1, S2)= sup |fS − fS |,
2
ƒ ∈Fc

where fSi are functions in Fc evaluated over the respective spaces Si.	2
It can be shown that, for any c ∈ (0, 1], dc is a pseudo-metric 5 . As a special instance, d0 characterizes bisimilar processes [22]. Quite interestingly, for c < 1 it can be shown that, given an approximation parameter ϵ > 0, the problem of checking dc(S1, S2) < ϵ is decidable.
This discussion leads to the notion of approximate bisimulation with level ϵ, or simply of ϵ-bisimulation [24]. Let R be a relation on a set A. A set A˜ ⊆ A is said to be R-closed if R(A˜)= {t|sR t, s ∈ A˜}⊆ A˜.
Definition 4.4 [Approximate Probabilistic Bisimulation] Consider two CMP S1 = (S1, T1, U ) and S2 = (S2, T2, U ). A relation Rє ⊆ S1 × S2 is an ϵ-bisimulation relation if, for any s1 ∈ S1 there is a s2 ∈ S2 such that s1Rєs2, and for any u ∈ U and Rє-closed set S˜1 × S˜2 ⊆ S1 × S2, it holds that
T1(S˜1|s1, u) − T2(S˜2|s2, u) ≤ ϵ.

5 In conformity with the discussions in [22,64], in the following we will not be formally distinguishing between pseudo- (or semi-)metrics and actual metrics, since we are simply interested in (pseudo-)metrics that are sufficient for characterizing bisimilarity (or trajectory equivalence, see Section 5) – the necessity is not fundamentally important.

In this case we say that the two CMP are ϵ-bisimilar (denoted S1Rє S2).	2
In general Rє does not satisfy the transitive property, and as such is not an equivalence relation [24]. Hence, it induces a cover of £1 × £2 but in general not a partition.
Example 4.5 An example of approximate probabilistic bisimulation relation Rє is obtained by adapting the models Si,i = 1, 2 from Example 4.2 allow for a noise term with a small drift ηi, namely wi ~ N (ηi, 1) and η1 /= η2. Based on the corresponding probabilistic kernels, this allows computing an upper bound ϵ on the (absolute value of the) difference in the marginalization of the corresponding kernels over the sets in R2 induced by R = Rє. In this specific instance Rє induces a partition of the composed state space R2 — this fact does not old in general. 2
The use of a metric between processes, as in Definition 4.3, allows to relate the distance in time between processes that are “similar.” We then employ a result from [22] and use it in the case where similarity between processes is precisely characterized by an approximate bisimulation relation.
Theorem 4.6 Consider two CMP S1 = (£1, f1, C ) and S2 = (£2, f2, C ) that are ϵ-bisimilar, namely S1RєS2. Then dc(S1, S2) < kϵ, with c < 1 and where k = supn∈R+ ncn.
Proof. The claim follows from [22, Prop. 7.5], where an ϵ-approximate bisimulation relation between S1 and S2 is used in place of the ϵ-perturbation notion of [22, Def. 7.4].	2
The idea to define discounted metrics over probability measures that admit bisimulation as a fixed point is taken up in [30], which uses the Kantorovic distance between probability measures to approximate MDP over infinite state spaces. This distance is related to that discussed in Section 6. The cited work in [64] introduces a discounted metric that is both closely related to that presented in this survey and which is also based on the Kantorovic distance.
Remark 4.7 While for processes over discrete, finite state spaces there exist algo- rithmic procedures to compute exact [11] and approximate [24] probabilistic bisimu- lations, the computational aspects related to these notions for processes over contin- uous state spaces require further research. Presently, based on these notions a few results [3,18,26] have put forward techniques to approximate these processes with finite state ones — however their scalability properties ought to be more thoroughly assessed. Next section proposes an alternative approach to synthesize approximate probabilistic bisimulations, which hinges on the computation of a function relating the two processes.	2

Approximate Bisimulations via Probabilistic Bisimu- lation Functions
Consider a CMP S1 = (£1, f1, C1) with associated realizations X1(k),k ∈ N, and a second model S2. The quantification of similarity between S1 and S2 can be assessed by comparing trajectories of the two models. A formal comparison can be set up by seeking a function g : £1 × £2 → R+ that induces a metric over the distance between the trajectories [40], for instance
g(X1, X2)= X1 − X2  2,	if £1 = £2.
If £1 /= £2, in order to effectively relate the two processes, we need to assume the existence of proper output maps Yi : £i → £o taking values over the same observation space £o. In this instance, we would then consider a function
g(X1, X2)= Y1(X1) − Y2(X2)  2.
In general, given such a measurable, non-negative function g evaluated over (X1(k), X2(k)),k ∈ N (the Markov process related to the joint system (S 1, S 2)), the quality of the approximation between S1 and S2 is then characterized over a finite and an infinite time horizon, by the following two quantities:

V N (x)= Px  sup g(X1(k), X2(k)) ≥ δ	(1)
0≤k≤N
and
Vδ(x)= Px	sup g(X1(k), X2(k)) ≥ δ	.	(2)
k≥0
Here x ∈ £1 × £2 represents a pair of initial conditions, and δ is a non-negative real number denoting the approximation quality.
It is of interest to provide meaningful and possibly tight bounds for the proba- bilistic quantities in (1)-(2). In order to do so, let us start by recalling the following classical notion [27]:
Definition 5.1 [(Super-) Martingale] Consider an autonomous stochastic process
X(k),k ≥ 0, taking values in £. A function χ : £ → R is called a martingale for the process X(k),k ≥ 0, if for any x = X(0) ∈ £,k ≥ 0, Ex[χ(X(k))] = χ(x). The function χ is called a supermartingale if Ex[χ(X(k))] ≤ χ(x).	2
In words, a (super-)martingale is a function of the process which, conditional on any initial condition, has an expected value that remains equal (does not increase) in time. Notice that the controls have not been introduced so far – they do play a role in the following. Let us introduce the notion of stochastic bisimulation function (SBF), as presented for continuous-time models in [40].
Definition 5.2 [Stochastic Bisimulation Function] Let the measurable function ϕ :
£1 × £2 → R+ satisfy the following conditions:

ϕ(x) ≥ g(x) for all x ∈ £1 × £2;
for any u1 ∈ C1, there exists u2 ∈ C2 such that the function (ϕ(X1(k), X2(k)))k≥0 is a Px-supermartingale for any fixed x ∈ £1 × £2.
Then ϕ is a stochastic simulation function of S1 by S2. If ϕ is also a stochastic simulation function of S2 by S1, then it is an SBF for the function g with respect to the joint process (S1, S2). If two processes admit an SBF, they are said to be probabilistically bisimilar with precision ϕ(x).	2
Notice how in this definition the controls of the two CMP are treated quite differently than those in Definitions 4.1 and 4.4, which were originally stated for LMP and associated labels. We will comment on these semantical differences in Remark 5.6.
The existence of an SBF can be directly used to compute an upper bound for the quantities in (1) and (2). More precisely, selecting a parameter δ > 0, any two initial conditions xi ∈ £i,i = 1, 2, and by resorting to the properties of the SBF (as described in Definition 5.2) and to the Markov inequality [27], the following holds:
P(x ,x ) sup0≤k<∞  Y1(X1(k)) − Y2(X2(k))  2 ≥ δ 

= P(x1,x2)  sup0≤k<∞ g (X1(k), X2(k)) ≥ δ
≤ P(x1,x2)  sup0≤k<∞ ϕ (X1(k), X2(k)) ≥ δ
≤ ϕ(x1,x2) .
(3)

We have shown that the knowledge of an SBF allows deriving bounds on the ap- proximation quality between two processes. Next, we survey three conceptually different approaches to find such an SBF.
Characterization of Stochastic Bisimulation Function based on Stochastic Sta- bility
The contribution in [40] puts forward conditions to construct an SBF for certain classes of continuous-time stochastic processes, namely models that are linear in the drift, in the diffusion coefficient, and in the observation map. The setup allows for spontaneous jumps (under homogeneous arrivals) with related (linear) resets, thus resulting in a model with hybrid structure [12,17]. The reader is referred to [40] for practical examples of computation of stochastic bisimulation functions.
In the present work we re-derive a condition for the existence of an SBF similar to [40] for discrete time models Si,i = 1, 2, and for the sake of clarity we focus on the following simpler (non hybrid) dynamics:

⎧ Xi(k + 1) = AiXi(k)+ Biui(k)+ FiXi(k)wi(k),
⎩ Yi(k)= CiXi(k).

(4)

Here wi are independent standard normal random variables, and we assume that the

outputs of the two processes take values over the same space. Consider a candidate SBF with the following quadratic form:
ϕ(x)= xT Mx,	(5)
where x = [X1 X2]T and M is a properly sized, symmetric, non-negative definite, constant matrix.
Theorem 5.3 Assume that S1 and S2 are autonomous (namely, disregard the terms Bi). Consider the joint process (S1, S2). A function ϕ as in (5) is a stochas- tic bisimulation function for S1 and S2 if and only if
M − CT C ≥ 0,
AT MA + F T MF − M ≤ 0,



where C = [C
— C ], A = ⎡ A1 0 ⎤, and F = ⎡ F1 0 ⎤.

1	2	⎣ 0 A ⎦
2
⎣ 0 F2 ⎦

Proof. The two conditions are directly derived from the corresponding require- ments in Definition 5.2. In particular, notice that
g(X1, X2)= C1X1 − C2X2  2 = xT CT Cx
and compare with (i). Furthermore, with reference to (ii) and Def. 5.1 and recalling the independence of the sample realizations of the noise process,
Ex [ϕ(X1(k + 1), X2(k + 1))]
= Ex [X1(k + 1) X2(k + 1)]M [X1(k + 1) X2(k + 1)]T
= xT AT MA + F T MF x.

Example 5.4 Consider the models Si,i = 1, 2 from Example 4.2, where AiXi = Xi + ai(Xi), and where FiXi = bi(Xi). The processes are (semantically) au- tonomous, since ui = 1 is fixed. An SBF for Si,i = 1, 2 is obtained considering

M = CT C = ⎡
1 −1 ⎤ ,

⎣ −1	1 ⎦

which is clearly positive semi-definite, and since matrix A is degenerate, M is such that
M − F T MF = CT C − (CF )T CF = (C(I − F ))T C(I − F ) ≥ 0.

2

Let us generalize the previous result to the non-autonomous case.
Theorem 5.5 Consider two non-autonomous processes S1 and S2. A function
ϕ as in (5) is a stochastic bisimulation function for S1 and S2 if and only if,
∀x ∈ £1 × £2
M − CT C ≥ 0,
max min  xT AT MA + F T MF − M x + 2xT AT MBu ≤ 0,
max min  xT AT MA + F T MF − M x + 2xT AT MBu ≤ 0,
where B = ⎡ B1 0 ⎤ and u = [u u ]T .
1  2
0 B2
Proof. It follows similarly to that of Theorem 5.3.	2
Let us now elaborate on the different role that controls in CMP play as opposed to labels in LMP.
Remark 5.6 [Labels vs Controls] Notice that the condition in Theorem 5.5 is set up as a dynamical game between the two models. This is in accord with the role that control inputs play in Definition 5.2, and is in contrast with Definition 4.1 or
4.4 (originally stated for LMP), which fixed the same control input for both models. This difference highlights two distinct ways to conceive the role of labels for LMP on the one hand, and that of control inputs for CMP on the other. In LMP labels are intended as predefined schedules or actions taken by the environment (or adversary), which the system reacts to. This adheres to the role that nondeteminism classically plays in LMP. For the second models (CMP, as well as MDP in the systems and control literature) control inputs are actions to be synthesized based on an objective function, or policies (“strings” of control actions over a time span) that are chosen for the model. Notice how this difference reflects in the game-theoretical definition of approximate bisimulation given in [24] (as a game between a “prover,” i.e. a model, and an “adversary”), in contrast to the formulation in Theorem 5.5.   2
Theorem 5.5 can be re-stated according to the LMP interpretation as follows:
Corollary 5.7 Consider two non-autonomous processes S1 and S2 with the same input space C. A function ϕ as in (5) is a stochastic bisimulation function for S1 and S2 if and only if for any u¯ = [u u]T ∈C × C the following holds, ∀x ∈ £1 × £2:
M − CT C ≥ 0,
xT AT MA + F T MF − M x + 2xT AT MBu¯ ≤ 0.


Conversely, for the sake of completeness, we provide a statement of Definition
4.1 according to the CMP interpretation as follows (notice that now C1 /= C2):

Definition 5.8 Consider two CMP S1 = (£1, f1, C1) and S2 = (£2, f2, C2). A binary relation R ⊆ £1 × £2 is a simulation of S1 by S2 if, for any s1 ∈ £1 there is a s2 ∈ £2 such that s1R s2, and for any u1 ∈ C1 and R-closed set S˜1 × S˜2 ∈ £1 × £2, there exists a u2 ∈ C2 such that
f (S˜1|s1, u1)= f (S˜2|s2, u2).
If R is also a simulation of S2 by S1, then it is a bisimulation of S1 and S2 and corresponds to an equivalence relation between pairs of states.	2
A similar restatement can be introduced for the approximate version of proba- bilistic bisimulation of Definition 4.4.
In this section we have raised structural assumptions on the joint process under study to derive sufficient conditions for the existence of an SBF with the shape of equation (5). These conditions can be shown to lead to certain stochastic stability properties of the models under study, and equation (5) to be related to a Lyapunov function for the process [31].

Characterization of Stochastic Bisimulation Function based on Stochastic Con- tractivity
The contribution in [1] introduces sufficient conditions for the existence of an SBF, based on the use of contractivity analysis [47] for probabilistic systems. (Please refer to this contribution for practical examples of computation of stochastic bisimulation functions.) Furthermore, it shows that the notion of stochastic contractivity is re- lated to a probabilistic version of the concept of incremental stability. Interestingly, the results presented in the previous paragraph and based on [40] leveraged as- sumptions on model stability that are analogous to the deterministic equivalents in [50,61], and similarly the contractivity assumptions, related to incremental stability, parallel similar results in corresponding deterministic literature [35,55]. The work in [2] extends the characterization of SBF to more general hybrid models [12,17].
In the present work we tailor the conditions in [1] to discrete time processes Si
of the following kind:

⎧ Xi(k + 1) = ai(Xi(k), ui(k)) + fi(Xi(k))wi(k),
⎩ Yi(k)= ci(Xi(k)),	k ∈ N.

(6)

In general, the functions ai, fi and ci can be nonlinear. As usual, the process Xi ∈ £i (e.g. Rn) and wi(k) are independent standard normal random variables. We assume that a solution is well defined, which solely requires boundedness assumptions on the quantities at the right-hand side of the state equation. Moreover, we assume that the observation functions ci vanish at the origin and that they are Lipschitz continuous with constant 0 ≤ νi < ∞.
Let us focus on autonomous models (i.e., let us disregard the effect of ui). The following definition is inspired by [52,53], which extends earlier studies for deter-

ministic models [47].
Definition 5.9 [Stochastic Contractivity] Consider the process Si in (6) charac- terized by its state equation with no control input. Assume that the following conditions are valid:
ai(·) is such that, for all x˜ ∈ £i, ∃ Λi < ∞ : λmax ∂ai (x˜)T ∂ai (x˜)  ≤ Λi,
where ∂ai/∂x(x˜) is the Jacobian of ai evaluated at x˜, and λmax(·) is a function computing the maximum among the real parts of the eigenvalues of a matrix;
fi(·) is Lipschitz continuous, with finite and positive constant Ki.
Then the system Si in (6) is said to be stochastically contractive (in the identity metric) if Λi + 2Ki < 1.	2
Properties of stochastically contractive processes (such as extensions to non- identity, weighted metrics, as well as the relationship to probabilistic incremental stability) are further discussed in [1].
Next, given two processes Si,i = 1, 2, we show that the property of stochastic contractivity of the joint process (S1, S2) entails a condition of probabilistic bisim- ilarity between the processes. The contractivity is intended to hold for the same metric (as discussed above, we consider here the identity metric) for both processes. Consider a parallel composition of the two processes,

a = ⎡ a1 ⎤ ,	f = ⎛ f1 0 ⎞ ,	c = [I − I] ⎡ c1 ⎤ = [c
— c ] ,

⎣ a2 ⎦
⎝ 0 f2 ⎠
1	2
c2

where the new output map computes the difference between the two original ones. Let us again start considering autonomous models.
Theorem 5.10 Consider two autonomous processes, solutions of systems S1, S2 as in (6). If the composition of S1, S2 is stochastically contractive, then S1, S2 are probabilistically bisimilar.
When existing, a probabilistic bisimulation function has the form ψ(X1, X2) = 2ν  [X1, X2]T 2, where ν = max{ν1, ν2}.	2
Example 5.11 Consider the models Si,i = 1, 2 from Example 4.2, where the vector field ai(Xi) takes the value Xi + ai(Xi) as in Example 4.2, whereas fi(Xi)= bi(Xi). The processes are again (semantically) autonomous, since ui = 1 is fixed. Notice that Λi = 0, whereas Ki < 1/2, so that Λi + 2Ki < 1. Since ci(Xi)= Xi, we have that νi = 1. Given that both processes are contractive, an SBF for Si,i = 1, 2 is obtained considering ψ(X1, X2)=2  [X1, X2]T 2.	2
The extension to the non-autonomous case follows.
Corollary 5.12 Consider two processes, solutions of systems S1, S2 as in (6). S1, S2 are probabilistically bisimilar if (1.) for any u1 ∈ C1 there exists a u˜2 ∈ C2 and if (2.) for any u2 ∈ C2 there exists a u˜1 ∈ C1 such that the composition of S1, S2

is stochastically contractive in the following two instances, ∀(x1, x2) ∈ £1 × £2:



a1.
=	a1(·, u1)	, and a a2(·, u˜2)
=	a1(·, u˜1)	,
a2(·, u2)

with associated parameters Λ1. and Λ2. respectively. Here f1. = f2. and we assume it is Lipschitz with parameter K. The above condition can be expressed as:
max min Λ1. + 2K < 1,	max min Λ2. + 2K < 1.
u1∈U1 u˜2∈U2	u2∈U2 u˜1∈U1
When existing, a probabilistic bisimulation function has the form ψ(X1, X2) = 2ν  [X1, X2]T 2.	2
In contrast to the approach in the previous section and based on matrix inequal- ities, the contractivity conditions are directly computable on the system dynamics (abstractly, it is possible to characterize the portion of the state space where such conditions are valid, and this region is – in a certain sense – invariant); also, the probabilistic bisimulation function is directly obtained; finally, the conditions are applicable to nonlinear dynamics; however, at present the former results are ap- plicable to models with richer dynamics. Both approaches can potentially yield bounds that are conservative.

Characterization of Stochastic Bisimulation Function as solution of a Proba- bilistic Reachability Problem
For a measurable function g : £1 × £2 → R+ and a parameter δ ∈ R+ define the
0	0
superlevel set
Sg(δ)= {x ∈ £1 × £2 : g(x) > δ}.

Consider the event set corresponding to the sample space Ω over respectively a finite and infinite time horizon N ∈ N ∪ {∞}, ΩN+1 = (£1 × £2)N+1, and equipped with the canonical product topology. Let us define the following events over ΩN+1, for any N ≥ 0 and A ∈ B(£1 × £2):
rN (A)= {ω ∈ ΩN+1|∃n ∈ [0,N ]: X(n, ω) ∈ A},
r(A)= {ω ∈ Ω∞|∃n ≥ 0: X(n, ω) ∈ A}.

The quantity rN (A) expresses the event that the joint process X = (X1, X2) enters set A within the time horizon [0,N ], whereas r(A) extends this quantity to the infinite horizon.
For a finite horizon N , it can be noticed that
V N (x)= Px[rN (Sg(δ))],

thus the metrics of interest V N (x) can be calculated by solving a probabilistic reach- ability problem in discrete time [6]. A number of contributions have put forward techniques to approximately compute this quantity [4,28].
Next, we focus on the infinite horizon case, where
Vδ(x)= Px[r(Sg(δ))].
Notice this latter quantity is in general difficult to precisely quantify. Recent work
[63] has provided methods for bounding this quantity or raised conditions for com- puting it with finite-step procedures. These conditions critically hinge on deciding and computing the presence of “absorbing” sets for the dynamics [63]: it is interest- ing to notice that these sets are related to the notions of stability and contractivity presented above.
The extension to the controlled case involves again setting up a game over the control inputs of the two models. The reader is referred to [63] for an example of computation of such a stochastic bisimulation function.

Approximation Metrics via Sampling Techniques and Randomization Algorithms
The collection of definitions and concepts described above allow establishing met- rics for the a-priori quantification of the similarity between (the distributions or trajectories of) two processes when considered over a finite or infinite time horizon. As such, they relied on structural assumptions over the models under study.
Next we present an approach, first described in [5], which has the advantage to be valid for general models, with no specific structural assumptions raised on them. It examines sample trajectories of the two processes over finite horizons. In other words, while the approaches above focused on the syntax of the models, this technique directly exploits the process semantics. The material focuses on the autonomous case.
Consider two autonomous processes S1, S2, for which equation (3) can be in- terpreted as follows:
Px dT (S1, S2) > δ  ≤ ϵ	⇔	Px dT (S1, S2) ≤ δ ≥ 1 − ϵ,
where dT (·, ·) represents a metric between trajectories evaluated over the finite time horizon [0,T ] and started at x ∈ £1 × £2, whereas δ is a given desired parameter quantifying the approximation precision, and ϵ is an a-priori quantity (probabilistic confidence on the approximation) depending on the models. The choice of the metric dT (·, ·) is unrestricted; [5] employs either a distance in time between the trajectories, or a Hausdorff distance between the traces of the two processes.
From a different perspective, the inequalities above can be interpreted as a quantification of the approximation (δ), given a certain certainty level (1 −ϵ) on the similarity of the two processes. The quality δ of the approximation up to level 1 − ϵ can be assessed as the solution of the following chance-constrained optimization

problem [15]:
min δ,	subject to:	(7)
δ∈঩
Px dT (S1, S2) ≤ δ ≥ 1 − ϵ.
Notice that (7) is a semi-infinite optimization program, since the number of proba- bilistic constraints is in general infinite while the number of optimization variables (δ) is finite. Denote with δє the solution of (7): while the computation of this solu- tion is in general hard, it can be mitigated by using a randomized approach, which provides an estimate of δє with approximation guarantees.
The randomized algorithm executes N trajectories of the two processes S1, S2
over [0,T ], for random extractions of the initial condition x and of the driving uncer- tainty. It then computes their distance dT (S1, S2) and discards the k < N obtained largest values, thus finding an approximate solution δˆє. Based on arguments devel- oped in [16], the work in [5] shows that a proper choice of the parameters k, N allows ensuring the feasibility of the solution δˆє (namely, the verification of the probabilis- tic constraints), and provides bounds on its performance degradation. This result holds up to a second confidence parameter that can be properly tuned. Intuitively,
by extracting at random N executions of the processes and discarding a-posteriori a
fraction k/N of them that corresponds to the largest discrepancies between the pro- cesses, one can improve the quality bound δ while guaranteeing that the violation set has size smaller than or equal to the prescribed ϵ value.
Additionally, the approach also enables an additional feature: the design of an approximation. Recall that, thus far, we have assumed that both models S1, S2 have been given. Here instead, we postulate that S2(θ),θ ∈ Θ, is a parameterized approximation of S1, where Θ is either a finite or an infinite but compact set. The synthesis problem can be stated as:


min
δ∈঩,ϴ∈Θ
δ,	subject to:
Px dT (S1, S2(θ)) ≤ δ ≥ 1 − ϵ.

The problem can be solved similarly as that in (7). In the instance of a continuous Θ, the argument within the probabilistic constraints needs to be convex in the optimization variable θ [5]. In the above problem we are actually selecting an optimal abstraction S2 of a given model S1, while quantifying its approximation level.
A few comments are due. The advantages of this approach over those based on the synthesis of a probabilistic bisimulation function are
the absence of assumptions on the dynamics of the two processes,
and the possibility of approaching the problem of synthesis of an approxima- tion.
On the other hand, the limitations are

the presence of a confidence level on the obtained bounds – this level can nevertheless be finely tuned,
the validity of the outcomes over finite horizons of time,
as of yet, the absence of an approach for non-autonomous models.
As discussed in Section 4 with reference to [26,64], the distance between two (comparable) stochastic processes can also be studied by setting up metrics on the corresponding probability distributions over their sample spaces. There is a vast literature on the use of metrics between probability measures [33]. Related to the work presented in this Section, the approach in [62] leverages Wasserstein pseudo- metrics between two processes, and approximates them by empirical quantities, obtained by taking samples of the trajectories of the two processes. While the empirical quantities are proven to converge to the actual distance with the number of samples taken, this approach does not provide explicit bounds based on finite samples for the distance between the two processes.

Discussion and Conclusions
The use of metrics to quantify distances between processes has a long history [33]. This survey has focused on distances based on the approximate notion of probabilis- tic bisimulation, which has seen a recent increased interest both from the depend- ability and formal verification community, as well as within the systems and control field. The two communities clearly differ in the respective approach to the problem: in a quest for categorization, it superficially looks like the first method opts for em- ploying the underlying conditional kernels of the processes under study, whereas the second favors a trajectory-based approach to the problem. Furthermore, the two techniques are grounded on different mathematics: algebra, logics, and category the first, versus dynamical systems (Lyapunov theory, contractivity and invariance anal- ysis) the second. As an alternative, sampling approaches and randomized methods look at the approximation problem from a totally different perspective. Here the focus is on the semantics of the processes and on the possibility to extract trajec- tories over a finite time horizon. The latter approach appears to yield results that are perhaps less formal (they hold with given confidence bounds, though extremely high), yet with outcomes that are less conservative and not stymied by assumptions on the model syntax (such as model stability, contractivity, etc.).
Looking forward, this survey would like to draw the attention to and place some emphasis on two topics:
practical computation of approximation levels between two given processes, and
synthesis of approximations of a given general state-space stochastic process.
Indeed, while the majority of the examined approaches assume to be given two similar processes to compare (one of which may be regarded as an approximation or an abstraction of the other), only a few put forward procedures for model ap-

proximation or abstraction with quantified quality. In particular:
The work in [26], followed by [18], puts forward an approximation based on time unfolding and relates it to the distance metrics developed by the same authors.
The work in [1] puts forward a procedure that constructs a discrete approximation of a diffusion process. The procedure is based on the discretization of space and time. Given a diffusion process, sufficient conditions for the existence of such an approximation are raised. It shows that the abstraction is probabilistically bisimilar to the original process, up to a certain approximation precision.
The work in [5] allows the design of an approximation of a continuous-space pro- cess. Similarly, the work in [62] allows for a synthesis of approximating processes.
The contributions in [3,58] have proposed two separate techniques to abstract a stochastic model into a finite-state Markov chain with probabilistic bounds on the distance in time between the trajectories of the two processes.
An emphasis on the computability aspects as well as on the problem of synthesis of abstractions will lead to practically relevant procedures helping with the analysis, verification, and control of general state-space Markov processes.
Acknowledgments
Thanks to Ilya Tkachev, to Maria Prandini, and to Alessandro D’Innocenzo for the collaboration on respectively [63], [5], and [3]. Thanks to Joost-Pieter Katoen and to Holger Hermanns for extended conversations, as well as to Martin Fr¨anzle, Prakash Panangaden, Agung Julius, Antoine Girard, and Paulo Tabuada for bene- ficial discussions, on the notion of bisimulation for (deterministic and) probabilistic processes.

References
Abate, A., A contractivity approach for probabilistic bisimulations of diffusion processes, in: Proceedings of the 48th IEEE Conference on Decision and Control and the 28th Chinese Control Conference, Peking, PRC, 2009, pp. 2230–2235.
Abate, A., Probabilistic bisimulations of switching and resetting diffusions, in: Proceedings of the 49th IEEE Conference on Decision and Control, Atlanta, GA, 2010, pp. 5918–5923.
Abate, A., A. D’Innocenzo and M. Di Benedetto, Approximate abstractions of stochastic hybrid systems, IEEE Transactions on Automatic Control 56 (2011), pp. 2688–2694.
Abate, A., J.-P. Katoen, J. Lygeros and M. Prandini, Approximate model checking of stochastic hybrid systems, European Journal of Control 16 (2010), pp. 1–18.
Abate, A. and M. Prandini, Approximate abstractions of stochastic systems: a randomized method, in: Proceedings of the 50th IEEE Conference on Decision and Control and European Control Conference, Orlando, FL, 2011, pp. 4861–4866.
Abate, A., M. Prandini, J. Lygeros and S. Sastry, Probabilistic reachability and safety for controlled discrete time stochastic hybrid systems, Automatica 44 (2008), pp. 2724–2734.
Alur, R. and D. L. Dill, A theory of timed automata, Theoretical Computer Science 126 (1994), pp. 183– 235.
Andova, S. and J. Baeten, Abstraction in probabilistic process algebra, in: Tools and Algorithms for the Construction and Analysis of Systems, LNCS 2031, 2001, pp. 204–219.


Baier, C. and H. Hermanns, Weak bisimulation for fully probabilistic processes, in: Computer-Aided Verification, LNCS 1254, 1997, pp. 119–130.
Baier, C., J. Katoen, H. Hermanns and V. Wolf, Comparative branching-time semantics for Markov chains, Information and Computation 200 (2003), pp. 492–508.
Baier, C. and J.-P. Katoen, “Principles of Model Checking,” The MIT Press, Cambridge, Massachusetts, 2008.
Blom, H. and J. Lygeros (Eds.), “Stochastic Hybrid Systems: Theory and Safety Critical Applications,” Number 337 in Lecture Notes in Control and Information Sciences, Springer-Verlag, Berlin, 2006.
Buchholz, P., Exact and ordinary lumpability in finite Markov chains, Journal of Applied Probability
31 (1994), pp. 59–74.
Bujorianu, M., J. Lygeros and M. Bujorianu, Bisimulation for general stochastic hybrid systems, in:
Hybrid Systems: Computation and Control (HSCC 05) (2005), pp. 198–214.
Calafiore, G. and M. Campi, Uncertain convex programs: randomized solutions and confidence levels, Mathematical Programming 102 (2005), pp. 25–46.
Campi, M., S. Garatti and M. Prandini, The scenario approach for systems and control design, Annual Reviews in Control 33 (2009), pp. 149–157.
Cassandras, C. and J. Lygeros (Eds.), “Stochastic Hybrid Systems,” Number 24 in Control Engineering, CRC Press, Boca Raton, 2006.
Danos, V., J. Desharnais and P. Panangaden, Labeled Markov processes: stronger and faster approximations, in: In Proceedings of the 18th Symposium on Logic in Computer Science (LICS 03), 2003, pp. 341–350.
Davis, M. H. A., “Markov Models and Optimization,” Chapman & Hall, 1993.
de Vink, E. and J. Rutten, Bisimulation for probabilistic transition systems: A coalgebraic approach, in: Proceedings of the 24th International Colloquium on Automata Languages and Programming (ICALP 98), 1998.
Desharnais, J., A. Edalat and P. Panangaden, Bisimulation for labeled Markov processes, Information and Computation 179 (2002), pp. 163–193.
Desharnais, J., V. Gupta, R. Jagadeesan and P. Panangaden, Metrics for labelled Markov processes, Theoretical Computer Science 318 (2004), pp. 323–354.
Desharnais, J., R. Jagadeesan, V. Gupta and P. Panangaden, The metric analogue of weak bisimulation for probabilistic processes, in: Proceedings of the 17th Annual IEEE Symposium on Logic in Computer Science (LICS 02), 2002, pp. 413 – 422.
Desharnais, J., F. Laviolette and M. Tracol, Approximate analysis of probabilistic processes: logic, simulation and games, in: Proceedings of the International Conference on Quantitative Evaluation of SysTems (QEST 08), 2008, pp. 264–273.
Desharnais, J. and P. Panangaden, Continuous stochastic logic characterizes bisimulation of continuous-time Markov processes, The Journal of Logic and Algebraic Programming 56 (2003), pp. 99– 115.
Desharnais, J., P. Panangaden, R. Jagadeesan and V. Gupta, Approximating labeled Markov processes, in: Proceedings of the 15th Annual IEEE Symposium on Logic in Computer Science (LICS 00), 2000,
pp. 95–105.
Durrett, R., “Probability: Theory and Examples - Third Edition,” Duxbury Press, 2004.
Esmaeil Zadeh Soudjani, S. and A. Abate, Adaptive gridding for abstraction and verification of stochastic hybrid systems, in: Proceedings of the 8th International Conference on Quantitative Evaluation of SysTems (QEST 11), Aachen, DE, 2011, pp. 59–69.
Ferns, N., P. Panangaden and D. Precup, Metrics for finite Markov decision processes, in: Proceedings of the 20th conference on Uncertainty in Artificial Intelligence (UAI 04), 2004, pp. 162–169.
Ferns, N., P. Panangaden and D. Precup, Metrics for Markov decision processes with infinite state spaces, in: Proceedings of the 21st Conference Annual Conference on Uncertainty in Artificial Intelligence (UAI 05), Arlington, VA, 2005, pp. 201–208.
Florchinger, P., Lyapunov-like techniques for stochastic stability, SIAM Journal on Control and Optimization 33 (1995), pp. 1151–1169.


Giacalone, A., C. Jou and S. Smolka, Algebraic reasoning for probabilistic concurrent systems, in: Proceedings of the IFIP TC2 Working Conference on Programming Concepts and Methods, 1990, pp. 443–458.
Gibbs, A. and F. Su, On choosing and bounding probability metrics, International Statistical Review (2001), pp. 419–435.
Girard, A. and G. Pappas, Approximation metrics for discrete and continuous systems, IEEE Trans. on Automatic Control 52 (2007), pp. 782–798.
Girard, A., G. Pola and P. Tabuada, Approximately bisimilar symbolic models for incrementally stable switched systems, IEEE Transactions on Automatic Control 55 (2010), pp. 116–126.
Givan, R., T. Dean and M. Greig, Equivalence notions and model minimization in Markov decision processes, Artificial Intelligence 147 (2003), pp. 163–223.
Henzinger, T., P. Ho and H. Wong-Toi, HyTech: A model checker for hybrid systems, Software Tools for Technology Transfer 1 (1997), pp. 110–122.
Hermanns, H., “Interactive Markov Chains, and the Quest for Quantified Quality,” Lecture Notes in Computer Science 2428, Springer Verlag, 2002.
Jonsson, B. and K. Larsen, Specification and refinement of probabilistic processes, in: Proceedings of Sixth Annual IEEE Symposium on Logic in Computer Science (LICS 91), 1991, pp. 266 –277.
Julius, A. and G. Pappas, Approximations of stochastic hybrid systems, IEEE Transactions on Automatic Control 54 (2009), pp. 1193–1203.
Kemeny, J. and L. Snell, “Finite Markov Chains,” D. Van Nostrand Company, Princeton, NJ, 1963.
Koutsoukos, X., Optimal control of stochastic hybrid systems based on locally consistent Markov decision processes, International Journal of Hybrid Systems 4 (2004), pp. 301–318.
Kushner, H. J., “Approximation and Weak Convergence Methods for Random Processes with Applications to Stochastic Systems Theory,” MIT Press, Cambridge, Massachussets, 1984.
Kushner, H. J. and P. Dupuis, “Numerical Methods for Stochastic Control Problems in Continuous Time,” Springer-Verlag, New York, 2001.
Lafferriere, G., G. Pappas and S. Sastry, O-minimal hybrid systems, Mathematics of Control, Signals, and Systems 13 (2000), pp. 1–21.
Larsen, K. and A. Skou, Bisimulation through probabilistic testing, Information and Computation 94
(1991), pp. 1–28.
Lohmiller, W. and J. Slotine, On contraction analysis for nonlinear systems, Automatica 34 (1998),
pp. 671–682.
Meyn, S. and R. Tweedie, “Markov Chains and Stochastic Stability,” Springer Verlag, 1993.
Milner, R., “A Calculus of Communicating Systems,” Springer-Verlag New York, Inc., Secaucus, NJ, USA, 1982.
Pappas, G., Bisimilar linear systems, Automatica 39 (2003), pp. 2035–2047.
Park, D., Concurrency and automata on infinite sequences, in: Proceedings of the 5th GI-Conference on Theoretical Computer Science, 1981, pp. 167–183.
Pham, Q., Analysis of discrete and hybrid stochastic systems by nonlinear contraction theory, in: Proceedings of the 10th International Conference on Control, Automation, Robotics and Vision (ICARCV 08), Hanoi, Vietnam, 2008, pp. 1054–1059.
Pham, Q., N. Tabareau and J. Slotine, A contraction theory approach to stochastic incremental stability, IEEE Transactions on Automatic Control 54 (2009), pp. 816–820.
Philippou, A., I. Lee and O. Sokolsky, Weak bisimulation for probabilistic systems, in: CONCUR, LNCS
1877 (2000), pp. 334–349.
Pola, G., A. Girard and P. Tabuada, Approximately bisimilar symbolic models for nonlinear control systems, Automatica 44 (2008), pp. 2508–2516.


Prandini, M. and J. Hu, A numerical approximation scheme for reachability analysis of stochastic hybrid systems with state-dependent switchings, in: In Proceedings of the 46th IEEE International Conference on Decision and Control, New Orleans, LA, 2007, pp. 4662–4667.
Puterman, M., “Markov decision processes: discrete stochastic dynamic programming,” John Wiley & Sons, Inc., 1994.
Sarich, M., F. Noe and C. Schu¨tte, On the approximation quality of Markov state models, Multiscale Modeling and Simulation 8 (2010), pp. 1154–1177.
Segala, R. and N. Lynch, Probabilistic simulations for probabilistic processes, Nordic Journal of Computing 2 (1995), pp. 250–273.
Strubbe, S. and A. van der Schaft, Bisimulation for communicating piecewise deterministic Markov processes (CPDPs), in: Hybrid Systems: Computation and Control (HSCC 05) (2005), pp. 623–639.
Tabuada, P. and G. Pappas, Bisimilar control affine systems, Systems & Control Letters 52 (2004),
pp. 49–58.
Thorsley, D. and E. Klavins, Approximating stochastic biochemical processes with Wasserstein pseudometrics, Systems Biology, IET 4 (2010), pp. 193 –211.
Tkachev, I. and A. Abate, On infinite-horizon probabilistic properties and stochastic bisimulation functions, in: Proceedings of the 50th IEEE Conference on Decision and Control and European Control Conference, Orlando, FL, 2011, pp. 526–531.
van Breugel, F. and J. Worrell, Towards quantitative verification of probabilistic transition systems, in: Proceedings of the 28th International Colloquium on Automata, Languages and Programming (ICALP 01), 2001, pp. 421–432.
Wimmer, R. and B. Becker, Correctness issues of symbolic bisimulation computation for Markov chains, in: Proceedings of MMB-DFT, 2010, pp. 287–301.
