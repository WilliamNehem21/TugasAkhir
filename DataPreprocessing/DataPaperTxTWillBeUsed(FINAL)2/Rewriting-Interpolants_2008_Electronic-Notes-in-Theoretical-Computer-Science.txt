	Electronic Notes in Theoretical Computer Science 212 (2008) 163–176	
www.elsevier.com/locate/entcs
Rewriting Interpolants
Christopher Lynch 1
Department of Mathematics and Computer Science Clarkson University
Potsdam, USA
Yuefeng Tang2
Department of Mathematics and Computer Science Clarkson University
Potsdam, USA

Abstract
We give a method of constructing an interpolant for linear equality, and inequality constraints over the rational numbers. Our method is based on efficient rewriting techniques, and does not require the use of combination methods. The interpolant is constructed in such a way that it reflects the structure of the rewrite proof.
Keywords: interpolants, rewriting


Introduction
Given two logical formulas A and B, a formula P is an interpolant of the pair (A, B) if P is implied by A, P implies B and P contains only symbols common to A and B. The idea of interpolant was defined by Craig in 1957 [1]. Basically, an interpolant defines an interface through which A and B interact, using only information that is shared between the two formulas. Recently, McMillan has shown that interpolants can be useful for verification, for finding inductive invariants, and for predicate abstraction [3,4,5].
For example, in model checking, suppose we want to find the inductive invariant of a process. We have some initial constraints(precondition), some transition con- straints, and some final constraints (postcondition) that we would like to be true. We set A as the initial constraints plus potentially some transition constraints, and

1 Email: clynch@clarkson.edu
2 Email: tangy@clarkson.edu

1571-0661 © 2008 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2008.04.060

B as the final constraints plus potentially some transition constraints. We need to prove that A implies B, but to prove this in general for any possible number of transitions, we need to find an invariant that will be true for any possible number of transitions. Since an interpolant P represents some formula ”in between” A and B, there is a possibility that an interpolant may be an invariant, or that there could be a fixed point operation to begin with this interpolant and develop an invariant. In refutational theorem proving, we find a proof of the unsatisfiability of A∧¬B. Therefore, most definitions of interpolation nowadays say that P is a formula such that A |= P , P is inconsistent with B, and P only contains symbols shared by A and
B. One way to find an interpolant is to examine the refutation proof of A∧ ¬B and construct an interpolant from the proof. We augment each constraint in the proof with an ”interpolant part”. We prove that this augmentation has certain properties, that are preserved by the inferences, and that will imply that the ”interpolant part” of the contradiction ⊥ is actually an interpolant for the proof.
In this paper, we present a method for such augmentations in refutation proofs of linear constraints over the rationals. However, because our approach is based on rewriting, we can easily extend our method to handle dis-equalities and uninter- preted function symbols without the combination of different methods. We show the correctness of the augmentations, and the soundness and completeness of the infer- ence system. However, we believe we have developed something more general. We consider it to be a useful framework to provide mappings and develop interpolants for other inference systems.
There can be an infinite number of interpolants for pairs of formulas (A, B). Our interest is to develop the interpolant in such a way as to be a representation of the way inferences are performed in the proof. To this end, we use substitutions to represent sharing between a constraint and its interpolant part. We represent the sharing with a shared variable between them, and a substitution part to store the expression that belongs there. We found that substitutions are also necessary to ensure that our inference steps preserve the required properties for guaranteeing an interpolant at the end of the proof. We believe our framework is quite general and can apply to other inference systems. We also think it is a good way to try to mimic the steps of the proof in the interpolant.
We first present our new inference system without interpolants, but we present it in such a way that interpolants can be introduced later. We prove the complete- ness of this inference system. Then we add interpolant parts and substitutions to these terms, and present the inference rules in this framework. We prove that each inference rule preserves the required properties for guaranteeing an interpolant in the end. This inference system is complete, because without the substitutions and interpolants, it is the same inference system as given earlier. We conclude with related and future work.

Preliminaries
We assume a signature Σ containing constants. A term is defined as a rational number, a constant, or kx where k is a rational number and x is a constant. In this context k is also called the coefficient of the constant x. An expression is a term or a summation of terms. t1 − kt2 is an abbreviation for t1 + (−k)t2 where t1 and t2 are terms. The symbol + is a predefined function symbol, which is not in Σ, which will be given the usual meaning. Instead of considering it as an associative and commutative binary symbol, we just consider it as a symbol applied to a multiset of terms.
Terms are always assumed to be simpliﬁed. This means that 0x is reduced to zero. Also, expressions are simpliﬁed. A simplified expression is a simplified term, or a summation of non-zero simplified terms where no constant appears twice an no numeric term appears twice.
A constraint is T or ⊥ or of the form sφt, where s and t are expressions and φ ∈ {≥, ≤, =, <, >}. Given an operator φ, we define an operator φn. φn is the nonstrict version of φ, defined as follows. If φ ∈ {=} then φn is ’=’. If φ ∈ {<, ≤} then φn is ’≤’. Also, we say that ’≥’ and ’>’ have the opposite direction of ’≤’ and ’<’.
Operators have their usual meaning in arithmetic. We say that a constraint (set of constraints) is satisﬁable if the constants can be substituted by rational numbers to make the constraint (set of constraints) true. A constraint (set of constraints) is unsatisﬁable if it is not satisfiable.
In the paper, we are going to consider two sets of constraints: A and B. Let ΣA be the signature of A and ΣB be the signature of B. Then Σ = ΣA ∪ ΣB. ΣA and ΣB are not necessarily disjoint. Given A and B, elements of ΣA ∩ ΣB are global. Elements which only exist in ΣA or ΣB are local. A term (expression) is global if all its symbols are global otherwise it’s local. If a local term (expression) contains no B-local symbols, then it is A-local. If a local term(expression) contains no A-local symbols, then it is B-local.
Given a set of constraints A and a conjunction of constraints p, we write A |= p to mean that p is true whenever A is true. Given sets of constraints A and B such that A ∪ B is unsatisfiable, we define a conjunction of constraints p to be an interpolant of (A, B) if A |= p, B ∪ {p} is unsatisfiable and p contains only global variables.
We assume an ordering ≺ on constants, which is well-founded, and total. We require that the local constants are larger than global constants. We extend the ordering to a well-founded total ordering on terms, where k1x ≺ k2y if x ≺ y for rational numbers k1 and k2 and constants x and y. The expression t1 + ··· + tn is viewed as a multiset {t1, ··· , tn}. Operators are ordered with the following precedence: {=} ≺ {≤} = {≥} ≺ {<} = {>}. Then a constraint sφt is given the measure (φ, s, t), and constraints are ordered by comparing their measures lexicographically.
In the next section, we assume that constraints are simpliﬁed, so that they are

always of the form xφt where x is a constant larger than every constant in t, and t is simplified. Tautologies are simplified to T. Contradictions are simplified to ⊥. Notice that if a simplified constraint is unsatisfiable then it must not contain any constants from Σ.
Let SV be a set of substitution variables disjoint from Σ. A substitution is a mapping from a substitution variable to an expression, which is homomorphically extended to all terms, expressions and constraints.  We consider a substitution
{V '→ t} to be simpliﬁed if t is simplified, and the largest term in t has a coefficient of 1 unless t is 0. We assume substitutions are always simplified, and we always write them in the form {V '→ x + t} where x is larger than any constant in t.
The formulas used in our proof will not be just constraints, but they will be triples c|i|θ, where c is a constraint, i is a conjunction of constraints, and θ is a substitution. We will call i the interpolant part of c to emphasize that it will lead to an interpolant. We are going to give an inference system so that whenever ⊥|i|θ is constructed then iθ is an interpolant.
For example, consider the triple V = 0|V = y ∧ z = 0|{V '→ x}, where c is
V = 0, i is V = y ∧ z = 0 and θ is {V '→ x}. In this case x, y and z are constants, and V is a substitution variable. This is really intended to represent the constraint cθ, which is x = 0, but x has been abstracted out of the substitution part so it can be shared with iθ, which is x = y ∧ z = 0, which will be used to help us construct an interpolant.
To simplify matters, we first give our refutational inference rules with single constraints. Then we show how to extend that inference system to triples, in order to find interpolants.

Inference Rules
In this section we present an inference system for determining the unsatisfiability of a set of constraints. Inferences will be applied to a set of constraints. After defining the inference system, we will prove that ⊥ can be generated by these inference rules from a set S of constraints if and only if S is unsatisfiable.
This inference system only involves single constraints. In later sections, we will show how to use this inference system to determine interpolants. At that point, we will need to extend this inference system using triples instead of single constraints. We are assuming that all our constraints are simplified. After each inference,
the conclusion is converted into simplified form.
There is only one inference rule Rewriting Rule. Rewriting Rule replaces a big element in a formula by a smaller one:

(1)
xφ1t1 xφ2t2
t1 φ2 t2
Since the constraints are simplified, x must be larger than all constants in ex-

pressions t1 and t2.  φ1 and φ2 ∈ {=, ≥, ≤, >, <}.  We always assume the right
premise is larger than or equal to the left one. If neither premise is an equation, the direction of φ1 and φ2 must be opposite. Otherwise this inference rule is not

applicable.
After applying the Rewriting Rule, the constant x in the right premise is sub- stituted by t1. The conclusion is smaller than the right premise.
Next we give an example. Given two sets A = {x = y, x ≥ 3z}, B = {y < z, z = 1}, suppose the ordering of the constants is z ≺ y ≺ x 3 . Here is a process to derive a contradiction using the Rewriting Rule.
Example 3.1
x = y x ≥ 3z y ≥ 3z
y ≥ 3z y < z
z < 0
z = 1 z < 0
⊥
The Conclusion has been simplified after each inference rule. This proves that
A ∪ B is inconsistent.
Completeness Proof
In this section, we prove the completeness of the inference rules defined in the previous section. In other words, we show that it is always possible to derive ⊥ from an unsatisfiable set of constraints. First we need some definitions to model a derivation.
Definition 4.1 Given a constraint c and a set of constraints S, c is redundant in S if there exist c1, ··· , cn ∈ S such that c1, ··· , cn |= c and ci ≺ c for all i. A set of constraints S is saturated if the conclusion of every inference of members of S is in S or is redundant in S.
A saturated set represents the result of an exhaustive application of our inference rules on a set of clauses. So in this section, we will deal with saturated sets. For completeness, we need to prove that if a saturated set S is unsatisfiable, then ⊥∈ S. Since the inference rules are sound, every inference preserves (un)satisfiability.
To simplify the discussion in this section, we will define sequences such as t0 < t1 ≤ t2 to be called paths.
Definition 4.2 A φ path over S proving t0φtn, where φ ∈ {<, >, ≤, ≥, =}, is a sequence t0, t1, ··· , tn, such that n > 0 and for each i > 1 there is a constraint si−1φisi in S, an expression ei and a number ki such that ti is the same as kisi + ei, and ti−1 is the same as kisi−1 + ei. If φ is ’≥’ then all φi must be ’≥’,’>’, or ’=’. If φ is ’>’ then all φi must be ’≥’, ’=’ or ’>’, and at least one φi must be ’>’. Analogously for when φ is ’≤’ or ’<’. If φ is ’=’ then all φi are ’=’.
Notice that if S |= t0 ≥ tn then there must be a ≥ path over S proving t0 ≥ tn+k for some non-negative number k. If S |= t0 > tn then

3 x must be the largest constant since it is local.

there is a > path over S proving t0 > tn + k for some non-negative number k
or
there is a ≥ path over S proving t0 ≥ tn + k for some positive number k.
If S |= t0 = tn then there is a ≥ path over S proving t0 ≥ tn and a ≥ path over S
proving tn ≥ t0, and there might be an ’=’ path over S proving t0 = tn.
We define a φ path over S proving sφt to be a φ smallest path over S proving sφt if there is no smaller φ path over S proving sφt. The paths are compared by considering them as multisets, and using the multiset extension of ≺.
We say that a φ path proving t0φtn contains a peak if there are consecutive terms ti−1, ti and ti+1 in the path such that ti−1 ≺ ti and ti+1 ≺ ti. If we assume t0 > tn, then the lack of a peak implies that t0 is the largest term on the path.
Lemma 4.3 Let S be a saturated set. Let P be a smallest path proving t0φtn over
S. Then P does not contain a peak.
Proof. Assume P is a smallest path containing a peak proving t0φtn. So there is an i such that ti > ti−1 and ti > ti+1. By definition of path there are corresponding constraints si−1φisi and uiφi+1ui+1. Since ti > ti−1 and ti > ti+1, we know that si > si−1 and ui > ui+1. If si and ui occur at disjoint positions in ti then we can first apply uiφi+1ui+1 to ti−1 and then si−1φisi to get a shorter proof. So assume that si and ui occur at overlapping positions in ti. Then there is an inference between si−1φisi and uiφi+1ui+1 which produces si−1φ'ui+1. This constraint is either in S or is redundant in S. If it is in S, we can remove ti from the path and get a smaller path. If it is redundant in S, then there are smaller constraints in S which imply si−1φ'ui+1. Therefore there must be a φ' path proving si−1φ'ui+1 which uses only terms smaller than si. In that case, ti can be removed from its path and replaced by smaller terms. This contradicts the fact that the original path is a smallest path. 

The lemma will be used to prove the completeness theorem. We need to prove that in an unsatisfiable set of constraints, we can always generate ⊥. We will prove this by showing that if we saturate a set of constraints and do not generate the empty clause then we can build a model, i.e., a consistent set of constraints that implies all the constraints in the saturated set, as in [6].
Theorem 4.4 Let S be a saturated set of constraints. If S is unsatisﬁable then
⊥∈ S.
Proof. We prove the contrapositive. Suppose that ⊥ /∈ S. We will create a set M such that M |= S, proving that S is satisfiable. Let S = {c1, ··· , cn}. We give the following co-inductive definitions of Mi and Pi for each constraint ci in S. They

are defined as follows. Let Mi =  c ≺c
Pj. Let Pi = {ci} if Mi |= ci. Otherwise,
 

Pi = ∅. If Pi = {ci}, we say that ci is productive. Let M = prove that M is a consistent set.
c ∈S Pi. We need to

To prove that M is consistent, we consider each ci in S, and prove by induction on the size of ci that if ci is productive then Mi ∪ ci is consistent.

The constraint ci is of the form sφt. We will assume that φ is the constraint <, since all other cases are similar.
By the form of the constraints, we know that s > t. If Mi∪{s < t} is inconsistent, then Mi |= s ≥ t. Therefore there must be a ≥ path proving s ≥ t + k, for some nonnegative number k, in S.
We consider the smallest such path. This path cannot contain a peak. So the first step on this path must be of the form sφt1, where t1 ≺ s, and φ is ≥, > or =. This means that sφt1 ∈ Mi. Also, it must be the case that Mi |= t1 ≥ t. There is an inference between s < t and sφt1, whose result is t > t1. By the saturation of S, this means that Mi |= t > t1. This conflicts with the fact that Mi |= t1 ≥ t. Therefore, Mi ∪ {s < t} must be consistent.

Adding Interpolant Parts
In the previous part, we only defined the inference rules without considering the interpolant. In this section we will introduce the method to obtain the interpolant based on the inference rules.
We must show how to take the original constraints from A and B and turn them into triples. In addition, we need to show how the inference rules apply to those triples. The plan is the following.
Give inference rules to take a constraint c' from A or B and convert it into a triple c|i|θ. This triple must have the property that c' is cθ, since we are going to simulate the inference system given earlier.
Give inference rules to simulate the inference rules already given, but using triples this time. Every inference rule given earlier must be simulated, and if we instantiate the conclusion constraint with the conclusion substitution then we must obtain the same conclusion as in the earlier inference rules.
We finally, need to prove that iθ is an interpolant of (A, B) when c becomes
⊥. We will prove this by showing an incremental fact. We will show that for every triple c|i|θ, A |= iθ and B ∧ i |= c. Those two properties are sufficient to ensure that iθ will be an interpolant when c becomes ⊥, along with the fact that iθ is global.
We will try to give more motivation for the use of the substitution. The reason for the substitution is in order to share structure between c and i. The effect of our inference rules will be that inferences involving A will take place in a substitution, thereby allowing those inferences to involve i in addition to c. However, inferences involving B will not take place inside a substitution, thus we will force the inference to involve c but not i. This will ensure that, as much as possible, inferences involving A are recorded in i but not inferences involving B. Therefore, we will keep a trace of the A-inferences performed. This allows the interpolant to be formed the same way as the inferences were executed. We believe this is the interpolant which is often needed in practice. There are infinitely many interpolants for any given unsatisfiable

pair (A, B) but we believe this is the interpolant that is really recording the way the proof is being done, and it will be more useful in applications, such as finding loop invariants.
We will define a triple to be correct if it is in the form we mentioned above. Additionally, we also need a condition about the global and local constraints in order to ensure that a triple containing the constraint ⊥ only has global variables in the interpolant part.
Definition 5.1 Let A and B be sets of constraints. A triple c|i|θ is geographically correct if
when iθ is simplified, it is not B-local.
if iθ is A-local, then i is identical to c
if i is identical to c, then cθ is implied by A, and
θ does not contain both A-local and B-local constants.
Definition 5.2 Let A and B be sets of constraints. A triple c|i|θ is (A, B)-correct
if
A |= iθ,
B ∧ i |= c, and
c|i|θ is geographically correct
Based on the way that we build triples, a triple always has the format V φ0|V φ0|θ
or V φ0|V φt ∧ i'|θ where i' does not contain substitution variables.
We begin by defining inference rules for creating triples from initial constraints depending on whether the initial constraint is from A or B. We call this rule Make-Triple:



where xφt ∈ A.
xφt


V φ0|V φ0|{V '→ x − t}

xφt


V φ0|V φnx − t|{V '→ x − t}

where xφt ∈ B, and φn defined in the preliminaries is the nonstrict version of φ.
Note that in constraints from A, we use new the substitution variable V to share everything of c in the substitution part i, because we want to record all the actions involving A in the interpolant. However, in constraints from B, we also use V to share c with i but we relate that to an original copy of the constraint which will not be modified by the inferences. This allows us to record the actions that occur on that constraint, not the actions using that constraint.
Lemma 5.3 If c is a constraint from A∪B, then the result of applying Make-Triple to c is (A, B)-correct.
Proof. Let’s look at the first Make-Triple rule.
Since xφt is from A, the first property A |= x − tφ0 is true.

The second property B ∧ V φ0 |= V φ0 is obviously true.
Next is to show the third property that the conclusion is geographically correct.
(V φ0)θ is not B-local where θ is {V '→ x − t} because the constraint xφt
is from A.
The interpolant part is identical to its constraint. So this property is true.
Since the constraint is from A, (V φ0)θ must be implied by A.
θ is A-local or global.
Next, let’s look at the second Make-Triple rule.
(V φnx − t)θ is a tautology. So, the first property A |= (V φnx − t)θ is true.
Let’s suppose φ is ≥ then φn is ≥ too. The proof for other operators is similar to the ≥ case. So, x ≥ t from B along with V ≥ x − t implies V ≥ 0. Thus, the second property B ∧ V ≥ x − t |= V ≥ 0.
Next is to show the third property that the conclusion is geographically correct.
since (V φnx − t)θ is a tautology, iθ when simplified is not B-local.
The constraint is from B. So, this property is true.
The interpolant part is not identical to its constraint. So, this property is true.
θ could be B-local or global.
Therefore, the result of applying Make-Triple to c is (A, B)-correct.
 
As we stated in the previous section, we have to simplify each newly generated constraint after applying an inference rule. Given an expression or a constraint, it is well-known how to simplify it. But after an inference rule, the substitution part might not be simplified anymore, because the coefficient of the largest term may not be positive one. Here we give an inference rule called Simplify Rule to simplify the substitution part of a constraint. This will be performed eagerly when each new constraint is generated.
V φ10|V φ2s ∧ i'|{V '→ kx + t}
kWφ10|kWφ2s ∧ i'|{W '→ x + t/k}
After this, it is simplified in the obvious way.
Example 5.4	 V3 < 0|V3 ≤ y − z|{V3 '→ 2z} 
2V5 < 0|2V5 ≤ y − z|{V5 '→ z}
Then, the conclusion can be simplified to the triple V5 < 0|V5 ≤ 1 z− 1 y|{V5 '→ z}
2	2
Lemma 5.5 An (A, B)-correct triple always simpliﬁes to an (A, B)-correct triple.
Proof. All properties of (A, B)-correct are trivial except the second property. But, the second property follows the fact that i' does not contain the substitution vari- able.	 
Next, we will show the redefined inference rules. The newly defined inference rules will be strictly based on the inference rule defined in the previous part, but

the inference will take place in the substitution, and we will control when sharing is allowed and when it is not allowed.
We use two inference rules Triple-Rewriting Rule and Combination Rule to simulate the Rewriting Rule defined in the previous part. For ease of presentation, before applying these rules, we switch positions of the two premises if the left premise’s interpolant part is not identical to its constraint and the right premise is non-strict inequality whose interpolant part is identical to its constraint. Then, if two premises have the format defined in the following Triple-Rewriting Rule, we apply the Triple-Rewriting Rule. Otherwise, we apply the Combination Rule.
The Triple-Rewriting Rule is the following:
V1φ10|V1φ10|{V1 '→ x − t1}	V2φ20 |i|{V2 '→ x − t2} V2φ20|i|{V2 '→ t1 − t2}
Notice that the left premise is implied by A based on the format of the triple and the conclusion looks like the right premise, except that the substitution has changed, thereby recording the inference into the eventual interpolant.
The Triple Rewriting Rule preserves correctness:
Lemma 5.6 If the premises of a Triple-Rewriting Rule are (A, B)-correct triples, then the conclusion is too.
Proof. Let θ1 be {x − t1}, θ2 be {x − t2} and θ' be {t1 − t2}.
Let’s assume φ1 is ≥, and φ2 is ≤. Proofs for other cases of the Triple-Rewriting Rule are similar to this one. Suppose i has the format V2 ≤ t ∧ i'. Our goal is to prove the first property A |= (t1 − t2 ≤ t) ∧ i'. Based on the assumption, A |= x − t1 ≥ 0 and A |= (x − t2 ≤ t) ∧ i'. Then, we can easily conclude t1 − t2 ≤ t from x − t1 ≥ 0 and x − t2 ≤ t. Thus, the first property is true.
The second property is obviously true because V2φ0 and i remain the same as the second premise.
Next is to show the conclusion is geographically correct.
since the interpolant part V1φ10 is identical to the constraint in the first premise, we can conclude (V1φ10)θ1 is implied by A from the assumption. Then, θ1 must be A-local or global. Thus, x and t1 can not be B-local. Based on the assumption, iθ2 when simplified is not B-local. Thus, by
replacing x(not B-local) by t1(not B-local), iθ' when simplified is not B-

local.
x is larger than any term any in t1 and t2. So, if iθ'
is A-local, then iθ2

is A-local. Based on the assumption that the second premise is (A, B)- correct, we can conclude i is identical to V2φ20. Thus, this property is true.
if the conclusion’s interpolant part is identical to its constraint, it implies that the right premise’s interpolant part is identical to its constraint be- cause those two parts remain the same after applying the inference rule. Thus, based on the assumption that the second premise is (A, B)-correct,
we can conclude i is identical to V2φ20.

Since x is larger than any term t1 and t2, and the first premise is implied by A, then t1 and t2 are A-local or global. So, θ' is A-local or global. Thus,
the conclusion is geographically correct.
Therefore, the conclusion is (A, B)-correct.

The next rule we will define is the Combination rule, which applies when there is a Rewriting Rule but the Triple-Rewriting Rule defined above is not applicable. This Combination rule will involve applying the substitution before the inference and then reconstructing it after the inference. So we define the following two rules, which will be used in the Combination Rule. The first is Back Substitution:
c|i|θ cθ|iθ|id
In the conclusion, id is the identity substitution, since no variables exist in the constraint and interpolant part.
Lemma 5.7 If the premise of Back Substitution is (A, B)-correct, then the conclu- sion is too.
Proof.
Based on the assumption, A |= iθ. So, the first property is true.
Based on the assumption, B ∧ i |= c. Then, B ∧ iθ |= cθ. So, the second property B ∧ iθ |= cθ is true.
Based on the assumption, we can easily derive that the conclusion is geograph- ically correct.	 
The second rule is Reconstruct Substitution.
xφt|i|id
V φ0|V φnx − t ∧ i|{V '→ x − t}
Lemma 5.8 If the premise of Reconstruct Substitution is (A, B)-correct then the conclusion is too.
Proof. Since the idea of this inference rule is very similar to the second rule of Make-Triple, the proof is also similar.	 
For a triple c|i|θ, define Apply(c|i|θ) as cθ. Given two triples t1 and t2, we want to define an inference rule whenever there is an inference between Apply(t1) and Apply(t2). Depending on the form of the interpolant part of the left premise, the Triple-Rewriting Rule will sometimes be applicable. In the Combination Rule, we define what to do when it is not applicable. The Combination Rule is the
following inference
c1|i1|θ1	c2|i2|θ2 c|i1θ1 ∧ i2θ2|id
where c is the conclusion of a Rewriting Rule between c1θ1 and c2θ2, and Reconstruct Substitution is immediately performed after this inference.

So we perform a Back Substitution followed by an inference on the constraints where the interpolants are conjoined, and then Reconstruct Substitution.
Lemma 5.9 If the premises of the Combination Rule are (A, B) correct then the conclusion is too.
Proof.
Based on the assumption, A |= i1θ1 and A |= i2θ2. Thus, the first property
A |= i1θ1 ∧ i2θ2 is true.
From the assumption, B ∧ i1 |= c1 and B ∧ i2 |= c2. Then, B ∧ i1 ∧ i2 |= c1 ∧ c2. Then, (B∧i1 ∧i2)θ1θ2 |= (c1 ∧c2)θ1θ2. Then, B∧i1θ1 ∧i2θ2 |= c1θ1 ∧c2θ2. Since c is the conclusion of c1θ1 and c2θ2, the second property B ∧ i1θ1 ∧ i2θ2 |= c is true.
Next is to show the conclusion is geographically correct. Let θ1 be {x− t1} and
θ2 be {x − t2}.
i1θ1 and i2θ2 when simplified are not B-local based on the assumption. Thus,
i1θ1 ∧ i2θ2 when simplified is not B-local.
If i1θ1 ∧ i2θ2 is A-local, then i1θ1 or i2θ2 is A-local. Suppose i1θ1 is A-local. Based on the assumption, we can conclude i1 and c1 are identical. Since x is larger than any term in t1, x must be A-local. So, c1θ1 is from A. Similarly, we can conclude c2θ2 is from A. But, if both premises are from A, the Triple- Rewriting Rule is applicable. So, we do not perform the Combination Rule. Therefore, i1θ1 ∧ i2θ2 can not be A-local.
c and i1θ1 ∧ i2θ2 can not be identical. This property is obviously true.
it is trivial that id does not contain A-local and B-local constants simultane- ously.
Therefore, the conclusion is (A, B)-correct.	 
Next, we show an example to construct an interpolant. We still use the example given in the previous part. Given two sets A = {x = y, x ≥ 3z}, B = {y < z, z = 1}, the ordering of the constants is z ≺ y ≺ x.
Example 5.10 First, we apply Make-Triple to convert single constraints into triples.
x = y
V1 = 0|V1 = 0|{V1 '→ x − y}
x ≥ 3z
V2 ≥ 0|V2 ≥ 0|{V2 '→ x − 3z}
y < z
V3 < 0|V3 ≤ y − z|{V3 '→ y − z} z = 1 
V4 = 0|V4 = z − 1{V4 '→ z − 1}
Then, we apply Triple-Rewriting Rule, Triple-Rewriting Rule, Simplify Rule, and Combination Rule in order.
V1 = 0|V1 = 0|{V1 '→ x − y} V2 ≥ 0|V2 ≥ 0|{V2 '→ x − 3z}
V2 ≥ 0|V2 ≥ 0|{V2 '→ y − 3z}

V2 ≥ 0|V2 ≥ 0|{V2 '→ y − 3z} V3 < 0|V3 ≤ y − z|{V3 '→ y − z} V3 < 0|V3 ≤ y − z|{V3 '→ 2z}
 V3 < 0|V3 ≤ y − z|{V3 '→ 2z} 
2V5 < 0|2V5 ≤ y − z|{V5 '→ z}
V4 = 0|V4 = z − 1{V4 '→ z − 1} V5 < 0|V5 ≤ 1 y − 1 z|{V5 '→ z}
2	2
⊥|z − 1 = z − 1 ∧ z ≤ 1 y − 1 z|id
2	2
Usually, we immediately perform Reconstruct Substitution after applying the Combination Rule. However, in this example since the constraint has become ⊥, we will not perform Reconstruct Substitution. After simplifying the interpolant part, we derive y ≥ 3z which is an interpolant in this example.
Theorem 5.11 If ⊥|i|θ is derived using the inference rules deﬁned in this section from sets A and B, then iθ is an (A, B)-interpolant.
Proof. We have proved that each conclusion of our inference rules is (A, B)-correct. Thus, ⊥|i|θ is (A, B)-correct.
Since the triple is (A, B)-correct, A |= iθ.
Since the triple is (A, B)-correct, B ∧ i |= ⊥. So, B ∧ iθ |= ⊥
Since the triple is (A, B)-correct, iθ when simplified is not B-local and iθ is not A-local because either ⊥ and i are not identical or i is ⊥ and iθ is global. Thus, iθ contains only global constants.
Therefore, iθ is an (A, B)-interpolant.
 
We define a triple t to be redundant in S if Apply(t) is redundant in Apply(S), where Apply(S) = {Apply(t) | t ∈ S}. Then we define saturation of a set of triples just like saturation of a set of constraints. In other words, a set S of triples is saturated if Apply(S) is saturated. Note that in S, we may have two different triples t1 and t2 where Apply(t1) is the same as Apply(t2). By completeness of constraints, it follows that for any set of triples, if S is saturated then ⊥ ∈ Apply(S). The inference rules are also sound, because they simulate the sound inference rules on constraints.

Conclusion
We gave a method of constructing interpolants for linear constraints over the ratio- nals. This is not in itself a new result. It has been done by McMillan. However, we believe our paper is novel in two ways. First is the actual inference system we use. It is based on rewriting techniques, which we believe will be more efficient than the method introduced by McMillan [4]. His approach requires inferences be- tween any two constraints, whereas our approach orients the constraints so that the largest term is on the left hand side, and we only allow inferences which replace a constraint with a smaller one. For example, McMillan would apply an inference between constraints 0 ≤ a and 0 ≤ b to generate 0 ≤ a + b, whereas we would not do that.

Because our approach is based on rewriting, we can extend our method to handle function symbols without using a combination method. But, McMillan axiomatizes function symbols and gives a combination method to combine his function symbol inferences with the linear constraint inferences. We believe it is more efficient to deal with them all in the same framework, and not to axiomatize function symbols. Aside from the relationship with McMillan’s work, others[8,9] have examined combination methods for interpolants. In particular, [7] does not create the inter-
polant from the proof.
We plan on many directions for future work. We are currently extending our ideas, with the hope to give a complete method for linear constraints over integers with uninterpreted function symbols. We would also like to extend our framework to other theories. We are planning an implementation. Finally, we would like a better understanding of how our methods fits into invariant generation, predicate abstraction, and other uses of interpolants

References
W. Craig. Three uses of the Herbrand-Gentzen theorem in relating model theory and proof theory. J. Symbolic Logic, 22(3), pages 269285. 1957.
N. Dershowitz and D.A. Plaisted. Rewriting. In J.A. Robinson and A. Voronkov, editors, Handbook of Automated Reasoning, Volume I, pages 537-608. Elsevier Science Publishers and MIT press, 2001.
K.L. McMillan. Interpolation and SAT-based model checking. In CAV’2003: Computer Aided Verification, LNCS 2725, pages 1-13. Springer, 2003.
K.L. McMillan. An interpolating theorem prover. In TACAS’2004: Tools and Algorithms for the Construction and Analysis of Systems, LNCS 2988, pages 16-30. Springer, 2004.
K.L. McMillan. Applications of Craig interpolants in model checking. In TACAS’2005: Tools and Algorithms for the Construction and Analysis of Systems, LNCS 3440, pages 1-12. Springer, 2005.
R. Nieuwenhuis and A. Rubio. Paramodulation-Based Theorem Proving. In J.A. Robinson and A. Voronkov, editors, Handbook of Automated Reasoning, Volume I, pages 373-440. Elsevier Science Publishers and MIT press, 2001.
A. Rybalchenko and V.S. Stokkermans. Constraint Solving for Interpolation. In VMCAI’2007: Verification, Model Checking, and Abstract Interpretation, LNCS 4349, pages 346-362. 2007.
V.S. Stokkermans. Interpolation in local theory extensions. Proceedings of IJCAR 2006, Seattle, USA, LNAI 4130, pages 235-250. Springer, 2006.
G. Yorsh and M. Musuvathi. A combination method for generating interpolants. In R. Nieuwenhuis, editor, 20th International Conference on Automated Deduction (CADE-20), LNAI 3632, pages 353-368. Springer, 2005.
