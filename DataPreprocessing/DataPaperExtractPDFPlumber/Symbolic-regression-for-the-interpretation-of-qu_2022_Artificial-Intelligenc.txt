Artificial Intelligence in the Life Sciences 2 (2022) 100046
Contents lists available at ScienceDirect
Artificial Intelligence in the Life Sciences
journal homepage: www.elsevier.com/locate/ailsci
Research Article
Symbolic regression for the interpretation of quantitative
structure-property relationships
Katsushi Takaki a, Tomoyuki Miyao a, b ,âˆ—
a Graduate School of Science and Technology, Nara Institute of Science and Technology, 8916-5 Takayama-cho, Ikoma, Nara 630-0192, Japan
b Data Science Center, Nara Institute of Science and Technology, 8916-5 Takayama-cho, Ikoma, Nara 630-0192, Japan
a r t i c l e i n f o a b s t r a c t
Keywords: The interpretation of quantitative structureâ€“activity or structureâ€“property relationships is important in the field
Model interpretability of chemoinformatics. Although multivariate linear regression models are typically interpretable, they do not
Quantitative structure-activity relationships generally have high predictive abilities. Symbolic regression (SR) combined with genetic programming (GP) is
Quantitative structure-property relationships
a well-established technique for generating the mathematical expressions that describe the relationships within
Symbolic regression
a dataset. However, SR sometimes produces complicated expressions that are hard for humans to interpret. This
Genetic programming
paper proposes a method for generating simpler expressions by incorporating three filters into GP-based SR.
The filters are further combined with nonlinear least-squares optimization to give filter-introduced GP (FIGP),
which improves the predictive ability of SR models while retaining simple expressions. As a proof-of-concept, the
quantitative estimate of drug-likeness and the synthetic accessibility score are predicted based on the chemical
structures of compounds. Overall, FIGP generates less-complicated expressions than previous SR methods. In
terms of predictive ability, FIGP is better than GP, but is outperformed by a support vector machine with a radial
basis function kernel. Furthermore, quantitative structureâ€“activity relationship models are constructed for three
matching molecular series with biological targets. In the case of one target, the activity prediction models given
by FIGP exhibit better predictive ability than multivariate linear regression and support vector regression with
the radial basis function kernel, whereas for the remaining cases, FIGP is slightly less accurate than multivariate
linear regression.
1. Introduction In terms of interpreting nonlinear ML models, approaches are gener-
ally based on individual compounds. That is, the prediction output of a
The interpretation of quantitative structureâ€“property or structureâ€“ ML model for a compound can be decomposed into additive molecular
activity relationships (QSPR/QSAR) is an important topic in the field descriptor contributions. Because this method is quite effective for un-
of chemoinformatics [1] . Classical QSAR models are interpretable when derstanding the relation between the model output and an input descrip-
multivariate linear regression (MLR) is employed in combination with tor set, i.e., local interpretation, it is widely employed for various target
meaningful molecular descriptors [ 2 , 3 ]. MLR has been widely employed types [9â€“12] . However, such a local interpretation does not always pro-
for a range of QSPR/QSAR applications, such as determining the rela- vide an understanding of the predictive model itself (i.e., QSAR/QSPR).
tion between enantio-selectivity and chemical reaction parameters [4â€“ Thus, modeling approaches that are interpretable to humans and are
6] . However, as a modeling method, MLR has a poor predictive ability more flexible than MLR are necessary.
when the relationship between the molecular descriptors and the prop- Symbolic regression (SR) searches for the mathematical expressions
erty (activity) is nonlinear. Thus, in practical applications, nonlinear that explain a training dataset. Roughly speaking, an SR expression con-
machine learning (ML) algorithms such as random forests (RF) [7] , sup- sists of a combination of arithmetic operators or mathematical func-
port vector machines with a nonlinear kernel function (SVM) [8] , and tions and terminals (variables and numerical constants). SR expressions
neural networks (NNs) are frequently employed. These nonlinear ML do not rely on a fixed functional form, unlike the engineered features
models accurately predict the property values, even when the structureâ€“ of MLR (multiplication/division). Thus, SR has the potential to repre-
property relationship is linear, by adjusting the model parameters. sent nonlinear QSARs/QSPRs as explicit expressions without any prior
knowledge regarding the functional form of the expression. Because the
search space of expressions is generally vast, and expressions can be nat-
âˆ— Corresponding author at: Data Science Center and Graduate School of Science and Technology, Nara Institute of Science and Technology, 8916-5 Takayama-cho,
Ikoma, Nara 630-0192, Japan.
E-mail address: miyao@dsc.naist.jp (T. Miyao) .
https://doi.org/10.1016/j.ailsci.2022.100046
Received 6 September 2022; Received in revised form 1 November 2022; Accepted 2 November 2022
Available online 5 November 2022
2667-3185/Â©2022 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license ( http://creativecommons.org/licenses/by/4.0/ )K. Takaki and T. Miyao Artificial Intelligence in the Life Sciences 2 (2022) 100046
urally represented as tree structures, genetic programming (GP) is used calculations in this study along with their average values and ranges are
to solve SR problems [13] . listed in Table 1 .
In materials science, GP-based SR and its variants have recently been
employed to derive mathematical expressions of physical phenomena 2.2. Formulas
[14] . An SR system named AI Feynman successfully recovered 100 equa-
tions of physical laws from datasets [15] . AI Feynman produces sets of The QED [22] and SAScore [23] were employed for the formula es-
expressions through a trade-offbetween the accuracy and simplicity of timation in this study. These metrics were chosen because they can be
the expressions. GP-based SR has also been used to engineer highly cor- analytically derived from a chemical structure and have been widely
related features for a target variable [ 16 , 17 ]. In terms of QSAR analysis, used in previous retrospective in-silico studies.
only a limited number of SR studies have been reported, and these have
mainly focused on the predictive ability of the models [ 18 , 19 ]. 2.2.1. QED
To ensure interpretable QSAR/QSPR models, the expressions gen- The QED is the geometric mean of eight desirability functions. Each
erated by SR should be as simple as possible, but flexible enough to function represents a desirable property of a compound in terms of a sin-
represent nonlinear structureâ€“property (activity) relationships. For the gle molecular descriptor, and the combination of these functions quanti-
purpose of improving the fit to a dataset, Kommenda et al. [20] proposed fies the drug-likeness of the compound. These descriptors are the molec-
to optimize numerical constants during the evolution of the SR expres- ular mass (M
r
), octanolâ€“water partition coefficient (ALOGP), numbers
sions, resulting in a great improvement in the predictive ability of the of hydrogen bond donors (HBDs) and acceptors (HBAs), molecular po-
generated expressions, even for test datasets. This technique is called lar surface area (PSA), number of rotatable bonds (ROTB), number of
GP with nonlinear least-squares (NLS) optimization of constant terms. aromatic rings (AROM), and number of structural alerts (ALERTS). Each
However, the expressions generated by this method sometimes contain desirability function d is an asymmetric double-sigmoidal function with
complicated functional relations and many constants, most likely from six parameters. These parameters were determined by fitting the func-
overfitting to a training dataset. tion to the density (histograms) of the descriptor values from a collection
In this paper, we consider the generation of interpretable of 771 orally dosed approved drugs. For each descriptor, a high desir-
QSAR/QSPR models. For this purpose, we introduce three filters into ability score is assigned to molecules with descriptor values around the
GP with NLS optimization to give filter-introduced GP (FIGP). The in- mode of the distribution. Because each desirability function is scaled
troduced filters are a function filter (F-filter), variable filter (V-filter), by the maximum desirability function score, the QED scores range from
and domain filter (D-filter). These filters constrain the generated ex- 0 (undesirable) to 1 (desirable). The outputs of the eight desirability
pressions to be simple and valid for compounds outside the domain of functions are weighted as follows to derive the weighted QED score.
the training dataset [21] . As a proof-of-concept, two well-defined prop-
erties are employed: the quantitative estimate of drug-likeness (QED) QED w = ğ· ğ‘€ ğ‘Ÿ â‹…ğ· ALOGP â‹…ğ· HBD â‹…ğ· HBA â‹…ğ· PSA â‹…ğ· ROTB â‹…ğ· AROM â‹…ğ· ALERTS ,
[22] and the synthetic accessibility score (SAScore) [23] . The predic-
(1)
tive performance of the proposed FIGP model is compared with that of
two other SR models, namely GP and AI Feynman. The effects of the where
( )
fi evlt oe lr us t ia or ne pan roa cly ez sse .d T b hy e m FIo Gn Pit o mr oin dg e lt h ge iv e ex sp sr ie mss pi lo en rs e g xe pn re er sa sit oe nd s d au nr din mg oth ree ğ· ğ‘– = exp ğ‘¤ ğ‘– Wln ğ‘‘ ğ‘– ,
stable predictive performance than GP without the filters. Furthermore,
t ch or mee p oQ uS nA dR s am reo d be ul is l tf o ur s is nu gb s Ft Ii Gtu Pe n at ss d o ef m th oe n sc th rae tm ivi ec a cl a s st er u sc tutu dr ie es s .o Of ua rc t ii mve - W = ğ‘¤ ğ‘€ r + ğ‘¤ ALOGP + ğ‘¤ HBD + ğ‘¤ HBA + ğ‘¤ PSA + ğ‘¤ ROTB + ğ‘¤ AROM + ğ‘¤ ALERTS
plementation of FIGP is publicly available in the GitHub repository at and w i is the weight for the i -th desirability function (one of the eight
https://github.com/takakikatsushi/FIGP. descriptors). A high weighted QED score can only be achieved when a
molecule gives high scores for all desirability functions. Note that QED
w
takes a value of 0 if any one of the d
i
is equal to 0. Three weighting
2. Materials and methods schemes have been proposed based on the information content of QED w .
In this study, QED
w,mo
is used, which takes the average of the top 1000
2.1. Compound dataset and molecular representations weight combinations that give the highest information content. These
weights are w
Mr
= 0.66, w
ALOGP
= 0.46, w
HBD
= 0.61, w
HBA
= 0.05,
From the ZINC15 database [24] , a total of 11,670,964 substances w PSA = 0.06, w ROTB = 0.65, w AROM = 0.48, and w ALERTS = 0.95. The
from 718 tranches were downloaded as SMILES strings using the fol- QED scores were calculated by the QED.default function implemented
lowing options: representation: 2D, reactivity: clean, purchasability: in- in the RDKit library [25] .
stock. After standardizing the chemical structures in the files, e.g., re-
moving salts and converting to neutralized forms of (de)protonated sub- 2.2.2. SAScore
structures of chemical structures, 1,000,000 compounds were randomly The SAScore represents the difficulty of synthesis based on the chem-
sampled. This compound pool was used for our virtual experiments. ical structure of a compound, from 1 (easy to synthesize) to 10 (difficult
All the molecular descriptors used in this study were implemented in to synthesize) [23] . The SAScore consists of two factors: the appearance
RDKit [25] . These descriptors were manually chosen with the aim of of rare substructures (FragmentScore) and the complexity of molecular
directly connecting to the interpretation of chemical structures. Thus, structures (ComplexityPenalty).
topological descriptors and descriptors based on the sum of atom-wise ğ‘† ğ´ğ‘† ğ‘ğ‘œğ‘Ÿğ‘’ ğ‘Ÿğ‘ğ‘¤ = âˆ’ ğ¹ ğ‘Ÿğ‘ğ‘”ğ‘šğ‘’ğ‘›ğ‘¡ğ‘† ğ‘ğ‘œğ‘Ÿğ‘’ + ğ¶ğ‘œğ‘šğ‘ğ‘™ ğ‘’ğ‘¥ğ‘–ğ‘¡ğ‘¦ğ‘ƒ ğ‘’ğ‘›ğ‘ğ‘™ ğ‘¡ğ‘¦ (2)
surface areas with property contributions were excluded. Furthermore,
descriptors counting the functional groups were omitted to prevent the In FragmentScore, frequently appearing molecular fragments con-
interpretation from being too specific to the functional groups. From tribute to positive values, while rare fragments produce negative scores.
this descriptor set, those descriptors having the same value for more These fragment frequencies were determined from 1,000,000 molecules
than 90% of the molecules were removed. Further variable selection in the PubChem database [26] . The ComplexityPenalty term is further
was conducted so that any pair of descriptors had a correlation coeffi- decomposed into four equally weighted penalty terms:
cient less than or equal to 0.9. In this variable selection, variables ex-
hibiting correlation coefficients greater than 0.9 more than once were
ğ‘…ğ‘–ğ‘›ğ‘”ğ¶ğ‘œğ‘šğ‘ğ‘™ğ‘’ğ‘¥ğ‘–ğ‘¡ğ‘¦ğ‘†ğ‘ğ‘œğ‘Ÿğ‘’ = log
10
( ğ‘›ğ‘…ğ‘–ğ‘›ğ‘” ğµ ğ‘Ÿğ‘–ğ‘‘ğ‘” ğ‘’ğ´ğ‘¡ğ‘œğ‘šğ‘  + 1)
iteratively removed. The remaining 23 descriptors used for benchmark + log
10
( ğ‘›ğ‘†ğ‘ğ‘–ğ‘Ÿğ‘œğ´ğ‘¡ğ‘œğ‘šğ‘  + 1) , (3)
2K. Takaki and T. Miyao Artificial Intelligence in the Life Sciences 2 (2022) 100046
Table 1
Statistics of descriptor values for 1,000,000 ZINC compounds.
Descriptor Definition Mean (std) Range [min, max]
EMWt Exact molecular weight 381.1 (92.7) [58, 998.3]
FCSP3 Fraction of C atoms that are SP3 hybridized 0.4 (0.2) [0, 1]
MaxAbsESI Maximum absolute value of the E-state indicator 12.2 (2) [1.5, 18.7]
MaxAbsPC Maximum absolute value of partial charge 0.4 (0.1) [0, 0.8]
MaxPC Maximum value of partial charge 0.3 (0.1) [-0.3, 0.8]
MinAbsESI Minimum absolute value of E-state indicator 0.1 (0.1) [0, 6]
MinESI Minimum value of E-state indicator -1.1 (1.5) [-8.5, 2]
NHOHCount Number of NH and OH 1.1 (1) [0, 26]
NOCount Number of N and O 5.8 (1.9) [0, 35]
NAliCc Number of aliphatic carbon rings 0.2 (0.6) [0, 13]
NAliHc Number of aliphatic heterocycles 0.7 (0.8) [0, 22]
NAliR Number of aliphatic rings 1 (0.9) [0, 22]
NAroCc Number of aromatic carbon rings 1.4 (0.9) [0, 29]
NAroHc Number of aromatic heterocyclic rings 0.9 (0.9) [0, 7]
NAroR Number of aromatic rings 2.3 (1.1) [0, 29]
NHA Number of hydrogen bond acceptors 4.7 (1.8) [0, 30]
NHetAtm Number of heteroatoms 6.9 (2.2) [0, 43]
NRB Number of rotatable bonds 5.3 (2.4) [0, 53]
NSCc Number of saturated carbon rings 0.2 (0.5) [0, 13]
NSHc Number of saturated heterocycles 0.5 (0.7) [0, 22]
NSR Number of saturated rings 0.7 (0.8) [0, 22]
RCount Number of rings 3.3 (1.1) [0, 34]
logp Octanolâ€“water partition coefficient 3.3 (1.6) [-13.1, 19]
2.3.1. Constant optimization in GP
ğ‘† ğ‘¡ğ‘’ğ‘Ÿğ‘’ğ‘œğ¶ğ‘œğ‘šğ‘ğ‘™ğ‘’ğ‘¥ğ‘–ğ‘¡ğ‘¦ğ‘† ğ‘ğ‘œğ‘Ÿğ‘’ = log
1 0
( ğ‘›ğ‘†ğ‘¡ğ‘’ğ‘Ÿğ‘’ğ‘œğ¶ğ‘’ğ‘›ğ‘¡ğ‘’ğ‘Ÿğ‘  + 1) , (4) One of the issues in GP with SR is the treatment of numerical pa-
rameters or constants in expression trees. For example, in Fig. 1 A , the
ğ‘€ğ‘ğ‘ ğ‘Ÿğ‘œğ‘ ğ‘¦ğ‘ ğ‘™ ğ‘’ğ‘ƒ ğ‘’ğ‘›ğ‘ğ‘™ ğ‘¡ğ‘¦ = log
10
( ğ‘›ğ‘€ğ‘ğ‘ ğ‘Ÿğ‘œğ‘ ğ‘¦ğ‘ ğ‘™ğ‘’ğ‘  + 1) , (5) c tho en ss et a pn at rs
a
a
m
a en td
er
b
s
a cap np e ba er ain
b
st oh re
b
e ex dp ir ne s ts hi eo n
st
y
ru
=
c
a
t
x
u
+
re
b .
o
I fn
G
a
P
n ba yÃ¯v ge
i
va ip np gr o tha ec mh,
only a limited number of choices, such as 0, 1, and ğœ‹. In more refined
ğ‘†ğ‘–ğ‘§ğ‘’ğ‘ƒ ğ‘’ğ‘›ğ‘ğ‘™ğ‘¡ğ‘¦ = ğ‘›ğ‘ğ‘¡ğ‘œğ‘šğ‘  1 . 005 âˆ’ ğ‘›ğ‘ğ‘¡ğ‘œğ‘šğ‘ , (6) ways, these parameters can be either sampled from a probability dis-
tribution, e.g., a uniform distribution ( Fig. 1 C left), or numerically op-
where a macrocycle is defined as having more than eight atoms in a
timized as a parameter set during the GP operation ( Fig. 1 C right). A
ring. Therefore, large compounds consisting of many complicated frag-
previous methodological comparison showed that the NLS estimation
ments represented by the structural features above produce high values
of the constant terms outperforms other GP variants in addition to sev-
of SAScore
raw
in Eq. (2) . This raw score is scaled from 1â€“10 to pro-
eral ML models [20] . Thus, our proposed method is based on GP with
duce the final SAScore. In the RDKit implementation for SAScore, sas-
NLS optimization in addition to introducing three filters, as explained
corer.calculateScore , the original SAScore
raw
definition was slightly mod-
below. In this manuscript, GP with NLS optimization of the constant
ified to treat macrocyclic structures and the symmetry of molecules.
terms is referred to as GP for simplicity.
2.3. Symbolic regression with genetic programming
The goal of SR is to learn the mathematical expressions underlying a 2.4. Filter-introduced GP
regression model between an objective variable y and independent vari-
ables x from a training dataset. Unlike black-box ML models, a mathe- 2.4.1. Three filters
matical expression describes the regression model and the structure of One motivation for using SR as the modeling method is to under-
the model is not fixed before training. Because the solution space of ex- stand natural phenomena or experimental results in the form of math-
pressions is vast, efficient search algorithms are necessary. GP [13] mim- ematical expressions. Therefore, simple and understandable mathemat-
ics the natural evolution process to search for the optimal solution, and ical expressions must be constructed. The expressions generated by GP
has been successfully applied to searches across the solution space of ex- without any constraints sometimes contain undesirable features, such as
pressions. In GP, an expression is represented as a tree, where leaves are one variable appearing in several terms (1), nested operations (2), and
numerical constants or variables and (non-leaf) nodes are mathematical invalid operations (3). These three situations are illustrated in Fig. 2 .
operators applied to their child node(s) ( Fig. 1 A ). This structure makes Fig. 2 A depicts situation (1) with an expression tree containing three
it possible to apply evolution-mimicking operations in GP, namely mu- variables. Variable x
2
appears twice in different terms of the expres-
tation and crossover. In the mutation operation, a selected subtree is sion, resulting in a model that is difficult to interpret. Fig. 2 B represents
replaced by another randomly generated subtree with a certain proba- situation (2) with an expression tree containing two consecutive â€œexp â€
bility. In the crossover operation, two individuals (expressions) are ran- operations. Situation (3) only occurs when applying the expression to
domly selected, and one (randomly selected) subtree from each expres- another dataset ( Fig. 2 C ). Expressions that are well-fitted to the training
sion is swapped with one from the other expression ( Fig. 1 B ). dataset sometimes produce infinite values for unseen test compounds be-
To guide the evolution of the expressions in a desirable direction, a cause of an invalid operation. This occurs when test data points reside
fitness function is used. The fitness function determines whether newly outside the domain of applicability of the expression [27] . For exam-
created individuals (expressions) survive into the next generation. In ple, when HBD is selected as the descriptor, and all molecules in the
general, individuals with higher fitness values survive. As a fitness met- training dataset have at least one HBD, this descriptor may become the
ric, the root mean square error (RMSE), the coefficient of determination denominator of an expression. Subsequently, if molecules without HBDs
(R 2 ), or the mean absolute error (MAE) between the observed and pre- are encountered, this expression will result in division by zero and be
dicted y values is usually employed [ 13 , 20 ]. invalid.
3K. Takaki and T. Miyao Artificial Intelligence in the Life Sciences 2 (2022) 100046
Fig. 1. Concept of symbolic regression (SR) with genetic programming (GP). A: Linear regression model with a graph representation in GP, where a and b are
constants to be optimized. B: Crossover operation of two expressions, where red dotted-squares are selected as target subtrees. C: Optimization of constants a and b .
Initial values for these two constants are randomly sampled (left), followed by nonlinear least-squares optimization (right).
To solve situation (1), expressions containing the same variables evolution, surviving expressions are expected to be easy for humans to
in different leaves are simply discarded. This is the V-filter. For situ- understand.
ation (2), expressions with specific operators such as â€œexp â€ or â€œlog â€
that appear more than once in a subtree are removed by the F-filter. 2.4.2. Limitations of FIGP
In this study, the F-filter detects the hierarchical usage of {exp, ln} One of the biggest limitations of the proposed FIGP is the possibility
and {sqrt, square, cube}. For situation (3), the detection of poten- of not being able to find the optimal expression for a phenomenon, such
tially harmful expressions during the training phase of GP is intro- as when the ground-truth formula for the phenomenon violates one or
duced through the D-filter. In the D-filter, several test data points out- more of the to-be-avoided situations explained in Fig. 2 . The precise
side the domain of the training data are used to determine whether expression of a mathematical formula usually requires the same variable
the output values exceed the range of the objective variable or not. to appear in different terms (violation of situation (1)). However, by
In this study, all data points in the training and test datasets passed ensuring that a variable appears at most once, the relation between the
through this filter. By applying these three filters during expression objective and independent variables becomes clearer. Note that simple
4K. Takaki and T. Miyao Artificial Intelligence in the Life Sciences 2 (2022) 100046
Fig. 2. Three cases where interpretation of the expression becomes difficult. A: The same variable appears more than once in a GP tree. B: Nested exponential
operations (right), while unnested usage of the operation is allowed (left). C: Possibility of zero division.
expressions can also be generated by introducing penalty terms in the Table 2
fitness function of GP, instead of using hard constraints. However, in our Experimental conditions for FIGP.
opinion, the three constraints must be satisfied to make the expression
Parameter name Value(s)
understandable, and are thus introduced as filters instead of numerical
penalty terms.
Population size 1000
Number of generations 200
Tree depth for initial population 1â€“2
Crossover probability 0.7
2.4.3. FIGP procedures Mutation probability 0.2
Tree depth for mutation 0â€“2
The procedures involved in FIGP are summarized in Fig. 3 . There are
Maximum depth 4
four components: initial expression generation, selection, evolutionary Function node types + , âˆ’ , Ã—, Ã·, sqrt, square, cube, exp, ln
operation, and fitness calculation. In the initial expression generation, Function filter {sqrt}, {square, cube}, {ln, exp}
one half of the individuals are generated with the Full method and the Tournament size 5
other half are generated with the Grow method [13] to ensure a diverse
set of individuals. Constant nodes in these individuals are optimized by
the NLS method. These individuals (expressions) are filtered out by the 2.5. Experimental conditions for GP
V-, F-, and D-filters. This process is repeated until the number of indi-
viduals reaches a predetermined population size. Expressions consisting The parameter names and values of the FIGP procedure are listed in
of only numerical parameters are disqualified in this phase. In the se- Table 2 . These values were determined based on trial runs using GP. For
lection phase, the expression with the best fitness value passes to the the conventional GP modeling, the same parameter values as for FIGP
next generation, alongside the expressions selected through tournament were used.
selection from five randomly selected individuals. In the evolutionary
process, crossover and mutation operations are applied to individuals 2.6. Comparison methods
or pairs of individuals with predefined probabilities. When the same
individual is produced as a result of an evolutional operation, another As comparison methods, we considered MLR and support vector re-
operation is applied until a unique individual is created (up to a prede- gression (SVR) [28] with radial basis function (RBF) and linear kernels.
fined number of iterations). In the fitness calculation module, numerical The objective loss function of the SVR is the sum of the norms of the co-
parameters (constants) are optimized by NLS, followed by score calcula- efficient vectors and the soft margin loss, which leads to robust models
tion. In this study, the negative RMSE is applied to the training dataset even in the presence of outliers. Nonlinear SVR with the RBF kernel has
as the fitness function to be maximized. This process is repeated for a been extensively used for QSAR models [ 29 , 30 ]. Linear SVR and MLR
predefined number of iterations. are directly interpretable based on the regression coefficients of the de-
5K. Takaki and T. Miyao Artificial Intelligence in the Life Sciences 2 (2022) 100046
Fig. 3. Procedure of FIGP. Four steps of finding the best SR model are described with methodological points in each step. Initial population generation creates the
individuals in the initial population. Selection selects the individuals that survive, followed by evolutional operations and fitness calculations.
scriptors. In this study, the SVR hyperparameters C , ğœ€ , and ğ›¾ (only for To understand the effect of the size of the training dataset on the
RBF kernel) were optimized by five-fold cross-validation of the training predictive ability and complexity of expressions, the number of training
dataset with the help of Optuna using the TPESampler function [31] . compounds was varied from 50 to 800: {50, 100, 200, 400, 800}. The
AI Feynman [15] , a physics-inspired SR modeling system, was also rest of the 1,000,000 ZINC compounds constituted the test data. For each
used for comparison. AI Feynman contains a cascade of filtering pro- number of training compounds, five training datasets were randomly
cesses to generate feasible equations satisfying physics-oriented con- compiled, and five prediction trials were conducted. For each training
straints such as symmetry. AI Feynman can propose expressions for SR dataset, five GP and FIGP models were built by changing the seed val-
models on the Pareto frontier between fitness and complexity. ues of the random number generator in GP. The representative model
was chosen as that which gave the highest R 2 for the training dataset.
2.7. Evaluation metrics Note that cross-validation was not conducted during the training phase
because the FIGP and GP models have no hyperparameters to be opti-
The prediction performance was evaluated in terms of the coefficient mized. Thus, the expression that best explains the training dataset was
of determination (R 2 ), RMSE, and MAE on test datasets. selected.
The AI Feynman system was only applied to the QED with default
2.8. Software and implementation of FIGP parameters. The training dataset size was fixed to 100. For this calcula-
tion, a further limited descriptor set was employed as a means of reduc-
FIGP was implemented on top of the DEAP GP library [32] . The code ing the computational cost and to ensure errorless outputs. The top 13 of
for FIGP, containing the V-, F-, and D- filters, is publicly available in 26 descriptors were selected based on the mutual information against
a GitHub repository at https://github.com/takakikatsushi/FIGP, along y ( Table S1 ) for 1,000,000 ZINC compounds. Thus, only meaningful
with example notebooks. descriptors were employed in this method.
3. Results and discussion 3.2. SR for QED and SAScore
3.1. Study design 3.2.1. Predictive performance
As a metric of the predictive ability of ML models, the R 2 values pro-
The predictive ability of various ML models was compared in terms duced for the test datasets were measured against the number of training
of the two objective variables of the QED and SAScore. The modeling compounds ( Fig. 4 ). Overall, SVR (rbf) shows the best predictive abil-
methods employed in this study were FIGP with the F- and D-filters ity. While GP models without any filters give a better fit to the training
(FIGP_FD), FIGP with the F-, V-, and D-filters (FIGP_FVD), GP, MLR, and datasets than those with filters, the R 2 values for the test datasets exhibit
SVR with the RBF kernel (SVR (rbf)) and linear SVR (SVR (linear)). With- large variances, implying that the GP models tend to be overfitted to the
out the D-filter, the FIGP expressions sometimes output infinite values training data, especially when the training datasets are small. In con-
for test compounds. Thus, FIGP was constrained to include the D-filter. trast, FIGP_FD and FIGP_FVD exhibit stable predictive ability with the
In the GP algorithm, the division, sqrt, and ln operators were pro- various training dataset sizes. For the QED, these two modeling methods
tected from undefined operations, such as zero division. In the DEAP consistently outperform SVR (linear) and MLR. In terms of the SAScore,
implementation [ 32 ], a value of 1 is returned when zero division is at- the FIGP models perform as well as MLR, but are inferior to SVR (lin-
tempted. For GP, R 2 values of less than zero for the test datasets were ear) and SVR (rbf) in terms of R 2 scores. This may be explained by the
treated as zero for ease of comparison in terms of property prediction. nature of SAScore: a simple summation of complexity scores, although
6K. Takaki and T. Miyao Artificial Intelligence in the Life Sciences 2 (2022) 100046
Fig. 4. Predictive capability of SR models. The average R 2 values for the test datasets of QED and SAScore are plotted against the training dataset sizes. Five
modeling methods were tested: FIGP_FD, FIGP_FVD, GP, SVR (rbf), and SVR (linear). Error bars represent the 95% confidence intervals based on the results of five
trials.
each penalty term is in the logarithmic scale. This assertion is supported than GP. For the SAScore with a training dataset of size 200, the average
by the fact that FIGP_FD and FIGP_FVD exhibit similar performance for constant node ratios are 4.56 (sd: 2.06) for GP, 4.40 (1.54) for FIGP_FD,
this target. By introducing the V- and D-filters into GP, the fitness scores and 4.15 (1.35) for FIGP_FVD, showing no significant difference.
with the training data become slightly worse, whereas the R 2 values for For the QED, where a nonlinear relation was expected between the
the test datasets remain unchanged. chemical structure and the objective variable, GP tends to employ more
constant nodes than the other methods.
3.2.2. Convergence of GP-NLS
For both target properties, the fitness values achieved on the training 3.2.3. Expressions returned by AI Feynman
data (RMSE) and the expression diversity were monitored as the compu- AI Feynman was also used to evaluate the QED with 100 training
tations progressed. The expression diversity was measured in terms of compounds and a seed of 0. Recall that AI Feynman produces a set of
operators and descriptors. For the operator diversity, the ratio of expres- expressions on the Pareto frontier, with a tradeoffbetween fitness and
sions containing specific operators to the total number of expressions, simplicity of expression ( Table S2 ). For most of the Pareto solutions,
i.e., population size, was monitored. In the same way, for the descriptor the R 2 values for the test data were infinite because of undefined func-
diversity, the ratio of expressions containing specific descriptors to the tional operations. The simplest expression showed an R 2 value of âˆ’0 .09
population size was monitored. Fig. 5 reports the expression diversity for the training set and negative infinity for the test set. The generated
for the QED when the training seed ID was 0 and the training dataset had expression was
a size of 100. Transition plots with other seeds (IDs of 1, 2, 3, and 4) are
QED = arccos
(
âˆ’0 . 03 Ã—NAliC c 2 + 0 . 03 Ã—NAliCc + 1 .
0)
consistent with that obtained from a seed of 0, as shown in Figs. S1 â€“S4 ( )
in the Supporting Information. Overall, the RMSE values decrease mono- + arctan âˆ’0 . 08 ( Ã—NSR 3 + 0 . 3 Ã—NSR 2 + 0 . 1 )1 Ã—NSR + 0 . 06
tonically and converge within 200 generations. The minimum RMSE âˆ’1 . 52 Ã—arccos 1 . 0 âˆ’ 0 . 01 Ã—NHOHCount 2
( )
value is achieved by GP, followed by FIGP_FD and FIGP_FVD. FIGP_FVD Ã—arctan âˆ’0 . 55 Ã—NAliHc 3 + 1 . 84 Ã—NAliH c 2 âˆ’ 1 . 08 Ã—NAliHc âˆ’ 0 . 39 .
exhibits slower convergence than FIGP_FD in terms of RMSE and the
(7)
descriptor and operator ratios.
Furthermore, as an indirect metric of the degree of overfitting to the This expression contains two arccos functions and two arctan func-
training data, the ratio of constant nodes per expression was monitored tions. The number of aliphatic heterocycles (NAliHc) appears in several
during the GP progress. Over the five trials for the QED with a training terms. Even the simplest expression is hard to interpret through a vi-
dataset of size 100, the average constant node ratio after convergence sual inspection, notwithstanding that it completely fails to explain the
is 4.36 (sd: 1.59) for GP, 2.63 (0.74) for FIGP_FD, and 2.16 (0.36) for training data. For the most complex expression, the R 2 value for the
FIGP_FVD. For the QED, the FIGP models used fewer constant nodes training data set was 0.98, suggesting a good fit to the training data.
7K. Takaki and T. Miyao Artificial Intelligence in the Life Sciences 2 (2022) 100046
Fig. 5. Convergence of FIGP training process. For the first of five GP trials (seed 0), the converge of the minimum RMSE values are plotted against the generation
(top row), the probabilities of using operators in an expression (middle row), and the probabilities of using descriptors in an expression (bottom row). For GP,
protected versions of the division, logarithm, and sqrt operation were used.
However, the R 2 value for the test data was âˆ’1 8.22 and the generated ways true according to Fig. 4 . The expression generated by GP is more
expression contained too many terms (274 plus signs and 286 minus complicated than those given by FIGP_FD and FIGP_FVD. For example,
signs). the effect of molecular weight (EMWt) on the QED prediction values
AI Feynman is intended to derive physics formulas from a dataset, is hard to understand. The expressions from FIGP are similar to each
with symmetries and separability considered inside the system. This other ( Table S4 ). Neither expression contains a variable appearing in
might not be appropriate for QSPR/QSAR analysis, because models for more than one term. This is not always true for FIGP_FD, as can be seen
QSPR/QSAR simply approximate the relations between chemical struc- from Table S3 (seed ID1 and ID4). The logarithm of the FIGP_FVD ex-
tures and properties/activities. Furthermore, in AI Feynman, a neural pression in Table 3 becomes the product of ( NAroR 3 + 7 . 13 â‹…NRB) and
network is constructed using a training dataset to detect symmetries and ( âˆ’0 . 000694 â‹…NHet At m âˆ’ 0 . 000694 â‹…logp) . The effects of the contributing
smoothness. To form an accurate response surface, many data points are features on the logarithm of QED values differ in scale and combination.
needed. In our calculation setting, we selected 13 out of 26 variables For example, the third power of the number of aromatic rings (NAroR)
based on the mutual information and 100 training compounds. This might have an equivalent effect on the QED values as 7.13 âˆ— NRB (number
calculation setting might impede AI Feynman from generating â€œtrue â€ of rotatable bonds). Likewise, the number of heteroatoms (NHetAtm)
expressions. and logP values have equivalent effects on the QED values based on this
equation. Note that the correlation among descriptors is not considered,
although it is likely that these descriptor values cannot be altered inde-
3.2.4. Expression analysis
pendently. Compared with the ground-truth QED definition in Eq. (1) ,
The three expressions for QED generated by FIGP_FD, FIGP_FVD,
several descriptors appear frequently in the FIGP expressions: NAroR,
and GP from a training seed ID of 0 and a training dataset of size
NRB, and logP. The exponential term in Eq. (1) was correctly identi-
100 are reported in Table 3 . All SR expressions from five trials gen-
fied by FIGP_FVD in all five trials ( Table S4 ) and by FIGP_FD in four of
erated by FIGP_FD, FIGP_FVD, and GP with a training dataset of size
the five trials ( Table S3 ). However, the generated expressions are not
100 are reported in Tables S3 â€“S5 , respectively. Among the expressions
identical to Eq. (1) .
in Table 3 , GP gives the best predictive ability, although this is not al-
Table 3
GP and FIGP expressions for QED. For the first of five GP trials (seed 0) with a training dataset
size of 100 for QED, SR expressions along with R 2 for the training and test datasets are listed. The
descriptors in the expressions are defined in Table 1 .
Method Expression Train R 2 Test R 2
FIGP_FD exp ( âˆ’1 . 40 â‹…10 âˆ’6 â‹…EMWt â‹…( NRB + 8 . 02) â‹…( NAroR 3 + NHet At m + 32 . 9) ) 0.72 0.64
FIGP_FVD exp ( ( NAro R 3 + 7 . 13 â‹…NRB) â‹…( âˆ’0 . 000694 â‹…NHet At m âˆ’ 0 . 000694 â‹…logp) ) 0.70 0.59
GP 1 . 40
E
â‹…1 M07
W
â‹…N
t
3A âˆ’li EH Mcâˆ’ W2
t
.
+
60
6
â‹… .1 00 37
â‹…
1â‹…N
07
A +r o MR in+
E
SE
I
+M 1N W
.
9Ht
6
A+ â‹…1+ 9
0
. 4 3
8
60 . â‹… 31 0 9 0.84 0.72
FCSP3+NAroR
8K. Takaki and T. Miyao Artificial Intelligence in the Life Sciences 2 (2022) 100046
Table 4
GP and FIGP expressions for SAScore. For the first of five GP trials (seed 0) with a training dataset size of 200 for SAScore, SR
expressions along with R 2 for the training and test datasets are listed. The descriptors in the expressions are defined in Table 1 .
Method Expression Train R 2 Test R 2
FIGP_FD FCSP3 + 0 . 0179 â‹…NRB + NE HM OW Ht
C
âˆ’ o4
u
. 9 n9
t +
â‹…1 20 23
7
+ 21 . 2 + ( NAliR + 131) â‹…NA El MiR W+
t
âˆš
+N MA ar xo AH bc
s
+ ES2 .
I
0 2 0.66 0.47
FIGP_FVD FCSP3 âˆ’ MaxPC + 0 . 262 â‹…NAroHc + 0 . 262 â‹…RCount + ( 0 . 000490 â‹…EMWt âˆ’ 0 . 554) â‹…( NAroR + 2 . 44) + 3 . 25 0.62 0.44
GP 0 . 777 â‹…FCSP3 + 0 . 0815 â‹…NHOHCount + 0 . 102 â‹…NRB + ( 0 . 608 âˆ’ 0 . 0395 â‹…NRB) â‹…( NAliR + 0 . 596 â‹…NAroHc) + 1 . 19 0.64 0.46
Table 5
MMS profiles.
ID Target name #CPDs Potency range [pK
i
] Core SMILES
1 Tyrosine-protein kinase ABL 76 [6.4, 10.7] O = C(Nc1cc2ccc( âˆ— )cc2cn1)C1CC1
2 Kappa opioid receptor 83 [5.1, 9.2] COC( = O)[C@@H]1C[C@H]( âˆ— )C( = O)[C@H]2[C@@]1(C)CC[C@H]1C( = O)O[C@H](c3ccoc3)C[C@]21C
3 Histamine H3 receptor 53 [6.8, 10.2] c1cc( âˆ— )ccc1OCCCN1CCCCC1
Similar analysis was conducted for SAScore with a dataset size of Table 6
200. The expressions generated by the three algorithms are reported Predictive ability of ML models for training and test
in Table 4 for a training seed ID of 0. All SR expressions for the five datasets.
trials with a training dataset size of 200 are reported in Tables S6 â€“S8
Training Test
for FIGP_FD, FIGP_FVD, and GP, respectively. The three expressions in Data ID Method
R 2 RMSE R 2 RMSE
Table 4 indicate comparable predictive performance for the test dataset.
All expressions use the fraction of SP3 carbon atoms (FCSP3) as a de- 1 SVR (rbf) 0.60 0.59 0.19 0.79
scriptor with a positive effect on the SAScore values (difficult to synthe- MLR 0.39 0.72 0.28 0.74
FIGP_FVD 0.49 0.66 0.26 0.75
size). This descriptor is related to the number of stereo centers, and is
2 SVR (rbf) 0.70 0.54 0.34 0.71
thus an important descriptor for SAScore prediction. The FIGP_FVD ex- MLR 0.36 0.79 0.24 0.76
pression is the simplest, as expected. For FIGP_FD and GP, the effect of FIGP_FVD 0.51 0.69 0.46 0.64
NRB on the SAScore is not clear because this descriptor appears in multi- 3 SVR (rbf) 0.64 0.41 0.22 0.47
MLR 0.58 0.43 0.03 0.53
ple terms in the expressions. Although FIGP_FD produces the most com-
FIGP_FVD 0.66 0.39 -0.04 0.54
plicated expression in Table 4 , GP without any filters generates more
complicated expressions based on the number of terms in Tables S6 â€“ For each dataset, the best predictive performance for the
S8 . test data is highlighted in bold.
3.3. Demonstration of QSAR modeling ating Environment Software ver. 2022.02 [35] . The MMS datasets with
these descriptors and potency values, as well as substituent SMILES
3.3.1. Datasets strings, are provided as tab-separated text in the Supporting Informa-
For a demonstrative application of FIGP, three sets of substituents tion.
with specific cores (analogous compounds) against specific targets were
compiled from the ChEMBL database version 29 [33] . Only bioactive
3.3.3. FIGP models
compounds annotated with K
i
values against specific human target
Each MMS dataset was randomly split into training (80%) and test
macromolecules were considered. These compound and K
i
data were
(20%) sets. MLR, SVR (rbf), and FIGP_FVD were employed with the same
extracted from assays with a confidence score of 9 (highest) and direct
settings as for property prediction. For FIGP, all the filters were included,
binding. Targets with more than 300 bioactive compounds after dis-
and all the data points for each target were used in the D-filter. The
carding the upper and lower 10th percentiles in the number of heavy
goodness-of-fit to the training and test datasets is reported in Table 6 .
atoms and showing a minimum potency range of 5 were extracted. From
The best modeling methods are different for each dataset. For datasets
these compound datasets, target-wise matching molecular series (MMS)
ID1 and ID3, MLR performs almost as well as FIGP_FVD. For dataset ID3,
[34] were created with the help of the RDKit community contribution
SVR (rbf) is the best method, whereas for dataset ID2, FIGP_FVD is the
module â€œmmpa â€[25] , with a substituent ratio against the core of 0.35.
best. Table 7 reports the expressions generated by FIGP_FVD. The ex-
MMS with a single-cut core and containing at least 40 substituents with
pression for dataset ID2 is nonlinear. In the numerator, NRB multiplied
a minimum potency range of 3.0 were selected. Twelve MMS against
eight targets were identified. From the eight targets, three MMS were
by MWt has a negative effect on the pK
i
prediction. The effect of NHA
is less important because it is much smaller than the other constant in
selected based on their target diversity and potency range. The profiles
the logarithm function. This is consistent with the regression coefficient
of the selected MMS are provided in Table 5 .
value of 0.001 for NHA in the MLR model. NAroR is divided by logp in
the denominator. The domain of logp contains zero, so this function is
3.3.2. Substituent descriptors not defined for compounds for which logp = 0. Thus, data points for the
The following seven descriptors were used: number of aromatic rings D-filter should be carefully selected for avoiding invalid operations. The
(NaroR), number of hydrogen bond acceptor/donor atoms (NHA/NHD), FIGP_FVD expression for dataset ID3 can be expressed by linear com-
logarithm of the octanol/water partition coefficient (logp), rotatable binations of descriptors and polynomial terms. That is why FIGP_FVD
bond counts (NRB), topological polar surface area (TPSA), and molecu- and MLR exhibit a similar predictive ability for the test dataset. Over-
lar weight (MWt). These descriptor values were only calculated for the all, FIGP_FVD provides a better fit to the training data than MLR,
substituents after replacing the attachment points with carbon atoms. but the predictive ability of FIGP_FVD is not always better than that
The descriptor calculations were conducted using the Molecular Oper- of MLR.
9K. Takaki and T. Miyao Artificial Intelligence in the Life Sciences 2 (2022) 100046
Table 7
Mathematical expressions generated by FIGP_FVD.
Data ID Expression
1
2
lo NAg
r
p
oR
âˆ’
2
+
0â‹…
. 0
0(
5
.
N
54
71R
6
â‹…NB
â‹…NR
HBâˆ’
Dâ‹… ( M
+0
W
lo
.
gt
4
(
7
âˆ’
N
6 H1)
A3 7
â‹…
)
+(
+
âˆ’
15
.0
12
7
.
.
3
0 â‹…2 100
3
1
)
â‹…TPSA âˆ’ 0 . 105) + ( 1 . 01 âˆ’ M23
W
. 7
t
) â‹…( NAroR + 0 . 286 â‹…NHD + 9 . 74)
3 0 .l 0og 1p 64 â‹…MWt + 0 . 0984 â‹…NRB âˆ’ 0 . 152 â‹…logp âˆ’ ( 0 . 0551 âˆ’ 0 . 0510 â‹…NAroR) â‹…( âˆ’4 . 88 â‹…NHD + TPSA âˆ’ 7 . 87) + 7 . 27
4. Conclusions Supplementary materials
This paper has described an interpretable QSAR/QSPR method based Supplementary material associated with this article can be found, in
on the use of three filters in GP for SR. The V-filter forces every variable the online version, at doi: 10.1016/j.ailsci.2022.100046 .
to appear no more than once, the F-filter suppresses the recursive usage
of functionals, and the D-filter ensures the expression does not output References
infinite or undefined values when compounds outside the domain of the
[1] Polishchuk P. Interpretation of quantitative structure-activity relationship models:
training dataset are given.
past, present, and future. J Chem Inf Model 2017;57(11):2618â€“39 .
In our proof-of-concept study, the proposed FIGP generated simpler [2] Hansch C, Maloney PP, Fujita T, Muir RM. Correlation of biological activity of phe-
QSPR models than two existing SR methods (AI Feynman and GP). The noxyacetic acids with Hammett substituent constants and partition coefficients. Na-
QSPR expressions given by FIGP provide insights into the original func-
ture 1962;194(4824):178â€“80 .
[3] Hansch C. The advent and evolution of QSAR at Pomona College. J Comput Mol Des
tional forms of the objective variable for the QED and SAScore, while 2011;25(6):495â€“507 .
maintaining a distance from the ground-truth expressions. For the QED, [4] Zahrt AF, Athavale SV, Denmark SE. Quantitative structure-selectivity rela-
FIGP showed better predictive ability than linear regression modeling tionships in enantioselective catalysis: past, present, and future. Chem Rev
2020;120(3):1620â€“89 .
methods, while for the SAScore, the predictive ability was slightly infe- [5] Santiago CB, Guo JY, Sigman MS. Predictive and mechanistic multivariate linear
rior to that of SVR (linear). The black-box machine learning method of regression models for reaction development. Chem Sci 2018;9(9):2398â€“412 .
SVM (rbf) exhibited the highest predictive ability. [6] Reid JP, Proctor RSJ, Sigman MS, Phipps RJ. Predictive multivariate linear regres-
sion analysis guides successful catalytic enantioselective minisci reactions of di-
The mathematical expressions generated by GP can be used to derive
azines. J Am Chem Soc 2019;141(48):19178â€“85 .
gradients. This makes it possible to constrain the generation of expres- [7] Ho TK. The random subspace method for constructing decision forests. IEEE Trans
sions to those with smooth response surfaces during evolution. Design- Pattern Anal Mach Intell 1998;20(8):832â€“44 .
[8] Cortes C, Vapnik V, Saitta L. Support-vector networks. Mach Learn
ing molecules based on the gradient of a compound may be a useful op-
1995;20(3):273â€“97 .
timization approach. Furthermore, GP contains stochastic operations in [9] RodrÃ­guez-PÃ©rez R, Bajorath J. Interpretation of machine learning models using
nature, so we must determine which expression should be used in prac- shapley values: application to compound potency and multi-target activity predic-
tions. J Comput Aided Mol Des 2020;34(10):1013â€“26 .
tical applications. This selection process may be heuristic, but FIGP has
[10] Balfer J, Bajorath J. Visualization and interpretation of support vector machine ac-
been designed to help humans interpret QSPR/QSAR. It is also possible tivity predictions. J Chem Inf Model 2015;55(6):1136â€“47 .
to derive common features by analyzing multiple generated expressions, [11] Tamura S, Jasial S, Miyao T, Funatsu K. Interpretation of ligand-based activ-
which might lead to interpretation of QSPRs/QSARs.
ity cliff prediction models using the matched molecular pair kernel. Molecules
2021;26(16):4916 .
Inside the FIGP architecture, the only criterion tested in this study [12] Asahara R, Miyao T. Extended connectivity fingerprints as a chemical reaction rep-
was the goodness-of-fit of expressions produced using a training dataset resentation for enantioselective organophosphorus-catalyzed asymmetric reaction
(RMSE). Other criteria could be used, such as the Akaike informa- prediction. ACS Omega 2022;7(30):26952â€“64 .
[13] Koza JR. Genetic programming as a means for programming computers by natural
tion criterion and Bayesian information criterion. Thus, further re- selection. Stat Comput 1994;4(2):87â€“112 .
search is needed to identify methods for generating simple predictive [14] Schmidt M, Lipson H. Distilling free-form natural laws from experimental data. Sci-
expressions. ence 2009;324(5923):81â€“5 .
[15] Udrescu SM, Tegmark M, Feynman AI. A physics-inspired method for symbolic re-
gression. Sci Adv 2020;6(16):eaay2631 .
[16] Xie J, Zhang L. Machine learning and symbolic regression for adsorption of atmo-
Declaration of Competing Interest spheric molecules on low-dimensional TiO
2
,. Appl Surf Sci 2022;597:153728 .
[17] Weng B, Song Z, Zhu R, Yan Q, Sun Q, Grice CG, Yan Y, Yin WJ. Simple descrip-
tor derived from symbolic regression accelerating the discovery of new perovskite
The authors declare that they have no known competing financial
catalysts. Nat Commun 2020;11(1):1â€“8 .
interests or personal relationships that could have appeared to influence [18] Archetti F, Lanzeni S, Messina E, Vanneschi L. Genetic programming for computa-
the work reported in this paper. tional pharmacokinetics in drug discovery and development. Genet Program Evolv-
able Mach 2007;8(4):413â€“32 .
[19] Archetti F, Giordani I, Vanneschi L. Genetic programming for QSAR investigation of
Data availability
docking energy. Appl Soft Comput 2010;10(1):170â€“82 .
[20] Kommenda M, Burlacu B, Kronberger G, Affenzeller M. Parameter identification for
Data will be made available on request. symbolic regression using nonlinear least squares. Genet Program Evolvable Mach
2020;21(3):471â€“501 .
[21] Miyao T, Funatsu K. Finding chemical structures corresponding to a set of coordi-
nates in chemical descriptor space. Mol Inform 2017;36(8):1700030 .
Acknowledgements [22] Bickerton GR, Paolini GV, Besnard J, Muresan S, Hopkins AL. Quantifying the chem-
ical beauty of drugs. Nat Chem 2012;4(2):90â€“8 .
We thank Swarit Jasial for carefully proofreading a draft of this [23] Ertl P, Schuffenhauer A. Estimation of synthetic accessibility score of drug-like
molecules based on molecular complexity and fragment contributions. J Chemin-
manuscript. We also thank Ryosuke Asahara for helping us set up com- form 2009;1(1):1â€“11 .
putational analyses. This work was supported by a Grant-in-Aid for [24] Sterling T, Irwin JJ. ZINC 15 - ligand discovery for everyone. J Chem Inf Model
Transformative Research Areas (A) 21A204 Digitalization-driven Trans- 2015;55(11):2324â€“37 .
[25] RDKit Open-source cheminformatics. https://www.rdkit.org
formative Organic Synthesis (Digi-TOS) from the Ministry of Education,
[26] Kim S, Chen J, Cheng T, Gindulyte A, He J, He S, Li Q, Shoemaker BA, Thiessen PA,
Culture, Sports, Science & Technology, Japan, and was supported by Yu B, et al. PubChem in 2021: new data content and improved web interfaces. Nu-
JSPS KAKENHI Grant Number JP20K19922. We thank Stuart Jenkin- cleic Acids Res 2021;49(D1):D1388â€“95 .
[27] Dragos H, Gilles M, Alexandre V. Predicting the predictability: a unified ap-
son, PhD, from Edanz (https://jp.edanz.com/ac) for editing a draft of
proach to the applicability domain problem of Qsar Models. J Chem Inf Model
this manuscript. 2009;49(7):1762â€“76 .
10K. Takaki and T. Miyao Artificial Intelligence in the Life Sciences 2 (2022) 100046
[28] Smola AJ, SchÃ¶lkopf B. A tutorial on support vector regression. Stat Comput [32] Fortin F-A, Marc-AndrÃ©Gardner U, Parizeau M, GagnÃ©C. DEAP: evolutionary algo-
2004;14(3):199â€“222 . rithms made easy. J Mach Learn Res 2012;13:2171â€“5 .
[29] Li L, Wang B, Meroueh SO. Support vector regression scoring of receptor-ligand [33] Gaulton A, Bellis LJ, Bento AP, Chambers J, Davies M, Hersey A, Light Y,
complexes for rank-ordering and virtual screening of chemical libraries. J Chem Inf McGlinchey S, Michalovich D, Al-Lazikani B, Overington JP. ChEMBL: a large-scale
Model 2011;51(9):2132â€“8 . bioactivity database for drug discovery. Nucleic Acids Res 2012;40:D1100â€“7 .
[30] RodrÃ­guez-PÃ©rez R, Bajorath J. Evolution of support vector machine and regres- [34] Wawer M, Bajorath J. Local structural changes, global data views: graphical
sion modeling in chemoinformatics and drug discovery. J Comput Aided Mol Des substructure âˆ’ activity relationship trailing. J Med Chem 2011;54:2944â€“51 .
2022;2022:1â€“8 . [35] MOE (Molecular Operating Environment). Montreal, Canada: Chemical Computing
[31] Akiba T, Sano S, Yanase T, Ohta T, Koyama M. Optuna: a next-generation hyperpa- Group Inc; 2022 .
rameter optimization framework. In: Proc. ACM SIGKDD Int. Conf. Knowl. Discov.
Data Min.; 2019. p. 2623â€“31 .
11