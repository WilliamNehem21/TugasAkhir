Array17(2023)100272
ContentslistsavailableatScienceDirect
Array
journalhomepage:www.elsevier.com/locate/array
Harmonizingmotionandcontrastvisionforrobustloomingdetection
QinbingFuâˆ—,1,ZhiqiangLi1,JigenPengâˆ—
MachineLifeandIntelligenceResearchCentre,SchoolofMathematicsandInformationScience,GuangzhouUniversity,Guangzhou,510006,China
A R T I C L E I N F O A B S T R A C T
Keywords: This paper presents a novel neural model of insectâ€™s visual perception paradigm to address a challenging
Neuralmodelling problemondetectionofloomingmotion,particularlyinextremelylow-contrast,andhighlyvariablenatural
Neuromorphiccomputing scenes.Currentloomingdetectionmodelsaregreatlyaffectedbyvisualcontrastbetweenmovingtargetand
Low-contrastloomingdetection cluttered background lacking robust and low-cost solutions. Considering the anatomical and physiological
ParallelON/OFFchannels
homologybetweenpreliminaryvisualsystemsofdifferentinsectspecies,thisgapcanbesignificantlyreduced
Contrastneuralcomputation
bycoordinatingmotionandcontrastneuralprocessingmechanisms.Theproposedmodeldrawslessonsfrom
researchprogressininsectneuroscience,articulatesaneuralnetworkhierarchybaseduponON/OFFchannels
encodingmotionandcontrastsignalsinfourparallelpathways.Specifically,thetwoON/OFFmotionpathways
react to successively expanding ONâ€“ON and OFFâ€“OFF edges through spatialâ€“temporal interactions between
polarity excitations and inhibitions. To formulate contrast neural computation, the instantaneous feedback
normalizationofpreliminarymotionreceivedatstartingcellsofON/OFFchannelsworkseffectivelytosuppress
time-varying signals delivered into the ON/OFF motion pathways. Besides, another two ON/OFF contrast
pathwaysarededicatedtoneutralizehigh-contrastpolarityopticflowswhenconvergingwithmotionsignals.
Tocorroboratetheproposedmethod,wecarriedoutsystematicexperimentswiththousandsoflooming-square
motionsatvariedgreyscales,embeddedindifferentnaturalmovingbackgrounds.Themodelresponseachieves
remarkably lower variance and peaks more smoothly to looming motions in different natural scenarios, a
significant enhancement upon previous works. Such robustness can be maintained against extremely low-
contrast looming motion against cluttered backgrounds. The results demonstrate a parsimonious solution to
stabilizeloomingdetectionagainsthighinputvariability,analogoustoinsectâ€™scapability.
1. Introduction motion,(2)noisybackgroundmotion,(3)highsolutioncostondealing
with high-dimensional features. Although the new technology based
Insects possess parsimonious visual systems capable of dealing on deep learning has good performance in reality, it demands large-
with complex navigation tasks in a both robust and low-energy man- scaledatasetsandconsumeslargevolumeofcomputingresources.In
ner [1]. Among visually guided abilities in navigation, looming de- ordertoleveragesystemrobustnessandenergyconsumptioninmotion
tection, i.e., the perception of objects that approach, is essential to detection, peopleâ€™s attention is gradually attracted by natural ability.
determine a variety of behaviours including predation and defence Learningfromthehomologybetweenloomingdetectionneuralsystems
against natural enemy [2], landing [3], clustering [4], and so forth. of different insect species could provide effective, low cost, tractable
In the human world, looming detection is also a frontier of scientific
solutions[19,20].
research to build collision-free artificial vision systems in service of
Locustsandfliesaretwoprominentmodellingparadigmstostudy
mobilerobots[5â€“8],UAVs[9,10],andgroundvehicles[11â€“14].
loomingdetectionstrategies.Aconsiderableamountofcomputational
Typical looming detection methods mainly depend on different
works thus has been proposed to simulate biological visual percep-
sensor strategies, such as radar [15], infrared [16], ultrasonic [17],
tion mechanisms for looming detection either at local, optical flows
and visual modalities [18]. In respect of retrieving more abundant of
level [19], or in neural networks hierarchy [20]. The advantage of
motionfeaturesshortly,vision-basedmethodologiesareprevailingover
such biologically plausible solutions stems from their resource effi-
other physical sensing techniques, however suffering from impact by
ciency (or parsimony) especially in terms of power and mass, thus
chaoticanddynamicenvironments.Inanotherword,currentartificial
creatingmanysuccessfulapplicationsinmicro-machineswithrestricted
visionsystemsforloomingdetectionarevulnerableto(1)low-contrast
âˆ— Correspondingauthors.
E-mailaddresses: qifu@gzhu.edu.cn(Q.Fu),jgpeng@gzhu.edu.cn(J.Peng).
1 QinbingFuandZhiqiangLiarejointfirstauthors.
https://doi.org/10.1016/j.array.2022.100272
Received14October2022;Receivedinrevisedform10December2022;Accepted13December2022
Availableonline16December2022
2590-0056/Â©2022TheAuthor(s).PublishedbyElsevierInc.ThisisanopenaccessarticleundertheCCBYlicense(http://creativecommons.org/licenses/by/4.0/).Q.Fuetal. Array17(2023)100272
computationalcapacitylikemicro-mobilerobots[21â€“23],microaerial 2. Relatedwork
vehicles [24â€“26], and small bio-mimic sensors [27]. Moreover, a few
methodshavebeenproposedtoenhancetherobustnessandadaptabil- Withinthissection,weconciselyreviewrelatedworksintheareas
ity of insect-inspired looming detection models in complex, dynamic of(1)insect-inspiredvisualsystemsforloomingdetection,(2)contrast
environments in recent years [20]. Accordingly, such insect-inspired neural computation for signal processing. We also highlight the new
approacheshave,tosomeextent,overcometheaforementionedprob- achievementsuponrelatedworks.
lems via filtering out irrelevant background motions and minimizing
2.1. Insect-inspiredmethodsforloomingdetection
resourcecostwithsuccessfulapplicationsontomicro-robot[22].
However,currentmethodologiesarestillsignificantlyinfluencedby
Insect-inspired intelligence has emerged as influential model sys-
spatial contrast, the difference of illumination between adjacent local
temsforartificialintelligenceandroboticsbenefitingfromitsresource
areasofreceptivefield.Themodelresponsetemporallyfluctuateswith
efficiency;italsohasshowngreatpotentialtoconnectbiologicaland
high variance against input variability of natural signals. In addition,
artificiallives[37].Forbuildingartificialvisualsystems,insectvision
recognition of low-contrast looming motion has always been a chal-
offerstractableandlow-costsolutionstoachieveeffectiveperformance
lengingproblemforartificialvisionsystems.Thecausalitywouldbe(1)
incomplex,dynamic,andsometimeshostileenvironments.Inparticu-
internally non-linear attribute of motion detection, and (2) externally
lar,thevisualsystemsoffliesandlocustsareprevalentmodelsystems
largevariationinlocalcontrastofnaturalsignals[28].
leading many successful looming-detecting applications in computing
Tosolvethisproblem,theresearchintoinsectneurosciencerecently hardware with extraordinarily restricted resources, like flying robots
hasrevealedtheircompactneuralcircuitsharmonizemotionandcon- and ground micro-robots [1,19,22,25]. By reflecting system complex-
trastvisualprocessingforrobustmotionvisionagainstnaturalsignals, ity at different scales, they each apply different strategies of visual
thoughwithorganizationalandfunctionaldisparitiesbetweendifferent processingindistinctstructures.
species [29,30]. The neural circuits of fruit fly Drosophila have been Flyvisualsystemshavebeenmodelledmostextensively,illustrated
studied and investigated most intensively [31â€“34]. Actually, contrast mainly as optical flow(OF)-based methods [19]. In terms of physi-
neuralcomputationhasbeenfoundtoplaycrucialroleswhichisprob- ology, a group of visual neurons called lobula plate tangential cells
ably generic to preliminary visual systems of other animals including (LPTCs) in flyâ€™s visual brain has been identified to indicate direction
mammals, concerning their commonalities after millions of years of andmagnitudeoflocalmotionflows[38â€“41].Suchloomingdetection
natural evolution [35]. Biologically dynamic vision systems decently strategy has been widely used in flying robots including micro aerial
resolve the local contrast issues whereas artificial vision systems are vehicles [26,42]. However, to the best of our knowledge, such OF-
stillgreatlychallenged. based approach is primarily used for lateral looming motion sensing
To this end, this paper addresses the local contrast problem in and collision avoidance, and is insufficient for detection of frontal
looming detection whereby the proposed method coordinates motion object approaching. Moreover, such visual method is intolerant of
andcontrastneuralcomputationinharmony.Specifically,thereceived low-contrastmotionalwaysresultinginfailureofloomingdetection.
signalsaresplitintofourparallelON/OFFchannelsspecializinginen- To address these OF-based problems, one category of modelling
solutions stems from the lobula giant movement detectors (LGMD) in
codingmotionandcontrastinformationofvisualstreams,respectively.
locustâ€™svisualbrain[43â€“46].Theseneuronsrespondmoststronglyto
ThetwoON/OFFmotionpathwayscorrelatebrightnesschangeinorder
looming objects that directly approach the eyes, a situation that the
toextractthesuccessiveexpansionofONâ€“ON/OFFâ€“OFFedgesthrough
OF-based methodscannot deal withvery well. Specifically, theloom-
spatialâ€“temporal competition between excitatory and suppressive lo-
selectivity of LGMD models or neural networks has been shaped well
cal response. The contrast neural computation includes instantaneous
to moving objects that signal proximity rather than other kinds of
feedbacksuppressionofpreliminarymotionarrivedattheentranceof
movements [20]. There have been different approaches to formulate
ON/OFF motion channels for dynamic normalization of time-varying
LGMD neuronal circuits with which the commonality is extracting
signals, cascaded with motion correlation. The two ON/OFF parallel
loomingfeaturesthroughmulti-layeredneuralnetworks.Althoughsuch
contrastpathwaysarededicatedtoattenuatehigh-contrastopticflows
models have been satisfactorily applied in small-sized hardware for
forinhibitingON/OFFlocalmotion,respectively.Inthismanner,our
collisiondetection[6,7,9,21,23],themodelperformanceisstillgreatly
proposedmodeldemonstratessignificantenhancementinloomingde-
affected by spatial contrast, especially in natural scenarios with high
tection against high input variability of natural signals, especially in
inputvariability.
extremely low-contrast scenes. To corroborate this model, we created Anothernewcategoryofmethodsspecializinginloomingdetection
a new data set consisting of thousands of looming-square motions at originatesfromthelobulaPlate/lobulacolumnartypeII(LPLC2)neu-
variedgreyscalesembeddedindifferentshiftingnaturalbackgrounds, ronal ensemble, deeper than LPTCs in flyâ€™s visual brain, that features
as input stimuli. The systematic experiments demonstrated threefold ultra-selectivity to only radial looming motion, i.e., edges diverging
achievementsofthisresearchuponpreviousworks: from the centroid of view [47]. Two computational works have been
lately proposed to simulate such specific looming detection neural
1. Theproposedmodelcoordinatesmotionandcontrastvisionwithin
systems[48,49].
four parallel ON/OFF channels, which works effectively to recog-
Comparedwithabovemethods,weemphasizethecoordinationof
nizeloomingmotioninextremelylow-contrastscenes.Therobust-
motionandcontrastvisioninparallelON/OFFchannelsmimickingthe
nessagainstnaturalsignalshasbeenenhancedwherebythemodel
generally four neuropil-layers of insect physiology shown in Fig. 1.
responsepeaksmoresmoothly.
We propose the contrast neural computation as shown in Fig. 3. The
2. Comparedtothetypicalmodelthatonlyhandleswithmotionsignals advantagesoverpreviousstudiesareabstractedasthefollowing:
forloomingdetection[36],theproposedcontrastcomputationcan
significantlyreduceresponsevariancetestedbythelargevisualdata 1. Therobustnessofloomingdetectionagainstvariousnaturalsignals
setofhighinputvariability. has been significantly enhanced through introducing motion and
3. Theneuromorphiccomputingofinsectâ€™sfour-layer,preliminaryvi- contrast neural computation in parallel ON/OFF pathways encod-
sualneuralcircuitsdemonstratesaparsimoniousandeffectivesolu- ing ONâ€“ON and OFFâ€“OFF dynamic features separately. The model
canrecognizeextremelylow-contrastloomingmotion,asignificant
tiontostabilizeloomingdetectionagainstnaturalsignals,analogous
enhancementuponpreviousworks.
toinsectâ€™scapability.
2. The proposed contrast mechanism and pathway harmonize in ex-
Therestofthispaperisstructuredasfollows:Section2reviewsre- traction of looming motion features to stabilize the neural model
latedworks.Section3formulatestheproposedneuralmodel.Section4 against natural signals of high input variability. The fidelity of
evaluatestheproposedmethod.Section5concludesthispaper. loomingdetectionhasbeenremarkablyimproved.
2Q.Fuetal. Array17(2023)100272
Fig.1. Schematicillustrationsofmulti-layeredpreliminaryvisualsystemsofinsectsforloomingdetection,andtheproposedneuralmodelmimickinginsectphysiology:abbreviations
areP:photoreceptor,M:normalizedmotionunit,E:excitationunit,I:inhibitionunit,TD:timedelayunit,C:contrastunit,NL:non-linearunit,S:summationunit,G:grouping
unit. The visual neural systems consist of four layers of Retina, Lamina, Medulla, Lobula, simulated by the proposed neural model. The red/green pipelines indicate ON/OFF
motionpathwaysrespectively,andtheblueonesdenotecontrastpathways.WithinON/OFFchannels,inhibitionisobtainedbyconvolvingsurroundingdelayedexcitations,local
contrastisobtainedbyconvolvingsurroundingunitresponses.IntheLobulalayer,groupingcellconvolvessurroundingsummationunitresponses.Theloomingperceptionunit
atLobulaintegratesalllocalgroupedresponses.Theflowchartofonlyoneprocessingunitisshown.FormulationoftheproposedneuralmodeliselucidatedinSection3.(For
interpretationofthereferencestocolourinthisfigurelegend,thereaderisreferredtothewebversionofthisarticle.)
2.2. Contrastneuralcomputation For computationally implementing contrast neural computation in
motionsensitivevisualsystems,Fuetal.introducedflycontrastmech-
Biologicalvisualsystemscanperformkeysurvivaltasksincomplex, anisms and pathways for estimation of natural background motion;
dynamic environments, whereas artificial vision systems are far from themodeldemonstratedimprovedresponsecomparedtoneuralmodel
suchcapability.Visualcontrastissueiscriticaltobeaddressed[50,51]. processingonlymotionsignals[59].Lietal.incorporatedinasingle-
Somemechanismscanadapttonaturalsignalssuchastheprocessingof channel LGMD model the contrast neural computation, initially in-
environmentalstatistics[52,53].However,theissueofspatialcontrast dicated its effectiveness in looming detection [60]. Wang et al. also
hasnotbeenwellresolvedwhichalwaysresultsinresponsefluctuation showedeffectivenessofcontrastcomputationinasmalltargetmotion
againsthighlyvariableinput.Accordingly,newmethodsarerequested detectorpreventingfakedetection[61].Differentlytothoseworks,and
toaddresssuchaproblem. combiningthelatestphysiologicalresearch,thispaperpresentsanap-
Contrastcomputationisageneralmechanismforneuronstoprocess proachtoharmonizingmotionandcontrastvisionwithinfourparallel
signals[54,55],notonlyinvisual[29],butalsoinolfactory[56],and ON/OFFchannelsforloomingdetection.Themethodisvalidatedbya
auditory [57] nervous systems. Such circuit mechanism works effec- largedatasetofnaturalsignals.
tively to remove higher-order correlations from natural signals [30,
58]. In fact, there are a few prominent works in fly visual systems 3. Formulationoftheproposedneuralmodel
to demonstrate the efficacy of neural circuits implementing contrast
mechanisms. The authors reported evidence for a non-linear, divisive Based on anatomical knowledge and modelling experience of in-
normalization mechanism to deal instantly with local spatial contrast sectsâ€™ preliminary visual systems, the proposed neural model mimics
that emerges at an intermediate neuropil layer of preliminary visual multi-layered insect physiology shown in Fig. 1. We herein highlight
systems, i.e., the Medulla [30]. More precisely, the foreground signal thecoordinationofmotionandcontrastneuralcomputationinfourpar-
intensity of each Medulla inter-neuron is divided into a neighbouring allelON/OFFchannels.Theproposedmodelissystematicallydescribed
backgroundfieldbyspatiallyintegratingsurroundingfeedbacksignals, by diagrams and mathematical formulas, and it can respond robustly
thewholeprocessofwhichhappenspriortomotioncorrelation.This to looming objects in highly variable natural scenes. In general, it is
bio-plausible mechanism represents dynamic, non-linear properties in anorganizationalneuralnetworkcomposedofdifferenttypesofnerve
normalizationasabasisofsensorycircuitmechanism.Toconsolidate cellsplacedinfourcomputationalneuropillayers.
it,theauthorsalsocomparedwithfeed-forwardcontrastnormalization,
and linear, static normalization methods through training a batch of 3.1. Computationalretina
elementarymotiondetectors(EMD).Theinstantaneous,feedback,dy-
namiccontrastnormalizationcanfinallyfitbestwiththephysiological Retina layer comes from the compound eyes of insects, in which
data. Another research from Bahl et al. pointed out parallel contrast eachommatidiumconsistsofphotoreceptorsandindependentlycollect
pathwaysbeginningfromtheMedullaaffectmotionsignalsnegatively light signals in the field of vision. In this paper, a matrix of ğ‘Ÿ-rows
at the Lobula area [29]. Such contrast pathway behaves to attenuate andğ‘-columnsisusedtosimulatethearrangementofphotoreceptors,
high-contrastlocalmotionsignal. andeachvalueinthematrixrepresentstheintensityofopticalsignal
3Q.Fuetal. Array17(2023)100272
determines the baseline sensitivity. ğ‘ƒÌ‚ (ğ‘¥,ğ‘¦,ğ‘¡) can be obtained by
ğ‘œğ‘›âˆ•ğ‘œğ‘“ğ‘“
Gaussianconvolutionofsurroundingcellresponsesas
ğ‘ƒÌ‚ (ğ‘¥,ğ‘¦,ğ‘¡)= ğ‘ƒ (ğ‘¢,ğ‘£,ğ‘¡)ğº (ğ‘¥âˆ’ğ‘¢,ğ‘¦âˆ’ğ‘£)ğ‘‘ğ‘¢ğ‘‘ğ‘£ (5)
ğ‘œğ‘› âˆ¬ ğ‘œğ‘› ğœ
ğ‘ƒÌ‚ (ğ‘¥,ğ‘¦,ğ‘¡)= ğ‘ƒ (ğ‘¢,ğ‘£,ğ‘¡)ğº (ğ‘¥âˆ’ğ‘¢,ğ‘¦âˆ’ğ‘£)ğ‘‘ğ‘¢ğ‘‘ğ‘£ (6)
ğ‘œğ‘“ğ‘“ âˆ¬ ğ‘œğ‘“ğ‘“ ğœ
1 ğ‘¥2+ğ‘¦2
ğº (ğ‘¥,ğ‘¦)= exp(âˆ’ ) (7)
ğœ 2ğœ‹ğœ2 2ğœ2
Parallel ON/OFF contrast channels The second is the calculation of
Fig.2. Inputâ€“outputrelationshipsoflinear,staticanddynamiccontrastnormalization localspatialcontrastdeliveredbyON/OFFcontrastpathwaysparallel
models.Inthedynamicmodel,theoutputisaffectedbytheGaussiannormalizedfield,
to ON/OFF motion pathways. According to the fundamental research
while in the static and linear models, the relationship between input and output is
in [29], in the nerve centre of Drosophila, the calculation of contrast
fixed.
informationandmotioninformationarecarriedoutindifferentpaths.
Thatistosay,itwillnotbeaffectedbythemotioninformationwhen
collectedbytheeyelet.Theinputtotheproposedmodelisğ¿(ğ‘¥,ğ‘¦,ğ‘¡)âˆˆ calculating the contrast. Therefore, the normalized signal flow will
R3whereğ‘¥andğ‘¦representabscissaandordinateofthematrix,andğ‘¡is enteraparallelchannelspeciallyusedtocalculatethecontrastthrough
implementingneuralcompetitionbetweencentreandsurroundingunit
thetemporalpositionofthevisualstreams.Intheproposemodel,every
response.Thecalculationcanbeexpressedasthefollowing:
photoreceptorretrievespreliminarymotioninformationbycalculating
luminancechangeovertime: ğ¶ ğ‘œğ‘›(ğ‘¥,ğ‘¦,ğ‘¡)=|ğ‘€ ğ‘œğ‘›(ğ‘¥,ğ‘¦,ğ‘¡)
(8)
( )
ğ‘ƒ(ğ‘¥,ğ‘¦,ğ‘¡)= âˆ« ğ›¿(ğ‘¡âˆ’ğœ)âˆ’ğ›¿(ğ‘¡âˆ’ğ›¥ğ‘¡âˆ’ğœ) ğ¿(ğ‘¥,ğ‘¦,ğœ)ğ‘‘ğœ (1) âˆ’ âˆ¬ ğ‘€ ğ‘œğ‘›(ğ‘¢,ğ‘£,ğ‘¡)ğ¾ ğ‘(ğ‘¥âˆ’ğ‘¢,ğ‘¦âˆ’ğ‘£)ğ‘‘ğ‘¢ğ‘‘ğ‘£|
where ğ›¿ is the unit impulse function. Note that for digital signals we
ğ¶ ğ‘œğ‘“ğ‘“(ğ‘¥,ğ‘¦,ğ‘¡)=|ğ‘€ ğ‘œğ‘“ğ‘“(ğ‘¥,ğ‘¦,ğ‘¡)
(9)
process,thetimeisdiscrete. âˆ’
âˆ¬
ğ‘€ ğ‘œğ‘“ğ‘“(ğ‘¢,ğ‘£,ğ‘¡)ğ¾ ğ‘(ğ‘¥âˆ’ğ‘¢,ğ‘¦âˆ’ğ‘£)ğ‘‘ğ‘¢ğ‘‘ğ‘£|
3.2. Computationallamina The contrast kernel ğ¾ ğ‘ obeys to spatially uniform distribution. The
aforementioned two operations of contrast neural computation are
Laminalayerlocatesintheearlystageofinsectâ€™svisualinformation illustratedtogetherinFig.3.
processing. Notably, the photoreceptors of Retina synapse onto the
Parallel ON/OFF motion pathways The third part is the calculation
LaminaformthestartingnervecellsofON/OFFchannelsthroughoper-
of motion information in ON/OFF channels. To extract looming mo-
ationsbypolarityinter-neurons.Intheprocessoftransmission,visual
tion features, the model responds to continuously expansion of ONâ€“
signalsaredividedintotwopartstoenterON/OFFchannelsconnecting
ON/OFFâ€“OFF edges via spatialâ€“temporal interaction between excita-
differentnervecellsinnextMedullalayer.Thisshuntmechanismcan
tionandinhibitioncells.Thenormalizedinformation(Eq.(4))directly
becalculatedbyhalf-waverectificationasfollows:
formsvisualexcitementwithoutdelay.
ğ‘ƒ (ğ‘¥,ğ‘¦,ğ‘¡)=[ğ‘ƒ(ğ‘¥,ğ‘¦,ğ‘¡)]+, ğ‘ƒ (ğ‘¥,ğ‘¦,ğ‘¡)=âˆ’[ğ‘ƒ(ğ‘¥,ğ‘¦,ğ‘¡)]âˆ’ (2)
ğ‘œğ‘› ğ‘œğ‘“ğ‘“ ğ¸ (ğ‘¥,ğ‘¦,ğ‘¡)=ğ‘€ (ğ‘¥,ğ‘¦,ğ‘¡), ğ¸ (ğ‘¥,ğ‘¦,ğ‘¡)=ğ‘€ (ğ‘¥,ğ‘¦,ğ‘¡) (10)
ğ‘œğ‘› ğ‘œğ‘› ğ‘œğ‘“ğ‘“ ğ‘œğ‘“ğ‘“
where[ğ‘¥]+,[ğ‘¥]âˆ’ aredescribedmathematicallyas
The acquisition of visual inhibition requires the information flow to
[ğ‘¥]+=max(ğ‘¥,0), [ğ‘¥]âˆ’=min(ğ‘¥,0) (3) bedelayedwithacentreâ€“surroundantagonism.Therefore,thepolarity
inhibitioncanbecalculatedbythefollowingformulas
3.3. Computationalmedulla
ğ¼ (ğ‘¥,ğ‘¦,ğ‘¡)= ğ‘€ (ğ‘¢,ğ‘£,ğœ)ğ›¹(ğ‘¡âˆ’ğœ)ğ¾ (ğ‘¥âˆ’ğ‘¢,ğ‘¦âˆ’ğ‘£)ğ‘‘ğ‘¢ğ‘‘ğ‘£ğ‘‘ğœ (11)
ğ‘œğ‘› âˆ¬ ğ‘œğ‘› ğ¼
Medulla layer, located in the middle region of optic lobe, plays a
ğ¼ (ğ‘¥,ğ‘¦,ğ‘¡)= ğ‘€ (ğ‘¢,ğ‘£,ğœ)ğ›¹(ğ‘¡âˆ’ğœ)ğ¾ (ğ‘¥âˆ’ğ‘¢,ğ‘¦âˆ’ğ‘£)ğ‘‘ğ‘¢ğ‘‘ğ‘£ğ‘‘ğœ (12)
central role to coordinate motion and contrast vision in the proposed ğ‘œğ‘“ğ‘“ âˆ¬ ğ‘œğ‘“ğ‘“ ğ¼
neuralmodel.Thestainedmicro-graphoftheMedullalayershowsthat ğ¾ is the convolution kernel, which represents the local suppression
ğ¼
there is an obvious hierarchical structure in this layer, and various weight. The closer the inhibitory cells are to the excited cells, the
synapses extend into different fibre layers for signal transmission and strongertheinhibitoryeffectis.Thefarthertheinhibitorycellsarefrom
interaction(seeFig.1).Forimitatingthis,thecomputationalMedulla theexcitedcells,thesmallertheinhibitionweightis.Afterdiscretiza-
layerconsistsofthreepartsofneuralcomputation. tion,thekernelcanbedescribedinasimpleformas
Contrastnormalizationmechanism Firstly,thesignalsdeliveredbystart- 0.125 0.25 0.125
â¡ â¤
[ ]
ingnervecellsofON/OFFchannelswillundergoaninstantaneousnor- ğ¾ ğ¼ =â¢ 0.25 0 0.25 â¥ (13)
malizedfeedbackoperation,whichisthecontrastsuppressionmecha- â¢ â£ 0.125 0.25 0.125 â¥ â¦
nism. There are three forms of this mechanism, namely linear, static,
ğ›¹(ğ‘¡)isthetimedelayfunction.Asweprocessdigitalsignals,itisrep-
anddynamicnormalizationasshowninFig.2.Thesecanbeexpressed
resented by a first-order low-pass filtering to correlate two successive
bythefollowingformulas:
moments.
Linear:ğ‘€ (ğ‘¥,ğ‘¦,ğ‘¡)=ğ‘ƒ (ğ‘¥,ğ‘¦,ğ‘¡)
ğ‘œğ‘›âˆ•ğ‘œğ‘“ğ‘“ ğ‘œğ‘›âˆ•ğ‘œğ‘“ğ‘“ Localsummationofmotionandcontrastsignals Next,thepolaritysum-
ğ‘ƒ (ğ‘¥,ğ‘¦,ğ‘¡)
Static:ğ‘€ (ğ‘¥,ğ‘¦,ğ‘¡)=tanh( ğ‘œğ‘›âˆ•ğ‘œğ‘“ğ‘“ ) mationcellsintegratethesignalflowoftheabovethreeparts.Theex-
ğ‘œğ‘›âˆ•ğ‘œğ‘“ğ‘“ ğ›¼ 1 (4) citatoryandinhibitoryquantitiesofnervecellsarelinearlysummedto
ğ‘ƒ ğ‘œğ‘›âˆ•ğ‘œğ‘“ğ‘“(ğ‘¥,ğ‘¦,ğ‘¡) reflecttheremainingmotioninducedlocal-excitationasthefollowing
Dynamic:ğ‘€ (ğ‘¥,ğ‘¦,ğ‘¡)=tanh( )
ğ‘œğ‘›âˆ•ğ‘œğ‘“ğ‘“ ğ‘ƒÌ‚ (ğ‘¥,ğ‘¦,ğ‘¡)+ğ›¼ formulas:
ğ‘œğ‘›âˆ•ğ‘œğ‘“ğ‘“ 1
Notethatweapplythedynamicsuppressioninthisneuralmodelwhich ğ‘† (ğ‘¥,ğ‘¦,ğ‘¡)=ğ¸ (ğ‘¥,ğ‘¦,ğ‘¡)âˆ’ğ›½âˆ—ğ¼ (ğ‘¥,ğ‘¦,ğ‘¡) (14)
ğ‘œğ‘› ğ‘œğ‘› ğ‘œğ‘›
hasbeenverifiedtofitbestthephysiologicalresults[30,60].Hereğ‘¡ğ‘ğ‘›â„
operationindicatesthehyperbolictangentfunction.Thecoefficientğ›¼ ğ‘† (ğ‘¥,ğ‘¦,ğ‘¡)=ğ¸ (ğ‘¥,ğ‘¦,ğ‘¡)âˆ’ğ›½âˆ—ğ¼ (ğ‘¥,ğ‘¦,ğ‘¡) (15)
1 ğ‘œğ‘“ğ‘“ ğ‘œğ‘“ğ‘“ ğ‘œğ‘“ğ‘“
4Q.Fuetal. Array17(2023)100272
Fig. 3. (a) Diagram of instantaneous feedback normalization in ON/OFF channels. Contrast normalization is the feedback of the combination of partial medulla neurons. (b)
Illustrationofparallelmotionandcontrastcalculationandconvergence.Abbreviationsâ€˜Câ€™,â€˜Eâ€™,â€˜Iâ€™,â€˜TDâ€™andâ€˜HPâ€™areshorthandforcontrast,excitation,inhibition,timedelayand
high-passfiltering.
ğ›½istheinhibitionweightcoefficient,whichrepresentstheinfluenceof Table1
inhibitorycellsonexcitedcells.Then,becausethemotioninformation Theparametersofproposedneuralmodel.
ismixedwithalargeamountofcontrastinformationofnaturalscenes, Parameter Value Description
the motion channel needs to converge with the contrast channel (see ğ‘Ÿ,ğ‘ adaptable lengthandwidthoftheinputimage
Fig.3(b)).Atthetimeofconvergence,themotioninformationissub- ğ›¼ 1 3 baselinesensitivityvalueofcontrastnormalization
ğ›½ 0.4 weightcoefficientofinhibitionunit
tractedfromthecontrastinformationtoweakentheinfluenceofhigh-
ğœƒ,ğœƒ,ğœƒ 1,1,1 influencecoefficientofON/OFFchannels
contrastopticalflowonloomingdetection.Atthesametime,through 1 2 3
ğ¶ ğ‘¤ 4 aconstantusedtocalculateğ‘¤
half-waverectification,thenegative-signsignalswillbefilteredout. ğ›¥ ğ¶ 0.01 asmallrealnumberusedtopreventcalculationerrors.
ğ‘†Ì‚ ğ‘œğ‘›(ğ‘¥,ğ‘¦,ğ‘¡)=[ğ‘† ğ‘œğ‘›(ğ‘¥,ğ‘¦,ğ‘¡)âˆ’ğ¶ ğ‘œğ‘›(ğ‘¥,ğ‘¦,ğ‘¡)]+ (16) ğ‘‡ ğ›¼ 2ğ‘” 1 0. .4 1 t sh care lesh co ol ed ffo icf ieg nro tu ip nin sig gmm oe ic dha trn ais nm sformation
ğ‘†Ì‚ (ğ‘¥,ğ‘¦,ğ‘¡)=[ğ‘† (ğ‘¥,ğ‘¦,ğ‘¡)âˆ’ğ¶ (ğ‘¥,ğ‘¦,ğ‘¡)]+ (17)
ğ‘œğ‘“ğ‘“ ğ‘œğ‘“ğ‘“ ğ‘œğ‘“ğ‘“
3.4. ComputationalLobula âˆ’ğ‘˜(ğ‘¡)
ğ¾(ğ‘¡)=(1+exp( ))âˆ’1 (24)
ğ›¼ âˆ—ğ‘Ÿâˆ—ğ‘
2
Lobula layer is the last nerve layer of insect optic lobe (Fig. 1). It
whereğ›¼ isascaleparameterinsigmoidtransformation,tunedtoavoid
has a large number of motion sensitive neurons, which can quickly 2
capture the edge information of moving objects in the field of vision saturation problem of different sized signals. Therefore, the sigmoid
and respond to the target accordingly. After harmonizing motion and membranepotentialwithregardtotimeistheoutputoftheproposed
contrast features in the Medulla layer, the Lobula layer integrates neural model. Then it projects to different areas of insectâ€™s forebrain
polaritysignalsfromON/OFFchannelsattwolevels.Firstatthelocal throughaxons,soastocontroldifferentbehavioursofinsects.
level,excitationsareintegratedobeyingthesupra-linearrule.
ğ‘†(ğ‘¥,ğ‘¦,ğ‘¡)=ğœƒ âˆ—ğ‘†Ì‚ (ğ‘¥,ğ‘¦,ğ‘¡)+ğœƒ âˆ—ğ‘†Ì‚ (ğ‘¥,ğ‘¦,ğ‘¡) 3.5. Settingtheparameters
1 ğ‘œğ‘› 2 ğ‘œğ‘“ğ‘“
(18)
+ ğœƒ âˆ—ğ‘†Ì‚ (ğ‘¥,ğ‘¦,ğ‘¡)âˆ—ğ‘†Ì‚ (ğ‘¥,ğ‘¦,ğ‘¡)
3 ğ‘œğ‘› ğ‘œğ‘“ğ‘“ TheparametersoftheproposedneuralmodelaregiveninTable1.
Here, the combination of ğœƒ ,ğœƒ ,ğœƒ represents the influence coefficient As most parameters of motion pathways are adapted from previous
1 2 3
of each channel. After that, a grouping mechanism acts to enhance modellingworks[21,62],theonlyadaptableparametersaredepending
theextractionofloomingcues,alleviateeffectofdynamicbackground ontheresolutionofinputvisualstreams.Learningmethodisavoided
clutterandreduceisolatedexcitationbyconvolutionandthresholding inthisresearchasitisoutofthescopeofthisstudy.Thecomparison
processes,describedas between linear, static, and dynamic contrast normalization has been
taken in our preliminary research recently [60], whereby the result
ğ¶ (ğ‘¥,ğ‘¦,ğ‘¡)= ğ‘†(ğ‘¢,ğ‘£,ğ‘¡)ğ¾ (ğ‘¥âˆ’ğ‘¢,ğ‘¦âˆ’ğ‘£)ğ‘‘ğ‘¢ğ‘‘ğ‘£ (19)
ğ‘’ âˆ¬ ğ‘” coincideswiththephysiologicalstudywell.Thatistosay,thedynamic
contrastnormalizationaddressesthecontrastproblemwellincomplex,
ğœ”(ğ‘¡)=ğ›¥ ğ¶+max(|ğ¶ ğ‘’(ğ‘¥,ğ‘¦,ğ‘¡)|)âˆ—ğ¶ ğ‘¤âˆ’1 (20)
dynamic scenes. Another critical parameter of the baseline sensitivity
ğº(ğ‘¥,ğ‘¦,ğ‘¡)=ğ‘†(ğ‘¥,ğ‘¦,ğ‘¡)âˆ—ğ¶ğ‘’(ğ‘¥,ğ‘¦,ğ‘¡)âˆ—ğœ”(ğ‘¡)âˆ’1 (21) valueinEq.(4)willbeinvestigatedinourexperiments.Itisalsoworth
emphasizing the proposed model processes visual signals within four
ğºÌ‚(ğ‘¥,ğ‘¦,ğ‘¡)={ ğº(ğ‘¥,ğ‘¦,ğ‘¡) ifğº(ğ‘¥,ğ‘¦,ğ‘¡)â‰¥ğ‘‡ ğ‘” (22) ON/OFF channels, in a feed-forward neural network structure, which
0 otherwise is a novel form of coordinating motion and contrast vision compared
Concretely,apassingcoefficientmatrixğ¶ isobtainedbyaconvolution torelevantworksspecializinginloomingdetection.
ğ‘’
process with an equally weighted kernel ğ¾ . ğœ” is a scale parameter
ğ‘”
updatedateverytime.ğ¶ isaconstant,andğ›¥ standsforasmallreal 4. Experimentalevaluation
ğ‘¤ ğ¶
number.ğ‘‡ indicatesthethresholdingroupingmechanism.
ğ‘”
Finally, the looming sensitive neuron in the Lobula collects all Inthissection,wecarryoutsystematicexperimentstoevaluatethe
movement information and converts it into membrane potential. The proposed method for looming detection against high input variabil-
computationsareasfollows: ity of natural signals. The experiments are taken gradually by three
ğ‘Ÿ ğ‘ categories of tests. To highlight the improvement of this method, we
ğ‘˜(ğ‘¡)= âˆ« âˆ« ğºÌ‚(ğ‘¥,ğ‘¦,ğ‘¡)ğ‘‘ğ‘¥ğ‘‘ğ‘¦ (23) alsocomparetworelatedworks.Concretely,wefirstdemonstratebasic
1 1
5Q.Fuetal. Array17(2023)100272
are synthesized by computer, which represents simple scenes free of
noiseinordertodemonstratethebasiccharacteristicsofourproposed
neuralmodel.Thebackgroundsandtheforegroundlooming-squaresof
such kind of video sequences are solid colour pictures with different
grey values, whereby the foreground objects expand with respect to
time. The background grey value varies between minimum of 0 and
maximumof255,andthesamplingintervalistakenevery25between
0and255.Thesameistruefortheforegroundlooming-square.Some
samples of the video sequence used in the experiment are shown in
Fig.4.Specifically,inthefirstvideo,thebackgroundgreyvalueis0,
andtheforegroundgreyvalueis255;atthistime,thebackgroundand
foregroundformthemaximumcontrast.Thebackgroundgreyvalueof
thesecondvideois100,andtheforegroundgreyvalueis150;atthis
time, the contrast becomes smaller. Notably, we also set the scenario
with extremely low contrast, tiny difference between foreground and
background,thatis,thegreyvalueofthebackgroundis125,andthe
foreground is 130. In this kind of visual stimuli testing, the squares
loombetweenframe-17andframe-38,otherwiseremainstationary.All
inputvideoshavetheresolutionof600Ã—600atthesamplingfrequency
of30Hz.
Fig. 4. Samples of looming-square in clean-and-consistent background with different The second part is the test of complex scenarios. In this test, our
contrastbetweenthem.â€˜Bâ€™andâ€˜Fâ€™respectivelyrepresentthegreyvalueofbackground data set includes 1100 original videos. These videos are made based
andforegroundloomingsquares.Thestimuliofextremelylow-contrastloomingis on different realistic, wide-field scenes adapted with respect from a
depictedatbottom.
previous research [63]. More specifically, the indoor scenes include
libraries,shoppingmalls,etc.Theoutdoorscenesincludeforests,grass-
lands, villages, etc. Based on these panoramic scenes, we generate a
looming square with different grey values, similarly to the test in the
aforementionedsimplescenarios.Inaddition,inordertosimulatethe
visualstimulationofinsectsduringflight,wealsosetthebackground
to move to the right at a constant angular speed of 20 degrees per
second. The resolution of these videos is 926 Ã— 250 with the frame
rate30Hz.Everyforegroundloomingmotionstartsfromframe-20and
endsatframe-63.Ontheotherhand,thebackgroundshiftsrightward
from beginning to end. Some samples of video sequence used in the
experimentareshowninFig.5.
4.2. Metric
Duetotheuseofalargenumberofdatasamples,wecomparethe
experimentalresultsofvariousmodelsbycalculatingthedispersionof
thecoefficientofvariation(ğ‘‰ )withrespecttotime.Thecalculationis
ğ‘
asthefollowing:
ğœ(ğ‘¡)
ğ‘‰ (ğ‘¡)= (25)
Fig.5. Samplesfromthousandsloomingprocesseswithinavarietyofclutteredmoving ğ‘ ğœ‡(ğ‘¡)
scenes:thebackgroundshiftsrightwardataconstantspeedğ‘‰ ğ‘;theforegroundlooming
squaresvaryatgreyscales. Here, ğœ represents the standard deviationof the model output, andğœ‡
representsthemeanvalue;tindicatesthetimeposition.Thedispersion
degreeofthecoefficientofvariationismeasuredbytheinter-quartile
characteristics of the proposed neural model with emphasis laid on range(IQR)oftheviolindiagram.Moreprecisely,thedenserthedis-
performance in extremely low-contrast scenarios, and against various tributionofthecoefficientofvariation,thebetterthestatisticalresult
natural signals. After that, we show improvement based upon the is. The smaller the coefficient of variation, the better the statistical
incorporation of ON/OFF channels in looming detection. Lastly, as resultis.Therefore,wewouldpreferthedistributionofthecoefficient
thecontrastneuralcomputationisthemainnoveltyofthismodelling ofvariationconcentratedatthebottomoftheviolinplot.Inaddition,
research upon previous works, we look into the effects of dynamic intheviolinplot,thecoloureddotsrepresentthecalculatedcoefficients
normalizationmechanism,andON/OFFparallelcontrastpathwayson ofvariation.Theborderofviolin(greyline)showsthecorresponding
loomingdetectionagainsthighinputvariability. distributionofthecoefficientofvariation.Thegreenlineineachviolin
representsabox-plot,usedtocharacterizethedispersiondegreeofthe
4.1. Settingtheexperiments coefficientofvariation.
Wehavetheimplementationcodeanddatasetsusedinthispaper 4.3. Demonstrationofbasiccharacteristics
uploadedtothelinkbelow.2Thevisualstimuliusedinourexperiments
can be divided into two categories. Firstly, a set of visual streams Thissubsectionintroducesthefirsttypeofexperimentswithcom-
parison to two related works on the same testing data of both simple
andcomplexscenarios.
2 https://github.com/fuqinbing/harmonizing-motion-and-contrast-vision- AscanbeseenfromFig.6,themodelofHuetal.[36]cannotdetect
for-looming-detection loomingmotioninverylowcontrast(e.g.F125-B130)andtheoutput
6Q.Fuetal. Array17(2023)100272
Fig. 6. The experimental results of the proposed model, the model of Li et al. [60], and the model of Hu et al. [36] in pure scenes. â€˜Fâ€™ and â€˜Bâ€™ in the legend represent the
greyvaluesofforegroundandbackgroundrespectively.Theredandbluedashedlinesindicatetheground-truthtimewindowofloomingprocess.Comparedtothetwoprevious
methods,theproposedmodel(leftpanel)performsmoreconsistently,andcanrecognizeloomingmotionwithextremelylowcontrast.(Forinterpretationofthereferences
tocolourinthisfigurelegend,thereaderisreferredtothewebversionofthisarticle.)
Fig.7. Thestatisticalresponsesoftheproposedmodelandthecomparativemodelsagainstavarietyofnaturalsignals.Theredandbluedashedlinesindicatetheground-truth
timewindowofloomingprocess.Thegreensolidlinerepresentstheaverageoutputofthemodelwithrespecttotime,andthepurpleshadowrepresentsthecorrespondingstandard
deviation.Theproposedmodel(leftpanel)performsmorerobustlyagainsthighinputvariability.(Forinterpretationofthereferencestocolourinthisfigurelegend,the
readerisreferredtothewebversionofthisarticle.)
Secondly, Fig. 7 compares the statistical responses between the
proposed method and the two comparative models against natural
signals. From another perspective, Fig. 8 represents the dispersion of
the coefficient of variation for each tested model. It is clear that the
variationofourproposedmodelrelativetothemodelofHuetal.[36]
andthemodelofLietal.[60]ismuchlowerandthecoefficientdistri-
butionisdenserandsmaller.Inaddition,thecorrespondingbox-plots
have smaller inner spacing which indicates that our proposed model
is more robust against natural scenes with drastic contrast changes.
Importantly, we also solve the problem of high-frequency oscillations
ofresponsebetweenframe-55andframe-62observedinthemodelof
Lietal.[60]throughtheeffectivecoordinationofmotionandcontrast
neural computation in four separate ON/OFF channels. Our proposed
modelpeaksmoresmoothlytoloomingmotion,andismorerobustto
irrelevantbackgroundmovements.
Fig.8. Theviolindiagramofthestatisticalresults:ineachviolin,thecoloureddots
indicate the coefficient of variation. The contour of violin (grey solid line) indicates 4.4. ImprovementbaseduponON/OFFchannels
the distribution of coefficient of variation. The denser the distribution is, the more
prominent the contour is. The green in the middle of the violin represents the box This subsection continues the systematic experiments to highlight
plot of the coefficient of variation. The proposed model outperforms the two theimprovementsbasedonON/OFFchannelscoordinatingmotionand
comparativemodelsagainstloomingmotioninthousandsofdynamicscenes.(For
contrast vision for looming detection against natural signals. Differ-
interpretationofthereferencestocolourinthisfigurelegend,thereaderisreferred
ently to the previous type of tests, we add two extra sets of complex
tothewebversionofthisarticle.)
scenarios to the original 1100 ones by increasing and decreasing the
global illumination of background images with +20% and âˆ’20% on
grey levels respectively, thus generating a total of 2200 additional
of the model will be greatly affected by the contrast representing the
videosequences.Thesevideosequencesareusedtosimulatebrighter
largestvariancetothetesteddata.Bothofourproposedmodelandthe
and darker environments for insect navigation, as new inputs to the
modelofLietal.[60]areabletodetectloomingmotioninlow-contrast investigatedmodels.
environments.IncontrasttothemodelofLietal.[60],theoutputof TheresultsinFig.9demonstratethatdespiteincreaseanddecrease
ourproposedmodelismoreconsistentacrossdifferentcontrasts. of global background illumination, our proposed model is enhanced
7Q.Fuetal. Array17(2023)100272
Fig.9. Thestatisticalresultsoftheproposedmodelandthecomparativemodel[60]indifferentbackgroundilluminations:(a)themeanandstandarddeviationofthemodel
outputafterthebackgroundgreyvalueincreasedby20%.(b)theviolinplotsformedbythecoefficientofvariationcorrespondingto(a).(c)theresultsofbackgroundgreyvalue
reducedby20%.(d)thecorrespondingviolinfigureto(c).Theproposedmodelperformsmorerobustlyagainstincreaseanddecreaseofbackgroundilluminationwhich
peaksmoresmoothlytoloomingmotion.
significantly by incorporating the ON/OFF channels, in comparison indicate the efficacy of ON/OFF-channels, We calculate the average
withthemodelofLietal.[60]thatprocessesmotionandcontrastvi- greyvalueofallnaturalbackgroundsinourdataset,whichis122.The
sionregardlessofpolaritychanges,i.e.,ON-contrastandOFF-contrast. OFFcontrastpathwayisfirstlyclosed.Inthiscase,theforegroundgrey
Precisely,theproposedmodelpeaksmoresmoothlytoloomingmotions scalevaluesbetween0â€“100arelowerthantheaveragegreyscalevalue
in a large number of different natural scenes. The statistical results of the background. These looming-square motions are mainly han-
showtheproposedmodelhasmoredenselydistributedcoefficientsof dled by the OFF-rather than the ON-channels of the proposed model.
variationandsmallerinnerdistances.Thissuggeststhatourproposed Therefore, the effect of OFF contrast pathway can be demonstrated
modelisinvulnerabletoenvironmentalillumination. via the comparative experiments of switching OFF contrast channels.
The results in Fig. 11 reveal that when the OFF contrast pathway is
4.5. Investigationoncontrastneuralcomputation turnedoff,thedistributionofthecoefficientofvariationofthemodel
response for videos with a foreground between 0â€“100 has greater
Inthelastkindofexperiments,asthecontrastneuralcomputation
dispersion(largerinnerspacingofbox-plots)thanthecaseswithOFF
isthemainnoveltyofthismodellingresearch,andplayscrucialrolesin
contrastpathwayturnedon.Inaddition,thelargerthegreyvalueofthe
enhancingtherobustnessofloomingdetectionagainstnaturalsignals
foreground looming-square is (closer to the average background grey
of high input variability, we investigate two factors that lead the
valueof122),thegreaterthedispersionofthecoefficientofvariation
performanceimprovement.
is (showing an upward trend) (see the left panel in Fig. 11). That is
The first is the baseline sensitivity parameter of dynamic contrast
to say, when the contrast between the foreground and background is
normalization that open the gates for ON/OFF motion signals, i.e., ğ›¼
smaller,theeffectofOFFcontrastpathwayismoreobvious,consistent
in Eq. (4). We adopt three different values in the proposed model
toourpreviousresultsondealingwithlow-contrastloomingmotion.
tested by all the original 1100 natural data. The statistical responses
On the other hand, the ON contrast pathway is closed. The fore-
areshowninFig.10.Specifically,whenthebaselinesensitivityisvery
ground grey value between 150â€“255 is greater than the background
small (ğ›¼ = 0.5, the middle panel of Fig. 10), the looming-detecting
averagegreyvalueof122,sotheONcontrastpathwaymattersinthis
neural model is also activated by movements induced by the shifting
case.WhentheONcontrastpathwayisturnedon,thedispersionofthe
of natural background. Increasing the baseline sensitivity improves
themodelperformanceindicatingthedynamiccontrastnormalization coefficientofvariationofeachforegroundgreyvaluedoesnotchange
alsoworkseffectivelytosuppresstheclutteredbackgroundmovement. much (hardly affected by contrast changes). Nevertheless, when the
The model represents smaller fluctuations and variance of response ONcontrastpathwaysisturnedoff,thedispersionofthecoefficientof
to background movements. In addition, the model can maintain such variation begins to change more greatly. The larger the grey value of
robustperformanceevenincreasingtoarelativelylargervalue(ğ›¼=10, theforegroundlooming-squareis,i.e.,thegreaterthecontrastbetween
therightpanelofFig.10).Notethatinthepreviousexperiments,the thebackgroundandtheforegroundis,thesmallerthedispersionofthe
selected value of the baseline sensitivity is ğ›¼ = 3 (the left panel of coefficientofvariationis(thereisanoveralldownwardtrend)(seethe
Fig.10)whichcanachievethebestperformanceinourinvestigation. rightpanelinFig.11).Accordingly,similarlytotheresultsofclosing
ThesecondistheparallelON/OFFcontrastpathwaysthatneutralize merelytheOFFcontrastpathway,thesmallerthecontrastis,theeffect
strongexcitationsinducedbyhigh-contrast,localON/OFFmotion.To ofONcontrastpathwayismoreobvious.
8Q.Fuetal. Array17(2023)100272
Fig.10. Thestatisticalresponsesoftheproposedmodelundertheinvestigationonbaselinesensitivityofdynamiccontrastnormalization:threebaselinevaluesareappliedfor
investigation,respectively.
Fig.11. TheviolinplotsofexaminationonclosingeitherONorOFFcontrastpathwayinloomingdetectionagainstnaturalsignals:theğ‘‹-axisindicatesdifferentgreyvaluesof
foregroundlooming-squaresandtheğ‘Œ-axisindicatescoefficientofvariation.TheON/OFFcontrastpathwaysworkeffectivelytomaintaintherobustnessoftheproposed
modelfordetectionoflow-contrastloomingmotion.
5. Conclusionanddiscussion CRediTauthorshipcontributionstatement
Thispaperhaspresentedanovelwayofcoordinatingcontrastand QinbingFu:Conceptualization,Methodology,Writing,Validation.
motion vision to improve effectively the performance of looming de- ZhiqiangLi: Software, Visualization,Investigation,Data curation. Ji-
tectioninextremelylow-contrastscenarios,andagainstalargevariety genPeng:Supervision,Fundingacquisition,Projectadministration.
of natural signals. The proposed neural model features feed-forward
visualprocessinginastratifiedneuralnetworkwithfourbio-plausible
Declarationofcompetinginterest
parallel ON/OFF channels encoding polarity motion and contrast in-
formation separately. The contrast neural computation is the main
Noauthorassociatedwiththispaperhasdisclosedanypotentialor
novelty of this modelling research as it first works as an instant, dy-
pertinentconflictswhichmaybeperceivedtohaveimpendingconflict
namicnormalizationmechanismtoopenthegatesforON/OFFmotion
withthiswork.
signals. There are also ON/OFF contrast pathways to neutralize high-
contrastlocalON/OFFmotioninducedexcitations,inordertostabilize
modelresponseagainsthighinputvariabilityofnaturalscenes.Accord- Dataavailability
ingly,theproposedmodelperformsconsistentlyinhighlyvariable,and
various-contrastedscenes. Datawillbemadeavailableonrequest.
To corroborate the proposed method, we have crafted a new data
setconsistingofthousandsoflooming-squaremotionsinclutteredand Acknowledgements
dynamicbackgrounds.Tohighlightourachievements,thecomparative
experiments have been carried out. The results verify our proposed
This research has received funding from the National Natural Sci-
method is more robust for looming detection in natural scenes, espe-
ence Foundation of China under the Grant No. 12031003, and the
cially at extremely low contrast. Separating motion and contrast into
Social Science Fund of the Ministry of Education of China under the
ON/OFFchannelsworkseffectivelytoalleviatetheresponsefluctuation
GrantNo.22YJCZH032.
againstnaturalsignals,andmakethevisualsystempeakmoresmoothly
toloomingmotion.
References
For resolving real-world, complicated detection problems, recent
yearshavewitnessedmuchprogressbaseduponimageprocessingand
deep learning methods [64,65], as well as advanced sensor strate- [1] Franceschini N. Small brains, smart machines: From fly vision to robot vision
gies [66]. We insist another promising way is drawing lessons from andbackagain.ProcIEEE2014;102:751â€“81.
[2] Yamawaki Y. Defence behaviours of the praying mantis tenodera aridifolia in
neuroscience on how animals deal with similar situations. Insect in-
responsetoloomingobjects.JInsectPhysiol2011;57(11):1510â€“7.
telligence is featured by efficiency and parsimony that can offer a
[3] Tammero LF, Dickinson MH. Collision-avoidance and landing responses are
number of excellent paradigms to build artificial vision systems and
mediatedbyseparatepathwaysinthefruitfly,drosophilamelanogaster.JExp
neuromorphicsensors.Inthisregard,theproposedapproachisalsoof Biol2002;205:2785â€“98.
greatpotentialtobeutilizedinhardwareapplicationslikebio-inspired [4] Baird E, Kornfeldt T, Dacke M. Minimum viewing angle for visually guided
roboticsystems[67,68],andmicro/aerialroboticsystems[19,20]. groundspeedcontrolinbumblebees.JExpBiol2010;213(10):1625.
9Q.Fuetal. Array17(2023)100272
[5] YueS,RindFC.Acollisiondetectionsystemforamobilerobotinspiredbythe [31] MaussAS,VlasitsA,BorstA,FellerM.Visualcircuitsfordirectionselectivity.
locustvisualsystem.In:Proceedingsofthe2005IEEEinternationalconference AnnuRevNeurosci2017;40(1):211.
onroboticsandautomation.ICRA,IEEE;2005,p.3832â€“7. [32] BorstA,HaagJ,ReiffDF.Flymotionvision.AnnuRevNeurosci2010;33:49â€“70.
[6] Fu Q, Hu C, Liu T, Yue S. Collision selective LGMDs neuron models research [33] Borst A, Euler T. Seeing things in motion: Models, circuits, and mechanisms.
benefits from a vision-based autonomous micro robot. In: Proceedings of the Neuron2011;71(6):974â€“94.
2017IEEE/RSJinternationalconferenceonintelligentrobotsandsystems.IROS, [34] Borst A, Haag J, Mauss AS. How fly neurons compute the direction of visual
IEEE;2017,p.3996â€“4002. motion.J.CompPhysiolA2020;206:109â€“24.
[7] Cizek P, Faigl J. Self-supervised learning of the biologically-inspired obstacle [35] BorstA,HelmstaedterM.Commoncircuitdesigninflyandmammalianmotion
avoidanceofhexapodwalkingrobot.BioinspirBiomim2019;14(4):046002. vision.NatureNeurosci2015;18(8):1067â€“76.
[8] MildeMB,BlumH,DietmÃ¼llerA,SumislawskaD,ConradtJ,IndiveriG,etal. [36] Hu C, Arvin F, Xiong C, Yue S. Bio-inspired embedded vision system
Obstacle avoidance and target acquisition for robot navigation using a mixed for autonomous micro-robots: The LGMD case. IEEE Trans Cogn Dev Syst
signal analog/digital neuromorphic processing system. Front Neurorobotics 2017;9(3):241â€“54.
2017;11:1â€“17. [37] deCroonGCHE,DupeyrouxJJG,FullerSB,MarshallJAR.Insect-inspiredAIfor
[9] Salt L, Howard D, Indiveri G, Sandamirskaya Y. Parameter optimization autonomousrobots.ScienceRobotics2022;7(eabl6334):1â€“11.
and learning in a spiking neural network for UAV obstacle avoidance [38] Schnell B, Raghu SV, Nern A, Borst A. Columnar cells necessary for motion
targeting neuromorphic processors. IEEE Trans Neural Netw Learn Syst responses of wide-field visual interneurons in Drosophila. J Comp Physiol
2020;31(9):3305â€“18. 2012;198:389â€“95.
[10] ZhaoJ,MaX,FuQ,HuC,YueS.AnLGMDbasedcompetitivecollisionavoid- [39] Maisak MS, Haag J, Ammer G, Serbe E, Meier M, Leonhardt A, et al. A
ance strategy for UAV. In: Artificial intelligence applications and innovations. directional tuning map of drosophila elementary motion detectors. Nature
SpringerInternationalPublishing;2019,p.80â€“91. 2013;500(7461):212â€“6.
[11] Yue S, Rind FC, Keil MS, Cuadri J, Stafford R. A bio-inspired visual collision [40] Takemura S-y, Bharioke A, Lu Z, Nern A, Vitaladevuni S, Rivlin PK, et al. A
detectionmechanismforcars:Optimisationofamodelofalocustneurontoa visual motion detection circuit suggested by drosophila connectomics. Nature
novelenvironment.Neurocomputing2006;69(13â€“15):1591â€“8. 2013;500(7461):175â€“81.
[12] StaffordR,SanterRD,RindFC.Abio-inspiredvisualcollisiondetectionmech- [41] WeiH,KyungHY,KimPJ,DeswplanC.Thediversityoflobulaplatetangential
anism for cars: Combining insect inspired neurons to create a robust system. cells (LPTCs) in the drosophila motion vision system. J Comp Physiol A
Biosystems2007;87(2â€“3):164â€“71. 2019;1â€“10.http://dx.doi.org/10.1007/s00359-019-01380-y.
[13] Krejan A, Trost A. LGMD-based bio-inspired algorithm for detecting risk of [42] RuffierF,FranceschiniN.Opticflowregulation:Thekeytoaircraftautomatic
collisionofaroadvehicle.In:Proceedingsofthe2011IEEE7thinternational guidance.RobotAutonSyst2005;50(4):177â€“94.
symposiumonimageandsignalprocessingandanalysis.IEEE;2011,p.319â€“24. [43] RindFC,SimmonsPJ.Localcircuitforthecomputationofobjectapproachby
anidentifiedvisualneuroninthelocust.JCompNeurol1998;395(3):405â€“15.
[14] HartbauerM.Simplifiedbionicsolutions:Asimplebio-inspiredvehiclecollision
[44] Rind FC, Simmons PJ. Seeing what is coming: Building collision-sensitive
detectionsystem.BioinspirBiomim2017;12(2):026007.
neurones.TrendsNeurosci1999;22(5):215â€“20.
[15] Reich GM, Antoniou M, Baker C. Memory-enhanced cognitive radar for
[45] Simmons PJ, Rind FC. Responses to object approach by a wide field visual
autonomousnavigation.IETRadarSonarNavig2020;14(9):1287â€“96.
neurone, the LGMD2 of the locust: Characterization and image cues. J Com
[16] Arvin F, Samsudin K, Ramli AR. Development of IR-based short-range com-
Physiol-[A]1997;180(3):203â€“14.
munication techniques for swarm robot applications. Adv Electr Comput Eng
[46] Rind FC, Wernitznig S, Polt P, Zankel A, Gutl D, Sztarker J, et al. Two
2010;10(4):61â€“8.
identifiedloomingdetectorsinthelocust:Ubiquitouslateralconnectionsamong
[17] EverettH.Sensorsformobilerobots:Theoryandapplication.Taylor&Francis;
their inputs contribute to selective responses to looming objects. Sci Rep
1995.
2016;6:35525.
[18] MukhtarA,XiaL,TangTB.Vehicledetectiontechniquesforcollisionavoidance
[47] Klapoetke NC, Nern A, Peek MY, Rogers EM, Breads P, Rubin GM, et
systems: A review. IEEE Trans Intell Transp Syst 2015;16(5):2318â€“38. http:
al. Ultra-selective looming detection from radial motion opponency. Nature
//dx.doi.org/10.1109/TITS.2015.2409109.
2017;551:237â€“41.
[19] Serres JR, Ruffier F. Optic flow-based collision-free strategies: From insects to
[48] ZhouB,LiZ,KimSSY,LaffertyJ,ClarkDA.Shallowneuralnetworkstrainedto
robots.ArthropodStructDev2017;46(5):703â€“17.
detectcollisionsrecoverfeaturesofvisualloom-selectiveneurons.ELife2022.
[20] Fu Q, Wang H, Hu C, Yue S. Towards computational models and appli-
[49] HuaM,FuQ,PengJ,YueS,LuanH.Shapingtheultra-selectivityofalooming
cations of insect visual systems for motion perception: A review. Artif Life
detectionneuralnetworkfromnon-linearcorrelationofradialmotion.In:IEEE
2019;25(3):263â€“311.
theinternationaljointconferenceonneuralnetworks.2022.
[21] Fu Q, Hu C, Peng J, Yue S. Shaping the collision selectivity in a looming
[50] Geisler WS. Visual perception and the statistical properties of natural scenes.
sensitiveneuronmodelwithparallelONandOFFpathwaysandspikefrequency
AnnuRevPsychol2008;59:167â€“92.
adaptation. Neural Netw 2018;106:127â€“43. http://dx.doi.org/10.1016/j.neunet.
[51] Rieke F, Rudd ME. The challenges natural images pose for visual adaptation.
2018.04.001.
Neuron2009;64(5):605â€“16.
[22] Fu Q, Hu C, Liu P, Yue S. Towards computational models of insect motion [52] Fitzgerald JE, Clark DA. Nonlinear circuits for naturalistic visual motion
detectorsforrobotvision.In:Towardsautonomousroboticsystemsconference. estimation.Elife2015;4:e09123.
2018,p.465â€“7. [53] ClarkDA,FitzgeraldJE,AlesJM,GohlDM,SiliesMA,NorciaAM,etal.Fliesand
[23] Fu Q, Hu C, Peng J, Rind FC, Yue S. A robust collision perception visual humansshareamotionestimationstrategythatexploitsnaturalscenestatistics.
neural network with specific selectivity to darker objects. IEEE Trans Cybern NatureNeurosci2014;17(2):296â€“303.
2019;5(12):5074â€“88.http://dx.doi.org/10.1109/TCYB.2019.2946090. [54] CarandiniM,HeegerDJ.Normalizationasacanonicalneuralcomputation.Nat
[24] Ruffier F, Viollet S, Franceschini N. OSCAR and OCTAVE: Two bio-inspired RevNeurosci2011;13:51â€“62.
visually guided aerial micro-robots. In: Proceedings of the 11th international [55] HeegerDJ.Normalizationofcellresponsesincatstriatecortex.VisualNeurosci
conferenceonadvancedrobotics.IEEE;2003,p.726â€“32. 1992;9:181â€“97.
[25] Franceschini N, Ruffier F, Serres J. Insect inspired autopilots. J Aero Aqua [56] OlsenSR,BhandawatV,WilsonRI.Divisivenormalizationinolfactorypopulation
Bio-Mech2010;1(1):2â€“10. codes.Neuron2010;66:287â€“99.
[26] Ruffier F, Franceschini N. Optic flow regulation in unsteady environments: A [57] RabinowitzNC,WillmoreBDB,SchnuppJWH,KingAJ.Contrastgaincontrolin
tethered MAV achieves terrain following and targeted landing over a moving auditorycortex.Neuron2011;70(6):1178â€“91.
platform.JIntellRobotSyst2015;79(2):275â€“93. [58] Barnett PD, Nordstrom K, Oâ€™Carroll DC. Motion adaptation and the velocity
[27] FloreanoD,Pericet-CamaraR,ViolletS,RuffierF,BrucknerA,LeitelR,etal. codingofnaturalscenes.CurrBiol2010;20:994â€“9.
Miniaturecurvedartificialcompoundeyes.ProcNatlAcadSci2013;110(23). [59] FuQ,YueS.Bioinspiredcontrastvisioncomputationforrobustmotionestima-
[28] Salazar-GatzimasE,ChenJ,CreamerM,ManoO,MandelH,MatulisC,etal. tionagainstnaturalsignals.In:IEEEtheinternationaljointconferenceonneural
Direct measurement of correlation responses in drosophila elementary motion networks.2021.
detectorsrevealsfasttimescaletuning.Neuron2016;92(1):227â€“39. [60] LiZ,FuQ,LiH,YueS,PengJ.Dynamicsignalsuppressionincreasesthefidelity
[29] BahlA,SerbeE,MeierM,AmmerG,BorstA.Neuralmechanismsfordrosophila ofloomingperceptionagainstinputvariability.In:IEEEtheinternationaljoint
contrastvision.Neuron2015;88:1240â€“52. conferenceonneuralnetworks.2022.
[30] DrewsMS,LeonhardtA,PirogovaN,RichterFG,SchuetzenbergerA,BraunL, [61] WangH,PengJ,ZhengX,YueS.Arobustvisualsystemforsmalltargetmotion
et al. Dynamic signal compression for robust motion vision in flies. Curr Biol detectionagainstclutteredmovingbackgrounds.IEEETransNeuralNetwLearn
2020;30:209â€“21. Syst2020;31(3):839â€“53.
10Q.Fuetal. Array17(2023)100272
[62] YueS,RindFC.CollisiondetectionincomplexdynamicscenesusinganLGMD- [65] Cha Y-J, Choi W. Deep learning-based crack damage detection using convolu-
basedvisualneuralnetworkwithfeatureenhancement.IEEETransNeuralNetw tionalneuralnetworks.Comput-AidedCivInfrastructEng2017;32:361â€“78.
2006;17(3):705â€“16. [66] Gallego G, Delbruck T, Orchard G, Bartolozzi C, Taba B, Censi A, et al.
[63] BrinkworthRSA,Oâ€™CarrollDC.Robustmodelsforopticflowcodinginnatural Event-basedvision:Asurvey.IEEETransPatternAnalMachIntell2020.
scenesinspiredbyinsectbiology.PLoSComputBiol2009;5(11). [67] Liu P, Huda MN, Sun L, Yu H. A survey on underactuated robotic systems:
[64] Cha Y-J, Choi W, Suh G, Mahmoudkhani S. Autonomous structural visual Bio-inspiration,trajectoryplanningandcontrol.Mechatronics2020;72:102443.
Inspection Using Region-based deep learning for detecting multiple damage [68] LiuP,NeumannG,FuQ,PearsonS,YuH.Energy-efficientdesignandcontrol
types.Comput-AidedCivInfrastructEng2018;33:731â€“47. of a vibro-driven robot. In: Proceedings of the 2018 IEEE/RSJ international
conferenceonintelligentrobotsandsystems.IROS,IEEE;2018,p.1464â€“9.
11