ArtificialIntelligenceinAgriculture6(2022)23–33
ContentslistsavailableatScienceDirect
Artificial Intelligence in Agriculture
journal homepage: http://www.keaipublishing.com/en/journals/artificial-
intelligence-in-agriculture/
Transfer Learning for Multi-Crop Leaf Disease Image Classification using
Convolutional Neural Network VGG
⁎
AnandaS.Paymode ,VandanaB.Malode
MGM'sJawaharlalNehruEngineeringCollege,Aurangabad431001,Maharashtra,India
a r t i c l e i n f o a b s t r a c t
Articlehistory: Inrecenttimes,theuseofartificialintelligence(AI)inagriculturehasbecomethemostimportant.Thetechnol-
Received9October2021 ogyadoptioninagricultureifcreativelyapproached.Controllingonthediseasedleavesduringthegrowingstages
Receivedinrevisedform8December2021 ofcropsisacrucialstep.Thediseasedetection,classification,andanalysisofdiseasedleavesatanearlystage,as
Accepted30December2021 wellaspossiblesolutions,arealwayshelpfulinagriculturalprogress.Thediseasedetectionandclassificationof
Availableonline7January2022
differentcrops,especiallytomatoesandgrapes,isamajoremphasisofourproposedresearch.Theimportantob-
jectiveistoforecastthesortofillnessthatwouldaffectgrapesandtomatoleavesatanearlystage.The
Keywords:
ConvolutionalNeuralNetwork(CNN)methodsareusedfordetectingMulti-CropsLeafDisease(MCLD).Thefea-
ConvolutionalNeuralNetwork(CNN)
ArtificialIntelligence(AI) turesextractionofimagesusingadeeplearning-basedmodelclassifiedthesickandhealthyleaves.TheCNN
VisualGeometryGroup(VGG) basedVisualGeometryGroup(VGG)modelisusedforimprovedperformancemeasures.Thecropsleavesimages
Multi-CropsLeafDisease(MCLD) datasetisconsideredfortrainingandtestingthemodel.Theperformancemeasureparameters,i.e.,accuracy,sen-
sitivity,specificityprecision,recallandF1-scorewerecalculatedandmonitored.Themainobjectiveofresearch
withtheproposedmodelistomakeon-goingimprovementsintheperformance.Thedesignedmodelclassifies
disease-affectedleaveswithgreateraccuracy.Intheexperimentproposedresearchhasachievedanaccuracyof
98.40%ofgrapesand95.71%oftomatoes.Theproposedresearchdirectlysupportsincreasingfoodproductionin
agriculture.
©2022TheAuthors.PublishingservicesbyElsevierB.V.onbehalfofKeAiCommunicationsCo.,Ltd.Thisisanopen
accessarticleundertheCCBY-NC-NDlicense(http://creativecommons.org/licenses/by-nc-nd/4.0/).
1.Introduction result, finding a quick, efficient, least inexpensive, and effective
approach to determine crops diseases instances is quite important
Tocontributetothedevelopmentofnations,knowledgeofagricul- (C.J.Chenetal.,2021).
turesectorsiscrucial.Agricultureisaone-of-a-kindsourceofwealth Artificialintelligence(AI)providesconsiderableassistancetoagri-
thatdevelopsfarmers.Forastrongcountry,thedevelopmentoffarming culture, which enhances a nation's gross domestic product (GDP)
isanecessityandaneedintheglobalmarket.Theworld’spopulationis mostlythroughthissector.Climatechange,labourscarcity,rainyseason
growingatanexponentialrate,necessitatingmassivefoodproduction uncertainty,naturaldisasters,andvariousdiseasesonplantleavesare
inthenext50years.Informationaboutdifferenttypesofcropsanddis- allmajorissuesinagriculture.Theplantleavesrecognitionanddetec-
easesoccurringateachlevelanditsanalysisatanearlystageplayakey tionstudieswithedgeintelligenceappliedtoagriculture.Thereisa
anddynamicroleintheagriculturesector.Afarmer'smainproblemis newadvancementwithdifferentdeeplearningmodelsthatovercomes
theoccurrenceofvariousdiseasesontheircrops.Thediseaseclassifica- thechallenge.TheYOLOv3neuralnetworkmodelisbasedondeep
tionandanalysisofillnessesisacrucialconcernforagriculture's learningandisbuiltonanembeddedsystemandtheNVIDIAJetson
optimumfoodyield.Foodsafetyisahugeissueduetoalackofinfra- TX2.Thesystemisimplementedonadrone,andphotographsofplants
structure and technology, so crop disease classification and identi- aretaken,pestpositionsareidentified,andpesticidesareappliedas
fication areimportanttobeconsideredin thecomingdays.Thisis needed;this is a novel approach based on deep learning (Al Hiary
necessaryforyieldestimation,foodsecurity,anddiseasemanagement. etal.,2011).
Detectionandrecognitionofcropsillnessesisanimportantstudytopic Hyperspectralandmultispectralknowledgeacquisitiontechniques
becauseitcouldbecapableofmonitoringhugefieldsofcropsandde- andapplicationshaveexhibitedtheirutilityinimprovingagricultural
tectingdiseasesymptomsassoonastheyoccuronplantleaves.Asa productionandpractisesbyprovidingfarmersandagriculturalmanage-
mentwithcrucialdataontheelementsimpactingcropconditionand
⁎ Correspondingauthor. growth.Thistechnologyhasbeenwidelyemployedinavarietyofagri-
E-mailaddresses:anandpaymode@gmail.com(A.S.Paymode), culturalapplications,includingsustainableagriculture(Ang,2021).
vandanamalode@jnec.ac.in(V.B.Malode).
https://doi.org/10.1016/j.aiia.2021.12.002
2589-7217/©2022TheAuthors.PublishingservicesbyElsevierB.V.onbehalfofKeAiCommunicationsCo.,Ltd.ThisisanopenaccessarticleundertheCCBY-NC-NDlicense(http://
creativecommons.org/licenses/by-nc-nd/4.0/).A.S.PaymodeandV.B.Malode ArtificialIntelligenceinAgriculture6(2022)23–33
Weeddetectioninvegetableplantationsismoredifficultthanincrop 2.Material&methods
plantationsduetounevenplantspacing.DeepLearningtechnologyis
anovelmethodthatblendswithimageprocessing.Thisapproachcon- 2.1.Datasets
centratessolelyonrecognisingplants,avoidingthehandlingofnumer-
ousplantspecies.Furthermore,byreducingtheamountoftraining Tosupportourresearchintheareaofcollectionofimagesavailable
imagecollectionandeventhecomplexityofweeddetection,thistech- from Pennsylvania state university named plantvillage dataset. The
niquecanimproveplantdiagnosisaccuracyandperformance(Jinetal., datasetplant-villageincluded152cropsolutions,38cropclasses,and
2021). 19cropcategories,for54,303cropleavesimages.Inthedatasets,high
Themassivecroplossoccurredbecauseofthefailuretopredictdis- qualityJPEGimageformatwith5471widthand3648heightpixelsare
easeatanearlystage,whichalwaysresultsinlowercropproduction.As available. In the pre-processing, de-nosing, segmentation and after
aresult,identifyingandanalysingcropdiseasesisacriticalstepinen- imagesare256X256pixels(Gandhietal.,2018).Theplantvillageisa
suringcropquality(Wu,2020).Ashighcomputingspeedandpower well-knowndatasetforcropdisease,withalargenumberofpublic
haverecentlyimproved,theavailabilityofmassivedatasetsimproves datasetsavailable.Aplantvillagedatasetimageswerecapturedinthe
thesystem'sefficiency. lab,thustheyareusedastrainingdatasets.Ourmodeltestedonreal
Inthissection,therearevarioustechniquesfordetectingandclassi- fieldcapturedimages,Asaresult,wemustconcentrateondeveloping
fyingcropleafdisease.Wepresenttherelatedsurveyasasystemthat ourownfielddatabase.Thetestimageswerecapturedwithaseparate
employsavarietyofclassifiertechniques.Therearetwotypesofcombi- Megapixelcameraandstoredinadatabase.Thedatasetspreparedin
nations:serialandhybrid,withthecombinationofserialandparallel thefieldareavailableandbeusedintheproposedresearch.Theagro-
achievingthesignificantperformanceparameterwithin600images deepmobileapplicationwasusedtocapturesomeon-fieldcropsimages.
(Massietal.,2020).Thehybridcombinationhasarecognitionrateof ThefieldphotographsweretakenwiththeredmiNote5ProMIUI
91.11%,whichishigherthantheserial,parallel,anddeeplearningap- Global11.0.5.0(PRIMEXM),AndroidVersionPKQ1.180904.001,anda
proaches.Foridentifyingandanalyzingleafillness,adeeplearning cameraframe4:3highpicturequalityon16MP+5MPwithf/2.2aper-
convolutionalneuralnetwork(CNN)modelwasusedtoclassifyhealthy turepixel,inavarietyofnaturalenvironments.Thedisease-affectedand
andsickimages.Themodeltraincontained25differentplants,58clas- healthyphotosarethemostcommonimagecategoriescollectedforre-
ses’sets,includinghealthyanddiseasedplants,andhad87,848images. searchpurposes.Healthyspotcontaminated,mosaicvirus,yellowleaf
Usingseveral(Ferentinos,2018)modelarchitectures,thebestperfor- curlvirus,septorialeafspotbacterialspot,earlyblight,lateblight,leaf
mancesuccessratewas97.53%.TheMulti-ContextFusionNetwork mould,septorialeafspot,andspidermitesareexamplesoftomato
(MCFN),adeeplearning-basedmethod,isbuiltandpreparedforcrop imagery.
diseasedetection.TheMCFNaidsintheextractionofvisualinformation
from50,000cropphotos.TheMCFNproduced77commoncropsin- 2.2.Proposedresearch
fectedusingadeepfusionmodel,witha97.50%identificationaccuracy
(Jinetal.,2021). TheschematicinFig1depictsapotentialviewformulti-cropleaf
TheidentificationofweedsincropsusingtheCovNetalgorithmis diseaseclassificationandanalysis.Initially,plantleafdiseaseimages
alsoapotentandcutting-edgeapproach.Inrecentresearch,bounding are collected and classified into several categories. Picture filtering,
boxesweredrawnacrosscroppedimagesandthemodelwastrained. greytransformation,picturesharpening,andscalingaresomeofthe
Colour-basedsegmentationsareappliedtoimagesandcolourinforma- image-processingtechniques.Byusingdataaugmentationmethods,
tion,andvisualcategorizationiscalculatedforweedimages.Thecolour newsamplephotosarecreatedfromavailablephotostoenhanceand
indexwasexaminedwithageneticalgorithmandBayesiancategoriza- preparethedataset.Augmentationproceduresliketurning,translation,
tion(Jinetal.,2021).Thedeepresidualnetworkandthedeepdense andrandomizedtransformationareemployedtoenhancethesizeof
networkarecombinedinthehybriddeeplearningmodel.Thehybrid thedataset.Thephotosarethenusedasinputtothesuggestedapproach
deeplearningmodelreducestrainingparameterswhileincreasingac- fortrainingthemodelinthefollowingstage.Thenewlytrainedarchitec-
curacybyupto95.00%(Zhouetal.,2021). turalmodelisusedtoanticipatepreviouslyunseenimages.Eventually,
Deeptransferlearningisanamazingperformancemethodology thefindingsofplantdiseasedetectionandidentificationareachieved.
foridentifyingplantdiseases.Forpre-traineddatasets,Inception Finally,completedetailsofthesestepsaredepictedinlaterparts(Table1).
andImageNetmoduleswereutilized(Chenetal.,2020).Theperfor-
manceofpepper,vegetable,potato,andtomatoleafimagesinthe 2.3.Sampleimagescategory
plantvillagedatabasewasstudiedandenhancedusingsupportvec-
tormachine(SVM)andmulti-layerperceptron.Aftertrainingthe ThesampleimagesofcropsshowninFig.2depictthecategoryof
modelthesystemachievesahigherperformanceaccuracyof94.35 field’stomatoleafimagesofvariousdiseaseandhealthyclasses.Theim-
%(Kurmietal.,2020). agesareone-of-a-kindforeachtypeofdiseasesymptom,pattern,spot,
Todetectandrecognizecorndietarysickness,aDeepConvolutional andcolourmark.Specifictomatoplantleafdiseasessuchasbacterial
NeuralNetworkwasdeployed.,Therecognitionofcornleafdiseasedac- wilt,leafmold,andgreyspotsareidentifiedanddetectedasdiseaseim-
curacywas88.46%,andtheusageofhardware,suchasaraspberrypi3 pactedrecognitiontraits(Paymodeetal.,2020).
withanIntelMovidiusNeuralComputeStickandasystemGPUthat Fig.3depictsfieldimagesofgrapevineleavesobtainedintheNashik
pre-trainedtheCNNModel,resultedinsuperiormetricaccuracyperfor- districtofMaharashtra,India.Agrapecategory,Healthy423,BlackRot
mance(Sunetal.,2020). 1180,BlackMeasles1383andLeafBlight1076imageswererecorded,
Withtherapidgrowthofartificialintelligenceanddeeplearn- recognized,andcaptured.Thedatasetsforgrapeplantleavesweregen-
ingtechnology,computervision(CV)madeabreakthrough.The eratedbyadjustingthebrightnessandhueofimagesfromtheAtoD
CV-basedapproachesarecommonlyutilizedfordiagnosinggrape category(SeeFigs.4-5).
leafdiseases.Theprinciplecomponentanalysis(PCA)andback ThesecondcropoftomatoessampledEarlyblight1000,Mosaicvirus
propagationmethodsaidinthediagnosisofgrapediseasessuch 373,Bacterialspot2127,Lateblight1909,Leafmould952,Septorialeaf
asdownymildewandpowderymildew,witharesearchaccuracy spot1771,1404spot,spidermites1676andYellowleafcurl3209.The
of94.29%(Xieetal.,2020),usingVGGNet.Theweightsareinitial- deeplearningbasedmethodsarestate-of-the-artincomputervision,
izedusingImageNetpre-traineddatasets,andoverthroughthe whichisusedinimagerecognitionandclassification.Ingeneral,datasetcol-
real-worlddataset,suchapproacheshadavalidationaccuracyof lecting,datapre-processing,imagesegmentation,featureextraction,and
91.83%. classificationarethefourstagesofArtificialIntelligence(AI)inagriculture
24A.S.PaymodeandV.B.Malode ArtificialIntelligenceinAgriculture6(2022)23–33
Fig1.Proposedresearchsystemflowdiagram.
approaches for crop leaf disease detection and classification utilising aresult,dataaugmentationbroadenstherangeoftrainingdataavailable
ConvolutionalNeuralNetwork(CNN).AGoogleColaboratoryplatform todeeplearningmodels.Deeplearning-basedaugmentationapproaches
wasusedtopre-processtheimage,extractionoffeatures,andclassifyit. includeimageflipping,cropping,rotation,colourtransformation,PCA
colouraugmentation,noiserejection,GenerativeAdversarialNetworks
2.4.Imageaugmentation (GANs),andNeuralStyleTransfer(NST)(ArunPandianetal.,2019).The
FasterDR-IACNNapproachfordetectinggrapeleafdiseasesisbasedon
Thelargenumberofdatasetsimprovesthelearningalgorithms'perfor- deeplearning.Theautomaticextractionofspotsonleaveshasahighde-
manceandpreventsoverfitting.Obtainingareal-timedatasetforuseas tectionspeedandaccuracy.Thereare4449originalphotographsand
inputtoatrainingmodelisacomplexandtime-consumingoperation.As 62,286photosdevelopedusingdataaugmentationtechniques.
Table1
Astudyofdeeplearningtechniqueswithclassificationandrecognitionrate(SeeFig.12).
Approach Classification Model Recognitionrate(%)
HybridCombination(Massietal.,2020) ThreeSVM SVM 91.11
DeepLearning(Ferentinos,2018) CNN VGG 97.53
Multi-ContextFusionNetwork(MCFN)(Wu,2020) CNN AlexNet&VGG16 97.50
DeepTransferLearning(DTL)(Chenetal.,2020) CNN VGG 91.83
MachineLearning(Kurmietal.,2020) SVM MLP 94.35
DeepLearning(Sunetal.,2020) DCNN DCNN 88.46
DeepLearning(Xieetal.,2020) FasterDR-IACNN Inception-v1ResNet-v2 81.11
25A.S.PaymodeandV.B.Malode ArtificialIntelligenceinAgriculture6(2022)23–33
Fig2.Sampletomatoleafimages(A:MosaicVirus,B:Healthy,C:TargetSpot,D:LateBlight,E:BacterialSpot,F:SeptoriaSpot,G:SpiderMite,H:LeafMold,I:EarlyBlight,J:YellowLeaf.
Theimagesareconvertedintoavectoroffixedfeaturesthroughfea- 3.1.1.Convolutionallayer
tureextractioninsegmentation.Thecolor,texture,andshapearethe Convolutionallayers'fundamentalfunctionistoextractuniquefea-
system-adoptedfeatures.Ameans,confidenceintervals,andsleekness turesfromimages.Theimplementationofconvolutionallayersona
have been employed as colored methods, with HSV and RGB color normalbasisfacilitatestheextractionofinputfeatures(Chenetal.,
spacesbeingretrieved.Thegray-levelco-occurrencematrixispreferred 2020),Thefeaturesextraction(Hi)amongseverallayersinCNNiscom-
whenextractingtexturefeaturesfromacolourimage.Thisapproachis putedusingtheformulabelow.
usedtoidentifyplantdiseases.
2.5.Transferlearning
H i¼φðH i−1W iþb iÞ ð1Þ
The model's optimization and training is a tough and time- Where,Hi-Featuremap,Wi–Weight,biisoffsetandφ–RectifiedLin-
consumingoperation.Apowerfulgraphicalprocessingunit(GPU) earUnit(RELU)
isrequiredforthetraining,aswellasmillionsoftrainingexamples.
However,transferlearning,whichisemployedindeeplearning, 3.1.2.Poolinglayers
solvesalloftheproblems.Thepre-trainedConvolutionalNeural ThepoolinglayersareacrucialcomponentofaConvolutionalNeural
Network(CNN)usedintransferlearningisoptimizedforonetask Network(CNN).Itshrinksthesizeofconvolvedfeaturesindimension
and transfers knowledge to different modes (Nevavuori et al., whilesimultaneouslyminimizingthecomputationalresourcesneces-
2019). The multi-crop image dataset model comprises a size of saryforimageprocessing.Poolingarisecategorizedintotwotypes:
224X224.Theresidualnetwork(ResNet)neededtobetweaked. maxpoolingandaveragepooling.Maxpoolingreturnsthemaximum
InallResNetmodels,thefinallayerbeforethesoftmaxisa7X7 valueofimages,whereasanaveragepoolingreturnstheaveragevalue
average-pooling layer. A smaller image can fit into the network oftheimagesection.
whenthepoolingsizedecreases.Thebasicpicturepreparationis
necessaryforthetransferlearningconsiderationswiththemulti- 3.1.3.Drop-outlayers
croppedimagedataset. Thedropoutlayersimprovethecapabilityofatrainedmodel.Itpro-
videsregularizationandpreventsthemodelfromover-fittingbyde-
3.Results&discussion creasingthecorrelationbetweentheneurons.Thedropoutprocessis
usedinalltheactivationfunctionsbutitisscaledbyfactor(Liu,2020).
3.1.Convolutionalneuralnetwork
3.1.4.Flattenlayers
Theconvolutionallayers,poolinglayers,fully-connectedlayers,and Itcollapsesthespatialdimensionsofthemappedpooledfeatures
denselayersconstitutethearchitectureoftheConvolutionalNeural whileretainingthechanneldimensions.Theflattenedlayeraddsextra
Network(CNN)(SeeFig.6).Thelayers'descriptionisshownbelow. dimensionsandafteritistransformedintoavector.Thevectoredfeed
Fig3.Samplegrapesplantleafimages.(A:GrapeBlackRot,B:GrapeEsca(BlackMeasles),C:Healthy,DGrapeLeafblight(IsariopsisLeafSpot).
26A.S.PaymodeandV.B.Malode ArtificialIntelligenceinAgriculture6(2022)23–33
Fig4.Multi-cropsimageaugmentation(a)(A:OriginalB:Rotate,C:Color,D:ImagePoint,E:Hstack,F:SizeG:GaussianNoise,H:Shape).
tofullyconnectedlayersalsoknownasthedenselayerorfullycon- which is introduced in the full vectors using rectified linear unit
nectedlayers. (RELU)activation.Theversatilityofclassseparationisgreaterwhen
employingasupportvectormachine(SVM).TheessentialsofSVMare
asdescribedinthefollowing:
3.1.5.Fully-connectedlayers
featF uu rl ely sbco en can ue sc ete od ftla hy ee irrs spa ere cin ae le pd ue rpd ofo ser .e Tx ht era sc ote ftd mi am xa fg ue ns cc tl ia os nsi pfi rc ea dt ii co tn
s
Minimize1=
2
∑ j¼n 1W2 1þC ∑ j¼N
1
ξj ð2Þ
earlierextractedimageattributesfromprecedinglayers.Softmaxisa
multiclassclassificationactivationfunctionintheoutputlayers.The WhereCisthetuningmeasure,subjecttotheconstrainty j(W∙X+b)≥
neuralnetworklayerusesamultilayerperceptronmodel(MLP)asa
1–ζ,j=1,2,3…N.Thesoftmaxparameterγ=1andC=1areused
classifier for two-class classification. The model with nonlinearity, throughouttrainingandtestsetsoftheclassificationalgorithm.
Fig5.AB:HStack,C:Original,D:Augmentation,E:BatchHstack,F:AdaptiveGaussiansNoise.
27A.S.PaymodeandV.B.Malode ArtificialIntelligenceinAgriculture6(2022)23–33
Fig6.ProposedconvolutionalneuralnetworkCNNarchitecture.
TheConvNetarchitecturedesign'smaincomponentisitsdepth.By TheVGGmodelimprovedwithlargekernel-sizedfilters,with11
definingadditionaldesignparametersandgrowingthenetworkdepth and5convolutionallayerswitha3x3-kernelfiltersize.Theinput
continuously,byaddingmoreconvolutionallayersthataredoableby imagesizeisfixedat224x224.Followingimagepre-processing,images
usingextremelysmall(3x3)convolutionfiltersinalllayers.Asaresult, werepassedthroughaconvolutionallayerwithafiltersizeof(3x3).For
they'vedevelopedsubstantiallymoreaccurateConvNetarchitectures lineartransformationoftheinputchannel,thefiltersizeissetto(1x1).
thatnotonlyreachstate-of-the-artaccuracyonfixeddatasetclassifica- Thestridesizeisfixedto1andmaxpoolingisperformedwith2x2sizes
tionandlocalisationtasks,butarealsoapplicabletootherimagerecog- andstridesetto2.Inthenextsteps,fullyconnectedlayershavethe
nitiondatasets,wheretheyperformadmirablyevenwhenutilisedas sameconfigurationwith4096channelsineachlayer.Thefinallayeris
partofrelativelysimplepipelines(SimonyanandZisserman,2015).Our thesoftmaxactivationlayers,followedbytheRELUactivationfunctions
ConvNetsarefedafixed-size224x224RGBpictureduringtraining. (SeeFig.7).
Theonlypre-processingweperformisremovingeachpixelfromthe
meanRGBvaluedeterminedonthetrainingset.Weapplyfilterswith 3.3.Performancemeasure
averysmallreceptivefield3x3tosendtheimagethroughastackof
convolutionallayers.Wealsouse1x1convolutionfiltersinoneofthe TheF1score,accuracymatrix,andReceiveroperatingcharacteristic
configurations,whicharealinearchangeoftheinputchannels(followed (ROC),aswellastheareaunderthecurve(AUC),arebeingusedtoeval-
bynon-linearity).Theconvolutionstrideissetto1pixel,andthespatial uatesegmentationperformance(AUC).Theperformanceoftheclassi-
paddingoftheconvolutionallayerinputissetto1pixelfor3conv.layers fierismeasuredusingevaluationmetrics.
so that the spatial resolution is kept after convolutional. Five max-
poolinglayers,whichfollowpartoftheconvolutionallayers,dospatial 3.3.1.Accuracymetrics
pooling(notalltheconvolutionallayersarefollowedbymaxpooling) Themodelperformanceforallclassesisaccuratelymeasured.The
Max-poolingisdonewithstride2overa2x2pixelwindow. accuracyiscalculatedbyaddingthetotalnumberofcorrectpredictions
tothetotalnumberofpredictions.Theperformanceparametercalcula-
tionofprecisionandrecallandF1-Scorearemeasured.Theaccuracyis
3.2.VGG16
expressedintermsasfollows.
The Convolutional Neural Network based VGG16 pre-trained
modelsareusedtoimprovetheperformanceandclassifythecrop ðTPþTNÞ
AC¼ ð3Þ
images as healthy and diseaseimages.Forquality detection and ðTPþFPþFNþTNÞ
analysisofcropleafimages,theinitialmodeltransfersinformation
frompre-trainedVGG16models.TheConvolutionalNeuralNetwork
(CNN)modelretainednewimagesofthefieldandlearnedtoper- Where,TPisTruePositive,TNTrueNegative,FNFalseNegativeand
formamodelfordiseasedetectionandclassification(Alencastre- FPFalsePositiveSamples.Theclassifierperformancemeasureusing
Mirandaetal.,2021). evaluationmetricsaregivesas;
Fig7.Proposedconvolutionalneuralnetwork(CNN)VGG16architecture.
28A.S.PaymodeandV.B.Malode ArtificialIntelligenceinAgriculture6(2022)23–33
3.3.2.Receiveroperatingcharacteristic
Thereceiveroperatingcharacteristic(ROC)curveisusedtounderstand
deterministicindicationsofcategorizationsortingaswellascomputational
modelingchallenges.Thecurveisagraphthatshowstheratiooffalsepos-
itivestotruepositivesunderdifferentstandardlimits(SeeFig.8).
Aprototypealsowithlargesttruenegativeratevalueswasusedtocor-
rectlycategorizedefectives,andthemodelwiththehighesttruepositive
ratevalueswasusedtocorrectlyclassifyhealthily.Toboostproductivity
byreducingprocessingtimefortrainingandtesting,theMCC(Matthews
CorrelationCoefficient)isemployedforthetotalcomputation.MCCisa
criterionforcategorizingcomplexdataintodistinctcategories.MCCisasu-
periormethodtoaccuracywhichonlyhassignificantimportanceifthe
Fig8.ReceiveroperatingcharacteristicsFPversusTP
truepositives,truenegatives,falsenegatives,andfalsepositivesoutcomes
areallpositive.TheMCCrangesfrom1(poorestjudgment)to1(perfect
predictions),withanMCCof0suggestingarandomguess.
Themodelistunedbythenumberofepochs,hiddenlayers,hidden
Table2 nodes,activationfunctions,dropout,learningrates,andbatchsize.The
Parametersettingfortrainedthemodel modelperformanceisaffectedbyhyperparametertuning.Theterm
Hyperparameter ValueSetting "hyperparametertuning"referstotheprocessofrepeatedlyadjustinghid-
denlayers,epochs,activationfunction,orlearningrate.Themodelisfine-
Crops Grapes&Tomatoes
ConvolutionalLayers 13 tunedtoachievethebestaccuracywhileminimisingtheaverageloss.
MaxPoolingLayer 5 TheexperimentalanalysiswascarriedoutonGoogleresearchprod-
DropoutRate 015/0.25/0.50 uctsonGoogleColaboratory.TheColaboratoryplatformsupportspython
ActivationFunction Relu,Softmax
programming,andnearlyallofthePythonlibrariesareuploadedand
Epochs 20/25/30/40/45
LearningRate 0.00001/0.0001 installedforresearchpurposes.ThePython3GoogleComputeEngine
ImageSize 224x224x3 backend(GPU)withRAMof12.72GBanddiscspaceof68.40GBisavail-
able while experimenting. The dataset is uploaded with the drive
mounted,andthemodelistrainedontheGoogleplatformwithhigh
configurations.APythonconverttoimagefunctionisusedforconverting
TP TN
TPR¼ðSensitivityÞ¼ ,TNR¼ðSpecificityÞ ð4Þ alltheimagestoanarrayandfetchingimagesfromthedirectory.
ðTPþFNÞ ðTNþFPÞ
Theprocessedimagescomefromadirectory,andalllabelimagesare
transformedusingthelabelbinarizedsklearnpythonpackage.Thetotal
FP
FPR¼ ðFPþTNÞ ð5Þ numberofimagesisdividedintotrainandtestusingtrain-test-splitpy-
thonfunctions.ThemodelparametersweresetasshowninTable2,and
themodelwastrainedtocalculatealltrainableandnon-trainablepa-
Where,TPRisTruePositiveRate,TNRTrueNegativeRate,andFPR
rameters.TheAdamoptimizationalgorithmisusedtotrainthedeep
FalsePositiveRate.
learningconvolutionalneuralnetworkmodel.Thealgorithmoptimized
TP TP thesparsegradientnoiseissue.
Precision¼ ,Recall¼ ð6Þ
ðTPþFPÞ ðTNþFNÞ Theinputnetworkuses224X224images,andthebatchsizeis30
forgrapesand25fortomatoes,respectively,andthesametestisper-
(cid:1) (cid:3)
m 1 formedfordifferentepochswithbatchsizeandlearningrate.Inevery
G−Mean¼ ∏ Recall ð7Þ
K¼1 K m pollinglayerwitha2x2-poolsizeandtheRELUfunctionutilizedin
thenetwork,themodelperformsamax-poolingoperation.Theoutput
HeremrepresentsthenumberofcategoriesandGdenotestheTNR ofthelastlayerisaoftmax-activationmulti-crop-developedprediction.
andFPRaccuracyratio. Duringthenetwork'strainingphase,hyperparameterssuchaslearning
Meanaverageprecision(mAP),whichconsistsofPrecision,Recall, rateandepochsizewereadjusted.Theaverageaccuracyachievedwas
andMean,isthealgorithmassessmentstandardemployed.Imagepro- 98.40%forgrapesand95.71%fortomatoes,respectively.Thelearning
cessinganddetectionrelyheavilyonthemAP.Fromtheentireresults, rateistestedatdifferentvaluestooptimizetargetedperformancemea-
theaccuracyhasclassifiedcorrectly.Fromthecompletefindings,there- sured.Thevalidationprocessisbasedonatotalnumberofimagesfrom
calliscorrectlyclassified. themulti-cropdataset.Withthesettingofdifferentepochsandbatch
TheF1scoreisanotherimportantmetricforevaluatingthealgo- size,theaccuracyimprovedandgrew.
rithm.It'sprecisionandrecallfundamentalthat'spresentedasfollows: Thecrops-leafimagesdatasetsareusedtotrainthemodelandiden-
tificationofclassandcategoryofdiseasewithtransferlearningtech-
F1Score¼2(cid:2)Precision(cid:2)Recall
ð8Þ niques including VGG16. The original datasets are divided into
ðPrecisionþRecallÞ trainingdata80%,validationdata10%andtestingdata10%.
Table3
Experimentalresultsofthegrapemodelforsettingdifferentparameters.
No.ofepochs Learningrate Dropoutrate No.ofimages Trainingloss Trainingaccuracy Validationloss Validationaccuracy
40 0.00001 0.25 450 0.0897 0.9840 0.0486 0.9889
30 0.0001 0.50 450 0.1136 0.9585 0.0686 0.9867
45 0.00001 0.25 400 0.0995 0.9796 0.0529 0.9858
45 0.0001 0.25 750 0.0875 0.9696 0.0521 0.9853
30 0.0001 0.50 450 0.1326 0.957 0.0686 0.9843
40 0.001 0.30 600 0.1139 0.9606 0.0529 0.9831
29A.S.PaymodeandV.B.Malode ArtificialIntelligenceinAgriculture6(2022)23–33
Table4
Experimentalresultsofthetomatoesmodelforsettingdifferentparameters.
No.ofepochs Learningrate Dropoutrate No.ofimages Trainingloss Trainingaccuracy Validationloss Validationaccuracy
25 0.0001 0.25 200 0.1643 0.9571 0.2627 0.9432
35 0.00001 0.20 180 0.2203 0.9281 0.3143 0.9013
30 0.00001 0.15 200 0.2624 0.9097 0.3345 0.8926
30 0.00001 0.25 200 0.3042 0.8983 0.3736 0.8849
30 0.00001 0.25 180 0.4871 0.8354 0.4149 0.8671
30 0.00001 0.50 200 0.5226 0.8255 0.4508 0.8538
3.4.Trainingandvalidationaccuracy 3.5.Figuresandgraphs
Trainingandvalidationaccuracyismeasuredbysettingdiffer- Amodel'sperformanceismeasuredandverifiedwithtraining,test-
entvalueswhiletrainingthemodel.Theexperimentswerecarried ing,andvalidationmethodsforgrapesandtomatoesleaves.Fig9and
outatGoogleColaboratoryontheavailableRAMof12.50GB.While Fig.10showthetrainingandvalidationaccuracyandlossofthegrape
performingtheexperiment,differentvaluesaresetforthefollow- leavesandtomatoes,respectively.
ing: the number of epochs, learning rate, dropout rate, and the Theconfusionmatrixhasbeenusedtomeasuretheperformancepa-
numberofimagesnotedastrainingloss,trainingaccuracy,valida- rameterforgrapesandtomatoesleaves,asshowninFig.11.Experiment
tionloss,andvalidationaccuracy.Amodel'sperformanceismea- withthefactscollected.Thesuggestedapproachistestedusingour
suredandverifiedonthegrapeandtomatocrops'leaves.Table3 grapesandtomatoesimagedatasets,whichweretakeninareal-field
andTable4showthedetailsoftheresultsofexperimentscarried withvariousbackdropandlightintensities,similartothetestsdonein
ongrapesandtomatoes,respectively. Section4.4.
Fig9.Trainingandvalidation.(a)Accuracyand(b)lossofVGG16grapes.
Fig10.Trainingandvalidation.(a)Accuracyand(b)LossofVGG16tomatoes.
30A.S.PaymodeandV.B.Malode ArtificialIntelligenceinAgriculture6(2022)23–33
Fig11.Confusionmatrix.(a)Tomatoesand(b)grapes.
120%
98.40% 97.53% 97.50%
100% 91.83% 88.46%
81.11%
80%
60%
40%
20%
0%
Proposed Deep Learning Mul(cid:2)-Context Deep Transfer Deep Learning DL
VGG16 VGG Fusion NetworkLearning VGG DCNN Incep(cid:2)on-v1
AlexNet & ResNet-v2
VGG16
Grapes Methods
Fig12.Comparisonbetweendifferentmodelvsaccuracyinpercentage(%)withproposedVGG16grapes.
Toassurethediversityofsampleimagesandavoidtheoverfitting 1. Imageresize:Thetotalimagesscaledintosizeof224x224pixels,for
problem,dataaugmentationtechniquessuchasrandomrotation,flip- themodelfitandminimum200imagestakenfromeachhealthyand
ping,andscaletransform,aswellasassociatedpre-processingactivities, unhealthycategoryareaugmentedwithdataaugmentationmethods.
areusedtoextendthetrainingsamples.Theprocessesaredescribedin 2. Imagepre-processing:Imagepre-processingisusedtodarkenthe
moredetailbelow. differentlengthsoftheimagedata,goingtobringthemintoratio
100%
95.71% 95.00%
95%
91.83%
90%
86.10%
85%
81.11%
80.30%
80%
75%
70%
Tomatoes Methods
Fig13.Comparisonbetweendifferentmodelvsaccuracyinpercentage(%)withproposedVGG16tomatoes.
31
egatnecreP
ni
ycaruccA
egatnecreP
ni
ycaruccAA.S.PaymodeandV.B.Malode ArtificialIntelligenceinAgriculture6(2022)23–33
and retaining the initial images' knowledge formation while presentlybeingsubmitted.Whererelevantcopiesofsuchpublications
attemptingtopreventimagedeformation. areattached
3. Thedatasetpartitionandtraining.Inthissectionaselectionofran- WewishtodrawtheattentionoftheEditortothefollowingfacts
domsampleimagesforproposedexperimentsandcalculatedwith whichmaybeconsideredaspotentialconflictsofinterestandtosignif-
carriedouttheresultasperSection4.4. icantfinancialcontributionstothiswork.[OR]
4. Validationandtesting.Thetestingisdoneontheimagesthatwere Wewishtoconfirmthattherearenoknownconflictsofinterestas-
usedtoevaluatethemodel,andnewimagesfromoutsidemodeling sociatedwiththispublicationandtherehasbeennosignificantfinancial
areusedtocheckthemodeleffectiveness.Theoutputresultsare supportforthisworkthatcouldhaveinfluenceditsoutcome.
comparedtothereal categories,the effectivenessofthe control Weconfirmthatthemanuscripthasbeenreadandapprovedby
thatgoeswiththemiscomputed. allnamedauthorsandthattherearenootherpersonswhosatisfied
thecriteriaforauthorshipbutarenotlisted.Wefurtherconfirmthat
TheresidualblockcollectionandDesnseNetusedintaskoftomato theorderofauthorslistedinthemanuscripthasbeenapprovedby
leafdiseaseidentificationwithRDNrestructuredmodel.Afterinput allofus.
imagenormalizingandaddingtheconvolutionallayerresidualmodules Weconfirmthatwehavegivendueconsiderationtotheprotection
denselayerclassifythetomatodiseaseimageswith95%accuracydis- ofintellectualpropertyassociatedwiththisworkandthatthereareno
easedataset(Zhouetal.,2021).ThepublicdatasetoftheAIChallenger impedimentstopublication,includingthetimingofpublication,with
Competitionin2018usedtheInception-ResNet-v2modelusingthe respecttointellectualproperty.Insodoingweconfirmthatwehave
RELUactivationfunction,withanaccuracyof86.1%.(Aietal.,2020), followed the regulations of our institutions concerning intellectual
under complex background conditions, the accuracy of VGG Net is property.
91.83%.OnemoreapproachtoINC-VGGNricediseasedetectionwith Wefurtherconfirmthatanyaspectoftheworkcoveredinthisman-
anaverageaccuracyof80.38%forboth"Phaeo-sphaeriaSpot"and uscriptthathasinvolvedeitherexperimentalhumanpatientshasbeen
"MaizeEyespot"diseases(J.Chenetal.,2020)(SeeFig.13). conductedwiththeethicalapprovalofallrelevantbodiesandthatsuch
approvalsareacknowledgedwithinthemanuscript.
4.Conclusion WeunderstandthattheCorrespondingAuthoristhesolecontact
fortheEditorialprocess(includingEditorialManageranddirect
Inthispaper,therearetwotypesofcropdiseaseleaveswerecollected communicationswiththeoffice).He/sheisresponsibleforcommu-
andpreparedasadatasetwithavailabledata.Thetechniquesofdataaug- nicatingwiththeotherauthorsaboutprogress,submissionsofrevi-
mentation,datasetpre-processing,training,andtestingareappliedtothe sionsandfinalapprovalofproofs.Weconfirmthatwehaveprovided
convolutionalneuralnetwork-basedVGG16model.Theproposedmodel acurrent,correctemailaddresswhichisaccessiblebytheCorre-
isbuiltandtestedtoimprovetheperformancemeasuredandcompared. spondingAuthorandwhichhasbeenconfiguredtoacceptemail
Theevaluationmetricsparametersarehigherandincreasedascompared frombiomaterials@elsevier.com.
tootheravailabledatasetsandmethods.Therefore,ourproposedre-
searchworkincreasedaccuracyforgrapesby98.40%andfortomatoes References
by95.71%.Alwaysimprovingtheperformanceofon-fieldcrops,leafim-
agesanddiseasesclassificationandanalysisisacriticalstep,butwithour Ai,Y.,Sun,C.,Tie,J.,Cai,X.,2020.Researchonrecognitionmodelofcropdiseasesandinsect
pestsbasedondeeplearninginharshenvironments.IEEEAccess8,171686–171693.
modelachievedthehighestperformance,whichsupportedagricultural https://doi.org/10.1109/access.2020.3025325.
development.Themajorfocusofresearchistoprovideadvancementin Alencastre-Miranda,M.,Johnson,R.M.,Krebs,H.I.,2021.Convolutionalneuralnetworks
theagriculturesectorandanincreaseinfoodproduction.Thecollection andtransferlearningforqualityinspectionofdifferentsugarcanevarieties.IEEE
Trans.Indust.Inform.17(2),787–794.https://doi.org/10.1109/TII.2020.2992229.
andpreparationofgenuinedatasetsandapplyingtothedeeplearning
Ang,K.L.M.,Seng,J.K.P.,2021.Bigdataandmachinelearningwithhyperspectralinforma-
modelswithmultiplecropsleavesimagesisafuturetarget.Inthefuture, tioninagriculture.IEEEAccess9,36699–36718.https://doi.org/10.1109/ACCESS.
theuseofInceptionV3andResNet-basedCNNmodelsformuchdeeper 2021.3051196.
analysisofcropimagesisanticipated.Ourworkencouragesandstimu- ArunPandian,J.,Geetharamani,G.,Annette,B.,2019.Dataaugmentationonplantleafdis-
easeimagedatasetusingimagemanipulationanddeeplearningtechniques.Pro-
latesfarmers,whichultimatelyraisesfarmincomeandhelpstobuild
ceedingsofthe2019IEEE9thInternationalConferenceonAdvancedComputing,
uppowerfulcountries. IACC2019,pp.199–204https://doi.org/10.1109/IACC48062.2019.8971580.
Chen,J.,Chen,J.,Zhang,D.,Sun,Y.,Nanehkaran,Y.A.,2020.Usingdeeptransferlearning
forimage-basedplantdiseaseidentification.Comput.Electr.Agricult.173(November
Acknowledgements
2019)105393.https://doi.org/10.1016/j.compag.2020.105393.
Chen,C.J.,Huang,Y.Y.,Li,Y.S.,Chen,Y.C.,Chang,C.Y.,Huang,Y.M.,2021.Identificationof
Farmers from Nashik and Aurangabad, Maharashtra [India], fruittreepestswithdeeplearningonembeddeddronetoachieveaccuratepesticide
contributedtothecollectionofrealfieldcropimagesforresearch spraying. IEEE Access 9, 21986–21997. https://doi.org/10.1109/ACCESS.2021.
3056082.
purposes.Wewouldliketo thankyou Dr.Panjabrao Deshmukh
Ferentinos,K.P.,2018.Deeplearningmodelsforplantdiseasedetectionanddiagnosis.
KrushiVidyapeet(Dr.PDKV),Akola,Maharashtra[India],fortheir Comput.Elect.Agric.145(September2017),311–318.https://doi.org/10.1016/j.
encouragementandassistance. compag.2018.01.009.
Gandhi,R.,Nimbalkar,S.,Yelamanchili,N.,Ponkshe,S.,2018.Plantdiseasedetectionusing
CNNsandGANsasanaugmentativeapproach.2018IEEEInternationalConferenceon
Declarationofcompetinginterest InnovativeResearchandDevelopment,ICIRD2018,no.May:1–5https://doi.org/10.
1109/ICIRD.2018.8376321.
Theauthorsdeclarethattheyhavenoknowncompetingfinancial Hiary,H.,Al,S.B.,Ahmad,M.,Reyalat,M.Braik,ALRahamneh,Z.,2011.Fastandaccurate
interestsorpersonalrelationshipsthatcouldhaveappearedtoinflu-
detectionandclassificationofplantdiseases.Int.J.Comput.Appl.17(1),31–38.
https://doi.org/10.5120/2183-2754.
encetheworkreportedinthispaper. Jin,X.,Che,J.,Chen,Y.,2021.Weedidentificationusingdeeplearningandimageprocess-
inginvegetableplantation.IEEEAccess9,10940–10950.https://doi.org/10.1109/AC-
Creditauthorstatement CESS.2021.3050296.
Kurmi,Y.,Gangwar,S.,Agrawal,D.,Kumar,S.,Srivastava,H.S.,2020.Leafimageanalysis-
basedcropdiseasesclassification.SignalImageVideoProcess.https://doi.org/10.
Wetheundersigneddeclarethatthismanuscriptisoriginal,hasnot 1007/s11760-020-01780-7.
beenpublishedbeforeandisnotcurrentlybeingconsideredforpublica- Liu,S.Y.,2020.Artificialintelligence(AI)inagriculture.ITProfes.22(3),14–15.https://
tionelsewhere. doi.org/10.1109/MITP.2020.2986121.
Massi,I.E.,Mostafa,Y.E.-s.,Yassa,E.,Mammass,D.,2020.Combinationofmultipleclassi-
WewouldliketodrawtheattentionoftheEditortothefollowing fiersforautomaticrecognitionofdiseasesanddamagesonplantleaves.SignalImage
publicationsofoneormoreofusthatrefertoaspectsofthemanuscript VideoProcess.https://doi.org/10.1007/s11760-020-01797-y.
32A.S.PaymodeandV.B.Malode ArtificialIntelligenceinAgriculture6(2022)23–33
Nevavuori,P.,Narra,N.,Lipping,T.,2019.Cropyieldpredictionwithdeepconvolutional Wu,W.,Yang,T.L.,Li,R.,Chen,C.,Liu,T.,Zhou,K.,Sun,C.M.,Li,C.Y.,Zhu,X.K.,Guo,W.S.,
neuralnetworks.Comput.Elect.Agric.163(June)104859.https://doi.org/10.1016/j. 2020.Detectionandenumerationofwheatgrainsbasedonadeeplearningmethod
compag.2019.104859. undervariousscenariosandscales.J.Integr.Agric.19(8).https://doi.org/10.1016/
Paymode,A.S.,Malode,V.B.,Shinde,U.B.,2020.Artificialintelligenceinagricultureforleaf S2095-3119(19)62803-0.
diseasedetectionandprediction:areview13(4),3565–3573. Xie,X.,Ma,Y.,Liu,B.,He,J.,Li,S.,Wang,H.,2020.Adeep-learning-basedreal-timedetec-
Simonyan,K.,Zisserman,A.,2015.Verydeepconvolutionalnetworksforlarge-scale torforgrapeleafdiseasesusingimprovedconvolutionalneuralnetworks.Front.Plant
imagerecognition.3rdInternationalConferenceonLearningRepresentations,ICLR
Sci.11(June)1–14.https://doi.org/10.3389/fpls.2020.00751.
2015-ConferenceTrackProceedings.http://www.robots.ox.ac.uk/.
Zhou,C.,Zhou,S.,Xing,J.,Song,J.,2021.Tomatoleafdiseaseidentificationbyrestructured
Sun,J.,Yang,Y.,He,X.,Xiaohong,W.,2020.Northernmaizeleafblightdetectionunder
deepresidualdensenetwork.IEEEAccess9,28822–28831.https://doi.org/10.1109/
complexfieldenvironmentbasedondeeplearning.IEEEAccess8,33679–33688. ACCESS.2021.3058947.
https://doi.org/10.1109/ACCESS.2020.2973658.
33