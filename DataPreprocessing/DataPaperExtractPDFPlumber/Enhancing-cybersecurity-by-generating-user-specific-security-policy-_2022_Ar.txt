Array14(2022)100146
ContentslistsavailableatScienceDirect
Array
journalhomepage:www.elsevier.com/locate/array
Enhancingcybersecuritybygeneratinguser-specificsecuritypolicythrough
theformalmodelingofuserbehavior
ArwaAlQadheeba,SiddharthaBhattacharyyaa,∗,SamuelPerlb
aComputerEngineeringandSciences,FloridaInstituteofTechnology,Melbourne,FL,32901,USA
bSoftwareEngineeringInstitute,CarnegieMelonUniversity,Pittsburg,PA,15213,USA
A R T I C L E I N F O A B S T R A C T
Keywords: Organizations today are faced with the difficult challenge of balancing the embrace of new and emerging
ZeroTrust technology,andsecuringtheirsystemsanddatathatsupportcriticalbusinessfunctions.Althoughtherehave
Automaticverification beensignificantadvancesinsecurityenforcementtechnology,attackersarestillabletocompromiseorganiza-
Correctness tionsandaccess.Theimpactsofcomputerintrusionshavebecomesountenablethatmanyorganizationsare
Cybersecuritypolicy
lookingatadrasticrethinkingoftheirapproachtothesecurityofinternalnetworks.Thisapproachiscalled
Securitypolicy
ZeroTrust anditseekstoremoveallnotionofatrustedinternalnetworkboundary.ThebenefitsofZeroTrust
Formalmethods
Userbehavior includesignificantlyincreasingtheworkthatattackerswouldneedtoperformtoachievetheirobjectives.But
Automatedsecuritypolicygeneration ZeroTrust willalsoincreasethemanagementcomplexityforinternalsecurityteams.Theseteamswillneeda
Finite-StateAutomata waytocollectdataandenforcepolicydecisionsbaseduponanalysis.Thisprocesswillneedtobedonefor
TimedComputationTreeLogic allorganizationalsystems,anddata,anditwillneedtobedoneinallaccesscontexts.
Ourapproachusesformalmethodstomodelandexamineend-userssecurity-relatedbehaviors.Researchers
have found that the users’ security decisions correlate with factors including demographics, personality
traits,decision-makingstyles,andrisk-takingpreferences.WedescribethesebehaviorsbyusingFinite-State
Automata(FSA).Thisallowsfortheautomatedformulationoflinear-timesecuritypropertiesbasedonTimed
Computation Tree Logic (TCTL). The logic is then used to check the satisfaction of collected and observed
securitybehaviorsagainstpolicy.Thisformalbehavioralanalysiscouldbecombinedwithothersecurityand
networkdataduringthecontextanalysisprocessthatneedstooccurforeachZeroTrust accessrequest.Other
networkorhostsecuritydatacouldincludeaddressidentifiers,tokens,eventdata,packetinspection,running
processdata,cyberthreatintelligence,andmuchmore.OurmethodallowsorganizationsthatembraceaZero
Trustphilosophytogeneratecontextspecificsecuritypoliciesthatcanbeautomaticallyverifiedforcorrectness
andcompletion.
1. Introduction new intrusions because the attack surface changes quickly and the
softwaresupplychainbecomesevermorecomplex.
Organizations today are faced with the difficult challenge of bal- Security professionals are developing new security models to be
ancing the embrace of new and emerging technology, and securing better prepared to Prevent, Detect, Respond, and Recover from cy-
their systems and data that support critical business functions. Al- berattacks. In 2010, John Kindervag, a Security and Risk Principal
though there have been significant advances in security enforcement Analyst at Forrester Research Inc., developed a Zero Trust security
technology, attackers are still able to compromise organizations and
model that radically prioritizes a classic security principles; ‘‘never
access. Perhaps more now than ever before, Organizations are re-
trust, always verify’’ [1]. The rules of operation for how a Zero Trust
quired to embrace new technical innovations including advances in
network operates are different from traditional security models. They
theInternetofThings,MachineLearningandStatisticalAnalysis,and
reflect lessons learned from over a decade of dealing with intrusions
CloudComputing.Asthesenewdevicesandservicesbecomeavailable,
andobservingtheadversariestactics,techniques,andprocedures.
organizations have a business need to connect them to their business
networks.Iftheydonot,theyriskbecomingovertakenintheirmarket Organizations considering Zero Trust will also need to pay atten-
bycompetitors.Thisfurtherteststheirsecurityteamsabilitytoprevent tion to the human behaviors [2]. The natural structure of humans
∗ Correspondingauthor.
E-mailaddress: sbhattacharyya@fit.edu(S.Bhattacharyya).
https://doi.org/10.1016/j.array.2022.100146
Received10June2021;Receivedinrevisedform15February2022;Accepted1April2022
Availableonline9April2022
2590-0056/©2022TheAuthors.PublishedbyElsevierInc.ThisisanopenaccessarticleundertheCCBYlicense(http://creativecommons.org/licenses/by/4.0/).A.AlQadheebetal. Array14(2022)100146
psychology,thelimitationofhumans’informationprocessingcapacity, modeling of human cognition following the principles of cognition.
and their reliance on previous experiences to take future action can The formal models where verified using Theorem Provers, not model
impedetheirsecuritychoices[3].ThePonemonInstitutestudybased checkers.Asaresult,itisamoremanualprocessthantheautomated
oninterviewing507companiesacrossthegloberevealsthataccidents methodusedbymodelcheckers.Finally,theworkbyCurzondiscussed
among users is the leading cause of 24% of data breaches, which are an approach to the verification but did not implement the approach.
worth,onaverage,around$3.5millionoffinancialdamage.Uninten- Degani[9]discussesanapproachtotheformalmodelingandanalysis
tionalandaccidentalbreachesresultfromso-calledinadvertentinsiders of the interface between the human and machine in the avionics
whohadexperiencedasuccessfulphishingattackorhadtheirdevices domaintocaptureerrorsinthedesignoftheinterface.Oncetheuser
infected, lost, or stolen. According to the Ponemon Institute, human modelsweredeveloped,acorrespondencetablewasdevelopedtoun-
errors in cybersecurity takes organizations around 181 days and 61 derstandhowauserwouldrespondtoanevent.Finally,thecomposed
daystoidentifyandcontain,respectively,adatabreachthatisrelated model was developed by generating the masked synchronous product
tosuchcarelesshumanaction[4]. of the user model with the autopilot model. This work was also a
Mostcomputersystemsaredesignedbasedonthegeneralpercep- theoreticalstudynotimplementedusinganytool.Bolton[10]surveyed
tion of that all users in an access group will behave similarly. This formalverificationbasedapproachesthatwasappliedtoverifyhuman
overlookstheideathatindividualssecuritybehaviorsdifferfromeach automationinteractiontoidentifyerrorsinthedesignoftheinterface.
other[5].Researchersinhumanfactors,haveexaminedthepsychology But,alloftheseapproacheswherefocusedonapplyingformalmethods
ofhumanstounderstandusers’differentbehaviorstowardprivacyand toidentifyerrorsduringdesigntime,noneoftheapproachesdiscussed
security.Someworksshowthatindividualdifferencesindemographics howformalusermodelscanbeintegratedaspartofanalyzingrealtime
and psychological constructs (e.g., personality traits, decision-making data, as well as, for security policy generation for cybersecurity. Our
styles,andrisk-takingpreferences)haveasignificantrelationshipwith approachdemonstrateshowformallymodeledcybersecuritybehavior
security behaviors and privacy attitudes. One research study found ofuserscanbeanalyzedinrealtimetothengeneratesecuritypolicies.
NorwegiansandJapanesetendtobrowsetheInternetmorecautiously Houser[11]discusseddevelopingmentalusermodeltocapturewhat
thantheircounterpartsinItalyandSpain,thuslowertheirchancesof theuserthinksthepresentstatusisofthesystem,theactualstateofthe
randomlyencounteringmalware-infectedwebsites[6]. system and then identifying if there are any vulnerabilities. Houser’s
TheprominenthackerKevinD.Mitnick,statesthatthemosteffec-
model does not capture the actual behavior exhibited by the user,
tivetechniquetobreakintoacompany’ssystemistotryexploitingthe
whichwearemodelingbyreviewingsafeandunsafebehaviorexhib-
weakestlinkthatishumans.Fromhispointofview,theonlyreliable
ited by users based on research conducted by Egelman [12], which
approachtoovercomethisproblemistocombinesecuritytechnologies
can be used to generate security policies. One similar work is that of
withfirmsecuritypoliciesalongwithpropereducationprogramsand
Enoch,SimonYusuf.‘‘Dynamiccybersecuritymodelingandanalysis.’’
training sessions for users [7]. As long as users are the weakest link
(2018) [1]. Enoch uses network state input to generate an adaptable
in cybersecurity, cunning adversaries will continue to seek out and
security model based upon constraints. Changes from the state of a
exploitusers’vulnerabilitiesinalmostanyinformationsecuritysystem
dynamic network are used as input to generate modified graphical
viaeverydeviouspossibleway.TheissuewithMitnick’ssolutionishow
securitymodelsbutdoesnottakeuserbehavioralinputexplicitly.The
toautomatetheprocessofhavingsecuritypoliciesthathelpwithusers’
workisalsodirectedatanetworkthatcandynamicallyadjustnetwork
securitymisbehaviorandpoordecisions. Inourresearch, weofferan
configurations(alsocalledActiveDefense)ratherthanassumingaZero
idealapproachtoimposemorecontrolovertheuserbyanalyzingthe
Trust environment. The models used to generate and evaluate attack
securitybehaviorandthengeneratinguser-specificpolicywithinaZero
scenarios focus upon possible attacker behavior (attack trees) rather
Trust environment.Ourgoalistogenerateuserspecificpoliciesbased
thanuponevaluatingtheriskofenduserbehaviors,choices,anddevice
upon security behaviors measured with scales in existing academic
settings.
literaturestudies.Thequestionweaddressinourresearchis:
There are four additional works for generating policy that are
Problem Statement How to generate explicit security policy after
morespecificallyappliedtoaZeroTrustenvironment.Chen,Baozhan,
observingandanalyzingendusersecuritybehaviorsalongwithother
et al. [13] and Mandal, Sudakshina, et al. [14] both focus on dy-
assumedzerotrust securityenforcementdecisions?’’
namically generating access control decisions but neither explicitly
Our method demonstrates the use of Formal Method based frame-
includes recent user security behaviors, choices, or device settings as
work for generating user specific security policy that suggests a new
decision-makingasinputorasmodelfeatures.Eidle,Dayna,etal.[15]
contributiontotheextantliterature.
adjustsaccesspolicyfor8differenttrustlevelsdynamicallyviafirewall
The remainder of this research is organized as follows: Section 2
Access Control Lists (ACLs) and Authentication Gateways. The model
describesingreaterdepthrelatedwork.Section3presentstheresearch
takes alert data from firewalls, authentication gateways, and other
methodology, outlining the sequential development process for the
network devices as input but does not include recent user security
automated approach. Section 4 discusses the selection of user secu-
behaviorsthatdonottriggeralarms.Lastly,Dean,Erik,etal.[16]use
rity behavior. Section 5 discusses the model considerations and the
automated device health attestation results as input for some of the
selectedmodelingparadigm.Section6discussestheoverallexperiment
user devices in their network during session authentication in a Zero
performed with selection and modeling of the security behaviors in
Trustenvironment.ThismapstothepropertiesinDeviceSecurement,
Section 6.1, Section 6.2 explains the checking of satisfaction of user
andUpdatingandmayevenmaptoPasswordsorProActiveAwareness.
security behavior. Section 6.3 defines the rule of generating a user-
However, the work does not list the specific device parameter checks
specific policy. Section 7 discusses the final results obtained by using
that are performed in the ‘‘Health Check’’. Another key difference is
our framework. Finally, Section 8 states our conclusions and future
that the work does not use reachability analysis to apply different
work.
levelsofsecuritypermissionsforslightlyhigherriskbutstillacceptable
2. Relatedwork deviceconfigurations.
Formal method based approach has been applied to the modeling 3. Researchmethodology
andanalysisofuserbehavior,withusermodelsmodeledincognitive
architecture, as described by Curzon [8]. With this approach the re- Research methodology, describes the approach used in addressing
searcherswereabletocapturepotentialerroneousinteractionsbetween the problem of generating user specific security policy following the
devices and humans. The focus of the research by Curzon was in the Zerotrustphilosophy.
2A.AlQadheebetal. Array14(2022)100146
Fig.1. Researchmethodology.
Ourapproachusesresultsfromthestudyofhumanintentions,at- Table1
titudes,norms,andresultingcybersecuritydecisionmakingbehaviors. Comparisonbetween[5]and[2]psycho-metrics.
Therearemanystudiesshowingthatusablesecurityisahardproblem. Metric Study[5] Study[2]
Usersoftenignoreexplicitwarningsandmisunderstandthelikelihood ConsiderationforFutureConsequence(CFC) ✓ ✘
of many risks and their resulting impacts [17]. Users also rationally SecurityBehaviorIntentionsScale(SeBIS) ✓ ✓
DomainSpecificRiskAttitude(DoSpeRT) ✓ ✓
reject warnings because they have experienced so many false alarms InternationalPersonalityItemPool(IPIP) ✘ ✓
in their past experience [18,19]. Human and Computer interaction GeneralDecisionMakingStyle(GDMS) ✓ ✓
interfaces are hard to design and inherent cognitive weaknesses can BarrattImpulsivenessScale(BIS) ✓ ✘
negativelyaffectsecuritydecisions[3,20].Somestudiesfindthatindi- NeedForCognition(NFC) ✓ ✘
vidualusersbehavedifferentlywhenpresentedwithsecuritydecisions
baseduponbackground,culture,andattitudes[2,5,21].
Becausehumanbehaviorsarevaried,difficulttopredict,andopen on users’ security-related behaviors in cyberspace. We chose to focus
ended, we limit the security behaviors in our study to those with an ondecision-makingbecauseithasexperimentallybeenproventobea
existing scale that has been validated in previous studies. Egelman strongerpredictorofsecuritypracticesthandemographics,personality
and Peer created a Security Behavior Intentions Scale (SeBIS) [12] to traits,andrisk-taking[2,12].
evaluateusers’abilitytoadheretocomputersecurityadvicebasedon The selection of predictors for this research is derived from the
self-declared information. The scale focuses on four constructs which observation of two particular earlier studies, which were conducted
are:devicesecurement,passwordgeneration,proactiveawareness,and by Egelman and Peer [5] and Gratian, Et al. [2], respectively. Both
updating. Gratian et al. [2] substantiate the accuracy of SeBIS and pieces of research aim to develop tailored security defenses, taking
broaden SeBIS to examine the correlations of personality traits and into account differences between individuals, in order to limit users’
demographicswithsecurityintentions. errorsandtheirresultingconsequences.Thesamplepopulationof[2]
OurFormalMethodguidedUser-SpecificPolicyGenerationFrame- included higher education participants from a large public university
work (FMUSPGF) in Fig. 1 sets out the structure of this research as a located in the USA, while Egelman and Peer surveyed a group of
whole,thefigureshowsthedevelopmentprocessasasequenceoffour individualsfromAmazonMechanicalTurk(MTurk)whoareoverthe
stages. age of 18. They both made use of SeBIS to carry out their stud-
ThefirststepinFMUSPGFinvolvesselectingsecuritybehaviors,this ies; however, Egelman and Peer’s area of interest regarding security
wasachievedbyconductingasurveyofexistingliteraturetoidentify wasinvestigatingthecorrelationsbetweenSeBISanddecision-making
whataretheexpectedsecuritybehaviors.Oncethesecuritybehaviors psycho-metrics.Gratianetal.didanextendedversionof[5]suchthat
areselected,thesecondstepinvolvesmodelingthesebehaviors,where they substantiate the accuracy of SeBIS, broaden the use of SeBIS to
we implemented a formal method-based approach. After the security examine the correlations of personality traits and demographics with
securityintentions.
behaviors are modeled, the next step involves labeling the security
FromTable1comparingEgelmanetal.[5]andGratianetal.[2]we
behaviors, this was accomplished by executing queries designed us-
identifiedthatSeBIS,DoSpeRT,andGDMSareusedforthesamepur-
ing formal specification. Finally, user specific security policies are
poseofidentifyingtherelationbetweensecurityintentions,risk-taking,
generatedguidedbythelabelinginthepreviousstep.
anddecision-making.Theprocessofdetermininghowtorespondtoa
Our main contribution is in the design of a formal method based
particularsituationrequiresriskevaluation,consideringfutureconse-
framework to support the process of user specific policy generation
quences, and exploring possible alternatives. The natural structure of
forcybersecurity.Intheprocess,wedemonstratedhowtoidentifyand
humanspsychology,thelimitationofhumans’informationprocessing
select the essential characteristics that define users security behavior.
capacity, and their almost absolute reliance on previous experiences
Then,wemodeledtheidentifiedsecuritybehaviorsasformalmodelsto
standinthewayofmakingtherightchoices[3].Failingtodetermine
enableautomatedreasoning.Finally,wewereabletodetectweakness
whatistherightthingtodoandviceversaisacriticalmatterincyber-
inuserssecuritybehaviorandthenproposerelevantpolicies.
security.Ifsomeindividualsdecidedtoleavetheirdeviceunattendedin
public,setupapasswordthatiseasytoguessorhack,rushtodownload
4. Selectingsecuritybehaviors
an anonymous email attachment, or underestimate the importance of
software updates, they are more at risk to be victimized by a crafty
Inthissection,wefocusonselectinguser’ssecurity-relatedbehavior individual.
by taking into account the security decisions made by that user. It Weconsidermodelingsecuritybehaviorswitheachuser’sbehavior
describes the scope of data collection, comparison, and selection in asasequenceofdifferentconnecteddecisions.Eachdecisioncorrelates
ordertoconstructareliableknowledgebasethatrepresentstherequire- with particular SeBIS construct: device securement, password gener-
mentsfordevelopingtheformalmodel,whichweaccomplishedafter ation, proactive awareness, or updating. Using the findings that we
reviewingawiderangeofpossibilities. collected from [2,5]. We chose to use Egelman and Peer’s results in
Previousstudieshavecomprehensivelyinvestigatedthecorrelations this work to develop the formalized users’ security-related behaviors
between individual differences in demographics, personality traits, accordingtospecificsecuritydecisionsasthebehaviorswereidentified
decision-makingstyles,andrisk-takingpreferencesandtheirinfluence asrealisticandusersecuritybehavior.
3A.AlQadheebetal. Array14(2022)100146
Fig.2. Cybersecurityuserbehaviorknowledgerepresentationarchitecture.
5. Modelingusersecuritybehavior 5.2. Designchoices:Modelingparadigmselection
Afterreviewingstudiesonhowthedecision-makingprocessrelated Although, there are several approaches that can be used to model
to security behavior, the appropriate knowledge base was built, and user behavior such as, Markov chains, architectural representations,
the most relevant user behaviors were selected to develop the formal weselectedformalmethodbasedapproach.Wedecidedthatthemost
model. The content of this section focuses on the design choices that appropriate method of representing user behavior is through the use
weremadepertainingtothearchitecturewithlevelsofabstraction,and ofaFinite-StateAutomata(FSA)[22]becauseitallowsustoperform
themodelingparadigmthatwasselected. automated analysis early in the design phase, which would empower
us to reason about the logical representations of the user’s behavior
to evaluate alternative design options in case there were profound
5.1. Designchoice:Levelsofabstraction
implications.Italsoallowsgraphicalrepresentationtovisualizeuser’s
behavioreasily.Itenablestheuseofwell-definedtoolstoo.
It is challenging to model human–machine interactions, because
In order to choose the correct platform for the purpose of de-
of the complexity of human behavior and the broad set of knowl-
signing and checking satisfiability with formal verification the formal
edge requirements. Although, we chose a specific knowledge base,
model of user’s behavior, several formalisms such as NuXMV [23],
it is still challenging to model and examine every aspect of a users
Uppaal [24], PVS [25], and Z3 [26] were considered carefully. We
security-related behavior that is relevant to device securement, pass-
chose Uppaal [27,28][24], due to its ability to model timing aspects
word generation, proactive awareness, and updating. To model users
that are critical for cybersecurity, as well as, its ability to generate
behavior across the different aspects of SeBIS, we applied principles
and visualize counterexamples. Uppaal represents models as timed
of decomposition inherited from software/systems engineering to ar-
automata, and Uppaal formalism supports model checking networked
chitectthestructureofthemodel.thearchitectureofthemodelisas timedautomatausingtemporallogics.Thismodelingparadigmallows
showninFig.2. the execution of requirements as temporal logic queries to check the
The architecture modeling the representation of knowledge about satisfactionofrelevantsafetypropertiesexhaustively.Wenextdescribe
thesecuritybehaviorincludesdifferentlevelsofabstractions,inorder thetimedautomataformalismusedbyUppaal.
toeasethedebugging,increasereadability/maintainabilityandlessen
thecomplexity.Wedecomposedthestructureintodifferentsortsofse-
5.2.1. Mathematicalrepresentationwithintimedautomata.
curityservicesonmultiplelayers,startingfrom(1)asthehighestlevel
Uppaalusestimedautomata[29],asubsetofhybridautomata,asa
of abstraction and ending with (3) as the lowest level of abstraction.
modelingformalism.Oneoftheessentialrequirementsinthedesignof
Bydoingso,weeliminateafairbitofconfusionaroundwhichsecurity
human–machineinteractionsistobeabletomodelthetimeassociated
aspectweemployedforaspecificSeBISdimension. withtheexecutionofoperationsorrules.Atimedautomataisafinite
Here,weillustrateeachlevelofabstractionindetail. automataextendedwithafinitesetofreal-valuedclocks.Clockorother
relevant variable values used in guards on the transitions within the
• Layer(1)isthemostabstractofthefoursecurityservicecheck
automata. Based on the results of the guard evaluation, a transition
layers.ItassimilatestheSeBISconcepts:devicesecurement,pass-
maybeenabledordisabled.Variablescanberesetandimplementedas
word generation, proactive awareness, and updating that are
invariantsatastate.Modelingtimedsystemsusingatimed-automata
specifiedbyEgelmanandPeer.Thesecorrespondtothehighest
approachissymbolicratherthanexplicit.Itallowsfortheconsideration
level of representation of the security task that needs to be
of a finite subset of the infinite state space on-demand (i.e., using
executed.
an equivalence relation that depends on the safety property and the
• Layer (2) breaks down SeBIS concepts according to key param-
timed automata), which is referred to as the region automata. There
eters within each category as identified at Level 1 for example, alsoexistsavarietyoftoolstoinputandanalyzetimedautomataand
device protection, update mechanism, password methods, and extensions,includingthemodelcheckerUppaalandKronos[30].
attentiontothreatsandviolations.Then,itisfurtherdecomposed
intopossibleadditionalsub-servicesbasedontheuserdecisions • TimedAutomata(TA)
ontheactionstheywanttotake. Atimedautomataisatuple(𝐿,𝑙 ,𝐶,𝐴,𝐸,𝐼),where:𝐿isasetof
0
• Layer(3)hasasub-treethatdescendsfromthespecificsofLayer locations; 𝑙 ∈ 𝐿 is the initial location; 𝐶 is the set of clocks; 𝐴
0
2forexamplescreen-lockingfeaturefordeviceprotectionandis isasetofactions,co-actions,andunobservableinternalactions;
enabledbywhattheuserchooses. 𝐸⊆𝐿×𝐴×𝐵(𝐶)×2𝐶×𝐿isasetofedgesbetweenlocationswithan
4A.AlQadheebetal. Array14(2022)100146
action,aguardandasetofclockstobereset;and𝐼∶𝐿→𝐵(𝐶) 6. Experiment
assignsinvariantstolocations.
Wedefineaclockvaluationasafunction𝑢∶𝐶→R ≥0fromtheset Toconducttheexperimentsthefirststepinvolvedtheexperimental
ofclockstothenon-negativereals.LetR𝐶 bethesetofallclock setup,whichinvolvedthemodelingoftheselectedsecuritybehaviors
valuations.Let𝑢 (𝑥)=0forall𝑥∈𝐶.Ifweconsiderguardsand
0 in timed automata 6.1. Once the models were developed, the next
invariantsasthesetsofclockvaluations(withaslightrelaxation
stepinvolvedconductingtheexperiments(6.2)tolabelgoodandbad
offormalism),wecansay𝑢∈𝐼(𝑙)means𝑢satisfies𝐼(𝑙).
securitybehaviors.
• TimedAutomataSemantics
Let (𝐿,𝑙 ,𝐶,𝐴,𝐸,𝐼) be a timed automata 𝑇𝐴. The semantics of
0
6.1. Experimentalsetup:Modelingofselectedsecuritybehaviors
the𝑇𝐴isdefinedasalabeledtransitionsystem⟨𝑆,𝑠 0,→⟩,where
𝑆⊆𝐿×R𝐶 isthesetofstates,𝑠 =(𝑙 ,𝑢 )istheinitialstate,and
0 0 0
→⊆𝑆×{R ≥0∪𝐴}×𝑆 isthetransitionrelationsuchthat: The design of our models were guided by the capability to for-
mally check the existence of good and bad user security behaviors
1. (𝑙,𝑢)→𝑑 (𝑙,𝑢+𝑑)if∀𝑑′ :0≤𝑑′ ≤𝑑 ⇒𝑢+𝑑′ ∈𝐼(𝑙) (asmeasuredbyinstrumentstakenfromacademicliterature)inTCTL.
2. (𝑙,𝑢)→𝑎(𝑙′,𝑢′)if∃𝑒=(𝑙,𝑎,𝑔,𝑟,𝑙′)∈𝐸suchthat𝑢∈𝑔, Sections6.1.1to6.1.4willpresentafurtherillustrationofwhyandhow
𝑢=[𝑟↦0]𝑢and𝑢′ ∈𝐼(𝑙)
wechosethemostcriticalmatterswithindifferentsecuritysettingsthat
where for 𝑑 ∈ R ≥0, 𝑢+𝑑 maps each clock 𝑥 in 𝐶 to the value arepartsofdevicesecurement,passwordgeneration,proactiveaware-
𝑢(𝑠)+𝑑, and [𝑟 ↦ 0]𝑢 denotes the clock valuation which maps ness, and updating. Using behavioral measurement scales in existing
eachclockin𝑟to0andagreeswith𝑢over𝐶⧵𝑟. literature,wesetupaselectionofexamplesseparatinggooddecisions
Notethataguard𝑔 ofa𝑇𝐴isasimpleconditionontheclocks frompoorones.
that enable the transition (or, edge 𝑒) from one location to an- Inthiswork,weperformthedatacollectionmanuallytoshowthe
other;theenabledtransitionisnottakenunlessthecorresponding concept, but the details of instrumentation (or data collection imple-
action𝑎occurs.Similarly,thesetofresetclocks𝑟fortheedge𝑒 mentation) will vary based upon organizations and their Zero Trust
specifiestheclockswhosevaluesaresettozerowhenthetransi- solutions, devices, policies, and procedures. There are also different
tiononedgeexecutes.Thus,atimedautomataisafinitedirected proposed solutions for implementing Zero Trust policy decisions, and
graphannotatedwithresetsofandconditionsover,non-negative anydatacollectionormeasurementofusersecuritybehaviorwillneed
real-valued clocks. Timed automata can then be composed into to interact with the specific Zero Trust solution. Zero Trust solutions
a network of timed automata over a common set of clocks and notionally include a policy enforcement point and a policy engine.
actions,consistingof𝑛timedautomata𝑇𝐴 =(𝐿,𝑙 ,𝐶,𝐴,𝐸,𝐼),
𝑖 𝑖 𝑖0 𝑖 𝑖 Typicallydataneededforasecuritydecisioniscollectedbythepolicy
1 ≤ 𝑖 ≤ 𝑛. This enables us to check reachability, safety, and
enforcement point and sent to the policy engine for review. Organi-
liveness properties, which are expressed in temporal logic ex-
zations could add data collection agents to include end-user security
pressions, over this network of timed automata. An execution
behaviorsaccordingtotheirspecificimplementationsandpolicies.Our
of the 𝑇𝐴, denoted by 𝑒𝑥𝑒𝑐(𝑇𝐴) is the sequence of consecutive
method allows organizations that embrace a Zero Trust philosophy to
transitions,whilethesetofexecutiontracesofthe𝑇𝐴isdenoted
generate context specific security policies that can be automatically
by𝑡𝑟𝑎𝑐𝑒𝑠(𝑇𝐴).
verified for correctness and completion. Future work will be required
toadduserspecificsecuritybehavioraldatatoexistingdatathatisfed
5.3. Querylanguageforverification
tothepolicyengine.ZeroTrust environmentsaretypicallyenvisioned
TheprocessofverificationinUppaaloperateswithaspecifictype to have a policy engine analyzing network, application, device, and
ofquerylanguagethatisusedtospecifyasetofpropertiesthatneed data access policies and determining a decision in an access context.
to be examined. The query language is a subset of Computation Tree Someexamplesincludeusingnetworkorhostsecuritydataincluding
Logic (CTL) called Timed CTL (TCTL) [31]. The syntax of the Timed MACaddressesidentifiers,InternetProtocol(IP)addressesidentifiers,
ComputationTreeLogicisexpressedasfollows: security access tokens, session tokens, process event data, packet in-
𝛷∶∶=𝑎|𝑔|𝛷
1
∧𝛷
2
|¬𝛷|𝐸 (𝛷
1
∪𝐽 𝛷 2)|𝐴(𝛷
1
∪𝐽 𝛷 2),where spection data, running process data, threat intelligence data, device
specific data such as installed application inventories, configuration
• 𝜙isthepropertyorproposition
settings,securityrelevantsettings,andmuchmore.
• aisanatomicaction.
• g isaclockconstraint.
6.1.1. Devicesecurement
• Emeans‘‘forsomepaths’’.
• DeviceProtection
• Ameans‘‘forallpaths’’.
We chose device protection as the first criterion for device se-
• J isanintervalwhoseboundsarenaturalnumber.
• state𝑠 ⊧E(𝛷 ∪𝐽 𝛷 )‘‘forsomepath’’𝑠,𝑠 ... curement.Itmeanswhetherornotusersprotecttheirdevicesby
(∃k≥𝑖 𝑖,k-i∈1 J)((𝑠2 ⊧q)(∀j,i≤j<k)𝑖
(𝑠
𝑖 ⊧+1
p))
passwords,PINcodes,fingerprints,orpatterns.Eventhoughlock-
𝑘 𝑗
ingdevicesofallkindsisasimplesecuritytask,itissometimes
• state𝑠 ⊧A(𝛷 ∪𝐽 𝛷 )‘‘foreverypath’’𝑠,𝑠 ...
𝑖 1 2 𝑖 𝑖+1 undervalued by end-users. In the Pew Research Center survey,
(∃k≥i,k-i∈J)((𝑠 ⊧q)(∀j,i≤j<k)(𝑠 ⊧p))
𝑘 𝑗 conductedin2017,28%ofAmericanmobilephoneusersreported
TCTL is similar to CTL in having temporal connectives that are thattheydonotusePINcodesoranyothersecurityfeaturetoac-
expressed as pairs of symbols. Such that, the first element of the pair cesstheirsmartphones[32].Thismatterofsecurityisalotmore
representsoneofthepathquantifiersthatiseitherAorEwhereasthe critical in the work environment. Because for instance, if some
secondelementofthepairisoneofthestatequantifiersthatisoneof employees are working outside the workplace using portable
thefollowing: devices (e.g., laptops, tablets, or smartphones) as their primary
workcomputer,theycouldleavethedeviceunprotectedinsome
• Gmeans‘‘allstatesinapath’’.
places as in a hotel room or a car. By doing so, if their device
• Fmeans‘‘somestateinapath’’.
is stolen, it is already unlocked, and the company’s data would
The different combinations of path formulae and state formulae beinthehandofanunauthorizedindividual.Mostorganizations
accepted by Uppaal are: AG invariantly A[], EG potentially always requirethiscontrolfordevicesholdingtheirdata,butitmaybe
E[],AFeventuallyA<>,EFpossiblyE<>. hardtomonitorandenforceacrossallecosystemsanddevices.
5A.AlQadheebetal. Array14(2022)100146
Fig.3. Devicesecurementstate-transitiongraphs.
Table2 for users to remember, and thus more likely to be stored inse-
Devicesecurementproperties. curely.Usersareadjustinganddevelopingcopingmechanismsto
No. Knowledgebaseproperty overcomethisburdenbymakingsomealterationstotheircurrent
1 E<>(device_protection.enabled) passwords. We included this rule to our set of specifications to
2 E<>(device_protection.disabled) show an example of the criteria that can be included in the
3 E<>(screen_locking.turned_on)
knowledgebase.
4 E<>(screen_locking.turned_off)
5 E<>(timeout.short) • PasswordLength
6 E<>(timeout.long) People want to protect their personal information, but they are
not willing to pay a little more effort for it. The biggest ex-
ample of this is that despite the continuous security warnings
thatalertusersabouttheuseofweakpasswordsandtheserious
• Screen-Locking
consequencesthatresultfromsuchbehavior,theystilluseshort
Password-protected screen saver feature is about setting up the
and easy-to-remember passwords. According to the Psychology
device to lock off automatically after some time of inactivity.
of the Password Report, 47% of people who participate in the
Some end-users find it a little troublesome thing to do when
studydeclaredthattheyprefertochooseeasypasswordsbecause
theyhavetoconsistentlyloginagaineverymomentthetimeout
they are afraid of forgetting them [37]. Martin et al. (2012)
is exceeded. Others have a low perception of the threat; they
illustratethatguessingapasswordthroughabrute-forceattackis
believe nothing would go wrong since they are around their
mostlikelyunsuccessfulagainstlongandcomplicatedpasswords
portabledevicesalmostallthetime,especiallysmartphones[33].
that contain capital and small letters, digits, and symbols. They
Some others do set a password-protected screen saver, but they mentionthatcrackingacomplicatedpasswordwithlengthsof4,
adjust the default timeout time (i.e., often 15 min) to a much 8, or 16 characters would take approximately 81 s, 210 years,
longer time [34]. We examine this side of device securement and 1.4 quintillion years, respectively [38]. According to Mad-
because leaving the device without a password-protected screen dox and Moschetto (2019), when users assign a password for
saverwouldallowmaliciousindividuals(e.g.,insiderthreats)to some account, they should maintain an adequate length, avoid
access data or perform some tasks they are not entitled to see well-known character substitutions, and use a variety of letters,
or do [35]. Insider threat is one of the most difficult security numbers,andspecialcharacters[39].Wethoughtthatthelength
issues; malicious insiders can put the organization at a greater of a password is necessary to look at to identify those whose
riskthanoutsidersbecausetheyaremorefamiliarwithsecurity accountsarevulnerabletopasswordattacks.
infrastructure,practices,andvulnerabilities.Theycanmoreeasily • PasswordRe-usability
avoiddetectionandremainhiddenforalongperiodoftime. With so many accounts to handle and keep track of, it can be
In Table 2, we can see how we translate the criteria mentioned temptingforuserstouseonepasswordacrossthemallandbring
aboveintoTCTLformulatewhereasFig.3depictsdeviceprotec- themselves some peace of mind; users might live to regret it.
tion, screen-locking, and screen-locking timeout state-transition Re-using the same password for multiple sites carries more risk
graphs,respectively. than writing down separate passwords on a piece of paper. If
individualsdecidedtoassignonepasswordfortheirdifferentac-
counts,theywouldallowattackerstocompromiseotheraccounts
6.1.2. Passwordgeneration that use the same password [40]. The struggle with password
• PasswordAge protectionisthatthemajorityofend-usersacknowledgetherisk
Passwordsareaperennialproblemincybersecurity.Muchadvice andtheconsequencesofpasswordre-use;yet,35%ofthemignore
isgiven,andpoliciesareenforced,butstilltheproblemofweak this knowledge in favor of remembering their easy and famil-
passwords is constantly growing. Setting a maximum password iar passwords [37]. We chose to cover this aspect of password
age is one of the traditional techniques for maintaining proper generationbecause,intheworst-casescenario,theresultingrisk
passwordhygiene.Itrequiresuserstochangetheirpasswordsin is not limited to the end-users but extends to the workplaces
aperiodicmanner,typicallybetween30and90days[36].Some and coworkers if they re-use the work password for some other
mightarguethatscheduledchangesmakethepasswordsharder personalaccount.
6A.AlQadheebetal. Array14(2022)100146
Table3 Table4
Passwordgenerationproperties. Proactiveawarenessproperties.
No. Knowledgebaseproperty No. Knowledgebaseproperty
1 E<>(password_age.non_expired) 1 E<>(spot_signs.yes)
2 E<>(password_age.expired) 2 E<>(spot_signs.no)
3 E<>(password_length.long) 3 E<>(report_threat.yes)
4 E<>(password_length.short) 4 E<>(report_threat.no)
5 E<>(password_reusability.unused) 5 E<>(security_policy.complied)
6 E<>(password_reusability.used) 6 E<>(security_policy.violated)
Table3liststheequivalentexpressionsofpasswordage,length, categorizedas:first,deviantbehaviorthatisdrivenbyintentional
andre-usabilityinUppaalspecificationlanguage. or planned desire to harm the organization entity. Second, neg-
ligentbehaviorthatisintendedtogoagainstsecuritypolicybut
withnomaliciousintenttocauseharm.Third,ignorantbehavior
6.1.3. Proactiveawareness that steams from unawareness due to a lack of cybersecurity
• SpotSignsofThreat knowledge and training. After identifying these different inter-
There is no doubt that the interest in cybersecurity is growing pretations of security policy violations, we modeled end-users’
andexpanding,makingpeoplemoreeducatedandcautiousabout adherencetosecuritypolicy,asitaidstheprocessofidentifying
online information sharing, fake e-commerce sites, scams, and therightpolicyactionstoimposeagainstaspecificuser.
securitythreats.Thereisalwaysa‘‘but’’inthisimperfectworld Table4showsthelinear-timepropertiesthathavebeengenerated
becausethereisasignificantnumberofpeoplewholackdigital toinvestigatetheknowledgebaseaspectofproactiveawareness.
security awareness and education, which in turn affect their
ability to recognize threats even if there were apparent signs.
End-userswouldnotbeabletoprotectthemselvesfromidentity 6.1.4. Updating
theft if they were unable to spot a sign of spyware on their • UpdatingMechanism
device,recognizeasocialengineeringattempt,identifyphishing Security-relatedsoftwareupdatesareoneofthesinglemostim-
or spoofing email, or any other elusive activities. According to portantsecurityprotectiontoolsthatend-usersshouldpaymore
Verizon’s Data Breach Investigations Report (DBIR) (2019), the attentiontoandensurethattheyarebeinginstalledonaregular
phishing attack was one of the leading causes of data breaches. periodic schedule. There are several options for the operating
Itwasacontributingfactorin32%ofconfirmeddataexposures, systemandapplicationupdatesthatend-userscanconfigure,such
and 78% of cyber-espionage incidents [41]. On account of this, ashowupdatesaredownloadedandinstalled(i.e.,automatically
we stressed the importance of spotting early warning signs by ormanually)ontheirdevices.Mostmodernsoftwaresystemsare
investigating the users’ ability to recognize and avoid phishing set to download and install security and other essential updates
scamsbeforeitistoolate. automaticallywithouttheneedforhumanstomakedecisions.In
• ReportThreat contrast, the manual update allows users to gain better control
In ‘‘If You See Something, Say Something®’’ national campaign, overtheirdevicesbychoosingwhichupdatetoinstallandwhen.
which raises public awareness of the indicators of terrorism- Thereisnocertainpositionwherewecansaythatonemechanism
related crime, we are encouraged to report the authorities if isbetterandsaferthantheotherbecauseitalldependsonusers’
something does not seem quite right to keep ourselves and our behaviors regarding this matter. It may come to mind that the
communities safe [42]. It is exactly the case in organizations’ automatic mechanism appears as a more responsible selection.
environments;reportingpossiblesecurityincidentscansavevalu- Still, the manual update is responsible as well in case end-users
able crucial time in the early stages of breach detection [43]. ensurethattheirsystemsareup-to-dateassoonasanewupdate
If employees know about cyberattack types and how they look isavailable.Wechoseincludingusers’preferencesoftheupdating
and occur, they are more likely to notice unauthorized changes mechanismtoobservethedifferentbehaviors.
thathavetakenplaceontheirsystems.Theyprobablywouldbe • TimetoUpdate
more confident and willing to reach out to the IT department. Eventhoughsomesoftwareupdatesandpatchesarereleasedto
Lack of cybersecurity awareness, training, and vigilance, and address security bugs that have been discovered in previously
miscommunication between employees and the IT team would installedsoftware,someend-usersavoidordelaytheinstallation
maketheformerhesitateandquestionthemselveswhetherthey because they consider that these incremental updates are just
havecaughtsomethingrealornot.Theideaofincludingthisarea useless technical additions [46]. Herein lies the risk for those
of interest to our research is to model whether users are truly userswhodownloadandinstallupdatesmanuallyaftertheywere
noteducatedenough,ortheyarejusttoorecklesstoreportsuch available a while ago. We discern from this that delaying the
urgentmatter. installationsofthelatestupdatesandpatchescreateswindowsof
• PolicyCompliance opportunities for malicious individuals to exploit open security
Identifying, determining, and handling risks to the confidential- vulnerabilities on the users’ devices [47]. Thus we investigated
ity, integrity, and availability of an organizations’ assets is a furtherincharacterizingandmodelingthenegligentbehaviorof
top-notchpriority.Securitypoliciesandproceduresarepartofthe usersagainsttimelyupdates.
hierarchyofanyorganizations’managementcontroltomaintain • TimeToReboot
the security of sensitive data, the most critical asset, from the Software developers have unremittingly endeavored to improve
complex and ever-evolving threat landscape. One of the biggest security by excluding the user role from the software update
concerns for any organization is how to protect data from its cycle.Theyfoundthatuserinterventionremainsamustbecause
employees[44].Securitypoliciesandguidelinesareputinplace some updates require a device reboot to allow changes to take
to draw a line for employees between what is acceptable and effect[48].Thereareoperatingsystems,suchasMicrosoftWin-
unacceptabletodowhentheyinteractwiththeinformationsys- dows,developedtoalertusersifarebootisrequiredafterupdates
tem. The problem lies in the employees’ non-compliance [45]. areinstalled.Inthiscase,thesystemshowsupanotificationpop-
AccordingtoMutlaqetal.(2016),non-compliantbehaviorcanbe upthatarebootwilloccurwithinawhile(i.e.,usually10min).
7A.AlQadheebetal. Array14(2022)100146
Table5 6.2.3. Generatinguser-specificsecurityproperties
Updatingproperties. Intheprevioussection,wehavesuccessfullymanagedtomodelthe
No. Knowledgebaseproperty user’ssecurity-relatedbehaviorthroughthemodelinggraphsofFinite-
1 E<>(updating_mechanism.automatically) StateAutomata(FSA).WemadeTomexhibitdifferentgoodandpoor
2 E<>(updating_mechanism.manually) securitybehaviorsregardingdevicesecurement,passwordgeneration,
3 E<>(time_to_update.short)
4 E<>(time_to_update.long) proactive awareness, and updating. In order to automatically analyze
5 E<>(time_to_reboot.right_away) Tom’sbehavior,weneededtocreatelinear-timepropertiesmanually,
6 E<>(time_to_reboot.after_awhile) whicharegeneratedspecificallyforTom.InFig.5,wegeneratedthe
propertiesweneededtocheckbasedonpropertiesidentifiedpreviously
specified in Section 4. We are generating these properties in order to
distinguishtheaspectswhereTomhasfailedtoapplypropersecurity
Usersaregiventheoptioneithertorebootthedeviceimmediately
practices.
or to postpone for an additional specific time. If users chose to
postpone,thewarningdialogwouldappearagainwiththesame
options[48].Usersdelaytherebootingtaskbecausetheymight 6.2.4. Reachabilityanalysis
havesomepressingmattersthatkeepthemfromrebootingfora Reachabilityanalysiswithmodelcheckingisaverificationprocedure
couple of hours. The decision to postpone rebooting more than for models that are designed based on the state-transition concept.
oncecouldnegativelyimpactthesecurityofthedevicebecause, According to Kong et al. (2015), reachability analysis is a technique
forthecomputersystem,theupdateinstallationisnotcompleted. used in a state-transition system in order to find out the type and
We observed this aspect of updating to draw the attention of number of states which can be accessed through a particular system
negligent and unaware users to the importance of immediate model[49].Reachabilityanalysisallowsformalanalysisforvalidation,
rebootifrequired. verification,andcheckingperformancemetrics,explainedasfollows:
InTable5,wepresenttheformalspecificationsofupdatingthat • Validation:Asimulationoftheprocessisshownwherethemodel
areexpressedintermsoftimedtemporallogicTCTL.
shouldreflectwhatitindentedtorepresent.
• Verification:Acheckingprocessiscarriedouttoensurethatthe
specificationsmeetthemodelthatisbuilt.
6.2. Experiments:Classifyingsecuritybehavior
• Performance: A set of predictions about the key performance
In this section, we model several test cases with different security indicatorsismade.
behaviors,asFinite-StateAutomata(FSA).Foreachseparatetestcase,
Among these procedures, we are checking the satisfiability of our
wegenerateasetofuser-specificlinear-timeproperties.Wethenclas-
specifications(i.e.,properties)inany,some,orallstatesofuser’sbe-
sifythebehaviorasgoodorbadbasedontheresultsofthereachability
haviormodel.AccordingtoEleftherakisetal.(2001),‘‘Amodelchecker
analysis. Once the behavior is classified we generate the relevant
takesamodelandapropertyasinputsandoutputseitheraclaimthat
securitypermissionssuchas,Strict,ModerateandLeastrestrictive.
thepropertyistrueoracounterexamplefalsifyingtheproperty.’’[50].
In this research, we favored reachability analysis over other methods
6.2.1. Automatedanalysis
suchasgraphmatchingapproachbecauseitprovidestheopportunity
We seek to analyze users’ behaviors in order to make a careful
to intensely and automatically check all possible paths to check the
analysisanddrawouttheirpoorsecuritydecisionsthathaveasignifi-
satisfaction of security properties while being computationally less
cantimpactonthesecuritysystem.Toultimatelyachieveourgoal,we
expensivethangraphmatching.
designed six test cases that cover as much as possible of different se-
For the set of combined linear-time security properties shown in
curitybehaviorsexhibitedbyusersinreal-worldscenariosthatrevolve
Fig.5,weappliedreachabilityanalysisusingUppaaltoseewhichprop-
arounddevicesecurement,passwordgeneration,proactiveawareness,
ertiesweresatisfiedandwhichwerenot.Theresultsofthisprocedure,
and updating. For each test case, we represent the user’s behavior
allow us to examine Tom’s behavior and identify his security weak-
as a state-transition graph using the Uppaal tool,1 manually generate
nesses. We identified through two examples of reachability analysis
user-specificlinear-timeproperties,applyreachabilityanalysis,identify
results in Uppaal, where Tom enabled manual updating and did not
good and bad security behaviors and generate user-specific policy. In
installthenewupdateswithinthefirstdayoftheirrelease.
this section, we demonstrate one example of these test cases as an
Uppaalexecutesreachabilityanalysisandcheckswhetherastateis
illustrationofourformalmethod-basedapproach.
reachableeitherwithBreadth-FirstSearch(BFS)orDepth-FirstSearch
(DFS)algorithmsfortraversinggraphs,respectively.WechoseBreadth-
6.2.2. Representingtestcases
FirstSearch(BFS)tocheckthesatisfactionofourreachabilityproper-
In order to have reliable test cases, we had to make several as-
ties(i.e.,securityproperties)inusers’state-transitiongraphsbecauseit
sumptionsandpredictionsofhowsomeusersmightbehaveandmake
allowstraversingagraphwithease.
security-relateddecisions.Inonetestcase,wecreatedascenariowith
ausernamedTom,whoworksasaDataEntrySpecialistatanetwork
6.3. Policygeneration
marketingcompany.Tomisassignedalaptoptoperformdutiesdirectly
related to the business of the company and to allow him to work
After the execution of the experiments we were able to check
remotelyandoutsideofregularworkinghours.Onthisbasis,thecom-
the satisfiability of the properties and then associate labels with user
pany requires him to be responsible and take reasonable precautions
specificsecuritybehaviors.Accordingtothoselabelswewereableto
to protect and maintain the laptop and its content. For this research,
we are focusing on capturing Tom’s security behavior rather than generate and define a set of policies to be imposed on specific users
his system role. Fig. 4 represents the state-transition graph of Tom’s basedonthesatisfactionofpoororgoodsecuritybehaviorfoundfrom
security-related behavior. All the other models can be found at https: model checking. The type of policies to be enforced depends on the
//github.com/sbhattacharyya/USPGZeroTrust. users’ decisions that represent their adherence to the rules set, which
weestablishedforeachsecurityaspecthighlightedinthisresearch:De-
viceSecurement(DS),PasswordGeneration(PG),ProactiveAwareness
1 Integratedtoolenvironmentformodeling,validation,andverificationof (PA), and Updating (U). We assign each security aspect one of three
Finite-StateAutomata(FSA)[24]. standardizedpolicytypesthatwedraftedasfollows:
8A.AlQadheebetal. Array14(2022)100146
Fig.4. Tom’sstate-transitiongraph.
Fig.5. Securitypropertiesverified.
1. Strict Policy (𝑠): Applied when the user is exhibiting severe satisfiedbytheuseri.Thebehaviorlabelcanbegood(𝐺 ),bad(𝐵 )
𝑘 𝑘
disregardfortheappropriatesecuritymeasures. oramixtureofgoodandbad(𝐺𝐵 ).Basedonthesatisfactionoutcome
𝑘
2. ModeratePolicy(𝑚):Appliedwhentheuserisexhibitingneg- thepolicy(𝑃 𝑡𝑦𝑝𝑒𝑖𝑘)isselectedtobeleastrestrictive,moderateorstrict
ligenceinfollowingtheappropriatesecuritymeasures. policyforuseriforsecuritybehaviork.Inthealgorithmweconsider
3. LeastRestrictivePolicy(𝑟):Appliedwhentheuserisexhibit- thenumberofuserstoben,thenumberofsecuritybehaviorstobep
ing good security behavior with full respect to the appropriate andnumberofsecuritypropertiestobem.
securitymeasures. In our example, a policy is based on four security behaviors, as
discussed in Section 4. The four security behaviors are device secure-
The assignment of a policy to a user is as described in the policy ment, password generation, proactive awareness, and updating. The
generationAlgorithm1.Theinputtothealgorithmare:1.modelofall representation of a general security policy based on the described
theknownsecuritybehaviors,asTA,2.representationofusersecurity algorithmisasgivenbelow:
behaviors (𝑈 𝑖𝑆𝑏 𝑘) as a trace in TA, where 𝑈 𝑖 is user i and 𝑠𝑏 𝑘 is the 𝑆𝑏 = {𝐷𝑆,𝑃𝐵,𝑃𝐴,𝑈𝑃} if 𝑆𝑎𝑡_𝑂𝑢𝑡 𝑖 = {𝐷𝑆(𝐺),𝑃𝐺(𝐵),𝑃𝐴(𝐺∕𝐵),
securitybehaviorkexhibitedbyuseri,formulationofsecurityproper- 𝑈𝑃(𝐺)}𝑃𝑜𝑙𝑖𝑐𝑦 ={𝑟,𝑠,𝑚,𝑟}
𝑖 𝑖 𝑖 𝑖 𝑖
tiesinTCTL𝑆𝑃𝑟𝑜𝑝 ,itisthesecuritypropertythatisbeingverifiedand As per the formal description of the general policy, we can deter-
𝑗
thesatisfactionoutput,forauserexhibitingallthebehaviorsstoredin minetheappropriatepolicythatissuitableforthesixtestcasestested
a list 𝑆𝑎𝑡_𝑂𝑢𝑡, it stores the security behavior and the behavior label areasfollows:
𝑖
9A.AlQadheebetal. Array14(2022)100146
Algorithm 1 INPUT: Results of Model checking performed on levels of abstraction to represent the knowledge about the potential
Timed Automata representation of User Security Behavior (TA, behaviors.Thisabstractedrepresentationofsecuritybehaviorsallowed
{{𝑈 1 𝑆𝑏 1, ..., 𝑈 1 𝑆𝑏 𝑘...𝑈 1 𝑆𝑏𝑝 }, {𝑈 𝑖 𝑆𝑏 1, ..., 𝑈 𝑖 𝑆𝑏 𝑘...𝑈 𝑖 𝑆𝑏𝑝 ustocreatetherequiredknowledgebaseasfinitestateautomataand
},{𝑈 𝑛 𝑆𝑏 1, ..., 𝑈 𝑛 𝑆𝑏 𝑘 𝑈 𝑛 𝑆𝑏𝑝 }} {𝑆𝑃𝑟𝑜𝑝 1, ..., 𝑆𝑃𝑟𝑜𝑝 𝑗,... 𝑆𝑃𝑟𝑜𝑝 𝑚}, italsoallowsforscalability,aswhilecheckingthesatisfiabilityyouare
{𝑆𝑎𝑡_𝑂𝑢𝑡 1...𝑆𝑎𝑡_𝑂𝑢𝑡 𝑖...𝑆𝑎𝑡_𝑂𝑢𝑡 𝑛}} checkingonelevelatatimeinsteadofincludingallthelevelsatonce.
OUTPUT: User Specific Security Policy ((𝑈𝑠𝑒𝑟 1, (𝑆𝑏 1, 𝑃 𝑡𝑦𝑝𝑒11), Once modeled, it enabled automated reasoning to check the sat-
(𝑆𝑏 2,𝑃 𝑡𝑦𝑝𝑒12), (𝑆𝑏 𝑝, 𝑃 𝑡𝑦𝑝𝑒1𝑝), (𝑈𝑠𝑒𝑟 𝑖, (𝑆𝑏 1, 𝑃 𝑡𝑦𝑝𝑒𝑖1), (𝑆𝑏 2,𝑃 𝑡𝑦𝑝𝑒𝑖2), (𝑆𝑏 𝑝, isfiability of good or bad security behaviors exhibited by users. As
𝑃 𝑡𝑦𝑝𝑒𝑖𝑝),(𝑈𝑠𝑒𝑟 𝑛,(𝑆𝑏 1,𝑃 𝑡𝑦𝑝𝑒𝑛1),(𝑆𝑏 2,𝑃 𝑡𝑦𝑝𝑒𝑛2),(𝑆𝑏 𝑝,𝑃 𝑡𝑦𝑝𝑒𝑛𝑝)) a result, using our framework user specific security related policies
1: forall𝑖∈{1,…,𝑛} do canbegenerated.Asthepolicygenerationwasalgorithmicthepolicy
2: forall𝑘∈{1,…,𝑝}do generationcanbeanautomatedprocessforzerotrustenvironmentto
3: SELECT𝑈𝑆𝑏 ;selectsecuritybehaviortraceforuseri generatepolicieswithchanginguserbehavior.
𝑖 𝑘
4: forall𝑗∈{1,…,𝑚}do We verified 90 properties for six test cases that were generated.
5: SELECT𝑆𝑃𝑟𝑜𝑝 𝑗;selectsecuritypropertytoverify The properties were executed on a 64 bit Mac, each property proved
6: PERFORM MODEL CHECKING ON (𝑈 𝑖𝑆𝑏 𝑘) WITH TCTL QUERY within6–18s.Thishigherlevelreasoningcanleadtothegenerationof
(𝑆𝑃𝑟𝑜𝑝 𝑗) parameterstomonitorforindividualuserstocapturetheuserspecific
7: STORE SATISFACTION OUTPUT FOR 𝑈𝑠𝑒𝑟 in
𝑖 behaviors.
a list 𝑆𝑎𝑡_𝑂𝑢𝑡 = {(𝑆𝑏 ,𝐵𝑒ℎ_𝐿𝑎𝑏𝑒𝑙 )}; where
𝑖 𝑘 𝑘
𝐵𝑒ℎ_𝐿𝑎𝑏𝑒𝑙 𝑖𝑠 𝐺 (𝐺𝑜𝑜𝑑) 𝑜𝑟 𝐵 (𝐵𝑎𝑑) 𝑜𝑟 𝐺𝐵 𝑒𝑞𝑢𝑎𝑙
𝑘 𝑘 𝑘 𝑘 8. Conclusion
𝑛𝑢𝑚𝑏𝑒𝑟𝑜𝑓 𝑔𝑜𝑜𝑑 𝑎𝑛𝑑 𝑏𝑎𝑑 𝑠𝑒𝑐𝑢𝑟𝑖𝑡𝑦𝑏𝑒ℎ𝑎𝑣𝑖𝑜𝑟
8: endfor
9: endfor We were able to provide a solution that supports the concept of
10: endfor Zero Trust by eliminating the trust, that all users act responsibly.
11: forall𝑖∈{1,…,𝑛} do Mostimportantly,weachievedsuccessinansweringtheresearchques-
12: forall𝑘∈{1,…,𝑝} do tion ‘‘How to automatically identify users security practices and then
13: From𝑆𝑎𝑡_𝑂𝑢𝑡 𝑖 Extractbehavior𝑆𝑏 𝑘 and𝐵𝑒ℎ_𝐿𝑎𝑏𝑒𝑙 𝑘 generatesecuritypolicyafterobservingandanalyzingsecuritybehav-
14: if{𝑆𝑏 𝑘∶𝐵𝑒ℎ_𝐿𝑎𝑏𝑒𝑙 𝑘==𝐺 𝑘}then iors,especiallysecurity-relateddecisions,exhibitedbyend-usersinan
15: 𝑃 =𝑟 ;Least restrictive policy
𝑡𝑦𝑝𝑒𝑖𝑘 𝑖 environment with Zero Trust assumptions?’’ In our approach, Finite-
16: elseif{𝑆𝑏 ∶𝐵𝑒ℎ_𝐿𝑎𝑏𝑒𝑙 ==𝐵 }then
𝑘 𝑖 𝑘 StateAutomatasupportedmodelingusersecuritybehavior.Itallowed
17: 𝑃 =𝑠 ;Strict security policy
𝑡𝑦𝑝𝑒𝑖𝑘 𝑖 showinghowausercouldtransitionfromsafetounsafestatebasedon
18: else
making some specific decisions. TCTL language was used to generate
19: 𝑃 =𝑚 ;Moderate security policy
20:
end𝑡𝑦 i𝑝 f𝑒𝑖𝑘 𝑖
linear-time properties, and thus, with reachability analysis we could
21: STOREpolicy𝑃𝑜𝑙𝑖𝑐𝑦 ={𝑃 } checkthesatisfactionofthesecuritybehavior.Afterobservingsecurity
𝑖 𝑡𝑦𝑝𝑒𝑖𝑘
22: endfor behavior and analyzing security behavior, the appropriate policy was
23: PRINT𝑃𝑜𝑙𝑖𝑐𝑦 𝑖={𝑃 𝑡𝑦𝑝𝑒𝑖1,...,𝑃 𝑡𝑦𝑝𝑒𝑖𝑘,...,𝑃 𝑡𝑦𝑝𝑒𝑖𝑝} assignedtoaddresssecuritygapscausedbyspecificuser.
24: endfor Our approach demonstrated if we can categorize the behavior of
users and capture relevant information regarding the behavior, it en-
ables automated reasoning to then identify weaknesses in a users
behaviortogeneratespecificpolicies.Futureworkinvolvesdeveloping
1. 𝑃𝑜𝑙𝑖𝑐𝑦 𝑇𝑜𝑚 = {DS(G), PG(G), PA(B), U(B)} = ⟨ 𝑟 𝑇𝑜𝑚, 𝑟 𝑇𝑜𝑚, 𝑠 𝑇𝑜𝑚,
surveys to evaluate if there are more selection predictors. Another
𝑚 𝑇𝑜𝑚 ⟩
extensionistoapplythemethodtoaccessingnetworkbasedservices,
2. 𝑃𝑜𝑙𝑖𝑐𝑦 𝑆𝑎𝑟𝑎 = {DS(B), PG(B), PA(G/B), U(B)} = ⟨ 𝑠 𝑆𝑎𝑟𝑎, 𝑠 𝑆𝑎𝑟𝑎, basedontheanalysisdiscussedinthisresearch.
𝑚 𝑆𝑎𝑟𝑎,𝑠 𝑆𝑎𝑟𝑎 ⟩
3. 𝑃𝑜𝑙𝑖𝑐𝑦 𝑍𝑜𝑒 = {DS(G), PG(G/B), PA(NA), U(NA)} = ⟨ 𝑟 𝑧𝑜𝑒, 𝑚 𝑧𝑜𝑒, CRediTauthorshipcontributionstatement
𝑚 𝑧𝑜𝑒,𝑚 𝑧𝑜𝑒 ⟩
4. 𝑃𝑜𝑙𝑖𝑐𝑦 𝐵𝑒𝑙𝑙𝑎={DS(B),PG(B),PA(G),U(G)}=⟨𝑠 𝐵𝑒𝑙𝑙𝑎,𝑠 𝐵𝑒𝑙𝑙𝑎,𝑟 𝐵𝑒𝑙𝑙𝑎,
Arwa AlQadheeb: Acquisition of data, Analysis and/or interpre-
𝑟 𝐵𝑒𝑙𝑙𝑎 ⟩ tation of data, Writing – original draft. Siddhartha Bhattacharyya:
5. 𝑃𝑜𝑙𝑖𝑐𝑦 𝐽𝑜ℎ𝑛={DS(G),PG(G),PA(G),U(G)}=⟨𝑟 𝐽𝑜ℎ𝑛,𝑟 𝐽𝑜ℎ𝑛,𝑟 𝐽𝑜ℎ𝑛,
Conceptionanddesignofstudy,Analysisand/orinterpretationofdata,
𝑟 𝐽𝑜ℎ𝑛 ⟩ Writing–originaldraft,Revisingthemanuscriptcriticallyforimportant
6. 𝑃𝑜𝑙𝑖𝑐𝑦 𝑍𝑎𝑐={DS(G),PG(NA),PA(B),U(NA)}=⟨𝑟 𝑍𝑎𝑐,𝑚 𝑍𝑎𝑐,𝑠 𝑍𝑎𝑐,
intellectual content. Samuel Perl: Conception and design of study,
𝑚 𝑍𝑎𝑐 ⟩ Writing–originaldraft,Revisingthemanuscriptcriticallyforimportant
Sothepolicycanbereadasfollows:ForTomthepolicyengineshould intellectualcontent.
implementleastrestrictivepolicy(r)wherever,devicesecurementand
password generation are required, as he has shown good behavior Declarationofcompetinginterest
in implementing these security behaviors. Whereas, a strict policy (s)
needstobeimplementedforproactiveawareness,suchasbysending The authors declare that they have no known competing finan-
morealertsorwarningsas,Tomhasshownweakbehaviorinspotting cial interests or personal relationships that could have appeared to
securitythreats.Finally,moderatepolicy(m)shouldbeimplementedin influencetheworkreportedinthispaper.
regardstoupdates,suchaswhentosendalertsorwhentoimplement
specificactionsthatneedtobetakenifupdatesarenotinstalledwithin Acknowledgment
atimeline.
Allauthorsapprovedtheversionofthemanuscripttobepublished.
7. Results
References
Using our FMUSPG framework we were able to select relevant
[1] Kindervag J, Ferrara E, Hollandand R, Shey H. Developing a framework to
user security behaviors from existing literature. We were then able
improvecriticalinfrastructurecybersecurity.Tech.rep.,ForresterResearch,Inc;
to decompose the security behaviors exhibited by users at different 2013.
10A.AlQadheebetal. Array14(2022)100146
[2] Gratian M, Bandi S, Cukier M, Dykstra J, Ginther A. Correlating human traits [26] Moura LD, Bjørner N. Z3: An efficient SMT solver. In: Proceedings of the
and cyber security behavior intentions. Comput Secur 2018;73:345–58. http: theory and practice of software, 14th international conference on tools and
//dx.doi.org/10.1016/j.cose.2017.11.015. algorithms for the construction and analysis of systems. TACAS’08/ETAPS’08,
[3] West R, Mayhorn C, Hardee J, Mendel J. Social and human elements of Berlin:Heidelberg:Springer-Verlag;2008,p.337–40,http://dl.acm.org/citation.
information security: Emerging trends and countermeasures. Hershey, PA: IGI cfm?id=1792734.1792766.
Global;2009,p.43–60.http://dx.doi.org/10.4018/978-1-60566-036-3.ch004. [27] BengtssonJ,LarsenK,LarssonF,PetterssonP,YiW.Uppaal:Atoolsuitefor
[4] SecurityI.Costofadatabreachreport.Tech.rep.,PonemonInstitute;2019. automaticverificationofreal-timesystems.TheoretComputSci1996.
[5] Egelman S, Peer E. Predicting privacy and security attitudes. ACM SIGCAS [28] LarsenKG,PetterssonP,YiW.Model-checkingforreal-timesystems.In:Proc.
ComputSoc2015;45(1):22–8.http://dx.doi.org/10.1145/2738210.2738215. of fundamentals of computation theory. Lecture notes in computer science,
[6] Canali D, Bilge L, Balzarotti D. On the effectiveness of risk prediction based (965):1995,p.62–88.
on users browsing behavior. In: ASIA CCS ’14 proceedings of the 9th ACM [29] Alur R, Dill DL. A theory of timed automata. Theoret Comput Sci
symposiumoninformation,computerandsecurity.NewYork,NY:ACM;2014, 1999;126:183–235.
p.171–82.http://dx.doi.org/10.1145/2590296.2590347. [30] Bozga M, Daws C, Maler O, Olivero A, Tripakis S, Yovine S. KRONOS: A
[7] MitnickKD,SimonWL,WozniakS.Theartofdeception:Controllingthehuman model-checking tool for real-time systems. In: Proceedings of the 10th inter-
elementofsecurity.Hoboken,NJ:Wiley;2002. nationalconferenceoncomputeraidedverification(CAV’98),Vol.1998.Berlin:
[8] Curzon P, Rukše˙nas R, Blandford A. An approach to formal verification of Heidelberg:Springer-Verlag;1998,p.546–50.
human–computerinteraction.FormAspComput2007;19(4):513–50.http://dx. [31] BehrmannG,DavidA,LarsenKG.Atutorialonuppaal4.0.2006.
doi.org/10.1007/s00165-007-0035-6. [32] Olmstead K, Smith A. Americans and cybersecurity. Tech. rep., Paw Research
[9] AD,M.H. Center;2017.
[10] Bolton M, Bass E, Siminiceanu R. Using formal verification to evaluate [33] AlbayramY,KhanMMH,JensenT,NguyenN.‘‘...Bettertousealockscreenthan
human-automation interaction: A review. Syst, Man, Cybern: Syst, IEEE Trans toworryaboutsavingafewsecondsoftime’’:Effectoffearappealinthecontext
2013;43:488–503.http://dx.doi.org/10.1109/TSMCA.2012.2210406. ofsmartphonelockingbehavior’’.In:Proceedingsofthethirteenthsymposium
[11] HouserA.Mentalmodelsforcybersecurity:Aformalmethodsapproach.2018. onusableprivacyandsecurity.Berkeley,CA:USENIX;2017,p.49–63.
[12] Egelman S, Peer E. Scaling the security wall: Developing a security behavior [34] SupportM.Howtochangethelogonscreensaverinwindows.2018.
intentions scale (SeBIS). In: CHI ’15 proceedings of the 33rd annual ACM [35] Cappelli D, Moore A, Shimealland TJ, Trzeciak R. Common sense guide to
conferenceonhumanfactorsincomputingsystems.NewYork,NY:ACM;2015, preventionanddetectionofinsiderthreats.2006.
p.2873–82.http://dx.doi.org/10.1002/andp.19053221004. [36] Barrett D, Hausman KK, Weiss M. CompTIA Security+ SY0-401 Exam Cram.
[13] ChenB,etal.Asecurityawarenessandprotectionsystemfor5Gsmarthealthcare Hoboken,NJ:PearsonITCertification;2015,p.422–37.
basedonzero-trustarchitecture.IEEEInternetThingsJ2020;403–16. [37] LastPass.LastPasspsychologyofthepassword.Tech.rep.,LastPass;2016.
[14] Mandal S, Khan DA, Jain S. Cloud-based zero trust access control policy: An [38] MartinS,TokutomiM.Passwordcracking.2012.
approachtosupportwork-from-homedrivenbyCOVID-19pandemic.NewGener [39] Maddox I, Moschetto K. Modern password security for users: User-focused
Comput2021;39.3:599–622. recommendationsforcreatingandstoringpasswords.2019.
[15] Eidle D, et al. Autonomic security for zero trust networks. IEEE 8th Annual [40] Ives B, Walsh KR, Schneider H. The domino effect of password reuse.
UEMCON;2017. Human-Comput Etiquette 2004;47(4):75–8. http://dx.doi.org/10.1145/975817.
[16] DeanE,etal.Towardazerotrustarchitectureimplementationinauniversity 975820.
environment,Vol.6.4.TheCyberDefenseReview;2021,p.37–48. [41] Verizon.Databreacheinvestigationsreport.Tech.rep.,Verizon;2019.
[17] WestR.Thepsychologyofsecurity.PsycholSecur:WhyDoGoodUsersMake [42] ofHomelandSecurityUD.Ifyouseesomething,saysomething.2015.
BadDecis?2008;51(4):34–40.http://dx.doi.org/10.1145/1330311.1330320. [43] Easen N. Speed is key in tackling data breach fallout. Raconteur: Cybersecur
[18] Herley C. So long, and no thanks for the externalities: The rational rejection 2019.
of security advice by users. In: NSPW ’09 proceedings of the 2009 workshop [44] Alotaibi M, Furnell S, Clarke N. Information security policies: A review of
on new security paradigms workshop. New York, NY: ACM; 2009, p. 133–44. challengesandinfluencingfactors.In:11thInternationalconferenceforinternet
http://dx.doi.org/10.1145/1719030.1719050. technologyandsecuredtransactions.NewYork,NY:IEEE;2016,http://dx.doi.
[19] HaleviT,MemonN,LewisJ,KumaraguruP,AroraS,DagarN,etal.Cultural org/10.1109/ICITST.2016.7856729.
andpsychologicalfactorsincyber-security.In:IiWAS’16proceedingsofthe18th [45] Pahnila S, Siponen M, Mahmood A. Employees’ behavior towards IS security
internationalconferenceoninformationintegrationandweb-basedapplications policy compliance. In: 2007 40th Annual Hawaii international conference on
andservices.NewYork,NY:ACM;2016,p.318–24.http://dx.doi.org/10.1145/ system sciences. New York, NY: IEEE; 2007, http://dx.doi.org/10.1109/HICSS.
3011141.3011165. 2007.206.
[20] Baier C, Katoen JP. Principles of model checking. Cambridge, MA: MIT Press; [46] Vaniea KE, Rader E, Wash R. Betrayed by updates: how negative experiences
2008. affect future security. In: CHI ’14 proceedings of the SIGCHI conference on
[21] SecurityI.Costofadatabreachreport.Tech.rep.,PonemonInstitute;2019. human factors in computing systems. New York, NY: ACM; 2014, p. 2671–4.
[22] P.CP.RTLhardwaredesignusingVHDL:Codingforefficiency,portability,and http://dx.doi.org/10.1145/2556288.2557275.
scalability. Hoboken, NJ: Wiley; 2006, p. 313–71. http://dx.doi.org/10.1002/ [47] Sarabi A, Zhu Z, Xiao C, Liu M, Dumitras T. Patch me if you can: A study
0471786411.ch10. on the effects of individual user behavior on the end-host vulnerability state.
[23] CimattiA,ClarkeE,E.G,F.G,M.P,M.R,etal.NuSMV2:AnOpenSourcetool In:18thInternationalconferenceonpassiveandactivenetworkmeasurement.
forsymbolicmodelchecking.In:CAV’02Proceedingsofthe14thinternational Cham,Switzerland:Springer;2017,p.113–25.http://dx.doi.org/10.1007/978-
conference on computer aided verification. Berlin, Heidelberg: Springer; 2002, 3-319-54328-4_9.
p.359–64.http://dx.doi.org/10.1007/3-540-45657-0_29. [48] WashR,RaderE,VanieaK,RizorM.Outoftheloop:Howautomatedsoftware
[24] Uppaal.Uppaalwebsite.2010,http://www.uppaal.org. updatescauseunintendedsecurityconsequences.In:10thSymposiumonusable
[25] OwreS,RajanS,RushbyJM,ShankarN,SrivasM.PVS:Combiningspecification, privacyandsecurity.Berkeley,CA:USENIX;2014.
proof checking, and model checking. In: 1996 Proceedings of computer aided [49] Kong S, Gao S, Chen W, Clarke E. dReach: 𝛿-reachability analysis for hybrid
verification:8thinternationalconference.Berlin,Heidelberg:Springer;1996,p. systems. In: 21st International conference on tools and algorithms for the
411–4.http://dx.doi.org/10.1007/3-540-61474-5_91. construction and analysis of systems. Berlin/Heidelberg: Springer; 2015, p.
200–5.http://dx.doi.org/10.1007/978-3-662-46681-0_15.
[50] Eleftherakis G, Kefalas P. Advances in signal processing and computer
technologies.WorldScientificandEngineeringSocietyPress;2001,p.321–6.
11