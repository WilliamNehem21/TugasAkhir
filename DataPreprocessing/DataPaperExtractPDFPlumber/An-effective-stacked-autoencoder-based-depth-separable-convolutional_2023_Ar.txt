Array19(2023)100294
Contents lists available at ScienceDirect
Array
journal homepage: www.sciencedirect.com/journal/array
An effective stacked autoencoder based depth separable convolutional
neural network model for face mask detection
Sundaravadivazhagan Balasubaramanian*, Robin Cyriac, Sahana Roshan,
Kulandaivel Maruthamuthu Paramasivam, Boby Chellanthara Jose
University of Technology and Applied Sciences - Al Mussanah, Department of Information Technology, Al Muladdah, 314, South Al Batinah, Oman
A R T I C L E I N F O A B S T R A C T
Keywords: The COVID-19 pandemic has been infecting the entire world over the past years. To prevent the spread of COVID-
COVID-19 19, people have acclimatised to the new normal, which includes working from home, communicating online, and
Stacked auto encoder maintaining personal cleanliness. There are numerous tools required to prepare to compact transmissions in the
Principal component analysis
future. One of these elements for protecting individuals from fatal virus transmission is the mask. Studies have
Depth-wise separable convolutional neural
indicated that wearing a mask may help to reduce the risk of viral transmission of all kinds. It causes many public
network
places to take efforts to ensure that its guests wear adequate face masks and keep a safe distance from one
Machine learning
Deep learning another. Screening systems need to be installed at the doors of businesses, schools, government buildings, private
offices, and/or other important areas. A variety of face detection models have been designed using various al-
gorithms and techniques. Most of the articles in the previously published research have not worked on dimen-
sionality reduction in conjunction with depth-wise separable neural networks. The necessity of determining the
identities of people who do not cover their faces when they are in public is the driving factor for the development
of this methodology. This research work proposes a deep learning technique to determine if a person is wearing
mask or not and identifies whether it is properly worn or not. Stacked Auto Encoder (SAE) technique is
implemented by stacking the following components: Principal Component Analysis (PCA) and Depth-wise
Separable Convolutional Neural Network (DWSC-NN). PCA is used to reduce the irrelevant features in the im-
ages and resulted high true positive rate in the detection of mask. We achieved an accuracy score of 94.16% and
an F1 score of 96.009% by the application of the method described in this research.
1. Introduction advancements. However, it is challenging for several different industries
to adapt to this new norm.
Because of the tremendous advancements in science and technology, People are still reluctant to go back to work even though the virus
it has progressed to the point where they can perform tasks that were will eventually be eradicated, and such sectors are becoming increas-
thought to be impossible a few decades ago. The development of tech- ingly eager to begin employing people face-to-face. 65% of workers
nologies such as Artificial Intelligence (AI) and Machine Learning (ML) today report feeling anxious about returning to the workplace [1]. Since
has made people’s lives easier and provided solutions to a lot of difficult the beginning of the viral pandemic, researchers from all over the world
problems in a wide range of fields. Algorithms used in modern computer have been looking for answers and strategies that will stop the spread.
vision are growing ever closer to being able to execute tasks of visual The current virus travels through the respiratory system of the patient to
perception on par with humans. From the classification of pictures to the the lung cells, where it then causes direct harm. The most effective
analysis of videos, computer vision has proven to be a game-changing strategy to stop the transmission of the virus is to keep distance from
component of today’s technology. Currently, technology is a saviour other people and always wear a mask when in a busy or public place.
for fighting viral infections and preparing ourself for any further out- To begin, masks are not obligatory for everybody, but researchers
breaks in the future. The concept of “work from home” has largely and medical professionals are becoming more and more inclined to
helped replace the traditional workday schedules in most industries and propose that everyone use masks. According to the findings of several
become ingrained in everyday life as a result of technological studies [2], wearing a face mask reduces the likelihood of viral
* Corresponding author.
E-mail address: sundaravadi@act.edu.om (S. Balasubaramanian).
https://doi.org/10.1016/j.array.2023.100294
Received 24 January 2023; Received in revised form 8 May 2023; Accepted 14 May 2023
Availableonline5June2023
2590-0056/©2023TheAuthor(s).PublishedbyElsevierInc.ThisisanopenaccessarticleundertheCCBYlicense(http://creativecommons.org/licenses/by/4.0/).S. Balasubaramanian et al. A r r a y 19(2023)100294
transmission and provides the user with a sense of safety. Face masks are face mask detection. PCA is an important technique for face mask
recommended for use to prevent the virus from spreading. This recom- detection using deep learning because it helps to reduce the dimen-
mendation comes from the World Health Organization as well as other sionality of the input data while retaining the most important features.
health organisations for most viral spreads that can hurt the respiratory In face mask detection, the input data is typically a set of images con-
system. Although every government tries to mandate the use of face taining faces with and without masks. These images can be high-
masks in public spaces, it might be difficult to manually identify those dimensional, with each pixel representing a separate feature. Howev-
who are not complying with this requirement in crowded environments. er, not all these features are equally important for the task of face mask
Researchers have been working to develop automated systems that detection. Some features may be redundant or irrelevant, while others
can identify people using face masks in public locations and enforce may be critical for distinguishing between masked and unmasked faces.
their use. It is impossible to manually monitor this policy on a large scale The primary objective of this research study is to develop a deep
and keep track of any infractions because of the large volume of viola- learning model that is capable of recognising individuals who are not
tions. The use of computer vision offers an alternative that is more wearing face masks. The proposed model makes use of MobileNetV2’s
desirable. Integrating object detection, object tracking, and image transfer learning in conjunction with surveillance cameras in order to
classification resulted in the creation of a sophisticated system that is identify individuals in public places who are not wearing masks. Image
capable of recognising face masks in both still photographs and moving augmentation techniques are utilised to broaden the scope of the
images. This was accomplished by combining the above mentioned four training data in order to optimise the functionality of the recommended
concepts. model. The following is a list of the primary contributions that the
The processing of digital photographs by a computer is referred to as proposed effort will make:
“digital image processing,” and it is accomplished using a powerful
digital computer. It is also possible to claim that it is the utilisation of • Conducted a literature review to gain a better knowledge of the harm
computer algorithms to improve the image and extract some significant caused by respiratory viral transmissions as well as the latest
data. The processing of images also involves significantly completing the research works on deep learning models for face mask detection.
following steps [3]: • Constructed a facemask detector to assist in the precise real-time
detection of a mask using picture and video streams.
• Importing the photograph by means of image capture software. • PCA is used to reduce the irrelevant features extracted from the
• Analysing and altering the photograph. images.
• Producing output, the result of which may be a modified image, or a • The proposed model makes use of well-known depth wise separable
report based on the evaluation of that photograph. convolutional neural networks techniques to build the classifier,
collect images of people wearing masks, and differentiate between
In recent years, there has been a lot of focus placed on Deep Learning classes of face masks and non-facial masks. This activity is accom-
(DL), particularly in areas such as computer vision, computational lin- plished by utilising Open-CV, Keras, and Python.
guistics, object classification, and other elements of information pro- • When compared to other models, the model that was proposed has a
cessing. Many previous studies on object identification have made use of smaller memory footprint and a shorter computation time.
models that are based on convolutional neural networks. There has been • The article offers suggestions for new lines of inquiry based on the
a boom in the use of CNNs, for several applications, including voice findings, with the goal of developing AI algorithms that are reliable
synthesis, picture identification, image thresholding, and object and effective, and which are capable of recognising faces in their
tracking, among others. The disciplines are well-suited to the data natural environments.
extraction capabilities of CNN, which are quite good. CNNs are quickly
becoming the method of choice for a rising number of research projects, The following outline has been chosen for this research article: The
which are looking to improve their ability to collect visual data and techniques of image processing and deep learning are utilised in the
produce more accurate classifications than they could with previous discussion of the current state of the art (SOTA) of face mask identifi-
classification approaches. There are several deep neural networks that cation in section 2. In addition to this, it addresses the problems and
are not ideal for mobile-based facial picture categorization because of difficulties associated with face mask detection approaches. In section 3,
resource constraints, the length of time and amount of money required you will find a full presentation of the research methods. It describes the
for their evaluation phase, and the possibility of false positives. anticipated study endeavour and includes an in-depth architectural
The problem can be summed up as follows: when performing a mask breakdown of the architecture. Section 4 provides an in-depth presen-
detection job, the classification model is required to categorise the facial tation of the datasets that were utilised for this body of research work, as
image based on the input of a face image. This research is successful in well as the experimental setup, trial findings, and related examinations.
developing the model with fewer learnable parameters and a smaller The research is ended in section 5. It comprises a summary as well as the
total number of learnable parameters by employing deep separable potential improvements that can be made in the future because of the
convolution layers rather than conventional convolutional layers. research work.
This study proposes a model for categorising facial photos based on
MobileNet. To handle this challenge, the model utilises the Depth Wise 2. Literature review
Separable Convolution (DWSC) technique. DSC is widely used in the
process of identifying issues that arise in image processing. In the William Wells, a professor of engineering at Harvard, and his wife,
beginning, it was presented in the article published by Laurent Sifre and Mildred Wells, a physician, began using more modern experimental
St´ephane Mallat [3]. DWSC is a quantized variation of the conventional methods to investigate airborne transmission in the 1930s [4]. Infec-
convolution. tious particles and droplets containing germs are discharged when a
Depth-wise and 1-point convolutions are two categories that are person has a cold or illness [5]. The resolution limit for viruses is
frequently used to categorise convolutions. Instead of using all input extremely tiny, much smaller than the one-to two-micron range and is in
channels as in standard convolution, the DWSC layer applies one the five-to-ten-micron region. There are several examples of respiratory
filtering to a single pulse. The DWSC outputs are then aggregated using a viruses involved; regrettably, this happens to them as well [6]. During a
single matrix pointwise convolution. DWSC reduces both the number of few pandemic pathogenicity outbreaks, numerous attempts to prevent
parameters that may be learned and the complexity of the test and train or reduce airborne infections were made during this time. This contrasts
simulations. from all other types of airborne diseases, which are distributed by air
In the previous study, PCA along with DWSC is not experimented for pollutants and may move up to 1 m in the air for lengthy periods of time,
2S. Balasubaramanian et al. A r r a y 19(2023)100294
in that airborne infections must be trapped within droplets to transmit of the colour pattern in pictures and line portraits.
and spread. The condition identification approach was utilised in the construc-
It was previously thought that COVID-19 was transmitted through tion of Qin and Li’s [19] face mask detection model. In the paper, the
the respiratory system; however, research then showed that airborne issue was dissected into four distinct parts: pre-processing the picture,
transmission was the primary mode of infection [7]. To control airborne clipping the facial portions, performing the super-resolution procedure,
infections effectively, a wide range of strategies needed to be employed. and forecasting the final condition. The utilisation of super-resolution as
This is necessary since diverse organisations hold varying opinions a means of enhancing the functionality of images of lower quality was
regarding the efficacy of certain strategies. Both air circulation and the key contribution made by this research.
droplet dispersion have been the subject of a significant amount of For facial detection in Ref. [20], the authors make use of the
research [8], with the goal of gaining a deeper comprehension of how to Darknet-53 (YOLOv3 algorithm). Machine learning and artificial intel-
achieve maximum droplet dispersion. The term “respiratory system” ligence are the two primary components of deep learning, which is
refers to the mechanism within the body that is responsible for breath- largely a blend of the two. In general, it has been demonstrated to be
ing. When utilised near the source of an illness, active protective tech- more adaptive and to develop more exact models than ML that is
niques such as respiratory area cleaners and air purifiers can assist in inspired by the operation of brain cells [21].
reducing the risk of exposure [9]. A method of detection that relies on mobile phones was developed by
Examples of respirators that protect the user from infection while the authors of [22]. From the Gray-Level Co-Occurrence Matrix (GLCM)
still offering occupational safety include face masks and N95 respirators of face mask micro images, it was able to obtain three different aspects.
[10]. There is a greater need for respirators even though face masks are The KNN algorithm was utilised to carry out a three-result recognition
less expensive and simpler to use, and more testing of their effectiveness analysis, which ended up having an accuracy rating of 82.87% overall.
has further improved those requirements [11]. Their initial goals were The system made use of a gray level co-occurrence matrix to determine
wound dressings, nontemporal surgical exposure to airborne microbes the presence of face masks in micro photos. However, given that the
[12], other significant issues regarding airborne infectious illnesses like model was only compatible with mobile phones, it was clear that it could
TB, particularly among the public, and traditional treatments including not be used in all situations.
the use of masks. The authors of the study [23] suggested that a pre-trained MobileNet
Some studies try to prove that face masks have been demonstrated to equipped with a global pooling block ought to be utilised for the pur-
be of little benefit [13], even if there is no evidence that they reduce the poses of facial recognition and detection. A shaded image is used as the
prevalence of respiratory infections and some of the assumptions about starting point for the creation of a multi-dimensional component map by
their efficacy are up for debate. But new studies have shown that using a the pre-configured MobileNet. Because it makes use of an overall pool-
face mask can help prevent the flu, even in otherwise healthy in- ing block, the model that was proposed does not suffer from the issue of
dividuals. Although face masks were more useful but had limited effi- over-fitting.
cacy, a systematic review of randomised controlled trials evaluating the Facial expressions and face mask detection are related in the sense
effectiveness of respirators and face masks against respiratory viruses that they both involve analyzing features of the face. Facial expressions
found that nurses were better protected. Respirators worn by healthcare are typically used to infer emotions or mood from the face, while face
workers also seemed to be effective, but the results only indicated mask detection is used to determine whether a person is wearing a mask
temporary efficacy. over their face or not. In recent studies [25,26], the authors used
Early on, the researchers largely concentrated on a few techniques, directional gradients techniques to recognise the face and expressions of
such as the Gray-scale facial picture algorithms [14]. While AdaBoost, face. Yassine et al. [27] published a review paper on the recent works in
one of the top classifiers at the time, processed the initial information of face mask detection. The paper described the various parameters that
the face models, a small number of others concentrated on pattern have been used to evaluate the face mask detection.
detection techniques. Real-time face detection was made possible later To hasten the development of automated face mask recognition and
with the development of the Viola-Jones detector. But it had a problem: social distance measuring on public spaces, the authors in [28] have
the dull, low light made it unable to function effectively, and the low used a massive dataset made up of 10,000 pictures that have been
light source made it unable to categorise properly. Additional hypoth- divided into two categories: those wearing face masks and those who are
eses have evolved to elucidate these notions, describing the same views not. The paper provided a complete pipeline for doing outside real-time
in further depth. It has been revealed without doubt that many viruses face mask identification and social distance measuring.
can spread by airborne pathways. The following Table 1 depicts the comparison of some notable works
In the recent past, there has been a trend toward the development of in the proposed problem domain based on different parameter. The
object recognition algorithms that utilise deep learning models rather mentioned articles in Table 1 are the most relevant to the problem
than shallow models [15]. This trend has resulted in deep learning
models being theorised to be superior to shallow models in terms of their
ability to perform complex tasks. A good illustration of this would be the Table 1
Comparison of existing work on face mask detection.
development of a model or system that operates in real time and is able
to determine whether or not individuals in public locations are wearing Ref. Techniques Datasets Achievements Accuracy
masks. (%)
Real-time deep learning was utilised by Shaik and Ahlam [16] to [18] HGL MAFA It able to identify the Front face
classify and distinguish emotions, while VGG-16 was used to categorise face mask on the side- – 93%
by-side position. Side face –
seven faces. This strategy functions well during the current Covid-19
87%
lock-down phase, which is intended to stop the further spread of the
[23] MobileNet with a Kaggle It added global 99
disease. In addition, Ejaz et al. [17] made use of main component global pooling block pooling block to
analysis to differentiate between people who had their faces masked and for face mask perform a flatten of
those who had their faces exposed. detection the feature vector.
[28] Improved feature 10,000 Improved YOLO-v3 95
Using CNN, face mask detection was implemented by Li et al. [18]. It
extraction and real-time outperformed well
could identify whether an individual was wearing a mask or not to track region proposal images than the existing
and enforce compliance to directives given by competent authorities. generation layers on baseline techniques
The authors came up with the HGL approach to categorise head postures the YOLO V3
architecture
by making use of masks for faces. This method involved the examination
3S. Balasubaramanian et al. A r r a y 19(2023)100294
domain. puts on a mask and applies it correctly, the remaining procedures can
In the previous studies, the YOLO-v3, MobileNet and Inception were continue. Because of this, everyone will be safe from the respiratory
used along with various techniques for detecting the mask on the face. droplet transmissions so long as they wear their masks appropriately. In
The proposed work aims to reduce the dimensions of the datasets using this way, the utilisation of this technology will contribute to the
PCA technique. It is worth noting that there exists a paucity of research reduction in the proliferation of any droplet-based transmissions. If the
on the application of a stacked autoencoder-based deep learning model system recognises the user’s face while they are not wearing a mask or
with principal component analysis for face mask detection. The objec- when the mask is not worn in the correct manner, it will notify the user
tive of the proposed study is to construct a deep learning framework and sends an alert to the governance system. The workflow flowchart for
utilising MobileNET-v2 architecture in conjunction with a stacked auto the complicated construction is depicted in Fig. 1.
encoder. The images undergo pre-processing by PCA, which serves to The proposed work starts out by having the datasets imported into it.
decrease dimensionality and reduce time complexity. Image processing scrubs the unprocessed data and sends it on to sub-
sequent steps where it is augmented with further information. The
3. Proposed methodology datasets are first partitioned into train and test data before the
augmentation of the data takes place. The well-known ratio of 80:20 is
Within the scope of this study, an attempt is being made to investi- utilised for both the test data and the train data. The data from the train
gate a variety of significant facets of face mask identification. The is modified before being fed into the suggested deep learning model
objective of face detection is to search for and determine the identities of known as DWSC-PCA-SAE (Depth-wise Separable Convolutional Neural
all faces that may be seen in an image or video. If there are numerous Network using Principal Component Analysis and Stacked Autoen-
faces, each one will have a bounding box surrounding it. This will allow coder). The model is put through its work, and the outcomes are assessed
other people to locate each individual face if there are multiple faces. in further sections.
The modelling of human faces is difficult due to the large number of
variables that might change, including facial expression, direction, 3.2. Image pre-processing
illumination, and partial occlusions caused by objects such as sun-
glasses, scarves, and masks, amongst other things. The outcome of the Before moving on to the testing and training of the model, it is
detection offers the face location parameters, which may be required in necessary to complete this crucial phase, which assists in the processing
a variety of different shapes, such as a rectangle containing the middle of the data. As soon as it reaches this point, it will initiate the process of
section of the face, eye centres, or characteristics such as the corners of turning all of the images that are contained within the dataset files into
the mouth and nose, the eyebrows, the nostrils, etc. arrays. It will develop the deep learning module by utilising these arrays
It is common practise to identify things based on the unique qualities as its building blocks and all the relevant tools are going to be imported
that they possess. A human face can be distinguished from a wide variety from the corresponding modules. Then, following the completion of the
of other things due to the fact that it possesses a number of distinctive data processing and the delivery of the conclusions to user in the form of
traits. It does this by isolating structural features of the face, such as the labels and then it will proceed to construct the variables and objects.
eyes, nose, and mouth, and then utilising those features to determine the The device’s built-in camera’s video input will be recognised by the
identity of a face. A statistical classifier is helpful in most situations for Haar cascade classifier. Before proceeding to the next stages, pre-
distinguishing between areas of the face and areas that do not contain processing is necessary for video and image data captured by the sys-
faces. Additionally, human faces have distinct textures that can be used tem’s camera. The RGB colour image contains a lot of extraneous data
to differentiate them from the textures of other objects. In addition, one that is not required for mask detection, thus during pre-processing the
can identify elements on a face by looking at the boundaries of the image is changed to a grayscale image. To maintain the input picture
characteristics that make up that item. In the following section, it will consistency across the model, it then scaled the image to 224 × 224
utilise OpenCV to design a feature-based approach, and then it will use pixels. The acquired pictures are then normalised, resulting in pixel
NumPy to evaluate that approach. values that range from 0 to 1. The normalization helps the learning
Image-based systems frequently utilise statistical analysis and ma- system understand and pick up the necessary information from the
chine learning approaches to detect the significant characteristics of photos more quickly.
photographs containing faces and pictures containing objects other than
faces. When it comes time to detect faces, the learned characteristics are 3.3. Data augmentation
use in the form of distribution models or discriminant functions. This
strategy implements several different methodologies, such as neural The training of the DWSC-PCA-SAE model requires an enormous
networks, HMM (Hidden Markov Model), SVM (Support Vector Ma- quantity of data in order to be carried out effectively. This is because
chine), and AdaBoost learning, among others. In the following section, there is not currently adequate data for training the model that has been
we will investigate how to use MTCNN, which stands for Multi-Task suggested. This is due to the requirement of providing the model with an
Cascaded Convolutional Neural Network and is an image-based acceptable quantity of data while it is being trained. The method of data
approach of face recognition. augmentation is going to be utilised to get to the bottom of this issue. In
In this research work, a new method of facial identification has been this process, the picture is transformed in a variety of ways, such as by
developed, and it makes use of complex depth-wise separable convolu- rotating it, zooming it, moving it, severing it, and flipping it, to obtain
tional neural networks in conjunction with principal component several different copies of the same image. Specifically, the image is
analysis. sheared, moved, rotated, and flipped. In the model that has been
described, the process of data augmentation includes the utilisation of
3.1. Stacked autoencoder based depth separable convolutional neural image augmentation as one of its components. Creating a portrait called
network model for face mask detection “image data creation” is a function that is designed for the goal of
improving images. Test and training sets of data are both returned by
A sophisticated framework successfully developed has been this function. The parameters for data augmentation are outlined in
demonstrated in this article for the purpose of identifying masks in the Table 2, which may be found here.
face of individuals. The learning architecture generates results by clas-
sifying the input picture according to whether it has a mask. These 3.4. Dimensionality reduction
findings are output. A warning is displayed if an individual is not
wearing a mask or is not correctly applying it to their face. If the user This method not only ensures that an adequate quantity of
4S. Balasubaramanian et al. A r r a y 19(2023)100294
Fig. 1. Proposed workflow.
features down to a smaller set of ‘y’ features. These linear combinations
Table 2
have as their goal the decoupling of the new y features from one another
Parameters for data augmentation.
while simultaneously increasing the sample variance. The process in-
Technique Parameter volves in the PCA is given in the algorithm 1.
Rotation (cid:0) 30o to 30o In order to perform face recognition, it must first train a dataset and
Gaussian Blur (in %) 25, 50, 75, 100 then apply PCA to the trained dataset. In the beginning, it will need to
Sharpness (in %) 50, 100, 150, 200 transform the train dataset into a face vector. Every two-dimensional
Emboss (in %) 50, 100, 150, 200
Shearing X and Y axis 10o train picture (x, y) is transformed into a one-dimensional face vector
Gaussian Noise 0.1 to 0.9 (x⋅y by 1). After all the pictures have been converted, they are loaded
Jitter (cid:0) 4 to 4 into the stack-autoencoder process. In this body of work, the total
Flips Horizontal and Vertical number of ‘n’ images is taken. Here, the value of ‘n’ is determined by the
total number of pictures generated after the augmented data for
training, and ‘P’ is a variable that loads each image. The mean value of
information is preserved for deep learning, the extraction of picture
augmented data is evaluated by using the following equation (1),
features, and the categorization of images, but it also shortens the
amount of time that is required for training and testing. In its most basic 1∑n(cid:0)1
form, data dimensionality reduction is the process of mapping data from M= n Pix(n) (1)
their original, high-dimensional space to their final, low-dimensional
i=0
space destination. Depending on whether or not labels are used in the
where M is the mean value of images taken, Pix(n) represents the pixels
process, this procedure can be further broken down into nonlinear or
of nth image.
linear or supervised or unsupervised dimensionality reduction. The
Image normalization is the important process to generate normalize
principal component analysis (PCA) and the stacked autoencoder are the
data. Normalization involves taking each image in the collection and
two dimensionality reduction components that are utilised in this
subtracting the value of image that appears on average within those
research work.
images. The final result of the normalization process is stored in the
3.4.1. Principal component analysis (PCA) variable denoted by δ n given in equation (2). After that, a new matrix ‘T’
is produced according to equation (3).
PCA is among the best approaches for dimensionality reduction in
the area of unsupervised dimensionality reduction. Simply decomposing Δ n=Pix(n)(cid:0) M (2)
the data’s eigenvalues is all that is required to reach the objectives of
data compression as well as the removal of redundancy. An image is T∈{δ 1,δ 2,δ 3,…..,δ n} (3)
another type of data that has a high degree of correlation. When it comes
Following the process of normalization, the ‘mask feature’ in the
to the extraction of characteristics from pictures, PCA performs signifi-
image that has been normalised. Later it computes the covariance matrix
cantly better. The image matrix is subjected to a variety of processes,
of the normalised vector by using equation (4). Because of the high
after which it is turned into an eigen subspace with less dimensions.
computational and memory costs associated with explicitly determining
After that, the covariance matrix is computed using the lower-
the covariance matrix, the I covariance method is rarely used in practical
dimensional matrix, as a starting point for computation. The covari-
implementations, particularly when dealing with high dimensional data
ance matrix is a representation of the relative variation that exists be-
(large ‘n’). This is primarily since it is inefficient. The computational cost
tween individual pixels in an image. After that, Eigen vectors are
of traditional covariance matrix is xy2 where ‘x’ and ‘y’ is the number of
computed using the covariance matrix as a starting point. The Eigen
row vectors and the number of elements in each row respectively. This
vectors that have the highest values are the ones that are taken into
research work uses covariance-free approach. The computational cost of
consideration to be the principal components.
covariance-free approach is 2•(xy).
In PCA, every new feature is a linear combination of previous fea-
tures, and it brings the total number of features from the original ‘x’
5S. Balasubaramanian et al. A r r a y 19(2023)100294
{ }
TX Both the output layer and the input layer have the same data size in their
Cov(T)=TX(Tr)= T yx ∗∗ xy
x∗x
(4) resp Te hc eti v ene cs oc da ele rs ’s. F oi ug t.
p
2
u
tr e op
f
r te hs ee n ht is
d
dth ee
n
a larc yh ei rt e fec atu ture
re
o
,
f
a
a lsu ot o ke nn oc wo nd e ar s.
the
Eigen value is calculated by using equation (5). coding feature, may be thought of as a characterisation of the data D that
was entered into the encoder. At the same time, the feature of the hidden
|T(cid:0) λ|=0 (5)
layer is the feature that is acquired by the dimensionality reduction of
the encoder. In this case, the data of the hidden layer H have a smaller
where T is the matrix and λ is the eigen value.
dimensionality than the data of the input layer D and the data of the
Cov(T) is a big square matrix. Calculating the eigenvalue and
eigenvector helps reduce the size of the mask/non-mask space vector,
output layer Do; this is shown by the fact that |D| is greater than |H| and |
which improves both the efficiency and accuracy of the calculation. To
Do| and that |D| is equal to |Do|. First, calculate H using the mapping
matrix H = x(D), which will take you from the input layer D to the
achieve recognition, it is necessary to compute a weight, which is then
compared with the weight of the test image. The following equation (6)
hidden layer H. Next, calculate Do using the mapping matrix Do =y(H),
helps to calculate the weight.
which will take you from the hidden layer H to the output layer Do. The
transformation may be represented by equation (7).
ω n=λX(n(cid:0) M) (6) x:α→δ
where ω is the weight of image, λ is the eigen vector, X is the matrix and y:δ→α
M is the mean value.
Algorithm 1. Dimensionality Reduction x,y=argmin||D(cid:0) y[x(D)]||2 (7)
x,y
1: Load the training data. The magnitude of the hidden space, denoted by δ, is denoted by the
2: Compute mean value using equation (1) letter α, which stands for the embedding input space (which is also
3: Compute data normalization using equation (2) known as the output space). The input space D is the element of α and
4: Find covariance-free matrix using equation (4) the characteristic space H is the element of δ are both sent to the self-
5: Find Eigen vectors and values using equation (5) encoder, and it is its job to solve the mapping (x, y) that exists be-
6: For value in eigenvalue’s: tween the two spaces in order to minimise the reconstruction error of the
7: Find the greatest eigenvalue. input feature.
8: Find the weight of image using equation (6) There is a possibility that a single autoencoder will be unable to bring
down the dimensionality of the input features. As a result, for situations
like these, we make use of stacked autoencoders. As its name indicates,
3.4.2. Stacked autoencoder (SAE) stacked autoencoders are a collection of encoders that are arranged in a
Encoding and decoding are the two parts that make up the Auto- vertical stack. The stacked autoencoder works based on the following
Encoder (AE) model, which is a representation of an unsupervised principle.
neural network. During the encoding stage, the implicit properties of the
input data are learned, and through the stage of decoding, the objective i. Train the first autoencoder based on the input data, and then
is to reproduce the correct data (input) by making use of the new fea- acquire the feature vector that was learnt.
tures that have been learned. Because the neural network model can ii. The feature vector from the previous layer is then utilised as the
understand new features more correctly and carry out the job of feature input for the layer that comes after it, and this process is
extraction, the capacity to represent features in the data that is processed continued until the training is finished.
by AE is significantly improved. Only data that are equivalent to the iii. After all of the hidden layers have been trained, the back-
training data can be compressed since the data that are created by AE are propagation algorithm (BP) is utilised to perform fine-tuning.
correlated with one another. A particular encoder is trained with the use This is accomplished by minimising the cost function and
of input from a particular class in order to accomplish the objective of updating the weights using labelled training sets.
autonomous learning from data samples. The purpose of the learning
process in AE, which falls under the domain of unsupervised learning, is 3.5. Development of deep learning architecture
to restore input without the need of labelling. One may consider it to be
composed of three layers: input layer, hidden layer, and output layer. The architecture is developed as a less complex and effective
Fig. 2. Architecture of autoencoder.
6S. Balasubaramanian et al. A r r a y 19(2023)100294
Convolutional Neural Network (CNN) model utilising libraries such as an output layer make up a network. There are several levels of convo-
TensorFlow with Keras and the OpenCV to determine whether the test lution in hidden layers. Numerous dense neural networks employ the
subjects are donning a face mask to protect themselves. The ‘work’s characteristics collected from CNNs for categorization. There are three
various aspects are all explained here. From the provided samples, the pairs of convection levels in each of the 32 formations, followed by the
deep learning architecture begins to distinguish and classify several highest pooling level. 100 kernels with a 3x3 window size and a
significant non-linear properties. To estimate the training pattern issues maximum pooling level of 2x2 window size make up the convolution
that are posed to it other than examples fed using the process depicted in layer. The highest value inside the 2x2 frame will be chosen by this layer
Fig. 3, this informed architecture is employed. The pseudocode of the after combining the results of the preceding convolution level.
proposed DWSC-PCA-SAE algorithm is given below. The number of parameters is decreased because of the local level of
performance being decreased. The computations for the network
Algorithm 2. DWSC-PCA-SAE
become easier consequently. The resolution ‘evel’s output will be flat-
tened and transformed into a 1-D array. Consequently, there are two
• Input: Image files
thick layers and a dropout layer. The dropout layer eliminates the
• Output: Mask or No-Mask
exclusion level drive to prevent network overfitting. Each neuron in the
1: Load the dataset
dense layer picks up nonlinear features as they are learned. The first
2: Load OpenCV
dense layer of 50 knots will contain the flat outcome. Finally, there is
3: Find the face in the datasets
another thick layer with two nodes that has two classes: one with a mask
4: Generate data augmentation
and the other without.
5: Perform PCA to reduce dimension
For unlabelled input, the autoencoder consists of two core models: an
6: Build DWSC-CNN using Stacked Autoencoder
encoder and a decoder. The input feature map is encoded using an
7: Load MobilNetv2
encoder, and then the feature map is decoded and rebuilt using a
8: Train model
decoder module. For a more comprehensive modelling of the features in
9: Test model
this study, it squeezed the output feature vector from the MobileNetV2
10: Classify the output
model using the encoder function of the stacked autoencoder. Global
average pooling is used to decrease the output dimensions of the
3.5.1. Depth-wise separable convolutional neural network MobileNetV2 model, which are 7 ×7 ×1280, to 1280 dimensions. The
Fig. 3 provides a visual representation of the multi-layered charac- suggested encoding technique is then given access to the output of the
teristics, as well as a comparison between traditional and depth-wise global average pooling to further extract more representative compo-
separable features. When combined, the depth-wise (dw) and point- nents for the last stage classification. The features vectors 1280 di-
wise (pw) convoluted structures produce what is known as a “Depth- mensions are first converted to 640 and then to 320 dimensions. The
wise separable” convoluted structure. The standard convolutional autoencoder complexity is mostly decreased by feature encoding uti-
structure is outperformed by the Depth-wise separable convolutional lising their halves.
structure, which offers a function that is equivalent to the previous In this research work, it employed stacked auto-encoding layers to
method but operates at a much quicker pace. Because the frames may be reduce the size of the MobileNetV2 output feature vector while main-
separated from one another in terms of depth, the offered approach does taining an abstract representation of all feature mappings. To use ReLU
not have a pooling layer in between them. To minimise the impact of the and softmax in a stacked autoencoder, it typically applies the ReLU
spatial dimension, a few of the depth-wise layers each include a stride of activation function to the hidden layers of the encoder and decoder, and
two. In this instance, the collection of output channels is also included apply the softmax activation function to the output layer of the decoder
into the point-wise layer that comes after it. when the task is multi-class classification. The weights, which include a
bias term and an ReLU activation function (given in equation (8)) are
3.5.2. DSC-PCA-SAE architecture multiplied with the data in the stacked autoencoder encoding module.
The CNN principles, which are essential for seeing patterns in pic-
ReLU:f(n)=max(0,n) (8)
tures, are used in the learning model. The neural network must be able
to view data from both classes. An input layer, many hidden layers, and
Fig. 3. Architecture of depth-wise convolutional neural network.
7S. Balasubaramanian et al. A r r a y 19(2023)100294
where ‘n’ represents the positive value return by the function and false of all the inputs. This ensures that the outputs add up to one, and can be
positive return ‘0’. The value of rectified linear unit is between ‘0’ to interpreted as probabilities of each class.
infinity. The overall proposed model can be expressed mathematically in
The first encoding layer in the suggested stacked encoded layers equation (10).
employs MobileNetV2’s output feature vector, while the next layer y=f(W 2◦f(W 1◦P x+b 1)+b 2) (10)
stacks feature from the first layer. To understand the encoded charac-
teristics before the classification layer, two fully linked (Dense) layers
where:
receive the output of the encoding layers. In the output layer, softmax is
used as the activation function and it is given in equation (9). • y is the binary classification output indicating whether the input
(cid:0) )
(cid:0) ) exp n image contains a mask or not.
softmax n j =∑ exp(nj ) (9) • P is the PCA projection matrix of size (HWC) x k. H-Height, W-Width
k
k and C-number of channels.
• x is the PCA pre-processed image.
where k is the number of classes. This means that for each class j, we take • W1 and W2 are the weight matrices of the DSCNN model.
the exponent of the input nj and divide it by the sum of the exponentials
Fig. 4. Dataset bifurcation in categories (a) with-mask, (b) without-mask.
8S. Balasubaramanian et al. A r r a y 19(2023)100294
• b1 and b2 are the bias vectors of the DSCNN model. Models for categorization were tested using the 10-fold cross-validation
• f is the activation function. method. Table 3 represents the results obtained with the training model
• +denotes element-wise addition. on Adam optimizer.
• ◦denotes element-wise multiplication.
4.3. Results
4. Results and disscussions
Table 4 depicts the comparative analysis of proposed DSC-SAE-MN
4.1. Dataset description
with AlexNet model. Proposed model outperformed well than AlexNet
model. It shown a 1.5% improvement in-terms of accuracy. Figs. 5 and 6
For training the proposed deep learning model, it has gathered a
illustrates the comparison of training accuracy with augmented and
variety of photos. CNN plays a significant role in the learning strategy’s
without augmented data. It shows that a decent improvement in the data
framework. The dataset consists entirely of facial photos. It comprises
augmentation model. Training loss is an important parameter that is
658 pictures in the category without masks and 670 pictures in the
used to evaluate the loss of a model. Figs. 7 and 8 represented the
category with masks. Ninety percent of the photos in each class are used
training loss of the proposed DSC-SAE-MN model. The proposed model
for training, while the remaining ten percent of each dataset are utilised
is compared with Alexnet [24] and the result is given in Fig. 9.
for testing. The numerous objects under each category—with mask and
A classification model can be evaluated in accordance with the
without mask—are shown in Fig. 4.
Receiver Operating Characteristic Curve (ROC) (Fig. 10), which states
The outcomes of the experiment are thoroughly explained in this that this evaluation can be done by comparing the model’s true positive
section. The Keras framework with TensorFlow as the backend is used
rate against its false positive rate at a variety of threshold values.
for all experiments, which runs on a GPU with 64 GB of RAM. The
Because lower values on the x-axis indicate a lesser number of false
datasets utilised for each model’s assessment, evaluation metrics, are all
positives and a higher number of true negatives, the fact that the curve is
included in this part. The further sections provide a brief description of
located in the top-left corner is seen as a sign of excellent performance.
each of these sections.
On the other hand, a higher significance level on the y-axis indicates a
lower number of false negatives and a higher number of real positives.
4.2. Evaluation metrics The time complexity of using PCA with DWSC for detecting masks in
the face will depend on several factors, including the size of the input
The comparison of the effectiveness of proposed algorithm makes use images, the number of principal components selected, and the archi-
of a confusion matrix. By combining the values of True Negative (TN), tecture of the DWSC. PCA involves computing the eigenvectors and ei-
True Positive (TP), False Negative (FN), and False Positive (FP), this genvalues of the covariance matrix of the input data. The time
matrix is used to generate various metrics. The performance metrics complexity of this step is typically O(n3), where n is the number of
used to assess models using the confusion matrix are listed below. features in the input data. However, there are faster algorithms such as
Accuracy is a measure of a model’s estimated value corresponds to its the Power iteration method that can reduce the time complexity to
real or actual value, which corresponds to the proportion of all samples O(k∗ n2), where k is the number of principal components selected.
that are properly categorised. The model’s accuracy is determined using The time complexity of the DWSC architecture will depend on the
the following formula: number of layers and the size of the filters used in each layer. Typically,
the time complexity of a single convolutional layer is O(k∗ n2h), where
TP+TN
Accuracy= (11) k is the number of filters, n is the size of the input feature map, and h is
TP+TN+FP+FN
the size of the filter. However, depth-wise separable convolutions are
Precision reveals the proportion of relevant occurrences among the more efficient than standard convolutions, as they require fewer pa-
chosen examples that are truly affirmative. To determine accuracy, rameters and computations. However, in general, DS-CNNs are known
apply the formula below: for their efficiency, and PCA can help to further reduce the dimension-
TP ality of the input data, potentially improving the overall speed and
Precision= TP+FP (12) performance of the system. The proposed DWSC-SAE technique was
tested on MobileNet and AlexNet architectures, and the corresponding
The percentage of genuine positives that are accurately detected is time consumption was 17.49 ms and 53.49 ms, respectively.
determined by recall or true positive rate (TPR). The following equation
is used to calculate recall:
5. Conclusion
TP
Recall= (13)
TP+FN The Mobile Net-based Depth-wise Separable Convolution Neural
Network using Principal Component Analysis and Stacked Autoencoder
The harmonic mean of accuracy and memory, which sums the
(DWSC-PCA-SAE) is proposed as a method for detecting masks in face
weighted average of precision and recall, is how the F1 score is often
pictures within the scope of this research. On several datasets, it
understood. The F1-score is calculated using the following formula:
Precision∗Recall
F(cid:0) Score= (14) Table 3
Precision+Recall
Training model on adam optimizer.
The proposed work is experimented using Windows 10 computer, an Epochs Loss Validation Loss Accuracy Validation Accuracy
Intel Core i5 processor, and Nvidia GTX 1080 GPU for the tests. Pro- 10 29.38 27.28 86.12 91.31
gramming was carried out using Python 3.8. The pre-trained model is 20 24.08 26.98 88.02 91.81
using 224x3 STIF frames. The proposed approach is tested using this 30 18.78 23.38 89.72 92.31
dataset. Datasets for training and testing have been produced. The 40 11.48 20.88 91.32 92.81
50 8.58 18.38 92.72 93.31
scaling factor was first set at 0.001, and after that, it decreases by a
60 5.68 15.88 94.62 93.81
factor of 0.9 every 10 epochs. The Adam optimizer uses a momentum 70 3.78 13.38 96.12 94.31
value of 0.999. The training process is repeated up till 100 epochs have 80 2.88 10.88 97.02 94.81
transpired. The layout of the recommended MobileNetV2 parameter 90 1.98 8.38 98.92 95.31
100 1.08 5.88 99.12 95.31
settings for efficient face picture classification (mask/no-mask) is used.
9S. Balasubaramanian et al. A r r a y 19(2023)100294
Table 4
Comparative Analysis of proposed method with existing methods.
Precision Recall F-Score Accuracy
AlexNet 0.966587 0.935335 0.950704 0.927959
Proposed 0.976134 0.944573 0.960094 0.941681
Fig. 7. Results of Training loss and validation loss.
Fig. 5. Results of training loss and validation loss – without data augmentation.
Fig. 8. Results of accuracy and validation accuracy.
Fig. 6. Results of accuracy and validation accuracy – without data
augmentation.
evaluates the results of the research in comparison to the original con-
volutional filters. According to the findings of the trials, the proposed
system performed much better than the existing conventional convolu-
tions. In addition, past work on a motivated baseline approach is
compared with the strategy that has been offered here. According to the
results, which include an accuracy score of 94.1%, a precision score of
97.6%, a recall score of 94.4%, and an F-score of 96.01%. The DWSC-
PCA-SAE algorithm generates the greatest overall performance across
a range of evaluation criteria. This model needs additional processing to
create visualisations, and due to the limitations of the dataset, it is un- Fig. 9. Comparative analysis of DWSC-SAE-MN with AlexNet.
able to differentiate between appropriate and inappropriate mask
application. In the future, one of our goals is to provide face mask
identification datasets that include a variety of various mask wearing
10S. Balasubaramanian et al. A r r a y 19(2023)100294
Musannah. Sundaravadivazhagan Balasubaramanian reports financial
support was provided by The Research Council-(TRC)-Block Funding-
Research Grant-Oman.
Data availability
The data that has been used is confidential.
Acknowledgements
All persons who have made substantial contributions to the work
reported in the manuscript have agreed to published the document in
Array-Open Access-Elsevier Journal.
References
[1] Woods A, Daily News B, Jun. Britain faces an anxiety crisis as people return to
work. 2020. https://bdaily.co.uk/articles/2020/06/22/britainfaces-an-anxiety-cri
sis-as-people-return-to-work.
[2] Howard J, Huang A, Li Z, Tufekci Z, Zdimal V, van der Westhuizen H, von Delft A,
Price A, Fridman L, Tang L, Tang V, Watson GL, Bax CE, Shaikh R, Questier F,
Hernandez D, Chu LF, Ramirez CM, Rimoin AW. Face masks against COVID-19: an
evidence review. Preprints 2020:2020040203. https://doi:10.20944/preprints20
2004.0203.v1.
[3] Laurent Sifre, Mallat St´ephane. Rigid-motion scattering for texture classification.
Int J Comput Vis 2014. https://doi.org/10.48550/arXiv.1403.1687.
[4] Jimenez JL, Marr LC, Randall K, Ewing ET, Tufekci Z, Greenhalgh T, Tellier R,
Fig. 10. Comparison of true positive rate with false positive rate. Tang JW, Li Y, Morawska L, Mesiano-Crookston J, Fisman D, Hegarty O, Dancer SJ,
Bluyssen PM, Buonanno G, Loomans MGLC, Bahnfleth WP, Yao M, Sekhar C,
Wargocki P, Melikov AK, Prather KA. What were the historical reasons for the
states. Alternatively, in the future, the work needs to use zero-shot resistance to recognizing airborne transmission during the COVID-19 pandemic?
learning to have the design recognise incorrect mask wearing states. Indoor Air 2022 Aug;32(8):e13070. https://doi.org/10.1111/ina.13070. PMID:
36040283; PMCID: PMC9538841.
[5] Ting Daniel Shu Wei, Lawrence Carin, Dzau Victor, “Tien Y Wong. Digital
Authorship statement technolog” and COVID-19. Nat Med 2020;26(4):459–61.
[6] Leung Nancy HL, Chu Daniel KW, Shiu Eunice YC, Chan Kwok-Hung,
McDevitt James J, Hau Benien JP, Yen Hui-L“ng, et al. Respiratory virus shedding
All persons who meet authorship criteria are listed as authors, and all
in exhaled breath and efficacy”of face masks. Nat Med 2020;26(5):676–80.
authors certify that they have participated sufficiently in the work to [7] Ather B, Mirza TM, Edemekong PF. Airborne precautions. [Updated 2022 aug 29].
take public responsibility for the content, including participation in the In: StatPearls [internet]. Treasure island (FL). StatPearls Publishing; 2022 Jan.
concept, design, analysis, writing, or revision of the manuscript. Available from: https://www.ncbi.nlm.nih.gov/books/NBK531468/.
[8] Bae Seongman, Kim Min-Chul, Kim Ji Yeun, Cha Hye-Hee, Lim Joon Seo,
Furthermore, each author certifies that this material or similar material Jung Jiwon, Kim Min-“ae, et al. Effectiveness of surgical and cotton masks in
has not been and will not be submitted to or published in any other blocking SARS–CoV-2: a controlled comparison”in 4 patients. Ann Intern Med
publication before its appearance in the Array-Open Access-Elsevier.
2020;173(1):W22–3.
[9] Tang JW, Li Y, Eames I, Chan PK, Ridgway GL. Factors involved in the aerosol
transmission of infection and control of ventilation in healthcare premises. J Hosp
Authorship contributions Infect 2006 Oct;64(2):100–14.
[10] Paton R, Tolhurst N, Perisa M, Dempsey K, Tallon J. What mask to use? Aust Nurs
Midwifery J 2014 Nov;22(5):31.
Category 1 [11] Emma P, Martin C. David Grass, Isaac Henrion, Warren S. Warren and Eric
Sundaravadivazhagan Balasubaramanian, Robin Cryic: Conception Westman. Low-cost measurement of face mask efficacy for filtering expelled
and design of study, Robin Cyriac, Sahana Roshan, Boby Chellanthara droplets during speech. Sci Adv 2 Sep 2020;6(36). https://DOI:10.1126/sciadv.abd
3083.
Jose,: Acquisition of data, Sundarvadivazhagan Balasubaramanian, [12] Interim Infection Prevention and Control Recommendations for Healthcare
Kulandaivel Maruthamuthu Paramasivam: analysis and/or interpreta- Personnel During the Coronavirus Disease 2019 (COVID-19) Pandemic. Internet
tion of data. source. 2022. https://www.cdc.gov/coronavirus/2019-ncov/hcp/infection-contr
ol-recommendations.html. Update on September 23.
Category 2
[13] Javaid Mohd, Abid Haleem, Raju Vaishya, Bahl Shashi, Suman Rajiv,
Drafting the manuscript: Kulandaivel Maruthamuthu Paramasivam, Vaish A’hishek. Industry 4.0 technologies and their applications in fighting
Boby Chellanthara Jose, revising the manuscript critically for important COV”D-19 pandemic. Diabetes Metabol Syndr: Clin Res Rev 2020;14(4):419–22.
[14] Loey M, Manogaran G, Taha MHN, Khalifa NEM. A hybrid deep transfer learning
intellectual content: Sundarvadivazhagan Balasubaramanian, Robin
model with machine learning methods for face mask detection in the era of the
Cyriac. COVID-19 pandemic. Measurement 2021;167:108288.
Category 3 [15] 21. Shashi Y. Deep learning based safe social distancing and face mask detection in
public areas for covid-19 safety guidelines adherence Int J Res Appl Sci Eng
Approval of the version of the manuscript to be published (the names
Technol 2020;8(7):1368–75. https://doi.org/10.22214/ijraset.2020.30560.
of all authors must be listed): [16] Hussain Shaik Asif, Ahlam Salim Abdallah Al Balushi. A real time face emotion
Sundarvadivazhagan Balasubaramanian, Robin Cyriac, Sahana classification and recognition using deep learning model. In: Journal of physics:
conference series, vol. 1432. Bristol: IOP Publishing; 2020, 012087.
Roshan, Kulandaivel Maruthamuthu Paramasivam, Boby Chellanthara
[17] Ejaz MS, Islam MR, Sifatullah M, Sarker A. Implementation of principal component
Jose. analysis on masked and non-masked face recognition. In: 2019 1St international
conference on advances in science, engineering and robotics technology
(ICASERT). IEEE; 2019. p. 1–5. https://doi.org/10.1109/ICASERT.2019.8934543.
Declaration of competing interest [18] Li S, Ning X, Yu L, Zhang L, Dong X, Shi Y, He W. Multi-angle head pose
classification when wearing the mask for face recognition under the covid-19
coronavirus epidemic. In: 2020 International conference on high performance big
The authors declare the following financial interests/personal re- data and intelligent systems (HPBD&IS). IEEE; 2020. p. 1–5. https://doi.org/
lationships which may be considered as potential competing interests: 10.1109/HPBDIS49115.2020.9130585.
Sundaravadivazhagan Balasubaramanian reports financial support was
provided by University of Technology and Applied Sciences - Al
11S. Balasubaramanian et al. A r r a y 19(2023)100294
[19] Qin B, Li D. Identifying facemask-wearing condition using image super-resolution communication technology (CICT). IEEE; 2020. p. 1–5. https://doi.org/10.1109/
with classification network to prevent covid-19. Sensors 2020;20(18):5236. CICT51604.2020.9312083.
https://doi.org/10.3390/s20185236. [24] Krizhevsky Alex, Sutskever Ilya, Geoffrey E. Hinton. “ImageNet classification with
[20] Li C, Wang R, Li J, Fei L. Face detection based on yolov3. In: Recent trends in deep convolutional neural networks.”. Adv Neural Inf Process Syst 2012.
intelligent computing, communication and devices. Springer; 2020. p. 277–84. [25] Ayeche F, Alti AHDG, HDGG. An extensible feature extraction descriptor for
https://doi.org/10.1007/978-981-13-9406-5 34. effective face and facial expressions recognition. Pattern Anal Appl 2021;24:
[21] Ochin S. Deep challenges associated with deep learning. In: 2019 International 1095–110. https://doi.org/10.1007/s10044-021-00972-2.
conference on machine learning, big data, cloud and parallel computing [26] Ayeche Farid, Alti Adel. Local directional gradients extension for recognising face
(COMITCon). IEEE; 2019. p. 72–5. https://doi.org/10.1109/ and facial expressions. Int J Intell Syst Technol Appl 2023;20(No. 6). https://doi.
COMITCon.2019.8862453. org/10.1504/IJISTA.2022.128525.
[22] Chen Y, Hu Menghan, Hua C, Zhai G, Zhang J, Li Q, Yang SX. Face mask assistant: [27] Himeur Y, Al-Maadeed S, Varlamis I, Al-Maadeed N, Abualsaud K, Mohamed A.
detection of face mask service stage based on mobile phone. IEEE Sensor J 2021;21 Face mask detection in smart cities using deep and transfer learning: lessons
(9):11084–93. https://doi.org/10.1109/JSEN.2021.3061178. learned from the COVID-19 pandemic. Systems 2023;11:107. https://doi.org/
[23] Venkateswarlu IB, Kakarla J, Prakash S. Face mask detection using mobilenet and 10.3390/systems11020107. 2023.
global pooling block. In: 2020 IEEE 4Th conference on information &
12