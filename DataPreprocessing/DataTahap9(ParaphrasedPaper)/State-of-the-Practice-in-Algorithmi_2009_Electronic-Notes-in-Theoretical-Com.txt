Once the execution tree (ET) is constructed, the debugger effectively navigates it using various search strategies [19, 10, 14, 1, 13], and consults the oracle to determine the correctness of each encountered question during the traversal of the ET. When dealing with a program exhibiting erroneous behavior, this method ensures that, upon the oracle's response to all questions, the bug will eventually be discovered. If multiple bugs exist in the program, only one of them will be identified in any given debugging session. Once the first bug is resolved, algorithmic debugging can be applied again to uncover subsequent bugs. This process will now be illustrated using an example.

Our initial study involved the selection of debuggers to be involved in the investigation. Thirteen algorithmic debuggers were identified, and all but those deemed too immature for practical use (refer to section 4.1) were included. Our aim was not to compare algorithmic debugging-based techniques, but rather to compare mature and usable implementations. Therefore, each debugger was evaluated based on its most recent implementation, rather than its most recent report, article, or thesis, to explore all potential offerings by the debuggers. We also identified desirable features of declarative debuggers that were not implemented by any existing debugger. Some of these features had been proposed in related literature, while others were introduced in this study. The desired properties of an algorithmic debugger include: downward exploration, top-down zooming, heaviest-first strategy, subterm dependency tracking, and dynamic weighting search. These strategies were designed to minimize both the number of questions and the time required to answer them. Firstly, the number of questions can be reduced by pruning the ET (for example, the "divide and query" strategy prunes nearly half of the ET after each answer). Secondly, the time needed to answer questions can be reduced by avoiding complex questions or by generating a series of questions that are semantically related (i.e., consecutive questions refer to related parts of the computation). For example, the top-down zooming strategy attempts to ask questions related to the same recursive (sub)computation. An overview of algorithmic debugging strategies is available in [reference to resource].

Tracing subexpressions offers two main advantages. Firstly, it reduces the search space as the debugger only explores the part of the ET related to the incorrect subexpression. Secondly, it enhances the understandability of the debugging process by giving the user some control over the bug search.

Algorithmic debugging can become too rigid if it is solely limited to question generation. At times, the programmer may have an intuition about the location of the bug within the ET. In such cases, allowing the programmer to freely explore the ET could be the most effective strategy. Providing the programmer with control over the exploration of the ET when directing the bug search is desirable.

A combination of main and secondary memory would be advantageous. It would be valuable to load a cluster of nodes into main memory and explore them until a new cluster is necessary. This approach would leverage the speed gained by operating in main memory (e.g., retaining the ability to apply strategies on the loaded cluster) while still being able to store large ETs in secondary memory.

It is important to note that our objective in this phase of the study was not to compare the debuggers against real programs. This comparison would be futile because, with the same ET, regardless of its size, all debuggers would find the bug with the same number of questions (assuming they use the same strategy). Instead, our goal was to examine the behavior of the debuggers when handling different types of ETs. Specifically, we generated deep, broad, balanced, and unbalanced ETs with varying node sizes. Through this experiment, we were able to assess the efficiency of the debuggers when storing the ET in memory and their scalability as the size of the ET increased.

The tool Hat-Delta stores the Abstract Reduction Tree (ART) into a file and traverses it during the debugging process. We considered the size of the entire ART rather than the size of the implicit ET. Since the ART serves other purposes beyond algorithmic debugging (e.g., tracing), it contains more information than necessary.

Similarly, Buddha also generates the entire ET in main memory. In this case, we used a shell script to measure the physical memory consumed by the data structures managed by the debugger. This might potentially create a slightly unfair advantage, as the in-memory representation of the ET is likely to be more compact than any other representation stored on disk.

Furthermore, we communicated with the developers of the Java Interactive Visualization Environment (JIVE), and the upcoming release will integrate an algorithmic debugger called JAVADD. This tool utilizes the Java Platform Debugger Architecture to examine the event log of the execution and produce the ET.

Hat-Delta, the former algorithmic debugger of Hat, was replaced by Hat-Delta, which incorporates new features such as tree compression and enhanced strategies to explore the ET. However, some of the old functionalities offered by Hat-Detect have not yet been integrated into Hat-Delta. Considering that these functionalities were already implemented by Hat-Detect, it is likely that the next release of Hat-Delta will include them. These functionalities are as follows:

The comparison of functionalities has produced a precise description of the features implemented by each debugger (for each programming language). From this description, it is evident that many features that should be implemented by any algorithmic debugger are only included in one of them. For instance, only the Mercury debugger has the capability to trace subexpressions, only Hat-Delta implements tree compression, only DDT has a graphical user interface (GUI), and only it allows users to graphically explore the ET.

Despite the numerous challenges we have identified, we can also conclude that there is continuous progress in the development of algorithmic debuggers. This progression can be observed by comparing the release dates of the study's tools and their implemented features, as well as by comparing different versions of the same debugger (for example, from Hat-Detect to Hat-Delta, many new functionalities have been added, such as tree compression and new search strategies).

The comparison presented in this study considered only objective criteria that can be validated. Subjective criteria that can be interpreted were omitted from the study. For instance, discussions about the ease of use or installation of the debuggers were not included. This was intentional, as it allows for such comparisons to be addressed in future work.