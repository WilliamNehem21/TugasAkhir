Domain adaptation techniques for two-stage detectors primarily rely on adversarial discriminative methods, which aim to align features at multiple levels and have been enhanced in various ways. For instance, alignment at the image and instance levels has been employed in previous work (ref). However, employing such an approach in one-stage detectors, which simultaneously predict bounding boxes and object classes, presents challenges.

In a weakly supervised cross-domain setting, transfer based on adversarial generative methods is used to transfer images with instance-level annotations from the source domain to the target domain. Additionally, in an unsupervised setting, a weak self-training approach based on self-supervision-based methods has been proposed. This enables the training of unlabeled images by mitigating the negative effects of inaccurate pseudo-labels. Nevertheless, the performance of these domain adaptation methods for one-stage detectors is found to be inadequate when compared to their performance for two-stage detectors.

Among the four categories of domain adaptation, adversarial generative and self-supervision-based methods can be readily applied to one-stage detectors. Furthermore, these two methods offer distinct advantages. Adversarial generative methods have access to accurate source labels, while self-supervision-based methods can utilize the original target images. To leverage the benefits of both methods, a novel unsupervised domain adaptation method that integrates adversarial generative and self-supervision-based methods is proposed. This approach combines transfer based on adversarial generative methods and weak self-training, which have demonstrated efficacy for one-stage detectors (16, 19). It is demonstrated that these two components complement each other, resulting in improved detection performance.

The development of deep convolutional neural networks (CNN) has enhanced the performance of object detection. While two-stage detectors like R-CNN, Fast R-CNN, and Faster R-CNN extract region proposals and classify them, one-stage detectors such as YOLO and SSD achieve significant improvements in inference speed using a single-stage network. Recent studies have shown enhancements in both accuracy and inference speed (6, 7).

In this study, the proposed method is tested on SSD, a representative one-stage detector known for its simple architecture and balanced trade-off between inference speed and performance. Furthermore, SSD has been utilized in previous related studies, allowing for a fair comparison.

The study considers source data (xs) and target data {(xi, yi)}nt drawn from the target domain xt, where ns. and nt represent the number of source and target samples, respectively. The data distributions are denoted as p(x) and p(xs)/= p(xt), indicating differing distributions between the source and target data as shown in the dataset, which shares the same classes as Pascal VOC. Additionally, the study considered the Watercolor2k and Comic2k datasets, which contain six classes in Pascal VOC and provided 1000 images each for training and testing. A model was trained without utilizing the labels of the target images, addressing unsupervised domain adaptation.

Regarding the performance of transfer based on adversarial generative methods, it was observed that it is ineffective for the Watercolor2k dataset in comparison to the Clipart1k and Comic2k datasets. Although the Fr√©chet Inception Distance (FID) between the domain-adapted and target images did not differ significantly across the datasets, the distance difference on Watercolor2k was the smallest, resulting in poor performance of the method. Conversely, transfer using adversarial generative methods performed better for Clipart1k and Comic2k, where the distance differences were larger. Hence, the effectiveness of the adversarial generative method depends on the specific target dataset.

Overall, the study addresses unsupervised domain adaptation for one-stage detectors by proposing a generative and self-supervised domain adaptation method. A learning strategy for SSDs is introduced, applying transfer based on adversarial generative methods and weak self-training.