This study introduces the SRM-ELM (Structural Risk Minimization Extreme Learning Machine) algorithm, which utilizes Particle Swarm Optimization (PSO) and the principle of structural risk minimization to determine the optimal number of hidden nodes for ELM. The SRM-ELM algorithm aims to address the challenge of time-intensive trial-and-error methods typically used to find the optimal number of hidden nodes. By incorporating the VC theory, SRM-ELM mitigates overfitting and offers computational efficiency compared to alternative optimization algorithms such as genetic algorithms (GA) or differential evolution (DE). The study demonstrates the effectiveness of the SRM-ELM algorithm in optimizing the number of hidden nodes for ELM through simulations on six benchmark datasets. The results indicate that SRM-ELM provides a reasonable and feasible approach for achieving good generalization in ELM.

Furthermore, the study highlights the significance of VC-dimension (h) as a measure of computational complexity in machine learning and its impact on improving the generalization of neural networks. The absence of a universal formula for calculating h for neural networks is noted, and the study discusses the derivation of VC-dimension h for feedforward networks with sigmoid activation functions. The novel algorithm proposed in this study leverages SRM and PSO to optimize the number of hidden nodes for ELM, where the formula for VC confidence is modified to create a concave function for SRM as the objective function. The application of PSO to optimize the SRM function in determining the optimal number of hidden nodes for ELM is substantiated by experimental results, demonstrating the algorithm's capability to produce effective numbers of hidden nodes and achieve excellent generalization.