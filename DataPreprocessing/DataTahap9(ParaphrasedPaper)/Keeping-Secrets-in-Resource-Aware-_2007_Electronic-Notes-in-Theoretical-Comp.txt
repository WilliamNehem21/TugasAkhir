Component-based software development allows for the reusability, interchangeability, and downloading of programs onto a running system. In some cases, the creator or user of a component may wish to safeguard certain data within the component from other components on the same system. However, achieving this objective becomes challenging due to potential attackers who may be running on the same computer as the target component and can monitor its resource usage. To address this issue, we have created a framework for assessing the degree to which values inside a component are kept secret from an attacker who can communicate with the component and monitor its resource usage.

Weighted automata are characterized by a simple weight or cost on each transition and have been extensively studied since the early days of computer science. In our automata model, we utilize a q-algebra to assign costs, allowing for a truly compositional model of the resource usage of components. We also incorporate timed automata concepts which label transitions with costs representing the time they take. Our model is akin to priced or weighted timed automata, which model time using clocks and feature costs on states and transitions. Notably, our model differs from some process calculi by allowing multisets of actions to occur simultaneously. Unlike other papers on computer security that focus on measuring the resources consumed by the attacker in an attack, our work allows the attacker to measure the resources consumed by the target system and potentially use this information to launch an attack, aligning it with the body of research on side channel.

In the subsequent section, we introduce our automata model and cost algebra, followed by an extension of these automata to pass values and define secrecy degrees for these values. We further introduce an automatic tool to verify secrecy in Section 4, and finally conclude the paper in Section 5.

The set of actions of the automata includes input, output, internal actions, and conditionals on data values, and our tools indicate increased secrecy degrees, demonstrating that the attacker cannot ascertain which value was the first choice and which was the second. Although this does not represent perfect secrecy, the heightened secrecy degrees illustrate the limitations on the attacker's ability to discern specific values.