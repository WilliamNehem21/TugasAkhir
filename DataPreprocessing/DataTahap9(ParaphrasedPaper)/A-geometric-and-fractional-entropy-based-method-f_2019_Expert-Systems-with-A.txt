Xia, Pan, and Qin (2014) proposed a method for clustering faces in a photo album, which utilizes spectral features, similarity features, minimum cost flow, and clustering techniques. The features are extracted from cropped face images, with the main goal being to identify images that contain the same faces. While this approach is suitable for organizing personal collections, it may not be well-suited for distinguishing family and non-family images.

Qin, Tan, and Chen (2015) introduced tri-subject kinship verification as a means of understanding familial relationships, focusing on establishing a degree of similarity between parents and children. The method employs a relative symmetric bilinear model to estimate similarity and incorporates spatial information to enhance results. Although this approach is effective when the recognition process is successful, it may not be ideal with recognition-based methods.

Robinson et al. (2018) presented a method for visual kinship recognition in family photos, utilizing deep learning for face verification, clustering, and improved baseline scores. The approach involves multimodal labeling to optimize annotation, incorporating data from family photos such as facial information and metadata. While effective for identifying kinship in family photos, it does not extend well to non-family photos.

Wang et al. (2015, 2017) proposed leveraging geometry and appearance cues for recognizing family photos. This method identifies facial points and constructs polygons to study geometric features, using k-means clustering and an SVM classifier for pairwise relationship estimation. However, accurate classification may be challenging when variations in heights and arrangements of faces are present in images.

In summary, while several methods focus on kinship recognition based on face detection and recognition, fewer studies have addressed the classification of family and non-family photos. Additionally, existing methods primarily rely on facial information and may not perform well in images with complex backgrounds. As a result, there is a critical need for an accurate method to classify family and non-family photos that considers spatial and background information.

To address this need, the proposed method combines spatial and angle features for facial structure analysis, along with tsallis fractional entropy-based texture features to capture background variations. These features are utilized to train a convolutional neural network for classifying family and non-family photos. Experimental results demonstrate the effectiveness of the proposed method compared to existing approaches, highlighting the contributions of spatial and angle features for facial structure analysis and the novel use of fractional entropy for background texture analysis.

However, the proposed method may encounter limitations in cases where the properties of facial regions and backgrounds are shared between family and non-family images. Additionally, challenges may arise when photos contain both family and non-family members, suggesting a need for future work to address these limitations.