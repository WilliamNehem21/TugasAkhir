Numerous software systems rely heavily on managing large amounts of data using data management systems, such as relational database management systems (RDBMS). RDBMS are commonly utilized to store information in a structured format and enforce various data constraints, thereby ensuring basic consistency. These systems are established, well-tested software products, known for their reliability in maintaining data integrity within defined constraints.

However, there are situations in which delegating the responsibility of consistency enforcement to the RDBMS is impractical or simply infeasible. In such cases, it becomes necessary to enforce data consistency at the business logic level of the system. Consequently, ensuring the correctness of the business logic in terms of data consistency becomes one of the most crucial aspects of testing data-intensive applications.

In this paper, we demonstrate how QuickCheck, a tool for random testing against specifications, can be leveraged to test the business logic of an application and enhance confidence in data integrity. We construct an abstract data model that contains the essential information required to create meaningful test cases, while ensuring that its state remains substantially smaller than the complete database. Subsequently, we automatically generate and execute test cases from the abstract model to verify the preservation of data constraints.

Many applications utilize one or more databases to store a vast amount of data and provide diverse interfaces for inspecting and modifying the data. These interfaces may be accessible through web-based or desktop applications, with different users having varying access rights. Consequently, the database imposes certain constraints on the data that cannot be violated, provided that the database management system is correctly implemented. In addition to these built-in constraints, the application enforces other rules, which may involve data format, relationships, or non-trivial calculations.

We present a method for testing data-intensive systems using QuickCheck, using a small example of an online shop to illustrate the approach. While our method was initially developed for testing a real insurance system, a subsequent master student project demonstrated its applicability in testing another commercial database-intensive system, resulting in the detection of several faults. Our method is designed to be applicable to both relational and non-relational databases with multiple concurrent clients accessing the system.

The focus of our method is to abstract the data from the database and utilize this abstraction as a test model, rather than creating a copy of the entire database as the state. We begin by identifying the interface functions in the application and then create specific generators for various aspects, such as customer information and product codes, to effectively simulate different scenarios for testing.

We outline the process of representing the state transitions and interface function executions using a state machine model, and describe the necessity of considering both positive and negative test cases to ensure comprehensive validation of the application's behavior. Additionally, we highlight the significance of using a transactional database and the importance of undoing the transaction to maintain the consistency of the database state during testing. The paper also discusses local checking functions for interface function testing and the overall significance of the approach in ensuring data consistency in large databases.

Overall, the paper presents a method for testing data-intensive systems using QuickCheck, with a focus on verifying the business logic layer's ability to maintain data consistency across various application interfaces. The method has been demonstrated to be effective in testing real-world systems, highlighting its potential for broader application in the domain of database-intensive applications.