In one experiment, it was observed that several genes exhibited inconsistent and noisy signals across all samples, making it difficult and time-consuming to analyze all genes collectively with a small sample size. As a result, there is a need for specific analysis to identify genes that show patterns of expression correlated with the disease state. Therefore, an artificial intelligence-based diagnostic system holds great significance in genetic research. With the increasing use of machine learning in various research domains, researchers have employed various classification techniques to handle high-dimensional microarray data. Additionally, gene expression datasets are characterized by high dimensionality, with a large number of genes or features but relatively few samples, presenting a major challenge in dataset classification.

To address this issue, researchers have adopted two main methods for selecting significant genes: feature selection and feature extraction. Feature extraction involves transforming the high-dimensional feature set into a reduced lower-dimensional feature set using linear and nonlinear methods, while feature selection aims to pick a subset of the most significant attributes from the high-dimensional microarray data, thereby reducing irrelevant features that have minimal impact on the learning model's performance. However, feature extraction may lead to the loss of useful data due to the complete transformation of the original data. Therefore, the present work considers both feature extraction and feature selection to enhance the learning process.

In addition, attribute selection techniques can be categorized into three types: filter, wrapper, and hybrid approaches. The filter feature selection approach involves evaluating each feature of the dataset using a statistical measure and selecting the subset of the most significant features, whereas the wrapper approach uses a classifier to identify the most vital subset of features, with classification accuracy being the criteria for evaluating the most significant feature subset. While the wrapper approach is more effective than the filter approach, the latter is widely accepted due to its lower evaluation cost. Moreover, the wrapper feature selection method combines metaheuristic and machine learning approaches to select the globally best feature subset.

The remainder of the paper is organized as follows: Section 2 discusses the analysis of the provided model, Section 3 covers background approaches, and Section 4 presents the proposed method. Sections 5 and 6 describe the experimental setup and the experimentation conducted.

To extract the most significant genes, the k-fs approach is initially used, where each gene is assigned a rank and the technique selects up to 500 genes from thousands of genes in the dataset. These preselected genes are then passed to sc-mbo-bls to obtain the best gene subset.