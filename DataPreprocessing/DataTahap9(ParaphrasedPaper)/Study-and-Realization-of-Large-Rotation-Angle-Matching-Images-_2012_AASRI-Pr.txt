This study seeks to address the challenge of matching images with significant rotation angles in aerial photography by combining the benefits of SIFT characteristic matching and pyramid image matching. The process involves initially matching images at the highest pyramid level using the SIFT characteristic matching method, followed by the application of the RANSAC algorithm to consolidate the results obtained from the SIFT method. Additionally, the study proposes predicting the initial location of matching points by utilizing the estimated rotation angle and performing rotation compensation of the matching window images prior to the matching process. This methodology is validated through experimentation with an aerial digital imagery exhibiting a large rotation in a specific area.

While the matching of images with large rotation angles has not been extensively explored in aerial photogrammetry, it has been thoroughly investigated in the domains of computer vision and medical image matching. Previous studies have proposed various methods for addressing this issue, such as a direction code-based matching method, a ring-projection transformation approach, and an edge extraction method. However, these methods have exhibited limitations, such as the requirement for an approximate value of the rotation angle, slow processing speed, and significant matching biases in the results.

The SIFT feature extraction and matching in this study are conducted exclusively at the highest pyramid image level, with the primary aim of establishing a coarse coordinate relationship between images with large rotation angles, rather than identifying numerous accurate conjugate point pairs. This strategy is effective in reducing the computational burden and enhancing the speed of SIFT feature matching, as images at the highest pyramid level are relatively small and thus require less computation.

Further, the study utilizes the keypoints as feature points and their descriptors as the feature to be used, with the similarity measure being based on the Euclidean distance between feature vectors. A given threshold is employed to determine the acceptance of the feature vector as the conjugate point based on the ratio of the nearest distance to the less nearest distance.

The determination of correct matches is based on calculating the discrepancies between the coordinates of remaining candidate points and those derived by the affine transformation model. If the discrepancies are within a specified threshold, the corresponding SIFT feature pair is deemed correct, whereas discrepancies beyond the threshold indicate incorrect matching. The ratio of outlier point pairs to the total point pairs is ultimately computed.

In the prediction of the initial position of conjugate points, affine transformation coefficients are directly employed to calculate the coordinates at the highest pyramid image level, while at other pyramid levels, parallax information from neighboring successfully matched points is utilized to derive the initial position of points that did not obtain correct matching points. The study emphasizes the consideration of the effect of the rotation angle on the parallax during the initial position prediction.

Moreover, the study addresses challenges related to geometric distortion and repetitive texture when using NCC as the similarity measure to search for conjugate points. Certain constraints are introduced to eliminate incorrect matching results, including the integration of iteration weighting strategy and the utilization of relative orientation with model conjunction condition to automatically identify and remove matching points with wrong parallax.

In summary, the study aims to address the matching problem associated with automatic rotation and large rotation angles in aerial photography by proposing a comprehensive methodology that leverages SIFT characteristic matching, pyramid image matching, and advanced techniques for initial point prediction and outlier removal.

Finally, the effectiveness of the proposed approach is validated through experimentation with an aerial digital imagery exhibiting a large rotation angle in a specific area.