The identification of novel behaviors in systems is crucial for their maintenance and smooth operation, making novelty detection a significant area of research. Novelty detection involves the ability of a model to recognize new classes of data that it has not encountered before, and it has been widely used in fields such as manufacturing, cyber-security, biomedical analysis, and astronomy.

During the inference process, autoencoders (AE) are exposed to new samples, leading to higher errors, thereby facilitating novelty detection. Various methods, including mean-square error (MSE), residual error, structural similarity (SSIM), and feature consistency, are used to calculate the differences between pixels.

One common challenge with using AE methods for novelty detection is their tendency to generalize to unseen classes, resulting in poor performance as novelty detectors. To address this issue, a classifier is introduced into the training path of a multi-discriminator-based autoencoder. However, this approach brings about a complex and costly training procedure. In contrast, an alternative proposed approach is the nearest latent neighbors (NLN) algorithm, which utilizes the reconstructions of nearest neighbors in the latent space of autoencoders to address the generalization problem.

One critical distinction among related work lies in whether supervised, semi-supervised, or unsupervised methods have been employed. Supervised methods are most relevant to anomaly detection scenarios, where both normal and anomalous data classes are known in advance. However, supervision may not be applicable in many settings where anomalous classes are either underrepresented or unknown. Semi-supervised methods are commonly used in practice, as normal data is more readily collected from most systems. In this case, models are designed to represent the expected operating conditions of a system, and any deviations from that are considered novel.

It has been shown that reconstruction-error based methods alone are not particularly robust to noise, changing backgrounds, and viewing angles. Generative autoencoding models address this issue by using reconstruction probability, attention mechanisms, or generative adversarial networks (GANs). Self-supervised learning (SSL) has also been applied to autoencoders and has shown improved performance in novelty detection by employing in-painting or position prediction pretext tasks.

For multi-class novelty detection, multiple classes are considered inliers and a single class is considered novel, representing a more challenging evaluation framework. In the context of one-class novelty detection, autoencoders are prone to implicitly learning representations of certain classes, leading to misidentification in reconstruction-based novelty detectors.

In order to evaluate the proposed approach across different datasets, appropriate modifications are made to the models and architectures. It is observed that the NLN-enabled AE struggles to distinguish between different texture patches, indicating an inherent weakness of standard autoencoding architectures.