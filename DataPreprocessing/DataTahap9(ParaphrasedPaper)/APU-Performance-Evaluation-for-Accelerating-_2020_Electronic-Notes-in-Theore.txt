Over time, computer systems have made significant advancements in integration, performance, functionality, and applications. An illustrative example of this progress can be seen in the evolution of central processing units (CPUs), which have transitioned from being originally designed for general-purpose tasks to incorporating application-specific circuitry for functions such as video processing, vector operation acceleration, multimedia decoding, and hardware acceleration for scientific applications. However, CPUs exhibit performance limitations when dealing with large datasets or tasks requiring numerous computing operations.

The observation that pixel color computation for an image can be performed in parallel using rasterization by multiple processors led to the development of the graphics processing unit (GPU). This circuit integrates numerous minimalist processors optimized for mathematical operations required for graphics tasks, resulting in significant performance gains in computer graphics. Consequently, GPUs are now extensively used in video games and multimedia applications.

Due to the performance limitations of CPUs for several tasks, extensive research has been focused on GPU architecture to utilize it as a general-purpose processor. This research has led to improved execution times for computationally intensive workloads, such as artificial intelligence, blockchain, and bioinformatics. As a result, GPUs have become the default architecture for numerous demanding workloads due to their parallel processing capabilities and high optimization for mathematical operations.

In 2011, the introduction of novel specialized circuits in the CPU die gave rise to a new type of computer architecture known as the Accelerated Processing Unit (APU). This architecture incorporates both CPU and GPU, sharing system memory (RAM) within the same integrated circuit and allowing for efficient sharing of data structures. The unique characteristics of the APU offer opportunities for the creation of specialized algorithms to leverage its capabilities. However, there are challenges in evaluating the performance of APUs in tasks where GPU performance is not practical due to constraints such as the PCI-Express bus transfer rate, inability to share data structures between the CPU and GPU, or when the GPU is executing code with a high number of branches.

Efforts have been directed towards accelerating the ray tracing algorithm through different approaches, with a focus on leveraging the specific characteristics of APU architecture to improve performance for computationally intensive workloads such as ray tracing. Experimental results and analyses are presented to demonstrate the potential of APUs as viable architectures for improving the performance of such workloads. Additionally, the paper discusses avenues for future research, such as evaluating the performance of APUs in tasks beyond ray tracing and exploring optimization techniques across different architectures.

The experimentation involved the development of a novel ray tracing algorithm specifically tailored for the APU architecture, leveraging its shared memory and optimized for parallel processing. The algorithm was compared to the same algorithm implemented for the CPU using C and the GPU using OpenCL, with the goal of maximizing the utilization of APU resources to achieve optimal performance.

Experimental design and analysis methods, including factorial analysis of variance (ANOVA) experiments, were employed to evaluate the effects of different factors on rendering time across APU, CPU, and GPU architectures. Factors such as image resolution, effects (e.g., anti-aliasing, reflections, transparencies), and architectural differences were considered in the evaluation to provide insights into rendering performance.

The paper concludes by emphasizing the potential of APUs as a low-cost architecture for accelerating computationally intensive workloads and identifies opportunities for further exploration, including extensive optimization of rendering code across different architectures and in-depth exploration of PCI-Express and memory transfers in discrete GPU solutions to maximize APU performance. Additionally, the paper suggests conducting experiments focused on FP32 operations and studying whether the APU maintains its performance and cost-efficiency advantage in various tasks.