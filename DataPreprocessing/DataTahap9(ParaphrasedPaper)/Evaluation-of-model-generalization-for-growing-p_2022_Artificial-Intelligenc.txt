This study addresses the challenge of limited generalization in semantic segmentation models for crop and weed segmentation, proposing a comparison of classical and adversarial training mechanisms to determine the most effective approach for a specific encoder-decoder model. The study uses simple u-net, segnet, and deeplabv3+ with resnet-50 backbone as segmentation networks, comparing their training with cross-entropy loss for classical training and patchgan loss for adversarial training. By adopting a conditional generative adversarial network (CGAN) hierarchical setting, the study penalizes different generators (G) using a patchgan discriminator (D) and L1 loss to generate segmentation output, aiming to exhibit fewer failures and comparable performance for growing plants with different data distributions. The study utilizes images from four different stages of sugar beet, partitioning the data so that the full-grown stage is used for training while earlier stages are dedicated to testing the model. The authors conclude that the adversarially trained u-net is more robust to changes in the dataset, reporting a 10% overall improvement in results with mean intersection over union (mIOU) scores of 0.34, 0.55, 0.75, and 0.85 for four different growth stages.

Weeds are unwanted plants that can be eradicated using herbicides, which have traditionally been applied uniformly across entire fields, impacting both the weeds and the crop while also causing environmental and health concerns due to excessive herbicide usage. Selective spraying can reduce herbicide consumption, and agricultural robots have the potential to perform weed and crop detection for precise spraying. However, existing robots lack a universal weed detection mechanism, leading to limitations in commercial use. Additionally, typical weed detection methods do not generalize to out-of-distribution data, necessitating updates for each new weed type or field, resulting in a time-consuming process.

The paper proposes a solution to improve model generalization, conducting experiments to achieve more reliable model tuning applicable for robot-based weed selection without additional training requirements. The dataset used in this research comprises images from multiple stages of sugar beet crop, divided into nineteen stages across four sections. The study aims to address the challenge of generalizing model parameters for unknown plant stages due to limited labeled data access and difficulty in annotating at the pixel level.

The paper is structured into five sections, discussing related work in section 2, describing data analysis, experiments, and model architectures in section 3, presenting results and model performance comparison in section 4, and concluding in section 5.

Furthermore, the paper discusses the utilization of local binary patterns (LBP) by Lottes et al. to find statistical features over RGB and Normalized Difference Vegetation Index (NDVI) channels for weed and plant detection. Additionally, the paper explores the use of gated-shaped CNN and semantic layout synthesis using CGAN in other relevant studies.

The study highlights the importance of finding an architecture and training scheme to effectively detect weeds and crops at multiple growth stages, focusing on exploratory data analysis to understand the underlying patterns and challenges in the data. Additionally, the study addresses the difficulty of differentiating between weeds and crops at an early stage and proposes artificial augmentation techniques to tackle soil variations effectively. However, the close resemblance of weed and crop at the early stage presents challenges in differentiation.