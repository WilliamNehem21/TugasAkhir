Various stimuli such as movie clips, music, and verbal commands can be used in emotion-related research. Among these, movie clips are particularly effective and reliable as they incorporate both audio and video. For an experiment involving native Chinese participants, Chinese movie clips were chosen. These clips were 4 minutes long and were categorized as positive, negative, and neutral based on specific selection criteria.

In our proposed convolutional neural network (CNN) structure, the input channel is normalized by a batch normalization layer, which is positioned between the convolutional layer and the ReLU layer. This serves to expedite the training process of the CNN and reduce its sensitivity to network initialization. Additionally, the use of the ReLU function is preferred over other functions as it accelerates the neural network.

The topographic images were fed into the CNN for feature extraction and emotion classification. Three types of EEG data corresponding to three emotional brain states were used to feed the CNN. The CNN architecture included multiple layers such as the convolutional layer, batch normalization layer, ReLU layer, and pooling layer, each of which was applied twice in the experiment. The classification accuracies against the three emotional classes (positive, negative, and neutral) were produced by the fully connected layer.

In this study, a CNN was employed for feature extraction and classification, resulting in a significant improvement in classification accuracy. The proposed method achieved the highest classification accuracies (89.056% ± 4.32 when using 25% of the data for training and 75% for testing, and 94.63% ± 3.68 when using 50% of the data for training and 50% for testing) when compared with other recent methods applied to the same dataset. These promising results indicate that the proposed expert system is expected to work effectively for other types of EEG signal classification, which will be the focus of future research.