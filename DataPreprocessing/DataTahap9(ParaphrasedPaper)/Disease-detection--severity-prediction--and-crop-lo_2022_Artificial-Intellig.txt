Livestock feed accounts for 12% of the maize yield, while an additional 12% is used to meet human food demand. Furthermore, 12% of the maize crop is utilized for industrial purposes. Maize consumption is on the rise due to its benefits in improving digestive health and reducing the risk of chronic diseases such as cardiovascular disease, diabetes, and obesity.

The first step in disease detection is segmentation, which involves isolating the region of interest (ROI) from input images. Various segmentation techniques, including threshold-based, pattern recognition, and deformable models, have been reviewed by the authors. These techniques involve manual or automatic determination of threshold values based on edge detection, region classification, or a combination of both. The authors noted that laplacian and canny edge detection techniques are widely used for image segmentation (Al-amri et al., 2010), with laplacian detecting the dark and light sides of an edge, and canny isolating noise before identifying edges and determining critical threshold values.

To address the issue of complex background, the authors proposed a deep learning-based network to enhance maize features in complex environments. This network's feature enhancement capacity removes image noise using retinex and wavelet-based methods. The authors developed a robust AlexNet model for maize feature enhancement.

While several researchers have focused on segmentation and crop disease identification using deep convolutional neural networks (CNNs), few have worked on automatic severity measurement and crop loss estimation specifically for maize crops. Additionally, existing approaches lack a complete system for data collection, pre-processing, disease identification, severity prediction, diseased area visualization, and crop loss estimation in maize crops. The models proposed in the literature have low accuracy, a large number of trainable parameters, high computation cost, and long training time. Moreover, there is a lack of visualization of features involved in disease prediction. These challenges hinder the use of these models for real-life predictions, and none of the existing models have been evaluated on real-life datasets. To address these gaps, the authors proposed a novel framework integrated with a web application for dataset collection, labeling, and validation by plant pathology experts, segmentation of diseased areas, classification into healthy, tlb, rust, and multiple disease classes, severity prediction, and crop loss estimation. The framework also employs gradcam for visualizing the infected regions involved in decision making.

The authors split the collected dataset into training and testing datasets using a trial and error mechanism to prevent data leakage. They ensured that images of different classes (healthy, tlb, rust, and multidisease) were distributed so that each image was part of either the training or testing dataset, and multiple copies of the same images were not included in both datasets. The training dataset was used exclusively for model training, while the test dataset was used to evaluate and compare the performance of different model architectures.

In the image segmentation process, black pixels represent the background region, non-black pixels represent the leaf area, and pixels encountered in the region of infection are transformed to white pixels. The authors used the k-means algorithm to segment leaf images into two clusters: ROI and background region. Pre-training of the proposed model was performed using the ImageNet dataset (LAB, 2017), and the impact of transfer learning on its performance was illustrated in the results section. The same dataset was used to train the pre-trained maizenet model, non-pre-trained maizenet model, and state-of-the-art models, including vgg-16, vgg-19 (Simonyan and Zisserman, 2015), and inception-v3. The performance of the proposed model was then compared with these state-of-the-art models.

In the results section, the authors presented deductions from experimental results obtained by employing the maizenet, vgg-16, vgg-19, resnet-50, inception-v3, and inception resnet-v2 models. The model with nine convolution layers was observed to outperform models with five through eleven convolutions.

The study utilized a dataset of 2996 images captured from the farmland of ICAR-AICRP, Mysore, where intentionally grown diseased crops were labeled by plant pathologists as healthy, tlb, rust, or multidisease.

After pre-processing the dataset using the k-means algorithm, the authors applied supervised and unsupervised algorithms to classify images into the mentioned classes. The authors trained k-means, vgg-19 (Simonyan and Zisserman, 2015), resnet-50, inception-v3, finetuned vgg-16, and maizenet models on a dataset comprising 2460 images. Among these models, maizenet reported the highest accuracy of 98.50% on the testing dataset comprising 536 images.

The proposed model has the lowest number of parameters at 1,55,956, resulting in minimal training time. Completing 20 epochs of training in just 140 seconds, the model's efficacy in calculating diseased leaf area, severity prediction, and crop loss estimation demonstrates its superiority over existing research works. Additionally, the model is integrated with a web application for real-life use as a disease prediction assisting tool. Although the framework efficiently classifies maize crops and makes disease severity and crop loss predictions, there is potential to incorporate soil parameters, atmospheric conditions, plant genomics, and disease-causing agents in the predictive process. Furthermore, the framework can be generalized for crop loss estimation in any crop.

Citations:
Al-amri et al., 2010
Khairnar and Goje, 2020
LAB, 2017
Simonyan and Zisserman, 2015
Xu and Goodacre, 2018