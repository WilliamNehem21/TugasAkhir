The exponential increase in our ability to collect and store data has not been matched by a similar trend in our capability to analyze it. Despite the abundant data available, the identification of truly interesting patterns is infrequent. Outlier detection, which involves identifying observations that deviate from normal behavior, has been a subject of extensive study in recent years, resulting in the development of algorithms designed to detect rare but potentially crucial events. In certain contexts, an outlier can be considered either as an abnormality or noise.

Outlier detection represents a unique classification scenario with two specific characteristics: first, the quantity of outliers is significantly smaller compared to normal instances; and second, the use of labels (supervised approach) in outlier detection is limited due to the fact that the outliers we are trying to detect represent new or unseen behavior. While some algorithms can operate using only labels for the normal class (semi-supervised approach) and use this information to enhance the detection rate, unsupervised approaches have the advantage of operating over unlabeled data, which are more commonly encountered in outlier detection.

Ensembling different classifiers is a common task, but outlier detection faces two additional challenges. First, ensembles typically work with discrete labels, while outlier detection is mainly concerned with scores. Second, ensembles generally rely on the existence of training data (supervised approach), whereas outlier detection does not typically have access to labeled data (unsupervised approach).

Outlier detection is an active research area, with new approaches proposed annually. However, the detection of outliers has been under consideration since 1887 in the statistical community, leading to the proposal of various techniques based on classification, clustering, density-based methods, and statistical inference.

The output of an outlier detection algorithm can be either a score or a binary label. The former type of output assigns a score to each observation and can be used to rank the observations based on their level of outlierness, while the latter assigns binary labels, usually using 1 for outliers and 0 for normal observations (inliers).

Constructing an ensemble of outlier algorithms is a promising approach to increase the detection rate of outliers and reduce the variance introduced by individual algorithms. However, using identical algorithms in an ensemble does not yield any benefit. Therefore, accuracy and diversity are crucial factors to consider when constructing an ensemble. Accuracy measures the quality of each algorithm's output, while diversity aims to build an ensemble with distinct and complementary results. Combining different types of algorithms may lead to better performance than using variations of the same algorithm. Nevertheless, a balance between accuracy and diversity is necessary to achieve an improved ensemble detection rate.

The process of building an ensemble involves three main considerations: the choice of algorithms, the organization (modular or ensemble), and the combination method. A multiclassifier can be categorized as modular or ensemble, with the latter focusing on combining results from algorithms working on the same search space. An important component is the combinatorial approach chosen to improve the overall performance.

One critical factor in constructing an ensemble is to mix algorithms with different error patterns to ensure complementarity and potential improved results. However, most such approaches assume the availability of accuracy measures for each algorithm using class labels for each observation, which is not practical in the context of unsupervised outlier detection. In the proposed approach, accuracy is estimated solely based on the output scores of each algorithm, and diversity is achieved using different types of outlier detection techniques.

The presented breadth-first method and cumulative sum method for feature bagging can be sensitive to the order in which outlier detection algorithms are applied, with the first technique in the ensemble having priority in determining the outlierness of a data record. Additionally, different similarity measures, such as correlation and mad, are used to evaluate the relationship between the outputs of different classifiers.

The proposed ensemble approaches, EDVC and EDVV, aim to ensure diversity in the combination of outputs of different outlier detection algorithms. The experiments conducted on several real-life datasets suggested that both approaches can achieve better performance than similar methods. It is important to note that these results were obtained using a relatively small number of ensemble iterations, indicating their potential for further improvement.