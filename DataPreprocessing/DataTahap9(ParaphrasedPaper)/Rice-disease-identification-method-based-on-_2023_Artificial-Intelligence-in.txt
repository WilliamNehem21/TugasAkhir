The use of machines and hyperspectral technology has been investigated for early identification of sugar beet diseases, achieving an accuracy rate of 97% in distinguishing healthy sugar beet from diseased leaves. Wang et al. (2019) employed color, shape, and texture features of fungal diseases on wheat leaves, such as powdery mildew, rust, and leaf spots, and utilized support vector machines for classification. The authors also applied the fuzzy c-means clustering algorithm to extract 25 disease features of wheat leaves and classified them using an artificial neural network to determine infection. Traditional machine learning methods often rely on manually generated specific features, resulting in low recognition efficiency. While remote sensing methods have shown promise in crop stress monitoring, they lack spectral specificity of diseases, leading to potential uncertainty in monitoring. With the advancement of big data and deep learning research, deep learning methods have provided new avenues for crop disease recognition, achieving significant results in crop monitoring and management.

In terms of identification models, statistical analysis revealed that the ResNet50 and SVM classification models demonstrated higher recognition accuracy than other models. The authors proposed an optimized dense convolutional neural network called DenseNet, which achieved an accuracy of 98.06% with fewer parameters and computation time than similar CNNs. Research on external defects in tomatoes utilized transfer learning training, with the ResNet18 model emerging as the most effective. Moreover, in peanut variety identification, integrating the CBAM module led to significant improvement in the recognition of sesame spot disease. By integrating the BiGRU module to extract advanced features, misclassification rates were further reduced, demonstrating the effectiveness of using RNNs to process features of rice diseases and enhance the performance of the CNNs.

This paper put forward an improved CNN for the extraction of features of rice diseases, which combines inception and ResNet theories to address the high misidentification rate by incorporating information about the rice disease images and their surrounding context. The improved CNN also incorporates the CBAM module for more precise feature extraction and introduces BiGRU to recognize the relationships between stress image features, deepening the model's understanding of the images and the structural characteristics of rice diseases. Experimental results demonstrate the effectiveness of the proposed model, showcasing higher accuracy and lower cost compared to other models. However, the current dataset is limited, containing only four types of rice disease samples. Future work will focus on collecting more comprehensive real-field samples and improving the model structure to enhance its generalization ability in complex scenarios.