Intel has announced plans to incorporate multiple processors operating concurrently within a shared memory in future standard computer chips. The processors' use of memory is interleaved at the fine granularity of individual memory accesses, and their individual speeds are not projected to significantly increase from current levels. Therefore, continued performance improvement will rely on the ability of programmers to leverage the concurrency of this multi-core architecture, as well as to avoid risks such as race conditions, non-determinism, deadlocks, and livelocks. To mitigate these risks, the paper proposes a theory of correctness for fine-grain concurrent programs that amalgamates various well-known and well-researched ideas, including flowcharts, Floyd assertions, Petri nets, process algebra, separation logic, critical regions, and rely/guarantee reasoning.

The paper discusses a structured calculus of correctness for fine-grain concurrent programs, which encompasses key features of a structured concurrent programming language. It describes a modular structure that can be imposed on a Petri net by enclosing certain subnets into a box with named ports. Assertions on these ports describe what the box assumes from its neighbors and what it guarantees. In execution, the enclosing boxes are completely ignored, and their dynamic behavior is intended to be the same as that of the boxes they enclose.

Concurrency in a Petri net is introduced, controlled, and eliminated through transitions, which act as barriers to the passage of tokens. These tokens, which carry with them ownership and read permissions for parts of the computer's state and its connections to the real world environment, are referred to as resources. The paper discusses the handling of these resources and the dynamic behavior of tokens at fan-out and fan-in transitions.

The paper also notes that reasoning about ownership can be effectively conducted using separation logic, a variety of modal logic, which handles assertions related to heap variables and ownership claims in a structured manner. The paper emphasizes the importance of designing a calculus that avoids false postconditions and discusses the prohibition of race conditions and the need for communication among threads. Sharing of resources through shared memory and the allocation of shared tokens are also considered, along with the concept of critical regions for thread program control over interactions at a higher level than individual memory accesses.

In order to effectively deal with non-determinism and reason about concurrent execution, the paper introduces rely and guarantee conditions, which define relations between states of shared resources and play crucial roles in ensuring the correctness of concurrent execution within critical regions of multiple threads sharing the same resource.