The paper discusses the effectiveness of replicating data across multiple sites of a data grid to improve performance in terms of load balancing, response time, and data availability. It emphasizes the importance of a carefully designed replication strategy based on availability to achieve the desired objectives. The proposed model aims to minimize the number of replicas while ensuring a certain degree of availability without compromising system performance. Unlike existing literature, the model considers the independent stability of nodes and proposes replicating data in nodes of similar stability to optimize availability. The paper also introduces a formula to calculate the number of necessary replicas based on different scenarios, including an optimistic case where replicas are stored in nodes with good stability, a pessimistic case where replicas are in nodes with poor stability, and a hybrid case with replicas in nodes of varying stability. Additionally, the paper discusses the role of each cluster-head in determining the desired availability in its cluster and compares it with the actual availability. The placement of replicas is identified as crucial, and the paper suggests a method to predict failures and efficiently place replicas in nodes without overloading the system. While the approach is semi-centralized, it addresses scalability constraints by limiting the number of nodes in each cluster. The paper also outlines future research directions, including studying the proposed model's behavior in a real grid and considering task replication and placement for fast and fault-tolerant system job execution.