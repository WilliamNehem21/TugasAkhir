Siddique et al. conducted an analysis of five machine learning algorithms for predicting the net power output of a combined cycle power plant (CCPP) using a six-year dataset. The dataset assessed output power based on input parameters such as temperature, humidity, and pressure. The study found that gradient boosted regression tree outperformed the other algorithms, with 450 trees yielding the lowest root mean square error (RMSE) and absolute error (AE). Tufekci et al. presented a viable model for predicting base load operated power output using the bagging technique with the Reptree predictor to forecast the next day's hourly energy production. Wang et al. introduced a new machine learning-based approach for predicting and optimizing organic Rankine cycle (ORC) performance. The study found that the BPNN and SVR models provided accurate predictions and improved cycle operating parameters and reverse prediction.

The primary contribution of the research involved a comprehensive examination of the optimal conditions for SCO2 Brayton cycles and utilizing advanced optimization techniques to achieve optimal thermal performance. The study employed machine learning algorithms and a creative approach to optimization using the genetic algorithm (GA) method. Additionally, the study highlighted the critical role of hyperparameter optimization for machine learning algorithms, particularly artificial neural networks (ANNs), to ensure their optimal performance in modeling and optimization tasks.

The study also analyzed the optimization technique of SCO2BC, incorporating concentrated solar power (CSP) and utilizing solar irradiance as the primary heat source. It assessed the impact of various factors on net power output, cycle thermal efficiency, and net energy utilization, while also exploring the potential application of a pre-compressor within a recompression cycle. Furthermore, the study investigated the inclusion of an additional cooler to enhance cooling at intermediate pressure, thereby improving overall system performance.

In this work, six machine learning algorithms, including XGBoost, Random Forest, LightGBM, AdaBoost, KNN, and ANN, were utilized to train the data, and the best model based on prediction accuracy was selected for the next stage of optimization. The theoretical framework used in the study was detailed in subsequent subsections, highlighting the supervised learning algorithms XGBoost, Random Forest, and KNN, as well as the feedforward neural network.

XGBoost, for example, accurately predicts a target variable by combining the values of simpler variables, implementing regression trees as weak learners, and minimizing the objective function through a convex loss function and penalty clause. Random Forest combines multiple independent decision trees to anticipate new input data, while KNN calculates distances between neighbors using weighting techniques.

The study also discussed the application of ANN, highlighting its versatility in handling various types of input-output mappings and its use of the mean squared error (MSE) as a performance metric. The training method utilized for ANN was bayesian regularization (trainbr) to provide a high degree of generalization for challenging or noisy datasets.

Overall, the study presented a comprehensive analysis of machine learning algorithms and their application in optimizing the performance of power generation systems, emphasizing the potential of these tools to significantly improve energy efficiency. The study underscored the importance of integrating machine learning models with thermodynamic optimization to effectively leverage their capabilities in system optimization.