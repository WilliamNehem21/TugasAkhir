This study focuses on the detection of faces in scenes of violence to aid in security control. The research employs the use of the violent flow (ViF) descriptor with the Horn-Schunck method as an initial step in violence scene detection. Subsequently, a non-adaptive interpolation super resolution algorithm is utilized to enhance video quality, followed by the implementation of a Kanade-Lucas-Tomasi (KLT) face detector. To optimize processing time, the super resolution and face detector algorithms are parallelized using CUDA. The experiments involved using the BOSS dataset and constructing a violence dataset from scenes captured by surveillance cameras. The study reports promising results in detecting faces in this context, highlighting the advantages of the proposed approach.

The need for surveillance camera systems is addressed, with emphasis on the potential challenges related to the lack of trained personnel for monitoring and attention maintenance. Consequently, the motivation is expressed for technological solutions that can enhance safety, particularly by facilitating the detection of potential violent behaviors in public spaces. The significance of identifying individuals engaged in violent actions within a scene is also underscored.

In exploring the use of audio and visual features in mediaeval environments, reference is made to the mediaeval 2013 dataset, which consists of movies featuring ideal conditions such as illumination and resolution. Recent research has introduced audio features, such as Mel-frequency cepstral coefficients (MFCC), and visual features, including histogram of optical flow (HOF), ViF, and color descriptors. These features were evaluated using the mediaeval 2014 dataset, with the finding that audio features hold greater relevance than visual features. Moreover, combining both types of features yielded improved results.

The study explains an approach to high-resolution image projection, where an error simulated from low-resolution frames is re-projected onto the high-resolution image, and the estimated high resolution image is updated based on the sum of the re-projected error. This iterative process continues until the maximum number of iterations is reached.