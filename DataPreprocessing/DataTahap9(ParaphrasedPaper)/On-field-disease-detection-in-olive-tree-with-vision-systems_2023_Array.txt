The study involved the generation of a dataset consisting of 500 images from each camera, which were categorized into healthy and faulty parts. This dataset was further split into an 80% training set and a 20% validation set. Data augmentation techniques, including zooming, rotation, and mirroring, were applied to artificially expand the dataset to 1000 samples. To ensure consistent results, the dataset was shuffled, and randomized training and validation sets were utilized, all of which yielded similar outcomes.

Several references in the literature underscore the utility of artificial intelligence in identifying faulty parts in olive leaves. Achieving 97% accuracy involved employing a combination of the vit model (visual transformer) and the vgg-16 (visual geometry group), while 91.8% accuracy was attained through the use of resnet101.

The faster-rcnn-inception-v2 neural network was utilized for detecting olive leaves, whereas the mask-rcnn-r-50-fpn-3x from detectron 2 was employed for intrinsic segmentation. Both networks were retrained using a dataset containing healthy and diseased leaves, with the goal of generating a representative sample for assessing tree health. Additionally, the inception v3 convolutional neural network was utilized to classify the detected leaves into different categories, building on its established success in classifying leaf diseases.

Furthermore, another neural network is to be retrained with a dataset of 3000 leaves divided into healthy, faulty parts, and unclassifiable categories. The training set will comprise 80% of the dataset, while the remaining 20% will constitute the validation set. Data augmentation techniques were again employed to increase the dataset to 4500 samples, and the resulting dataset was reassorted to identify potential inconsistencies in network training.

The study began with an exploration of the ability of convolutional neural networks (CNNs) to identify faulty parts on leaves. Subsequently, two neural networks were retrained to extract a leaf sample from trees, which were then utilized to gauge the disease level of an olive tree crop. It was observed that both the mask rcnn and the fast-r cnn networks effectively detected a sample of leaves, however, they occasionally identified non-leaf objects such as olive fruits and flowers. It was necessary for the classifier to discern and ignore these false detections. Additionally, leaves that were out of focus were categorized as non-classifiable, and the classifier was retrained with a new dataset generated by the detector and the intrinsic segmenter.

The second part of the study focused on implementing neural networks to detect and evaluate the disease level of olive trees. The results demonstrated that both detection and semantic segmentation networks could derive a representative sample of leaves, enabling the classification of the disease level of a part of the tree. The system for assessing the health status of an olive tree was then integrated into an embedded system for potential on-field applications.

Future work will center on refining the detection and intrinsic segmentation capabilities to identify diseases present in other parts of the olive tree. Furthermore, efforts will be made to mount the device on an autonomous quadricycle to eliminate the need for an operator and to enhance disease mapping in extensive fields. Finally, the study aims to develop and assess the capability of a fully autonomous fumigation system based on the information provided by the detection system.