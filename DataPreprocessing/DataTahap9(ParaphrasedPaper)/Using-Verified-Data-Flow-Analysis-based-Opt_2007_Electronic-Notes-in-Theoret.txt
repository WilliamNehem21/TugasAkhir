Creating verified compilers can be challenging, particularly when conducting complex analyses like type checking and data-flow analysis. Both the type checking and program optimization communities have developed techniques to verify the correctness of these processes and have created tools for utilizing verified type systems and optimizations. However, integrating both of these analyses into a single declarative framework is difficult because they operate on different program representations: type checking on abstract syntax trees and data-flow analysis-based optimization on control flow or program dependency graphs.

Our work introduces an attribute grammar specification language that includes constructs for defining attribute-labelled control flow graphs and both ctl and ltl-fv formulas for specifying data-flow analyses. These formulas are model-checked on these graphs to conduct the specified analyses. Consequently, verified type rules and verified data-flow analyses can both be encoded into a single declarative framework based on attribute grammars, thereby enabling the construction of high-confidence language implementations. Additionally, the attribute grammar specification language is extensible, making it relatively straightforward to add new constructs for different temporal logics, thus allowing for the use of alternative logics and model checkers in specifying data-flow analyses within this framework.

In order to build a verified compiler, a specification must be written that covers all aspects of the language and is amenable to the types of analyses required to prove correctness. However, different aspects of the compiler are naturally defined using different notations for different program representations. For example, type checking is typically syntax-directed, tightly coupled to the syntax-tree program representation, while optimizing transformations are often expressed as rewrite rules with data-flow analysis-based side conditions, tightly coupled to the control flow graph or dependency graph program representations.

As an example of data-flow analysis-based optimizations, we demonstrate how immediate dead code analysis on the assign production is utilized to determine if the assignment should be changed to a skip statement. The synthesized higher-order attributes opt stmt and opt stmts are used to construct the optimized program. The results of the model checker are passed down as an inherited attribute to the productions that require the results.

A notable feature of this work is the design and implementation of Silver as an extensible language, allowing for easy extension with new language constructs and semantic analyses. By implementing attribute grammar specifications in Haskell, Silver is able to perform data-flow analysis based on different temporal logics and can be extended with new logics and model checkers.

We developed these data flow analysis extensions to Silver to write high-level language specifications that include both syntax-directed and control flow graph-based analyses in a single framework. Silver is used to specify extensible host languages and language extensions, including those with domain specific constructs such as embedding SQL into an extensible Java host language and adding efficient unbounded numeric types in a computational geometry extension. The use of temporal logics provides a high-level formalism for specifying data-flow properties that may be used in optimizations of domain specific constructs.