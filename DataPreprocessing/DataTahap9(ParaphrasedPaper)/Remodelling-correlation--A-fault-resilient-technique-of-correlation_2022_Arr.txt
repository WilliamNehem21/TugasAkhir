The utilization of stochastic computing for binary number computation is gaining popularity due to its numerous advantages over conventional weighted-binary computation. It offers a low-power, cost-effective alternative to complex arithmetic functions and has demonstrated significant reductions in size, circuit complexity, and power consumption. Stochastic architecture has proven to be more immune to noise compared to traditional binarization algorithms and is also applicable to various image processing tasks. However, various errors such as soft errors, correlation-induced errors, and random fluctuation errors can impact the accuracy and reliability of stochastic circuits, posing a significant challenge in generating the desired function using unreliable components in the presence of errors.

Transient or soft errors, induced by external radiation and manufacturing defects, can cause false logic at the output of the circuit, leading to bit-flips in stochastic bitstreams and undesirable correlations between numbers. This vulnerability to errors has prompted the need for a technology-independent framework to observe error-free output in complex circuits with minimal hardware. Additionally, the reliability of a circuit's performance is shown to be unaffected by subtle changes in correlation status.

As technology continues to advance, circuits are becoming more susceptible to transient faults induced by factors such as cosmic rays, capacitive coupling, electromagnetic interference, and power transients. Furthermore, the probability of a given number in a single-level circuit may change when considering multi-level circuits, presenting another challenge in stochastic computing.

Correlation between bitstreams, whether as cross-correlation or auto-correlation, has been identified as a leading source of inaccuracy in stochastic circuits. While earlier correlation in stochastic circuits was vaguely identified as inaccurate output caused by a pair of bitstreams passing through an AND gate, recent research has quantified and definitively identified correlation in stochastic computing.

With semiconductor technology advancements leading to reduced feature size and increased scalability, circuits are becoming more susceptible to soft errors, primarily caused by alpha particles and high-energy cosmic rays. Although soft errors are not unique to stochastic circuits, their properties make them more tolerant to soft errors than weighted-binary logic circuits. Notably, transient or soft errors are of growing concern for nano-scale devices due to their increasing prominence as device features are downscaled to sub-micron ranges.

An analysis has been conducted to reduce errors at different degrees of transient faults, and a proposed approach has demonstrated a lower deviation in output compared to a non-priority-based approach. This method has shown the ability to handle high error rates with less hardware and achieve the desired value with fewer iterations. However, the efficacy of this method heavily depends on the presence of correlation-sensitive logic blocks in the circuit, and careful consideration is needed when placing recovery (reco) blocks to prevent error propagation.