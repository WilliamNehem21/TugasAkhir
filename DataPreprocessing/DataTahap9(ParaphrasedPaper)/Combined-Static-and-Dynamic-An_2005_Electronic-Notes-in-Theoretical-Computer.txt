The paper presents a method for conducting static analysis that closely resembles the behavior of dynamic execution. Unlike dynamic analysis, which assesses properties based on event traces from actual program runs, the proposed approach leverages graph-free analysis to align static analysis more closely with dynamic execution. The authors extend this graph-free static analysis to a generic analysis applicable to dynamic analysis as well.

In their method, known as jnuke, static analysis mimics dynamic execution, employing non-deterministic control flow and graph-free data flow analysis to enhance data locality. The analysis algorithm runs until a termination condition is met or the entire abstract state space has been explored. The program state space iteration is separate from the analysis logic. A generic control flow module governs symbolic execution of instructions, while the analysis algorithm handles the representation of (abstract) data and the analysis semantics.

The control flow module utilizes a priority queue iteration, executing a complete computation path as long as unvisited successor states exist, without storing the flow graph. The module selects an instruction from a set of unvisited states, runs the specific analysis algorithm on that state, updates the abstract state, and checks the properties of interest. Valid successor states are added to the queue of states to visit, with duplicate avoidance mechanisms in place. Branch instructions and potential exception targets are also incorporated into the state space.

The paper observes that certain Java bytecode instructions do not influence control flow, and thus the algorithm does not store the current state if an immediate successor instruction is eligible. States are only stored if they are the target of branch instructions to reduce memory usage. The paper stresses that although this may result in visiting a state twice in some cases, the occurrence of this overhead is minimal.

Furthermore, the paper discusses how a generic analysis represents program states and event handlers, outlining the information used by the generic analysis and detailing the role of the environment as a proxy for the virtual machine in static analysis. The discussion touches on the challenges of achieving conceptual isomorphism between static and dynamic analyses, particularly in the context of pointer analysis accuracy.

The paper also examines the differences between context-insensitive and thread-local properties in the context of static and dynamic analyses. It sheds light on the challenges associated with run-time verification and the creation of new analysis instances for each method call and thread.

The authors address the approach for calculating the set of all possible program states in static analysis, as well as the storage of method call effects as summaries. They also highlight the potential for splitting up the analysis algorithm into a generic algorithm and its environment, with the precision of the analysis hinging on the approximation of pointer aliasing.

Finally, the paper touches on the comparison between static and dynamic analysis, and the use of a graph-free analysis to maintain proximity to program execution, enabling the reusability of the algorithmic part for dynamic analysis. Experiments with jnuke show that the static variant of a stale-value detection algorithm is faster but less precise than the dynamic version, emphasizing the benefits of using static information to reduce the overhead of run-time analysis. The paper concludes by highlighting the potential for combining static and dynamic analysis in a tool that applies run-time verification to test cases resulting from static analysis reports.