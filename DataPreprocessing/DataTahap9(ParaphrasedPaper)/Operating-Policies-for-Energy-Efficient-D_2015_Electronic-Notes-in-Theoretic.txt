The widespread challenges associated with providing large-scale computing services that do not relate to functionality are extensively documented in academic literature. Among these challenges, the escalating costs of energy have emerged as a paramount concern. The expenses tied to energy now surpass the total cost of ownership (TCO) of IT infrastructure, and it is projected that data center operators will allocate more funds to energy costs than to hardware infrastructure over the next five years. According to the U.S. Environmental Protection Agency (EPA), data center computing accounts for 1.5% of electricity consumption in the United States, and Gartner estimates that the ICT industry was responsible for 2% of global CO2 emissions in 2007. Furthermore, the power consumed by data centers in Western Europe was estimated to be 56 terawatt-hours per year in 2007, with projections indicating that this figure will double by 2020. As a result, there is an urgent need to enhance the energy efficiency of IT operations.

The utilization of cloud services and information processing has become a major trend, with one of the most notable advantages being the flexibility offered by the cloud. It facilitates the conversion of capital expenditure into operational expenditure, which is highly advantageous for launching new services. Additionally, given the substantial increase in the volume of data being collected for commercial, scientific, or medical purposes, the large capacity of data centers is ideal for processing such massive datasets. The cloud's provision of an illusion of virtually unlimited computing resources on demand makes cloud computing essential for extracting valuable insights from the enormous amount of data available.

Effectively managing energy consumption in distributed systems presents significant challenges, particularly in addressing workload variability. Various measures can be applied to mitigate the impact of fluctuating supply and demand. For example, a range of load balancing techniques and traffic shaping measures can be employed to regulate demand and prevent resources from becoming excessively overutilized during periods of high demand. An alternative approach involves dynamically managing the supply of service capability by making more servers available during peak demand. Slegers et al. investigated the problem of determining the optimal allocation of servers to different services under variable loads in order to minimize a performance-based cost function.

The remainder of this paper is structured as follows: the following section provides an overview of the context of this work in relation to previous research on energy reduction. Section 3 describes the system model and introduces six heuristic strategies for controlling the number of servers powered on and off. This is followed by a brief description of the simulation environment in Section 4, after which the results of the experiments are presented and discussed. Finally, some conclusions are drawn.

There are some limitations to our approach. Firstly, we have only examined delays that are negatively exponentially distributed, which may not reflect real-world conditions. Additionally, we have assumed that all servers are identical, whereas in reality this may not be the case. It would be beneficial to consider more than one type of server and to explore the impact of using different server configurations on system performance.