The New Mexico chili pepper (Capsicum annuum) is highly popular in the southwestern region of the United States due to its mildly pungent, crisp, and smoky flavor. Often referred to as chiles, the pepper is a significant cash crop in New Mexico, covering an area of approximately 8,000 to 10,000 acres annually. These peppers are utilized for consumption, processing into dried spice, or as decorative items, such as being strung on ristras.

Different activations functions, such as Leaky ReLU, ELU, Maxout, and Probout, are used to process input data, with the activation of the function being denoted as zi, j, k located at (i, j). Details about these activation functions can be found in the referenced literature.

Object detection has evolved over the years, with recent advancements leveraging computer vision to identify the location and nature of objects in space. There are generally two eras in the progression of object detection: traditional object detection before 2014 and the use of deep learning (DL) for object detection after 2014. The introduction of DL techniques has overcome limitations related to computational power and trainable image representation, as described in the referenced survey on object detection.

The Viola-Jones detector, introduced by Viola and Jones (2001), was developed with the aim of achieving robust, fast, and real-time detection. The authors focused on simple features instead of pixels to expedite the detection process, making three main contributions: the integral image method, an algorithm based on Adaboost for feature extraction, and a cascade method for classification. This method was also applied to facial recognition, demonstrating its robustness.

The Histograms of Oriented Gradient (HOG) detection system, presented by Dalal and Triggs (2005), utilizes edge direction and gradient intensity to analyze image appearance. This system builds upon the Viola-Jones detector and represents a significant development in object detection.

The Deformable Part-based Model (DPM), developed by Felzenszwalb et al. (2008) based on the work of Dalal and Triggs, establishes HOG descriptors via histogram gradient magnitudes within each 1D pixel. Learning is accomplished on the Pascal training data using a latent SVM, leading to outstanding performance in the Pascal Visual Object Classes (VOC) detection challenge.

Furthermore, convolutional neural networks (CNN) have seen significant advancements, with the emergence of models like AlexNet and the fast R-CNN, which achieved close to real-time object detection speeds. The Fast R-CNN and Faster R-CNN models have demonstrated notable improvements in detection speed and performance metrics compared to their predecessors. The YOLOv3 architecture has shown promising results in reducing the performance gap with the Faster R-CNN, particularly in terms of detection speed and mean average precision (mAP).

To experimentally verify the proposed techniques, thermal and RGB cameras were utilized to capture images of chili plants, enabling the evaluation of object detection algorithms in complex environmental settings.

In the experimentation results section, the authors present the findings of utilizing various techniques, including the HOG algorithm, the Mask R-CNN architecture, and the YOLOv3 model, to detect chili peppers in challenging environmental conditions.

The Mask R-CNN architecture was able to achieve a mean average precision (mAP) of 0.872 in training and 0.896 in testing on the RGB dataset, with a computational time of 40.79 seconds per test image. In contrast, the YOLOv3 model demonstrated computational speeds approximately ten times faster and achieved 100% precision accuracy (mAP) in both training and testing, with a computational time of 3.64 seconds per test image.

The YOLOv3 model exhibited superior real-time detection capabilities and demonstrated potential for application in robotic harvesting. However, challenges were observed in detecting objects in environments with high debris and overlapping artifacts in RGB images. Thermal imaging was shown to address these challenges, particularly in the context of real-time robotic harvesting, by providing significant features for object detection and improving accuracy predictions in complex lighting and environmental conditions.

Additionally, it is suggested that further research should focus on improving object detection in scenarios with dense debris and poor ambient lighting by expanding the diversity of the training dataset and including multiple classes and image variations to mitigate overfitting.

Overall, the study demonstrates the potential of advanced object detection algorithms in agricultural settings, particularly in the context of real-time robotic harvesting, and highlights the importance of leveraging diverse imaging techniques to address environmental challenges.

Reference:
[Provide the details of the referenced literature mentioned in the original paper.]