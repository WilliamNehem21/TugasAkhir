ASIC platforms offer high-performance and high-speed computing capabilities while consuming low power. However, their fixed architecture limits their flexibility when adopting different designs, which is particularly important in neural network implementations that depend on various network and communication parameters.

In our research, we utilize a 32-bit floating-point unit (FPU) shared by four cores on each tile. The latency in the IP core, representing the number of cycles it takes for an accumulation to propagate through the block from input to output, is 14 cycles at 250 MHz.

Real-world applications such as the World Wide Web, medical informatics, social networks, and machine learning libraries make use of graph-based algorithms. Pioneering Own Evaluative Template Systems (POETS) with the capability of fast and parallel processing at a large scale utilize graphs to map applications to the hardware. To facilitate graph processing, our framework provides high-level programming models for users to easily create the graphs and edges without needing to deal with low-level FPGA coding. Users need to consider how to divide their application components into vertices and edges. For example, in the case of spiking neural networks (SNNs), the neurons are vertices, and the edges represent the synaptic weights between the neurons. Presently, there are two different toolchains for mapping the simulations and applications to hardware, namely, graph schema and Polite.

Polite is another high-level programming environment toolchain similar to the vertex-centric paradigm, supporting both synchronous and asynchronous messaging. It is a layer of abstraction that manages mapping arbitrary graphs onto the Tinsel overlay. Polite serves as a C++ light software layer on top of the Tinsel hardware, designed to implement a graph-based event-driven abstraction while hiding architectural details from the user. Similar to graph schema, the vertices receive events, and if the vertex state changes, it will send a message via the edge to the other connected vertices. The event messages are handled by the following event handlers.

Machine learning algorithms have been instrumental in tasks related to automation, recognition, classification, and prediction. Artificial neural networks, a class of machine learning models inspired by biological counterparts, continuously transmit real-valued signals between neurons, which can be interpreted as firing rates. In contrast, spiking neural networks (SNNs) operate via discrete events, or spikes, mimicking action potential generation in the brain. SNNs offer significant energy savings due to their sparse event-driven nature, but training and simulating such models remains challenging.

In larger networks, the number of messages exceeds that of clocked synchronization (CS). However, removing global synchronization can accelerate computation, especially in non-fully connected networks running on distributed, federated, or heterogeneous systems, facilitating parallelization. Implementing this method on our platform, in addition to the reviewed benefits of Globally Asynchronous Locally Synchronous (GALS), we anticipate greater capability to speed up computation and communication due to the lack of global clock connections.

In this study, we introduce Hardware Idle Detection (HID) for neuromorphic event-driven system synchronization based on termination detection. A hardware barrier synchronization will synchronize the event-based neurons in the HID method. This method is designed for globally asynchronous applications and uses a signal to ensure there are no undelivered messages in the system. HID identifies an event when there is no thread in the system with spikes across the network.

POETS is designed to efficiently simulate highly scalable event-based models, particularly focusing on simulating spiking neural networks that implement parallel distributed processing at a large scale.

Routing algorithms serve the purpose of directing data packets, with the goal of efficiently determining the most effective path for transmitting a packet within Network on Chip (NoC)-based neuromorphic systems. Message delivery in the POETS system is guaranteed by the hardware, provided that all threads eventually execute the messages available to them. Threads communicate with each other via mailboxes, using unicast and multicast methods for message communication between threads. The programmable routers automatically propagate messages to any number of destination threads distributed throughout the cluster. If a router supports multicast routing, neurons with a high fan-out can communicate efficiently, minimizing inter-FPGA bandwidth and offloading work from the processing cores.

We conducted tests using an x86 machine with 28 cores, with the capability to efficiently simulate highly scalable event-based models. 

The POETS ecosystem mapping strategy's efficiency depends on the number of vertices and edges in the mapped graph. Communication between neurons on the same thread or different threads is crucial, as threads on neighboring mailboxes communicate faster compared to threads on further mailboxes, leading to varying time and bandwidth consumption. The execution of Brian simulations revealed that the hardware implementation on POETS is more than twenty times faster than the Brian simulator.

Synchronization is crucial in designing neuromorphic event-driven systems for simulating SNNs. In this work, we introduce Hardware Idle Detection (HID) as a novel synchronization method for neuromorphic systems. Implementing these algorithms on hardware, we introduce POETS as a new large-scale neuromorphic system that is flexible using FPGA clusters, easily scalable by adding more FPGA boards, reliable, and fast due to parallel processing of data and high-speed interconnection bandwidth.

We also discuss the use of synchronization methods such as clocked synchronization (CS) and Globally Asynchronous Locally Synchronous (GALS), and conclude that HID is the best synchronization approach considering speed and spiking accuracy.