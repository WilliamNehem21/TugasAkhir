We introduce a new unsupervised approach for creating general extractive multi-document summaries through a ranking system that utilizes dynamic programming (DP). While previous cluster-based methods fail to adequately consider word informativeness, our framework comprehensively accounts for sentence relevance, diversity, informativeness, and length constraints. We employ density peaks clustering (DPC) to simultaneously obtain relevance and diversity scores for sentences. Our framework demonstrates superior performance on the DUC2004 benchmark, achieving a Rouge-1 score of 0.396, a Rouge-2 score of 0.094, and a Rouge-su4 score of 0.143, outperforming popular baselines including DUC best, FGB, and BSTM.

With the rapid growth of internet-based information, there is an increasing need for multi-document summarization (MDS) to distill comprehensive information from a large collection of documents. Most existing studies focus on extractive methods, which involve directly extracting notable sentences from source materials without modification and combining them to form a summary. In this article, we focus on extractive summarization from multiple documents and address four key issues: relevance, diversity, informativeness, and length constraints.

The article is organized as follows: Section 2 provides a detailed review of related research motivating our approach. Section 3 introduces our proposed multi-document summarization framework and outlines the summary generation process using dynamic programming technology. Sections 4 and 5 present the evaluation of the algorithm on the DUC2004 benchmark for multi-document summarization, followed by conclusions and future research directions.

Various extractive multi-document summarization methods have been proposed, including supervised methods such as hidden Markov models, conditional random fields, and RegSum. Sparse coding has also been applied to document summarization due to its effectiveness in image processing. However, supervised methods rely on a large amount of labeled data, requiring the availability of annotated documents relevant to the trained summarization model. Additionally, when the target of summarization or document characteristics change, the model must be retrained with reconstructed training data.

Some researchers have used generative models to efficiently model the Bayesian probability distributions for selecting salient sentences based on themes. Additionally, efforts have been made to reduce redundancy in summaries, for example, through maximal marginal relevance (MMR) approaches. In this work, we follow the cluster-based method but propose an integrated weighted score framework that evaluates salient scores and eliminates redundancy in the summary, employing dynamic programming for optimal sentence selection.

We introduce diversity scoring to argue that a good summary should not include similar sentences, especially when a document set contains a core topic and subtopics. We propose using maximal marginal relevance (MMR) and cluster-based method of density peaks clustering (DPC) to achieve a global diversity score that ensures minimal redundancy.

In our experiments, we varied the values of the parameters a, b, and g from 0 to 1.5 to determine the best-performing values for our framework. We used DUC2007 as our development set to investigate the relationship between the parameters a, b, and g in the integrated score framework. We evaluated our summarization method's performance using the Rouge 1.5.5 toolkit, which focuses on the occurrence of the same words between generated and reference summaries, and implemented the proposed integrated score framework for ranking sentences based on informativeness, relevance, and diversity scores.

Our experiments on standard datasets demonstrate the effectiveness of our method for multi-document summarization, showcasing its capability to create concise and informative summaries from large document sets.