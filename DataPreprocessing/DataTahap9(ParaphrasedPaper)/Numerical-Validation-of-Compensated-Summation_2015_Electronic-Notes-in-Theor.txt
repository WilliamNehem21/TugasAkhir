The capacity of computational resources is continuously increasing, with plans to achieve exascale computing (10^18 operations per second) within the next decade. However, in floating-point arithmetic, each operation is likely to introduce a rounding error, which can accumulate over the course of a computation, resulting in a significant deviation from the exact result. To address this issue, increasing the precision of computation is necessary, and one effective approach is the use of compensated algorithms. These algorithms are founded on the ability to accurately compute rounding errors for certain elementary operations, such as addition and multiplication, and rely on error-free transformations (EFT) to enhance accuracy. When using floating-point arithmetic adhering to the IEEE754-2008 standard and rounding to the nearest value, the rounding error of an addition can be precisely computed. We intend to analyze the influence of random rounding mode on algorithm 3, and investigate how compensated summation is affected by directed rounding. While the impact of directed rounding on compensated summation has been addressed, previous studies considered slightly different algorithms and did not account for instability detection. We have demonstrated the validation of compensated summation based on the fasttwosum algorithm using discrete stochastic arithmetic, even when error-free transformations are not valid due to the use of directed rounding modes. In future work, we plan to extend this analysis to other error-free transformations, such as twosum and twoproduct, to determine if discrete stochastic arithmetic can still be utilized to validate compensated algorithms for dot product and polynomial evaluation (compensated Horner scheme).