The advancement of information technology has created a need for document resources that facilitate theme discovery, information retrieval, and related processes. As a result, text clustering technology has emerged as an essential component of natural language processing, particularly in the context of document clustering. Text clustering techniques have achieved significant success in this area, with a focus on addressing the numerous linguistic phenomena present in document clustering, including synonyms and near-synonyms. This paper aims to utilize latent semantic indexing (LSI) to investigate and resolve these linguistic phenomena, thereby enhancing the performance of document clustering.

The experimental corpus, TANCORPV 1.0, is sourced from the Chinese Academy of Sciences, specifically from Dr. Tan Songbo, and the text classification corpus from Sogou Lab. From the 12 categories in TANCORPV 1.0, 12 classes are randomly selected, comprising a total of 2,400 texts, referred to as the Chinese Academy of Science Corpus 1. These texts range from 1 kb to 14.7 kb in size. Additionally, 1,000 texts from 9 classes are randomly chosen from the Sogou Lab text corpus, with the largest class containing 200 documents and the smallest containing 80 documents. Furthermore, 3,000 texts from 60 smaller classes are randomly selected, forming the Chinese Academy of Science Corpus 2.

The paper emphasizes the significant impact of feature transfer on the performance of latent semantic indexing. Increasing the feature transfer number can introduce non-existent feature co-occurrence information, which in turn affects the similarity between features and subsequently impacts the performance of latent semantic indexing. To mitigate this, the paper employs a method of feature selection based on document frequency (DF) to reduce the feature transfer number and eliminate non-existent feature co-occurrence information before decomposing via singular value decomposition (SVD). The DF method selects features based on their occurrence in the document collection while filtering the transfer number between features. The paper also proposes future research to explore feature selection based on conditional entropy between features and conditional entropy.