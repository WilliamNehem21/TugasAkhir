Debugging is a time-consuming activity in program design, and efforts in automatic debugging have garnered significant attention, with dedicated symposiums in the field. Automatic debugging is typically triggered when a test fails in one situation but passes in another, such as when a test fails in one program version but succeeds in another. In these cases, automatic debugging seeks out the smallest difference that causes the failure, aiding in identifying and rectifying the root cause of the bug.

A new testing method has been developed to introduce schedule-modifying instructions into concurrent programs, aiming to increase the likelihood of revealing concurrent bugs, such as races and deadlocks. This paper explores the integration of this testing approach with automatic debugging, emphasizing the importance of pinpointing the location of bugs by identifying the minimal set of instrumentations that expose the bug.

The detection and analysis of concurrent defects, such as race conditions and deadlocks, present challenges and are costly, often eluding detection until they reach the production stage. The increasing prevalence of multi-core processors underscores the need for robust testing and debugging of multi-threaded applications, leading to heightened focus from commercial entities like Intel, IBM, and Microsoft in developing methodologies and tools for this domain.

Extensive research has been conducted on testing multi-threaded programs, spanning areas such as data race detection, replay in distributed and concurrent contexts, static analysis, generating different interleavings to uncover concurrent faults, model checking, coverage analysis, and cloning, among others.

The paper describes the development of a new debugging tool based on noise creation testing technology, where noise creation involves introducing delays, random or otherwise, to modify the timing of the program under test. This approach seeks to identify the minimal set of noise containing instrumentations that reveal the bug, providing valuable information to developers. The paper also discusses the use of genetic algorithms to search for the set of changes with the highest likelihood of finding the bug.

The authors leverage AspectJ, an aspect-oriented extension to Java, to implement their work, enhancing its capabilities to support the modular implementation of various cross-cutting concerns. They also detail algorithms designed to identify the minimal amount of instrumentation needed to expose the bug, addressing the challenges of non-deterministic bugs and the expected size of the minimal group of changes needed.

Experimental work is showcased to demonstrate the feasibility of the proposed approach on both synthetic and real-world applications, with a focus on automatically detecting and addressing concurrent faults. The paper also highlights the potential for the developed algorithms to be adapted for parallel computing and their applicability in different usage scenarios.

The authors acknowledge the limitations and challenges associated with the proposed algorithms, noting the importance of practical applications and the need for alternative search techniques in non-monotonic scenarios. Additionally, they emphasize the significance of instrumentation points in influencing the probability of exposing bugs and the implications for test execution time and deadlock detection.

The paper concludes by discussing how their modifications to AspectJ can benefit other testing tools, particularly in coverage measurement and performance impact reduction, and outlines future directions for their research, including the suggestion of fixes for pinpointed bugs and further experiments on real applications.