One approach to address the discrepancy between training data and new samples from a specific writer is to transform the model into a writer-dependent (WD) model through writer adaptation. This involves converting the writer-independent (WI) model to the WD model using adaptation data from the specific writer. Writer adaptation faces the challenge of limited data, as a WI model with numerous parameters may overfit when adapted with limited adaptation data. Writer adaptation in deep learning is closely linked to techniques such as domain adaptation, transfer learning, and fine-tuning.

In this research, we propose a novel method for writer model-based adaptation using a connectionist temporal classification (CTC)-based model to achieve optimal Arabic online handwriting recognition. Our approach employs adversarial multi-task learning (MTL) to address the mismatch between deep features generated by the WI and WD models. In adversarial learning, two tasks are involved: the primary task of label classification and the secondary task of deep feature discrimination. We evaluated our method using two datasets, the Chaw and Online-Kahtt datasets, and found that it consistently outperformed both the WI and fine-tuned WI models with the same target writer data.

The paper is structured as follows: Section 2 reviews previous work on writer adaptation for online handwriting recognition. Section 3 explains the architecture of our proposed method. Section 4 presents the results and compares our architecture against the original WI model using both supervised and unsupervised adaptation settings. Lastly, Section 5 outlines our conclusions and suggestions for potential future work.

Several approaches to model adaptation have been proposed, including systems based on pre-trained time-delay neural networks (TDNNs), output adaptation modules (OAM), and deep transfer mapping (DTM). Some methods focus on adapting multiple layers of the model, including convolutional neural networks (CNNs) and fully connected layers, rather than exclusively focusing on the top layers. Additionally, deep learning methods have been utilized for features transformation adaptation, particularly for online Chinese handwriting recognition.

In this research, a minimax game is used to jointly optimize the primary task of label classification and the secondary task of features discrimination, with the goal of achieving a higher recognition rate for the modified WD model compared to the original WI model. This adaptation approach utilizes a discriminative sub-network and prioritizes capturing additional information from different abstraction levels.

The proposed method was evaluated using standard metrics such as character error rate (CER) and word error rate (WER). Handwriting samples not used during WI model training were utilized for the adaptation process. The evaluation involved handwritings from 84 writers for each dataset, with a specific number of training and testing samples selected for each writer.

The adaptation method is particularly relevant for Arabic handwriting recognition, as it considers the contextual influence of characters within words and aims to generalize despite potential data limitations. The authors acknowledge the potential benefits of using decoding techniques such as beam search decoder with language modeling and data augmentation for performance improvement.

This research is the first to approach writer adaptation for e2e models in the context of online handwriting recognition, specifically targeting Arabic language applications. The proposed adversarial MTL adaptation method has the potential to extend to other languages and types of e2e models, such as attention and self-attention models. Future research will explore applying adversarial MTL to attention-based models and investigating the impact of synthesized adaptation training data on performance.