In recent years, several methods for re-identification (re-id) in video surveillance have been proposed, falling into two main categories: feature representation and matching strategy. Research on feature representation has focused on generating robust body appearance representation, making use of color and texture information due to the low resolution of RGB images in surveillance environments. For matching strategy, metric learning and learning-to-rank methods have been extensively explored, with metric learning-based methods being particularly successful.

Despite their success, these multi-modal methods may not perform well in handling diverse environments due to offline learning of similarity metrics and potential errors in feature combination. To address these challenges, this paper proposes an effective online re-id framework. It leverages the complementary nature of clear face images and ambiguous body images and combines them using an online learned metric model and a feature funnel model based on feature reliability.

The paper is structured as follows: Section 2 reviews related works, Section 3 presents the proposed method, including features extraction, online metric model update, and the feature funnel model. Section 4 discusses experiments assessing the method's performance and comparing it to state-of-the-art approaches, and finally, Section 5 draws conclusions.

Re-identifying individuals based solely on appearance or geometric features can be challenging due to environmental variations. To address this, multimodal biometric systems are adopted to enhance reliability. The proposed framework utilizes both appearance and geometric features, and leverages P-N learning, a semi-supervised learning method, to incorporate clear face images into the online metric learning process, making the metric model adaptive to new environments.

The framework extracts noise-insensitive appearance-based and illumination-invariant geometric features from skeletal joints, and uses SIlvera ILTP histograms to overcome pose variation and illumination sensitivity. Additionally, the online update strategy is observed to adapt better to new environments compared to the offline strategy.

In summary, this paper introduces an online re-id learning framework overcoming the limitations of offline training, incorporating face information to update the metric model online and demonstrating adaptability to changing environments. The research was supported by multiple grants and funding sources.