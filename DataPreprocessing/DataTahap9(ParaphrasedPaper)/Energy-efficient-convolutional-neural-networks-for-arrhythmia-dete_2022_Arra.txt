The efficient implementation of energy in analog or digital hardware can be achieved by determining the parameters of the 7 biquad blocks of the second-order stage (SOS) architecture to achieve the desired transfer function of the bandpass filter. The high order of the filter allows for effective suppression of baseline errors and noise. Future hardware implementations will require a proper rearrangement of the second-order stages to maintain the amplitude within a reasonable range between the filter stages.

Due to the complexity of input signals, the linear nature of convolution cannot capture all the underlying information. Therefore, activation functions are used to map the previous layer to the next one in a non-linear manner. However, the application of multiple filters on the same input can substantially increase the dimensions of the feature maps, thus the pooling operation is responsible for condensing the complexity of the CNN by down-sampling information. Subsequently, the generated features of the CNN are fed into fully connected layers with dense connections between them. The selection of the number of layers, kernel, pooling size, and the number of nodes in the fully connected layers are crucial hyperparameters that define the structure of the CNN and should be chosen appropriately based on network performance and learning ability.

Using a CNN architecture for the continuous classification of arrhythmia over a long duration, such as 12 hours while wearing a smartwatch, is highly energy inefficient. It is more practical to limit the detection of arrhythmia to short repeated intervals, such as using 7-second intervals. Ideally, the classifier should be able to decide about arrhythmia or non-arrhythmia without examining the entire 2 minutes.

Chaur et al. also developed a 1D CNN for the detection of atrial fibrillation, consisting of 10 layers of convolutions followed by pooling operations and 2 fully connected layers, with one softmax layer output. The number of filters at each convolutional layer ranges from 32 to 512, resulting in 3,933,634 trainable parameters, which is 34,505 times more parameters than the proposed model 4.

In this study, we propose energy-efficient recurrent CNN architectures for long time series and apply our approach to the detection of atrial fibrillation in ECG signals. Our workflow focuses on the development of lightweight, fully-segmented models with significantly fewer model parameters than previous studies. Incorporating energy consumption as an additional metric for performance evaluation enables us to generate architectures that can be easily embedded on small physical hardware devices.

Our proposed model consists of two convolutional layers and one fully connected layer, with a total of 114 parameters, which is millions of times smaller than the model sizes suggested by others. After energy optimization, our model achieved an accuracy of 95.3% on a test set of 4800 ECGs. Using the optimal energy classifier allowed us to reduce energy consumption by 81% for the classification of 2-minute signals. Specifically, only an average of 3.09 signal segments of 7 seconds, or approximately 21 seconds, were needed for the classification of the whole 112 seconds. Mistakes due to wrong segment-wise decisions are avoided by recurrently utilizing the information from previous segments.