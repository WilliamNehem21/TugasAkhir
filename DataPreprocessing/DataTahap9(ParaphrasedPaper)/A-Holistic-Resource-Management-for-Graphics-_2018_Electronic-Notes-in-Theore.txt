This paper presents two main contributions. Firstly, it proposes a systematic architecture for managing the sharing of GPU resources in cloud computing environments for general-purpose use, with a focus on application deployment time and ensuring quality of service (QoS) during operation. Additionally, the architecture takes into account performance and energy consumption as key factors. Secondly, the paper conducts a comparative experimental study to assess the architectural impact on performance, power, and energy consumption on heterogeneous GPUs.

The subsequent sections of the paper are structured as follows: Section 2 introduces related work, Section 3 presents the proposed architecture, Section 4 introduces heterogeneous GPU benchmarking and analysis, Section 5 explains the GPU benchmarking experiments and their results, and, finally, Section 6 concludes the paper and discusses future work.

The paper discusses the importance of GPU occupancy as a metric for analyzing performance in general-purpose GPU use. GPU occupancy is defined as the ratio of active threads to the maximum number of threads in a streaming multiprocessor (SM), with a value between 0 and 1. The paper describes an experiment where the number of threads per block was gradually increased to the maximum (1024 threads per block) while keeping the number of blocks constant at 80 x 80 to ensure simultaneous working of SMs. The paper details how the increase in the number of threads per block affected power consumption and execution time and discusses findings pertaining to Fermi C2075 and Kepler K40c GPUs.

The paper presents findings related to power consumption and energy savings in relation to the number of threads per block and specific matrix multiplication sizes for Fermi C2075 and Kepler K40c GPUs. It discusses the impact on performance and power consumption in the context of varying GPU workloads and resident blocks in the SM, highlighting the differing behavior of the GPUs. The paper also discusses the correlation between GPU occupancy, GPU memory types, and hardware block scheduling factors with power consumption in Fermi C2075 GPU and examines the trade-off between performance and energy consumption for both Fermi C2075 and Kepler K40c GPUs.

Furthermore, the paper proposes an adaptive architecture for managing heterogeneous GPU resources in cloud computing environments, focusing on performance and energy consumption factors. It introduces a heterogeneous GPU analyzer to study the architectural behavior of heterogeneous GPUs in terms of performance, power, and energy consumption. Additionally, it aims to develop a novel energy consumption prediction model and an energy-efficient scheduling policy to allocate GPU applications to the most energy-efficient virtual machine, considering execution time as a key factor. Finally, the paper aims to develop an adaptive management framework to maintain QoS during operation time, taking into account energy efficiency, performance, and cost trade-offs.