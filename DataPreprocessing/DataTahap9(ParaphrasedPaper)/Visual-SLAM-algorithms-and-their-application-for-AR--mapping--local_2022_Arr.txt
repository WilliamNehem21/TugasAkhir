This academic paper categorizes and summarizes recent visual simultaneous localization and mapping (VSLAM) algorithms and their applications in augmented reality (AR), mapping, navigation, and localization. VSLAM is essential for enhancing the AR experience by adding virtual objects to the real-world environment using localization and environment structure information. The paper discusses various types of VSLAM techniques depending on the camera type, such as monocular, stereo, and RGB-D, as well as their applications in different scenarios.

The paper highlights the advantages of using cameras for mapping and localization, including their affordability, ability to gather detailed environmental information, and compact design. It also discusses the limitations of using only visual sensors for SLAM, and proposes solutions such as combining visual sensors with laser rangefinders to improve accuracy.

Furthermore, the paper provides an overview of specific visual SLAM algorithms, such as Monoslam and ORB-SLAM, and their features. It also discusses the limitations of existing evaluation methods for SLAM algorithms and suggests exploring new approaches to accurately evaluate the performance of SLAM systems.

Overall, the paper aims to provide a comprehensive review of visual SLAM algorithms and their applications in various fields, emphasizing their significance in advancing augmented reality experiences and robotic applications.