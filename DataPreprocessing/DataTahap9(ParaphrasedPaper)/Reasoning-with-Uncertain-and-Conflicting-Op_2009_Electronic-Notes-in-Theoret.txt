Over the past few years, the widespread use of online services and applications such as online shops, social networks, and peer-to-peer applications has raised significant security concerns. One of the key issues is that users often have to interact with numerous services and other users whom they may not know well and with whom they have limited or no prior experience. In order to determine the trustworthiness of these services and users, and thus assess whether they will behave as expected (e.g., handling personal information responsibly and providing reliable information sources), it becomes essential for users to have access to reliable information on their trustworthiness.

Reputation systems have been developed to address this need by aggregating user recommendations about the trustworthiness of services and other users to derive reputation values, based on a specific trust model. However, establishing a reliable trust model is challenging due to the uncertain nature of trust statements and the potential for conflicting opinions. Consequently, it is necessary to reason with uncertain indications and degrees of support, as well as address conflicting opinions within trust models in an effective manner.

The paper highlights that existing trust models have not adequately resolved the handling of conflicting opinions and the evaluation of trust graphs. As a solution, the authors propose new representations for trust relations and values that consider the degrees of belief, ignorance, disbelief, and conflict. They introduce an approach for reasoning and computing with these trust values, which builds upon their previous trust representation approach while addressing the limitations observed in current models.

The authors first present a deterministic calculus for discrete trust values and then extend this approach to encompass continuous values. The proposed evaluation approach effectively handles conflicting opinions and avoids counterintuitive effects caused by re-normalizations, making it suitable for application to trust graphs with arbitrary topologies.

The paper also introduces inference rules that define the logic of reputation systems regarding how opinions can be combined and how the resulting reputation value depends on the trust values of the first-hand trust relations. The authors propose deterministic operators for conjunction, disjunction, negation, recommendation, and consensus for the formulation of inference rules. They demonstrate how these operators can be applied to both discrete and continuous trust values, and provide examples of typical trust inference rules.

In addition, the paper outlines a new approach for computing with continuous trust values, based on a random experiment involving the selection of discrete trust values for first-hand trust statements. The resulting discrete reputation value is then computed using a deterministic approach, and the paper defines the resulting continuous reputation value based on the probabilities of belief, ignorance, disbelief, and conflict.

Overall, the paper presents a comprehensive framework for managing and computing trust values in reputation systems, addressing key challenges such as handling conflicting opinions and uncertainties in trust statements. The proposed approaches offer promising solutions for enhancing the trustworthiness and reliability of online services and applications in an increasingly interconnected digital landscape.