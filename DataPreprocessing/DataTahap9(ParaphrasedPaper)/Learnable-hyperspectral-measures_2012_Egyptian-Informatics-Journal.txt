The use of hyperspectral measures offers an alternative method for obtaining distinctive information about spectral signatures. These measures are straightforward and require minimal computational resources. They can effectively capture the similarity between two spectra, as demonstrated in the Spectral Angle Mapper (SAM), where the similarity values range from 0 (highly similar) to 1 (highly dissimilar). The proposed approach aims to replace static threshold hyperspectral measures with learnable hyperspectral measures by utilizing the values of these measures as similarity patterns and employing a classifier to act as an adaptive similarity threshold. The resulting similarity patterns are versatile, as they can capture the specific notion of similarity appropriate for each spectral region. Two similarity patterns are suggested: the cosine similarity vector for the second spectral derivative pair and a composite vector of various similarity measures values.

In version 1.1, cosine similarity vectors for the second order derivatives of spectral signature pairs are computed to form similar and dissimilar patterns, which are then classified by Support Vector Machines (SVM) acting as an adaptive similarity threshold. This approach is applied to the entire hyperspectral space of the spectral signature. In version 2.1, different similarity values are calculated using nine similarity measures to form similar and dissimilar patterns, which are then classified by SVM to act as an adaptive similarity threshold. Both versions have been implemented twice using the full hyperspectral space and subspaces. MATLAB version R2009b and libsvm have been employed for implementing the hyperspectral measures.

An analysis conducted by Wu and Chang demonstrated that certain spectral classes have very similar signatures, while others have less similar or dissimilar signatures. Additionally, some classes are highly mixed, indicating a high noise level during data acquisition. One-Versus-All (OVA) classification was not suitable for highly mixed classes, as the spectral signatures of the separated classes often overlapped, leading to inefficient discrimination of similarity patterns. On the other hand, One-Versus-One (OVO) classification proved to be more effective, as each OVO classifier was trained using samples of only two classes, resulting in better discrimination and shorter training times.

Previous experiments focused on nine out of 17 classes due to the small sample size of the remaining eight classes. The Nearest Class Average (NCA) approach was applied to the neglected classes to calculate the classification accuracy for each class. The proposed approach outperformed other methods such as Principal Component Analysis (PCA) and NCA, as confirmed by experimental evaluation and a right-tail z-test comparing its performance with the NCA approach. While PCA performed poorly, NCA achieved good results but was computationally expensive and time-consuming compared to the proposed approach versions.

In conclusion, it was found that using simple learnable hyperspectral measures surpassed complex or manually tuned techniques in classification tasks. The proposed approach demonstrated robustness and achieved significant improvements in classification accuracy compared to competitive approaches.