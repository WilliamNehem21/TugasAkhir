With the evolution of hardware and the emergence of new interconnect technologies, there are various considerations for application developers. As hardware upgrades occur, developers need to reassess the performance of different hardware generations to effectively design system software that can capitalize on improved data transfer rates. Additionally, the proliferation of new interconnects stemming from novel hardware features may have implications for application performance and thus warrants systematic investigation.

Different types of data center applications, such as HPC workloads, deep learning training and inferences, big data analytics, and cloud-based microservices, exhibit distinct performance characteristics. It is crucial to separately and meticulously evaluate the impacts of new interconnect technologies on these varying workloads. Therefore, there is a pressing need to conduct comprehensive benchmarking experiments to analyze the performance characteristics of modern data centers and HPC interconnects under diverse application scenarios. This necessitates an extensive survey of advanced interconnects in modern data centers and HPC clusters, along with associated representative benchmarks, to enhance the community's understanding of these technologies.

Ethernet has traditionally been a widely used interconnect for HPC and data center clusters. Initially, 1 Gb/s Ethernet (1-GigE) was prevalent, but with advancements in CPU performance and I/O speed, it has become a bottleneck. The demand for higher bandwidth and data transfer rates has led to the development of Ethernet with 10-GigE, 25-GigE, 50-GigE, and even 100-GigE. As of June 2022, 25-GigE is the most commonly used interconnect in the top500 list, with Ethernet constituting nearly 50% of the list.

RDMA over Converged Ethernet (RoCE) has been developed to leverage the benefits of RDMA over Ethernet networks, supporting RDMA over layer 2 networks, while RoCE v2 extends this support to layer 3 networks. InfiniBand (IB), provided by NVIDIA, is another prevalent interconnect technology and the second most popular interconnect family in the top500 list. It features higher bandwidth (up to 400 Gbps) and is widely deployed in top-level clusters.

RDMA-capable networks, particularly InfiniBand, support four types of transport modes: reliable connection (RC), reliable datagram (RD), unreliable connection (UC), and unreliable datagram (UD). These modes have varied support for different RDMA operations and are compatible with different network topologies. Moreover, IB incorporates a congestion control mechanism, and the introduction of GPUDirect RDMA has significantly enhanced data communication performance among GPUs.

Several benchmarking tools and tests, including perftest and network_load_test, are utilized to evaluate the performance of different interconnects under varying scenarios. These tools enable the assessment of throughput, latency, and congestion impact and aid in understanding the impact of congestion across systems with different networks. Additionally, newer storage hardware, such as NVMe SSDs, relies on different drivers and libraries in data centers, and benchmarking tools like NVMe perf are used to evaluate their performance.

Application-level benchmarks, such as MPI and PGAS-based benchmarks, along with big data system benchmarks like HiBench, MRBench, and TPC benchmarks, are employed to represent a broad range of data center applications and assess their performance on different interconnects. These benchmarks have been designed for specific application scenarios and demonstrate their applicability and convenience in experimenting with different interconnects.

The paper was supported by the NSF research grant CCF#2132049, the Exascale Computing Project, and the US Department of Energy, among others. The research was conducted using computing resources provided by the Laboratory Computing Resource Center at Argonne National Laboratory, USA, and the Cyberinfrastructure and Research Technologies (CIRT) at the University of California, Merced.