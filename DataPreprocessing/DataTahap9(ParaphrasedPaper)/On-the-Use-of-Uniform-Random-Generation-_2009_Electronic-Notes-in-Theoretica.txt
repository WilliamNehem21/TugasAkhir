The development of efficient and automated testing methods poses a significant challenge for the software validation community. This paper demonstrates the relevance of a uniform random generation process for finite automata, as introduced in a recent work by Bassino and Nicaud, to various aspects of automatic testing. The main contribution is the integration of two major testing approaches, namely model-based testing and random testing, resulting in a novel testing technique that has been successfully applied to a realistic case study. Additionally, the use of random testing on an implementation of the Chinese postman problem revealed an error in a well-known algorithm. Furthermore, the paper provides statistics on model-based testing algorithms.

The quest for producing secure, safe, and bug-free programs presents a formidable challenge in modern computer science. Verification and testing are two complementary approaches to address this issue. While verification techniques offer mathematical proof of code or model safety, their complexity makes them difficult to apply to large-scale systems. On the other hand, testing techniques do not provide formal proof but are still pertinent. The paper also discusses statistics on test suites generated in a pure model-based testing approach based on finite state machine (FSM) coverage, which may aid validation engineers in selecting appropriate testing techniques and enhance comprehension of coverage criteria.

The paper presents an approach that utilizes the statistics of test suites to generate a specified number of tests based on a given automaton and coverage criterion. This approach aims to augment the number of tests obtained using the selected test generation algorithm on the original automaton, rather than reducing the test suite.

The authors also describe a formal model of the system, presented as an abstract machine and a Java implementation, along with several variations of the implementation known as mutants. These mutants, each intentionally containing a mistake, serve to evaluate the effectiveness of a test suite. A greater number of killed mutants indicates a more efficient test suite.

The execution of tests aims to identify discrepancies between the obtained results and the expected results based on the model. This conformance relationship is established by observing the outputs of different commands and comparing the status codes. A test fails if the observed codes do not align with the expected codes at a given step during test execution.

The paper demonstrates that the average length of test suites remains relatively consistent for a given number of final states, while computation time decreases with an increase in the number of final states. The authors attribute this to the simplification of finding the optimal path in the Chinese postman algorithm due to the addition of final states and associated backward transitions. However, the resulting test cases are longer.

The paper emphasizes the concept of uniform random generation in testing, highlighting the importance of randomness not being influenced by the tester and ensuring that every element has an equal chance of selection. The findings reveal that randomly generating strongly connected finite automata and testing them for minimal paths can expose program failures, as demonstrated by an identified automaton causing program failure.

Furthermore, the paper explores an original combination of random and model-based testing to expand test suite sizes and illustrates how random testing can uncover bugs in widely-used algorithms. Experimental data and statistics on various test generation algorithms based on automata are also provided.

The adopted approach in this paper is based on a random approach, which, despite being considered a relatively poor method for generating data, has proven to be effective in uncovering errors and instilling confidence in software. The paper specifically highlights the efficient application of random testing in test data generation, such as in the Dart approach, which combines static and dynamic program analysis for software testing.

Recent developments in testing have seen the exploration of random path generation in various works. For instance, Dwyer et al. detail the inclusion of a random process in depth-first search algorithms to enhance test suites. The paper also introduces an algorithm for uniformly generating paths of specified lengths, successfully applied to very large models.

The paper introduces a test generation technique that employs a test sequence length-guided approach. This approach aims to automate the generation of test purposes for the TGV tool, with the goal of providing a user-defined number of tests. To the best of the authors' knowledge, this approach has not been previously explored.