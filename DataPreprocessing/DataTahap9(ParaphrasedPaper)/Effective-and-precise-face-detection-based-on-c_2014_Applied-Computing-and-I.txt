The above criteria enable a significant reduction in the occurrence of false positive identifications without compromising the detection rate. The proposed method has been tested on three datasets containing a total of 180 samples, encompassing both 2D and depth images, with the face positions manually labeled for testing purposes.

The depth information obtained from the Kinect sensor, which provides the relative distance of each pixel from the sensor at the time of image capture, is not effective for distinguishing between different individuals at a distance due to high inter-class similarity. However, it can enhance the robustness of a face detector by reducing sensitivities to various factors such as illumination, occlusions, changing expressions, and poses, owing to its low intra-class variation. The usage of Kinect devices has gained popularity due to their affordability and availability, and initial benchmark datasets have been compiled for 3D face recognition or detection.

Similar to other methodologies proposed in existing literature, this study aims to leverage depth information to minimize the occurrence of false positive detections and enhance the accuracy of detections. The authors employ a 2D multi-step algorithm to achieve a coarse-to-fine classification, followed by refining the face location quality using a 3D tracking approach.

A third filtering rule, based on the depth map, is established to eliminate flat or uneven objects, such as candidate faces found in a wall or tree leaves, respectively. Integration of color and depth data facilitates the extraction of candidate face regions from the background, and measures of depth and regularity are utilized to filter out false positives.

Regrettably, there is a dearth of freely available large datasets for face detection that include both color and depth maps, particularly containing challenging images with complex backgrounds. Although several datasets exist for face recognition using the depth map, the face detection step in those datasets is relatively straightforward. Consequently, the proposed approach has been evaluated using a gathered dataset, which will be made publicly available for future comparisons.

For the purpose of aligning color images and depth maps of the faces, calibration data for the depth and color cameras of the Kinect are computed using a method proposed by Herrera et al. (2012). This approach entails computing both the intrinsic parameters of the depth and color cameras and the extrinsic parameters between the two cameras. Subsequently, 3D positions of the depth samples are determined using the intrinsic parameters of the depth camera, followed by reprojection of the 3D samples into the 2D color image reference system utilizing both the intrinsic and extrinsic parameters of the color camera. This procedure results in the association of a color and a depth value with each sample.

The depth map also provides valuable information regarding the flatness or unevenness of candidate face regions. A segmentation procedure is initially applied, followed by the calculation of the standard deviation (std) of the pixels of the depth map within each face candidate region. Regions with a std outside a predetermined range [0.15, 4] are eliminated.

The segmentation of both the color and depth maps is carried out in accordance with the method of Dal Mutto et al. (2012), which leverages the normalized cuts spectral clustering algorithm proposed by Shi and Malik (2000) to jointly exploit geometry and color information for optimal performance.

Following the joint calibration of the depth and color cameras, it becomes feasible to compute the 3D coordinates of each sample in the acquired depth map, along with associating a 3D vector containing the r, g, and b color components. To unify geometry and color meaningfully, color values are transformed into a perceptually uniform space to provide perceptual significance to the color distances utilized in the clustering algorithm. In this case, the CIELAB space is utilized, and a parameter k is introduced, balancing the contribution of color and geometry.

The dataset used in this study, comprising diverse indoor and outdoor scenes captured at varying times of the day to account for different lighting conditions, depicts individuals engaged in various daily activities. Notably, most individuals are not directly facing the camera, and some faces are partially occluded, rendering this dataset more challenging than previous ones.

The depth map aids in the identification and removal of false positives in several critical scenarios. It enables the determination of the actual size of candidate faces, thereby facilitating the removal of objects that are either too small or too large to be a face. Additionally, it assists in the segmentation process, which is crucial for ensuring proper processing in subsequent steps.