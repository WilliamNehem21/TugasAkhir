These findings pertain to the performance differences between inefficient interpreters as compared to efficient interpreters and optimizing native code compilers. Many interpreters prioritize goals such as portability and ease of implementation over performance. Therefore, it is beneficial to optimize an interpreter before transitioning to a compiler. While common optimization techniques are typically applicable to interpreters, recent findings show that this is not universally true for the Python interpreter, indicating a disparity in virtual machine abstraction levels.

Interpreters with low abstraction levels, which closely correspond bytecode to native machine code (e.g., Forth, Java, and OCaml), validate the assumption that dispatch is the most resource-intensive operation within an interpreter. However, interpreters with high abstraction levels, like Python, Perl, and Ruby, deviate from this assumption. Additionally, the interpreter of Lua occupies an intermediate position between these two classes.

Specifically, in the case of Java, the language's instruction set comprises 205 operations, including reserved opcodes, and is typed for primitive data types. In contrast, Python, a dynamically typed language, features 93 instructions in Python 3.0rc1, supporting ad-hoc polymorphism and enabling hybrid programming paradigms.

These results are not limited to the languages analyzed in the corresponding papers, as it is conjectured that similar characteristics hold true for interpreters of other programming languages, such as Perl and Ruby, in addition to Python.