In this paper, we continue to utilize the soft margin consistency and apply it to semi-supervised problems, proposing the semi-supervised soft margin consistency based multi-view maximum entropy discrimination (SSMVMED). However, when applying SSMVMED, a potential issue arises when dealing with datasets that contain few labeled instances and numerous unlabeled ones. Labeled instances offer more discriminant information compared to unlabeled instances, but in real-world applications, datasets often contain few labeled instances alongside numerous unlabeled ones due to the high cost of labeling instances. Consequently, the performance of learning machines for traditional semi-supervised problems is highly sensitive to the characteristics of the datasets. To enhance the performance of learning machines, a common and viable approach is to generate additional unlabeled instances by combining the original labeled or unlabeled instances, which will possess discriminant information derived from the original instances. Universum learning is one such method used for this purpose.

However, universum-based learning machines face two key issues. Firstly, when generating the universum set, the weights of views and features, which play distinct discriminant roles, are often overlooked. Secondly, traditional universum-based learning machines only use labeled or unlabeled instances for generating additional unlabeled instances. To address the first issue, we employ weighted multi-view clustering (WMVC), a multi-view clustering method capable of determining the optimal cluster assignment and obtaining the weights of views and features. For the second issue, we propose to design schemes that involve using both labeled and unlabeled instances to generate additional unlabeled instances.

SMVMED differs from MVVMED and AMVMED in that its margin is soft. SMVMED achieves margin consistency by minimizing the Kullback-Leibler divergence between the posteriors of margin parameters from two views. Additionally, a trade-off parameter that balances large margin and margin consistency is introduced to enhance the flexibility of the model.

The model of SMVMED is then illustrated, followed by a description of the datasets used in the experiments, which include the Course dataset, Citeseer and Cora datasets, WebKB dataset, and Newsgroup dataset.

Furthermore, quantitative evaluation analysis is conducted in terms of test accuracy using paired t-tests and the Nemenyi statistical test. Paired t-tests are used to analyze the significance of differences between compared learning machines on individual datasets, while the Nemenyi statistical test is employed to assess the significance of differences between compared learning machines on multiple datasets.

Lastly, the computational complexity of SSMVMED is theoretically analyzed, focusing on the three steps involved in the process. The computational complexities for different steps are discussed in terms of the number of labeled instances, original unlabeled instances, and additional unlabeled instances.