Furthermore, computer vision has recently played a critical role in enabling the digital world to interact with the physical world. Essentially, the technology utilizes cameras coupled with computers to identify, track, and estimate targets for image processing, rather than relying on human eyes. It is integral to technology by powering object detection, classification, and tracking of objects across all domains. Notably, smart agriculture tasks such as plant ailment detection, weed detection, crop yield prediction, and identification of plant species are now achieved through computer vision technology (Neupane and Baysal-Gurel, 2021).

Unmanned aerial vehicles (UAVs) have gained considerable attention in the research domain, particularly in making the industry less labor-intensive. The application of computer vision to drone technology enables interpretation and interaction with surroundings, including buildings, trees, and diverse terrain. The use of data from UAVs for farming applications has been increasingly popular in both research and industry. Compared to human-based monitoring, UAVs are considered to be cheaper and more convenient, with shorter inspection times required. The optimal control of UAVs in the presence of obstacles is commendable, which is critical when working with two crop rows.

In general, weeds hinder the movement of irrigation water, disrupt the process of applying pesticides, and serve as a breeding ground for pathogens. As a result, weed detection and control play a vital role in overall crop productivity and farming expenses. Effective weed control is crucial in agriculture, as it minimizes crop yields, dramatically increases production costs, negatively impacts crops, and significantly compromises product quality. Weeds compete with productive crops for essential resources such as water, nutrients, and light, thereby diminishing overall agricultural output.

Traditional weed management methods include chemical means, such as the uniform application of herbicides throughout the field, using mechanical means or physical elimination. However, these methods have drawbacks, including overuse of chemicals and labor-intensive farming methods. These issues can be addressed by applying the concept of site-specific weed management (SSWM), which involves detecting patches of weeds across the field and carrying out spot spraying or mechanical removal. SSWM can be broadly classified into prescription maps-based methods and real-time monitoring methods for the detection and control of weeds.

Existing techniques for image processing provide promising outcomes under optimal imaging conditions, although they can be challenging under real-time conditions. The overlap of plant leaves and weeds at different stages of growth makes them indistinguishable from each other. Additionally, leaves are often occluded, discolored, or damaged by undesired materials, altering their morphological and spectral characteristics. Changes in lighting conditions, shadows formed by the plant canopy, and solar inclination can directly impact the color of vegetation. Furthermore, different plant growth stages result in variations in the morphological, textural, and spectral attributes of leaves.

This paper focuses on discriminating between crops and weeds using machine learning approaches. Traditional image processing techniques like Hough transform can also be used for this purpose, but they are not the focus of this paper. Instead, the paper commonly uses image processing techniques to extract features such as color, shape, etc., which are then fed to machine learning algorithms. The effectiveness of these methods depends largely on the manually designed features and has a high dependence on image acquisition methods, preprocessing methods, and the quality of features extracted.

Hyperspectral sensors, which provide hundreds or thousands of bands, have also been utilized in discriminating crops and weeds. These sensors capture images using multiple bands in the visible and near-infrared spectrum, and have shown comparable performance with multispectral images in vegetation properties estimation.

The quality of captured images is influenced by various environmental factors, including lighting conditions and humidity levels. Illumination conditions have been shown to play an important role in determining the quality of images, affecting the accuracy of weed detection and classification. High light intensity leads to a loss of information, while low light intensity introduces dark current noise. Additionally, the quality of images captured using the line-scan method is affected by the attitude and position changes of the UAV.

We hope this has helped to paraphrase the academic paper effectively. If you need further assistance with any specific sections, feel free to ask!