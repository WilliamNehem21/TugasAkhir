The recent adoption of biometric technologies across various applications has heightened the interest in developing solutions for monitoring individuals in an environment. Different approaches to this end include fingerprint-based control systems, iris-based control systems, and face recognition and verification. However, the need to deploy autonomous systems places emphasis on face recognition due to its lack of requirement for interaction between the system and its users. A critical condition for achieving dependable face recognition is the representation of faces, which can be challenging due to the variability of intra- and inter-face characteristics. As an example, considering a 3D matrix representing a face, a simple rotation of the face results in a completely different matrix representation. Thus, the challenge in face representation lies in finding a description that remains invariant after rotation, translation, illumination, and other variations.

Several representations have been proposed to address this challenge, with one of the initial approaches being fractal representation. While this method utilized fewer computational resources than the traditional principal component analysis (PCA) approach, it required recalculation of feature vectors when inserting a new sample. Subsequent representations have generally aimed to convert the matrix (typically 3D) to a 1D feature vector to reduce computational resource usage, but many of these representations assume images with high resolution and do not effectively address spoofing attacks.

This paper introduces a face representation called FASIVA (Face Signature for Identification, Verification, and Authentication) to address these challenges. The proposed representation aims to provide a robust solution for face recognition while also considering reinforcement processes such as image enhancement, verification, and authentication.

The paper is structured as follows: Section 2 presents a review of previous work, with emphasis on relevant studies related to the current research. Section 3 provides details of the FASIVA signature, including the formalization processes. Section 4 presents the different implementations carried out and the results obtained to validate the model. Finally, Section 5 concludes the work with a summary and outlines directions for future research.

The proposed method relies on the principle of sparsity, which involves identifying minimal elements within the original matrix of the face image to robustly and accurately represent the given face, yielding a feature vector. Several mathematical approaches have been developed to derive these feature vectors, with well-known examples including Local Binary Patterns (LBP), Eigenfaces, and Fisher Faces. These methods have specific strengths and weaknesses and address challenges such as sensitivity to local variations of illumination and handling partial occlusions.

The paper discusses the issue of adversarial examples, where attacks generate patches that can deceive the system, and explores potential approaches to overcome this issue, such as the defensive distillation method. Additionally, the use of coordinate-independent features in Convolutional Neural Networks (CNNs) is highlighted as a means to facilitate handling of coordinates when transitioning from one frame to another.

To address the limitations of using a generic dataset for training, the paper describes training the model specifically on human face images from the Faces in the Wild dataset. The training process involves using a portion of the dataset for training and a separate portion for testing, followed by fine-tuning the model to enhance its resolution using a convolutional neural network.

The process of matching the features vector of an input image to a class in the knowledge base is discussed, with the use of K-Nearest Neighbor (KNN) and Support Vector Machine (SVM) algorithms for classification. The paper also delves into the testing phase, discussing the performance of the proposed method in identifying real and fake videos and images.

The FASIVA method is detailed, outlining how it considers image quality, pattern extraction, and an authentication mechanism that incorporates eye blinking and spoofing verification. The implementation and testing of FASIVA demonstrate its validity, efficiency, and robustness, extending its focus beyond recognition to encompass operations that enhance image quality and authentication mechanisms to prevent spoofing attacks.

Future work is pinpointed towards further investigation of blinking detection, specifically in non-frontal and occluded faces, as well as the capability to detect adversarial attacks.