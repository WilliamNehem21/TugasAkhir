Human vision is crucial for navigating the world, as the information received through the eyes is unmatched by other senses. Artificial vision in computer science aims to develop computational systems capable of understanding digital images. Computer vision techniques, such as pattern recognition, statistical learning, projective geometry, and image processing, are used to describe scenes. Image range finding, which measures the distance between an object in a scene and the image captured by a sensor, is becoming increasingly important. This technique provides three-dimensional information about scenes, including background, shape, and depth measurements of objects. Applications of depth information include collision detection on mobile robots, engineering applications with range optic sensors, quality control, and storage planning. This paper focuses on robust estimation of absolute distance using low-cost components like a webcam and a laser pointer to estimate distances from the real world.

The paper is structured as follows: Section 2 provides an overview of previous works related to distance estimation. Section 3 explains the process used for camera calibration. Section 4 details the scanner and the geometry of the model. Finally, Section 5 presents the implementation and analysis. The paper concludes by discussing the results and potential future directions in Section 6.

"3D Range Acquisition Through Differential Light Absorption" (2002) describes a 3D camera based on the differential absorption of light by a colored liquid illuminated by a circular light source to obtain 3D information.

"A Projective Method to the Measurement of Box Dimensions in Real Time" (2006) presents a method for computing box dimensions in real time, employing projective geometry to recover the box dimensions using information of the box edges and the projection of two dot lasers on one side of the box.

Several aspects must be considered when comparing results among different techniques, with precision being the most important. The paper adopts the camera calibration procedure proposed by Abdel-Azis and Karara, which takes into account lens distortions. The simplicity of the model and the robust results have led to the widespread application of this approach.

Considerable effort was devoted to the camera calibration procedure, with some authors proposing the use of genetic algorithms and pre- and post-processing of data to enhance results. From a practical standpoint, some authors suggest a method based on 2D patterns that yields good results and is easy to use.

The camera's orientation involves the calculation of external parameters to define its state and axis in a world coordinate system. The implemented approach uses OpenCV, and the results from the camera calibration were validated with the MATLAB camera calibration toolbox.

Previous works have used two laser pointers of class II with a wavelength of 650nm. In this paper, a modified class II laser pointer with a red light color and a wavelength of 630-650nm was used.

The experiments utilized various measures of the distance between the webcam and laser pointer, different image resolutions, and different data samples in the regression model. A dataset was used in the experiments, with a specific set using a distance of 25cm and a resolution of 352x288, among other parameters.

In the last experiment, the distances obtained by the scanner showed a high level of approximation. The mean absolute error (MAE) of approximation was 0.8613cm for an uncalibrated camera and 0.6492cm for a calibrated camera. Additionally, the mean absolute percentage error (MAPE) was 0.824% for an uncalibrated camera and 0.557% for a calibrated camera.