An alternative technique for animating an avatar involves using blend shapes or morph targets. In this method, the animator manually deforms the mesh geometry vertex by vertex to create intermediate positions, allowing for greater flexibility in morphing the geometry without the restrictions of a rig. However, this approach is more computationally expensive than rigging.

Candide, originally introduced in 1987 by Rydfalk and later updated by Ahlberg in 2001, is a parametric computer graphical model of the human face inspired by Ekman's work on micro facial expressions related to emotions. The model implements a set of action units (AUs) aiming to replicate a subset of Ekman's micro expressions, providing an advantage in capturing specific emotions.

During the avatar retargeting process, it is essential to ensure that any face or head accessories, such as glasses or hats, are independent 3D meshes that will not obstruct the process. Additionally, a clean 3D mesh with only one texture image assigned is necessary to facilitate the retargeting process.

Furthermore, a workflow for generating avatars capable of reproducing emotional expressions in real-time was proposed, based on the retargeting of a pre-designed avatar with the Candide model. The proposed workflow was implemented to represent emotional states on facial expressions in six available avatars, all licensed under the creative commons copyright.

To evaluate the effect of the modifications made to the avatar's face through facial replacement, a group of six digital artists conducted a subjective comparison between the original and retargeted avatars. The experts observed differences between the two avatars, but generally considered these variations to be relatively minor, supporting the conclusion that the retargeting process generates an avatar very similar to the original.