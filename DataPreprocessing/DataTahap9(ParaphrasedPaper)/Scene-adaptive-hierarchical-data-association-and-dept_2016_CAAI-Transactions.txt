Lately, there has been a growing trend in the integration of RGB and depth data for applications in computer vision. This trend is attributed to the increasing availability and affordability of depth sensors, such as the Microsoft Kinect, which enable the real-time capture of not only color images but also depth maps with sufficient resolution and accuracy. The incorporation of depth data offers additional information from the third dimension, which helps to mitigate challenges associated with ill-posed problems in 2D image processing. Furthermore, depth data is less susceptible to issues arising from poor illumination conditions commonly found in indoor environments, making it a valuable complement to RGB data.

In our work, we have adopted depth data to address practical challenges and to develop a time-critical indoor multi-tracking system. Previous studies have leveraged depth data for tasks such as motion detection, background subtraction, and 3D body pose estimation, offering robust and diverse target detection methods. Various depth-based features have also been proposed for both target detection and representation. In this work, we utilize depth-based cues, including 3D position, 3D motion, and 3D spatial layouts, for target representation. These depth-based features add diversity to the feature set, enhancing the reliability of target representation, and significantly improving the robustness of the system in practical applications characterized by cluttered environments, poor illumination, and scale variation.

One challenge in previous works is the reliance on spatial information derived solely from the 2D image plane, resulting in limitations when dealing with practical scenarios involving dislocation, truncation, or occlusion of detected regions. To address this issue, we propose a novel depth-invariant part-based approach that considers the symmetry of human body to handle view variation.

Apart from low-level features such as color and motion, the appearance of the target is an important high-level feature for representation and is widely utilized in pedestrian-related applications. Existing works often underutilize body structure information, leading to suboptimal performance.

In our study, we conducted experiments to observe, compare, and analyze the effectiveness of the proposed framework. These experiments encompassed the verification of scene-adaptive feature selection, the evaluation of the depth-invariant part-based appearance model (DIAM), and the analysis of the hierarchical data association framework. Furthermore, we evaluated the real-time capability of the algorithm by computing the frames per second (FPS).

Additionally, we conducted detailed experiments to assess the effectiveness of the hierarchical data association (HDA) scheme. These experiments focused on analyzing the influence of hierarchical feature space construction and comparing the HDA scheme with a non-hierarchical data association (non-HDA) scheme using the same hierarchical feature space.