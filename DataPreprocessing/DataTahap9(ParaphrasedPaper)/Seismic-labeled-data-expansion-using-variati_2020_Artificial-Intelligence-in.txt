Supervised machine learning algorithms are commonly employed in seismic exploration processing, but their application is hindered by the scarcity of labeled examples. In this study, we propose a method to expand labeled seismic data using deep variational autoencoders (VAE), comprising neural network-based encoder and decoder components. The scarcity of training samples often leads to overfitting of the network. To mitigate this issue, we train the VAE using the entire seismic dataset, employing a data-driven approach to substantially reduce the risk of overfitting.

The encoder captures the ability to map seismic waveforms (y) to latent deep features (z), while the decoder captures the ability to generate seismic waveforms (y) from latent deep features (z). Subsequently, we input the labeled seismic data into the encoders to obtain the latent deep features. By fitting the distribution of deep features for each class of labeled data using a Gaussian mixture model (GMM), we generate a large number of expansion deep features (z*) according to the GMM and input them into the decoder to generate expansion seismic data. Experimental results on synthetic and real data demonstrate that our approach mitigates the issue of insufficient labeled seismic data for supervised seismic facies analysis.

When the VAE converges, it captures the deep feature distribution of seismic data. By inputting the labeled samples into the decoder, we obtain the deep feature distribution of each class. It is straightforward to fit the deep feature distribution with a GMM for each class, thereby addressing the issue of overfitting. Application of this method to synthetic and real data shows that the generated expansion labeled data enhance the performance of seismic waveform classification. In the synthetic data experiment, classification accuracy is improved by 20% with our proposed method when signal-to-noise ratio (SNR) is 3.

The features (z) must adhere to a prior Gaussian distribution. Therefore, the loss function of the VAE consists of two parts: one is the reconstruction error, measured by the Euclidean distance, and the other part pertains to the feature (z) and uses the Kullback-Leibler (KL) divergence to measure the differences between (z) and the prior Gaussian distributions. Hence, the VAE loss function is defined as follows:

We introduce a novel data-driven, semi-supervised label expansion method. By using the entire survey seismic data as training data for the VAE, we obtain sufficient training data and mitigate the risk of overfitting. The VAE's encoder projects seismic data into deep features, while the decoder generates seismic data from these deep features.

This manuscript has not been previously published and is not under consideration for publication elsewhere. All authors have contributed to the creation of this manuscript, providing significant intellectual content, and have read and approved the final manuscript. We declare that there are no conflicts of interest.