In our research, we aim to explore the characteristics of algorithm animations and other program visualizations that impact the user's ability to comprehend the intended concepts. We argue that effective program visualization systems must facilitate visually appealing graphical design, layout, and animation, as well as sound pedagogical design. Our goal is to identify and assess the perceptual, attentional, and cognitive features of program visualizations that influence viewer comprehension. This work is part of a larger project involving observational studies of instructors, empirical studies of the perceptual properties of low-level animation actions using the Vizeval environment, and the enhancement of presentation and interaction techniques for program visualization in the context of computer science education.

The animation playback can be manipulated by the viewer through the animation control area (c). One feature allows the user to select from a variety of data sets as the input for the algorithm, while another control adjusts the animation speed. The animation can be paused, stopped, and then restarted from the beginning. Advancing step by step through the animation, which is only possible when the animation is paused, causes the next step of the animation to execute before pausing again. A slider indicates the progress of the animation, with users able to move the slider to select a point at which to restart the animation.

When a participant is viewing the animation, a popup occurs, causing the animation to pause until an answer is provided. These questions can be related to the animation of the algorithm on a specific data set. Additionally, the experimenter can specify that the popup only appears during the initial run of the animation of the algorithm with the associated data set. To prevent users from using the pseudocode to provide the correct answer to the popup questions, the popup window is positioned over the pseudocode area and cannot be moved. The experimenter also has the option to display the correct answer or other feedback after the participant submits a response. User answers to these popup questions are recorded in the log.

The graphical visualization produced by the SKA module is the result of collaboration between an algorithm and an animator working somewhat independently. A threaded architecture, following the producer-consumer design pattern, is utilized. An algorithm thread serves as the producer of data for visualization, while the animator thread consumes the data.

The graphical representations consist of graphical objects and actions on one or more of these objects. Graphical objects include lines, rectangles, text labels, circles, and composite graphics, each with various properties such as color, fill, visibility, font, position, and labels. The display canvas references a list of graphics, and as graphics are updated by the animator module, the canvas repaints the graphics, resulting in animation.

Two between-subject factors were manipulated: cueing and exchange animation. Participants were assigned randomly to one of four groups, each with its corresponding animation. Fourteen participants were in the cueing with move (MC) category, sixteen in cueing with grow (GC), twelve in no cueing with move (MX), and seventeen in no cueing with grow (GX).

The traditional questions were further categorized into groups based on the type of knowledge the question tested, labeled knowledge, comprehension, and application. ANOVA analyses were conducted on these subsets, with no significant difference found among the four animation groups.

An analysis of the animation reveals the use of various cueing methods to indicate the comparison of two bars. Specifically, color, labeled arrows, and location within the current partition serve as cues for the identity of the bars being compared. Therefore, we do not assert that such flash cueing does not contribute to the comprehension of animations. Instead, we conclude only that the use of flash cueing as a redundant cue in this animation did not significantly enhance comprehension.

The SSEA environment provides robust support for conducting empirical studies of program visualizations. Several studies have been conducted to date, one of which is reported here. Support for sound actions has been integrated into the SKA package, and additional studies examining the roles of voice-over and non-speech audio in animations are in progress.