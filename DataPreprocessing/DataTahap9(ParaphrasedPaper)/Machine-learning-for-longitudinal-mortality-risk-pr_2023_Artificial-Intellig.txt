Neoplasms are characterized by abnormal tissue growth and can be categorized as benign or malignant. Benign neoplasms exhibit slow and organized spread, well-defined borders, and lack invasive features, while malignant neoplasms display rapid and disorganized growth, poorly defined borders, and have the potential to invade adjacent tissues and organs, indicating the possibility of metastatic cancer.

The initial dataset includes four categories based on the latest available patient information: 1) alive without cancer, 2) alive with cancer, 3) death from cancer, and 4) death without further information. The focus of the study was on patients who had confirmed cancer-related deaths between 12 and 24 months after diagnosis. For the negative outcome, patients who were alive without cancer or alive with cancer between 12 and 36 months after diagnosis were included. Patients categorized as 4) death without other information were excluded.

Quantitative variables were normalized using z-score separately in the training and test sets. For qualitative variables, one-hot encoding was employed to separate each category. A new category was created for missing values in the variable type of diagnosis. Additionally, patients with missing information on cancer stage and the difference in days between the first medical appointment dates and diagnosis were removed.

The study tested the predictive performance of six machine learning algorithms: CatBoost, XGBoost, LightGBM, Gradient Boosting Classifier, Random Forest, and Logistic Regression. Hyperparameters for the algorithms were selected using 10-fold cross-validation with the aid of hyperopt and random search. In cases of high class imbalance, the synthetic minority oversampling technique (SMOTE) was applied. Furthermore, the Boruta method was utilized for variable selection in the training set. After model training, the best-performing models were evaluated in the test set.

The performance of the models was assessed using various metrics such as AUC-ROC, AUC-PR, precision, recall, positive predicted value, negative predicted value, and F1 score. Models were also evaluated in the 20% of patients with the highest risk using true positive, false positive, precision, and recall metrics. Shapley values were calculated to interpret and evaluate the contribution of each variable to the outcome, in line with the guidelines from the Transparent Reporting of a Multivariable Prediction Model for Individual Prognosis or Diagnosis (TRIPOD).

All nine models achieved AUC-ROC values of at least 0.871, with six of them surpassing 0.900. The general model yielded the best overall performance, with an AUC-ROC of 0.946 and an AUC-PR of 0.932. An algorithm for the five main causes of death (top-5) exhibited an AUC-ROC of 0.945 and an AUC-PR of 0.937.

The study also provided a detailed analysis of model performance for individual patients. Additionally, it demonstrated that the use of routinely-collected data alone could effectively predict cancer mortality, with the general algorithm generally outperforming cancer-specific algorithms.

In summary, the study developed nine final models with high predictive performance for assessing the risk of death in cancer patients. These algorithms could serve as valuable tools to aid in treatment prioritization and patient allocation for cancer treatments, particularly in low-income regions. The study suggests exploring the proposed methodological structure and evaluating its predictive performance using different routinely collected data in future research.