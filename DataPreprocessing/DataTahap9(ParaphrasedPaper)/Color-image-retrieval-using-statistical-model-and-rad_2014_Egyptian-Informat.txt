This study introduces a novel framework for color image retrieval using the full range autoregressive model (FRAR). A Bayesian approach is employed to estimate the parameters of the FRAR model. The framework utilizes the FRAR model with Bayesian approach to extract color autocorrelogram, a modified version of edge histogram descriptor (EHD), and micro-texture (MT) features. These features are then combined to create a feature vector, which is normalized and stored in an image feature vector database. The database is categorized based on image characteristics using radial basis function neural network (RBFNN) and k-means clustering algorithm. The retrieval process utilizes the Manhattan distance measure of order one to assess the similarity between query and target images. Additionally, a query refinement approach based on short-term learning through relevance feedback is adopted to reduce the semantic gap. Experimental results based on precision and recall demonstrate the improved effectiveness and efficiency of the proposed framework.

Despite the development of numerous techniques, the retrieval accuracy of existing content-based image retrieval (CBIR) systems remains limited and unsatisfactory. Therefore, there is a need to focus on extracting concise and balanced visual characteristics of images. Moreover, the extraction of various visual characteristics (color, texture, shape, etc.) from images using different techniques has been a complex process due to the complementary nature of these techniques.

The paper proceeds as follows: Section 2 describes the FRAR model, Section 3 discusses the feature extraction method, Section 4 explains the RBFNN, Section 5 provides details on similarity measurement and system performance, Section 6 explains the proposed retrieval system, Section 7 presents experimental results, and Section 8 formulates the conclusion.

In the proposed system, color features are extracted from the hue (H) and saturation (S) components of an image. The H and S components are uniformly quantized using the Generalized Lloyd algorithm with a fixed number of quantization levels (L=8). Autocorrelation coefficients (ak) are derived from the FRAR model coefficients CR, and the color autocorrelogram, which captures spatial correlation between identical colors at a distance L, is computed for the H and S components of an image.

This paper improves the retrieval performance of conventional EHD by extracting very fine edges using a framework based on the FRAR model with Bayesian approach. In the proposed system, the V component image is used for edge extraction. After edge detection, the orientation of each edge is computed and quantized into 72 bins of 5 degrees each to enhance EHD.

When a query image is submitted to the system, it automatically extracts the features using the FRAR model with Bayesian approach, determines the category of the query image using RBFNN, and performs similarity matching using the L1 distance measure in the corresponding category of the indexed feature database to retrieve target images. The retrieved images are ranked based on similarity scores, with lower scores receiving higher ranks. User interaction is permitted in the final stage of the retrieval process to refine the search.

Overall, the proposed framework demonstrates improved retrieval performance and efficiency compared to the conventional EHD, as indicated by experimental results based on precision and recall.