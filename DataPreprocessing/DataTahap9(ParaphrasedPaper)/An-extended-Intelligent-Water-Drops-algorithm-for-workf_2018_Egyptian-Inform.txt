Cloud computing is becoming increasingly popular as a high-performance computing environment that comprises a large-scale, diverse collection of independent systems and a flexible computational architecture. Various resource management methods can improve the efficiency of cloud computing systems as a whole. One critical aspect of resource management in cloud computing is resource scheduling. The optimized scheduling of tasks on virtual machines in the cloud is a computationally challenging problem, and numerous algorithms have been developed to address it. The differences among these schedulers arise from the fact that their scheduling approaches are tailored to the changing environment and the characteristics of the tasks. This paper focuses on workflow scheduling in cloud computing, which has garnered significant attention due to the emergence of workflows as a means of representing complex computing problems. We have introduced a new algorithm that extends the natural-based Intelligent Water Drops (IWD) algorithm to optimize the scheduling of workflows in the cloud. Our algorithm has been implemented within a workflows simulation toolkit and tested in various simulated cloud environments with different cost models. The results show that our algorithm provides substantial improvements over traditional workflow scheduling algorithms. We compared our proposed IWD-based algorithm with other well-known scheduling algorithms, such as min-min, max-min, round robin, FCFS, MCT, PSO, and C-PSO, and found that our algorithm consistently outperforms them in terms of both performance and cost efficiency in most scenarios.

Grids and clouds are known for their capacity to model a wide range of applications, including scientific computing, multi-processor systems, multi-tier web applications, and big data processing applications. Consequently, the issue of workflow scheduling in the cloud has become a significant area of research due to the advancement of cloud technology.

In general, workflow schedulers aim to minimize both cost and makespan. Cost not only encompasses the computational expenses incurred from processing individual tasks, but also includes data transmission costs, particularly when large volumes of data need to be transferred between computing and storage sites.

The IWD algorithm operates by mimicking the behavior of water drops as they move through a path; the rate of increase in the drop's size depends inversely on its travel time, which, in turn, is influenced by the velocity of the stream and the distance traveled. The IWD algorithm constructs probabilistic solutions for the best path(s), updating algorithm parameters iteratively to converge to high-quality solutions. Optimum approximation algorithms are used to find approximate solutions. The authors identified three reasons for the significance of the IWD algorithm: (i) it converges to a solution faster than other techniques, (ii) it converges to high-quality solutions using average values, and (iii) it is adaptable to dynamic environments and can easily accommodate emerging threats.

The authors proposed a market-oriented hierarchical scheduling approach that optimizes both task-to-service assignment and task-to-VM assignment in local cloud data centers. They utilized the Cat Swarm Optimization (CSO) algorithm for workflow scheduling in the cloud, aimed at reducing energy wastage by updating the positions of "cats." The algorithm was found to be more efficient than PSO as it converged to optimal solutions in fewer iterations. Additionally, a resource-aware hybrid algorithm was proposed to schedule both batch jobs and workflows in the cloud, wherein tasks are initially assigned to groups of cloud resources, followed by the application of classical scheduling for each group's tasks.

This phase represents an extension of the original IWD algorithm, commencing after the completion of the second phase, in which the entire workflow is traversed and all IWD paths are discovered. In this phase, the scheduler assigns workflow tasks to cloud VMs level-by-level, guided by the best-discovered IWD paths in order. The scheduler traverses all tasks in the best-discovered path from its root to its leaves, assigning each task to the fastest idle machine when available, or the next available machine if no idle machine exists. This approach ensures that the precedence relationship among tasks is respected and that all tasks are assigned in a manner consistent with their dependencies. If after these steps there are unscheduled tasks remaining in the workflow, the same process is repeated for the next best IWD path containing unscheduled tasks.

The IWDc algorithm calculates the best paths for workflow tasks in multiple iterations, discovering the order in which the best paths are traversed. In subsequent iterations, paths are revisited and new best paths are determined until all paths in the workflow graph are discovered.

Our algorithm was compared with common heuristic algorithms and schedulers based on metaheuristic optimization techniques, such as PSO and its variant, C-PSO. We utilized Workflowsim to run our scheduler for 16 different workflows on a cloud environment with 6 VMs, simulating an environment with approximately double the price for those seeking a balance between speed and cost. The results indicated that using m1.small and c4.large instance types may be the best choice for scheduling workflows, with m1.small being better for cost-focused workflows and c4.large being better for workflows prioritizing the makespan.