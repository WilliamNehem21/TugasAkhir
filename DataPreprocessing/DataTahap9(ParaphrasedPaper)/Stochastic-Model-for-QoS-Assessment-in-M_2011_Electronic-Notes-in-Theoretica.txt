In accordance with software performance engineering (SPE) practices, performance analysts conducting performance testing are expected to ensure that the system under test (SUT) is executed in isolation and follows a specific test plan aligned with a well-defined testing objective [2,3]. Adhering to SPE practices introduces additional responsibilities and new roles, such as performance analysts, leading to increased costs and risks for software projects. However, strict adherence to SPE guidelines may not always be feasible due to the lower priority or even the impossibility of prioritizing pure performance testing in software projects. In contrast, functional testing is considered more crucial for stakeholders and carries a higher priority level. Therefore, in software projects, it is important to strike a balance between the benefits of employing SPE to create responsive and performant applications and the efforts involved.

The subsequent sections of this paper are structured as follows. Section 2 provides a general overview of software testing and performance testing. Section 3 explains our target application, its architecture, and internal operational details. In Section 4, we delve into stochastic modeling and the formalism known as stochastic automata networks. Section 5 presents our model and an analysis of our results. Finally, in Section 6, we present our conclusions and outline future works.

Software testing is an essential activity in modern information technology (IT) organizations as it ensures the delivery of high-quality products to end customers. Every type of software project, whether small, medium, or large, must consider two aspects of testing: functional software testing (FST) and performance testing. FST follows a strict set of rules to allow testers and developers to replicate error conditions and resolve issues promptly. Its primary focus is to ensure that a functionality produces the expected output for a given input.

Performance testing, on the other hand, is a crucial component of SPE practices and addresses the non-functional aspects of systems, such as availability, security, reliability, and responsiveness, among other attributes. Three key objectives guide the performance testing of an application: evaluating the product's quality, adhering to service level agreements (SLAs), and preparing the application for deployment in a production environment.

SLAs, high-level contracts established between stakeholders, ensure the presence and maintenance of quality of service in a business relationship. Defining SLAs aids in understanding responsibilities and conditions for delivering high-performance services. SLAs are pertinent to non-functional application testing as they help in establishing a compromise regarding the expected quality of service.

Moreover, the paper discusses the use of stochastic models to characterize the behavior of applications and predict their performance under various conditions. By employing a stochastic model tailored for applications undergoing performance testing and subjected to external workloads and SLAs, the research aims to forecast the impact of external influences on meeting service level agreements. The model provides insights into whether the system will likely meet the SLAs and identifies external influences as potential causes of test failures, distinct from bottleneck issues.

An analysis of the application architecture leads to the identification of the main server acting as a dispatcher, responsible for distributing the workload among the remaining servers. Post-processing transactions, executed in a clean and dedicated environment, enables the population of a stochastic model with measured parameters. These models facilitate the computation of the average time required to process a transaction and allow for ongoing monitoring of the execution to ascertain SLA compliance.

Furthermore, the paper describes the use of Stochastic Automata Networks (SAN) to model the behavior of multi-tier architectures, outlining their ability to capture synchronizing behaviors and solve stochastic models efficiently. The research presents a worst-case scenario analysis, determining the time needed to process application phases and detailing the use of SAN to capture different behaviors influenced by external factors.

A key outcome of the research is the development of stochastic models to predict the application's response time and ensure SLA compliance under varying workload intensities. The paper also outlines future work to extend the model's applicability to complex workload scenarios, such as busy environments with intense workload variations and the inclusion of phase-type transitions to address non-exponential phenomena.

The authors express gratitude to Dr. Alberto Avritzer from Siemens Corporate Research (SCR), Princeton/NJ/USA, for valuable discussions and acknowledge the collaboration between the Faculty of Informatics at PUCRS and Dell Brazil in conducting the performance testing research. This work also received support from FAPERGS/CNPq.