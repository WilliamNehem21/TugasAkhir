The use of medical imaging is crucial for the accurate diagnosis, staging, and management of various cardiac pathologies. However, traditional image segmentation methods are laborious and prone to human error. To address these challenges, deep learning approaches have been developed to enable accurate and efficient analysis of cardiac images.

In this review, we summarize over 60 papers that propose deep learning models for cardiac image segmentation. We discuss various deep learning architectures such as convolutional neural networks (CNNs), fully convolutional neural networks (FCNs), UNet, V-Net, No-New-U-Net (NNU-Net), transformer networks, DeepLab, generative adversarial networks, autoencoders, and recurrent neural networks. Additionally, we highlight performance-enhancing techniques including adaptive convolutional kernels, atrous convolutions, attention gates, and deep supervision modules.

Cardiovascular diseases are a leading cause of mortality worldwide, and medical imaging advancements have significantly contributed to the diagnosis and management of these diseases. As medicine moves towards personalized care, precise quantification and analysis of cardiac structure and function are essential. Image segmentation, which involves classifying pixels within an organ or substructure based on specific features, is a critical component of cardiac image analysis. Accurate segmentation enables advanced processing, 3D reconstruction, and motion analysis of the heart.

We also discuss challenges in cardiac image segmentation, including image quality and artifacts, and the three categories of segmentation approaches: manual, semi-automatic, and automatic segmentation. Furthermore, we present an overview of the top-performing neural network architectures for various cardiac segmentation tasks, identify current challenges, and propose future research directions.

In discussing specific models, we highlight the V-Net architecture, which employs a reversible mechanism and asymmetrical convolutions to maintain image quality. We also describe the No-New-U-Net, a model that proposes an end-to-end automated segmentation methodology with high performance standards. Additionally, we introduce the TransUNet model, which incorporates the transformer architecture into image processing, and DeepLab, which utilizes atrous convolutions for handling multi-scale images.

We also discuss the use of generative adversarial networks (GANs) for image segmentation, particularly the Segmentation Adversarial Network (SEGAN) and the Swin Transformer-based GAN for multi-modal medical image translation (MMTrans). Moreover, we explore attention gates (AGs) as a solution for improving the computational efficiency of CNNs, and deep supervision modules (DSVs) for generating multiple segmentation maps at different resolutions.

Finally, we address loss functions commonly used in image segmentation, including cross-entropy, mean-Dice loss, weighted cross-entropy, weighted Dice loss, and unified focal loss. We also provide examples of challenges and datasets used for evaluating cardiac image segmentation models, such as the ACDC challenge and the Multi-Centre, Multi-Vendor, and Multi-Disease Cardiac Image Segmentation Challenge (M&Ms).

In conclusion, as the field of biomedical imaging advances, user-friendly, end-to-end image processing frameworks such as the Medical Open Network for AI (MONAI) are becoming increasingly important for driving scientific progress in the field.