Feature selection is a crucial aspect of machine learning that helps reduce dataset dimensionality by eliminating irrelevant or redundant features. While considerable research has focused on feature selection for single-label data, there is a notable gap in the study of feature selection for multi-label data. This paper introduces and evaluates four multi-label feature selection methods that utilize the filter approach, which assesses the quality of features independently of any specific classifier. The methods employ standard multi-label feature selection approaches, involving the transformation of multi-label data into single-label data. Two problem transformation approaches are used in conjunction with the relieff and information gain measures to gauge the effectiveness of features, resulting in the development of four multi-label feature selection methods. The methods are experimentally evaluated on 10 benchmark datasets, and the results demonstrate that relieff can select fewer features without compromising the quality of the classifiers constructed using the selected features.

This research was supported by the Brazilian Research Council FAPESP, and the authors express their gratitude to the anonymous referees for their valuable feedback on this paper. Additionally, thanks are extended to Victor Augusto Moraes Carvalho and Antonio Rafael Sabino Parmezan for their assistance in additional analysis.

The paper explains that while feature selection has been extensively researched in the context of single-label learning, where each instance in the dataset is associated with a single class, there has been limited investigation into feature selection for multi-label learning, where instances can belong to multiple classes concurrently. The development of multi-label feature selection methods is described, involving the adoption of the filter approach to assess feature quality independently of any specific classifier. The standard multi-label feature selection approach, which transforms multi-label data into single-label data for feature selection, is utilized in this work.

The paper elaborates on the binary relevance and label powerset problem transformation approaches used in multi-label learning. The binary relevance approach decomposes the multi-label learning task into several independent binary classification problems, while the label powerset approach transforms the multi-label learning task into a multi-class learning task. The article also discusses extensions of the binary relevance approach, specifically the brknn-a and brknn-b, which were proposed to enhance predictive performance and directly address the multi-label problem. Furthermore, the paper provides an overview of evaluation measures for multi-label classification tasks and explains the specific versions of the binary relevance and label powerset approaches utilized in the study.

The paper then presents a detailed account of the experimental evaluation of the proposed multi-label feature selection methods on 10 benchmark datasets. It discusses the results and provides insights into the performance of the feature selection methods, emphasizing the effectiveness of the relieve measure compared to information gain. The paper also highlights the need for future research, including experimental evaluation of relieve using synthetic datasets and the exploration of potential relieve extensions for multi-label feature selection without problem transformation.