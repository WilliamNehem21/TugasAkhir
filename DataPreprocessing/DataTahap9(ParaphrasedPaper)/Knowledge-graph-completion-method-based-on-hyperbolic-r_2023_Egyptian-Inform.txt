To address the aforementioned issues, this study introduces the attcl approach, which integrates hyperbolic representation learning and contrastive learning techniques. The attcl method involves embedding knowledge into a hyperbolic space and employs adversarial noise overlay for samples with limited hierarchical characteristics and insufficient feature information. The loss function of the embedded samples is backpropagated to the embedding vectors, with perturbations added and adjusted in the gradient direction to enhance their smoothness and localization. Additionally, a hyperparameter is introduced to fine-tune the adversarial strength when constructing adversarial samples.

Embedding is a widely used technique for addressing the knowledge graph completion problem, as it allows for the mapping of entities and relations into a lower-dimensional vector space, enabling the quantification of entity similarity and relation distance. Various existing models, such as Transe, Distmult, Complex, and graph neural network models, have been developed to capture the interconnectedness among entities and relations while retaining the integrity of the original information. However, these models have limitations in handling complex relations and representing entity and relation interactions.

In the realm of contrastive learning, the comparison of similarities and differences between positive and negative sample pairs has been shown to enhance the ability to distinguish between different entities and relationships, leading to more semantically informative representations. To this end, simctg and simkgc frameworks have been proposed, each addressing specific challenges related to neural text generation and knowledge graph completion tasks, respectively.

In knowledge graph completion, particularly in the context of the wn18rr dataset, which primarily centers around semantic relations, the att-cl model demonstrates greater improvement on the fb15k-237 dataset compared to the wn18rr dataset. By integrating hyperbolic representation learning and contrastive learning mechanisms, the study observes performance improvements of 2.2%, 1.6%, and 2.62% in MRR, hits@1, hits@3, and hits@10, respectively. This suggests that further enhancement of the embedding space can yield superior results and performance in the task of completing knowledge graphs.