This paper introduces a novel approach that combines object segmentation with low-level features to extract key frames that represent significant events in a shot. The method involves summarizing the visual content of a shot in real-time by selecting key frames, segmenting frames into salient objects, and using position-based and shape-based criteria to identify relevant objects. A many-to-many correspondence approach is then used to compare objects in each frame to those in previous key frames, enabling the detection of new events. The main contribution of the proposed method is the ability to summarize a shot on-the-fly while extracting key frames that illustrate relevant events. Experimental results demonstrate the effectiveness of the method using standard metrics. The approach is based on shot boundary detection and object-based event detection, with key frames selected based on the appearance and disappearance of significant objects. The method prioritizes recent key frames and utilizes a fuzzy coarse region segmentation technique to segment the first frame of each shot into salient objects. The approach also integrates temporal behavior with the visual appearance of objects and compares each frame to previously selected key frames to avoid considering temporal appearance or disappearance of objects as new events. The many-to-many assignment approach minimizes redundancy in the final key frames, and the method is applied on-the-fly for each received frame until the end of the shot. Additionally, frames in subsequent shots are compared to key frames from all previous shots.