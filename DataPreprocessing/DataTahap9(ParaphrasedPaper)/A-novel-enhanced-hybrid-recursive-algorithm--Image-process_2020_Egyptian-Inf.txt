This academic paper addresses the limitations of current augmented reality systems in liver and bowel surgeries, which struggle to accurately visualize hidden structures such as the gallbladder and uterus behind these organs. The research aims to enhance the accuracy of visualization in augmented reality videos of bowel and liver surgeries to prevent inadvertent damage to these hidden structures. The proposed system incorporates improved techniques for recursive matching and parameterization to enhance visualization, along with the addition of a mean shift filter to improve the matching process during image registration. The study demonstrates that the proposed system significantly improves accuracy in visualizing liver and bowel surgeries, with errors reduced by 0.53 mm and 0.22 mm, respectively. Moreover, the system increases the frame rate by 2 frames per second compared to the existing system. The paper concludes that the developed system successfully addresses visualization challenges posed by adjacent and hidden anatomical structures.

The primary objective of this article is to decrease registration errors, visualization errors, and processing time in the context of liver and bowel surgeries. The study highlights the effectiveness of the hybrid recursive matching (HRM) algorithm, which integrates advanced features such as noise reduction, image segmentation, and surface reconstruction. The HRM algorithm comprises block recursive and pixel recursive components and is deemed to be particularly suitable for the research objectives.

A literature review revealed various challenges encountered in augmented reality (AR) surgery, including tumor localization, visualization of organs and nerves, soft tissue deformations, and complex image registration for parts of the body such as the heart, liver, eye, and bowel. Several relevant studies were examined as part of this analysis.

Kersten-Oertel et al. developed an augmented reality neuro-navigation system for precise patient-to-image registration, achieving a registration error of 3.44 and a calibration and re-projection error of 2.02 mm. However, the need for robust visualization techniques and rigorous evaluation was emphasized, as the workflow should not be disrupted. Conversely, Ieiri et al. utilized 3D reconstructed patient images and multi-detector low CT (MDCT) data for registration using an optical tracking system and body fiducial markers. Wen et al. developed a surgical robot system guided by hand gestures, supported by an augmented reality-based surgical system, and employed a random forest (RF) method for organ segmentation from stereo endoscope camera images.

The study also elaborates on the methodology employed within the research, which includes the use of 3D images from a stereo endoscope camera for organ segmentation using the RF method and subsequent surface reconstruction utilizing the HRM algorithm. The HRM algorithm involves block recursive and pixel recursive stages, ultimately providing information on start, update, and final vectors. These vectors contribute to the creation of depth map images, projecting these onto intra-operative surfaces for depth matching and dynamic registration. Biomechanical models are aligned using a 3D mosaic method, with laparoscopic cholecystectomy surgery samples and endoscopic and CT images undergoing comprehensive analyses.

The research involved 10 laparoscopic cholecystectomy surgery sample videos, as well as endoscopic and CT images from diverse age groups and genders, with video lengths ranging from 10 to 20 minutes. Sample classification included liver surgery (for gallbladder visualization) and bowel surgery (for uterus visualization). Furthermore, the study encompassed the visualization of neighboring organs, and all video and image sources were freely available online, with image frames extracted using MATLAB to generate AR videos.