The significance of using model checking counterexamples for debugging programs and specifications is well-established. However, counterexamples produced by bounded model checkers are often challenging to comprehend due to the values chosen by a SAT solver. This paper introduces two approaches to improve the utilization of bounded model checking (BMC) counterexamples. The first approach presents a new concept of counterexample minimization, which minimizes values based on the type system of the language being model checked, rather than at the level of SAT variables. It discusses greedy and optimal strategies for minimizing the counterexamples. The second approach extends a BMC-based error explanation method to automatically generate hypotheses for the causes of errors in a counterexample, and these hypotheses in terms of variable relationships can be automatically verified for causal dependence. Experimental results demonstrate the automatic determination of causes for errors in complex ANSI C programs.

This paper also acknowledges the sponsorship received for this research and specifies that the views and conclusions expressed in the document are those of the author and do not represent the official policies of the sponsoring organizations.

Additionally, the paper emphasizes the importance of concise and easily comprehensible model checking counterexamples for debugging purposes. It points out that counterexample values are heavily influenced by the decision heuristics used by the SAT solver, which may result in unnecessarily large values for program variables. The paper addresses this issue by proposing techniques for counterexample minimization that consider the type system of the language being model checked. It also discusses an error explanation approach to provide information about the causality of errors beyond what is contained in the counterexample alone.

Furthermore, the paper discusses the challenges in minimizing counterexample length and values, and presents algorithms for achieving minimization. It also compares the performance of different approaches for minimizing counterexample values, highlighting the trade-offs between speed and the extent of minimization achieved.

Overall, the paper presents novel approaches to improving the usability of model checking counterexamples for debugging, and offers insights into minimizing counterexample length and values as well as automatically hypothesizing causes for errors in counterexamples.