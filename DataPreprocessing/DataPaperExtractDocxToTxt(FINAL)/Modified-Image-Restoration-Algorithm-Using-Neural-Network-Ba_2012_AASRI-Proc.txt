Available online at www.sciencedirect.com



AASRI Procedia 1 (2012) 196 – 206
AASRI
Procedia
www.elsevier.com/locate/procedia





2012 AASRI Conference on Computational Intelligence and Bioinformatics
Modified Image Restoration Algorithm Using Neural Network Based on Harmonic Model
Yang Bing*a, Zhang Zhigangb, Dai Shufena, Xiao Zhongnanb
aDongling School of Economics & Management, University of Science & Technology Beijing, Beijing, 100083, China
bSchool of Mathematics & Physics, University of Science & Technology Beijing, Beijing, 100083, China




Abstract

In this paper, we considered the neural network image restoration algorithm based on harmonic model and improved the efficiency of the algorithm. After analyzing the complexity of the algorithm, I found that the storage of the connection weight wi , j wastes a lot of spaces. And when I made a deeper analysis of the wi , j , I found that there are many duplicated
elements, and the distribution of the elements is regular. So I started from this point to improve the algorithm, and simplified the calculation of the connection weights matrix, and avoided a large amount of data storage. As a result, the space complexity reduced to O(n) from O(n2 ) , meanwhile, the time complexity is improved. This is a great improvement.
At last, I made some data simulation experiment, and the result give a further description of the algorithm.

© 2012 Published by Elsevier B.V. Open access under CC BY-NC-ND license.
Selection and/or peer review under responsibility of American Applied Science Research Institute

Keywords: image restoration; neural network; harmonic model







* Corresponding author. Tel.: 13810614116;
E-mail address: yangjingyuan1984@sina.com.






2212-6716 © 2012 Published by Elsevier Ltd. Open access under CC BY-NC-ND license.
doi:10.1016/j.aasri.2012.06.031


Introduction

In the image processing, image restoration has been one of the most important basic research subjects. Many application fields need clear and high quality images, so image restoration (such as denoising, deblurring etc.) is of great significance. The traditional image restoration method is mainly about image filtering processing. With most of the image information existing in the edge portion, therefore, image filtering is needed to not only remove the blur and noise from the image but also to keep the detail of the image. Because of image details and noise in frequency bands aliasing, making the image smoothing and the edge details remain becomes a pair of contradiction and the traditional filtering methods are difficult to deal with this kind of problem. The development of neural network technology in recent years to solve this contradiction of the image restoration provides a new method (Zhou Y T and Chellappa R, 1988; Paik JK and Katsaggelos AK, 1992; Yubing Han and Lenan Wu, 2004; Perry S.W and Guan L, 2000; Erler K and Jernigan E,1994; Wu W and Kundu A,1992).
Neural network for image restoration model was first put forward by Zhou et al. (Zhou Y T and Chellappa R, 1988). They linked image restoration with Hopfield neural network through the energy function, and converted image restoration into optimization problem of the neural network calculation. However, using the Zhou method there are shortcomings that the network model is huge and network state is updated slow and so on. In order to overcome these disadvantages, Paik et al. (Paik JK and Katsaggelos AK, 1992) put forward an improved Hopfield neural network model for gray-scale image restoration. Later, the Paik method was improved by many scholars from the network model and the convergence rate and so forth (Yubing Han and Lenan Wu, 2004; Perry S.W and Guan L, 2000; Erler K and Jernigan E, 1994; Wu W and Kundu A, 1992). Literature (Yadong Wu, 2006) on the basis of Paik algorithm, using the regularization term based on the harmonic model, proposed a neural network algorithm based on the harmonic model. But the author in the
analysis of the algorithm found that the storage of the connection weights needs a size of matrix L  L , among them L  M  N , M and N for the image width to height. For an image of the size 128×128, the
connection weights matrix will be the 16384 d. It's not conducive to the computer processing. Then based on this algorithm an improved algorithm is proposed, to simplify the calculation of the connection weights.

The Restoration Model

According to the problem of the image restoration model, the image restoration problem can be transformed to minimize the following error function:

E   y  H  x 2 / 2   
D  x 2 / 2
(1)

Among them,  represents the norm of L2 , x is the estimated value of the real image, y is the degraded image. x And y for column vectors, namely x  (xi ) , y  ( yi ) .In the above equation, the first term represents that finding a x makes H  x approximate y in the case of minimum variance; the second term is the constraints of x , also called the regularization item; for regularization parameter  , it controls the
proportion between removing fuzz and smoothing noise. Matrix H represents the distortion of the imaging system, which is the size of L  L Toeplitz matrix generated by the point spread function. D is the high-pass
filter, which is a matrix generated by the regularization operator. In the traditional rehabilitation model,
regularization operator is the Laplace operator. If the point spread function h for the1 r matrix, d also
should be written as the 1 r matrix. D is in the same form with H . The harmonic model will be introduced into the image restoration frame based on neural network as follows,



EHarmonic 
y  H  x 2 / 2    (DX  x)2  (DY  x)2 2 / 2
(2)





Among them, DX and DY are the L  L
horizontal gradient. The connection weight is for,
Toeplitz matrixes respectively generated by vertical and


L	L	L

wi, j   hp,i hp, j   DX p,i DX p, j   DYp,i DYp, j
(3)

p1
p1
p1



The Recovery Algorithm

Based on the above model, the algorithm generated by referencing the structure of the Paik algorithm can be found in the literature [8], time complexity of the algorithm is O(n3 ) , and space complexity is O(n2 ) . Then we will improve it as follows.
First of all, several definitions and theorems prepared for the improved algorithm are introduced.

For a matrix
A  a


nn
,it is the Toeplitz matrix; i.e., for all the 2  i, j  n , ai, j

 ai1, j 1 . And A is

also the symmetric matrix. Then A is called the symmetric Toeplitz matrix.
For arbitrary matrix n  n with the following form,


 a	a

a2	⋯  ⋯
an1 

 a1
 a
a0	a1	⋱	⁝ 
a	⋱  ⋱  ⋱	⁝ 

(4)

A  





2
⁝
⁝
n1
1
⋱  ⋱  ⋱	a1
⋱	a1	a0
⋯  ⋯  a2	a1

a2 
a1 
a0 


That is a symmetric Toeplitz matrix.

Theorem 1: if a matrix H  h


nn
n
is the Toeplitz matrix, then the matrix W  w


nn

is the symmetric

Toeplitz matrix, among them wi, j  hp,ihp, j .
p1
n	n
Proof: first prove the symmetry of the matrix W . Because of wi, j  hp,ihp, j   hp, jhp,i  wj ,i ,
p1	p1

namely the arbitrary element satisfies matrix;
wi, j  wj ,i for the matrix W , so the matrix of W is the symmetric

For all the 2  i, j  n , according to the definition of H , the equation hi, j  hi1, j1 is established. So


n	n

wi1, j 1  hp,i1hp, j 1  hp,i hp, j
 wi, j
(5)

p1	p1


That is W for the symmetric matrix;
Thus, W is a symmetric Toeplitz matrix. QED.
Corollary 1: the linear combination of symmetric Toeplitz matrixes is still a symmetric Toeplitz matrix.

Proof: this proposition is equivalent to proving the following conclusion. If A1, A2 ,⋯, An
are all

symmetric matrices with the order n n , 1, 2 ,⋯, n are all the arbitrary constants, then
A  1A1  2 A2 ⋯ n An


(6)


Still for the symmetric Toeplitz matrix.
Obviously A is a symmetric matrix; assume that arbitrary element of A is A(i, j) , the arbitrary element of
1, 2 ,⋯, n is A1 (i, j), A2 (i, j),⋯, An (i, j) respectively, then

A(i, j)  1A1 (i, j)  2 A2 (i, j) ⋯ n An (i, j) A1 , A2 ,⋯, An are Toeplitz matrixes, so for all the 2  i, j  n ,
A1 (i, j)  A1 (i 1, j 1) , A2 (i, j)  A2 (i 1, j 1) ,⋯⋯, An (i, j)  An (i 1, j 1)

(7)



(8)



So

A(i, j)  1 A1 (i, j)  2 A2 (i, j) ⋯ n An (i, j)
 1 A1 (i 1, j 1)  2 A2 (i 1, j 1) ⋯ n An (i 1, j 1)
 A(i 1, j 1)




(9)


That is A(i, j)  A(i 1, j 1) , so A is the Toeplitz matrix.
To sum up, A is the symmetric Toeplitz matrix, namely the linear combination of symmetric Toeplitz matrixes is still a symmetric Toeplitz matrix. QED.
Corollary 2: if a matrix W is a symmetric Toeplitz matrix, then for the arbitrary element of the matrix W

wi, j  w1, ji 1 ,1  i, j  n .	(10)


Proof: first consider for the arbitrary element matrix, wi, j  wi1, j 1 , we can draw the conclusion:
j  i , according to the definition of the Toeplitz



wi, j  wi1, j 1  ⋯  wi(i1), j (i1)  w1, j i1

And for j  i , according to the property of the symmetric matrix we can get the conclusion:

wi, j  wj ,i  w1,i j 1
(11)




(12)



From two equations above, for the arbitrary element1  i, j  n , wi, j  w1, ji 1 .QED. Before going further, we first present two properties of the Toeplitz matrix related.
H  is  the  order  of	n n Toeplitz  matrix  generated	by h  h1, h2 ,⋯, hr 



,among  them,

n  r, r 1 . H has the following form,


 h	h

 0	h1
⋯	h	⋯	0 

h2	⋱	⁝ 

 ⁝	0	⋱ ⋱ ⋱	h 

H  
 hr
r 
⋱ ⋱ ⋱  h2	⁝ 
(13)

 ⁝	⋱	0	h	h 


 h	⋯	h
1	2 
⋯	0	h 

 2	r
nn


Make hi, j for the arbitrary element; from its structure we can see that the following two properties are obvious:
Property 1: for all the 1  i, j  n


hi, j  hi j 1,1
i  j

 h	 h
i  j
(14)

 i, j	1, ji1

Property 2: the elements of the first line and the first column of the element have the following relationship


hi,1  h1,ni2 , among them 2  i  n
(15)


Or
h1, j  hn j2,1 , among them 2  j  n . We will use the two properties to prove the following theorem

for many times.
Theorem 2: if H is the order of
n n Toeplitz matrix generated by h  h1, h2 ,⋯, hr  , among

them, n  r, r 1
then the matrix W  w


nn
at most only has the number of r different nonzero

elements, of which wi, j


  hp,i hp, j ;
p1

And, if n  2r  1 , W has r different nonzero elements, and as the increase of n , the value of the r elements will not change, which are as follows:

w	 h 2  h 2 ⋯ h 2

(16)

 1,1	1	2	r
w1,2  h1h2  h2 h3 ⋯ hr 1hr
w1,3  h1h3  h2 h4 ⋯ hr 2 hr


 w1,r  h1hr









Proof: This proposition is divided into two parts to prove:
(1) From the above discussion we know the structure of H , making hi, j for the arbitrary elements.
From theorem 1, it is known that W is a n n symmetric Toeplitz matrix; for1  i, j  n , the corollary 2 tells us that W satisfies wi, j  w1, ji 1 . Therefore we just need to prove that in the first line ofW there are at most only r different nonzero elements.
According to the generation rules of W and property 1 and 2 we can derive the following equations:




w1,n  hp,1hp,n p 1
 h1,1h1,n ⋯ hn2,1hn2,n  hn1,1hn1,n  hn,1hn,n
 h1,1h2,1 ⋯ hn2,1h1,3  hn1,1h1,2  hn,1h1,1
 hn,1h1,1  h1,1h2,1 ⋯ hn2,1hn1,1  hn1,1hn,1
 h1,2 h1,1  h1,1h2,1 ⋯ hn2,1hn1,1  hn1,1hn,1




(17)


And




w1,2  hp,1hp,2
p1
 h1,1h1,2  h2,1h2,2 ⋯ hn1,1hn1,2  hn,1hn,2
 h1,2 h1,1  h1,1h2,1 ⋯ hn2,1hn1,1  hn1,1hn,1



(18)


Namely w1,2  w1,n ;Vice versa, w1,3  w1,n1 , ⋯, w1,r  w1,nr 2 .Another obviously results:


w	 h 2  h 2 ⋯ h 2
(19)

1,1	1	2	r

So far, we know that W has possessed r elements.
From the above analysis, we can conclude w1,r  w1,r 1 , if n  2r 1. Namely the first line ofW just has
r elements, so if n  2r  1, the conclusion is set up.
Then we continue to prove that, if the first line of W has other elements, the other elements are zero. That


is when n  2r and if r 1 j  n  r 1, then w1, j  0 .

Given in the range,




w1, j  hp,1hp, j p1
 h1,1h1, j  h2,1h2, j ⋯ hnr 1,1hnr 1, j  hnr 2,1hnr 2, j ⋯ hn,1hn, j

(20)



From the structure of H , when n  2r
, and if 2  i  n  r 1 , then wi,1  0 ; In addition,

when j  r 1 , h1, j  0 so the equation above is changed into the following form:

w1, j  hnr 2,1hnr 2, j ⋯ hn,1hn, j



(21)



For n  n  r  2  n  r 1 
j , so according to property 1 we can derive the following equations:



hnr 2, j


 hnr  j 3,1
⁝	(22)


	n, j
 hn j 1,1



That by r 1 
j  n  r 1is known,
 n  r  j  3  n  2r  2  n  r 1

So , hnr j3,1  0 ; Similarly, r  n  j 1  n  r  n  r 1, namely hn j1,1  0 , from this we can
get w1, j  0 .
To sum up, the first part of theorem 2 is established. Namely the matrix W at most only has the number of r different nonzero elements.
(2) Apparently , w	 h 2  h 2 ⋯ h 2 ; By the definition ofW , considering n  2r  1,
1,1	1	2	r


w1,2  h1,1h1,2  h2,1h2,2 ⋯ hnr 2,1hnr 2,2 
hnr 3,1hnr 3,2 ⋯ hn1,1hn1,2  hn,1hn,2

(23)



According to property 1 and 2 the equation above can be transformed into the following.

w1,2  h1,1h1,2  h1,n h1,1 ⋯ h1,r h1,r 1  h1,r 1h1,r ⋯h1,3 h1,4  h1,2 h1,3


(24)



When j  r 1; h1, j
 0 ; So the values are substituted into it, we can draw



w1,2  h1h2  h2h3 ⋯ hr 1hr
(25)


We can see that the values of w1, 2 don’t matter with n ; similarly the following equation can be drawn,

w1,3  h1h3  h2 h4  ⋯  hr 2 hr



 w	 h h
(26)

	1,r	1 r

These values have nothing to do with n , that is, when n  2r  1, along with the increase of n , these values will not change. Proposition is proved.
Consolidated conclusions of (1) and (2), theorem 2 is proved. QED.
Let's talk about the actual significance of the theorems above in the algorithms. In the image restoration algorithms based on harmonic model, the network connection weight values are defined as follows

L	L	L

wi, j   hp,i hp, j   DX p,i DX p, j   DYp,i DYp, j
(27)

p1
p 1
p 1


Among them, H , DX and DY are all the Toeplitz matrixes . From theorem 1 and its inferences to

know, the generated matrix W  w


LL
is a symmetric Toeplitz matrix; assume that the point spread

function h for the 1 r matrix which generates H . In actual applications, the image size L  r , we
think L  2r 1. So from the corollaries of theorem 1 reasoning and theorem 2 we can know some key features of the matrix W :
The number and the values of nonzero elements are defined, which can be expressed by using the elements of h .And along with the changes of L , the values will not be changed;
The elements of the matrixW are regular. All elements and some element of the first line are in same value, and this equivalence relation follows certain rule.
Based on the two points above, we think that in the course of the algorithm, there is no need to generate the Toeplitz matrix H , and only need to calculate its certain numerical values according to the rule. If we do so, for the original algorithm space complexity and time complexity will have a very big improvement. The following describes the algorithm of calculatingW .
The matrixes generating H , DX and DY are given, written by the form of1 r .They are as follows:
 h  h1 , h2 ,⋯, hr 

dx  dx , dx ,⋯, dx 
(28)

	1	2	r
dy  dy1 , dy2 ,⋯, dyr 
In order to facilitate the calculation, the matrixes above are expanded for1 (2r 1) , and the elements of the part expanded are filled with zero, so it can be written as the following form:


 h  h1 , h2 ,⋯, hr ,0,⋯,01(2r 1)

dx  dx , dx ,⋯, dx ,0,⋯,0
(29)

	1	2	r
1(2r 1)

dy  dy1 , dy2 ,⋯, dyr ,0,⋯,01(2r 1)

Calculate r different values ofW , and then store them in a 1 r matrix T ; For i = 1: r




T (i)  h(t)h(t  i 1)    dx(t)dx(t  i 1)    dy(t)dy(t  i 1)
t 1
(30)


End

Assign for each element wi , j ofW , and the algorithms are described below:
Make q  j  i 1;
If r 1  q  L  r 1
wi, j  0
Else if q  L  r 1
wi, j  T (L  2  q)
Else
wi, j  T (q)
End

The Experimental Results and Discussion

The algorithms in the last section are from matrix internal data features, looking for the relationship between dates. The improvement is that it avoids the redundant data storage, thus avoiding the generation of large scale matrix.
The calculating process of W only needs r2 times; in the original algorithm, external circulation times are L2 . In practical application r 2  L , so time complexity T (n) (make n  L ) of the improved algorithm is


T (n)  O(r 2n2 )  O(n2 )
(31)


In the space complexity, the improved algorithm only has the linear complexity O(n) ; relative to the original algorithm of O(n 2 ) .This is a great improvement, and also the main work done of the algorithm. In order to test the improved algorithm restoration effect, degraded images all use 1 9 motion blur. And we join
the Gaussian white noise with the variance of 25, using the MSE and PSNR as measures. In the algorithm, the



gradient operator takes the Sobel operator: vertical gradient operator for  1
 2 4  1
0 1 , horizontal gradient
0  
0 1

operator for  1  1  2
0	0
4
	2
 1 .  of algorithms take experience value   0.05 .

1 

To different images, the value of  is different, which is computed in the program. The following is

processing effect of the standard image, in this example  
1   0.0204 .
SNR


		


(a)
(b)	(c)



Figure.1. (a) original image; (b) Fuzzy image ; (c) Restored image.

Seen from the pictures, the algorithm in noise removal performance is very good, but in keeping the edge of performance is relatively insufficient, which confirmed the previous theoretical knowledge: Harmonic canonical in the gradient and the edge of the two orthogonal directions are diffused, and has the same diffusion coefficient. Therefore, the harmonic model in noise smoothing also fuzzes edges of the image. Fuzzy
image MSE  2256.7 , PSNR  14.5960 ;Restored image MSE  1614.2 , PSNR  16.0513 .
The End

This paper first studied the complexity of the original algorithm, and then had a detailed analysis of the calculation process of connection weight matrix, finding the internal structural features. By the form of Theorem 1and 2 it was summarized and the theorems was applied to the original algorithm. Then we put forward a new improved algorithm saving time and space and finally did the data simulation experiment, which not only deepened the understanding to the algorithm, but also illustrated the advantages of the improvement algorithm.


References
Zhou Y T, Chellappa R. Image restoration using a network. IEEE Trans. on Acoust, Speech, Signal Process 1988; 36(7):1141-1151.
Paik JK, Katsaggelos AK. Image restoration using a modified Hopfield network. IEEE Transactions on Image Processing 1992; 1(1):49-63.
Yubing Han, Lenan Wu. Image restoration using a modified Hopfield neural network of continuous state change. SIGNAL PROCESSING 2004; 20(5):431-435.
Perry S.W, Guan L. Weight assignment for adaptive image restoration by neural networks. IEEE Trans


Neural Networks 2000; 11(1):156-170.
Erler K, Jernigan E. Adaptive image restoration using recursive image filters. IEEE Transactions on Signal Processing 1994; 42(7):1877-1881.
Wu W, Kundu A. Image estimation using fast modified reduced update Kalman filter. IEEE Transactions on Signal processing 1992; 40(4):915-926.
Yadong Wu. Research on Image Restoration Algorithms: Degree thesis. University of Electronic Science and technology of computer application technology 2006.
