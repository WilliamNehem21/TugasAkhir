Available online at www.sciencedirect.com
ScienceDirect

AASRI Procedia 4 (2013) 50 – 56


2013 AASRI Conference on Intelligent Systems and Control
Comparison of Distance Measures on Fuzzyc-Means Algorithm for Image Classification Problem
Jiho Hana, Dong-Chul Parka*, Dong-Min Wooa, and Soo-Young Minb
aDept. of Electronics Eng., Myongji Univ.,Gyeongi-do, 449-728, Rep. of KOREA
bKorea Electronics Tech. Inst.,SongNam, 463-816, Rep. of KOREA




Abstract

A study on the use of two different distance measures, Euclidean distance and divergence distance, for FCM is conducted for an image classification problem in this paper.Conventional FCM algorithm which uses Euclidean distance measure utilizes only mean information from an image block for its feature while FCM algorithm with divergence utilizes both of variance and mean information. Evaluationson a set of Caltech databaseshow that Divergence-based FCM gives higher accuracy when compared with some conventional algorithms with Euclidean distance.

© 2013 The Authors. Published by Elsevier B.V. Open access under CC BY-NC-ND license.
Selection and/or peer review under responsibility of American Applied Science Research Institute

Keyworkds: Fuzzy c-Means, Classification, Divergence Measure, SOM


Introduction

Recent increase use of compressed image data requires for an automatic tool thatcan retrieve image data efficiently. Several conventional algorithms adopted for this purpose includesFuzzy c-Means (FCM) algorithm andSelf OrganizingMap(SOM) [1][2].FCM algorithm is the most widely used one and can be thought as an improved version of earlier clustering. The FCM algorithm shows more robustnesswhen



* Corresponding author. Tel.: +82-31-330-6975; fax: +82-31-330-6977
E-mail address: parkd@dreamwiz.com










2212-6716 © 2013 The Authors. Published by Elsevier B.V. Open access under CC BY-NC-ND license. Selection and/or peer review under responsibility of American Applied Science Research Institute doi:10.1016/j.aasri.2013.10.009


compared with SOM and k-Means algorithm. By combining the ideas of FCM and divergence measure for the problem of image classification, we expect a better feature extraction procedure for more accurate classification scheme. The method adopts the FCM algorithm with Divergence Measure [3]-[5]for acquiring texture information from image data.

Section 2 summarizes FCM algorithms with two different distance measures: Euclidean distance and divergence distance. Section 3 reports the evaluations and a comparison of different schemes through experiments. Section 4 presents conclusions.

Adopted Clustering Algorithms

Fuzzy c-MeansAlgorithm

The following equation is used as the objective function for FCM[2] :






wheredi(xk) ,ki,m, n, and c follow the definitions in [2]. From Eq. (1), Bezdekfinds the following equations [2]:





FCM with Divergence Measure
(1)





(2)




(3)


The choice of different distance measure can affect the performance of clustering results [1]. This leads to the idea of divergence measure for image classification problem.
Given two Gaussian Probability Density Functions,  and , i = 1, , d , the divergence distance can be defined as follows[6,8]:




(4)


where	,	,	and follow the definition in [6,8]. Note that the divergence measure is also called as
Kullback-Leibler Divergence.

FCM calculates the parameters of center and membership values by applying all the data at once in batch mode. However, the D-FCM used in the proposed classifier calculates and updates their parameters at each application of each data vector as the Gradient-based FCM [3]. The advantage of this iterative application and updating the center parameters was reported in [3]. When each data vector  is presented to the network, the following can be also found :

(5)


Subsequently, the following update equation for the mean and variance was derived[6]:


(6)



(7)

where	, and  follow the definitions in [6].


Experiments and Results

For evaluation and comparison purpose for different classification schemes, we performed some experiments on a set of the Caltech image database[7]. The Caltech image database has been widely used as a benchmark data for various image classification problems. Examples of the four-category data used in experiments are given in Fig. 1.200 data are used for each category. Preparation for experiments follows the procedure used in [4]: 150 randomly selected training data and 50 remaining data for each class are used for the evaluation of different classifier schemes. Note that all the image data are converted to grey images with identical resolution.
The first step for designing a data classifier is the feature extraction process. The local feature extraction adopted in our experiments allows us to find localized feature information from entire image space.By collecting thefeature information from local points, each image data can be expressed in terms of features. In our experiments, 8 8 blocks are used for extracting localized information of an image data. The local information in each image window can be extracted by using conventional feature extraction methods [9]-[11]. Among them, Gabor filters and wavelet filters show reasonable performance except requiring extensive computational burden. This computational burden keeps these methods from being used for feature extraction tools for several applications. On the other hand, the Discrete Cosine Transform (DCT) is more suitable to acquire frequency information in images and DCT is used for our experiments because DCT does not require so much computational effort. Even though DCT coefficients out of each block image produces 64- dimensional one, the 32 lower frequency part of the 64 coefficients are used [4] and this yields a total 32- dimensional vector value for each local block image.
The model for a data category is formed by deciding the code vectors using clustering algorithms on its feature vectors. The modeling or training process consists of finding representativecode vector for


eachcategory with its feature vectors.Bayesian classifier is utilized for the performance evaluation on various classification schemes. Itallocates a class for a given testdata according to the following probability calculation [4]:


(8)



(9)



(10)

whereM,ci,d (=32), and i follow the definitions in [4].





(a) Car	(b) Motorbike


(c) Bike (d) Airplane



Fig. 1 Examples of data


The same training and test procedures for the same data sets are performed on two conventional clustering algorithms, SOM and FCM, and compared with the accuracy of the proposed algorithm. During experiments, several numbers of code vectors up to 19 are used for each algorithm. Fig. 2 summarizes their classification accuracies. The average accuracies over different numbers of code vectors (3 to 19) for SOM, FCM, and D- FCM are observed as 42.22%, 44.61%,and 73.33%, respectively. The classification accuracy is increased with
code vector numbers. Note that their classification accuracies are somewhat saturated when  code vector
numbers reach 15. Note also that SOM and FCM don’t use the variance while D-FCM does. Table 1 summarizes the classification performance for each category of image data when 15 code vectors are used. From Fig. 2 and Table 1, we can notice that the covariance value utilized in D-FCM along with mean information plays an important role in improving the classification accuracy for image data. The divergence distance measure allows the image classifier to have an advantage over the Euclidean distance and similar results are reported in [4]. Table 2 shows a confusion matrix of D-FCM based image classifier for the case of 15 code vectors. Car images are classified well enough while motorbike data are confused with airplane data. Some other feature extraction methods that can discriminate car data from airplane data need to be done in
future research. Future research also include the comparison of FCM and Gradient-based FCM under
divergence measure environment.


Fig. 2. Comparison of classification accuracies ofvarious classifier schemes over numbers of code vectors

Table 1. Classification performance of SOM, FCM, and D-FCM for the case of 15 code vectors



Car
Bike	Motorbike	Airplane
Avg.






Table 2. Detailed classification results of D-FCM

Classified








Conclusions
Inputs


A comparative study Euclidean distance and divergence distance for FCM is conducted in this paper.When used for an image classification problem, conventional FCM algorithm which uses Euclidean distance measure utilizes only mean information from an image block for its feature. On the other hand, FCM algorithm with divergence utilizes both of variance and mean information from an image block for its features. Self-Organizing Map is also used in our experiments as a baseline method for the performance comparison purpose. Experiments on Caltech database are performed for a four category problem. Classification accuracies from different classification schemes imply that divergence-based FCM is a better fit for image classification problem than the conventional FCM or SOM that use only the mean information as their features for image data. We can conclude that the divergence information of image data plays an important role in image classification problem and the resultant classification scheme that uses the divergence information as well as the mean information from image data is a better choice for image classification problem. However, a further effort should be given to find a feature extraction method for overcoming the confusion between Motorbike data and Airplane data.



Acknowledgements

This work was supported byIT R&D program of The MKE/KEIT (10040191) and by National Research Foundation of Korea Grantfunded by the Korean Government (2010-0009655).




References
[1]Bezdek, J.C. Pattern Recognition with Fuzzy Objective Function Algorithms. Plenum;1981. [2]Kohonen,T.The Self-Organizing Map. Proceedings of IEEE, 1990;78 :1464-1480.
Park D.C.et. al. Classification of Audio Signals Using Gradient-Based Fuzzy c-Means Algorithm with Divergence Measure. Proc. Pacific Rim Conference on Multimedia.2005; 698-708.
Park D.C., Woo D.M. Image classification using Gradient-Based Fuzzy c-Means with Divergence Measure. Proc. Int. Joint Conference on Neural Networks.2008; 2520-2524.
Park D.C. Satellite Image Classification Using a Divergence-Based Fuzzy c-Means Algorithm.Proc.Int. Conf. on Image and Signal Processing. 2012;555-561.
Park D.C. et. al.Centroid Neural NetworkWith a Divergence Measurefor GPDF Data Clustering.IEEE


Transactions on Neural Networks. 2008;19(6): 948-957. [7]http://www.vision.caltech.edu/html-files/archive.html
[8]FukunagaK. Introduction to Statistical Pattern Recognition, Academic Press Inc.;1990.
[9]Daugman J.G. Complete Discrete 2D Gabor Transform by Neural Networks forImage Analysis and Compression. IEEE Transactions on Acoustics, Speech, and SignalProcessing.1988;36:1169-11179. [10]Pun C.M., LeeM.C. Extraction of Shift Invariant Wavelet Features for Classification of Images with Different Sizes. IEEE Transactions on Pattern Analysis andMachine Intelligence. 2004;26(9) :1228-1233.
[11]Huang Y.L., Chang R.F. Texture Features for DCT-Coded Image Retrieval andClassification. Proc. Int. Conf. on Acoustics, Speech, and SignalProcessing.1999;6:3013-3016.
