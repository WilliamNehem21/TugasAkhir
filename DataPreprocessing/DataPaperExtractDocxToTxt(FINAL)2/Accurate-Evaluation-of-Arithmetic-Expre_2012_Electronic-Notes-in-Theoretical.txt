Available online at www.sciencedirect.com


Electronic Notes in Theoretical Computer Science 287 (2012) 3–16
www.elsevier.com/locate/entcs
Accurate Evaluation
of Arithmetic Expressions (Invited Talk)
Matthieu Martela,b,c,1
a Universit´e de Perpignan Via Domitia, Digits, Architectures et Logiciels Informatiques 52 avenue Paul Alduy, F-66860, Perpignan, France
b Universit´e Montpellier II
Laboratoire d’Informatique Robotique et de Micro´electronique de Montpellier UMR 5506, 161 rue Ada, F-34095, Montpellier, France
c CNRS, Laboratoire d’Informatique Robotique et de Micro´electronique de Montpellier UMR 5506, 161 rue Ada, F-34095, Montpellier, France


Abstract
In this article, we focus on the synthesis of arithmetic expressions that can be evaluated efficiently on computers in the sense that they do not create overflows, are accurate and do not use unnecessary ressources. We consider several computer arithmetics for integers, floating-point and fixed-point numbers and intervals and we show how to synthetize new expressions, mathematically equivalent to the original ones and more efficient. Our approach is based on abstract interpretation. We introduce two abstractions to represent in polynomial size sets of mathematically equivalent expressions. Then, we extract optimized expressions by searching the most accurate expression among the expressions contained in the abstract structures. We focus on the correctness of the synthesis which consists of showing that the new expressions cannot be distinguished from the source expressions when an observational abstraction is used.
Keywords: Abstract Interpretation, Code Synthesis, Computer Arithmetic.


Introduction
During the last decade, static analysis techniques based on abstract interpretation
[2] have reached an industrial level of maturity. Tools like Astr´ee [8], Clousot [9] or Fluctuat [4] have been successfully used on real case studies. These tools are able to compute subtle properties on codes such as accurate ranges for floating-point variables. However, when a run-time error or an unexpected behavior of the program is detected, these tools do not indicate how to fix the code. Then, a natural extension of this work is to propose bug corrections to the programmer. Such techniques have

1  Email:matthieu.martel@univ-perp.fr


1571-0661 © 2012 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2012.09.002

recently been proposed to repair integer expressions and relations between integer expressions [10] and to improve the accuracy of floating-point expressions [11].
In this article, we focus on the synthesis of expressions well-suited for the com- puter arithmetic in the sense that their evaluation by the machine is efficient, ac- curate and does not rise run-time errors. We consider that the expressions written in source codes by programmers are mathematical formulas which would return the expected results if the computers used exact arithmetics (with mathematical integer or real numbers). Then we synthesize new expressions which are mathematically equivalent to the original ones and whose evaluation in the computer arithmetic raises less errors. We consider four computer arithmetics: the integer arithmetic is subject to overflows which can be avoided in certain cases is the expressions are transformed [10]. In addition to overflows, the floating-point arithmetic [1,14] is subject to accuracy problems due to the rounding of the operations. The accuracy of expressions can be improved if the expressions are replaced by mathematically equivalent ones [11,6]. In the fixed-point arithmetic [5], the evaluation of equiv- alent versions of an expression may require more or less ressources depending on the size of the intermediary results. Finally, the interval arithmetic [12] introduces over-approximations because of the lack of relations between variables. In many cases, these over-approximations can be limited by transformation of the source expression.
Our work is based on P. and R. Cousot’s framework for program transformation [3]. We introduce non-standard semantics and an observational abstraction for the integer, floating-point, fixed-point and interval arithmetics. The synthesis is correct if it generates a new expression which cannot be distinguished from the source ex- pression when the observational abstraction is used. Because in general there exists too many expressions mathematically equivalent to a source expression, we present two abstractions of the sets of equivalent expressions [11,6]. Finally, the synthesis consists of selecting a expression among the abstract sets of equivalent expressions. This selection is based on an abstract interpretation of the non-standard semantics introduced for the four arithmetics.
This article is organized as follows. In Section 2, we introduce the computer arithmetic and, for each of them, we discuss how the synthesis of a new equivalent expression may improve the evaluation. Section 3 is dedicated to the correctness of the synthesis. It introduces the non-stndard semantics and obsevational abstrac- tions. In Section 4, we describe the abstraction of sets of equivalent expressions. Finally, the synthesis itself is described in Section 5 and Section 6 concludes.

Computer Arithmetics and Expression Synthesis
In this section, we review several computer arithmetics and, for each of them, we present how to synthesize expressions that can be evaluated efficiently. We start with our simpliest arithmetic which is the integer arithmetic. Then we discuss the cases of the floating-point and fixed-point arithmetics and, finally, we end this section by examining the case of interval arithmetic.

The signed integer arithmetic enables one to represent exactly any integer num- ber between a minimal value m and a maximal value M. For example, in many languages, the int format corresponds to the integer numbers between m = −231 and M = 231 − 1. When the result of some operation is out of the interval [m, M] then it wraps around this interval. This is a source of error in programs, as noted by F. Logozzo and T. Ball who propose code repairs for integer expressions and relations [10]. Formally, the elementary operations are defined by:



a ⊕ b =
m ⊕ (a + b − (M + 1)) if a + b > M M ⊕ (a + b − (m − 1)) if a + b < m
⎪⎩ a + b  otherwise

a ⊗ b =
a ⊕ (a ⊗ (b − 1)) if b ≥ 1
−a ⊕ (a ⊗ (−b − 1)) if b < 1

(1)

For example, with 32 bits signed integers, if x = 230 and y = −215 then

2 × x


3
+ y = −715860650 and  2 ×
x
 + y = 715795114. 3

Both expressions are mathematically equivalent while the closest integer to the exact result is 715795115. Because, in the signed integer arithmetic, errors may arise when intermediary results are out of the range [m, M], the synthesis of expressions has to generate expressions which are mathematically equivalent to the original ones and whose evaluation introduces the smallest intermediary results, in absolute value.
The floating-point arithmetic is defined by the IEEE754 Standard [1]. Floating- point numbers are used to encode real numbers. However, because they are finite representations of they mathematical cousins, roundoff errors arise during compu- tations and these approximations may, in some cases, significantly falsify the result of the evaluation. A floating-point number x is defined by
x = s · (d0.d1 ... dp−1) · βe = s · m · βe−p+1	(2) where s ∈ {−1, 1} is the sign, m = d0d1 ... dp−1 is the mantissa with digits 0 ≤
di < β, 0 ≤ i ≤ p − 1, p is the precision and e is the exponent, emin ≤ e ≤ emax. The IEEE754 Standard specifies several formats for the floating-point numbers by providing specific values for p, β, emin and emax. It also defines some rounding modes, towads +∞, −∞, 0 and to the nearest. Let us write ◦+∞, ◦−∞, ◦0 and
∼ the rounding functions, the IEEE754 Standard defines the semantics of the elementary operations by:
x ②r y = ◦r(x ∗ y)	(3)
where ②r denotes a floating-point operation +, −, × or ÷ computed using the rounding mode r and ∗ denotes an exact operation. Because of the roundoff errors, the results of the computations are not exact. For example, the value e = 2.7182818 ... can be computed using Bernouilli’s formula:

e =  lim
n→+∞

un  with un =
1+ 1
n
, n ≥ 0.

In double precision, u8 = 2.718282 but then the accuracy decreases as n grows:
u14 = 2.716110, u16 = 3.0.35035 and u17 = 1.0. For the floating-point arithmetic,

x	x	x	6
x	3	x	3

Fig. 1. Two fixed-point implementations of x2 − 6x +9 where x format is ⊕5, 3⟩.


the synthesis of expressions consists in generating an expression which is mathe- matically equal to the original one and which minimizes the roundoff error on the result, i.e. the distance |r − rˆ| between the exact result r and the floating-point result rˆ.
There exists no standard for the fixed-point arithmetic comparable to the IEEE754 Standard. A fixed-point format ⟨w, i⟩ depends on the total number of bits w used to encode the value and on the location of the fixed-point relative to the most significant bit [5]. In general, the numbers are encoded using two’s complement and the sequence of bits bw−1 ... b0 reprensents the value −bw−1 · 2i−1 +  j=w bw−j · 2i−j and the distance between two consecutive numbers is 2i−w. The format ⟨wr, ir⟩ of the result of an elementary operation depends on the formats ⟨w1, i1⟩ and ⟨w2, i2⟩ of its operands:


Addition:  wr = ir + max(w1 − i1, w2 − i2)
ir = max(i1 + ¬s1 ∧ s2, i2 + ¬s2 ∧ s1)+1 
Product:  wr = w1 + w2
ir = i1 + i2
(4)


In Equation (4), s1 and s2 denote the signs of the operands. Using the formats of Equation (4), the operations are exact and no rounding is needed.
Synthesizing an efficient expression for the fixed-point arithmetic consists of generating an expression equivalent to the original one and which minimizes the size of the implementation, or, in other words, which minimizes the sum of the sizes w of the formats of the intermediary results (the outputs of the operators.) For example, Figure 1 displays two implementations of the polynomial x2 −x+9, with x in the format ⟨5, 3⟩. The first scheme corresponds to the direct implementation and requires 68 bits to store the intermediary results while the second scheme implements the equivalent formula (x − 3) × (x − 3) and necessitates 40 bits only.
Our last computer arithmetic is the interval arithmetic [12]. Intervals are com- monly used to bound the exact result of computations carried out with floating- point numbers. Given two intervals [x, x] and [y, y] whose bounds are floating-point

numbers, the elementary operations are defined by:
⎡⎢	⎧⎪⎪⎨ x ⊗−∞ y ⎫⎪⎪⎬	⎧⎪⎪⎨ x ⊗+∞ y ⎫⎪⎪⎬⎤⎥

[x, x] ☒ [y, y]= [x ⊕	y, x ⊕	y]	[x, x] ☒ [y, y]= min
x ⊗−∞ y



, max
x ⊗+∞ y
⎥

(5)

Interval arithmetic suffers from the decorellation of the variables (the absence of relations) and from the wrapping effect. For example, because of the decorrelations, the value of the function f (x)=  x  is [1.5, 4] when x = [3, 4]. However, the function f is mathematically equal to g(x)= 1+  2  and g([3, 4]) = [2, 3]. While both results are correct, g([3, 4]) is clearly more accurate than f ([3, 4]). Synthesizing efficient expressions for the interval arithmetic then consists of generating expressions whose evaluation yields intervals of small width, in order to optimize the accuracy of the results.
Correctness of the Synthesis
The synthesized expressions being possibly very different from the original ones, the correctness of the process is based on semantics and not on syntax. We use the framework for program transformation introduced by P. and R. Cousot [3]. In Figure 2, we introduce four non-standard small-step operational semantics for the evaluation of expressions, where ∗ stands for any elementary operation. These semantics are denoted →int, →float, →fixed and →[] and they are related to the integer, floating-point, fixed-point and interval arithmetics, respectively.
For the integer arithmetic →int, a non standard value is a pair (vˆ, v) ∈ int × Z where int denotes the set of computer signed integers (for example the 32 bits or 64 bit integers) and Z denotes the set of signed mathemtical integers. Intuitively, a value (vˆ, v) gives both the exact value v and its computer approximation vˆ. A state
⟨e, m, ρ⟩∈ Expr × N × Envint of the integer non-standard semantics is made of an expression e, of an environment ρ : Var → (int × Z) of Envint mapping variables to non-standard values and of a non-negative integer m ∈ N indicating the maximal value encountered during the evaluation of the expression, in absolute value. The integer m has to be minimized during the synthesis of a new expression in order to keep the intermediary results inside the range [m, M] introduced in Section 2.
For the floating-point arithmetic →float, a non-standard value is a pair (vˆ, v) ∈ float × R where float is the set of floating-point numbers (one of the IEEE754 formats) and R the set of real numbers. In Figure 2, we assume that the floating- point operations are carried out using the rounding mode to the nearest. A state
⟨e, ρ⟩ of the non-standard floating-point semantics is made of an expression e and of an environment ρ ∈ Var → (float × R) mapping variables to non-standard values. Intuitively, the synthesis of an efficient expression for the floating-point arithmetic has to minimize the quantity |vˆ − v|, i.e. the difference between the computer and exact results.
For the fixed-point arithmetic →fixed, a non standard value is a pair (v⊕w,i⟩, v) ∈
fixed × R where fixed denotes the set of fixed-point numbers. We consider that in



ρ(x)= (vˆ, v) mj = max (|v|, m)
⟨x, m, ρ⟩ →int ⟨(vˆ, v), mj, ρ⟩
vˆ = vˆ1 ② vˆ2 v = v1 ∗ v2 mj = max(|v1|, |v2|, |v|, m)
⟨(vˆ1, v1) ∗ (vˆ2, v2), m, ρ⟩ →int ⟨(vˆ, v), mj, ρ⟩
⟨e1, m, ρ⟩ →int ⟨ej , mj, ρ⟩ mjj = max(m, mj)
⟨e1 ∗ e2, m, ρ⟩ →int ⟨ej ∗ e2, mjj, ρ⟩
⟨e2, m, ρ⟩ →int ⟨ej , mj, ρ⟩ mjj = max(m, mj)
⟨(vˆ1, v1) ∗ e2, m, ρ⟩ →int ⟨(vˆ1, v1) ∗ ej , mjj, ρ⟩

ρ(x)= (vˆ, v)


⟨x, ρ⟩ →float ⟨(vˆ, v), ρ⟩
⟨e1, ρ⟩ →float ⟨ej , ρ⟩
vˆ = vˆ1 ②~ vˆ2 v = v1 ∗ v2


⟨(vˆ1, v1) ∗ (vˆ2, v2), ρ⟩ →float ⟨(vˆ, v), ρ⟩
⟨e2, ρ⟩ →float ⟨ej , ρ⟩

⟨e1 ∗ e2, ρ⟩ →float ⟨ej ∗ e2, ρ⟩	⟨(vˆ1, v1) ∗ e2, ρ⟩ →float ⟨(vˆ1, v1) ∗ ej , ρ⟩
ρ(x)= (v⟨w,i⟩, v)
⟨x, W, ρ⟩ →fixed ⟨(v⟨w,i⟩, v), W, ρ⟩

v⟨w,i⟩ = v⟨w1,i1⟩ ② v⟨w2,i2⟩
v = v1 ∗ v2 Wj = W + w1 + w2 + w

1	2
⟨(v⟨w1,i1⟩⟩, v1) ∗ (v⟨w2,i2⟩, v2), W, ρ⟩ →fixed ⟨(v⟨w,i⟩, v),Wj, ρ⟩
1	2
⟨e1, W, ρ⟩ →fixed ⟨ej ,Wj, ρ⟩
⟨e1 ∗ e2, W, ρ⟩ →fixed ⟨ej ∗ e2,Wj, ρ⟩
⟨e2, W, ρ⟩ →fixed ⟨ej ,Wj, ρ⟩
⟨(v⟨w1,i1⟩, v1) ∗ e2, W, ρ⟩ →fixed ⟨(v⟨w1,i1⟩, v1) ∗ ej ,Wj, ρ⟩
1	1	2

ρ(x)= (vˆ, v)


⟨x, ρ⟩ →[] ⟨(vˆ, v), ρ⟩
⟨e1, ρ⟩ →[] ⟨ej , ρ⟩
vˆ = v1  vˆ2 v = {x ∗ y : x ∈ v1, y ∈ v2}


⟨(vˆ1, v1) ∗ (vˆ2, v2), ρ⟩ →[] ⟨(vˆ, v), ρ⟩
⟨e2, ρ⟩ →[] ⟨ej , ρ⟩

⟨e1 ∗ e2, ρ⟩ →[] ⟨ej ∗ e2, ρ⟩	⟨(vˆ1, v1) ∗ e2, ρ⟩ →[] ⟨(vˆ1, v1) ∗ ej , ρ⟩

Fig. 2. Non standard semantics for the integer, floating-point, fixed-point and interval arithmetics.
fixed, each fixed-point number has its own format ⟨w, i⟩, as introduced in Section
2. A state ⟨e, W, ρ⟩ ∈ Expr × N × Envfixed is made of an expression e, a non- negative integer W and an environment ρ ∈ Var → (fixed × R) mapping variables to non-standard values. Intuitively, W records the total number of bits required to represent all the intermediary results during the evaluation of the expression. The synthesis of a new expression for the fixed-point arithmetic has to minimize W .
Finally, a non standard value (vˆ, v) ∈ (float × float) × ℘(R) for the interval arithmetic is made of an inteval vˆ with floating-point bounds and a subset v of R (℘(R) denotes the powerset of R.) Intuitively, v is used to compute the exact image of the points belonging to the input intervals. In other words, if e(x, y) is an expression depending on two variables x ∈ [a, b] and y ∈ [c, d], we aim at computing in the non-standard semantics the exact image I = {e(x, y) : a ≤ x ≤ b, c ≤ y ≤ d}

of e. For the interval arithmetic, the synthesis of new expressions has to minimize the width of the interval corresponding to the result of the computation.
Given a set Θ of environments, the collecting semantics [e]]int Θ, [e]]float Θ, [[e]]fixed Θ and [[e]][] Θ correspond to the sets of maximal traces starting by the states {⟨e, 0, ρ⟩ : ρ ∈ Θ} for the integer arithmetic, {⟨e, ρ⟩ : ρ ∈ Θ} for the floating-point arithmetic, {⟨e, 0, ρ⟩ : ρ ∈ Θ} for the fixed-point arithmetic and
{⟨e, ρ⟩ : ρ ∈ Θ} for the interval arithmetic.
In order to define the correctness of the synthesis, we also introduce observational abstractions α& of the states [3]. It is correct to replace an expression e by another expression ej if for any Θ, [e]] Θ = S, [[ej]] Θ = Sj and {α&(s) : s ∈ S} = {α&(sj) : sj ∈ Sj} where [e ] Θ is one of our four collecting semantics. For the synthesis of expressions, the observational abstraction discards the computer results of the states and conserve only the mathematical results. Then, the synthesis is correct if the new expression always returns the same mathematical result than the source expression.
In all our semantics, values are pairs (vˆ, v) where vˆ is a value representable in
machine and v is a mathematical value. We define α& as the second projection,
i.e. α& (vˆ, v) = v for any non-standard semantics. The abstraction α& is then extended to states by projecting the values inside the expressions and environments.

Abstraction of Equivalent Expressions
In general, the number of expressions equivalent to an original expression e by associativity, commutativity, distributivity and factorization is exponential in the size of e.  For example, the number of ways to evaluate the polynomial (x − 1) × ... × (x − 1) is 2.3 · 106 for n =5 and 1.3 · 109 for n =6 [13]. In this sec-
`	n t˛i¸mes	x
tion, we introduce two abstractions, polynomial in size, of the set of mathematically
equivalent expressions.
The first abstraction consists of identifying the expressions whose syntactic trees are equal up to depth k. This abstraction is a simplified version of the abstraction in- troduced in [11]. In the present article, we introduce an under-approximation of the set of equivalent expressions while the more complicated abstraction introduced in
[11] was a complete covering of the mathematically equivalent expressions. Because we limit ourselves to the expressions whose syntactic trees are equal up to depth k, the application of algebraic laws like associativity, commutativity, etc. yields a limited number of expressions related to the user defined parameter k. We start by introducing a special expression T ∈ Expr and the function .’k : Expr → Expr which discards the deepest level of the syntactic tree of an expression [11]:


 v’k = v  if k ≥ 0
 x’k = x if k ≥ 0
 e1 ∗ e2’0 = T	if k =0 
 e ∗ e ’k =  e ’k−1 ∗ e ’k−1 if k ≥ 1	(6)

1	2	1	2
Let R ⊆ Expr × Expr be a binary relation on the set of expressions. We use R
to identify mathematically equivalent expressions. For example, R may contain




×

×	c


2

Fig. 3. APEG for the expression e =  (a + a)+ c × c.
associativity or distributivity:
  e1 + (e2 + e3), (e1 + e2)+ e3  : e1, e2, e3 ∈ Expr  ⊆ R	(7)


  e1 × (e2 + e3), e1 × e2 + e1 × e3  : e1, e2, e3 ∈ Expr  ⊆ R	(8)
Note that we do not require R to be transitive. To generate a subset of the expres- sions equivalent to a source expression e, we use the transition ⇒k of Equation (9) which relates states ⟨E, K⟩∈ ℘(Expr) × ℘(Expr):
e ∈ E e R e′  e′’k /∈ K
.	(9)
⟨E, K⟩→  ⟨{e′}∪ E, { e′’k}∪ K⟩

Using Equation (9) and the initial state ⟨{e}, { e’k}⟩, we may generate a maximal set E of expressions all equivalent to e and such that for any pair e1, e2 ∈ E,
 e1’k /= e2’k. The set E is an under-approximation of the set of expressions mathematically equivalent to e.
The second abstraction is based on the notion of Abstract Program Equivalence Graph (APEG for short) [6]. The APEGs are an extension of the Equivalence Program Expression Graphs (EPEGs) introduced by R. Tate et al. [15,16]. An APEG is defined inductively as follows:
A value v or a variable x is an APEG,
An expression p1 ∗ p2 is an APEG, where p1 and p2 are APEGs and ∗ is a binary operator,
A box	is an APEG, where ∗ is a commutative and associative
operator and the pi, 1 ≤ i ≤ n, are APEGs,
A non-empty set {p1,..., pn} of APEGs is an APEG where pi, 1 ≤ i ≤ n, is not a set of APEGs itself. The set {p1,..., pn} is called equivalence class.
An example of APEG is given in Figure 3. When an equivalence class (denoted by a dotted ellipse in Figure 3) contains many APEGs p1,..., pn then one of the pi
1 ≤ i ≤ n may be selected in order to build an expression. A box

represents any parsing of the expression p1 ∗ ... ∗ pn. From an implementation point of view, when several equivalent expressions share a common sub-expression, the latter is represented only once in the APEG. Then APEGs provide a compact representation of a set of equivalent expressions and make it possible to represent in an unique structure many equivalent expressions of very different shapes. For readability reasons, in Figure 3, the leafs corresponding to the variables a, b and c are duplicated while, it practice, they are defined only once in the structure.
The set A(p) of expressions contained inside an APEG p is defined inductively as follows:
If p is a value v or a variable x then A(p)= {v} or A(p)= {x},
If p is an expression p1 ∗ p2 then A(p)=  e1∈A(p1), e2∈A(p2) e1 ∗ e2,
If p is a box	then A(p) contains all the parsings of e1 ∗ ... ∗ en
for all e1 ∈ A(p1),..., en ∈ A(pn),
If p is an equivalence class {p1,..., pn} then A(p)=	1≤i≤n A(pi).
For instance, the APEG p of Figure 3 represents all the following expressions:

A(p)= ⎧⎪⎪⎨
⎪

(a + a)+ b × c,  (a + b)+ a × c,  (b + a)+ a × c,
(2 × a)+ b × c, c × (a + a)+ b , c × (a + b)+ a , c × (b + a)+ a , c × (2 × a)+ b , (a + a) × c + b × c,
⎫⎪⎪⎬
⎪


(10)

⎪⎩ (2 × a) × c + b × c, b × c + (a + a) × c, b × c + (2 × a) × c ⎪⎭
In comparison, with the first abstraction introduced at the beginning of this section, one may under-approximate the set of expressions equivalent to e = c× (a + a)+ b by the set


and by the set
S1 = c × (a + a)+ b , c × (a + a)+ c × b  if k = 1,	(11)

S  =	(a + a)+ b × c,  a + (a + b) × c,
(a + a) × c + b × c, a × c + (a + b) × c
,  if k = 2.	(12)

In their article on EPEGs, R. Tate et al. use rewritting rules to extend the structure up to saturation [15,16]. In our context, such rules would consist of per- forming some pattern matching in an existing APEG p and then adding new nodes in p, once a pattern has been recognized. For example, the rules corresponding to distributivity and box construction are given in Figure 4. An alternative technique for APEG construction is to use dedicated algorithms. Such algorithms, working in polynomial time, have been proposed in [6].
The abstractions defined previously in this section do not introduce expressions that are not mathematically equivalent to the source expression. Then, for synthesis, it is correct to select any expression belonging to the abstraction of a set of equivalent expressions. The selection criteria used at synthesis time are discussed in Section
5. We end this section by formalizing the correctness of the abstractions.
Let R⊆ Expr × Expr be the binary relation on the set of expressions introduced ealier in this section to identify mathematically equivalent expressions (see equations

×
 
+	p3		+	p3	×	×


p1	p2
p1	p2
p1	p3
p2	p3



✳

✳	p3

p1	p2
Fig. 4. Some rules for APEG construction by pattern matching.
(7) and (8).) The set of expressions equivalent to an original expression e can be generated by the following rule ⇒∈ ℘(Expr) × ℘(Expr):
e ∈ E  e R e′
(13)
E → {e′}∪ E

The set E (e) of expressions equivalent to e using the relations contained in R is such that the sequence {e} →∗ E (e) of transitions is maximal (i.e. E (e) → Ej implies Ej = E (e).)
Let ⟨E , K⟩ be the state resulting from a maximal transition path based on Equation (9): ⟨{e}, { e’k}⟩ →k ⟨E , K⟩ and let A(p) be the set of expressions contained inside an APEG p built from e, for example using the rules of Figure 4. Then E and A(p) are under-approximations of E (e) and there exists the following Galois connexions between the set of equivalent expression and its abstractions:

γ1
⟨℘(Expr), ⊆⟩	⟨℘(Expr) × ℘(Expr), ⊆  ⟩	(14)
α1



γ2
⟨℘(Expr), ⊆⟩	⟨Π, ⊆ ⟩	(15)
α2
In equations (14) and (15), ⊆× denotes the component-wise inclusion, Π denotes the set of APEGs and ⊆Π is the partial order on APEGs. Intuitively, p1 ⊆Π p2 if A(p1) ⊆ A(p2). An inductive definition of ⊆Π is given in [6]. The concretizations of abstract states ⟨E , K⟩ or p are defined by the following functions:


γ1(⟨E, K⟩)= 

E′	and	γ2(p)= 

E′.	(16)


	
Hence, the abstract sets ⟨E , K⟩ and p do not contain expressions which are not mathematically equivalent to the others and any expression ej in E or A(p) may be selected in order to synthesize a new expression as it will not be distinguishible from e by the observational abstraction α& introduced in Section 3.



ρ(x)= [v, v] mj = max (|v|, |v|, m)

⟨x, m, ρ⟩ → 
⟨[v, v], mj, ρ⟩

[v, v]= [v1, v1]  int [v2, v2] mj = max(|v1|, |v1|, |v2|, |v2|, |v|, |v|, m)

⟨[v1, v1] ∗ [v2, v2], m, ρ⟩ → 
⟨[v, v], mj, ρ⟩

⟨e1, m, ρ⟩ → 
⟨ej , mj, ρ⟩ mjj = max(m, mj)

⟨e1 ∗ e2, m, ρ⟩ → 
⟨ej ∗ e2, mjj, ρ⟩

⟨e2, m, ρ⟩ → 
⟨ej , mj, ρ⟩ mjj = max(m, mj)

⟨[v1, v1] ∗ e2, m, ρ⟩ → 
⟨[v1, v1] ∗ ej , mjj, ρ⟩

ρ(x)= ([vˆ, vˆ], [v, v])
⟨e1, ρ⟩ →	⟨ej , ρ⟩

	float	1	

⟨x, ρ⟩ → 
⟨([vˆ, vˆ], [v, v]), ρ⟩
⟨e1 ∗ e2, ρ⟩ → 
⟨ej ∗ e2, ρ⟩


		
[vˆ, vˆ]= [vˆ1, vˆ1] ~ [vˆ2, vˆ2] [v, v]= [v1, v1]  ↓ [v2, v2]

⟨([vˆ1, vˆ1], [v1, v1]) ∗ ([vˆ2, vˆ2], [v2, v2]), ρ⟩ → 
⟨([vˆ, vˆ], [v, v]), ρ⟩

⟨e2, ρ⟩ → 
⟨([vˆ1, vˆ1], [v1, v1]) ∗ e2, ρ⟩ → 
⟨ej , ρ⟩
⟨([vˆ1, vˆ1], [v1, v1]) ∗ ej , ρ⟩

ρ(x)= [v, v]⟨w,i⟩
⟨e1, W, ρ⟩ →	⟨ej ,Wj, ρ⟩

	fixed	1	

⟨x, W, ρ⟩ → 
⟨[v, v]⟨w,i⟩, W, ρ⟩
⟨e1 ∗ e2, W, ρ⟩ → 
⟨ej ∗ e2,Wj, ρ⟩

[v, v]⟨w,i⟩ = [v1, v1]⟨w1,i1⟩  fixed [v2, v2]⟨w2,i2⟩  Wj = W + w1 + w2 + w

⟨[v1, v1]⟨w1,i1⟩ ∗ [v2, v2]⟨w2,i2⟩, W, ρ⟩ → 
⟨[v, v]⟨w,i⟩,W j, ρ⟩

⟨e2, W, ρ⟩ → 
⟨[v1, v1]⟨w1,i1⟩ ∗ e2, W, ρ⟩ → 
⟨ej ,Wj, ρ⟩
⟨[v1, v1]⟨w1,i1⟩ ∗ ej ,Wj, ρ⟩

ρ(x)= [v, v]


⟨x, ρ⟩ →  ⟨[v, v], ρ⟩
⟨e1, ρ⟩ → ⟨ej , ρ⟩
[v, v]= [v1, v1]  x [v2, v2]

⟨[v1, v1] ∗ [v2, v2], ρ⟩ → ⟨(vˆ, v), ρ⟩
⟨e2, ρ⟩ → ⟨ej , ρ⟩

[]	1	[]	2
⟨e1 ∗ e2, ρ⟩ → ⟨ej ∗ e2, ρ⟩	⟨[v1, v1] ∗ e2, ρ⟩ → ⟨[v1, v1] ∗ ej , ρ⟩
[]	1	[]	2

Fig. 5. Abstract semantics for the integer, floating-point, fixed-point and interval arithmetics.
Generation of New Expressions
This section concerns the last step of the synthesis which consists of selecting an expression inside the abstract representations of equivalent expressions. First of all, we introduce abstract semantics, in Figure 5, in order to compare the quality of mathematically equivalent expressions. These semantics abstract the non-standard semantics of Figure 2 in which the mathematical values have been discarded. The abstract state contain intervals instead of scalar values since we aim at synthesizing expressions optimized for large ranges of inputs.

A value of the abstract integer semantics → 
is an interval [v, v] ∈ int × int

and an abstract state is a triple ⟨e, m, ρ⟩ ∈ Expr × int × Env	where Env	is
the set of environments mapping variables to abstract integer values. The op- erator  int denotes the operation ∗ between intervals of integers, no rounding is require in this case. An expression e1 is better than an expression e2 for an

abstract environment ρ , denoted e
≺ρ	e , if ⟨e , 0, ρ ⟩ → ∗
⟨[v , v ],m , ρ ⟩,

1	int	2	1
int
1	1	1	1

⟨e2, 0, ρ ⟩ → ∗  ⟨[v2, v2], m2, ρ ⟩ and m1 ≤ m2. Recall from Section 3 that m gives
the maximal value, in absolute value of the intermediary results encountered during the evaluation of the expression.

A value of the abstract floating-point semantics → 
is a pair of intervals

([vˆ, vˆ], [v, v]) ∈ (float × float) × (float × float). Intuitively, the first interval is the abstraction of the set of concrete values and the second interval is an under- approximation of the exact results of the computation. Hence, in the abstract semantics of Figure 5, the operations between the first intervals are carried out using the standard rounding mode ∼ of the machine (to the nearest in general) while for the second intervals, we use the rounding mode towards inside, denoted ↓. For instance

and
[v1, v1] ☒∼ [v2, v2]= [v1 ⊕∼ v2, v1 ⊕∼ v2]	(17)
[v1, v1] ☒↓ [v2, v2]= min(v1 ⊕−∞ v2, v1 ⊕−∞ v2), max(v1 ⊕+∞ v2, v1 ⊕+∞ v2) .	(18)

An abstract state is a pair ⟨e, ρ⟩ ∈ Expr × Env 
where Env 
denotes the

environments mapping variables to abstract floating-point values. An expression e1

is better than an expression e2
for an abstract environment ρ , denoted e1
ρ 
float
e2,

if ⟨e1, ρ ⟩ → ∗
⟨([vˆ1, vˆ1], [v1, v1]), ρ ⟩, ⟨e2, ρ ⟩ → ∗	⟨([vˆ2, vˆ2], [v2, v2]), ρ ⟩ and

float	1	float
max(|vˆ  − v |, |vˆ − v |) ≤ max(|vˆ  − v |, |vˆ − v |). In other words, e
2
≺ρ	e if

1	1	1	1
2	2	2	2
1	float  2

the error in the work case between the computer and mathematical results is less
for e1 than for e2.

Concerning the fixed-point semantics → 
, an abstract value is an interval of

fixed-point numbers which all have the same format. Such an interval is denoted
[v, v]⟨w,i⟩. We have:
[v, v](w,i⟩ =  v(w,i⟩ : v ≤ v ≤ v	(19)
An abstract state is a triple ⟨e, W, ρ⟩ ∈ Expr × int × Env	where Env 
is the set of environments mapping variables to abstract fixed-point values. The operator fixed denotes the operation ∗ between intevals whose bounds are fixed- point numbers. The operations are exact and no rounding mode is needed for  fixed. An expression e1 is better than an expression e2 for an abstract environment ρ ,

denoted e
≺ρ 
e , if ⟨e , 0, ρ ⟩ → ∗
⟨[v , v ]⟨w1,i1⟩,W , ρ ⟩, ⟨e , 0, ρ ⟩ → ∗

1	fixed  2	1
fixed	1	1
1	1	2
fixed

⟨[v2, v2]⟨w2,i2⟩, W2, ρ ⟩ and W1 ≤ W2. In other words, e1 is better than e2 if the number of bits require to store the intermediary results is less for e1 than for e2.

A value of the abstract interval semantics → 
is an interval [v, v] ∈ float ×

float. As in Section 2, the operator  denotes the operation ∗ between intevals of floating-point numbers with the rounding mode towards outside (see Equation

(5).) An abstract state is a pair ⟨e, ρ⟩ ∈ Expr × Env 
where Env 
denotes the

environments mapping variables to intervals of floating-point values. An expression

e is better than an expression e for an abstract environment ρ , denoted e
≺ρ  e ,

1	2	1
[]	2

if ⟨e1, r ⟩ → ∗ ⟨([v1, v1]), ρ ⟩, ⟨e2, r ⟩ → ∗ ⟨([v2, v2]), ρ ⟩ and v1 − v1 ≤ v2 − v2 i.e,
[]	1	[]	2

 
e1	float e2
if the width of interval resulting from the evaluation of e1
is smaller

than the width of the interval resulting from the evaluation of e2.
To synthesize a new expression equivalent to a source expression e using the first abstraction of Section 4, we use the rule of Equation (9) to compute the set E such that ⟨{e}, { e’k}⟩ →∗ ⟨E , K⟩} and we evaluate all the expressions of E with the abstract semantics of Figure 5, for the desired arithmetic. Then we select the expression which yields the smallest result in the sense of ≺int, ≺float, ≺fixed or ≺[].
Concerning APEGs, the synthesis of a new expression requires special tech- niques to handle the abstract boxes and to search inside the structure. For boxes, a greedy algorithm has been proposed [6].  It consists of selecting in
the best operation pi ∗ pj, 1 ≤ i, j ≤ n, i /= j in the sense of ≺int, ≺float, ≺fixed or ≺[] and then repeating the process with the box
.	For generic APEGs con-
taining equivalence classes, a limited depth search algorithm with memoization has also been proposed [6]. In its simplest setting, it consists of only considering the best expression of the child equivalence classes when synthesizing an expression for a parent equivalent class.



Conclusion
In this article, we have presented a general framework for the synthesis of arithmetic expressions which can be evaluated by computers accurately, without overflow and with limited ressources. We have considered the integer, floating-point, fixed-point and interval arithmetics and two abstractions of the set of mathematically equivalent expressions have been described. A large part of this article has been dedicated to the correctness of the synthesis.
Most of this work has been implemented in a tool, called Sardana [7], which ac- cepts the floating-point and fixed-point arithmetics and which implements APEGs. Many experimentations have been carried out with Sardana and the results are convincing [6].
In the future, we would like to generalize our approach to pieces of code more complicated than simple arithmetic expressions. For example, F. Logozzo and T. Ball have worked on binary relations between integer expressions [10]. More gener- ally, we also aim at modifying control structures like conditionals and loops.

References
ANSI/IEEE. IEEE Standard for Binary Floating-point Arithmetic, std 754-2008 edition, 2008.
Patrick Cousot and Radhia Cousot. Abstract interpretation: A unified lattice model for static analysis of programs by construction of approximations of fixed points. In Conference Record of the Fourth Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, pages 238–
252. ACM Press, New York, NY, 1977.
Patrick Cousot and Radhia Cousot. Systematic design of program transformation frameworks by abstract interpretation. In Conference Record of the Twentyninth Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, pages 178–190. ACM Press, New York, NY, 2002.
David Delmas, Eric Goubault, Sylvie Putot, Jean Souyris, Karim Tekkal, and Franck Vedrine. Towards an industrial use of fluctuat on safety-critical avionics software. In Formal Methods for Industrial Critical Systems (FMICS’12), pages 53–69, 2009.
Mentor Graphics. Algorithmic C Datatypes, software version 2.6 edition, 2011. http://www.mentor. com/esl/catapult/algorithmic.
Arnault Ioualalen and Matthieu Martel. A new abstract domain for the representation of mathematically equivalent expressions. In Static Analysis Symposium (SAS’12), volume 7460 of Lecture Notes in computer Science, pages 75–93. Springer Verlag, 2012.
Arnault Ioualalen and Matthieu Martel. Sardana: an automatic tool for numerical accuracy optimization. In 15th GAMM-IMACS International Symposium on Scientific Computing, Computer Arithmetic and Verified Numerical Computations (SCAN’12), 2012.
Daniel K¨astner, Stephan Wilhelm, Stefana Nenova, Patrick Cousot, Radhia Cousot, J´erˆome Feret, Antoine Min´e, Laurent Mauborgne, and Xavier Rival. Astr´ee: Proving the absence of runtime errors. In Embedded Real Time Software and Systems (ERTSS 2011), 2010.
Francesco Logozzo. Practical verification for the working programmer with code contracts and abstract interpretation. In Proceedings of the 12th Conference on Verification, Model Checking and Abstract Interpretation (VMCAI’11), volume 6538 of Lecture Notes in computer Science, pages 19–22. Springer Verlag, 2011.
Francesco Logozzo and Tom Ball. Modular and verified automatic program repair. In Proceedings of the 27th ACM International Conference on Object Oriented Programming Systems Languages and Applications (OOPSLA’12). ACM Press, New York, NY, 2012.
Matthieu Martel. Semantics-based transformation of arithmetic expressions. In Static Analysis Symposium (SAS’07), number 4634 in Lecture Notes in computer Science. Springer Verlag, 2007.
Ramon E. Moore, R. Baker Kearfott, and Michael J. Cloud. Introduction to Interval Analysis. SIAM, 2009.
Christophe Mouilleron. Efficient computation with structured matrices and arithmetic expressions. PhD thesis, Universit´e de Lyon–ENS de Lyon, November 2011.
Jean-Michel Muller, Nicolas Brisebarre, Florent de Dinechin, Claude-Pierre Jeannerod, Vincent Lef`evre, Guillaume Melquiond, Nathalie Revol, Damien Stehl´e, and Serge Torres. Handbook of Floating-Point Arithmetic. Birkh¨auser Boston, 2010.
Ross Tate, Michael Stepp, Zachary Tatlock, and Sorin Lerner. Equality saturation: A new approach to optimization. In Proceedings of the 36th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, (POPL’09), pages 264–276. ACM Press, 2009.
Ross Tate, Michael Stepp, Zachary Tatlock, and Sorin Lerner. Equality saturation: A new approach to optimization. Logical Methods in Computer Science, 7(1), 2011.
