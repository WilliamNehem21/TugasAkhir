Electronic Notes in Theoretical Computer Science 112 (2005) 167–189 
www.elsevier.com/locate/entcs


Performance Evaluation of Security Protocols Specified in LySa	1
Chiara Bodei, Michele Curti, Pierpaolo Degano 2
Dipartimento di Informatica, Universit`a di Pisa Viale F. Buonarroti, 2, I-56127 Pisa, Italy.

Mikael Buchholtz, Flemming Nielson, Hanne Riis Nielson 3
Informatics and Mathematical Modelling, Technical University of Denmark Richard Petersens Plads bldg 321,
DK-2800 Kongens Lyngby, Denmark
Corrado Priami 4
Dipartimento di Informatica e Telecomunicazioni, Universit`a di Trento Via Sommarive, 14 – 38050 Povo (TN), Italy.

Abstract
We use a special operational semantics which drives us in inferring quantitative measures on system describing cryptographic protocols. The transitions of the system carry enhanced labels. We assign rates to transitions by only looking at these labels. The rates reflect the distributed architecture running applications and the use of possibly different cryptosystems. We then map transition systems to Markov chains and evaluate performance of systems, using standard tools.


1 Supported in part by the Information Society Technologies programme of the European Commission, Future and Emerging Technologies, under the IST-2001-32072 project DE- GAS; the Danish SNF-project LoST.
2 Email: {chiara,curtim,degano}@di.unipi.it
3 Email: {mib,nielson,riis}@imm.dtu.dk
4 Email: priami@science.unitn.it
1571-0661 © 2004 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2004.01.017

Introduction

Cryptographic protocols, used in distributed systems for authentication and key exchange, are designed to guarantee security. A “prudent engineering” of protocols cannot leave out consideration of the trade-off between security and its cost. This is a preliminary proposal for partly mechanizing the estimate of quantitative aspects of protocol design.
Cryptography is a means of adding security to communication protocols: many algorithms (for hashing and encryption) may be used and each one has its cost. We are mainly interested in specifying and evaluating the cost of each cryptographic operation and more in general of each exchange of messages. Here, “cost” means any measure of quantitative properties such as speed, availability, and so on. To measure protocols, we describe them through a process algebra [5] and use an enhanced version of its semantics (along the lines of [8], see Appendix A) able to associate a cost (see Appendix B) with each transition, as proposed in [14]. Our approach then includes somewhat cryptography issues in the picture, even at a limited extent, so allowing the designer to be cryptography-aware. Significantly, quantitative measures here live together with usual qualitative semantics, where instead these aspects are abstracted away.
Consider the following version of the Otway-Rees protocol [15].
A → B : A, B, N, {A, B, N, NA}KA
B → S : A, B, N, {A, B, N, NA}KA, {A, B, N, NB}KB
(OR1)
S → B : N, {NA, KAB}KA, {NB, KAB}KB
B → A : N, {NA, KAB}KA
Intuitively, A sends B the plaintext A, B, N and an encryption readable only by A and the server S; B forwards it to S together with a message readable only to B and S. The server receives and decrypts both. If the components A, B, N in the encrypted messages match with the plaintext, S generates the session key KAB and sends B the key twice; one encrypted with the shared key KA and the other with the shared key KB. Finally, B sends A the first encryption. Here, the basic cryptographic system is a shared-key one, such as AES [3]: the same key shared between two principals is used for both encryption and decryption.
Often, designers use more cryptographic operations than strictly needed, just to play safe. Additional encryptions/decryptions make protocols less efficient, though. This is the case of OR1: according to [2], with the same cryptosystem, much encryption can be avoided when names are included in

S’s reply, resulting in
A → B : A, B, NA
B → S : A, B, NA, NB
(OR2)
S → B : {A, B, NA, KAB}KA, {A, B, NB, KAB}KB
B → A : {A, B, NA, KAB}KA
Here, it is easy to roughly evaluate the cost and establish that the 2 4-ary encryptions and 2 binary encryptions in OR1 are more expensive than the 2 4-ary encryptions in OR2.
However, looking at protocol narrations is not sufficient. Indeed, here you only have a list of the messages to be exchanged, leaving it unspecified which are the actions to be performed in receiving these messages (inputs, decryptions and possible checks on them). This can lead, in general, to an inaccurate estimate of costs.
The above motivates the choice of using a process algebraic specification like LySa [5] – a close relative of the π [12] and Spi-calculus [1] – that details the protocol narration, in that outputs and the corresponding inputs are made explicit and similarly for encryptions and the corresponding decryptions. Also, LySa is explicit on which keys are fresh and on which checks are to be per- formed on values received. More generally, LySa provides us with a unifying framework, in which protocols can be specified and analysed [5].
Here, we show how we can compare and measure protocols, specified in LySa. This allows the designer to choose among different protocol versions, based on an evaluation of the trade-off between security guarantees and the price for each alternative. Also, our approach makes it possible to estimate the cost of an attack, if any. Consider again our example based on the two versions of Otway-Rees protocol. The literature reports that both versions assure key authentication and key freshness, but they differ with respect to goals of entity authentication. In (OR1), A has assurance that B is alive,
i.e. that B has been running the protocol; indeed in receiving message .4, she can deduce that B must have sent message .2 recently. In (OR2) instead, A does not achieve liveness of B. We will show below that they differ also in efficiency, confirming the intuition given above.
Technically, we give LySa an enhanced operational semantics, in the style of [14]. We then mechanically derive Markov chains, once given additional information about the rates of system activities. More precisely, it suffices to have information about the activities performed by the components of a system in isolation, and about some features of the net architecture. The actual performance evaluation is then carried out using standard techniques

and tools [21,19,20].
The interpretation of the quantities that we associate to transitions can cover not only rates, but also other measures as fees or whatever. One could, for instance, think of a system where one has to pay a certain “fee” to a provider of cryptographic keys, such that certain operations are more “expen- sive” than others. The economical cost maybe naively taken into account in our approach as a time delay. Anyway, this is a matter of interpretation of the model we produce.
In summary, what we are proposing is a first step towards the development of a single, formal design methodology that supports its users in analysing both the behaviour and the performance of protocols, with a semi-mechanizable procedure. In this way, performance analysis is not delayed until a system is completely implemented, which may cause high extra-costs. Also, we can use the available analyser of LySa [5] to check security at the same specification stage. Indeed, this integration is possible because we use LySa as a unifying specification language. Moreover, our approach can be used with any of such languages endowed with an operational semantics.

Technique
We consider in the following the two versions of the Otway-Rees protocol specified in LySa, as our running example. In this section we only want to give the intuitive idea of our framework and therefore we will skip any technical detail. In particular, we give an intuitive introduction to the semantics, and the cost functions that enrich transitions with their costs; finally, we give the intuition on how to extract the necessary quantitative information to derive the Continuous Time Markov Chains (CTMC). The formal development is left to the Appendix.

LySa specification
The formal specifications of our protocols are in Table 1 and Table 2. The right part has a concise explanation of the action on the left, w.r.t the corresponding message exchange in the informal protocol narration. LySa [5] is based on the π-calculus [12] and Spi-calculus [1], but differs from these essentially in two aspects: (i) the absence of channels: there is only one global communication medium to which all processes have access; (ii) the tests associated with input and decryption are naturally expressed using pattern matching.
We are going to give the intuition of its semantics, on our running example, by briefly describing parts of the computation of both systems. We postpone


the introduction of enhanced labels, a basic ingredient of our proposal, to the next sub-section.

Example
In both versions of the protocol, the whole system is given by the parallel composition (|) of the three processes A, B, S. Each of them performs a certain number of actions and then re-starts again. In our calculus, new names such as nonces or keys are created with a restriction operator (νn)P , that acts as a static binder for n in the process P . In this way, we introduce: (i) the long-term key KA (resp. KB), shared between the server S and the principal A (resp. B); (ii) the nonces N,NA and NB; and (iii) the session key KAB to be shared between A and B. One of the basic forms of LySa dynamics, i.e. the communication, can be shown by using the first transition of Sys1, where we omit (νKA)(νKB). In the transition


(((νN )(νNA)(⟨A, B, N, {A, B, N, NA}KA
⟩. AJ) | (A, B; xN , xA
). BJ) | S) −→

((νN )(νNA)(AJ  | BJ[N/xN , {A, B, N, NA}K
A
enc
]) | S)

the principal B receives (l. 6 in Tab. 1) the message ⟨A, B, N, {A, B, N, NA}KA ⟩
sent by A (l. 3 in Tab. 1), where the term {A, B, N, NA}KA represents the encryption of the tuple (A, B, N, NA) under the symmetric key KA. Tests associated with input are directly embodied in the input: an input suc- ceeds, resulting in name instantiation, only if the first terms received coin- cide with the ones syntactically preceding the semi-colon. In the present

case, the input prefix has the form (A, B; xN , xA
).	The first two terms

are A, B as intended and, consequently, the remaining variables xN and xA are bound, within the continuation B', to the remaining terms of the mes- sage: N and {A, B, N, NA}KA , respectively (we indicate these instantiations

as B'[N/xN , {A, B, N, NA}K
A
enc
]). Similarly, in the second transition

((νN )(νNA)(AJ | (⟨A, B, N, {A, B, N, NA}K , {A, B, N, NB}K ⟩.

BJJ[N/xN , {A, B, N, NA}K
A
enc
]) | (A, B; yN , yA
B
enc
). SJ) −→

((νN )(νNA)(AJ | BJJ[N/xN , {A, B, N, NA}K
A
enc
]) |

SJ[N/yN , {A, B, N, NA}K
A
enc
, {A, B, N, NB}KB
B
enc

Now, in the third transition, the process S' that, after the substitutions is

decrypt {A, B, N, NA}KA
as {A, B, N ; wA }
A
in SJJ

attempts to decrypt {A, B, N, NA}KA with the key KA (see line 13 in Tab. 1).
Decryption represents the other basic form of dynamics of our calculus. Simi- larly to the input case, checks on part of the ciphertext are directly embodied



Table 1
OR1 Specification
in decryptions: a decryption succeeds only if the key is the same and the first terms decrypted coincide with the ones syntactically preceding the semi-colon. Here, the key is KA and the first three terms are A, B, N as intended and, consequently, the remaining variable wA is bound to NA.
Enhanced Labels
Once the protocol has been specified in LySa, we associate a label to each tran- sition, in particular to each communication and to each decryption. To this aim, we use an enhanced version of operational semantics called proved, in the style of [7,8] (see Appendix A for further details). In our proved operational semantics the transition labels are enhanced so that they record the syntac- tic context in which the actions take place, besides the actions themselves. The context part represents the low level routines performed by the run-time support to execute the transition itself. Therefore, the enhanced label of a communication must record its output and input components and their con- texts. We choose instead not to use contexts to enrich labels of decryptions.
Again, we are not going to formally introduce the enhanced semantics



Table 2
OR2 Specification

and its labels; we only give the flavour of it, still using our running example. The context, used here only for communication labels, takes into account the parallel composition and the restriction construct, by recalling for each output (resp. input) which restrictions precede it and in which parallel component of the whole system the output (resp. input) is. We obtain it by a pre-processing step. Given a LySa process (fully parenthesized), we statically enrich each prefix (output or input) with sequences ϑ of tags, where a tag can be νn,
0 or  1. The tag νn appears in the sequence if the prefix occurs after a restriction; while the tag  0 (resp.  1) appears, if the prefix is collocated in the left (resp. right) branch of a parallel composition. Parallel composition and restrictions can be nested.

Example (cont’d)
Returning to our example, the sequence of tags preceding the output
⟨A, B, N, {A, B, N, NA}KA ⟩ of A (line 3 in Tab. 1) is νKAνKB νN νNA  0  0: in- deed it comes after the four restrictions of KA,KB,N, NA and the process A is inside the left branch of the parallel composition (A|B), in turn on the left of the parallel composition ((A|B)|S). In our systems, sequences of tags reduce

to the following:
ϑA = νKAνKB νN νNA  0  0 preceding the prefixes of A in Sys1 and

' = νK
νKB
νNA
0 0 preceding the prefixes of A in Sys2;

ϑB = νKA
νKB
0  1 (resp. ϑ'
= νKA
νKB
νNB
0  1 preceding the first input of

B (resp. of B') in Sys1 and Sys2;

ϑS = νKA
νKB
1 (resp. ϑ'
= νKA
νKB
νKAB
1) preceding the first input of S

(resp. preceding the last output of S) in Sys1 and in Sys2.
Fig. 1 and 2 depict the finite transition system of the OR1 and OR2 LySa specifications, respectively. The transition system is a graph, in which pro- cesses form the nodes and arcs represent the possible transitions between them. For our present purpose, we just refer to abstract transitions from state P to

state P ' in the form: P (label,caption)
P ', where the first part refers to the

label of the transition. The second part is only added to recall the reader which part of the protocol the transition represents, for example the caption (1 : A −→ B) says that the transition represents the communication between A and B, reported in the first message of protocol. These captures are of no other use.
The following are the enhanced labels of the first three transitions of Sys1
discussed above:
A
l1 = ⟨ϑA⟨A, B, N, {A, B, N, NA}KA ⟩, ϑB(A, B; x  )⟩,

l2 = ⟨ϑ' ⟨A, B, N, {A, B, N, NA}K
, {A, B, N, NB}K
⟩, ϑS(A, B; yA, yB)⟩,

B	A
l3 = {A, B, N; wA }.
B	N	N

The other labels can be computed likewise.

l2 ,2:B−→S


l3 ,2:S dec









l7 ,4:B−→A

Fig. 1. Sys1 state transition system.



l' ,2:B−→S



l' ,3:S−→B


l' ,4:B−→A
l' ,3:B dec






Cost Function
Fig. 2. Sys2 state transition system.

We now introduce a function $(·) that intuitively assigns costs to individual transitions derived from their labels, alone (see Appendix B for further de- tails). Recall that by “cost” we mean any measure that affects quantitative properties of transitions. In particular, we are interested in cryptographic rou- tines that implement encryptions and decryptions. By inspecting enhanced labels we derive the costs of transitions. The context in which the action occurs, represents a suitable representation of the execution of the run-time support routines leading to that action on the target machine. Following this intuition, we let the cost of the transition depend on both the current action and on its context. Technically, this cost represents the rate of the transition,
i.e. the parameter which identifies the exponential distribution of the duration times of the transition. In other words, with “cost” we intend a measure of the time the system is likely to remain within a given transition. Our function therefore specifies the cost of a protocol in terms of the time overhead due to its primitives (see also [16]). In the next sub-section we will perform opera- tions on costs to tune a probabilistic distribution with respect to the expected speed of actions.
We intuitively present the main factors that influence costs.
The cost of a communication depends on both the input and the output components. Finally, it also depends on its context.
The cost of an output depends on the size of the message and on the cost of each part (or term) of the message. Note that the cost of an encryption is not constant: it depends on the algorithm that implements it, on the size of the cleartext, on the kind of the key (on its size and on its intended use, e.g. long-term or short-term).
The cost of an input depends on the size of the message and on the cost of the terms to be matched. It depends also on the number of checks to make in order to accept the message.
The cost of a decryption of a ciphertext depends on the algorithm that im- plements it, on the size of the ciphertext, on the kind of the key. It depends also on the number of checks to make in order to accept the decryption. To


simplify our presentation, we let the cost of a decryption not depend on its context.
Here, we do not fix the cost function: we only propose for it a possible set of parameters that reflect some features of a somewhat idealized architecture and of a particular cryptosystem, e.g. we take into account the number of processors or the kind of cryptographic algorithms. Although very abstract, this s to make our point.
As discussed before, the context of each action must be considered. Con- texts indeed slow down the speed of actions. We therefore determine a slowing factor for any construct of the language. Nevertheless, for simplicity, in our example, we only consider the cost due to parallel composition.
Parallel composition is evaluated according to the number np of processors available.
The cost of restriction depends at least on the number of names n(P ) of the process P because its resolution needs a search in a table of names. Furthermore, it depends on the kind of the name introduced (nonce, long- term key or short-term key).
The activation of a new agent via a constant invocation has a cost depending on the size and the number of its actual parameters, as well as on the number of processors available. We do not associate any cost to activations, though.

Example (cont’d)
We now associate a cost to each transition in the transition systems in Fig. 1 and 2. For the sake of simplicity, in computing the performance, we neglect the cost due to restrictions. Also, since we can assume that each principal has its own processing unit, we can give cost 1 to each tag i (i = 0, 1). In other words, we can ignore the context, in our example. Moreover, we give the same cost to output and input. More precisely:
in a transition representing a communication we assign a cost equal to n ∗

l
i=1
mi ∗ e, where n is the size of the message, s denotes the cost of a

unitary output, mi is the size of the ith encryption included in the message
(if any) and e denotes the cost of a unitary encryption.
in a transition representing a decryption we assign a cost equal to n ∗ d, where n is the size of the decryption and d denotes the cost of a unitary decryption.
For instance, the cost of the first transition in Fig. 1, carrying label l1 =
A
⟨ϑA⟨A, B, N, {A, B, N, NA}KA ⟩, ϑB(A, B; x  )⟩, is given by (7s + 4e), where 7
are the unary terms used for the output message and 4 is the size of the en-



Table 3
Cost Labels in Sys1 (on the left) and Sys2 (on the right).

crypted cleartext (we assume that input and output have the same cost). The cost of the third transition is instead 4d, that represents the cost of decrypting a ciphertext, obtaining a cleartext of size 4. The full list of the costs ci relative to the labels li in Sys1 and Sys2 are in Tab. 3. Note that cost parameters depend on the platform and on the actual protocol. For instance, in a system where cryptographic operations are performed at very high speed (e.g. thanks to a cryptographic accelerator), but with a slow link (low bandwidth), the cost for encryptions will be low and high for communication.
Markov Chains
Now, we show how to extract quantitative information from a transition sys- tem (obtained using our enhanced operational semantics) by transforming it into a CTMC.
Our first step is introducing a function that assigns costs to individual transitions, and afterwards, we will perform operations on costs to tune a probabilistic distribution w.r.t. the expected speed of actions. Although we interpret costs as parameters of exponential distributions, our relabeling func- tions are not intended to manipulate random variables. The intuition is that cost functions define a single exponential distribution by subsequent refine- ments as soon as information on the run-time becomes explicit. Operationally we start with an optimistic selection of an exponential distribution and then, while scanning contexts, we jump to other distributions until the one suitable for the current transition is reached. The cost functions encode this jumping strategy. Once the exponential distributions of transitions have been com- puted, we make some numerical calculations, possibly by collapsing those arcs that share source and target.
Recall that the exponential distributions we use enjoy the memoryless property. Roughly speaking, the occurrence of the next transition is inde- pendent of when the last transition occurred. This means that any time a


transition becomes enabled, it restarts its elapsing time as if it were the first time that it was enabled. Furthermore, all transitions are assumed to be time homogeneous, meaning that the rate of a transition is independent of the time at which it occurs.
We first associate a parameter r with a transition to derive some transition probabilities, defined as the rate at which a system changes from behaving like process Pi to behaving like Pj: it corresponds to the sum of the costs of all the possible transitions from Pi to Pj. Note that in our example, in both transition systems, there is only one transition between each pair of nodes and consequently rates coincide with single costs.
Definition 2.1 The transition rate between two states Pi and Pj, written
q(Pi, Pj), is the rate at which the transitions between Pi and Pj occur

q(Pi, Pj) = Σ
θk
Pi−→Pj

$(θk).


Remember that $ is the cost function as defined in Appendix B. A con- tinuous time Markov chain C can be conveniently represented as a directed graph whose nodes are the states of C, and whose arcs only connect the states that can be reached by each other.
The rates at which the process jumps from one state to another can be arranged in a square matrix Q, called generator matrix. Apart from its diag- onal, it is the adjacency matrix of the graph representation of the Continuous Time Markov Chain of the process under consideration (CTMC (P )). The entries of Q are called instantaneous transition rates and are defined by

,, q(Pi, Pj) =	Σ
$(θk) if i /= j


(1)

qij =
,

,,, —



n

j=1 j/=i
θk
Pi−→Pj


qij	if i = j

Performance measures of systems make sense over long periods of execu- tion. These measures for a process P are then usually derived by exploiting the stationary probability distribution Π for the CTMC we associate with P (it exists, because both transition systems are finite and cyclic).
Definition 2.2 Let Πt(xi) = p(X(t) = xi) be the probability that a CTMC is in the state xi at time t, and let Π0 = (Π0(x0), . . . , Π0(xn)) be the initial dis- tribution of states x0, x1, . . . , xn. Then a CTMC has a stationary probability

distribution Π = (Π(x0), . . . , Π(xn)) if


ΠQ = 0 and
Σ Π(xi) = 1.
i=0

The stationary distribution for each of the two systems in Fig. 1 and 2, is the solutions of the system of linear equations, defined as above.
Note that we can use standard numerical techniques and exploit the pre- ferred numerical package available to make all the computations needed above; the very same for the stochastic analysis, we will make afterwards.
Finally, we measure the performance of a process P by associating a reward structure with it, following [11,10,6]. Since our underlying performance model is a continuous time Markov chain, the reward structure is simply a function that associates a value with any state passed through in a computation of P ,
i.e. with any derivative of P , rather than to each transition, as often done in the literature, e.g. in [14]. For instance, when calculating the utilisation of a cryptosystem, in order to perform a decryption, we assign value 1 to any transition in which the decryption is enabled. All the other transitions earn the value 0 as transition reward.
Definition 2.3 Given a function ρθ associating a transition reward with each transition θ in a transition system, the reward of a state P is

ρP = Σ
θ
P −→Q

ρθ.


Intuitively, the reward structure of a process P is a vector of rewards with as many elements as the number of derivatives of P . From it and from the sta- tionary distribution Π of CTMC of a process P we can compute performance measures.
Definition 2.4 Let Π be the stationary distribution of CTMC(P ). The total reward of a process P is computed as

R(P ) = Σ
Pi∈d(P )

ρPi × Π(Pi).


For instance, we obtain the utilisation of a cryptosystem by summing the values of Π multiplied by the corresponding reward structure. This amounts to considering the time spent in the states in which the usage of the cryptosystem is enabled.


Example (cont’d)
Consider again the transition systems in Fig. 1 and 2 which are both finite and have cyclic initial states. These features ensure that they have stationary distributions. We derive the following generator matrices Q1 and Q2 of CTMC(Sys1) and CTMC(Sys2), respectively.


 0
Q1 =  0
0
2d






 −3s

0 
0
0
2s
−2d
0 

Q2 =  0
0 

The stationary distributions of the Markov chains Π i = (X0, . . . , Xn−1)
(i = 1, 2 and n = 6, 8) for Sys1 and Sys2, solutions of the following systems of linear equations



are as follows:
ΠQ = 0 and
n−1
Xi = 1.
i=0

Π = h A,  A ,  A ,  A , A,  A ,  A ,  A i


where:
1	b	4c	4d	4d	a	2d	2s	2d



and
4abcds
A =
6bcs + 4adcs + adbs + 2adbc + 4dbcs

a = 5s + 4e	b = 7s + 4e	c = 2s + e	g = 8s + 4e
Π = h 4B, B, 4B, B, 4B, B i


where
2	3s	s	f	d	s	d

3df s
B =
20df + 12sd + 6sf
f = 8s + 6e

We compare now the relative efficiency of the two versions of the protocol, in terms of their utilization of cryptographic routines, as discussed above. We assign value 1 (a non-zero transition reward) to any transition in which the decryption is enabled and we assign value 0 to any other transition. In


particular, we assign value 1 to the 3rd, 4th, 6th, 8th transitions in Sys1 and to the 4th and 6th transitions in Sys2.
Using this performance measure, which we call R, we obtain that the performance of OR1 is lower than the one of OR2, as expected. Indeed

R(Sys1) =
3A	2B
2d	R(Sys2) =  d

It is possible to prove that R(Sys1) is less or equal to R(Sys2), for every pos- itive s, d and e, assuming that encryption and decryption have the same cost. Consequently, we could measure and compare the performance of different versions of the same protocol and establish which is the more efficient.

Conclusion
We have presented a framework in which the performance analysis of security protocols is driven by the semantics of their specifications, given in terms of the process algebra LySa [5].
We have used an enhanced operational semantics, whose transitions are labelled by (encodings of) their proofs. Taking advantage of enhanced labels, we have mechanically associated rates, i.e probabilistic information, with tran- sitions. This is done symbolically, by looking at the enhanced labels, alone. Actual values are obtained as soon as the user provides some additional in- formation about the architecture and the cryptographic tools relative to the analysed system.
Since enhanced labels can be tightly connected to the routines called by the run-time support to implement each operator of the language, the information about architectural features and about algorithms used can be supplied by a compiler.
We are particularly interested here in the evaluation of the aspects due to cryptography, such as those depending on the cryptosystem and on the kind of keys used in a particular protocol. This makes it possible to weigh and compare different versions of protocols by the performance point of view. Each cryptosystem implies a different cost that depends on how it consumes resources and time. Furthermore, the algorithm behaviour is influenced by the target platform and vice versa, e.g. in a shared-key architecture where many principals want to communicate each other requires a higher number of different keys than in Client-Server architecture. Therefore our approach makes the critical cost factors evident and helps the designer to choose efficient solutions.
In this paper we have assumed that any activity is exponentially dis- tributed, but general distributions are also possible (see [18]), as they depend


on enhanced labels, alone. Once rates have been assigned to transitions, it is easy to derive the CTMC associated with the transition system of a process. From its stationary distribution, if any, we evaluate the performance of the process in hand. Moreover, although many different timing models can be used, in this paper we concentrate on a continuous time approach.
It is worth noticing that our approach follows the same pattern presented in [7] to derive behavioural information from our enhanced labels. Also, behavioural properties, such as confidentiality and authentication, can be checked by using a tool integrated with ours, like the analyser of LySa [5]. Therefore, we propose our operational semantics as a basis to uniformly carry out integrated behavioural and quantitative analysis.
We hope that our proposal is a little step in supporting the designers in the development of applications, by driving and assisting them in error-prone steps such as the translation of a specification into a model, suitable for quantitative analysis.

References
M. Abadi and A. D. Gordon. A calculus for cryptographic protocols - The Spi calculus.
Information and Computation 148, 1:1–70, January 1999.
M. Abadi and R. Needham. Prudent engineering practice for cryptographic protocols In Proc. of IEEE Symposium on Research in Security and Privacy, pp.122–136, IEEE, 1994.
J. Daemen and V. Rijndael. The design of Rijndael. Springer-Verlag, 2002.
A. A. Allen. Probability, Statistics and Queueing Theory with Computer Science Applications.
Academic Press, 1978.
C. Bodei, M. Buchholtz, P. Degano, F. Nielson, and H. Riis Nielson. Automatic validation of protocol narration. In Proc. of CSFW’03, pages 126–140. IEEE, 2003.
G. Clark. Formalising the specifications of rewards with PEPA. In Proc. of PAPM’96, pp. 136-160. CLUT, Torino, 1996.
P. Degano and C. Priami. Non Interleaving Semantics for Mobile Processes. Theoretical Computer Science, 216:237–270, 1999.
P. Degano and C. Priami. Enhanced Operational Semantics. ACM Computing Surveys, 33, 2 (June 2001), 135-176.
H. Hermanns and U. Herzog and V. Mertsiotakis. Stochastic process algebras – between LOTOS and Markov Chains. Computer Networks and ISDN systems 30(9-10):901-924, 1998.
J. Hillston. A Compositional Approach to Performance Modelling. Cambridge University Press, 1996.
R, Howard. Dynamic Probabilistic Systems: Semi-Markov and Decision Systems, Volume II, Wiley, 1971.
R. Milner, J. Parrow, and D. Walker. A calculus of mobile processes (I and II). Info. & Co., 100(1):1–77, 1992.
R. Nelson. Probability, Stochastic Processes and Queeing Theory. Springer-Verlag, 1995.


C. Nottegar, C. Priami and P. Degano. Performance Evaluation of Mobile Processes via Abstract Machines. IEEE Transactions on Software Engineering, 27(10):867-889, Oct 2001.
D. Otway and O. Rees. Efficient and timely mutual authentication. ACM Operating Systems Review, 21(1):8–10, 1987.
A. Perrig and D.Song. A First Step towards the Automatic Generation of Security Protocols.
Proc. of Network and Distributed System Security Symposium, 2000.
G. Plotkin. A Structural Approach to Operational Semantics, Tech. Rep. Aarhus University,
Denmark, 1981, DAIMI FN-19
C. Priami. Stochastic π-calculus with general distributions. In Proc. of PAPM’96, pp.41-57. CLUT Torino, 1996.
A. Reibnam and R. Smith and K. Trivedi. Markov and Markov reward model transient analysis: an overview of numerical approaches. European Journal of Operations Research: 40:257-267, 1989.
W. J. Stewart. Introduction to the numerical solutions of Markov chains. Princeton University Press, 1994.
K. S. Trivedi. Probability and Statistics with Reliability, Queeing and Computer Science Applications Edgewood Cliffs, NY, 1982.

Enhanced Operational Semantics of LySa
The syntax of LySa consists of terms E and processes P , where N and X denote sets of names and variables, respectively. Encryptions are tuples of terms E1, · · · , Ek encrypted under a term E0 representing a shared key. Values, that correspond to closed terms, i.e. terms without free variables, are used to code keys, nonces, messages etc. ,

E ::= terms ∈ E
n	name (n ∈ N )
x	variable (x ∈ X )
{E1, · · · , Ek}E0	symmetric encryption (k ≥ 0)

P ::= processes ∈ P
0	nil
⟨E1, · · · , Ek⟩. P	output
(E1, · · · , Ej; xj+1, · · · , xk). P	input (with matching)
P1 | P2	parallel composition
(ν n)P	restriction
A(y1, . . . , yn)	constant definition
decrypt E as {E1, · · · , Ej; xj+1, · · · , xk}E0 in P
symmetric decryption (with matching)
The set of free variables/free names, written fv(·)/fn(·) and α-equivalence ≡α are defined in the standard way. As usual we omit the trailing 0 of pro- cesses and use the standard notion of substitution: P [E/x] is the process P where the occurrences of x are replaced by E. Here, ⟨E1, · · · , Ek⟩ and (E1, · · · , Ej; xj+1, · · · , xk) represent the output and the input prefix, respec- tively. At run-time prefixes contain closed terms (apart from the variables xj+1, · · · , xk). To denote run-time prefixes we will use the meta-variables µout and µin, resp. in the following. Our enhanced operational semantics for LySa is built on the top of a reduction semantics. As usual, processes are consid-

ered modulo structural congruence ≡. The reduction relation —→θ
is the least

relation on closed processes, i.e. processes with no free variables, that satisfies the rules in Table A.1.


We first focus on the actions (similar to the standard semantics) and after- wards on the new form of processes and on the labels that enrich transitions. The rule (Com) expresses that an output ⟨E1, · · · , Ej, Ej+1, · · · , Ek⟩. T is
matched by an input (E' , · · · , E' ; xj+1, · · · , xk).T ' in case the first j elements
1	j
are pairwise the same. When the matchings are successful each Ei is bound
to each xi.
Similarly, the rule (Decr) expresses the result of matching the term re- sulting from an encryption {E1, · · · , Ej, Ej+1, · · · , Ek}E0 , against the pattern
inside the decryption decrypt E as {E' , · · · , E' ; xj+1, · · · , xk}E'  in T : the first
1	j	0
j components should be the same, in addition, the keys must be the same,

i.e. E0 = E'
— this models perfect symmetric cryptography. When suc-

cessful, each Ei is bound to each xi. The rules (Par), (Res) and (Congr) are standard. Finally, P (a1, . . . , an) is the definition of constant (hereafter a˜ denotes the sequence a1, . . . , an). Each agent identifier A has a unique defin- ing equation of the form A(y1, . . . , yn) = P , where the yi are distinct and fn(P ) ⊆ {y1, . . . , yn}. Hereafter, we will restrict ourselves to processes that generate finite state spaces, i.e. which have a finite set of derivatives. 5 Note that this does not mean that the behaviour of such processes is finite, because their transition systems may have loops. Indeed, particular forms of loops are essential to apply the steady state analysis that we carry out in our examples. The above ensures that our processes have a finite set of derivatives.
For the (proved) operational semantics of the our calculus, we need to as- sociate to each transition an enhanced label in the style of [7,8]. An enhanced label records: the action corresponding to the transition and the syntactic context in which the action takes place, in particular to the input and output part of a communication. To associate the context to each component, we statically associate a context label ϑ to each prefix of a given process. Above all, these labels take into account the parallel composition and the restric- tion construct (by distinguishing which kind of name the restriction creates). Technically, we use two functions: the first D distributes context labels on a given process and the second T builds the label, by introducing a  0 (resp. 1) for the left (resp. for the right) branch of a parallel composition and a νa for each restriction of the name a. In the end, we will have a new kind of processes LP, ranged over by T, T ', where each prefix is associated by a context label.
Definition A.1 Let L = {0, 1} with χ ∈ L∗, O = {νa, νK, νN } e o. Then the set of context labels is then defined as (L ∪ O)∗, ranged over by ϑ.

5 A sufficient condition for a process to be such is that all the agent identifiers occurring in it have a restricted form of definition A(y˜) = P . Namely, A can occur in P only if prefixed by some action and cannot occur within a parallel context.



Table A.1
Proved Operational semantics, T −θ→ T '.


Definition A.2 (Distributing labels)


— ϑ D 0 = 0
ϑ D(ϑ'µ.T ) = ϑϑ'µ.(ϑ D T )
ϑ D T0 | T1 = (ϑ D T0) | (ϑ D T1)
ϑ D(νa)T = (νa) ϑ D T
ϑ D A(y1, . . . , yn) = A(y1, . . . , yn)
—ϑ D decrypt {E1, · · · , Ek}	as {E' , · · · , E' ; xj+1, · · · , xk}E' in T =
E0	1	j	0
decrypt {E1, · · · , Ek}	as {E' , · · · , E' ; xj+1, · · · , xk}E'  in ϑ D T
E0	1	j	0

We can now define the function T mapping processes from P in LP.
Definition A.3 Let A, B be standard processes and let D the operator intro- duced in the previous definition. The following is a bijection:


T ((νa)T ) = (νa)νa DT (T )
T (T0|T1) = 0DT (T0) | 1DT (T1)
T (0) = 0
T (µ.T ) = µ.T (T )
T (A(y1, . . . , yn)) = A(y1, . . . , yn)
T (decrypt E as {E1, · · · , Ej; xj+1, · · · , xk}E0 in T ) =
decrypt E as {E1, · · · , Ej; xj+1, · · · , xk}E0 in T (T )
We need the following structural congruence rule to distribute the restric- tion labels to parallel processes:
(νa)(νa D T0)|T1 ≡ (νa)(νa D T0|νa D T1)
Now, we are ready to introduce the enhanced labels of transitions. Note that in the first label (the one relative to communication), there is a common part between the input and the output contexts.
Definition A.4 The set Θ of enhanced labels, ranged over θ, is defined by
θ ::= ⟨ϑ  1−iϑOµO, ϑ  iϑI µI⟩|⟨{E' , · · · , E' ; xj+1, · · · , xk} ' ⟩
1	j	E0

`	˛¸	x ` ˛¸ x



`	˛¸	x




Labelled transitions
—ϑ→ are introduced in (Com) and (Dec). The re-

duction —ϑ→ is closed under the other inference rules (parallel composition, constant invocation, restriction and congruence rule).
To recover the original reduction semantics that, by definition, does not use labels, it is sufficient to eliminate them and to eliminate context labels from processes.

Cost function
We are going to formally define the function which associates a cost with each transition labelled by θ. This cost represents the rate of the transition, i.e. the parameter which identifies the exponential distribution of the duration times of θ.
Therefore the cost of each component of an enhanced label ϑµ depends on the action µ and on the context ϑ.
To define a cost function, we start by considering the execution of the action µ on a dedicated architecture that only has to perform µ, and we


estimate once and for all the corresponding duration with a fixed rate r. Then we model the performance degradation due to the run-time support. In order to do that, we introduce a scaling factor for r in correspondence with each routine called by the implementation of the transition θ under consideration. We proceed now with our definitions. First we assign costs to the composi- tion of terms (in particular of encryptions), and to the components of actions µin, µout. The functions fu(n) and fu(n) represent the cost of unary terms, the functions, while fenc represents the cost function for the encryption (comput- ing the cost of the routines that implement the encryption algorithm). The cost function of a tuple coincides with the minimum cost among the costs of each component, to reflect the speed of the slower operation. Moreover, the functions fin, fout define the costs of the routines which implement the send
and receive primitives, where the function f=(j) represents the cost function
for a pattern matching of size j. In the following, fkind(crypt) denotes the cost of an encryption or a decryption, due to the cryptosystem used; similarly
for fkind(EO) denotes the cost due to the choice of a particular key (depend- ing on the size and the intended use). Moreover, for fsize(ctxt) denotes the cost due to the size of the cleartext to encrypt.
Furthermore, fsize(msg) stands for the cost due to size of the message to send or to receive in the evaluation of the cost of an output or an input. Finally, f=(j) is the function that computes the cost of performing a pattern matching on j terms.
$T (n) = fu(n)
$T (x) = fu(x)
$T ({E1 , . . . , En}E0 ) = fenc(fkind(crypt), fsize(ctxt), fkind(EO ), $T (E1, . . . , Ek))
$T ((E1, . . . , En)) = min($T (E1), . . . , $T (En))
$in(µin) = fin(fsize(msg), f=(j), $T (E1, . . . , Ej ))
$out(µout) = fout(fsize(msg), $T (E1, . . . , Ek))
According to the intuition that contexts slow down the speed of actions, we now determine a slowing factor for any construct of the language. The idea is to devise a general framework in which real situations
The cost of the operators is expressed by the function
$o(  i) = f(np), i = 0, 1
$o((νa)) = fν(n(P ), fkind(a))
Parallel composition is evaluated according to the number np of processors available. A particular case is $o(  ) = 1 which arises when there is an un- bound number of processors. (Recall that we are not yet considering commu- nications.) The cost of restriction depends at least on the number of names n(P ) of the process P because its resolution needs a search in a table of names.


Furthermore, it depends on the kind of the name fkind(a) (nonce, long-term key, short-term key).
Let the label of the transition in hand be ⟨ϑ||iϑinµin, ϑ||1−iϑoutµout⟩. The two partners perform independently some low-level operations locally to their environment. These operations are recorded in ϑin and ϑout, inductively built by the application of the function T . Each of the tags of ϑi leads to a delay in the rate of the corresponding µi, which we compute through the auxiliary cost function $o. Then the pairing ⟨||iϑinµin, ||1−iϑoutµout⟩ occurs and corresponds to the actual communication. Since communication is synchronous and hand- shaking, its cost is the minimum of the costs of the operations performed by the participants independently to make communications reflect the speed of the slower partner. Recall indeed that the lower the cost, the greater the time needed to complete an action and hence the slower the speed of the transi- tion occurring. 6 We estimate the corresponding duration with a fixed rate r = min{$in(||iϑinµin), $out(||1−iϑoutµout)}. Finally, there are those operations, recorded in ϑ, that account for the common context of the two partners.
If the label is ⟨dec⟩, then the cost is the one computed with the func- tion fdec, that corresponds to the cost of the routines that implement the decryption algorithm, including the cost of pattern matching.
We now have all the ingredients to define the function that associates costs with enhanced labels. It is defined by induction on θ and by using the auxiliary functions $µ as basis, and then $o.
Definition B.1 Let the cost function, where i = 0, 1, can be defined as
$(µ) = $µ(µ)
$(oθ) = $o (o) × $(θ)
$(  iθ) = $o(  i) × $(θ)
$(⟨ϑ  iϑinµin, ϑ  1−iϑoutµout⟩) = $(ϑ) × min{$(  iϑinµin), $(  1−iϑoutµout)
$(⟨dec⟩) = fdec(fkind(crypt), fsize(ctxt), f=(j), fkind(EO ), $T (E1, . . . , Ej ))





6 An exponential distribution with rate r is a function F (t) = 1 − e−rt, where t is the time parameter. The value of F (t) is smaller than 1 and limt→∞ F (t) = 1. The shape of F (t) is a curve which monotonically grows from 0 approaching 1 for positive values of its argument t. The parameter r determines the slope of the curve. The greater r, the faster F (t) approaches its asymptotic value. The probability of performing an action with parameter r within time x is F (x) = 1 − e−rx, so r determines the time, ∆t, needed to have a probability near to 1.
