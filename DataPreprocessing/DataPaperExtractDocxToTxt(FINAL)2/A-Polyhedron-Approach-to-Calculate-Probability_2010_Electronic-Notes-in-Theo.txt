

Electronic Notes in Theoretical Computer Science 264 (2010) 19–35
www.elsevier.com/locate/entcs

A Polyhedron Approach to Calculate Probability Distributions for Markov Chain Usage Models
Winfried Dulza Stefan Holppb Reinhard Germana
a Department of Computer Science 7 University of Erlangen-Nuremberg Erlangen, Germany
b sepp.med gmbh Roettenbach, Germany

Abstract
Statistical usage testing of hardware/software systems is based in the main on a Markov chain usage model. This kind of model represents the expected use of the system by a usage profile, i.e. appropriate probability values that are attached to the state transitions. In this paper we present a constraint-based polyhedron approach to calculate the probability distribution for the MCUM from a given set of usage constraints. Comparing the computed probability distributions of our polyhedron approach with the maximum entropy technique shows that our result is much closer to the intented constraint semantics. Using the polyhedron method, customer profiles can be calculated so that they reflect the intended system usage of different customers or customer types much better. In order to demonstrate the applicability of our approach, workflow testing of a complex RIS/PACS system in the medical domain was carried through and yielded very promising results.
Keywords: statistical usage testing, Markov chain usage model, profile generation, metrics, medical application domain


Introduction
MBT (Model-based Testing) techniques apply formal descriptions (models) of either the SUT (System under Test) or the expected usage behavior of SUT customers. In the former case, a behavioral specification is derived from the requirement defini- tions and serves as a starting basis to automatically generate test cases in order to test the SUT [9]. In the latter case, usage models are deduced from the requirements

1 Email: dulz@cs.fau.de
2 Email: german@cs.fau.de
3 Email: Stefan.Holpp@seppmed.de

1571-0661 © 2010 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2010.12.012

and may be considered as independent of the specification. Because exhaustive test- ing of real systems is infeasible in practice, an appropriate set of test cases is derived for accomplishing a given test goal. At this point, Markovian statistics come into play.
Statistical software testing has experienced a large growth of interest during the last years [4,6,3]. In contrary to other testing approaches, the statistical testing approach benefits from usage-driven testing and the possibility to make statistical inferences about the system, based on a set of (statistically correct) sampled test cases (Fig. 1).

Fig. 1. The Statistical Testing Approach.
The core objective of statistical testing is not to improve the quality of the system by finding more software defects, but to provide an estimate of the achieved quality metrics. Cleanroom software engineering [11] uses statistical testing as a reliability certification method.
Statistical testing relies on Markov chain usage models [14] that characterize the estimated distribution of possible uses of a given software in its intended en- vironment. A Markov chain consist of states and transitions between states [15]. This directed graph structure describes all possible usage scenarios for a given SUT derived by randomly traversing the arcs between dedicated start and end states. Transitions are augmented by probabilities from a usage profile that reflects usage choices users will have when they interact with the SUT (Fig. 2). Providing more than one usage profile for a given Markov chain structure is also possible. Hereby, the statistical selection of test cases reflects distinct properties of different roles or user classes, e.g. experts or normal users, in interaction with the SUT.
Markov chains are mathematically represented by transition matrices 4 . Here, the i-th row of the j-th column of the transition matrix holds the transition prob- ability for leaving state i and entering state j as depicted in Fig. 3.
Each path of the MCUM represents a possible use of the system, and correspond- ing transition probabilities define the mean rate at which a costumer will traverse this part of the system during the application.
Analytical computations can be applied even before test cases are executed in order to obtain characteristic test metrics. Examples are the Kullback-Leibler diver-

4 The transition matrix is often called stochastic matrix since the matrix elements are probability values.


0.2

Fig. 2. Example Markov Chain.




Start State  0

Usage State A  0
0.3
0.2
0.7	0 

0.5	0.3

Usage State B 	0
End State  0	0
0	1 
0	0 

Fig. 3. Corresponding Transition Matrix.

gence with respect to the given profile, the mean number of test cases necessary to reach a certain confidence level, or the expected reliability of the future system [7]. Because all computations of MCUM metrics heavily rely on the probability distribution of the given profile, methods for deriving correct probabilities are a critical part in creating a MCUM [13]. In this paper we focus on the computation of probability distributions from a given set of probability constraints by applying
a polyhedron approach.

Derivation of Usage Profiles
Motivation
After all structural components, i.e. states and arcs of the MCUM, have been identified [1], appropriate transition probabilities have to be obtained. Ideally, for every state of the MCUM, the exact probability distribution of the outgoing arcs of each state is known and fixed. Unfortunately, this is often not the case. For example, in the medical domain very large and complex RIS/PACS systems have to be tested, where the usage of the system is subject to diverse influences [5]. American Image Centers, for example, show a typical similar system usage and can be treated as one customer type. The behavior of this customer type is therefore mapped to a single MCUM.

General Strategies for Proﬁle Derivation
In [12], Whittaker proposes three possible techniques to compute MCUM transition probabilities, namely:
uninformed: probabilities are uniformly assigned over all outgoing arcs of a state,
informed: probabilities are assigned according to collected field data and
intended: probabilities are assigned according to the intended use of the system.

Uninformed Strategy
This is the most simple but also least suitable strategy for creating usage profiles. All outgoing arcs of a state within the usage profile are assigned equal probability values. While this approach does not presume any information about system usage, it can be applied if no such information is available.

Informed Strategy
Informed probability generation presumes collecting field data, which is then mapped to a usage profile. Hence, this method represents the most accurate way of gaining information about system usage. Field data may be derived from direct logging of user interaction use or screen recording, and can afterwards be evaluated or directly mapped to the model structure.

Intended Strategy
Probability values are defined by estimating the intended use of the system and strongly depend on the quality of the information sources. We preferred this strategy because neither changes on the system nor any additional technical resources are necessary. Development teams often possess a multitude of information sources for the required customer specification. In addition, application specialists, customer support and application trainers generally know the different customers and their specific way of working very well.

Constraint-Based Strategy
Since it can not be assumed that customer experts do also have expert knowledge about statistics and MCUM theory, the process of information acquisition must be arranged in the most informal way as possible. This implies that customer experts are allowed to describe their knowledge in terms of constraints [13]. Instead of assigning fixed numbers to the MCUM transition probabilities, they have to pos- tulate relationships between them. These constraints can further be automatically transformed to fixed probabilities by using algebraic techniques.
Reffering to the simple state example shown in Fig. 4, a customer expert has several possibilities to formulate his knowledge.
Area Definition



Fig. 4. MCUM State Example for Constraint Descriptions.

”Having selected a demo container, the fraction of time a radiologist would order a procedure is deﬁnitely bigger than 20%.”
This would result in p2 > 0.2.
Interval Definition
”Having selected a demo container, the fraction of time a radiologist would open an additional case is in between 50% and 80%.”
This would result in p1 ≥ 0.5 and p1 ≤ 0.8.
Exact Definition
”Having selected a demo container, the fraction of time a radiologist would enter of modify a note is exactly 25%.”
This would result in p3 = 0.25.
Dependent Definition
”Having selected a demo container, the fraction of time a radiologist would order a procedure is twice as big as opening an additional case.”
This would result in p2 =2 · p1.
Constraints can be further classified as follows:
Structural constraints are implicitly given by the model structure, i.e.
The probability values pi,j of all outgoing arcs ai,j of a state si must sum to one:	pi,j =1	∀i
j
Each probability value pi,j must be in the interval [0..1]: pi,j ≥ 0,	pi,j  ≤
1	∀i, j
Usage constraints are given to define the intended system usage and cannot be treated automatically.
Constraints reduce the solution space when searching for a suitable probability distribution for the MCUM. This is demonstrated by re-using the previous con- straints definitions referring to Fig. 4:
Taking the constraints (iii) and (iv) (p3 = 0.25,  p2 = 2 · p1) in addition to the structural constraints (p1 + p2 + p3 = 1,  p1 ≥ 0, p2 ≥ 0, p3 ≥ 0,  p1 ≤ 1, p2 ≤ 1, p3 ≤ 1), the correct probability distribution is implicitly given with p1 = 0.25, p2 = 0.5, p3 = 0.25.
Considering constraints (i) and (ii) instead of (iii) and (iv), there exists an infinite set of possible solutions. The distribution p1 = 0.7, p2 = 0.25, p3 = 0.05 is valid as well as p1 = 0.5, p2 = 0.3, p3 = 0.2.

Obviously, objective functions have to be defined so that they deliver a single prob- ability distribution in case that the number of possible solutions is greater than one.

Maximum Entropy Approach
In [8], it was argued to use the entropy of the probability distribution as objective function and to maximize this entropy afterwards.
The state entropy h(si) of a state si with n outgoing arcs ai,j and their corre- sponding probabilities pi,j with j = 1..n is defined as:

n
h(si)= −	pi,j · log2(pi,j)	(1)
j=1
This seems reasonable because the entropy is a measure of uncertainty and there- fore guarantees that the information content is limited exclusively by the defined constraints. Considering the entropy function without defining constraints, the maximum is found when the probability values represent a uniform distribution, which also matches the idea of the uninformed strategy 2.2.1.

Constraints as Equalities
Let us consider a constrained, non-linear optimization problem with equality con- straints first. Optimization problems of the form
max f (p1, ..., pk)	(2)
with constraints
g1(p1, ..., pk)=0 
··· 
gm(p1, ..., pk)=0 
(3)
can be solved using the Lagrange Method as proposed in [8]. Constraints as dis- cussed in section 3 can easily be converted to this form by simple transformations. Having the operational function

k
f (p1, ..., pk)= −	pi · log2(pi) ,	(4)
i=1
the structural constraint

k
g1(p1, ..., pk)= −1+	pi ,	(5)
i=1

and m − 1 usage constraints
gj(p1, ..., pk)= 0,	j = 2..m ,	(6)
the Lagrange function Λ can be defined as follows
m
Λ(p1, ..., pk, λ1, ..., λm)= f (p1, ..., pk)+	λj · gj(p1, ..., pk)	(7)
j=1
where λj are Lagrange Multipliers. The gradient of Λ is given by

∂Λ	⎛log2 pi Σ

∂λtgt
∂pt

∇pi,λj (Λ) = ∂(p ,λ ) = ⎜⎝	t=1
⎟⎠	(8)


Assuming only linear constraints, the constraint functions can be written as

k
gt(p1, ..., pk)=	(at,i · pi)+ ci ,	with	at,i, ci ∈ R	and	t ∈ [1..m]	(9)
i=1
where at,i, ci are fixed constants, resulting from the previous constraint definitions. The gradient of Λ can be simplified to

⎛log2 p1 +
⎜

⎜
m t=1
.
Σm
at,1 · λt ⎞
⎟

⎟

∂Λ
∇	(Λ) =
log2 pk +
⎜

t=1
at,k · λt
⎟
(10)

pi,λj
∂(pi, λj)
k
(a1,t
⎜
· pt)+ ct
⎟


⎜⎜⎝
t=1
.
Σk

⎟⎟⎠



To obtain the critical values of Λ, ∇(Λ) is set to zero. This leads to a system of equations
log2 p1 + a1,1 · λ1 + ··· + am,1 · λm =0 
.
log2 pk + a1,k · λ1 + ··· + am,k · λm =0 
a1,1 · p1 + ··· + a1,k · pk =0 
.
am,1 · p1 + ··· + am,k · pk = 0	(11)

with (k + m) equations and (k + m) unknowns. Thus, solving this equation system yields the probability distribution (p1, ..., pk) with maximum entropy.

Constraints with additional inequalities
The method of Lagrange Multipliers can be extended to handle additional inequality constraints. The Karush-Kuhn-Tucker Conditions (KKT [2]) describe a generaliza- tion of the method of Lagrange Multipliers. Let us consider the same optimization problem as before extended with additional inequalities:
h1(p1, ..., pk) ≤ 0
.
hn(p1, ..., pk) ≤ 0


The KKT conditions state that p is a global minimum 5 of f (p) if
(12)


m	n
∇f (p)+ Σ μi∇gi(p)+ Σ νj∇hj(p) = 0	(13)

under the conditions
gi(p) are affine functions,
hj(p) are convex functions,
νj ≥ 0 and μi exist ∀ i = 1..m, j = 1..n ,
νj · hj(p)=0	∀ j = 1..n .
Solving this can be done analogously to the method of Lagrange Multipliers.

Polyhedron Approach
Motivation
The maximum state entropy strategy faces a major drawback: while the state entropy is maximized, the resulting probability distribution for outgoing arcs of each state is always as uniform as it could be. For example, referring to Fig. 4 and using maximum state entropy, the single constraint p1 ≥ 2 · p2 would lead to the same result as the constraint p1 =2 · p2 would do.
However, the customer expert who formulated the constraint probably had in mind p1 to be truly bigger than twice the amount of p2. Thus, maximizing the state entropy may lead to inadequate solutions in certain cases. We therefore propose a more sophisticated method for generating constrained probability distributions while assuring the most probable constraint semantics.

5 To obtain the maximum of f (p), the minimum of −f (p) can be calculated.














p2



Fig. 5. Equality constraint, limiting the solution space by an affine subspace.


Fig. 6. Inequality constraint, limiting the solution space by a halfspace.
4.2  Computing the Probability Distribution
The basic idea is as follows. Without any constraints, the solution space of the searched probability distribution of a state with k outgoing arcs would be Rk. Of course, at least the structural constraints and, if stated, any usage constraints, restrict the solution space.
Equality constraints can be considered as restrictions to affine subspaces of lower dimensions within Rk (see Fig. 5) while inequalities result in restrictions to half spaces, as shown in Fig. 6. Regarding lots of constraints will lead to a convex polyhedron representing the constrained solution space. Based on this polyhedron, a suitable probability distribution is obtained. Again, let gk(p) be the set of equality constraints, and hl(p) the set of inequality constraints where p is the vector of all outgoing state transition probabilities pi.
g1(p)= c1
.
gm(p)= cm
h1(p) ≤ cm+1
.
hn(p) ≤ cm+n	(14)
A polyhedron can be defined as a system of linear equations. To obtain such a poly-

hedron, the inequality equations hl(p) must be transformed to equality constraints by inserting additional variables sl for each inequality:
hl(p) ≤ cl → hl(p)+ sl = cl, sl ≥ 0	∀l ∈ [(m + 1)..(m + n)]	(15) This leads to the following system of linear equations:
g1(p)= c1
.
gm(p)= cm
h1(p)+ s1 = cm+1
.
hn(p)+ sn = cm+n	(16)
with the solution vector x = (p1, ..., pk, s1, ..., sn)T . This can also be written in matrix form for a (m + n) × (k + n)-Matrix A = (ai,j) ∈ R(m+n)×(k+n):
A · x = c,	where	c = (c1, ..., cm+n)T	(17)
It is obvious that
k + n ≥ m + n	(18)
holds since the dimension of the solution space (k) is always greater than or equal the number of linear constraints (m). For each linear constraint, the solution space is limited by a further affine subspace and therefore loses (at least) one degree of freedom. In the special case where k + n = m + n, the vector x is implicitly given and no further inequality constraints can affect the result. Let bs be the r-th basis
vector in column s of A defined as

β1
b = ⎜	.
⎞

⎟ ,	where	βr = 1,	βi =0	∀ i /= r.	(19)

r	⎜	.	⎟



Assume that
⎝βm+n⎠



(α1, ..., αm+n),	αi ∈ Z+	(20)

is a possible arrangement of basis vectors within A and αk is corresponding to bαk .
All possible combinations of basis vectors are given by the set
B := (t1, ..., tm+n) | ti ∈ {α1, ..., αk+n}, ti /= tj ∀i, j = 1...(m + n), .	(21)
Each element zi ∈ B represents a combination of basis vectors, which leads to a valid basis solution of A. To obtain a solvable order of these basis vectors, one can choose a permutation of this combination for which A is solvable. The set of possible permutations for a given combination of basis vectors is given by the set
P(zi) :=  (t1, ..., tm+n) | ti ∈ zi \ {t1, ..., ti−1}, .	(22)




Fig. 7. Valid Solution Space with respect to Constraint Definitions.


Fig. 8. Center of Mass of a Polyhedron.
Each basis solution xi represents an intersection of affine subspaces and half spaces, while basis solutions with xi > 0 represent the corners of the convex polyhedron. Let {si}⊂B be the set of w unique permutations of zi which lead to solvable basis solutions xi with xi > 0, i = 1..w. The polyhedron itself represents the valid solution space given by the defined constraints. Every point within this solution space leads to a valid probability distribution (see Fig. 7). Of course, one of these valid solutions must be picked now and there might be a multitude of possible approaches for doing so. Intuitively, a probability distribution which matches the semantics of the defined constraints must be found somewhere in the center of the polyhedron. A suitable approach for choosing a distribution is to calculate the polyhedron’s center of mass R as follows (see also Fig. 8). Let xp be the vector
p	i
of k upper elements of xi, with xi (p1, ..., pk), which holds the searched probability
distribution. The center of mass R ∈ R is given by


R =  1 · Σ xp

(23)

In Table 1 and Table 2, we compare the solutions for both polyhedron and maximum state entropy approaches for different constraint definitions.

Table 1
Maximum Entropy vs. Polyhedron Approach for a constraint p1 ≥ p2 ≥ p3 ≥ p4.

In our opinion, the probability distribution obtained from the polyhedron ap- proach is more closer to the intended constraint semantics than the probabilties that are derived by maximizing the state entropy function: instead of always delivering values that are as close as possible to a uniform distribution, i.e. as random as possible, the polyhedron approach is focussing on providing the center of all con- straints inequalities and not on returning marginal distributions by considering only the edge values.
It should also be remarked that in the limiting case of using only equalities both techniques produce the same solution set for the probabilities.
Table 2
Maximum Entropy vs. Polyhedron Approach for a constraint p1 ≥ p2 + p3, p3 ≤ p4.



4.3	Constraint Modeling
For reasons of compactness, constraints can be placed directly within the model. The combination of both constraints and models result in a MCUM usage profile. To ensure an unambiguous mapping, each arc of the MCUM is assigned a unique name. Then, constraints can be placed in the model as a simple text field, as
depicted in Fig. 9.
Usage Profile Comparison
”How much does the expected usage of two customers differ?”
Usage profiles may be compared 6 with respect to the represented expected system usage. The resulting value indicates the magnitude of deviation of two usage profiles. Thus, high values prove that two customers use the system very differently.
The Kullback-Leibler divergence KL [7] is an information theoretic measure of the difference between two probability distributions P and Q:
KL(P, Q)=	p(i) · log	p(i)	(24)
q(i)
i

6 Usage profiles have to be based on the same MCUM structure to be comparable.



Fig. 9. Modeling of Constraints in Together Architect.
In order to compare Markov chain usage profiles, this metric is extended in the following to consider steady state information, i.e. the rate π(si) a user will chose state si of P during the average system usage:

KL(P, Q)= Σ π(si) Σ p


i,j
· log	pi,j	(25)
qi,j

i	j
Obviously, KL(P, Q) is not symmetric, i.e. in general,
KL(P, Q) /= KL(Q, P )	(26)
The KL divergence assumes that P represents a precisely calculated distribution, whereas Q is an approximation of P . Since usage profiles have to be treated equiv- alently, some kind of average KL divergence is needed.
The Jensen-Shannon divergence (JSD) delivers this measure. The JSD is a popular metric to obtain the difference of two equivalent probability distributions and can therefore be used to measure the similarity of two usage profiles P1 and P2.
1	1


with
JSD(P1, P2)= 2 KL(P1,M )+ 2 KL(P2,M )	(27)
1
M = 2 (P1 + P2)	(28)

Table 3 provides an overview of the deviation of created usage profiles for testing medical workflows [5].
It shows the derivation between a general profile averaged over all hospitals, whereas the USA and Australian profiles characterize two specific hospital type. A

Table 3
Usage Profile Divergence.

zero value indicates no profile deviation. It can be seen that an Australian hospital type is more closer to an average hospital than the USA one.
Another possible application of divergence measurements between MCUM pro- files is the classification of customers. A customer’s profile could be compared and assigned to existing classes, based on the divergence of the usage profiles. Such a class could be “3D User” for customers who use 3D features of the software ex- tensively. After a customer is assigned to a class, comparative data emerges for a variety of parameters. A simple example is the customer’s hardware standard. Customers in the class “3D User” are likely to have similar standards as for their hardware equipment. Furthermore, customer trainings could be tailored to these classes to give a certain group of customers specific trainings.
Test Planning
We finally present a technique based on the KL divergence, which allows to predefine the number of test cases that have to be executed. This issue is of main interest if the time for test case execution is limited at the end of a software development project.
In this situation, the KL divergence can also be used to identify the quantity of coverage between sampled test cases and the expected usage of the system given by a MCUM profile. Thus, a low value states that testing matches the expected customer usage behavior very closely.
Let si be an arbitrary state with n outgoing arcs ai,j. Let further ki,j denote the number of times the transition ai,j is covered by a set of sampled test cases. The resulting coverage rate ti,j for the test profile is calculated as



ti,j =
ki,j vi
0,	for vi =0 
6 j = 1..n,	vi =
Σj=1
ki,j	(29)

Let now T denote a test profile resulting from a test case sample and U an arbitrary usage profile. The KL divergence is defined as


K(U, T )=	πi
i

ui,j
j
· log	ui,j	(30)
ti,j

Obviously, the KL divergence is defined only if all arcs of the usage model are tested at least once. To circumvent this situation, [10] proposes an approximated

KL divergence. For arcs, which are not covered by test cases, ti,j is substituted by a small value ϵ > 0 that is close enough to zero depending on the wanted accuracy in order to avoid a division by zero. The resulting approximated KL divergence is given by

K˜ (U, T ) =	πi
i

ui,j
j
· log	ui,j
ϵ − ϵ · (sgn(ti,j)) + ti,j
	(31)

with

sgn(x)  =
,,,⎨

1,  if x > 0
0, if x =0 


(32)

−1, if x < 0
Figures 10 and 11 explain the behavior of the KL divergence during test case sampling with respect to different usage profiles. The X-axis is showing the number of test cases already used, whereas the Y-axis represents the corresponding K˜ (U, T ) values. Obviously, the KL divergence tends to reach lower values for samples from
usage profile from which the test cases are sampled.

Fig. 10. Test Cases Sampled from the General Profile.

7	Conclusions
We have shown that statistical testing based on MCUMs is a promising extension to existing deterministic testing approaches in general, and in the medical domain in particular.
In order to define customer usage profiles, appropriate transition probabilities have to be obtained. The constraint-based approach turned out to be most con- venient for this purpose. A polyhedron method for calculating suitable probability distributions has been presented and compared to the maximum entropy approach. From the usage models instructive metrics we have not explicitly mentioned can be analytically derived to improve test planning or to support management



Fig. 11. Test Cases Sampled from an Australian Profile.
decisions. Examples are the mean frequency customers will chose certain usage states or the mean lenght of the test cases for estimating the test exection time. Specific scenarios in order to compare customer classes by means of different MCUM usage profiles have also been identified and discussed.
As for test planning, a method based on the KL divergence to integrate a practi- cable test stop criteria into existing test case selection procedures has been proposed. All in all, model-based test case generation using MCUMs and dedicated profile classes enable promising techniques for testing complex systems, for example in the medical or the automotive domain. In the latter case, we are currently extending the test framework of a leading German automobile manufacturer to statistical test
case generation techniques.

References
M. Beyer and W. Dulz. Scenario-based statistical testing of quality of service requirements. In Springer LNCS 3466, International Dagstuhl Workshop on ”Scenarios: Model, Transformations and Tools”, pages 152–173. Springer Berlin, Heidelberg, 2005.
P. Bosch and J. A. Gomez. Karush-kuhn-tucker theorem for operator constraints and the local pontryagin maximum principle. Rev. Mat. Apl., 18:79–106, 1997.
W. Dulz and F. Zhen. MaTeLo - statistical usage testing by annotated sequence diagrams, Markov chains and TTCN-3. In IEEE Proc. of Third International Conference on Quality Software (QSIC 2003), pages 336–342, 2003.
W. J. Gutjahr. Importance sampling of test cases in Markovian software usage models. Probability in the Engineering and Informational Sciences, 11:19–3, 1997.
S. Holpp. Proving the Practicality of the Scenario-based Statistical Testing Approach within the Scope of the System Validation of a RIS/PACS System. Master’s thesis, Department of Computer Science, University of Erlangen-Nuremberg, Germany, February 2008.
D. P. Kelly and R. Oshana. Improving software quality using statistical testing techniques. Information & Software Technology, 42(12):801–807, 2000.
S. J. Prowell. Computations for markov chain usage models. Technical report, Software Engineering Institute, Carnegie-Mellon University, Pittsburgh, USA, 2000. UT-CS-03-505.
J. H. Poore, G. H. Walton, and J. A. Whittaker. A constraint-based approach to the representation of software usage models. Information & Software Technology, 42(12):825–833, 2000.


S. Rosaria and H. Robinson. Applying models in your testing process. Information and Software Technology, 42:815–824, 2000.
K. Sayre. Improved Techniques for Software Testing Based on Markov Chain Usage Models. PhD thesis, The University of Tennessee, Knoxville, TN, 1999.
C. J. Trammell S. J. Prowell. Cleanroom Software Engineering: Technology and Process. Addison- Wesley, 1999.
J. A. Whittaker and J. H. Poore. Markov analysis of software specifications. ACM Trans. Softw. Eng. Methodol., 2:93–106, 1993.
G. H. Walton and J. H. Poore. Generating transition probabilities to support model-based software testing. Softw. Pract. Exper., 30(10):1095–1106, 2000.
G. H. Walton, J. H. Poore, and C. J. Trammell. Statistical Testing of Software Based on a Usage Model. Software - Practice and Experience, 25(1):97–108, 1995.
J. A. Whittaker and M. G. Thomason. A markov chain model for statistical software testing. IEEE Transactions on Software Engineering, 20(10), 1994.
