Available online at www.sciencedirect.com


Electronic Notes in Theoretical Computer Science 322 (2016) 3–18
www.elsevier.com/locate/entcs


Exploiting Linearity in Sharing Analysis of Object-oriented Programs
Gianluca Amato  Maria Chiara Meo  Francesca Scozzari
Dipartimento di Economia, Università di Chieti-Pescara, Pescara, Italy

Abstract
We propose a new sharing analysis of object-oriented programs based on abstract interpretation. Two variables share when they are bound to data structures which overlap. We show that sharing analysis can greatly benefit from linearity analysis. We propose a combined domain including aliasing, linearity and sharing information. We use a graph-based representation of aliasing information which naturally encodes sharing and linearity information, and define all the necessary operators for the analysis of a Java-like language.
Keywords: Sharing analysis, linearity, aliasing, object-oriented programming.


Introduction
In object-oriented languages, program variables are often bound to complex data structures which may overlap. This is the case for Java programs, whose objects are stored in a shared memory called heap. Discovering whether two data structures may overlap is the scope of sharing analysis. This information is used in program parallelization and distribution: data structures which do not overlap allow the execution of methods on different processors, using disjoint memory. Moreover, it is very useful for improving other kind of analysis, like shape, pointer, class and cyclicity analysis. Sharing properties has been deeply studied for logic programs (e.g., [10,9,12,8,5,2]) and the large literature on this topic has been the starting point for designing our enhanced abstract domain for sharing analysis. In particular, the use of a linearity property [7,9,12,11,3,4] has proved to be very useful when dealing with sharing information (see [6] for a comparative evaluation). We show how the same idea can be rephrased to enhance sharing analysis of object-oriented programs. We propose a new combined analysis of sharing, aliasing and linearity properties for

1 Email: {gamato, cmeo, fscozzari}@unich.it
2 The authors would like to thank Fausto Spoto for helpful suggestions.

http://dx.doi.org/10.1016/j.entcs.2016.03.002
1571-0661/© 2016 The Authors. Published by Elsevier B.V.
This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).




Fig. 1. A concrete state with variables v0, v1, v2, v3, v4.





l	r




Fig. 2. Abstraction of the concrete state in Fig. 1.


Java-like programs based on abstract interpretation, inspired by the corresponding domains on logic programs.
A concrete state in a object-oriented program is usually described by a frame, which is a map from variables to memory locations (or null), and a memory, which is a map from locations to objects. Our idea is to abstract concrete states into a new kind of graphs we call ALPs graphs. For instance, given the class Tree with two fields l and r, the state in Fig. 1 is abstracted into the ALPs graph in Fig. 2. All ALPs graphs have at most two levels: nodes in the first level are labeled with one or more variables, while nodes in the second level are unlabeled. First-level nodes may have outgoing and incoming edges labeled with field names, while second-level nodes have no outgoing edges. Note that the data structures pointed by the variables v0 and v3 are abstracted in the same way, since we do not consider the whole data structure.

Aliasing and nullness.
ALPs graphs may encode definite nullness for variables and fields. A variable is definitively null if it does not appear as a label in the graph, while a field v0.f is null when there is no edge labeled with f departing from the v0 node. For example, v1.r is definitively null according to Fig. 2.
The graph also encodes definite weak aliasing : two variables (or two fields) are weak aliased when they point to the same location (possibly null). In the ALPs graph, this means they are the same node. For instance, the variables v3 and v4 in Fig. 1 are in the same node. Moreover, the fields v2.l and v2.r are abstracted into a single node.



Fig. 3. A concrete state with variables v7, v8, v9, v10.

Fig. 4. Abstraction of the concrete state in Fig. 3.
Sharing information.
We are interested in representing possible sharing information. We say that two locations share when it is possible to reach from them a common location. Consider the concrete state depicted in Fig. 3. Here v7.r and v8.l are bound to two different data structures which overlap, since v7.r.r.r and v8.l.l.l are bound to the same object: we say that v7.r and v8.l share. In the abstract graph, we represent this information with an (undirected) edge between the two nodes. For instance, the sharing information in Fig. 3 is captured by the edge connecting v7.r and v8.l in Fig. 4. To keep the graph as simple as possible we omit sharing information which can be derived, such as the edge between v7 and v8.
Linearity information.
We say that a location is non linear when there are two different paths starting from it and reaching a common location. Consider for instance Fig. 3. Starting from v9.r, we reach the same object by either v9.r.r.l.r or v9.r.r.r.l. Therefore we say that v9.r is non linear. It is easy to note that also v9 is non linear. In general, whenever a field v.f is non linear, the variable v is non linear too. We represent possible non linearity information by means of self loops. For instance, the concrete state for variables v9 and v10 in Fig. 3 is abstracted as in Fig. 4.

An example program
We show the relevance of linearity information with the help of the example program in Figure 5.



Tree makeTree ( n : I n t e g e r ) with m: I nteger i s {
m = 0 ;
if (n = m)
out = null ;
else {
out = new Tree ; m = n −1;
out . l = makeTree (m) ;
out . r = makeTree (m) ;
void useTree ( )
with m: Integer , t : Tree , t l : Tree , left : Tree ,
r i g h t : Tree i s { m = 1 0 ;
t = makeTree (m) ; tl	= t . l ;
right = t l . r ; left	= t l . l ;
}

} }

Fig. 5. The example program

l
		

The ALPs graph returned by the makeTree method.
ALPs graph representing the state at the end of the useTree method. All nodes in the first row are first level nodes, even if there are edges pointing to them.

Fig. 6. Two ALPs graphs for the example program.

The makeTree method builds a complete tree of depth n, whose nodes are all different. Actually, with a bottom up static analysis using ALPs graphs, we can easily infer that, for any input n ≥ 2, makeTree returns a data structure which may be described by the graph in Fig. 6a, where the label out denotes the return value of a method. Since there are no undirected edges between out.l and out.r, it means that out.l and out.r do not share. Moreover, since there are no self-loops, everything is guaranteed to be linear. In particular, out.l.l and out.l.r do not share.
The useTree method calls makeTree and extract two subtrees which do not share. In detail, in the useTree method, since we know that t is linear, we can infer that tl is linear too. Since tl is linear, its fields tl.r and tl.l do not share, and therefore right and left do not share. Note that linearity is not needed to prove that t.l and t.r do not share (sharing is enough for this). We need linearity when we want to go deeper and prove that t.l.l and t.l.r do not share. Linearity of t is essential here in proving that left and right do not share. The heap at the end of the useTree method may be described by the graph in Fig. 6b.

Preliminaries
We denote by [v1 '→ t1,..., vn '→ tn] the function f where dom(f ) = {v1,..., vn} and f (vi)= ti for i = 1,..., n. Its update is f [w1 '→ d1,..., wm '→ dm], where the domain may be enlarged. By f|s (f|−s) we denote the restriction of f to s ⊆ dom(f ) (to dom(f ) \ s). The two components of a pair are separated by . A definition of a pair S = a b silently defines the pair selectors s.a and s.b.

The Language
We use the Java-like object-oriented language defined in [15], which is a normalized version of Java with downward casts, and which we extend with upper casts.
Syntax.
Each program has a set of variables (or identifiers) V and a finite set of classes (or types) K ordered by a subclass relation ≤ such that K  ≤ is a poset. The set V includes the special variables this, res, out. Since we do not allow multiple inheritance, for any class κ ∈ K, the set {κj | κj ≥ κ} is a chain.
A type environment is a map from a finite set of variables to the associated class.
The set of type environments is

TypEnv = {τ : V → K | dom(τ ) is finite}.

Any class κ ∈ K defines a type environment F (κ) that maps the fields of the class κ (including both the fields defined in κ and those inherited by the superclasses) to their types. For ease of notation, we require that fields cannot be redefined in subclasses. It means that if f ∈ dom F (κ), and κj ≤ κ, then f ∈ dom F (κj) and F (κj)(f)= F (κ)(f).
Example 2.1 For the example program in Sect. 1.1, K = {Tree, Integer} has a flat ordering. Moreover F (Tree)= [l '→ Tree, r '→ Tree] and F (Integer)= [].
Expressions and commands are normalized versions of those of Java. We require that all casts are explicit, so that in any assignment v := exp the types of v and exp coincide. The same is required for formal and actual parameters. This is not a limitation since we allow upward and downward casts. The syntax of expressions and commands is:

exp ::= null κ | new κ | v | v.f | (κ)v | v.m(v1,..., vn)
com ::= v:=exp | v.f:=exp | {com; ··· ;com}
| if v = w then com else com | if v = null then com else com

where κ ∈ K and v, w, v1,..., vn ∈ V are distinct when they appear in the same clause. Each method κ.m of a class κ is defined with a statement like

κ0 m(w1 : κ1,..., wn : κn) with wn+1 : κn+1,..., wn+m : κn+m is com

where w1,..., wn, wn+1,..., wn+m ∈ V are distinct and are not res nor this nor out. Their declared types are κ1,..., κn, κn+1,..., κn+m ∈ K, respectively. The method can also use a variable out of type κ0 which holds its return value. We define body (κ.m)= com and returnType(κ.m)= κ0.

Semantics.
The semantics of the language is defined by means of frames, objects and memories
defined as follows:
Frameτ = {φ | φ ∈ dom(τ ) '→ Loc ∪ {null}} Obj = {κ φ | κ ∈ K, φ ∈ FrameF (κ)} Memory = {μ ∈ Loc → Obj | dom(μ) is finite}

where Loc is an infinite set of locations. A frame binds variables (identifiers) to locations or null. A memory binds such locations to objects, which contain a class tag and the frame for their fields. A new object of class κ is new(κ) = κ φ, with φ(v) = null for each v ∈ dom(F (κ)). The set of possible states with type environment τ is
Στ = {φ μ | φ ∈ Frameτ , μ ∈ Memory, φ  μ : τ}

where φ μ : τ means that φ μ is well typed w.r.t the type environment τ .
Example 2.2 Let τ = {v7 '→ Tree, v8 '→ Tree} and consider the state φ μ depicted in Figure 3. We have that φ = {v7 '→ l0, v8 '→ l1} and
μ = {l0 '→ Tree  {l '→ l2, r '→ l3}, l1 '→ Tree  {l '→ l4, r '→ null},
l2 '→ Tree {l '→ null, r '→ null}, l3 '→ Tree {l '→ null, r '→ l5}, l4 '→ Tree {l '→ l6, r '→ null}, l5 '→ Tree {l '→ null, r '→ l7},
l6 '→ Tree {l '→ l7, r '→ null}, l7 '→ Tree {l '→ null, r '→ null}} .

The denotation for an expression is a partial map E I _ : exp '→ (Στ → Στ+exp) from an initial to a final state, containing a distinguished variable res holding the value of the expression, where τ + exp = τ [res '→ typeτ (exp)] and typeτ (exp) is the static type of exp. The denotation of a command is a partial map from an initial to a final state: CIJ_) : com '→ (Στ → Στ ).
Each method κ.m is denoted by a partial function from input to output states and an interpretation I maps methods to partial functions on states, such that I(κ.m): Σinput (κ.m) → Σscope(κ.m), with the type environments:
input (κ.m)= [this '→ κ, w1 '→ κ1,..., wn '→ κn]

scope(κ.m)= input (κ.m) ∪ [out '→ κ0, wj
'→ κ1,..., wj
'→ κn,

wn+1 '→ κn+1,..., wn+m '→ κn+m]
where wj ,..., wj are fresh variables used to keep track of the actual parameters.
1	n
Each wj is assigned to the same value of the corresponding wi at the beginning of the method execution, and it is never changed later.

Example 2.3 Consider the method makeTree in Section 1.1. We have that
input (Tree.makeTree) =[this '→ Tree,n '→ Integer]
scope(Tree.makeTree) =input (Tree.makeTree)∪
[out '→ Tree, nj '→ Integer,m '→ Integer] .

Reachability, sharing, linearity and aliasing
We formalize here the concepts of reachability, sharing, linearity and aliasing for objects. In a later section we will use these concepts to introduce the new abstract domain ALPs. The following definition will simplify notation later.
Definition 3.1 (Fields of locations) Given σ = φ μ ∈ Στ , l ∈ dom(μ), f an identifier and f¯ = f1,..., fn a possibly empty sequence of identifiers, when they exist we write:
l.f for μ(l).φ(f), which is the location reachable from l through the field f;
l.f¯ for l.f1	fn; if f¯ is empty, l.f¯ = l.
Now we introduce some notation to treat variables and their fields as uniformly as possible.
Definition 3.2 (Qualified fields and identifiers) Given a type environment τ, we call qualified field a pair v.f where v ∈ dom(τ ) and f ∈ dom(F (τ (v))) and we call qualified identifier either a variable in dom(τ ) or a qualified field. We denote by Qτ and Iτ the set of qualified fields and identifiers respectively.
It is worth noting that we only consider fields that are in the declared type of the variables, and we do not consider further fields that are in the actual type. This choice, although may decrease the precision of the analysis, simplifies a lot the correspondence between abstract and concrete semantics and may increase the speed of the analysis.
Example 3.3 In Example 2.2, the qualified fields are Qτ = {v7 .l, v7 .r, v8 .l, v8 .r}
and the qualified identifiers are Iτ = {v7 , v8 }∪ Qτ .
Definition 3.4 (Notations for qualified fields) If σ = φ μ ∈ Στ and v.f ∈ Qτ , for uniformity of notation with variables we define:
τ (v.f)= F (τ (v))(f), i.e., the declared type of the field f for the variable v;
φ(v.f) = null if φ(v) = null, φ(v.f) = φ(v).f otherwise, which is the location pointed to by the field f in the variable v.
Definition 3.5 (Sharing, linearity and aliasing) Let σ ∈ Στ and i1, i2 ∈ Iτ . We say that:
i1 and i2 share in σ when φ(i1) /= null /= φ(i2) and there are f¯1, f¯2 such that
φ(i1).f¯1 = φ(i2).f¯2 /= null;
i1 is non-linear in σ when φ(i1) /= null and there are f¯1 /= f¯2 such that φ(i1).f¯1 =
φ(i1).f¯2 /= null; otherwise, i1 is said to be linear.

i1 and i2 are (weakly) aliased in σ when φ(i1)= φ(i2).
Example 3.6 Following Example 2.2, the field v7 .r shares with v8 .l. As a con- sequence, v7 shares with v8 .l and v8 . The fields v7 .l and v8 .r share only with themselves and the respective parents. All the identifiers are linear. In the example in Fig. 3, we have that v9 .r and v10 are not linear.
A qualified identifier i ∈ Iτ shares with itself if and only if it is not null. Moreover, each i ∈ Iτ such that φ(i) = null is linear and does not share with any other identifier.
It must be observed that two qualified identifiers might never be able to share if their static types do not let them be bound to overlapping data structures. Anal- ogously, certain qualified identifiers are forced to be linear.
Example 3.7 In the example in Section 1.1, we have thata Tree is not an Integer, an Integer is not a Tree and they do not have any field which can share. Therefore, any identifier of type Tree can never share with any identifier of type Integer. Moreover, any identifier of type Integer may only be linear.
We denote by NL the set of classes whose instances may be non-linear and by SH the set of pair of classes which may share. Both NL and SH may be computed by typing information only.

The new abstract domain
In this section we use the concepts of sharing, linearity and aliasing introduced before to define a new abstract domain, called ALPs (Aliasing Linearity Pair sharing), for the analysis of Java-like programs.
Aliasing graphs
We start by defining a basic domain encoding definite aliasing and definite nullness.
Definition 4.1 (Pre-Aliasing Graphs) A pre-aliasing graph over the type envi- ronment τ is a directed graph G = N  E  l such that:
N is the set of nodes;
E ⊆ N ×V × N is the set of directed edges, each labeled by an identifier;
l : dom(τ ) ~ N is a partial map from variables to nodes; with the additional condition that
∀n ∈ N, ∀f ∈ V, there is at most an outgoing edge from n labeled by f and
∀n ∈ N, ∀f ∈ V, if ⟨n, f, nj⟩ ∈ E then there exists v ∈ dom(τ ) such that l(v)= n
and v.f ∈ Qτ .

We write n1 −→f
n2 instead of ⟨n1, f, n2⟩. When it is clear from the context, we

denote G.N , G.E and G.l just by N , E and l. Moreover, we denote Gi.N , Gi.E
and Gi.l by Ni, Ei, li, and similarly for other typographical variants of G.

Definition 4.2 (Extension of l) Given a pre-aliasing graph G = N E l, we extend l on qualified fields v.f ∈ Qτ by



n	if l(v) /= ⊥∧ l(v) −→f
l(v.f)= 
n ∈ E

⊥	otherwise


The idea of a pre-aliasing graph is that, given an identifier i ∈ Iτ , l(i)= ⊥ means i is definitively null, while l(i)= l(j) means that i and j are either both null or aliased. This suggest to define the following preorder.
Definition 4.3 (Preordering on pre-aliasing graphs) Given G1, G2 ∈ Gτ , we say G1 ≤ G2 iﬀ
for each i, ij ∈ Iτ , l2(i)= l2(ij) ⇒ l1(i)= l1(ij);
for each i ∈ Iτ , l2(i)= ⊥⇒ l1(i)= ⊥.
Note that, given their intended meaning, some pre-aliasing graphs contain re- dundant information. For example, nodes which are not labeled by any qualified identifiers may be removed. On the converse, two identifiers i1, i2 of incompara- ble types may be (weak) aliased only if they are both null. We therefore restrict our attention to the pre-aliasing graphs which present some additional regularity conditions.
Definition 4.4 (Aliasing graph) An aliasing graph is a pre-aliasing graph G such that, for all n ∈ N, {τ (i) | i ∈ Iτ ∧l(i)= n} is a non-empty chain. We denote by Gτ the set of aliasing graphs over the type environment τ, by τ (n)= {τ (i) | i ∈ I ∧ l(i)= n} the type of the node n and by ψG(n)= {τ (w) | w ∈ dom(τ ) ∧ l(w)= n} the type that may be inferred by variables only.
Given a concrete state σ ∈ Στ , we may abstract it into an aliasing graph which conveys the relevant information.
Definition 4.5 Given σ = φ μ ∈ Στ , we define the abstraction of σ as an aliasing graph αa(σ)= G ∈ Gτ where
N = {l ∈ Loc | ∃i ∈ Iτ .φ(i)= l};
for each v ∈ dom(τ ), l(v)= φ(v) if φ(v) /= null, l(v)= ⊥ otherwise;

l −→f N.
lj ∈ E iﬀ there exists v ∈ dom(τ ) such that l(v)= l, v.f ∈ Qτ and l.f = lj ∈

We say that G ∈ Gτ is a correct abstraction of σ ∈ Στ iff αa(σ) ≤ G. Note that if αa(σ) ≤ G and l(i)= ⊥, then φ(i)= null, hence l may actually be used to represent definite nullness. Moreover, if l(i1)= l(i2), then either φ(i1)= φ(i2) ∈ Loc or φ(i1) = φ(i2) = null. Hence l actually encodes definite weak aliasing between variables.

ALPs graphs
Aliasing graphs are a very concrete representation of the part of the program state which is reachable from variables through a single field access. Pair-sharing and linearity, instead, summarize global properties of the state. We want to add possible sharing and possible non-linearity information to an aliasing graph.
Definition 4.6 (Pre-ALPs graph) A pre-ALPs graph G = G sh nl is a pre- aliasing graph G with a set sh ⊆ {{n, m}| n, m ∈ N} and a set nl ⊆ N.
When it is clear from the context, we denote G.G, G.sh, G.nl by G, sh, nl and
Gi.G, Gi.sh, Gi.nl by Gi, shi, nl i. Similarly for other variants of G.
The set sh in a pre-ALPs graph encodes possible pair sharing, while nl en- codes possible non-linearity. In particular, two identifiers i, j ∈ Iτ may share when
{l(i), l(j)}∈ sh, while i may be non-linear when l(i) ∈ nl . This suggests to extend the preorder on aliasing graphs to ALPs graphs as follows:
Proposition 4.7 (Preordering on pre-ALPs graphs) Pre-ALPs graphs are pre- ordered by

G1 ≤ G2 ⇐⇒ G1 ≤ G2 and ∀i ∈ Iτ . l1(i) ∈ nl 1 ⇒ l2(i) ∈ nl 2 and
∀i, j ∈ Iτ . {l1(i), l1(j)}∈ sh1 ⇒ {l2(i), l2(j)}∈ sh2 .

Not all the pre-ALPs graphs make sense, due to the way aliasing, non-linearity and sharing interact. In particular, some sharing and non-linearity information can be derived by other information. For example, if n is a node in G, then {n} should be in sh, otherwise any identifier i s.t. l(i) = n is forced to be null and G could be simplified by removing the node n. Other non-linearity or sharing information is redundant, since it cannot happen in practice due to the class hierarchy under consideration: pairs {n, m}∈ sh such that classes τG(n) and τG(m) cannot share, or variables n ∈ nl such that τG(n) ∈/ NL. We want to restrict our attention to those pre-ALPs graphs which explicitly show all implied and redundant information.
Definition 4.8 (ALPs graph) An ALPs graph G is a pre-ALPs graph where
G is an aliasing graph;
{{n}| n ∈ N}⊆ sh;
if there is a non-empty loop in G involving n, then n ∈ nl;
if {n, m}∈ sh then (τG(n), τG(m)) ∈ SH;
if n ∈ nl then τG(n) ∈ NL;
clG(sh  nl )= sh  nl.
Here clG(sh, nl ) is the smallest pair shj  nlj, under the component-wise ordering, such that
{n, m}∈ shj ∧ nj −→f  n ⇒ {nj, m}∈ shj;

n −f→1
m1, n −f→2
m2, f1 /= f2, {m1, m2}∈ shj ⇒ n ∈ nlj;

n ∈ nlj ∧ nj −→f  n ⇒ nj ∈ nlj.
We denote by ALPsτ the set of ALPs graphs over the type environment τ.
Given a concrete state σ ∈ Στ , we may abstract it into an aliasing graph which conveys the relevant information.
Definition 4.9 (Abstraction map on ALPs graph) Given σ = φ μ ∈ Στ , we define the abstraction of σ as α(σ)= αa(σ)  sh  nl where
sh = {{l1, l2}⊆ N | l1 and l2 share in σ} ,
nl = {l ∈ N | l is not linear in σ} .
We say G is a correct abstraction of σ when α(σ) ≤ G.
Given σ = φ μ and α(σ) ≤ G, if i1, i2 ∈ Iτ share in σ then {l(i1), l(i2)} ∈ sh. Moreover, if i ∈ Iτ is non-linear in σ, then l(i) ∈ nl . Hence G actually encodes possible sharing and non-linearity among variables.
Proposition 4.10 The preordered set of ALPs graphs has least element ⊥, greatest element T, lub Y, and glb Ω.
We may define a concretization map γ : ALPsτ → ℘(Στ ) which maps aliasing graphs to the set of concrete states they represent as γ(G)= {σ ∈ Στ | α(σ) ≤ G}. If we lift the map α in Def. 4.9 to an additive map α : ℘(Στ ) → ALPsτ as α(S)= 

σ∈S
α(σ), then α and γ form a Galois connection.

An Abstract Semantics on ALPs.
We present the abstract semantics on the domain ALPsτ . We provide a correct abstract counterpart for each concrete operator in the standard semantics. The ab- stract counterpart of an interpretation is an ALPs interpretation, defined as follows.
Definition 5.1 An ALPs interpretation I maps methods to total functions such that
I(κ.m): ALPsinput (κ.m) '→ ALPsscope(κ.m) for each method κ.m.
Abstract Denotation for the Expressions
Abstract denotations for expressions and commands are given compositionally on their syntax.
Definition 5.2 Let τ describe the variables in scope and I be a ALPs interpretation. Figure 7 defines the ALPs denotation for expression (except method calls) SE I J_) :
exp '→ (ALPsτ '→ ALPsτ+exp).
We briefly explain the behavior of the abstract semantic operators with respect to the corresponding concrete ones. The concrete semantics of null κ stores null in the variable res. Therefore, in the abstract semantics, we only need to add the new variable res in the type environment, without modifying the abstract state.
The concrete semantics of new κ stores in res a reference to a new object o, whose fields are null. The other variables do not change. Since o is only reachable from


SEI Jnull κ)(G)= G
SEI Jnew κ)(G)= N ∪ {nnew} ٨E ٨ l[res '→ nnew ] ٨ sh ∪ {{nnew}} ٨ nl
SEI Jv)(G)= N ٨ E ٨ l[res '→ l(v)] ٨ sh ٨ nl


SEI J(κ)v)(G)= 
⊥	if τ(l(v)) ∪ {κ} is not a chain
G	if l(v)= ⊥

add(G, l(v), κ)  otherwise
⊥	if l(v)= ⊥
I
τ
⎩add(G, l(v.f),τ (v.f))  otherwise

Fig. 7. The ALPs interpretation for expressions.

res, variable res shares with itself only and is clearly linear. Therefore, we only need to add a new node labeled with res, without affecting sharing nor non-linearity information.
The concrete semantics of v simply makes res an alias for v. Since the type of v and res coincides, we only need to add the variable v to the same node of res. The other variables are unchanged.
When it is defined, the cast (κ)v stores in res the value of v. When l(v) is not null, we use an auxiliary operator add(G, n, κ) which adds the label res to the node l(v), and possibly add new nodes for the fields of res which are not fields of v. In this case we can exploit the notion of linearity. In fact, when v is linear, we know that fields of res cannot share with each other and are linear.
The concrete semantics of v.f stores in res the value of the field f of v, provided v is not null. When v.f is not null, this essentially amounts to the same procedure of the previous case.

Abstract Denotation for the Commands
Definition 5.3 Let τ describe the variables in scope, I be an ALPs interpretation. Figure 8 shows the ALPs denotation for commands SCI J_) : com '→ (ALPsτ '→
ALPsτ ).
The concrete semantics of v:=exp evaluates exp and stores its result into v. Thus, the final abstract state is obtained by first computing SE I exp and then renaming res into v. Some of the nodes may become unlabeled and must be removed. This is accomplished by the auxiliary operation prune which removes unnecessary infor- mation, in particular unlabeled nodes and fields which are not in the declared type of the variables.
The evaluation of v.f :=exp is the most complex operation of the abstract se- mantics, since we must take into account that v might be aliased to many different nodes. The candidates are those variables, denoted by Vcomp, which share with l(v) and have compatible types. For each node labeled by a variable in Vcomp, we add a new fresh node in Nnew pointed by an edge (labeled by the field f) in Enew. Finally, all possible sharing and non-linearity are added. A slightly different treatment is devoted to the special case when the result of the expression is definitively null.

SCI Jv:=exp)(G) = prune((N ′ ٨ E′ ٨ l′[v '→ l′(res), res '→ ⊥]) ٨ sh′ ٨ nl′)
⊥	if l′(v)= ⊥
cl(prune((N ′ ∪ Nner ٨ E′ \ Edel ∪ Ener ٨ l′[res '→ ⊥])٨
	
cl(prune((N ′ ∪ Nner ٨ E′ \ Edel ∪ E′	٨ l′[res '→ ⊥])٨



SCI  if v = null


(G) = 
 SCI Jcom1)(G)	if l(v)= ⊥

z  then com else com
SCI Jcom1)(G|v=null) Y SCI Jcom2)(G)  otherwise

1	2	z	z

SCI  if v = w

(G) = 
 SCI Jcom1)(G)	if l(v)= l(w)

z  then com
else com
SCI Jcom1)(G|v=r ) Y SCI Jcom2)(G)  otherwise

1	2	z	z
SCI J{com1; ... ; comp}) = (λs ∈ ALP sz .s) ◦ SCI Jcomp) ◦ ··· ◦ SCI Jcom1)
z	z	z

where G′ = SEI Jexp)(G) and
Vcomp = {x ∈ dom(τ) | l′(x) /= l′(v), {x, v} ∈ sh′, {τC' (l′(x)), τC' (l′(v)} is a chain}
Nner = {nÆ' (x) | x ∈ Vcomp, f ∈ dom(F (ψC' (l′(x))), l′(x.f) /= l′(res)} new distinct nodes

E	′	f  ′
′	f  ′
′	comp

del = {l (v) −→ l (v.f)}∪ {l (x) −→ l (x.f) ∈ E
| x ∈ V	}

Ener = {l′(x) −f n '	| x ∈ V
comp
, nÆ' (x) ∈ Nner
}

shner = {{nÆ' (x), n′} | nÆ' (x) ∈ Nner, {l′(x.f), n′} ∈ sh′} ∪ 
{{nÆ' (x), nÆ' (y)} | nÆ' (x), nÆ' (y) ∈ Nner, {l′(x.f), l′(y.f)} ∈ sh}

E′	= Ener
′	f  ′

ner
′
ner




′
∪ {l (v) −→ l (res)}
= {{n, n′} | {l′(v), n} ∈ sh′ and {l′(res), n′} ∈ sh′} ∪ 
{{nÆ' (x), n′} | nÆ' (x) ∈ Nner, {l′(res), n′} ∈ sh′} ∪ 
{{nÆ' (x), n′} | nÆ' (x) ∈ Nner, {l′(x.f), n′} ∈ sh′} ∪ {{nÆ' (x), nÆ' (y)} | nÆ' (x), nÆ' (y) ∈ Nner}
{n ∈ N ′ | {n, l′(v)} ∈ sh′}∪ {nÆ' (x) | nÆ' (x) ∈ Nner}	if {res, v} ∈ sh′ or res ∈ nl′

nlner =
{n ∈ N ′ | {n, l′(v)} ∈ sh′, {res, n} ∈ sh′}	otherwise Fig. 8. The ALPs interpretation for commands.

Note that a similar situation also arise in [14].
To determine a correct approximation of the conditional “ if v = null” we check whether l(v)= ⊥. If this is the case, then we known that v is null and we evaluate com1. Otherwise, we evaluate both branches and compute the lub. When evaluating the first branch, we may improve precision by using the auxiliary operator G|v=null which returns a correct approximation of the program states {φ μ | α(φ μ) ≤ G ∧ φ(v) = null}, i.e., the states correctly approximated by G where v is null. Similarly for the conditional “if v = w” where we use another auxiliary operator G|v=w which returns a correct approximation of the set of program states {φ μ | α(φ μ) ≤ G∧φ(v)= φ(w)}. The composition of commands is denoted by functional composition over ALPs, where the identity map λs ∈ ALPsτ .s is needed when p = 0.

Abstract semantics of method call
When a method v.m is called, the class of v is inspected and the correct overloaded method for m is selected. The abstract domain contains only a partial information on the run-time class of v, since we only know that the class of v must be less than the class of any variable aliased with v, namely less than τG(l(v)). We exploit this information in computing the abstract semantics of a method call in Figure 9. In practice, we conservatively assume that every method m in any subclass of τG(l(v))



E£I Jv.m(v1,..., vn))(G)=  ⊥
if l(v)= ⊥
′


where linput = [this '→ l(v), w1 '→ l(v1),..., wn '→ l(vn)}] and G′ = prune(N ٨ E ٨ linput ٨ sh ٨ nl ).
Fig. 9. The ALPs interpretation for methods.
may be called. Note that methods defined only in superclasses of κ are already considered in κ.
When exiting from a method call, we need to rename out into res since, from the point of view of the caller, the returned value of the callee (out) is the value of the method call expression (res). We will use an auxiliary operation match which, given an initial and final state, updates the initial state trying to guess possible matching of variables in the abstract states.
Theorem 5.4 The abstract denotations in Figures 7, 8 and 9 are correct. More- over, the transformer on ALPs interpretations which, given a ALPs interpretation I, returns a new ALPs interpretation Ij such that


j	I
scope(κ.m)
Jbody (κ.m)) ◦ (λG ∈ ALPsinput (κ.m).N  E  l  sh  nl )

is correct, where lj = l[wj
'→ l(w1),..., wj
'→ l(wn)].

The abstract denotational semantics is the least fixpoint of this transformer, and it is correct w.r.t. the concrete denotational semantics used in [15].
Example 5.5 Consider the method Tree.makeTree in Sect. 1.1, where
scope(Tree.makeTree)=[ this '→ Tree,n '→ Integer, nj '→ Integer,
m '→ Integer, out '→ Tree] .
According to Theorem 5.4, we can compute a new ALPs interpretation from the least informative ALPs interpretation I⊥(Tree.makeTree)= λG.⊥scope(Tree.makeTree):
I1(Tree.makeTree)(G)= N ∪ {nm, nout}  E 
l[nj '→ l(n), out '→ nout,m '→ nm]  sh ∪ shj  nl
where shj = ∅ if l(n) = ⊥, and shj = {{nm, l(n)}} otherwise. Now, starting from
I1(Tree.makeTree), we can compute a new interpretation as follows:
I2 (Tree.makeTree)(G)= N ∪ {nm, nout, nout.l, nout.r, }  E 
l[nj '→ l(n), out '→ nout, out.l '→ nout.l, out.r '→ nout.r,m '→ nm]
 sh ∪ shj ∪ {{nout, nout.l}, {nout, nout.r}}  nl
which is the least fixpoint. Relatively to the case l(n) /= null, the abstract states
I1(Tree.makeTree)(G) and I2(Tree.makeTree)(G) are depicted in Figure 10.



n, n’ 		n, n’ 	




(a) First iteration.	(b) Second iteration.
Fig. 10. ALPs interpretations for the makeTree method.

Conclusions
We propose a new abstract domain ALPs which combines aliasing, linearity and sharing analysis for an object-oriented language, and provide all the necessary ab- stract operations. We show in Sec. 1.1 a simple example where linearity plays a fundamental role in proving that the two subtrees do not share.
The property of sharing for object-oriented languages has been studied in a few work, while it is deeply studied in the context of logic programming, where it is commonly combined with linearity analysis. At the best of our knowledge, this is the first attempt to combine sharing with linearity for Java programs. We also plan to implement ALPs as an abstract domain for the Jandom static analyzer [1].
In [15] the authors propose a simple domain of (pair-)sharing. In [13] the authors extend this domain proposing a combined analysis of (set) sharing, nullness and classes. The main differences of our paper w.r.t. these proposals are:
the ALPs abstract domain encodes linearity and aliasing information, in addition to pair-sharing;
information is encoded at the level of the fields of the objects pointed to by the variables in the environment, not only at variable level.
In [14], the authors propose a framework for the analysis of object-oriented lan- guages, and introduce two abstract domains for definite and possible aliasing re- spectively. The objects of these domains are similar to aliasing graphs, but without being restricted to two levels. Terminations is guaranteed by widening. These do- mains may be enriched by providing type information for the leaves of the graphs. However, they do not consider sharing or linearity properties.
The combination with linearity information allows us to improve the precision of the analysis in blocks of assignments, method calls, and thus on recursion. This is a fundamental issue that has not been considered in any previous analysis. In fact, an important point is that linearity information allows us to distinguish a tree from a DAG (direct acyclic graph). For instance, the result of makeTree in Figure 5 is a tree. However, the abstract representation of a tree in any abstract domain containing only information about reachability, sharing, acyclicity, nullness, distinctness and aliasing cannot be distinguished from the abstraction of a DAG. For example, the data structure t2:
Tree t 2 = new Tree ( ) t2 . l = new Tree ( )
t2 . r = new Tree ( )
t 2 .l.l = new Tree ( )

t 2 .l. r = t 2 .l.l 

has the same sharing, acyclicity, nullness, etc etc... properties of a tree, but t2 is not linear, while t in Figure 5 is linear. At the end of the method useTree, left is equal to t.l.l, right is t.l.r, but they do not share since t is a tree. However, t2.l.l and t2.l.r share. Therefore we need linearity to distinguish these two situations.
We believe that the ability to retrieve information after a call method is manda- tory for an analysis to scale on real programs. Moreover, we also provide information on nullness and classes, which may help other analyses.

References
Gianluca Amato, Simone Di Nardo Di Maio, and Francesca Scozzari. Numerical static analysis with Soot. In Proc. of the ACM SIGPLAN SOAP ’13, New York, NY, USA, 2013. ACM.
Gianluca Amato and Francesca Scozzari. Optimality in goal-dependent analysis of sharing. Theory and Practice of Logic Programming, 9(5):617–689, 2009.
Gianluca Amato and Francesca Scozzari. On the interaction between sharing and linearity. Theory and Practice of Logic Programming, 10(1):49–112, 2010.
Gianluca Amato and Francesca Scozzari. Optimal multibinding unification for sharing and linearity analysis. Theory and Practice of Logic Programming, 14:379–400, 2014.
Roberto Bagnara, Patricia M. Hill, and Enea Zaffanella. Set-sharing is redundant for pair-sharing.
Theoretical Computer Science, 277(1–2):3–46, 2002.
Roberto Bagnara, Enea Zaffanella, and Patricia M. Hill. Enhanced sharing analysis techniques: A comprehensive evaluation. Theory and Practice of Logic Programming, 5(1–2):1–43, 2005.
Michael Codish, Dennis Dams, and Eyal Yardeni. Derivation and safety of an abstract unification algorithm for groundness and aliasing analysis. In Proc. of ICLP, pages 79–93, 1991. The MIT Press.
Michael Codish, Harald Søndergaard, and Peter J. Stuckey. Sharing and groundness dependencies in logic programs. ACM Transactions on Programming Languages and Systems, 21(5):948–976, 1999.
Werner Hans and Stephan Winkler. Aliasing and groundness analysis of logic programs through abstract interpretation and its safety. Technical Report 92–27, Technical University of Aachen, 1992. Available from http://sunsite.informatik.rwth-aachen.de/Publications/AIB. Last accessed June 5, 2015.
Dean Jacobs and Anno Langen. Static analysis of logic programs for independent AND parallelism.
The Journal of Logic Programming, 13(2–3):291–314, 1992.
Andy King. A synergistic analysis for sharing and groundness which traces linearity. In Proc. of ESOP ’94, volume 788 of LNCS, pages 363–378. Springer, Berlin Heidelberg, 1994.
Kalyan Muthukumar and Manuel V. Hermenegildo. Compile-time derivation of variable dependency using abstract interpretation. The Journal of Logic Programming, 13(2–3):315–347, 1992.
Mario Méndez-Lojo and Manuel V. Hermenegildo. Precise set sharing analysis for java-style programs. In Proc. of VMCAI 2008, volume 4905 of LNCS, pages 172–187. Springer Berlin Heidelberg, 2008.
I. Pollet, B. Le Charlier, and A. Cortesi. Distinctness and Sharing Domains for Static Analysis of Java Programs. In Proc. of ECOOP 2001, volume 2072 of LNCS, pages 77–98, Budapest, Hungary, 2001.
S. Secci and F. Spoto. Pair-Sharing Analysis of Object-Oriented Programs. In Proc. of SAS 2005, volume 3672 of LNCS, pages 320–335, London, UK, 2005. Springer.
