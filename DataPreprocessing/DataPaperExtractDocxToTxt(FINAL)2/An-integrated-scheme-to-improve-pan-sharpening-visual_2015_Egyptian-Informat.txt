
ORIGINAL ARTICLE
An integrated scheme to improve pan-sharpening visual quality of satellite images

A.K. Helmy a, Gh.S. El-Tawel b,*

a National Authority of Remote Sensing and Space Sciences, Egypt
b CS Dept., Faculty of Computers and Informatics, Suez Canal University, Egypt

Received 17 October 2014; revised 26 January 2015; accepted 16 February 2015
Available online 6 March 2015

Abstract Pan-sharpening is the process to fuse a low-resolution multispectral (MS) image with a high-resolution panchromatic (Pan) image to construct high spatial and spectral resolution MS image. In this study, a novel pan-sharpening scheme based on integration of Curvelet Transform (CT) and Bi-dimensional Empirical Mode Decomposition (BEMD) is investigated.
First, input MS image decomposes into a sequence of intrinsic mode functions (IMFs) and resi- dues using BEMD to remove large amounts of redundancies and carries their spatial and frequency components of all pixels.
Second, decompose IMFs component and detail coefficient of Pan image using Curvelet Transform (CT), which are directional. Then, we use linear dependency to decide which detail coef- ficient of Pan should be injected into MS coefficient. Finally, we perform the inverse curvelet and inverse of BEMD to get high-resolution MS image.
In experiments with IKONOS, Quick Bird and GeoEye satellite data, we demonstrated that our scheme has good spectral quality and efficiency. Spectral and spatial quality metrics in terms of SAM, RASE, RMSE, CC, ERGAS and QNR are used in our experiments. We compared our scheme with the state-of-the-art pan-sharpening techniques and found that our new scheme improved quantitative and qualitative results.
© 2015 Production and hosting by Elsevier B.V. on behalf of Faculty of Computers and Information,
Cairo University. This is an open access article under the CC BY-NC-ND license (http://creativecommons.
org/licenses/by-nc-nd/4.0/).






* Corresponding author.
E-mail addresses: akhelmy@narss.sci.eg (A.K. Helmy), ghada_eltawel@ ci.suez.edu.eg (Gh.S. El-Tawel).
Peer review under responsibility of Faculty of Computers and Information, Cairo University.
Introduction

Main objective of pan-sharpening is containing spatial infor- mation from a high-resolution image, e.g. Pan or Synthetic Aperture Radar (SAR) image to a low-resolution image, e.g., MS image, while remaining spectral characteristics of MS image. In addition, registration should be done before pan- sharpening to avoid artifacts of the output image and, MS image should be resampled into the similar spatial reference


http://dx.doi.org/10.1016/j.eij.2015.02.003
1110-8665 © 2015 Production and hosting by Elsevier B.V. on behalf of Faculty of Computers and Information, Cairo University. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).



and grid like the Pan image, using nearest neighbor or cubic convolution techniques.
Over the last decades, a number of pan-sharpening algo- rithms have been developed that are either based on Multi- resolution Analysis (MRA) or Component Substitution (CS). There are also hybrid methods based on both MRA and CS.
CS-based methods such as intensity hue saturation (IHS) [1,2] have widely used due to the high sharpening capability. Since the intensity component of MS image substituted with the Pan image. In addition, other CS-based methods such as Principle component analysis (PCA) [3], Brovey transform and Gram-Schmidt (GS) [4] provide superior visual high- resolution multispectral images, but have a limitation of high- quality spectral information. Although a variety of modified methods [5,6] have proposed to recompense for such distor- tion, the limitation of CS-based methods does not fully overcome.
Recently, different methods based on MRA have demon- strated a greater capability of injecting high frequency compo- nents from PAN image into MS low-frequency sub-band with low spectral distortion. Between them, the commonly accepted approximation tools are ‘‘a´ trous’’ wavelet transform [7], gen- eralized Laplacian pyramid [8], in addition to the anisotropic frame-based transforms such as curvelet [9,10], nonsubsam- pled contourlet [11,12] and shearlet transform [13]. As the


spectral domains simultaneously; enhance spatial resolution and is based on MRA. So, this combination will give superior fusion results.
This paper is structured as follows: In Section 2, we briefly describe BEMD and curvelet transform. Section 3 describes the proposed pan-sharpening scheme in detail. Section 4 gives Quantitative Quality Assessment that used in evaluation. Section 5 presents different results and the comparisons with other methods. Finally, we draw the conclusion in Section 6.

Materials and methods

In this section, we describe BEMD and give a brief illustration of curvelet transform.

BEMD

EMD is a highly efficient approach that offers high frequency information and accurate timing of non-stationary and non- linear signal. The EMD permits to extract spatial frequency components of different spatial scales from finest to coarsest scales [18]. This signal can be decomposed using EMD into IMFs and a residue as follows:
Xn



not only does it have an improvement on minimizing the spec-
tral distortion, but it also gives a flexibility to describe how the HP coefficients of Pan are injected into the LP sub-band of MS. Initial mechanism recommended directly inserting the HP coefficients into the LP sub-band of MS. However, differ- ent techniques using the ARSIS concept [14,15] bend the coef- ficients based on specified algorithms [16]. Regularly, these algorithms feature in modified injection of information accord- ing to the local correlation between Pan and MS images, and do better than the directly injecting method.
Empirical mode decomposition (EMD) is considered as a new signal decomposition technique for analyzing nonlinear and non-stationary signals, which was suggested by Huang et al. [17,18]. EMD is a novel data representation that has bet- ter spatial and frequency characteristics than wavelet analysis. Input images are represented by EMD as IMFs taking their spatial and frequency components of each pixel. However, one of the main drawbacks of EMD is the mode-mixing prob- lem, which is defined as either a single IMF contains compo- nents of wide disparate scales, or a component of a similar scale residing in different IMFs.
Bi-dimensional EMD [19] is data adaptive decomposition and decomposes 2D signal into near orthogonal (not fully orthogonal) IMFs and taking their spatial and frequency com- ponents about each pixel.
Curvelet provides a multiscale and multidirectional decom- position of images. Since, it is sensitive to directional edges and able to represent the high-pass details of contours at dissimilar scales.
Contribution of the paper: proposed scheme is better than some other image pan-sharpening methods in two significant ways. Firstly, it uses the spatial similarity property of IMFs to remove large amounts of redundancies by estimating IMFs at high-resolution levels. Secondly, it uses the curvelet transform, which provides richer information in the spatial,
where f(x) be a signal, IMFi(x) is described as the ith IMF of
the original signal and r(x) is described as the residue.
BEMD is the 2D extension of EMD, which decomposed input image into several IMFs components and a residue com- ponent [19–21]. The first IMF includes the highest of local fre- quencies, the final IMF includes the lowest local frequencies of oscillation and the residue contains the trend of the data. IMF components of BEMD have the following characteristics:

Maximum and minimum points are the same as zero crossing points.
IMF components represent every frequency of local data; they correspond to high frequency, and low points are the frequency data; the residue component repre- sents development tendency of the original image. BEMD is a kind of completely self-adaptive decomposi- tion. The decomposition process can describe as:

J
I(m; n)=  Dj(m; n)+ Rj(m; n);  J ∈ N	(2)
j=1
where Dj is the jth 2D IMFs, Rj is the residue component after
J layers decomposition. IMF components are divided into two types, high frequency and low frequency as shown in Fig. 1.

Curvelet Transform (CT)

Curvelets presented in [22,10,23] as an expansion of wavelets and ridgelet transforms for multidimensional data and detect- ing curved edges effectively. Main difference between wavelet and curvelet is that curvelets are only directional. The curvelet transform gets good representation in images containing edges; therefore, we can use it to enhance image edges as in Figs. 2 and 3. It is summarized as:

Rf(a; b; h)= 
Z ∞ Z ∞
Wa;b;h(x1; x2)f(x1; x2)dx1dx2	(3)

where
—∞  —∞

W	(x ; x )= a—1 w((x cos H + x sin H — b)/a)
a;b;h  1  2	2	1	2
for each a > 0; b ∈ R and H[0; ∈ 2p)	(4)
Proposed pan-sharpening scheme






Figure 1	BEMD.


An input image is decomposed into three sub-bands (P1, P2, P3) using sub-band filtering.
Tilting is the process of dividing image into overlapping tiles. This process can advance the ability of the curvelet transform to handle curved edges.
The ridgelet transform obtained on every tile of the sub bands P2, P3. So, the edges of the image will be repre- sented professionally by the ridgelet transform since the edges are approximately similar to straight lines as to scale.

The ridgelet coefficients of an image f(x1, y1) are represent- ed by:

In this section, we will discuss the proposed scheme in detail. BEMD used as a self-adaptive tool to decrease the noise dis- tortion, improves computational time and carrying their spa- tial and frequency components about each pixel. Curvelet is suitable for image pan-sharpening, which is based on MRA. The major feature of CT is that it is responsive to directional edges and able to represent the high-pass details of contours at varies scales. Integrating curvelet with BEMD improves the visual quality of the output image and reduces the spectral and spatial distortions. The fusion rule can be described below. Fig. 4 shows block diagram of the proposed scheme, which consists of a number of essential stages as follows:

MS input image must co-register to the Pan image and resample to the pixel spacing of the Pan image by using bi-cubic interpolation.
Decompose MS image into a series of IMF components and a residue component by using BEMD. The BEMD completed when the residue is ideally i.e. does not con- tain any extrema points.



Figure 2	Curvelet transform.


original image	curvelet coefficients


50

100

150

200

250











50	100	150	200	250
200

400

600

800











200	400	600	800


Figure 3	Input image and the corresponding curvelet coefficients.

















































Figure 4	Block-diagram of proposed pan-sharpening scheme.


Decompose IMF components and Pan image into two level decomposition of curvelet transform to select the low frequency fusion coefficients; denote the decom-
M  N
D =
i=1 j=1
B2(m; n)— B(m; n)	(5)

posed coefficients as C1, C2,.. ., Cn.
Consider low frequency part of MS image as a low
The Gramian is defined as:
G(v ; v ; .. . ; v )= det(I*I);	I = (v ; v ; .. . ; v )	(6)

frequency part of final image.
1  2	n
1  2	n

Linear dependency used to decide which detail coefficient of Pan should be injected into the MS detail coefficient and can be performed based on Gramian. For input M · N image I Wronskian’s determinant is calculated as:
where B(m; n) is the (m; n) pixel and vi is an m-dimensional vector of all pixels located in the ith column of the image.
Linear dependency test is computed based on either Eq. (6) or (7). The higher value is the more prominent feature inside the window and its value can compare MS details and Pan



ones to determine, which input image has the stronger feature at the (m, n)th detail coefficient.
Consequently, the detail coefficients of Pan will be injected to the final image only if it is satisfied that Pan Value is greater than MS details value. Therefore, it will avoid the injection of noise and non-related details. The fusion rule, which is used in


where b and l represent the high spatial resolution and low spa- tial resolution images, l(i) represents mean radiance of spectral band and N represents no of bands.
Formula of RMSE:
rﬃﬃﬃﬃ1ﬃﬃﬃﬃﬃﬃﬃXﬃﬃﬃﬃﬃﬃﬃLﬃﬃﬃﬃﬃXﬃﬃﬃﬃﬃﬃﬃKﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ2ﬃﬃ



D (m; n)=  Dpan(m; n) if LinDPan(m; n) P LinDMS(m; n)
where F described as the high-resolution pan-sharpening

F
DMS
(m; n)  if LinD
Pan
(m; n) < LinDMS
(m; n)
(7)
image, MS is the original multispectral image, and L · K is the image size.
Formula of RASE:

where LinDMS(m; n) and LinDPan(m; n) are the value of linear
or (7), respectively. In addition, DMS(m; n), DPan(m; n) and dependency test which can be computed using either Eq. (6)
It measures average performance of image pan-sharpening into spectral bands, which is performed by:
100 rﬃﬃ1ﬃﬃﬃﬃXﬃﬃﬃﬃﬃﬃﬃMﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ

		


The finer coefficients (high frequency coefficients are then filtered by wiener filtering). Since, the Wiener filter is used to suppress the noise information in the high fre-
quency coefficients. If we take the high frequency coeffi- cients y0; y1; ... ; yj, ai is the shrinkage factor of the wiener filtered high frequency coefficients f^0; f^1; ... ; f^i are acquired:
where N represents mean radiance of M bands (Bi), RASE
should be as close to 0 as possible.
Formula of CC:
This index measures the spatial quality of the pan-sharpen- ing image, the higher correlation between the output pan- sharpening image and original image, the more accurate the estimation of the spectral values is, and the ideal value is unit. The equation of CC is given by:

f^i = aiyi	(8)
Perform an inverse curvelet transform and BEMD
(ri;j — s¯)(si;j — r¯)
qPﬃﬃﬃﬃﬃﬃﬃﬃ(ﬃﬃrﬃﬃiﬃ;ﬃjﬃﬃ—ﬃﬃﬃﬃﬃr¯ﬃﬃ)ﬃ2ﬃﬃPﬃﬃﬃﬃﬃﬃﬃﬃ(ﬃﬃsﬃﬃyﬃﬃﬃﬃﬃﬃ—ﬃﬃﬃﬃﬃs¯ﬃﬃ)ﬃﬃ2ﬃ
(12)

image. Finally, the Pan spatial detail image is integrated into the MS image bands.
Finally, we evaluate the proposed scheme using quanti- tative and qualitative measures.


Quantitative analysis
where r and s represent original Pan image and pan-sharpening
image, M · N are the size of images, r¯ and s¯ represent the mean values of r and s respectively.
Formula of SAM:
This index determines the spectral similarity between two spectral vectors as a spectral angle:
PM x y

cos b = 	i=1 i i	
x	y
(13)

quantitative quality of pan sharpening images. However, accurate quantitative assessment is difficult since a reference high-resolution MS image is not existing. Wald’s consistency characteristic [24] measures the pan-sharpening image degrad- ed to the resolution of the MS image, which should be closed to input MS image. The spectral metrics without reference attempts to measure this spectral. The PAN and MS images degraded in resolution such that the resulting pan-
where M represents number of bands, x = (x1; x2; ... ; xN) and y = (y1; y2; .. . ; yN are two vectors in the input MS image and result pan-sharpening image, respectively and SAM value is
performed as the average of all b values for every pixel.
Formula of QNR:
We use QNR Dsp spatial [27] metrics for quality assessment without reference and is defined as:
rﬃﬃﬃﬃﬃﬃXﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ

as the reference.
We use relative dimensionless global error synthesis
Dsp =	M
_
i=1|UIQI(Ni; P)— UIQI(Ni; P)|
_
(14)

(ERGAS) [25,26], Root Mean Square Error (RMSE) [25,26], Relative Average Spectral Error (RASE [25,26], Correlation Coefficient (CC) [25,26], Spectral Angle Mapper (SAM) [25,26], and Quality Not requiring a Reference (QNR) indexes metric.

Formula of ERGAS:

sﬃﬃﬃﬃﬃXﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ ﬃﬃﬃ2ﬃﬃ

 	
where N represents input MS band, P represents Pan image, N
is the pan-sharpened MS image, P represents the high-resolu- tion Pan image, UIQI indicates Universal Image Quality Index, and N represents number of MS bands.

Experimental results

We have given several descriptive examples to demonstrate the efficiency of our proposed scheme. The MS and Pan images must be registered and the MS image should be resampled to





Datasets

The satellite images used for performing experimental analysis are raw satellite Quick Bird, IKONOS and GeoEye datasets. These images include four bands of multispectral images, and a panchromatic image rendered in gray level. The Quick Bird dataset was taken over the Pyramid area of Egypt. The test images (Quick Bird, IKONOS and GeoEye) of size 1024 by 1024 at the resolution of 0.7 m are cut from the raw images. The four bands are B4 – near infrared, B3 – red, B2 – green and B1 – blue. Furthermore, for simplicity of working with the images and pansharpening algorithms, we have generated 20 MS (512 · 512) and the pan (1024 · 1024) images from
GeoEye, 10 MS (256 · 256) and the pan (1024 · 1024) images from the Quickbird datasets, and 10 MS (256 · 256) and the pan (1024 · 1024) images from IKONOS. The IKONOS satel- lite captures 1 m/pixel Pan image and 4 m/pixel MS image cov- ering NIR, red, green, and blue bands. The IKONOS images are from Cairo in Egypt. GeoEye images are from Hurghada in Egypt. The study area is composed of various features such as roads, buildings and trees.

Visual analysis

Visual analysis is required to check if the objective of pan- sharpening has been met. The general visual quality measures are the global image quality. Pan-sharpening can increase the spatial and spectral resolution of images. The output results show high correlation of proposed scheme.
Fig. 5 shows the original Quick Bird images and the Pan- sharpening results. Spatially degraded Pan and MS images from the original datasets are used, and the output results compared to the original data. Some subsets of the original (not degraded) datasets extracted to compare the visual effect of different pan-sharpening algorithms. Therefore, there is no reference high-resolution MS image in the visual or subjective comparisons.

Quantitative evaluation

To evaluate the spatial quality of the pan-sharpening image, we have used (CC) between the pan and pan-sharpened images. Here, we have compared the spectral qualities (ERGAS, RASE, and SAM) indexes of dissimilar pan-sharp- ened results with respect to their spatial quality (CC) to the pan index.
In Fig. 6, we have presented the qualitative evaluation of the zoomed area of proposed output image, which performs on degraded GeoEye input images and have compared it with Brovey output image, UNB output image, PCA output image. We can see that the result of proposed scheme is better than other methods. UNB [28] has a color distortion. The wavelet result shows clear spatial detail however; its color intensity is weak.
In addition, Fig. 7 shows the visual results of the adaptive IHS and Brovey methods are sharp enough, but the colors changed compared to the low-resolution MS images. The result of the PCA method is not clear, and the colors are



 
(a) Input MS Image	(b) Input Pan Image

(c) Proposed output Image

Figure 5	(a) Input GeoEye MS image, (b) input Pan image and (c) proposed output GeoEye image.


 
(a) Proposed output image	(b) Brovey output image

(c) UNB output image	(d) PCA output image

Figure 6 Comparison of different pan-sharpening techniques for GeoEye image, zoomed area as true-color combination of the Blue, Green, and Red bands are presented as (a) Pan image at 1 m. (b) 4-m MS image interpolated at 1 m. (a) Proposed output image. (b) Brovey output image. (c) UNB output image. (d) PCA output image.


changed. With the GS method, the colors are preserved, but the spatial details from the Pan image did not appropriately transfer to the pan-sharpening image. The curvelet method results are good in spatial quality in the pan-sharpening image, and detail information from the pan image appropriately saved, while the spectral from the low-resolution MS image has changed to some extent. The result of the proposed scheme visually shows good spatial quality and the colors well pre- served from the low-resolution MS image, since combination of curvelet that enhances spatial resolution and spatial similar- ity property of IMFs to remove large amounts of redundancies helps to get a good spatial quality results.
Moreover, Fig. 8 shows the different zoomed area for the Quick Bird image of different methods as proposed scheme, UNB, Wavelet and GS. We observe that the zoomed area of proposed scheme is better than the other methods.
Furthermore, Fig. 9 shows the correlation coefficients between Pan input image and the corresponding output pan- sharpening image for the Quick-Bird image. The value of CC of proposed scheme is better than other several known meth- ods. In addition, we found that the Pan image resolution is
0.7 m, MS image is 2.8 m, and the output image result is 0.7 m. Moreover, Fig. 10 shows the spatial QNR index measure between the MS input image and pan-sharpening of different output image. The proposed method gives the best results for all metrics except the QNR spatial metric, where surpris-
ingly, wavelet gives slightly better result.
In addition, the analysis results have demonstrated that the proposed scheme does considerably decrease the color
distortion compared to the traditional, non-adaptive pan- sharpening methods. In other words, the results have proved that the concept of the proposed scheme is promising.

Comparisons with other pan-sharpening methods

We have compared the scheme with different state-of-the-art pan-sharpening methods. We have used GS spectral sharpen- ing [24], adaptive IHS, Brovey, PCA method and curvelet as pan-sharpening methods for validation. The cause for this choice is that, between the most extensively used CS methods that considered producing the finest results, and adaptive IHS is the fastest.
Table 1 shows the results of the spectral quality measure (RMSE, RGAS, RASE, SAM) for different pan-sharpening methods (adaptive IHS, Brovey, GS spectral sharpening, Curvelet, PCA and proposed scheme) and we observe the following:

The proposed scheme outperforms the IHS technique in spatial and spectral qualities. Since the CC index of the IHS method is acceptable, while the corresponding spec- tral is very weak.
Our scheme gives better results than the Brovey algo- rithm, since the corresponding ERGAS, RASE values for it are very weak and the Brovey method yields small SAM values.


 
Input MS Image	(b) Input Pan Image

(c) Proposed output image	(d) UNB output image

(e) Wavelet output image	(f) GS output image

PCA output image	(h) Brovey output image

Modified-IHS output image
Figure 7  Comparison of different pan-sharpening techniques for Quick Bird image as true-color combination of the Blue, Green, and Red bands. The scene presented is of size 512 · 512 pixels, at a 1-m spatial scale. (a) MS input image, (b) Pan input image, (c) proposed output image, (d) UNB output image, (e) Wavelet output image, (f) GS output image, (g) PCA output image, (h) Brovey output image and
(i) modified IHS.



Proposed output

UNB

Wavelet

GS
Figure 8	Zoomed area of Fig. 7 the Quick Bird results of proposed scheme, UNB, Wavelet and GS methods.



Figure 9	Correlation coefficients between the original Pan and output pan-sharpening images.







Computation time




Figure 10	Spatial metric QNR index between the MS input image and pan-sharpening of different output image.


(iii) Our scheme provides better results than the PCA algorithm. While the CC index of our method has a little difference with that of the PCA method, for other index- es our scheme produces a higher gap with those of the PCA.
Computation time of our scheme is presented for MS size 1024 · 1024, Pan image size 2048 · 2048 in Table 2. The soft- ware was coded in MATLAB Version R2007b and run on an Intel Core 2 Duo 3.0 GHz CPU with 3 Gigabyte RAM under the Window Operating System. We see that the proposed pan- sharpening scheme takes times less than other methods.

Conclusion

In this paper, we presented a new scheme of BEMD and CT  for  pan-sharpening  low-resolution  MS  Image  and






high-resolution Pan Image of the same scene in order to obtain high-resolution MS output image. BEMD is used for decom- posing low-resolution MS into IMF and the residue compo- nents, while CT is used for decomposing IMF components, which one has the better spatial and spectral responses at a given pixel position and Pan Image into coarse coefficients and details coefficients. Then, the details coefficients of Pan Image and IMF components are fused by linear dependency rule to obtain high-resolution MS output image.
The proposed scheme has compared with other methods both in synthetic and real images and its performance has assessed both numerically and visually. Experiments achieved on very-high-resolution Quick Bird, IKONOS and GeoEye images have demonstrated that the proposed scheme is quan- titatively comparable with state-of-the art pan-sharpening techniques. Depending on the datasets, conversely, the perfor- mance ranking of pan-sharpening methods may be different. In particular, on the Quick Bird dataset our scheme outper- forms the Gram-Schmidt spectral sharpening method that is applied in the software package ENVI and other methods as PCA, adaptive-IHS, Curvelet and Brovey that is saleable Pan-sharpened products are achieved.

References

Masoudi Rasoul, Kabiri Peyman. New intensity-hue-saturation pan-sharpening method based on texture analysis and genetic algorithm-adaption. J Appl Remote Sens 2014;8(1):083640.
Carper WJ, Lillesand TM, Kiefer RW. The use of intensity-hue- saturation transformations for merging spot panchromatic and multispectral image data. Photogramm Eng Remote Sens 1990;56:459–67.
Chavez PS, Sides JSC, Anderson JA. Comparison of three different methods to merge multiresolution and multispectral data landsat TM and SPOT panchromatic. Photogramm Eng Remote Sens 1991;57:295–303.
Brower B, Laben C. Process for enhancing the spatial resolution of multispectral imagery using pan-sharpening. US Patent 6011875; 2000.
Rahmani S, Strait M, Merkurjev D, Moeller M, Wittman T. An adaptive IHS pan-sharpening method. IEEE Trans Geosci Remote Sens Lett 2010;7:746–50.
Aiazzi B, Baronti S, Lotti F, Selva M. A comparison between global and context-adaptive pansharpening of multispectral images. IEEE Trans Geosci Remote Sens Lett 2009;6:302–6.
Otazu X, Gonzalez-Audicana M, Fors O, Nunez J. Introduction of sensor spectral response into image fusion methods. Application to wavelet-based methods. IEEE Trans Geosci Remote Sens 2005;43:2376–85.
Aiazzi B, Alparone L, Baronti S, Garzelli A. Context-driven fusion of high spatial and spectral resolution images based on oversampled multi-resolution analysis. IEEE Trans Geosci Remote Sens 2002;40:2300–12.
Choi M, Kim RY, Nam M-R, Kim HO. Fusion of multispectral and panchromatic satellite images using the curvelet transform. IEEE Trans Geosci Remote Sens Lett 2005;2:136–40.
Nencini F, Garzelli A, Baronti S, Alparone L. Remote sensing image fusion using the curvelet transform. Inf Fusion 2007;8:143–56.
Shah VP, Younan NH, King RL. An efficient pan-sharpening method via a combined adaptive PCA approach and contourlets. IEEE Trans Geosci Remote Sens 2008;46:1323–35.
Mahyari AG, Yazdi M. Panchromatic and multispectral image fusion based on maximization of both spectral and spatial similarities. IEEE Trans Geosci Remote Sens 2011;49:1976–85.
Shi Cheng, Liu Fang, Li Ling-Ling, Hao Hong-Xia. Pan- sharpening algorithm to remove thin cloud via mask dodging and non-sampled shift invariant shearlet transform. J Appl Remote Sens 2014;8(1).
Massip P, Blanc P, Wald L. A method to better account for modulation transfer functions in ARSIS-based pansharpening methods. IEEE Geosci Remote Sens 2012;50(3):800–8.
Thomas C, Ranchin T, Wald L, Chanussot J. Synthesis of multispectral images to high spatial resolution: a critical review of fusion methods based on remote sensing physics. IEEE Trans Geosci Remote Sens 2008;46:1301–12.
Garzelli A, Nencini F. Interband structure modeling for pan- sharpening of very high-resolution multispectral images. Inf Fusion 2005;6:213–24.
Xiaohong X, Jiping N. Review of EMD based image fusion. In: Int conf intelligence and information engineering. Wuhan: IEEE; 2011. p. 282–5.
Altaf B et al. Rotation invariant complex empirical mode decomposition. In: IEEE int conf acoustics, speech and signal processing. Hawaii: IEEE; 2007. p. 1009–12.
Zhang K, Liu Y, Chen J. Fusion of the infrared and color visible images using bidimensional EMD. In: IEE int conf multimedia and information technology. Three Gorges: IEEE; 2009. p. 257– 60.
Damerval C, Meignen S, Perrier V. A fast algorithm for bidimensional EMD. IEEE Signal Process Lett 2005;12(10):701–4.
Sharma JB, Sharma KK, Sahula Vineet. Digital image dual watermarking using self-fractional Fourier functions, bivariate empirical mode decomposition and error correcting code. J Opt 2013;42:214–27 (March).
Choi M, Kim RY, Nam M-R, Kim HO. Fusion of multispectral and panchromatic satellite images using the curvelet transform. IEEE Geosci Remote Sens Lett 2005;2(2):136–40.
Palsson F, Sveinsson JR, Benediktsson JA, Aanaes H. Classification of pansharpened urban satellite images. IEEE J Sel Top Appl Earth Observ Remote Sens 2012;5(1):281–97.
Wald L. Data fusion: definitions and architectures: fusion of images of different spatial resolutions. Les Presses de l’´Ecole des Mines; 2002.
Laben CA, Brower BV. Process for enhancing the spatial resolution of multispectral imagery using pan-sharpening. U.S. Patent 6 011 875; January 4, 2000.
Makarau Aliaksei, Palubinskas Gintautas, Reinartz Peter. Analysis and selection of pansharpening assessment measures. J Appl Remote Sens 2012;6(1):083640.
Alparone L, Aiazzi B, Baronti S, Garzelli A, Nencini F, Selva M. Multispectral and panchromatic data fusion assessment without reference. Photogramm Eng Remote Sens 2008;74(2):193–200.
PCI geomatica pan-sharpening technical specification. PCI geomatics. Richmond Hill, ON, Canada; January 2007.
