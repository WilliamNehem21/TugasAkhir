	Electronic Notes in Theoretical Computer Science 141 (2005) 199–220	
www.elsevier.com/locate/entcs

Modelling Component Behaviour with Concurrent Automata
Sotiris Moschoyiannis, Michael W. Shields and Paul J. Krause
Department of Computing, University of Surrey Guildford, Surrey, GU2 7XH, England

Abstract
The effective (re)use of components requires languages for the precise description of observable behaviour, along with methods for checking the compatibility of component interfaces in a design. This is even more challenging in the presence of concurrency. In previous work we have considered a set-based model of components and their composition, in a concurrent setting. In this paper, we present a class of automata, called Σ-automata, in which true-concurrency is treated as an explicit structural property. We show how an automaton can be derived from a component and that every such automaton generates back a component. Apart from determining a usage protocol for the underlying component, this extension to our model provides useful insights on component composition.
Keywords: component behaviour, concurrency, automata


Introduction
Complex high-integrity software systems, such as those described in [9], are typically divided into interconnected components. However, experience has shown (e.g. in the consumer electronics industry [28]) that the resulting soft- ware may not function as required because of subtle inconsistencies that arise during the complex call interplay between component interfaces. For exam- ple, one component may require certain signals to arrive consecutively while the other is generating them concurrently. As a result, systems may exhibit

1 Email: s.moschoyiannis@eim.surrey.ac.uk




1571-0661 © 2005 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2005.04.035

pathological behaviour. That is, behaviour not intended but resulting from such inconsistencies.
We study discrete models of interactive systems and, naturally, our inter- est lies with the observable behaviour of components rather than their internal structure. In this context, it proves crucial to describe behaviours as experi- enced on interfaces of the component. We present an automata-based language for describing such behaviour of a component. This allows to capture assump- tions about the order in which the operations of a component are called, and the order in which the component (in response) calls external operations. In a certain important sense, we are inherently also modelling the environment of a component and when it comes to composition, two components can be put together if there is some environment that satisfies all assumptions of both. This is in line with the optimistic view prescribed in [6].
While using an automata-based formalism for modelling behaviour is not new, the proposed automata are interesting in that they make it possible to express concurrency explicitly. It may be argued that there are phenomena in a component setting such as race conditions which may only be understood as an unfortunate interaction between concurrency and nondeterminism. Such phenomena are of interest in areas such as communication and consumer elec- tonics products. It may also be argued that interleaving approaches to con- currency are inadequate for proper treatment of properties such as fairness [14].
Additionally, in previous work [19,18] we have been concerned with the development of a formal model of components which allows for reasoning about generic properties of components and their composition. In this paper, we are concerned with deriving from that model a class of automata which generates the objects of the model and only them. The corresponding automata can be seen as an extension that brings the model a step closer to automation and eventually tool support.
The paper is structured as follows. In Section 2 we give an account of our model of components and outline component composition. In Section 3, we introduce Σ-automata for describing component behaviour. We start with a type of abstract machine and then consider concurrency as a further structural property which leads to the definition of Σ-automata. We also outline preliminary work on a formal notion of composition in terms of Σ- automata. The paper finishes with some concluding remarks and ideas for future work.

A model of components
In this section we briefly outline the model of components we are considering. The presentation has been restricted to the key concepts behind the model. Further details and a proper presentation can be found in [19,18].
In the familiar ’design by contract’ paradigm [15], a component provides services to other components and, possibly, requires services (pre-condition) from other components in order to deliver those promised (post-condition). The offered services are made available via a set of provides interfaces while the reciprocal obligations are to be satisfied via a set of requires interfaces.
In light of the contractual use of components, the static semantics of a component is captured in terms of two disjoint sets of interfaces. Those the component requires and those that the component provides. Furthermore, the static semantics specifies for each interface the operations it supports. Let I be the set of names for interfaces and Op be the set of operations associated with interfaces in I.
Definition 2.1 A component signature is a tuple Σ = (PΣ, RΣ, βΣ) where
PΣ ⊆ I is a set of provides interfaces
RΣ ⊆ I is a set of requires interfaces
βΣ : PΣ ∪ RΣ → ℘(Op); hence, βΣ(i) returns the set of operations associated with interface i
and we require that PΣ ∩ RΣ = ∅. Define IΣ = PΣ ∪ RΣ.
The dynamic semantics of a component consists of a set of possible be- haviours. Each behaviour associates a sequence of operations with every in- terface. We define VΣ to be the set of all functions v : IΣ → Op∗ such that for each i ∈ IΣ, we have v(i) ∈ βΣ(i)∗. We shall refer to elements of VΣ as component vectors.
By βΣ(i)∗ we denote the set of finite sequences over βΣ(i). Mathemati- cally, VΣ is the cartesian product of the sets βΣ(i)∗. Component vectors are essentially n-tuples of sequences where each coordinate corresponds to an in- terface of the component (hence n is the number of component interfaces) and contains a finite sequence of events (e.g. operation calls) that may occur on that interface. The idea is that behaviour of the component as a whole can be described by assigning such a sequence to each of its interfaces.
We may now define a component by restricting to an appropriate subset of VΣ comprising component vectors that describe intended behaviour only.
Definition 2.2 A component c is a pair (Σ,V ), where
Σ is the signature of c

V ⊆ VΣ (and V /= ∅) is the set of behaviours of c.
Thus, the static structure of a component is described by a signature Σ while its behaviour is described by a component language V , which is essen- tially a ’language’ of vectors over Σ.

Properties of a component language
In this section we introduce the basic operations which will allow us to ma- nipulate a component language and reason about component behaviour.
We have seen that component vectors are essentially tuples of sequences. We may thus define operations on components vectors in terms of well known operations on sequences. For u, v  ∈ VΣ, we define,
u.v to be the unique vector w such that w(i) = u(i).v(i), for each i ∈ IΣ
(concatenation)
u ≤ v iff u(i) ≤ v(i), for each i ∈ IΣ (preﬁx ordering)
It is easy to see that VΣ is a monoid with binary operation ’.’ and identity ΛΣ, where ΛΣ is the unique vector with ΛΣ(i)= Λ, for each i ∈ IΣ, and Λ denotes the empty sequence. Furthermore, VΣ is a partially ordered set (poset) with partial order ’≤’ and bottom element ΛΣ.
Now based on the order-theoretic properties of VΣ we may further define,
for u, v  ∈ VΣ,
u H v to be the vector w which satisfies w(i)= min(u(i), v(i)), for each i
u H v (if it exists) to be the vector w which satisfies w(i)= max(u(i), v(i)) Note that u H v is defined only when max(u(i), v(i)) exists, for each i.
In terms of partial orders, these operations essentially give the greatest lower
bound and the least upper bound, respectively, of u, v  ∈ VΣ, in the usual sense of lattices and domain theory [5,29]. To anticipate, greatest lower and least upper bounds have a significant role to play in defining the normality property (cf Definition 2.5) which allows us to restrict to a class of components, the so-called well-behaved components.
We next consider a right-cancellation operator ’/’. Intuitively, if u is an initial part of behaviour v so that u ≤ v, then v/u is the ’continuation’ of u that extends it to v. Put formally, if u ≤ v, then we define v/u to be the unique element z ∈ VΣ such that u.z = v
The right-cancellation operator is particularly useful for defining the tran- sition structure of the corresponding automata since it determines what events occur in going from a behaviour represented by u to a behaviour represented by v. We will have more to say about this when we have also defined well-

behaved components.
Well-behaved components
In our approach towards modelling component behaviour, we restrict to a par- ticular class of components. These are components whose language is discrete and locally left-closed. These properties are defined as follows (see also [19]).
Definition 2.3 Let c = (Σ,V ) be a component, then V is discrete iff, Λ ∈ V and whenever u, v, w  ∈ V such that u, v  ≤ w, then (i) u H v ∈ V and (ii) u H v ∈ V
Note that u H v ∈ V is understood as asserting that u H u is defined.
Definition 2.4 Let c = (Σ,V ) be a component, i ∈ IΣ and x ∈ βΣ(i)∗. Then,
V is locally left-closed iff, whenever v ∈ V such that Λ < x < v(i), then there exists u ∈ V such that u ≤ v and u(i)= x.
Discreteness captures the fact that a system’s computations always have a starting point and imposes a finiteness constraint in the sense that it excludes infinite ascending or descending chains of events with respect to time order- ing. In order to obtain a precise description of discrete behaviour, we further require that every occurrence of an event (e.g. operation call) is ’recorded’ in the component language V . This motivates the local left-closure property.
Definition 2.5 Let c = (Σ,V ) be a component. The set of behaviours V is normal iff it is locally left-closed and discrete. Also, c is well-behaved if V is normal.
Well-behavedness of the corresponding component reflects the fact that the guarantees that accrue from discreteness and local left-closure are ’embedded’ in its behaviour.
A well-behaved component can be associated with an order-theoretic struc- ture called behavioural presentation [24]. This non-interleaving behavioural model mildly generalises event structures [20] by considering the time order- ing of events to be a pre-order rather than a partial order, thereby allowing the representation of simultaneity as well as concurrency.
Apart from the theoretical motivation, discreteness and local left-closure can have practical benefits for component-based design, as shown in [19]. The idea is that in checking a component language against these properties it is possible to identify missing behaviours - either undesirable or, simply, un- thought in design.
In a normal component language, and based on consequences of local left- closure in particular, we may define an ordering among component vectors in

which one is ’immediately beneath’ the other, allowing no other vector in V
to exist in between them.
Definition 2.6 Let c = (Σ,V ) be a component and u, v  ∈ V . Then, v covers u in V , and we write u aV v iff (i) u ≤ v and u /= v and (ii) if z ∈ V such that u ≤ z ≤ v, then z = u ∨ z = v
The normality property also has as a consequence that component vectors in V decompose into products of vectors, each of which has at most one operation call per coordinate. Mathematically, such vectors comprise the set EΣ = {e ∈ VΣ \ {ΛΣ} : i ∈ IΣ ⇒ |e(i)| ≤ 1} where |x| denotes the length of
sequence x. We also define E⊥ = EΣ ∪ {Λ }. Thus, the set EΣ consists of
Σ	Σ
’column vectors’, each of whose coordinates is either the empty sequence or
a single action. Intuitively, e ∈ EΣ represents a simultaneity class of events; precisely those events e(i) with e(i) > Λ. These correspond to simultaneity classes of event occurrences in the corresponding behavioural presentation.
The relation ’a’ determines immediate predecessors / successors in a com- ponent language and combined with the corresponding column vectors that extend a predecessor to its immediate successor, we may talk about immediate causality in the sense of [13] where labelled prime event structures are used to interpret interactions between instances appearing in a sequence diagram. The following result relates ’a’ with the right-cancellation operator.
Proposition 2.7 Let V ⊆ VΣ be normal and let u, v  ∈ V . If u a v, then
v/u ∈ EΣ.
To anticipate further, this allows us to define a transition structure on
V when it comes to associating well-behaved components with automata in Section 3.
Example 2.8 Consider the example component of Fig. 1 which is expected to operate as follows (perhaps in the context of a given scenario):
the component receives calls to operation c on interface p1 (from other components or the environment)
once an operation call c is received, the component responds by making a call to operation d on each of the interfaces r1 and r2 (implementation of these interfces is provided by other components)
the component then proceeds to make an operation call t on interface r3
and is then ready to receive a new c on p1
The signature Σex of the component is given by Σex = (PΣex , RΣex , βΣex ) where PΣex  = {p1}, RΣex  = {r1, r2, r3} and βΣex (p1) = {c}, βΣex (r1) =
{d} = βΣex (r2) and βΣex (r3) = {t}. We may check that PΣex ∩ RΣex  = ∅







Fig. 1.
and PΣex ∪ RΣex = IΣex .
We may now obtain a set of behaviours that indicates what would be de- sirable behaviour of the ex component with respect to the informal description of its functionality given above. Hence, we consider vectors over the signa- ture Σex and if we write (x, y, z, w) for v(p1) = x, v(r1) = y, v(r2) = z and v(r3)= w such description of behaviour would be interpreted into the follow- ing component language
Vex = {(Λ, Λ, Λ, Λ), (c, Λ, Λ, Λ), (c, d, Λ, Λ), (c, Λ, d, Λ), (c, d, d, Λ), (c, d, d, t)}
Each component vector is to be understood as a snapshot indicating which events have already occurred, and on which interface.
Note that cex = (Σex, Vex) is a component, by construction. It is worth pointing out here that the set Vex would normally be obtained by a (partial) description of behaviour given by a component developer, perhaps even in the form of a sequence diagram describing the interactions of the component with regard to the fragment of behaviour we are considering. For instance, in [17] we describe the use of LSCs [4] (restricted to basic features) as a starting point for a version of our component model. Further considerations on obtaining the component language are however beyond the scope of the present paper. The component of our example is well-behaved. We do not check against normality here due to space limitations. It is relatively straightforward to check that this is indeed the case by drawing the Hasse diagram for the order
structure of Vex.
With regard to Definition 2.6 of ’a’, we have
(Λ, Λ, Λ, Λ) a (c, Λ, Λ, Λ) and (c, Λ, Λ, Λ) a (c, d, Λ, Λ)
(c, Λ, Λ, Λ) a (c, Λ, d, Λ) and (c, d, Λ, Λ) a (c, d, d, Λ)
(c, Λ, d, Λ) a (c, d, d, Λ) and (c, d, d, Λ) a (c, d, d, t)
The set of column vectors (events) associated with the component (wrt the fragment of behaviour considered in our example) is
e1 = (c, Λ, Λ, Λ), e2 = (Λ, d, Λ, Λ), e3 = (Λ, Λ, d, Λ), e4 = (Λ, Λ, Λ, t)
and thus, EΣex = {e1, e2, e3, e4}. The example is continued in Section 3.	 

Component Composition
Insofar we have been concerned with a single component. In this section, we briefly outline composition within our framework. Full details can be found

in [18]. The key idea behind composition is the following. If component c1 provides interface i and component c2 requires interface i, then a behaviour of c1 and a behaviour of c2 can be composed if their restrictions to interface i are the same. From the composition of those behaviours, the sequence of operation calls corresponding to i is removed.
Composition takes place on complementary interfaces; that is, interfaces required by one component and provided by the other, in the spirit of comple- mentary labels in CCS [16] or CSP [11]. We assume disjoint sets of provided and required interfaces for each of the components. As a result, a condition is required on the component signatures. We define Σ1, Σ2 to be consistent, and write Σ1 ↓ Σ2 iff
PΣ1 ∩ PΣ2 = ∅
RΣ1 ∩ RΣ2 = ∅
∀i ∈ IΣ1 ∩ IΣ2 : βΣ1 (i)= βΣ2 (i)
Note that consistency among component signatures implies that complemen- tary interfaces are those that belong to the set
IΣ1 ∩ IΣ2 = (PΣ1 ∩ RΣ2 ) ∪ (RΣ1 ∩ PΣ2 )
The signature of the composite is formed from the signatures of the in- dividual components by eliminating all complementary interfaces. In effect, the composite signature internalises all shared interfaces. Thus, we define Σ1 ⊕ Σ2 =Σ where
PΣ = (PΣ1 ∪ PΣ2 )\(RΣ1 ∪ RΣ2 )
RΣ = (RΣ1 ∪ RΣ2 )\(PΣ1 ∪ PΣ2 )
βΣ(i)= βΣ (i) wherever i ∈ IΣ ,k = 1, 2
Having defined the signature of the composite we now proceed to define its component language, in a fashion similar to the treatment of a single component. First, we describe how component vectors are composed.

Definition 2.9 Let c1 = (Σ1, VΣ1 ) and c2 = (Σ2, VΣ2) be components. The vectors u1 ∈ VΣ1 and u2 ∈ VΣ2 are consistent, and we write u1 ↓ u2, if
u1[IΣ ∩IΣ = u2[IΣ ∩IΣ
where f [X denotes the restriction of function f to the set X, in which case we define,
u1 ⊕ u2 = (u1 ∪ u2)[IΣ1 ΔIΣ2

where IΣ1 ΔIΣ2 = (IΣ1 \ IΣ2 ) ∪ (IΣ2 \ IΣ1 ) and u1 ∪ u2 : IΣ1 ΔIΣ2 satisfies


(u1
∪ u )(i)= ⎧⎨ u1(i)	,	i ∈ IΣ1


which is well defined if u1 ↓ u2.
⎩ u2(i)	,	i ∈ IΣ2

We may now give a formal definition of composition of components.
Definition 2.10 Let ck = (Σk, VΣk ), for each k, be components. Define their composition c1 ⊕ c2 = (Σ,V ) where,
Σ= Σ1 ⊕ Σ2
V = VΣ1 ⊕ VΣ2 where
VΣ1 ⊕ VΣ2 = {v ∈ VΣ|∃u1 ∈ VΣ1 , ∃u2 ∈ VΣ2 : u1 ↓ u2 ∧ v = u1 ⊕ u2}
Finally, we will need some notation for the projection of vectors of the composite onto vectors of its constituent components.	For v ∈ VΣ1 ⊕ VΣ2 ,

with Σ1 ↓ Σ2, we define v[k] = v[IΣ
, where k = 1, 2. This construction is

reminiscent of the projections used to give the trace semantics of parallel
composition in COSY [12] and CSP [11].

Automata for modelling component behaviour
In this section we define a class of automata, the so-called Σ-automata, for modelling the observable behaviour of components. Full details, together with the complete proofs, can be found in [26]. The proposed automata can be seen as an elaboration of asynchronous transition systems [23,2] and a specialisation of hybrid transition systems [25].
In a normal component language V , a vector z extends a vector u to a vector v if v = u.z and there is no other vector in V that lies strictly between u and v. The latter requirement can be expressed by saying that v covers u, in the sense of Definition 2.6. The continuation z which extends u to v is defined using the right-cancellation operator, i.e. v/u = z. In a normal component language such continuations turn out to be elements of EΣ (by Proposition 2.7). This observation gives a transition relation which leads to the definition of a type of transition systems.
Definition 3.1 Let Σ be a component signature. We define a Σ-machine to be a pair M = (Q, >) where
Q is a set of states
>⊆ Q × EΣ × Q is the transition relation, and we write q >e q' for (q, e, q') ∈>

which satisfies:
q >e q1 ∧ q >e' q2 ∧ e ≤ e' ⇒ e = e' ∧ q1 = q2
q >e q' ∧ q >e' q' ⇒ e = e'
We also define a rooted Σ-machine to be a pair M ∗ = (M, q) where M = (Q, >) is a Σ-machine and q ∈ Q.
We will write q >e to denote that there exists q' ∈ Q such that q >e q'.
Note that condition (i) includes the case that e = e' in which case the condition can be rewritten as q >e q1 ∧ q >e q2 ⇒ q1 = q2. This condi- tion guarantees unambiguity and also relates to point (iii) of the subsequent definition of Σ-automata (cf Definition 3.6).
Rooted Σ-machines determine languages of vectors in the usual way.
Definition 3.2 Let M = (Q, >) be a Σ-machine, q ∈ Q. Define q →u q' if
q = q' and u = Λ 
u = v.e, e  ∈ EΣ, such that q →v qˆ >e q', some qˆ ∈ Q
We also define V (M, q)= {u ∈ VΣ : ∃q' ∈ Q, q →u q'}.
This gives the execution vectors of a Σ-machine. Effectively, these are component vectors formed by repeatedly concatenating column vectors e, and can be understood as describing sequences of individual transitions.
Point (i) of Definition 3.2 refers to internal transitions which, perhaps not surprisingly, become significant when it comes to composition. Point (ii) of the definition says that whenever there is a component vector that is a concatenation of another vector, v, and a column vector, then there is a state which takes you to the target state via the simple transition of the column vector, and that state is reachable from the source state through transition(s) implied by vector v. It can be seen that this may involve decomposition of a component vector into a series of concatenations with column vectors from EΣ, as shown in [27]. This is further exploited in showing that the vector language of the corresponding Σ-automaton is locally left-closed, as part of establishing that a Σ-automaton generates a normal component language.
Before introducing Σ-automata we discuss how a Σ-machine can be derived from a well-behaved component. This is done by taking component vectors in V as states and defining a transition relation in a way that reflects the observation that behaviours may be seen to be built up from the empty vector by repeatedly concatenating column vectors to it. In fact, this takes up on the ideas presented prior to defining Σ-machines.
Definition 3.3 Let c = (Σ,V ) be a component with V normal. Define Mc =



(V, >V ) where

u >e

v ⇔ u a v ∧ v/u = e

We also define M ∗ = (Mc, Λ ).
Note that v/u ∈ EΣ, whenever u a v, by Proposition 2.7 so that the defini- tion makes sense.
This construction gives a Σ-machine Mc. Moreover, it can be shown that the vector language generated by Mc from intial state ΛΣ determines the same component using the execution vectors of Definition 3.2. In our notation, this is expressed as V (M ∗)= V .
We are now set to consider true-concurrency in a component language and the corresponding Σ-machine, and this while still dealing with normal com- ponent languages. In order to express concurrency explicitly in this context, where the same events may sometimes be concurrent and sometimes not, we define an independence relation on component vectors (cf Definition 3.4) and determine its relationship to the transition structure of Σ-machines (cf Defi- nition 3.5 ). This results in additional constraints on Σ-machines, which lead to the definition of Σ-automata.
We start by considering an independence relation on component vectors.
Definition 3.4 Let u, v  be component vectors in VΣ. u and v are independent, and we write u ind v, iff
∀i ∈ IΣ : u(i) > Λ ⇒ v(i)= Λ
The definition is motivated by the fact that behaviours u and v may take place independently so long as they engage different interfaces of the compo- nent. It might be worth pointing out that independence alone is not enough to guarantee concurrency. This should become clear by examining the following definition.
Definition 3.5 Let M  = (Q, >) be a Σ-machine.  We define a relation
IM ⊆ Q × EΣ × EΣ, and we write e1 IM e2 for (q, e1, e2) ∈ IM , by

e  IM e
⇐⇒ e ind e ∧ (∃q ,q , q' ∈ Q : q >e1 q ∧ q >e2 q
	
>e1 q')


1  q	2
1	2	1	2	1	2

We shall, as usual, drop the superscript when it is clear from context.
q1



e 1 ind e 2
e 1
q	q’
e 2

q2
Fig. 2. Concurrent transitions e1 , e2

Thus, the minimal requirement for concurrency at state q is that both independent outgoing transitions are enabled and both occur between states q and q' in no particular order. This is pictured in Figure 2.
The relation Iq defines local concurrency, in the sense that column vectors
e1 and e2 are concurrent at state q of the machine.
We are now set to refine Σ-machines to Σ-automata, taking into account both relations.
Definition 3.6 Let Σ be a signature.  A Σ-automaton M is a Σ-machine
M = (Q, >) satisfying
If e1 IM e and q >e1 q1 >e2 qˆ, then q >e2 q2 >e1 qˆ, some q2 ∈ Q
If q1 >e1 qˆ and q2 >e2 qˆ and q1 /= q2, then e1 ind e2 and there exists q ∈ Q
such that q >e2 q1 and q >e1 q2
If u, v  ∈ V	and q →u.v q'', then ∃q' ∈ Q such that q →u q' ⇔ q' →v q''
If e1, e2 ∈ EΣ s.t. q >e1 ,e2 and x ∈ V (M, q) with e1, e2 ≤ x, then e IM e2
We also define a rooted Σ-automaton to be a rooted Σ-machine M ∗ = (M, q) where M is a Σ-automaton.
Note that by Definition 3.5 and (i) of Definition 3.6 we have that Iq is symmetric and irreflexive. Symmetricity reflects the fact that concurrency is always mutual while irreflexivity prohibits considering an event as being concurrent with itself.
Condition (i) is characteristic of automata for non-interleaving represen- tation of behaviour and is sometimes called the lozenge rule [23,25,27]. Effec- tively, it says that if two independent events have occurred between two states q and qˆ, then they have happened in no particular order. In other words, it should be possible for them to have occurred with their order interchanged. This is depicted in Figure-3.




e 1 Iq e 2




q
q1
q1
e 1	e 2
=>	q	q
e 2	e 1
q2

Fig. 3. Condition (i) of Definition 3.6

Condition (ii) relates to discreteness of the generated language. A few words are in order to explain this further. Discreteness requires that elements bounded above in the vector language have their least upper bound and great- est lower bound in it. Therefore, in order to guarantee discreteness we need conditions under which posets are (finite) lattices. Subsequent analysis in [26]

shows that V is a discrete subset of VΣ precisely when ↓ u = {v ∈ V : v ≤ u} is a sublattice of VΣ. This turns out to be the case only when V satisfies the following
6u, v, x  ∈ V, u /= v Λ u a x Λ v a x =⇒ x = u H v Λ u H v
This is the so-called lower lozenge property (LLP), which essentially says that whenever we have the upper half of a lozenge, then we have the whole lozenge. It manifests itself in the structure of Σ-automata in the form of condition (ii). It is illustrated in Figure 4.

q	q



q1	q2	=>
e 1 ind e 2		q1	q2


q
Fig. 4. Condition (ii) of Definition 3.6
Condition (iii) excludes the possibility that an execution vector may be produced in two different ways from sequences of individual transitions. In other words, when the first part of an execution vector takes us from its initial state to an intermediate state, then the remaining part takes us from that state to the (execution vector’s) final state. Dually, we may state the same for the second part of the execution vector. The condition is depicted in Figure-5.

q’’


q’	u.v
u
q


v
=>  q’
u

q’’


u.v


q

q’’


q’


q




=>	q’
q’’

Fig. 5. Condition (iii) of Definition 3.6
Condition (iv) says that if two distinct transitions can start off the same behaviour from q, i.e. be part of the same execution vector from q, then they must do so concurrently. The motivation for this condition is not hard to see. Given a component vector u which describes behaviour of the component at state q, the two distinct transitions e1, e2 essentially provide two different ways, say v1, v2, of extending to a behaviour described by x. In other words, u.v1 = x and u.v2 = x. But this implies that v1 and v2 describe the same behaviour. Since, e1 is a prefix of v1, e2 of v2 and e1, e2 are distinct, we can not have v1 = v2 in general. This will only be the case if e1, e2 are concurrent. This is the point of condition (iv).
UML [21] is widely used for modelling and documenting software systems. Though it was not developed for component-based design as such, some of

its notation can be useful in bringing our component model closer to more conventinoal approaches to software design. With regard to UML 2.0 state machines and the notion of a compound transition defined therein (pp 500-1 in [21]), condition (iv) can be seen as a formalisation of the case where the head of a compound transition has multiple transitions to a set of orthogonal states (fork). Also, by applying condition (iv) to the conclusion of condition
(ii) we may say the same for the tail of a compound transition in UML 2.0 state machines.
The only problem with regard to establishing a relation between compound transitions in UML and condition (iv) (and (ii)), is that the semantics of com- pound transitions as given in the UML 2.0 spec document does not allow triggers on transitions entering a join or emanating from a fork (pp 470-4 in [21]). According to our ’semantics’, transitions can be labelled by an event in both cases and the trigger of the fork or join is the conjunction of the triggers (events) of the individual transitions. Our interpretation is that they are con- current (see condition (iv)). In fact, this is consistent with the STATEMATE semantics of joins and forks (pp 302-3 in [8]) in statecharts [7].
As a final note on Definition 3.6, it can be seen that condition (iii) is a global rather than a local property. This makes checking against it difficult.
[26] establishes the following for this purpose. Let M = (Q, >) be a Σ- machine and let V ⊆ VΣ. If (a) there exists an onto function φ : V → Q such that φ(u) >e φ(v) iff v = u.e and, (b) if u, v  ∈ V and u ≤ v, (u /= v), then there exists e ∈ EΣ such that u.e ∈ V and u.e ≤ v, then M satisfies (iii) of Definition 3.6.
Example 3.7 Considering the component of Example 2.8, we may now define a tuple Mex = (Qex, >ex) where Qex = Vex and >ex is given by

e	if f ∃e ∈ EΣ
and u, v  ∈ Vex s.t. u a v Λ v/u = e

For the component vectors in Vex we have,
Λ >e1 (c, Λ, Λ, Λ)	(c, Λ, Λ, Λ) >e2 (c, d, Λ, Λ)
(c, Λ, Λ, Λ) >e3 (c, Λ, d, Λ)	(c, d, Λ, Λ) >e3 (c, d, d, Λ)
(c, Λ, d, Λ) >e2 (c, d, d, Λ)	(c, d, d, Λ) >e4 (c, d, d, t)
We check the conditions of Definition 3.1.
q >e and q >e' with e ≤ e' for no q ∈ Qex, e, e' ∈ EΣex . Thus, (i) of Definition 3.1 holds.
q >e q' and q >e' q' with e /= e' for no q, e, e'. Thus, (ii) of Definition 3.1 also holds.
Hence, Mex is a Σ-machine.

In order to show further that Mex is a Σ-automaton we need to consider local concurrency. We start by identifying independent column vectors. We have e1 ind e5−k , for k = 1..3, and e2 ind e5−k , for k = 1, 2 and also e3 ind e4. Hence, all e ∈ EΣex are independent in this case. According to Definition 3.5,
'
if eIq e', then e ind e' and q >e q and q >e q >e q'. We observe that all events
associated with the component are independent and therefore we need only
check the latter requirement. q >e and q >e' hold only for e and e , for which
3
it is also true that ∃q1, q2, q' such that (c, Λ, Λ, Λ) = q >e2 q1 = (c, d, Λ, Λ) and (c, Λ, Λ, Λ) = q >e3 q2 = (c, Λ, d, Λ) >e2 q' = (c, d, d, Λ).
Thus, e2 I(c,Λ,Λ,Λ) e3.
Note that this example shows that independence alone is not enough to guarantee local concurrency. Furthermore, it also shows that two column vectors may be concurrent at some state (q = (c, Λ, Λ, Λ) here) but not in others; for instance, we do not have e2 I(c,d,d,Λ) e3.
Finally, we show that Mex is a Σ-automaton by checking the conditions of
Definition 3.6.
The first condition is relevant only for e2, e3 (take q = (c, Λ, Λ, Λ), q1 =
(c, d, Λ, Λ), qˆ = (c, d, d, Λ)) in which case we have q >e3 q2 >e2 qˆ for q2 =
(c, Λ, d, Λ) ∈ Qex. Thus, condition (i) of Definition 3.6 holds.
'
For condition (ii), we have that, q1 >e qˆ, and q2 >e qˆ, and e /= e', is the
'
case only when e = e2 and e = e . But for these column vectors we have
that e2 ind e3 and there exists q = (c, Λ, Λ, Λ) such that q >e3 q1 and q >e2 q2. Thus, condition (ii) holds.
For condition (iii), we find it easier to check against the associated lemma. We define a function φ : Vex → Qex by φ(u)= qk, 6u ∈ Vex, k = 0..5 so that φ((Λ, Λ, Λ, Λ)) = q0	φ((c, Λ, Λ, Λ)) = q1	φ((c, d, Λ, Λ)) = q2
φ((c, Λ, d, Λ)) = q3	φ((c, d, d, Λ)) = q4	φ((c, d, d, t)) = q5
By definition of φ and the relations ’a’ of example 2.8 the first condition (a) holds. Condition (b) follows from the component language Vex together with the covers relation. Thus, we may deduce that condition (iii) of Definition 3.6 holds.
For condition (iv), the only case in which q >e,e'  is for q = (c, Λ, Λ, Λ)

and e = e , e' = e , for which we also have e , e 
≤ x = (c, d, d, Λ). Thus,

2	3	2	3
the premises of condition (iv) are met for e2, e3. But then, for these column
vectors we have e2 I(c,Λ,Λ,Λ) e3 and thus, condition (iv) of the definition holds. Hence, Mex is a Σ-automaton. It can be represented by a state diagram which - the co relation aside - conforms to the UML 2.0 state diagrams [21] notation and that of statecharts [7]. The state diagram for Mex is given in Figure 6, where q1 co q2 implies that the transitions from q1 to q2 and q3 take place in no particular order. This is expressed in terms of the associated



Fig. 6. The Σ-automaton Mex

Σ-automaton by saying that they are related by Iq.
Note that without introducing the co relation between states, the dia- gram would simply denote a nondeterministic choice between taking e2 and then e3, and taking e3 and then e2. Since in a Σ-automaton we can express true-concurrency, we want a graphical notation that represents e2, e3 hap- pening in no particular order. We opted for the use of co mainly driven by early suggestions for indicating independence between events on transitions in asynchronous transitions systems (e.g. shading the lozenge shape in [23,25] or using ∼ within a lozenge shape in [10]). A suitable choice of notation is yet an issue for further consideration.	 
By exploiting the additional structure that went in to moving from Σ- machines to Σ-automata it can be shown that:
well-behaved components generate Σ-automata from initial state ΛΣ and the corresponding Σ-automaton generates back the same component language
the vector language of a rooted Σ-automaton corresponds to a normal com- ponent language which in turn gives rise to a rooted Σ-automaton for which the initial state is ΛΣ.
In the latter construction, the question arises as to the relationship between the rooted Σ-automaton (M, q) we start with and the rooted Σ-automaton (Mc, ΛΣ) derived from the corresponding component. The answer given in
[27] is that they are bisimilar in the sense of strong bisimulation in [16].
The main results of this section are summarised in the following theorem.
Theorem 3.8 Let CΣ denote the class of all well-behaved components with
signature Σ and let M ∗ denote the class of all rooted Σ-automata. Then,

there exists an onto function σ : M ∗ → CΣ given by
σ[M ∗]= (Σ,V (M ∗))

and furthermore,

σ[M ∗]= σ[M ∗] ⇐⇒ M ∗ ~ M ∗

1	2	1	2
where ~ denotes that there is a bisimulation from M ∗ to M ∗
1	2
Composition in terms of Σ-automata
In this section, we give a brief account of composition of Σ-automata. The intention is to show that the Σ-automata-theoretic framework described so far is indeed compositional. In a fashion similar to that of composition of components, the key idea is that a component vector v represents behaviour of the product M1||M2 providing it results from behaviours vk of Mk, each k, which agree on complementary interfaces.
Essentially, the transition relation is given by (q1, q2) >e  (q' , q' ) if and
1	2
e[k]	'	'
only if for each k either e[k] /= ΛΣk and qk >	q or e[k] = ΛΣk and qk = q .
This is expressed more succinctly as qk >>e[k] q' , each k. Mathematically,
q1 >>e q2 ⇐⇒ (q1 >e q2) V (e = ΛΣ Λ q1 = q2)
In terms of notation, using q to denote that (q1, q2) ∈ Q1 × Q2, and conse-

quently q
k
for qk, each k, we may write q >e q' for the transition relation of

the composite, which is translated in terms of the constituent automata as
q >>e[k] q' , each k.
k	k
In defining the transition relation of the composite we need to take account
of two possibilities:
e(i) /= Λ, i ∈ IΣ1 ∩ IΣ2 , in which case e[k] /= ΛΣk , for each k, and execution of the transitions from each automaton involves communication. This means
that both transitions must be executed simultaneously so that the composite has a transition (q1, q2) >e (q' , q' ).
1	2
e(i) = Λ, all i ∈ IΣ1 ∩ IΣ2 , in which case there is no communication and
execution of the transition of one of the constituent automata (the one for which e[k] /= ΛΣk , k =1 or k = 2) may occur independently of any transition in the other. Hence, the composite automaton has a transition (q1, q2) >e (q' , q2)
if k = 1, and (q1, q2) >e (q1, q' ) if k = 2.
Note that while e(i)= Λ, all i ∈ IΣ1 ∩ IΣ2 , it is still possible for e[k] /= ΛΣk , each k. Composition would then force the rest of the events (those appearing on the coordinates which correspond to the non-connected interfaces of each
i.e. e[k](i), each k : i /∈ IΣ1 ∩ IΣ2 ) to be simultaneous while this clearly need not be the case in general. Thus, an additional requirement on the transition structure is that if the e[k] are both non-null, then they must have some non-

empty coordinate in common.
Bringing the above concepts together we may now give a formal definition of composition.
Definition 3.9 Let M1 = (Q1, >) and M2 = (Q2, >) be Σk-machines, k = 1, 2 for which Σ1 ↓ Σ2 and let Σ = Σ1 ⊕ Σ2. Define M1||M2 = (Q1 × Q2, >), where >⊆ (Q1 × Q2) × EΣ × (Q1 × Q2) is given by q >e q' ⇐⇒
q >>e[k] q', for each k
If e(i)= Λ, all i ∈ IΣ1 ∩ IΣ2 , then either e[1] = ΛΣ or e[2] = ΛΣ .
Point (1) of the above definition refers to the case i) discussed above. Point
(2) relates to case ii) and expresses the additional requirement that compo- sition does not force otherwise independent column vectors to be necessarily simultaneous.
Our aim is to show that the proposed Σ-automata-theoretic framework is compositional, and to this end we need to establish that the composition (following Definition 3.9) of Σ-automata is itself a Σ-automaton.
First, we need to consider compatibility of Σ-automata in terms of their respective transitions. With regard to the discussion prior to Definition 3.9, we are concerned with the case where communication is involved. In this case, the corresponding components have (at least one) complementary interfaces and thus, their component vectors should agree on the corresponding non-empty coordinates. We may express this formally, and write u1 ⇓ u2 iff
6i ∈ IΣ1 ∩ IΣ2 : u1(i), u2(i) /=Λ ⇒ u1(i)= u2(i) Also, we may define the set of events (transitions) of a machine to be
E(M )= {e ∈ EΣ|∃q ∈ Q : q >e}
Thus, we now have that e1 ⇓ e2 iff on all non-empty common coordinates the ek agree. Hence, ’⇓’ does not cater for cases where, say, e1(i)= Λ Λ e2(i) /= Λ, i ∈ IΣ1 ∩ IΣ2 . The following definition rectifies this by imposing that if two transitions have at least one non-empty common coordinate on which they agree, then this must be the case for all their common coordinates.
Definition 3.10 Let M1 and M2 be Σk-machines, k = 1, 2, and Σ1 ↓ Σ2. Then, M1, M2 are compatible, and we write M1 ↓ M2 if
6e1 ∈ E(M1), 6e2 ∈ E(M2).e1 ⇓ e2 ⇒ e1 ↓ e2
This gives the compatibility condition within our automata-theoretic frame- work. One important consequence of this is that the execution vectors of the composite automaton are precisely those which project on execution vectors
of the constituents, i.e. (q ,q ) →u (q' , q' ) ⇐⇒ q →u[k] q' , for each k.

1	2	1	2
k	k	k

Second, we need to establish a relationship between local concurrency in the constituents and that of the composite automaton. We start by addressing independence. It is relatively straightforward to show that behaviours u, v  of the composite automaton can take place independently iff their projections onto the constituent automata are independent. Put formally,
u ind v ⇐⇒ u[k] ind v[k], each k
This allows for concurrency in the composite automaton to be defined in terms of the translation of the composite’s transition relation for the constituents.
Definition 3.11 Let M be a Σ-machine and q ∈ Q and e , e  ∈ E⊥. Define,
1	2	Σ

1 ˆ  e2
⇐⇒ e1
ind e2
Λ (∃q', q'', qˆ ∈ Q : q >>e1 q' Λ q >>e2 q'' >>e1 qˆ)

Now we are in a position to establish the relationship betwen concurrency in the constituents and concurrency in the composite automaton by

q
e IM
f ⇐⇒ e

[k]
q
I k f

[k]
, each k

where e, f  ∈ EΣ and M1, M2 are Σk-machines, k = 1, 2 and Σ1 ↓ Σ2 with Σ= Σ1 ⊕ Σ2 and M = M1||M2.
To sum up, we have considered a notion of compatibility among transitions of the constituent automata and related concurrency in constituents to that of the composite. It can now be shown that the composite of Σ-automata, following the construction given in Definition 3.9, is itself a Σ-automaton.

Conclusions and Future Work
We have presented an automata-based formalism for modelling the observ- able behaviour of components, in the presence of concurrency. We have also described how to compose Σ-automata. In fact, this extension to our ex- isting component model [19,18] allows two approaches to composition: either generate the corresponding components and then compose or compose the au- tomata and then generate a component from the composite automaton. The two approaches are shown to commute in [26].
Further work on composition is in progress and in particular, preservation of normality under automata composition. Preliminary results are encourag- ing. An interesting side effect of pursuing the dual aspects of composition - in terms of automata - has to do with relaxing the compatibility conditions that ensure preservation of normality in component composition [18].
Σ-automata can be seen as a usage protocol state machine for a component. They model both provides and requires assumptions and thus restrict the environment in a fashion similar to the interface automata of [6]. In contrast

to interface automata however, Σ-automata capture true-concurrency and this is carried on to the structure of the composite automaton, as discussed earlier. The concept of concurrency in our component model is based on that in- troduced by C.A. Petri in his 1962 thesis and further discussed in [22]. Tech- nically, nets at the condition-event level may be equipped with a semantics in terms of asynchronous transition systems, which may be shown to correspond to that of so-called process nets via a Mazurkiewicz trace language semantics for the asynchronous transition systems ([25], ch. 16-17). Further, an exten- sion of this semantics involves the so-called hybrid transition systems in which transitions are associated with multisets of event names ([25], ch. 22). The Σ-automata described in this paper lie somewhere between the two, in that the underlying asynchronous transition system is equipped with a specialised association of transitions to column vectors (in EΣ), which may be interpreted
as multisets.
It may be instructive to relate our approach to the algebraic model of [3] where behaviours are also described in terms of finite and infinite (we only consider finite) sequences associated with ports. The dynamics of components are given in terms of functions f : I → O where I, resp. O, is the set of all vectors with input, resp. output, ports as coordinates. Under certain conditions these functions can be described by equations in the manner of process algebra while recursion is handled using fixed point techniques. [3] points out that such equations may be represented by automata. Curiously, the independence of two vectors with distinct coordinates non-empty, and the possible pitfalls which figure prominently in this paper, are not addressed.
In order to increase the scope for reuse in different contexts, the compo- nent developer should not have to foresee possible reuse contexts during de- sign. This implies a need for dynamic coupling between provided and required services. Drawing on parametric contracts [1], essentially a finite state ma- chine based approach, we would like to see whether environmental properties can become parameters of the component’s provides/requires assumptions. Extending our model to address this in a concurrent setting, is one possible direction for future work.
In [17], we considered a scenario-based description of behaviour, in terms of LSCs [4], as the starting point for our component model. In particular, we showed how component interactions within a given scenario can give rise to an algebraic representation of behaviour, in terms of component vectors. Associating components with automata, as described in this paper, builds a bridge between algebraic and order-theoretic representation of component behaviour. This offers interesting perspectives concerning the move from a scenario-based specification to a state-based specification which we are keen

to explore further.

References
S. Becker, R. H. Reussner, and V. Firus. Specifying Contractual Use, Protocols and Quality Attributes for Software Components. In Proc. of 1st Int’l Workshop on Component Engineering and Methodology, pages 13–22, 2003.
M. A. Bednarczyk. Categories of Asynchronous Systems. PhD thesis, University of Sussex, 1988.
M. Broy. Algebraic Specification of Reactive Systems. Theoretical Computer Science, 239(2000):3–40, 2000.
W. Damm and D. Harel. LCSs: Breathing Life into Message Sequence Charts. Formal Methods in System Design, 19(1):45–80, 2001.
B. A. Davey and H. A. Priestley. Introduction to Lattices and Order. Cambridge Mathematical Textbooks, Cambridge University Press, 1990.
L. de Alfaro and T. Henzinger. Interface Automata. In Proc. of Foundations of Software Engineering (FSE’01), pages 109–120. ACM Press, 2001.
D. Harel. Statecharts: A Visual Formalism for Complex Systems. Science of Computer Programming, 8(3):231–274, June 1987.
D. Harel and A. Naamad. The STATEMATE Semantics of Statecharts. ACM Trans. on Software Engineering and Methodology, 5(4):293–333, October 1996.
C. Heitmeyer. Managing Complexity in Software Development with Formally Based Tools. In Proc. ETAPS 2004 workshop on Formal Foundations of Embedded Software and Component- Based Software Architectures (FESCA’04), volume 108 of ENTCS, pages 11–19. Elsevier, 2004.
T. H. Hildebrandt and V. Sassone.  Comparing Transition Systems with Independence and Asynchronous Transitions Systems. Technical Report RS-96-18, BRICS Report Series, University of Aarhus, June, 1996.
C. A. R. Hoare. Communicating Sequential Processes. Prentice Hall, 1985.
R. Janicki and P. E. Lauer. Speciﬁcation and Analysis of Concurrent Systems: The COSY Approach, volume 26 of EATCS Monographs in Theoretical Computer Science. Springer Verlag, 1992.
J. Ku¨ster-Filipe.  Modelling Concurrent Interactions.  In C. Rattray, S. Maharaj, and
C. Shankland, editors, Proceedings of Algebraic Methodology and Software Technology (AMAST 2004), volume 3116 of Lecture Notes in Computer Science, pages 304–318. Springer, 2004.
M. Z. Kwiatkowska. Fairness in Non-Interleaving Concurrency. PhD thesis, University of Leicester, 1989.
B. Meyer. Applying ”design by contract”. IEEE Computer, 25:40–51, 1992.
A. J. R. Milner. Communication and Concurrency. Prentice Hall, 1989.
S. Moschoyiannis. Generating Snapshots of a Component Setting. In Proc. ETAPS 2004 workshop on Formal Foundations of Embedded Software and Component-Based Software Architectures (FESCA’04), volume 108 of ENTCS, pages 83–98. Elsevier, 2004.
S. Moschoyiannis and M. W. Shields. A Set-Theoretic Framework for Component Composition.
Fundamenta Informaticae, 59(4):373–396, 2004.
S. Moschoyiannis, M. W. Shields, and J. Ku¨ster-Filipe. Formalising Well-Behaved Components. In H. Dang Van and Z. Liu, editors, Proc. of FME 2003, workshop on Formal Aspects of Component Software (FACS’03), pages 121–142. UNU/IST Report No. 284, 2003.

M. Nielsen, G. Plotkin, and G. Winskel. Petri Nets, Event Structures and Domains, part 1.
Theoretical Computer Science, 13:85–108, 1981.
OMG. UML 2.0 Superstructure Draft Adopted Speciﬁcation. OMG document ad/03-01-07, available from http://www.omg.org, August 2003.
C. A. Petri. Concurrency. In G. Goos and J. Hartmanis, editors, Proceedings of Advanced Course on General Net Theory of Processes and Systems, volume 84 of Lecture Notes in Computer Science, pages 251–260. Springer-Verlag, 1979.
M. W. Shields. Concurrent Machines. Computer Journal, 28:449–465, 1985.
M. W. Shields. Behavioural Presentations. In de Bakker, de Roever, and Rozenberg, editors, Linear Time, Branching Time and Partial Orders in Logics and Models for Concurrency, volume 354 of Lecture Notes in Computer Science, pages 671–689. Springer Verlag, 1988.
M. W. Shields. Semantics of Parallelism. Springer-Verlag London, 1997.
M. W. Shields. An Automata Theory for Components. Technical Report SCOMP-TC-04-04, Department of Computing, University of Surrey, 2004.
M. W. Shields and S. Moschoyiannis. An Automata-Theoretic View of Software Components. Technical Report SCOMP-TC-02-04, Department of Computing, University of Surrey, 2004.
R. van Ommering. Building Product Populations with Software Components. In Proceedings of International Conference on Software Engineering (ICSE’02), pages 255–265. ACM Press, 2002.
G. Winskel and M. Nielsen. Models for Concurrency. In S. Abramsky, D. Gabbay, and
T. Maibaum, editors, Handbook of Logic in Computer Science, vol. 4, Semantic Modelling, pages 1–148. Oxford Science Publications, 1995.
