Available online at www.sciencedirect.com


Electronic Notes in Theoretical Computer Science 351 (2020) 187–203
www.elsevier.com/locate/entcs

Strong Normalization for the Simply-Typed Lambda Calculus in Constructive Type Theory Using Agda


Sebastian Urciuoli1
A´lvaro Tasistro Nora Szasz2

Universidad ORT Uruguay Montevideo, Uruguay

Abstract
We consider a pre-existing formalization in Constructive Type Theory of the pure Lambda Calculus in its presentation in first order syntax with only one sort of names and alpha-conversion based upon multiple substitution, as well as of the system of assignment of simple types to terms. On top of it, we formalize a slick proof of strong normalization given by Joachimski and Matthes whose main lemma proceeds by complete induction on types and subordinate induction on a characterization of the strongly normalizing terms which is in turn proven sound with respect to their direct definition as the accessible part of the relation of one-step beta reduction. The proof of strong normalization itself is thereby allowed to consist just of a direct induction on the type system. The whole development has been machine-checked using the system Agda. We assess merits and drawbacks of the approach.
Keywords: Formal Metatheory, Lambda Calculus, Constructive Type Theory


Introduction
In [3] we have presented a formalization of the Lambda Calculus in Constructive Type Theory using first-order syntax, with only one sort of names for both bound and free variables, without identifying terms up to alpha conversion, and using multiple (simultaneous) substitution as fundamental operation.
It was then our aim to investigate whether this very concrete approach was in any way amenable to full formalization. The approach is historically rooted in the detailed meta-theoretical study of the calculus by Curry and Feys [7] where (unary) substitution was given a well-known definition as a total meta-operation on terms on top of which all the relevant relations of the calculus where defined, starting with alpha conversion. That definition of substitution proceeds by recursion on the

1 Partially supported by Agencia Nacional de Investigaci´on e Innovaci´on (ANII), Uruguay.
2 Email: {urciuoli,tasistro,szasz}@ort.edu.uy

https://doi.org/10.1016/j.entcs.2020.08.010
1571-0661/© 2020 The Author(s). Published by Elsevier B.V.
This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).

size of terms, but its full justification requires a simultaneous proof that its use as a renaming operation (i.e. when the substituted term is a variable) does not affect the size of the term wherein it is effected. This makes its formalization in e.g. Constructive Type Theory and using any of the proof assistants by now available, extremely difficult or even impossible.
However, the use of simultaneous multiple substitution as suggested in e.g. [11] brought about the possibility of achieving a development of the meta-theory of the calculus that was at the same time fully formal –to the extent of being close to a machine-checkable version– and humanly readable. Indeed, as explained in [11,3] the use of this kind of substitution makes it possible to avoid the recursion on the size of terms since, when crossing over lambdas the bound name is changed to an appropriate one and the corresponding renaming recorded into an enlarged, multiple substitution that goes on to operate on the body of the abstraction. Hence the effect of substitution can be given a simple definition by structural recursion which makes it plausible that the meta-theory of the calculus can be pursued using also simple forms of induction. The fact that bound names are always changed permits to avoid case analyses too.
Our work in [3,6] verified the preceding hypotheses to some extent: we were able to carry out full formalizations of the meta-theory of the pure Lambda Calculus up to the Standardization Theorem, and of the simply typed Lambda Calculus (more precisely, of the system of assignment of simple types to terms) up to the Subject- Reduction Theorem. Our main conclusion from those efforts has been that, in spite of having to explicitly consider alpha conversion, the workload was manageable, the formal machine-checked proofs not extremely lengthy, and their presentation in de- tailed mathematical English readable and reasonably complete. We also generated a basic Agda library [2] that was successfully employed and enlarged by a Master’s student in [6].
In the present paper we wish to continue the preceding line of work, with the purposes of:
testing the foregoing hypotheses against challenges of increasing complexity, and
making progress towards a comprehensive corpus of fully formal meta-theory of the Lambda Calculus.
We therefore tackle the problem of formally proving Strong Normalization for the system of assignment of simple types to terms. The method of proof we choose to formalize is due to [8] where the authors present slick proofs of weak and strong normalization which proceed by simple induction on the type system. These proofs use a main lemma that allows to deal with the difficult case of applications in the induction, via a separate complete induction on types, with a subordinate induction which, in the case of strong normalization, proceeds on a characterization of the strong normalizing terms originally given in [13].
In [8], vector notation is used for presenting terms which we shall avoid for a matter of convenience of the formalization. Also, –like in most of meta-theory developments– terms are identified under alpha conversion, with the usual conven-

tions for choice of bound names being made use of without further ado. Then, for example, variable capture is not take into account –which of course, we will have to. We wish to test whether:
our formalization can still be kept within limits of reasonable complexity,
our pre-existing Agda library makes the grade as to continue supporting this additional development, and
the effort is within the reach of a newcomer with limited experience in full formalization, the use of proof assistants, and Agda in particular. Actually, the work forms part of the Master’s thesis of the first author. The whole development has been formalised in Constructive Type Theory and machine- checked in the system Agda [10]. The corresponding code is available at https://github.com/surciuoli/lambda-metatheory.
We proceed now to the development itself. Its structure is as follows: in the next sec- tion we present the basic definitions, and results that are used in this formalization –some from [3], and some new developments. In Section 3 we give two definitions of the strongly normalizing terms. The first is the more natural one, defined as the accessible part of the one-step beta reduction, and the other is a syntactic charac- terization originally given (in vector notation) in [13]. Our formulation of the latter is mutual with the predicate characterizing strongly normalizing neutral terms and the strong head reduction. We formalize the proof of soundness of the second defi- nition with respect to the original one in Section 4. In Section 5 we make use of the syntactic characterization to obtain a proof of the Strong Normalization Theorem for typable terms in the system of assignments of simple types, which ultimately consists of a direct induction on the type system. Finally, in Section 6 we present the overall conclusions.

Preliminaries
Syntax
We start with a denumerable type V of names, also to be called variables; i.e. for concreteness we can put V =def N or V =def String. Letters x, y, z with primes or subindices shall stand for variables. Terms are defined inductively as usual —below we show a grammar for the abstract syntax:
Definition 2.1 The terms in Λ are deﬁned by the following grammar:
M, N ::= x | MN | λxM.
M , N , P , Q. . . range over lambda terms. In the concrete syntax we assume the usual convention according to which application binds tighter than abstraction.
Definition 2.2 That a variable x is free in M is written x ∗ M and its opposite is written x#M, to be pronounced x fresh in M as in nominal techniques. Both relations are deﬁned inductively in a standard manner.

Substitutions
We work with multiple (simultaneous) substitutions, i.e. mappings associating a term to every variable. Actually, the substitutions we must handle are identity almost everywhere, and so we can generate them by starting up from the empty substitution ι, which maps each variable to itself as a term, and applying the update operation defined as follows:
Definition 2.3 (Substitution Update) (σ, x:=M) is the substitution deﬁned by:
(σ, x:=M ) x = M
(σ, y:=M ) x = σx, if x ∗= y.

Whenever needed, we will write [x:=N ] as syntactic sugar for (ι, x:=N ).
Also, we often consider the restriction of a substitution σ to the free variables of a given term M , which is just written (σ, M ). Then, we can extend fresh and free variables to restrictions as well:
Definition 2.4 A variable x is fresh in (σ, M ) and written x#(σ, M ) iff for all y ∗ M, then x#σy. On the contrary, x is said to be free in (σ, M ) and written x ∗ (σ, M ) iff there exists some y ∗ M such that x ∗ σy.
Definition 2.5 (Effect of Substitution on Terms) The effect of a substitution
σ on a term M is deﬁned by recursion on M:
x · σ = σx
(MN ) · σ = (M · σ)(N · σ)
(λxM ) · σ = λz(M · (σ, x:=z))  with z = χ(σ, λxM )	(1)
In equation (1), notice that the bound variable x is always replaced with a new one. The new variable z is obtained by means of a choice function χ that computes the first variable fresh in (σ, λxM ), so that it does not capture any of the names introduced into its scope by effect of the substitution (see [3] for more details).
Besides implementing capture-avoidance, the use of multiple substitutions and uni- form renaming of bound variables allows us to employ simple structural induction, avoiding case analyses when reasoning with substitutions. We will use Mσ as syn- tactic sugar for M · σ and, in concrete syntax, substitution will bind tighter than application. The following properties about substitutions are proven in [3]:
Lemma 2.6
χ(σ, M )#(σ, M )
χ(ι, M )#M
M (σ, x:=Nσ)= M [x:=N ]σ
Definition 2.7 (Equality on Restrictions) (σ, M ) = (σj,Mj) iff M and Mj
share the same free variables and (∀x ∗ M ) σx = σjx.
Then, σ = σj ↓ M will be sugar for (σ, M )= (σj,M ).

Alpha Conversion
Definition 2.8 (Alpha-conversion)

∼v:

x ∼α x
∼app:
M ∼α Mj	N ∼α Nj
MN ∼α MjNj
~ λ:
 M [x:=z] ∼α N [y:=z]
λxM ∼α λyN
(*)

(*) with z#λxM, λyN.
Alpha conversion is extended to restrictions by the following definition:
Definition 2.9 σ ∼α σj ↓ M = (∀x ∗ M ) σx ∼α σjx
Then, the following lemmas –also proven in [3]– hold:
Lemma 2.10
ι ∼α ι ↓ M
σ ∼α σj ↓ M ∧ N ∼α P ⇒ (σ, x:=N ) ∼α (σj, x:=P ) ↓ M
Next we show some results about ∼α proven in [3] and needed in our development:
Lemma 2.11
∼α is an equivalence relation.
y#(σ, λxM ) ⇒ M (σ, x:=y)[y:=N ] ∼α M (σ, x:=N )
y#λxM ⇒ λxM ∼α λy(M [x:=y])
M ∼α N ⇒ λxM ∼α λxN
y#(σ, λxM ) ⇒ (λxM )σ ∼α λy(M (σ, x:=y))
x#M ∧ M ∼α N ⇒ x#N
M ∼α Mj ∧ σ ∼α σj ↓ M ⇒ Mσ ∼α Mjσj
M ∼α N ⇒ Mσ = Nσ 
M ∼α Mι 
From these, some useful corollaries are immediate:
Corollary 2.12
z#(σ, λyM ) ⇒ M (σ, y:=z)[z:=Nσ] ∼α M [y:=N ]σ
(λxM )N ∼α (λyMj)Nj ⇒ M [x:=N ] ∼α Mj[y:=Nj]
λxM ∼α λyN ⇒ M [x:=y] ∼α N

Beta Reduction
(One step) β-reduction is denoted →β, and it is defined by the following rules:
Definition 2.13 (Beta Reduction)

β:	M →β Mj
N →β Nj

(λxM )N →β M [x:=N ]
appL:
MN →β
MjN
appR:
MN →β
MNj

M →β Mj
λ: λxM →β λxMj
Multi-step reduction is written → and defined below:
Definition 2.14 (Multi-step Reduction)

 M ∼α N  M → N
M →β N M → N
M → N	N → P M → P

We extend → to substitutions as follows:
Definition 2.15 (Reductions on Substitutions) σ → σj = (∀x) σx → σjx. The following results from [3] involving →β will be needed in our development: Lemma 2.16
x#M ∧ M →β N ⇒ x#N
x#(σ, M ) ∧ M →β N ⇒ x#(σ, N )
σ → σj ⇒ Mσ → Mσj
M → Mj ⇒ MN → MjN
From now on, except when explicitly stated, all results presented constitute new developments.
Lemma 2.17 (Compatibility of substitution with →β, up to ∼α)
M →β N ⇒ (∃P ) Mσ →β P ∼α Nσ 
Proof. By induction on the derivation of M →β N .
Case β:  (λxM )N  →β  M [x:=N ].  Let P  = M (σ,  x:=z)(ι,  z:=Nσ) with z = χ(σ, λxM ).  Then, we need to show: (i) ((λxM )N )σ →β P and (ii) P ∼α M [x:=N ]σ. (i) By definition of the effect of substitution (Def. 2.5) we have ((λxM )N )σ = (λz(M (σ,  x:=z))Nσ and by β rule, (λz(M (σ,  x:=z))Nσ →β
M (σ, x:=z)(ι, z:=Nσ). (ii) By Corollary 2.12.1.
Case appL: MN →β MjN follows from M →β Mj. By ind. hyp. we know there exists some Q s.t. Mσ →β Q ∼α Mjσ. Using appL rule we get (MN )σ →β QNσ and by ∼app it follows QNσ ∼α (MjN )σ.
Case appR : MN →β MNj follows from N →β Nj. Analogous to the appL case.
Case λ: λxM →β λxN follows from M →β N . We have to show: (i) (λxM )σ →β	 P and (ii) P ∼α (λxN )σ, for some P . First, by ind. hyp. we know that there	 exists some Pj s.t. M (σ, x:=z) →β Pj ∼α N (σ, x:=z). Let P = λzPj. On	 the one side, (i) follows immediately by λ rule and Definition 2.5. (ii) On the	 other side, by Lemma 2.11.4 we have λzPj ∼α λzN (σ, x:=z). In addition, by	 Lemma 2.6.1 we get z#(σ, λxM ), thus by Lemma 2.16.2 we obtain z#(σ, λxN ).	 Finally, by Lemma 2.11.5 we have λzPj ∼α (λxN )σ, as desired.	2
Lemma 2.18 (Commutativity of ∼α and →β)

M ∼α N →β P ⇒ (∃Q) M →β Q ∼α P
Proof. By induction on M . We show only the proofs of the interesting cases.
Case λxM ∼α λyN →β λyP . On the one hand, λyN →β λyP must follow from N →β P (Def. 2.13) and by Lemma 2.17 there is a term Q s.t. N [y:=x] →β Q ∼α P [y:=x]. In addition, by Corollary 2.12.3 we get M ∼α N [y:=x]. Then, by ind. hyp. using M ∼α N [y:=x] →β Q we obtain M →β Qj ∼α Q, for some Qj, and by Definition 2.13 we get λxM →β λxQj. On the other hand, by hypothesis, using Lemmas 2.11.6 and 2.16.1 we get x#λyP , and by Lemma 2.11.3, λyP ∼α λxP [y:=x]. Finally, λxQj ∼α λyP holds by Lemma 2.11.4 and transitivity of ∼α.
Case (λxM )Mj ∼α (λyN )Nj →β N [y:=Nj]. Let Q = M [x:=Mj]. By Def. 2.13 we get (λxM )Mj →β Q and using Lemma 2.12.2 we have Q ∼α N [y:=Nj].  2

Lemma 2.19 (Commutativity of ∼α and →)
M ∼α N → P ⇒ (∃Q) M → Q ∼α P
Proof. Follows easily by cases on N → P , using Lemma 2.18.	2
Unary Substitutions
It turns out convenient to introduce substitutions that arise in the process of re- ducing a β-redex. They will consist of a pair associating a variable to a term accompanied by several variable renamings.
Definition 2.20 A substitution σ is unary of variable x and term M –written as
Unary σx M– iff σx = M and, for all y ∗= x, σy is a variable.
Lemma 2.21 (Unary Substitution Lemmas)
Unary [x:=M ] xM 
Unary σx M ⇒ Unary (σ, x:=N ) xN 
y ∗= x ∧ Unary σx M ⇒ Unary (σ, y:=z) xM 
Unary σxy ⇒ Unary (σ, z:=M ) zM 
Proof. Trivially by definition.	2

Inductive Definitions of Strongly Normalizing Terms
Our goal is to prove that all terms typable in the system of assignment of simple types are strongly normalizing. In order to do that, we will proceed as follows:
In this section we present two definitions of the strongly normalizing terms. The first one (predicate sn) is naturally introduced as the accessible part of the one- step beta reduction. The second one (predicate SN) is an alternative syntactic characterization introduced in [13], originally given in vector notation and adapted in [1] in a somewhat different context (i.e. using typed reductions).

We shall presently give the two definitions together with some of their properties, in order to eventually prove the soundness of the second definition with respect to the original one, i.e. that for all terms M , SN M implies sn M , in the next section. Later, in Section 5, we will complete the Strong Normalization proof by showing that all terms typable in the system of simple types assignment satisfy the second definition (SN).
Strongly Normalizing terms
A term is strongly normalizing if and only if it is in the accessible part of →β:
Definition 3.1 (Accessibility definition of strongly normalizing terms)
(∀N ) (M →β N ⇒ sn N )
sn M
Lemma 3.2 (Closure of sn under ∼α) sn M ∧ M ∼α N ⇒ sn N.
Proof. By induction on sn M . Take N such that M ∼α N and P such that N →β P . By Lemma 2.18 we have Q s.t. M →β Q ∼α P . Hence sn Q and by ind. hyp., since Q ∼α P , sn P as desired.	2
Lemma 3.3 (Properties of sn)
sn x
sn M ∧ M → N ⇒ sn N
sn (MN ) ⇒ sn M ∧ sn N
sn M ⇒ sn (λxM )
Proof. (3.3.1) By vacuity, since there is no possible way of having x →β M for any
x. (3.3.2) By induction on M → N . (3.3.3) By induction on sn (MN ). (3.3.4) By induction on sn M .	2
Strongly Normalizing terms: a syntactic deﬁnition
Now we introduce the second definition of strongly normalizing terms. In order to do this, we must define three mutually inductive predicates: strongly normalizing terms (SN), strongly normalizing neutral terms with head x (SNe x) and the relation of strong head reduction (→SN).
Definition 3.4 (SN, SNe and →SN)

v:
SNe x x
app:  SNe x M	SN N 
SNe x MN 

ne:  SNe x M 
SN M
λ:   SN M	
SN λxM
exp:  M →SN N	SN N 
SN M

β: 	SN N	
(λxM )N →SN M [x:=N ]
appL:
M →SN Mj
MN →SN MjN

α:  M →SN R	R ∼α N 
M →SN N

Soundness of SN
In this section we will show that SN is sound with respect to sn, i.e, every term in the first predicate is also in the second one. In order to achieve this, we first need to introduce two notions, namely that of neutral term and that of strongly normalizing head reductions that do not step inside abstractions.

Neutral terms
Let us call neutral the iterated applications having a variable as head:
Definition 4.1 (Neutral terms)

ne x x
  ne x M 
ne x MN 

We will omit the head and just write ne M whenever it results convenient. Neutral terms enjoy the following properties:
Lemma 4.2 (Closure of ne under →β) ne M ∧ M →β N ⇒ ne N
Proof. By induction on ne M .	2
Lemma 4.3 (Closure of sn/ne under app.) ne M ∧ sn M ∧ sn N ⇒ sn MN. Proof. By lexicographic induction on sn M , sn N . Assume MN →β P and proceed by cases to prove sn P :
In case P = MjN with M →β Mj, using Lemma 4.2 we obtain ne Mj. By definition of sn M we get sn Mj and then, by ind. hyp., sn P .
In case P = MNj with N →β Nj proceed analogously using sn Nj.	2
Strongly Normalizing head reductions
Definition 4.4 (Strongly Normalizing head reductions) →sn is the reduc- tion relation deﬁned as:

β: 	sn N	
(λxM )N →sn M [x:=N ]
appL:
M →sn Mj
MN →sn MjN
α:  M →sn R	R ∼α N 
M →sn N

Lemma 4.5 (Confluence) Let M →sn N and M →β P. Then either N ∼α P or there exists Q s.t. P →sn Q and N → Q.
In other words, let ΔL be the outer-leftmost redex of M not inside of an abstraction: then N is obtained from M by contracting ΔL. Let Δ be the redex contracted in M →β P . If Δ = ΔL, then N = P . Otherwise, let Q be obtained by contracting ΔL from P , i.e. P →sn Q. If Δ was discarded in M →sn N , then N = Q. If not, then necessarily N →β Q is derived by contracting Δ –and possibly other redexes in it.
Proof. By induction on M →sn N and subordinate analysis of M →β P .
- Case β: Suppose sn N .
- If (λxM )N →β P is obtained by rule β then we get P = M [x:=N ] immediately.

If (λxM )N →β P is obtained by rule appL then P is (λxMj)N and M →β Mj. Let Q = Mj[x:=N ]. By Lemma 2.17 and Definition 2.14 it follows that M [x:=N ] → Q and then, using rule β of Definition 4.4, we get P →sn Q.
If (λxM )N →β P is obtained by rule appR then P is (λxM )Nj and N →β Nj. Let Q = M [x:=Nj].  Now, on the one hand, by Lemma 2.17 we have M [x:=N ] → Q. And, on the other, since sn Nj follows from sn N and Lemma 3.3.2, we can use again rule β of Definition 4.4 to get P →sn Q.
Case appL: Suppose M →sn Mj.
MN →β P cannot be obtained using rule β, for in such case M would be an abstraction. But we have M →sn Mj and →sn does not proceed on abstractions.
If MN →β P follows from rule appL then P is MjjN and we have M →β Mjj. The ind. hyp. gives us two possibilities: either Mj ∼α Mjj or there exists some Qj such that Mj → Qj and Mjj →sn Qj. In the first case, it follows immediately MjN ∼α MjjN . Otherwise, let Q = QjN , then by Definitions 4.4 and 2.14 we get MjN → Q and MjjN →sn Q.
If MN →β P is obtained by rule appR then P is MNj and we have N →β Nj. Choose then Q = MjNj and use definitions of → and →sn.
Case α: Suppose M →sn R and R ∼α N . Suppose further M →β P . The	 ind. hyp. gives either R ∼α P or there exists Q s.t. R → Q and P →sn Q. In the	 first case, from R ∼α N and R ∼α P we obtain N ∼α P . In the other case, since	 R ∼α N , from R → Q it follows also N → Q by Lemma 2.19.	2
4.3  The Proof of Soundness
In order to prove that SN implies sn, we also need corresponding proofs of sound- ness of SNe and →SN with respect to sn and →sn. The difficulty lies in the case corresponding to the exp rule in the definition of SN, where SN M follows from M →SN N and SN N . By ind. hyp. we have M →sn N and sn N , and then we need a way of showing that the →sn relation is backward closed under sn. This is the goal of Lemma 4.8 below. In fact, what this lemma states is that →sn is also sound: if we have a →sn reduction from M to N and N is strongly normalizing, then M must also be. This reflects the idea behinds the →sn relation: it characterizes all computation strategies or possible reductions.
Coming back to Lemma 4.8, its proof goes by case analysis on the derivation of
M →sn N plus three auxiliary results –one for each case (Lemmas 4.6, 3.3.3 and 4.7).
Next, we need to prove that sn N and sn M [x:=N ] implies sn (λxM )N . However, –as in the previous lemma– since we are explicitly dealing with alpha-conversion, we need a stronger induction hypothesis, so we state the thesis is valid for any Q alpha-convertible with M [x:=N ]:
Lemma 4.6 (Weak Head Expansion) Let sn N, sn Q and Q ∼α M [x:=N ]. Then sn (λxM )N.
Proof. By lexicographic induction on sn N and sn Q. Assume (λxM )N →β P for some P and then proceed by cases proving sn P :

Case P = M [x:=N ]. By Lemma 3.2 and hypothesis.
Case P = (λxMj)N with λxM →β λxMj, which in turn must follow from M →β Mj. By Lemma 2.17, we have M [x:=N ] →β R ∼α Mj[x:=N ] for some R. Then, using Lemma 2.18 we obtain S such that Q →β S ∼α R. Hence, since S ∼α Mj[x:=N ] by transitivity of ∼α, we obtain by ind. hyp. sn (λxMj)N .
Case P = (λxM )Nj, obtained from N →β Nj. By Lemma 2.16.3, M [x:=N ] → M [x:=Nj]. Also, by Lemma 3.2 we get sn (M [x:=N ]). We apply Lemma 3.3.2 to obtain sn (M [x:=Nj]) and then, by ind. hyp. we conclude sn ((λxM )Nj).	2
Next, we introduce the following lemma which will be useful later on Lemma 4.8:
Lemma 4.7 Let M →sn Mj as well as M, N and MjN be sn. Then sn MN.
Proof. By lexicographic induction on sn M , sn N . Assume some MN →β P and proceed by cases showing sn P :
Case P = MjjN with M →β Mjj. By Lemma 4.5, either Mj ∼α Mjj or there exists some Q such that Mj → Q and Mjj →sn Q. The first case follows from the hypothesis sn (MjN ) and Lemma 3.2. In the second case, first notice that by Lemma 3.3.2 and by Definition 2.14 we get sn (QN ). Then, by definition of sn M , we have sn Mjj and can apply the ind. hyp. to conclude sn P .
Case P = MNj with N →β Nj. Use then the ind. hyp. and sn (MjNj).	2
Lemma 4.8 (Backward Closure of sn) Let M →sn N and sn M. Then sn M.
Proof. By induction on M →sn N .
Case β: Using Lemma 4.6.
Case appL: Assume M →sn Mj and sn (MjN ). By Lemma 3.3.3 we have sn Mj
and sn N . By ind. hyp. we have sn M , and using Lemma 4.7, we get sn (MN ).
Case α: Use Lemma 3.2 and the ind. hyp.	2
Now we only need two preparatory results:
Lemma 4.9 (Soundness of SNe with respect to ne) SNe x M ⇒ ne x M.
Proof. By a simple induction on SNe x M .	2
Lemma 4.10 M →SN N ⇒ M → N
Proof. By induction on M →SN N .
Case α: M →SN N is obtained from M →SN P ∼α N . By ind. hyp. we have M → N . Also, by Definition 2.14 we get P → N . Then, by transitivity of ∼α we have M → N .
Case β. By Definition 2.14.
Case appL: MN →SN MjN is obtained from M →SN Mj. By ind. hyp. we have
M → N hence, by Lemma 2.16.4 we have MN → MjN .	2
Finally, we prove that the alternative definition of the strongly normalizing terms is sound with respect to the accessible definition:

Theorem 4.11 (Soundness of SN)
SN M ⇒ sn M
SNe x M ⇒ sn M
M →SN N ⇒ M →sn N
Proof. By simultaneous induction, following Definition 3.4.
Case v: By Lemma 3.3.1.
Case app: Necessarily M = PQ and SNe x (P Q) is obtained from SNe x P and SN Q. Then, by ind. hyp. we have sn P and sn Q, and by Lemma 4.9 we get ne P . Finally, by Lemma 4.3 we obtain sn P Q.
Case ne: By ind. hyp.
Case λ: By ind. hyp. followed by Lemma 3.3.4.
Case exp: By ind. hyp. followed by Lemma 4.8.
Case β: By ind. hyp. and Definition 4.4.
Case appL: By ind. hyp. and Definition 4.4.	2
Strong Normalization Theorem
In this section we present the proof of the Strong Normalization Theorem for typable terms in the simply typed Lambda Calculus.
Typing judgements
Definition 5.1 Types are deﬁned by the following grammar, starting from a cate- gory τ of ground types:
α, β::= τ | α → β.
We introduce an ordering between types in order to later perform complete induction on them:
Definition 5.2 We write α ≤ β when the type α is a (structural) component of type β, and α ≺ β when it is a proper component.
Definition 5.3 The system of assignment of simple types to lambda terms is the following:

▶v: 	x ∈ Γ	
Γ ▶ x : Γx

▶a:
Γ ▶ M : α → β	Γ ▶ N : α


Γ ▶ MN : β

▶λ:
Γ,x : α ▶ M : β


Γ ▶ λxM : α → β

where Γ stands for a context (implemented as a finite list) of variable declarations of the form x1 : α1, x2 : α2,..., xn : αn. In rule ▶ v, x ∈ Γ means that x is declared in Γ, and Γx is the (last) type declared for x in Γ.
The following are proven in [3]:
Lemma 5.4 (Weakening) Let x#M and Γ ▶ M : α. Then Γ,x : β ▶ M : α.
Lemma 5.5 (Subject Reduction) Γ ▶ M : α ∧ M → N ⇒ Γ ▶ N : α.

Typed Substitutions
Next, we introduce typed substitutions (w.r.t. the free variables of a term M ):
Definition 5.6 (σ, M ) assigns to the variables in Γ terms of appropriate types under Δ —all of which is to be written σ :Γ → Δ ↓ M— iff for all x ∗ M s.t. x ∈ Γ, we have Δ ▶ σx : Γx.
These are useful for stating that, if a term M is typable then Mσ is also typable, as the following lemma —proven in [3]— declares:
Lemma 5.7 Let Γ ▶ M : α and σ :Γ → Δ ↓ M. Then Δ ▶ Mσ : α.
Then, the following three lemmas –also proven in [3]– hold:
Lemma 5.8 Let x#(σ, λyM ) and σ :Γ → Δ ↓ λyM. Then (σ, y:=x): (Γ, y:α) → (Δ, x:α) ↓ M.
Lemma 5.9 Let x#M and σ :Γ → Δ ↓ M. Then (σ, x:=y): (Γ, y:α) → (Δ, x:α) ↓ M.
Lemma 5.10 Let Γ ▶ M : α. Then [x:=M ]: (Γ, x:α) → Γ ↓ M.
We end up this subsection with some useful general results.
Lemma 5.11 Let ne x M and Γ ▶ x : β. Then:
Γ ▶ M : α ⇒ α ≤ β
Γ ▶ M : α → γ ⇒ α ≺ β
Proof. Immediate.	2
Lemma 5.12 u#M ⇒ Mσ = M (σ, u:=N )
Proof. By definition of equality of restrictions (Def. 2.7).	2
Strong Normalization
It is possible to prove by using a simple induction on the given type system that the typable terms are strongly normalizing . For this, we need to deal with the case of applications, that will be proved after the theorem (Lemma 5.14).
Theorem 5.13 (Strong Normalization) Γ ▶ M : α ⇒ SN M.
Proof. By induction on Γ ▶ M : α.
Case ▶v: By Definition 3.4.
Case ▶a: Γ ▶ MN : α is obtained from Γ ▶ M : β → α and Γ ▶ N : β. By ind. hyp. we get SN M and SN N . Then, by Lemma 5.14 2 (ii) we have SN MN .
Case ▶λ: By ind. hyp. and Definition 3.4.	2
We may now turn our attention to the main lemma. As already said, its purpose is to establish that SN MN follows from SN M and SN N for typable M and N but, in order to obtain this, some additional results must be proven simultaneously.

Lemma 5.14 Let Γ ▶ M : α, SN N, σ :Γ → Δ ↓ M, Unary σx N and Γ ▶ x : β. Then:
SNe y M ⇒ (i) SN M σ, (ii) y∗=x ⇒ SNe σy Mσ and (iii) α = β→γ ⇒ SN MN.
SN M ⇒ (i) SN Mσ and (ii) α = β→γ ⇒ SN MN.
M →SN P ⇒ Mσ →SN Pσ.
Proof. The proof proceeds by complete induction on the structure of the type β, and subordinate induction on Definition 3.4 indexed by M . So, to begin with, take β and assume the statement for all of its proper components. We proceed to the subordinate induction:
Case v: Then M = y and we have to show 1: (i) SN yσ, (ii) y∗=x ⇒ SNe σy yσ and
(iii) α = β→γ ⇒ SN yN . As to (i), either y = x or not. If true, then by Def. 2.20 we have σy = N . If not, —also by same definition— σy = z is a variable. Either case: SN σy. As to (ii), if y∗=x then in addition by Def. 3.4 we have SNe z z. As to (iii): by rule app of Def. 3.4 on SNe y y and SN N , followed by rule ne.
Case app: Then M = PQ and SNe y PQ follows from SNe y P and SN Q, and Γ ▶ PQ : α follows from Γ ▶ P : δ → α and Γ ▶ Q : δ. We need to show 1: (i) SN (P Q)σ, (ii) y∗=x ⇒ SNe σy (P Q)σ and (iii) α = β→γ ⇒ SN (P Q)N . First, by ind. hyp. we have SN Pσ and SN Qσ. Besides, by Lem. 5.7 we get Δ ▶ Pσ : δ → α and Δ ▶ Qσ : δ. Now, we have either y = x or not. In the first case, by Lem. 4.9 we have ne x P , thus by Lem. 5.11.2 it follows δ ≺ β. Then, as to (i), we can apply the main ind. hyp. 2(ii) with M = Pσ, N = Qσ and β = δ and get SN PσQσ which equals to SN (P Q)σ, as desired. On the contrary, if y∗=x then by ind. hyp.
(ii) we get SNe σy Pσ. Further, by definition of SN it follows SNe σy PσQσ, thus
SN (P Q)σ. (ii) Just proven. (iii) Similar to case v.
Case ne: Then SN M follows from SNe y M and 2 is immediate by the main ind. hyp. 1 (i) and (iii).
Case λ: Then M = λyP and SN λyP follows from SN P and Γ ▶ λyP : δ → ϵ from Γ,y : δ ▶ P : ϵ. We need to show 2: (i) SN (λyP )σ and (ii) SN (λyP )N . As to (i), we have (λyP )σ = λzP (σ, y:=z) with z = χ(σ, λxP ). We now proceed by cases: either y = x or not. In the first case, before we can apply ind. hyp. with SN P and (σ, x:=z) we need to show Γ,x : δ ▶ x : β. However, this does not necessarily follow, since δ is rather arbitrary. Nevertheless, we can proceed us follows: let us fix some u = χ(ι, P ). First, by Lemma 2.6.1 we have u#(ι, P ) and thus by Lemma 2.6.2 get u#P . Now, by Lemma 2.6.1 we have z#λxP and then by Lemma 5.8 obtain (σ, x:=z): Γ,x : δ → Γ,z : δ ↓ P , thus by Lemma 5.9 have ((σ, x:= z), u:=v): Γ, x:δ, u:β → Δ, z:δ, v:β ↓ P for any v. Besides, by Lemma 5.4 we have Γ, x:δ, u:β ▶ P : ϵ and then by Def. 5.3 we get Γ, x:δ, u:β ▶ u : β. In addi- tion, by Lemma 2.21.2 we have Unary (σ, x:=z) xz, thus by Lemma 2.21.4 we get Unary ((σ, x:=z), u:=v) u v. Now, since SN v, we can apply the ind. hyp. and get SN P ((σ, x:=z), u:=v). Then, by Lemma 5.12 P ((σ, x:=z), u:=v) = P (σ, x:=z), and thus SN P (σ, x:=z). Finally, by the λ rule of Def. 3.4 we obtain SN (λxP )σ, as desired. Now if, on the other hand, y ∗= x, then by Lemma 2.21.3 we have Unary (σ, y:=z) xN and thus we can apply the ind. hyp. to obtain SN P (σ, y:=z)

and therefore derive SN (λyP )σ in the same way. As to (ii), first notice that, since α = β → γ, it follows β = δ, hence Γ, y:β ▶ y : β. Then, by Lemma 2.21.1 we have Unary [y:=N ] yN and by Lem. 5.10 we have [y:=N ]: Γ, y:β → Γ ↓ P , thus we can apply the ind. hyp. (i) and obtain SN P [y:=N ]. Lastly, by β rule of Def. 3.4 we obtain (λyP )N →SN P [y:=N ] and thus by exp rule we can derive SN (λyP )N .
Case exp: Then SN M follows from M →SN P and SN P , and we need to show 2: (i) SN Mσ and (ii) SN MN . As to (i), by the main ind. hyp. 3 we have Mσ →SN Pσ and by ind. hyp. 2(i) SN Pσ, thus by rule exp we obtain SN Mσ. As to (ii), by ind. hyp. (ii) on SN P we have SN PN , therefore by rule appL applied to M →SN P we get MN →SN PN and thus by exp we can derive SN MN , as desired.
Case β: Then (λxM )N →SN M [x:=N ] follows from SN N and we need to show 3: ((λxM )N )σ →SN M [x:=N ]σ. First, notice that by Def. 2.5 we have ((λxM )N )σ = (λzM (σ, x:=z))Nσ with z = χ(σ, λxM ). In addition, by the main ind. hyp. 1(i) we have SN Nσ, thus by β rule of Def. 3.4 we have (λzM (σ, x:=z))Nσ →SN M (σ, x:=z)[z:=Nσ]. Furthermore, by Lem. 2.6.1 we get z#(σ, λyM ), hence by Cor. 2.12.1 we have M (σ, x:=z)[z:=Nσ] ∼α M [x:=N ]σ. Finally, we can use rule α of Def. 3.4 and obtain ((λxM )N )σ →SN M [x:=N ]σ.
Case appL: Then MN →SN MjN follows from M →SN Mj and we must show 3: (MN )σ →SN (MjN )σ. By ind. hyp. we have Mσ →SN Mjσ, thus by appL rule we can apply Nσ on both sides and obtain MσNσ →SN MjσNσ which by Def. 2.5 equals to (MN )σ →SN (MjN )σ.
Case α: Then M →SN P follows form M →SN N and N ∼α P and we need to	 show 3: Mσ →SN Pσ. By ind. hyp. we have Mσ →SN Nσ and by Lem. 2.11.8	 we get Nσ = Pσ, thus by Lemma. 2.11.1 we obtain Nσ ∼α Pσ and then by α	 rule of Def. 3.4 we can derive Mσ →SN Pσ, as desired.	2
Conclusions
The preceding work should be assessed in connection with the expectations stated in the Introduction. We assign relevance first of all to the complexity of the formalized version, both in Agda and in mathematical English.
Concerning the latter, we believe that this method makes it possible to come closer to a presentation in textbook style that does not hide details that need formalization. Of course, the main price paid has been the explicit handling of alpha-conversion; this has shown itself mainly in the formulation of the main definitions and results, which often must replace identity of terms by their alpha conversion, due to the renaming implicit in the effect of substitution on abstractions. As to additional, housekeeping lemmas, these seem to have been circumscribed to results of closure under alpha conversion. Also Lemma 5.12 is particularly noticeable. It could be replaced by a proof that Definition 3.4 is closed under alpha conversion.
Another aspect of the complexity has to do with the kind of proof methods required: when dealing with terms, we have been able to proceed by using only structural in- duction. In addition to this, we used of course induction on the various predicates and relations introduced, among which there is the somewhat complex mutual Def-

inition 3.4 of Section 3, as well as the well-founded induction on types which was the main method in the proof we chose to formalize.
On the other hand, the size of the Agda code has by no means exploded: it is of about 600 lines, split almost in halves between the proof of soundness of the inductive characterization of the strongly normalizing terms of Section 3 and the theorem of strong normalization property of Section 5. The complexity of the development can also be assessed by the effort required: the first author completed the work as part of his Master’s thesis in about 400 hours of work. This of course reveals a quite high cost for each Agda line of code.
Our pre-existing library providing the basics for the formalization of the calculus by the method chosen was only marginally updated. The required new results are shown in Section 2. The library was readily understood and made use of by the author of the formalization, despite his not having much prior experience in Agda (this was of only one tutorial course).
We believe we have made progress towards developing a corpus of formalized meta- theory of the Lambda Calculus somewhat along the lines of [9]. We also think that the present approach allows to aspire at achieving such a goal using the sort of explicit mathematical English we have used above, in turn supported by the Agda version.
This work should be compared to other formalizations of strong normalization, most notably those referred to in [1]. They employ variants of higher-order abstract syntax and of the de Bruijn notation, both of which of course dispense with alpha conversion. A full discussion is outside the scope of the present paper, but should be carried out. We should for that matter experiment with the full challenge posed in [1], using Kripke-style logical relations for proving strong normalization. The use of typed reduction will then force us to reformulate the calculus. We also have tried a formalization in Constructive Type Theory using Agda of principles of induction implementing the Barendregt variable convention –see [5,4], somewhat similarly to [12]. Again, we are still short of a full comparison in this respect.

References
Abel, A., G. Allais, A. Hameer, B. Pientka, A. Momigliano, S. Sch¨afer and K. Stark, POPLMark reloaded: Mechanizing proofs by logical relations, Journal of Functional Programming 29 (2019).
Copello, E., Agda library for Formal metatheory of the lambda calculus using Stoughton’s substitution, Available at https://github.com/ernius/formalmetatheory-stoughton.
Copello, E., N. Szasz and A´lvaro Tasistro, Formal metatheory of the lambda calculus using Stoughton’s substitution, Theoretical Computer Science 685 (2017), pp. 65 – 82.
Copello, E., N. Szasz and A´lvaro Tasistro, Machine-checked Proof of the Church-Rosser Theorem for the Lambda Calculus Using the Barendregt Variable Convention in Constructive Type Theory, Electronic Notes in Theoretical Computer Science 338 (2018), pp. 79 – 95, the 12th Workshop on Logical and Semantic Frameworks, with Applications (LSFA 2017).
URL http://www.sciencedirect.com/science/article/pii/S1571066118300720

Copello, E., A´lvaro Tasistro, N. Szasz, A. Bove and M. Fern´andez, Alpha-Structural Induction and Recursion for the Lambda Calculus in Constructive Type Theory, Electronic Notes in Theoretical Computer Science 323 (2016), pp. 109 – 124.
URL http://www.sciencedirect.com/science/article/pii/S1571066116300354


Copes, M., N. Szasz and A. Tasistro, Formalization in Constructive Type Theory of the Standardization Theorem for the Lambda Calculus using Multiple Substitution, in: F. Blanqui and G. Reis, editors, Proceedings of the 13th International Workshop on Logical Frameworks and Meta-Languages: Theory and Practice, Oxford, UK, 7th July 2018, Electronic Proceedings in Theoretical Computer Science 274 (2018), pp. 27–41.
Curry, H. B. and R. Feys, “Combinatory Logic, Volume I,” North-Holland, 1958, xvi+417 pp., second printing 1968.
Joachimski, F. and R. Matthes, Short Proofs of Normalization for the simply- typed λ-calculus, permutative conversions and G¨odel’s T, Archive for Mathematical Logic 42 (2003), pp. 59–87.
Nipkow, T. and S. Berghofer, Fundamental Properties of Lambda-calculus (2019), available from https://isabelle.in.tum.de/library/HOL/HOL-Proofs-Lambda/document.pdf.
Norell, U., “Towards a Practical Programming Language Based on Dependent Type Theory,” Ph.D. thesis, Department of Computer Science and Engineering, Chalmers University of Technology (2007).
Stoughton, A., Substitution revisited, Theoretical Computer Science 59 (1988), pp. 317–325.
Urban, C. and C. Tasson, Nominal Techniques in Isabelle/HOL, in: R. Nieuwenhuis, editor, Automated Deduction – CADE-20, Lecture Notes in Computer Science 3632, Springer Berlin Heidelberg, 2005 pp. 38–53.
van Raamsdonk, F. and P. Severi, On Normalisation, Technical report, Centrum voor Wiskunde en Informatica (CWI), Amsterdam (1995).
