Electronic Notes in Theoretical Computer Science 175 (2007) 19–32	
www.elsevier.com/locate/entcs

Self-assembling  Trees
Vincent Danos1 ,
E´quipe PPS, CNRS & Universit´e Paris VII
Jean Krivine2 ,
INRIA Rocquencourt & Universit´e Paris VI
Fabien Tarissan3
E´quipe PPS, CNRS & Universit´e Paris VII

Abstract
RCCS is a variant of Milner’s CCS where processes are allowed a controlled form of backtracking. It turns out that the RCCS reinterpretation of a CCS process is equivalent, in the sense of weak bisimilarity, to its causal transition system in CCS. This can be used to develop an efficient method for designing distributed algorithms, which we illustrate here by deriving a distributed algorithm for assembling trees. Such a problem requires solving a highly distributed consensus, and a comparison with a traditional CCS-based solution shows that the code we obtain is shorter, easier to understand, and easier to prove correct by hand, or even to verify.
Keywords: Self Assembling, RCCS, CCS, Distributed Consensus.


Introduction
We propose in this paper to illustrate a method for deriving distributed algorithms. The broad idea is to solve a simpler problem, and then reinterpret the obtained so- lution assuming a generic distributed backtracking mechanism. This is reminiscent of the classic breakdown of solutions to NP problems into an exploration (guessing the solution) and a verification phase (checking the guess is correct). It is also rem- iniscent of simulated annealing methods where a locally-driven search is backed by a random perturbation. Another analogy is with declarative programming where

1 Email: vincent.danos@pps.jussieu.fr
2 Email: jean.krivine@inria.fr
3 Email: fabien.tarissan@pps.jussieu.fr

1571-0661 © 2007 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2006.11.017

terse solutions can be obtained because the ambient evaluation framework includes a generic enumeration mechanism.
It turns out that the notion of a solution to a simpler problem can be neatly characterised in terms of the theory of concurrent systems, using the notion of causal transition system, and so does the correctness of the generic backtracking mechanism. A rather general result then ensures that the reinterpreted solution is indeed a solution to the original problem [4].
This compares best with direct approaches when the problem of interest needs reaching a consensus which is itself highly distributed. Thus, for the purpose of illustrating the method, we choose a class of problems which is a simple idealisation of the phenomenon of self-assembly, where simple parts assemble in some predefined spatial arrangement by means of local and asynchronous interactions. Solutions of such problems indeed involve arbitrarily complex distributed consensus.
Specifically, we derive a distributed algorithm for an ensemble of processes to self-assemble in patterns described as trees. To formulate the algorithm, we use a partially reversible derivative of CCS [12], called RCCS, which introduces a distinc- tion between reversible and irreversible computation steps, together with a notion of distributed memory which allows backtracking reversible steps [3].
The algorithm itself is obtained indirectly. One first defines a simple CCS al- gorithm such that any allowed tree construction can be simulated, and conversely all trees resulting from a series of local interactions are allowed. This is not yet a solution since the induced assembly may deadlock, but it gets very close to be- ing one. Indeed, by merely reinterpreting the same algorithm in RCCS, and thus allowing backtrack on reversible actions, one obtains a real solution. For the sake of evaluating the method we compare the first algorithm with a direct solution in CCS which explicitly copes with deadlocks. One sees clearly that the latter is both harder to understand, and to prove correct, and also assumes more computational power from the basic processes.
There are limitations to this method. It is likely to provide significantly sim- pler solutions only to problems in need of complex consensus. Another limitation is that it is for the moment restricted to problems the solution of which can be expressed in CCS. However, recent developements show that correct backtracking mechanisms can be derived for a vastly more comprehensive SOS-based class of agent-languages [15], and that the reinterpretation theorem can be made to bear in the abstract framework of monoidal categories, and thus also covers more general grounds, such as Petri Nets [5].
The paper is self-contained but for the more technical notion of causality which is treated informally; a rigorous treatment is given in ref. [3,4]. Sec. 2 presents the self assembly specification; Sec. 3 introduces the algorithm in CCS; Sec. 4 shows that although it may deadlock, it is well designed in that its causal computations are as in the specification, and that it is therefore correct in RCCS; Sec. 5 compares with a direct solution in CCS. 4

4 A preliminary version of this work was presented as a poster at the 7th International Conference on Artificial Evolution, Lille, France, Oct 26–28, 2005.

Specification

The aim of this section is to define the specification for our distributed implemen- tation as a labelled transition system (LTS).



Transition systems and Bisimulation
A labelled transition system consists of a triple: a state space S, a set of labels (or actions) L, and for each l ∈ L, a binary relation over S, written →l and called the transition relation. Sometimes one also adds an initial state s0 ∈ S to the preceding data. We will write →w, with w = l1 ··· ln a word over L, for the composite relation
→l1 ; ··· ; →ln .
Given some specification of a distributed system (such as the one given below in this section), and another LTS (possibly obtained from a CCS process as in Sec. 3) believed to be an implementation, one needs some means of stating the correctness of the implementation with respect to the specification. This is given by the notion of bisimulation.
Specifically, suppose given two LTSs (S, s0, L, →), (S', s' , L', →'), and a relation Φ over L × L'. Define the domain of Φ as {l ∈ L | ∃l' ∈ L' : (l, l') ∈ Φ}, and the codomain of Φ as the domain of the converse relation Φ−1.
Given words w, w' over L, L': define wΦ (w' ) as the word w with all occurrences of labels not in the domain (codomain) of Φ erased, and write (w, w') ∈ Φ if wΦ =
l1 ··· ln and w' = l' ··· l' have the same length, and for all 1 ≤ i ≤ n, (li, l') ∈ Φ.
Φ	1	n	i
Actions in the domain (codomain) of Φ will be called visible, and Φ itself will be
called a visibility relation, thus wΦ represents the actions in w which are visible according to Φ.
One then says a relation  over S × S' is a Φ-bisimulation, if s0  s' , and
whenever s  s':
if s →w t, then s' →' ' t', with (w, w') ∈ Φ and t  t',
if s' →' ' t', then s →w t, with (w, w') ∈ Φ and t  t'.
The two conditions above are symmetric and state that whatever series of visible actions one LTS may perform, the other may match. In other words the two LTSs, different as they may be, are indistinguishable by synchronisation on visible actions; one says they are Φ-bisimilar.
In the context of CCS (see Sec. 3), one has a distinguished silent action, written τ , and setting L = L', and Φ = {(l, l) | l /= τ } obtains what is known as weak bisimulation. Only non-silent actions, as the name suggests, are observed. An even more stringent case is when Φ is the identity relation, i.e., all actions are visible, and one speaks of strong bisimulation. Our slight generalisation where the two LTSs use different sets of actions, and some flexibility is allowed regarding which actions are visible and how they match, will be convenient.

The speciﬁcation
Let V be a set of nodes given together with a degree map δ : V → N stipulating how many nodes a given node may connect to. The trees considered here will be represented as:
t ::= (a, {t1,... , tn})
where a ∈ V and n ≥ 0. Hence the simplest tree is (a, ∅) which will be simply denoted a. Other examples are (a, {b, c}) where a has two children, b and c, and (a, {(b, {c})}) where a and b each have one child, b and c. A childless node will be called a leaf as usual. Trees will be considered to be commutative, that is to say for instance (a, {b, c}) and (a, {c, b}) stand for the same tree, as the set notation suggests.
A tree t will be said to be coherent if all nodes in t have their degree as prescribed by the degree map δ, which means in particular that leaves in t will have arity smaller than 1 (and exactly 1 if they are not also the root of t). Imagine for instance that δ(a) = 2, and δ(b) = δ(c) = 1, then (a, {b, c}) is coherent, while (a, {(b, {c})}) is not. Also one has that a is coherent if and only if δ(a) = 0. Finally, we will write n(t) to denote the nodes of t.
A state of our specification LTS is defined as a pair (N, i ti) where N ⊆ V represent the free nodes, and each ti is a coherent tree representing the trees already built. We write + both for the addition of multisets and the disjoint union of sets. Labels are coherent trees over V , and transitions are given as follows:
N + n(t), Σi ti →t N, t + Σi ti

Note that coherence is the only constraint on trees grown out of our starting set of nodes V . Instead, one could choose a different rule for growing trees, by specifying from the outset which trees are allowed. We opt here for the local growth rule, since it allows for simpler notations, and the method given here can anyway be readily adapted to the global growth case.

Implementation
To define agents showing a collective behaviour in accordance with the specification given above, we use CCS [12], where the only means of communication between agents are binary synchronisations through complementary actions. This restriction translates effectively the intuitive constraint on self-assembly, namely that the global behaviour should be obtained only by means of local interaction.
CCS
CCS processes have the form:
p ::= 0 | Σ αi.pi | (p | p) | (a)p | D(x˜)

act  Σ α .p

→αi pi



par
p →α p'
p | q →α p' | q







syn
p →α p'	α /= a, a¯ (a)p →α (a)p'
p →a p'	q →a¯ q'

p | q →τ p' | q'


res

Fig. 1. CCS labelled transition system.

nodei=def τ.(buildδ(i) | waitδ(i))+ Σrij.(buildδ(i)−1 | waitδ(i)−1)	(1)

i	i٨
i	ij
j∈V

buildn+1=def Σr¯ij.buildn, build0=def 0	(2)
i	i	i
j∈V

waitn+1=def wi.waitn , wait0 =def w¯j. ↑i , wait0 =def oki. ↑i
(3)

iα	iα	ij	j	i٨	٨

Fig. 2. Self-assembly.

where α ::= a | a¯ | τ can be a reception, an emission, or a silent action, and D(x˜) stands for parametric recursive definitions. Sums are taken finite, and the empty sum is denoted by 0 and called the zero process. Structural congruence, written
≡, is the least equivalence relation over processes closed under sum, product and restriction, and such that sum and product are associative and commutative and have 0 as neutral element. One also assumes α-conversion (renaming), and the following rule to unfold recursive definitions: D(x˜) ≡ p if D(x˜)=def p . Thereafter processes are all considered up to ≡.
The CCS labelled transition system given in Fig. 1 explains how a process be- haves in terms of the actions it can perform. Thus any CCS process generates an LTS, where states are processes, and labels are CCS actions.
We fix a countable subset K of CCS actions, shown as underlined in the various examples below; these are to be later interpreted as irreversible actions in RCCS, and play no specific role in the CCS semantics.
The implementation
With both our specification and agent language in place, we turn to the definition of the CCS process describing how agents interact in order to self-assemble. The definition is given in Fig. 2, with n an integer, i, j ∈ V , α ∈ V + { }, and δ the degree function described earlier.
Each node is translated as a specific agent nodei, with i ∈ V . An agent can either decide to be the root of a new tree (left hand side of the choice in (1)), or be recruited by another agent (right hand side of the choice in (1)). In both
cases, two subprocesses are spawned, buildn, and waitn , where n is the number
i	iα
of nodes the agent needs to recruit, as determined by its degree δ(i); α stands for
the agent parent, if any, or for  if the agent is a root. The process buildn (2) uses

rij to recruit n free agents, while waitn
(3) uses wj to get confirmations of these

recruitments, and then uses w¯j to send a confirmation to its parent. In the special case the agent is the root of the tree, and has no parent, it performs instead the final underlined action oki to indicate the end of the construction.
There is no intrinsic reason why wait should gather confirmations in sequence; this is due to the restrictive syntax of CCS which does not allow prefixing by a set of actions (see for instance ref. [2, Sec. 3]). Likewise, using a richer language such as π-calculus [13] would make a more elegant code, replacing the rijs with a public name (see ref. [6, Sec. 8]). That would also need a π-calculus analog of RCCS (see ref. [10, Chap. 9]), and this simple CCS version, perfectible as it is, shall be enough for our illustrative purposes.
One could set the final state of an agent to be simply a zero process, but our
convention to take it to be a loop process ↑i =def τ. ↑i , indicating that agent i was
successfully recruited by agent α, makes it slightly easier to extract the tree a given process has actually finished to build.
The complete system is represented as the product of all agents where all actions but the final okis are restricted.

Examples
Here is a computation example with δ(a)= 2, δ(b)= δ(c)= 1:

nodea | nodeb | nodec →	build2 | wait2 | nodeb | nodec

a
٨	wait2
a٨
a٨
wait0
ba
wait0
ca

≡	wa.wa.oka. ↑a| w¯a. ↑b | w¯a. ↑c
٨	a	a
→٨	oka. ↑a|↑b |↑c
٨  a  a
→ok  ↑a| ↑b |↑c
a	٨	a	a

This corresponds to a single transition {a, b, c}, ∅ →(a,{b,c}) ∅, {(a, {b, c})} at the specification level. In general, the construction of a tree t will decompose in 2 ∗ n(t) steps. As expected, the obtained code is not correct yet, and may well deadlock, as in the following where δ(a)= δ(b) = 1, and δ(c)= 3:

nodea | nodeb | nodec → build1 | wait1 | nodeb | nodec
a	a٨
→ wait1 | nodeb | build2 | wait2
a٨	c	ca
→ wait1 | wait0 | build1 | wait2
a٨	bc	c	ca
≡ wait1 | wc. ↑b| build1 | wc.wc.wa. ↑c u
a٨	c	c	a
→ wait1 |↑b| build1 | wc.wa. ↑c
a٨	c	c	a

At this stage, the incoherent tree (a, {(c, {b})}) is built, but there is no node left for build1 to recruit. Yet there is a successful trace, where a recruits b instead of

c, corresponding at the specification level to the single transition {a, b, c}, ∅ →(a,{b})
{c}, {(a, {b})}.
Therefore, it is clearly impossible to exhibit a bisimulation relation between the specification and the code induced LTS. However, the code is correct in the weaker sense that its causal computations (defined below) indeed match the specification. As we will see in the next section this is enough to ensure correctness, provided the process is re-interpreted in RCCS. The idea is that, for instance, the deadlocked trace above may backtrack in RCCS up until the wrong decision of recruiting c was made, and eventually recruit b. Note that this is not saying that the process will find a solution, it may well loop infinitely. There are known theoretical results showing that one cannot do better in a purely non-deterministic interpretation [14]. This is of little practical importance, since such backtracking schemes will be implemented with probabilities, and such futile infinite loops will have probability zero.
To prevent backtracking from a successful state, where a coherent tree has been constructed, the corresponding underlined final actions oki will be chosen irreversible.

Correctness
This section reviews a variant of the implementation of distributed backtracking in RCCS, and the reinterpretation theorem used to derive correctness of the pre- vious section code. The operational semantics of RCCS we present here differs from the original one [4] in that it requires abstract identifiers for uniquely tagging communications. This makes the presentation notably simpler than in the original presentation which was more adapted to the theoretical study of RCCS properties. In the present work, we adopt Phillips and Ulidowski’s approach [15] in which com- munication keys are used to identify partners of communication. A reader familiar with the previous semantics of RCCS may wonder whether the above calculus, using communication identifiers, is equivalent to the original one. It is indeed the case [10] and we give basic hints to prove this affirmation in the appendices. Since it is not necessary for the understanding of the rest of this paper, the reader may readily proceed with the next section.
RCCS
RCCS is an extension of CCS where processes are equipped with memories used to undo computations. Memories and terms are given in Fig. 3 where: i = 1, 2; θ is an abstract name, drawn from a countable set I, used to uniquely identify a communication; and p is a CCS process (as in Sec. 3) with some distinguished underlined actions declared as irreversible.
In addition to the congruence rules (see Fig. 3) for distributing memories among forking processes, and commuting restrictions with memories (assuming a was never used in the past –which is always possible using α-conversion), product and sum are considered commutative and associative, and having 0 as neutral element, as in CCS.


m ::= ⟨⟩ | ⟨i⟩.m | ⟨θ, α, p⟩.m | ⟨|θ|⟩.m r, s ::= m D p | (r | s) | (x)r
m D (p | q) ≡ ⟨1⟩.m D p | ⟨2⟩.m D q m D (a)p ≡ (a)(m D p) if a /∈ m

Fig. 3. RCCS memories, terms and additional congruence rules.
θ /∈ f(m)	θ /∈ f(m)

act m D α.p + q →
θ:α
⟨θ, α, q⟩.m D p
⟨θ, α, q⟩.m D p →
θ:α−
m D α.p + q

θ /∈ f(m)
act 	
m	α.p + q →θ:α ⟨θ⟩.m	p

r →θ:a r'	s →θ:a¯ s'	r →θ:a− r'	s →θ:a¯− s'

com
r | s →
θ:τ
r' | s'
com-
r | s →
θ:τ−
r' | s'






r →θ:ζ r'	θ /∈ f(s)
r →θ:α r'	s →θ:α s'
com	
r | s →θ:τ r' | s'
r →θ:ζ r'	a /∈ ζ



r1 ≡ r →θ:ζ r' ≡ r2

par
r | s →θ:ζ r' | s
res
(a)r →θ:ζ (a)r'
cgr
1
→θ:ζ r2




Fig. 4. RCCS labelled transition system.
Define f(m) (resp. f(r)) to be the set of identifiers occurring in the memory m (resp. memories of subprocesses of r). The RCCS labelled transition system is given Fig. 4. Its labels are of the form θ : ζ, with ζ ::= α | α− | α, and θ an identifier. Side conditions of the form θ /∈ f(s) ensure θ is indeed unique (or a nounce in the cryptographic protocols terminology). One should note that this property corresponds to the freshness condition on communication keys in Phillips and Ulidowski’s approach [15].
Forward action and communication rules each have their opposite, allowing to backtrack actions, unless the action is underlined, and thus explicitely made un- backtrackable.
Reinterpretation theorem
As said, the weaker notion of correction we need, uses the notion of causal trace. Intuitively, such traces do not involve contention among agents, since all actions therein contribute to the last one, and in addition represent atomic successful com- putations, since one asks the last action to be the trace only irreversible one.

More precisely, a trace σ is said to be causal if it contains a single irreversible transition t and for all σ' ∼ σ, σ' ends by t, where ∼ is the equivalence relation over CCS traces obtained by permuting concurrent transitions [1].
Here are some examples:

a.b.0 | c.0 →a b.0 | c.0 →c b.0 →b 0
a.b.0 | c.0 →a b.0 | c.0 →b c.0
a.b.0 | a¯.0 →τ b.0 →b 0
The first trace is not causal since its last action b commutes to the earlier action c, as in the second one which is causal; likewise, the last trace is causal, since the marked action b does not commute to τ .
Definition 4.1 Let P be the set of CCS processes, K be the set of underlined

CCS actions, and define p1 →c
p2, if there is a causal trace from p1 to p2 ending

with k. The causal transition system induced by p, written CTS(p), is defined as (P, p, K, →c ).


In the examples above, one has a.b.0 | c.0 →c
c.0, a.b.0 | a¯.0 →c
0, and not

a.b.0 | c.0 →c 0.
The theorem below asserts that the LTS induced by the interpretation of p in RCCS is equivalent to CTS(p), when observations are restricted to irreversible actions.
Theorem 4.2 ([4]) Let p be a CCS process, and Φ be the relation {(k,θ : k); k ∈
K, θ ∈ f}, then CTS(p) ≈Φ LTS(⟨⟩ D p).

Back to self assembling trees
To apply this definition to the case of interest, we need to map macro-states (states of the specification) to micro-states (states of the corresponding process). Define first the family of maps [ ]]α, with α ∈ V + { }:

[[(a, {t1,... , tn})]]α =def ↑a | [[t1]]a | ... | [[tn]]a

This obtains a map from macro-states to what one might call their standard repre- sentation as micro-states (restrictions are not shown):
[[N, Σi ti]] =def  i∈N nodei |  j [[tj]]٨
Defining Φ' = {(t, oki) | i ∈ V }, one has:
Proposition 4.3 The relation {(N, i ti), [[N, i ti]]} is a Φ'-bisimulation between the speciﬁcation LTS and CTS([[V ]]).

The proof is routine. Concretely, this is saying two things. Firstly, whenever some tree may be constructed from the remaining free nodes of the specification, there exists a causal sequence of interactions among the agents that implements it (see first example in Sec. 3). Secondly, whenever a tree is built after a successful series of agent interactions, this tree is indeed coherent, and therefore corresponds to a transition in the specification (this is even easier to prove, since the number of neighbours of any given process representing a node is always kept smaller or equal to its arity as specified by δ).
Putting that proposition together with the theorem above one obtains:
Corollary 4.4 The speciﬁcation LTS and LTS(⟨⟩ D [[V ]]), are Φ'; Φ-bisimilar.
One may object that the visibility relation Φ'; Φ used here is highly non-injective, since it relates a tree t to some oki, which contains no other information than the name of the process being the root of t. Using a value-passing version of CCS, one can decorate the implementation and construct during the assembly an expression describing the tree being constructed, which could then be used to encode injec- tively t in the final irreversible action concluding the construction. However, the bisimulation relation we exhibit clearly contains all the needed information since the macro-to-micro map itself is injective.

Discussion
It remains to appreciate whether a direct solution in CCS could compare well with the indirect solution we have obtained. We base our discussion on a comparison with one particular reasonable direct implementation, given Fig. 5, and obtained by patching the indirect code to recover from deadlocks. The recruitment phase is quite similar to the one in the previous code, except build and wait processes are now run in sequence. A more important difference is that the root may abort

the construction by running at any time the process abortS
which waits for the

freeS(end) process to free recruited agents, and then re-spawns the initial state. Any already recruited agent i enters the abort state upon reception of a request by
its parent using action killi. Accordingly, the final state †S indicating that the ith
agent has finished its part of the recruitment, in the case α /= still waits for a possible such abort request initiated by the root agent and forwarded by its parent.
Thus, the direct code may escape deadlocks. To keep things simple, we give up part of the distributed structure of the system: a node does not wait for the confirmations of its children until it has completed its recruiting task. This results in a better control of the construction process at the price of a loss of efficiency, since no agent can validate its recruitment until its parent is ready to receive the validation. Yet the main difference is in the backtracking mechanism: the RCCS code finds its way to a final shape by using partial backtracking, whereas the CCS one uses a top-down cancellation procedure to abort altogether the construction (as in ref. [9]).
One sees the RCCS code is more intuitive; this is because, in essence, it is easier


nodei	=def τ.buildδ(i),∅ + Σrij.buildδ(i),∅
i٨	ij
j∈I

buildn+1,S
=def Σ r¯ik.buildn,S∪{k} + killi.abortS

ij	ij	i
k∈I

buildn+1,S
=def Σ r¯ik.buildn,S∪{k} + τ.abortS

i٨

build0,S
iα
ij	i
k∈I
=def wait|S|,S

waitn+1,S
=def wi.waitn,S + killi.abortS

ij
waitn+1,S
ij	i
=def wi.waitn,S + τ.abortS

i٨	i٨	i

wait0,S
ij
wait0,S
i٨
=def wj. †S
=def oki. †S
+ killi.abortS



freeS∪{i}(end) =def killi.freeS(end)

free∅(end)	=def end.0

S	=def τ. †S
S	=def τ. †S
+ killi.abortS

abortS
i
=def (end)(freeS(end) | end.ni)

Fig. 5. Self-assembly directly in CCS.

to describe what has to be done, than what has to be undone. Furthermore, it is necessary to prove that the complete code conforms to its specification, and exhibit a bisimulation relation between the code and the specification (given Sec. 2). It is not clear at all how to do this by hand, and to get a sense of how difficult that may be, we have tested our code with the Mobility Workbench [16], a toolkit able to verify certain properties on π-calculus [13] processes. We succeeded in building the bisimulation relation for a system composed of 3 agents. For such a simple system, the Mobility Workbench already returns 600 states. Running the tool for 24 hours was not enough to obtain an answer in the case of a system of 4 agents. 5 The reason for this explosion in the size of the bisimulation is that the backtracking mechanism induces a lot of transitory states that try to undo their local constructions. More details about how the indirect method helps in automated verification can be found in ref. [11].

Conclusion and future work
We have presented a distributed algorithm for self assembling trees using CCS. Part of the appeal of the solution is that both the language used and the solution itself

5 Tests were made with a 1.4 GHz Pentium M with 256 MB of RAM.

stay simple. First one formulates a solution which is only required to be correct in weak sense. One then uses the reversible infrastructure provided by RCCS to obtain correctness. Not only the proof is greatly simplified in so doing, but the actual code obtained is also simpler in that backtracking stays implicit.
Our model leaves aside more subtle forms of self-assembly based on graph- rewriting. These would likely need a more powerful language [7,6], but there seems to be no reason why the decomposition of the self-assembly question advocated in this paper, would not extend to these richer languages. Our model also ignores the question of how one represents real space, in that connections are represented ab- stractly as synchronisations. Another important aspect of self-assembly which our model does not take into account is its quantitative nature, as our model only knows of non-deterministic evolutions, and doesn’t assign to them any measure of their likelihood. More work is needed to understand how both spatial and probabilistic features could be added to the picture. One could think of a distributed language where agents would use timeouts to decide to backtrack. Substituting the RCCS operational semantics to the ordinary CCS one, or whichever richer language one is using, would obtain agents that would behave correctly with respect to the global specification. This requires first a thorough study of the impact of timeouts on the operational semantics of RCCS, a question which we plan to address in future work. Decoupling in a given system the forward and backward components of its be- haviour, is even more natural in the modelling and analysis of biomolecular interac- tions. Indeed, one may regard molecules as blind agents trying to bind haphazardly. Each time their spatial configurations match, proteins have a chance to bind, and these bounds are also frequently broken down. These exploration mechanisms have been argued to be of central importance in the evolvability of biological systems [8]. Here the implicit backtracking mechanism of RCCS comes in handy as a transpar- ent way to model this instability [2], but, if anything, the addition of probabilities to backward moves, so as to generate a quantitative behaviour and be able to tune the backtracking mechanism, seems even more important in this specific context, and it remains to be seen how the method we have illustrated here can cope with
these.

References
Boudol, G. and I. Castellani, Permutation of transitions: An event structure semantics for CCS and SCCS, in: de Bakker, J.W. et al., editors, Linear Time, Branching Time and Partial Order in Logics and Models for Concurrency, LNCS 354 (1989), pp. 411–427.
Danos, V. and J. Krivine, Formal molecular biology done in CCS, in: Proceedings of BIO-CONCUR’03, Marseilles, France, ENTCS (2003), to appear.
Danos, V. and J. Krivine, Reversible communicating systems, in: CONCUR’04, LNCS 3170 (2004),
pp. 292–307.
Danos, V. and J. Krivine, Transactions in RCCS, in: CONCUR’05, LNCS 3653 (2005).
Danos, V., J. Krivine and P. Sobocinski, General reversibility, in: EXPRESS’06, ENTCS (2006), to appear.
Danos, V. and C. Laneve, Formal molecular biology., TCS 325 (2004), pp. 69–110.

Danos, V. and F. Tarissan, Self-assembling graphs, in: J. Mira and J. Alvarez, editors, IWINAC’05, LNCS 3561 (2005), pp. 501–510.
Kirschner, M. and J. Gerhart, Evolvability, PNAS 95 (1998), pp. 8420–8427.
Klavins, E., Automatic synthesis of controllers for assembly and formation forming, in: ICRA’02, 2002,
pp. 3296–3302.
Krivine, J., “Alg`ebres de Processus R´eversibles,” Ph.D. thesis, Universit´e Paris 6 & INRIA- Rocquencourt (2006), moscova.inria.fr/∼ krivine.
Krivine, J., A verification algorithm for declarative concurrent programming, Technical report, INRIA- Rocquencourt (2006), moscova.inria.fr/∼ krivine.
Milner, R., “Communication and Concurrency,” International Series on Computer Science, Prentice Hall, 1989.
Milner, R., J. Parrow and D. Walker, A calculus of mobile process (i and ii), Information and Computation 100 (1992), pp. 1–77.
Palamidessi, C., Comparing the expressive power of the synchronous and asynchronous pi-calculi, MSCS 13 (2003), pp. 685–719.
Phillips, I. and I. Ulidowski, Reversing algebraic process calculi, in: FOSSACS’06, LNCS 3921 (2006),
pp. 246–260.
Victor, B. and F. Moller, The Mobility Workbench — a tool for the π-calculus, in: D. Dill, editor,
CAV’94, LNCS 818 (1994), pp. 428–440.

Appendix
Instead of abstract names, one can use memories as concrete identifiers [3]. We recall in this appendix how this is done, and argue that both the abstract and concrete identifying schemes are in fact intertranslatable. This is useful in so far as the reinterpretation theorem we used earlier was actually proven only for the concrete scheme. A complete proof is in ref. [10, Chap. 3].
Concrete memories are given as:
m ::= ⟨⟩ | ⟨i⟩ · m | ⟨٨, α, p⟩ · m | ⟨m', α, p⟩ · m | ⟨|◦|⟩ · m

where stands for an unknown communication partner, the equivalent of which, in the semantics above, is a θ that is unique to the whole process. The corresponding transition system, shown below, has now labels of the form μ : ζ where μ is a set of one or two memories; rm'@m denotes the substitution of with the concrete identifier m' in ⟨٨, α, p⟩ · m; irreversible rules are not shown.

m Q α.p + q →m:α ⟨٨, α, q⟩ · m Q p	⟨٨, α, q⟩· m Q p →m:α− m Q α.p + q

r →m:a¯ r' s →m':a s'	r →m:a¯− r' s →m':a− s'

r | s →m,m' :τ r' '	| s'	'
rm'@m | sm@m' →m,m' :τ − r' | s'

m @m	m@m


r →μ:ζ r'


r | s →μ:ζ r' | s
r →μ:ζ r' ζ /= a, a¯, a−, a¯−


(a)r →μ:ζ (a)r'

r ≡ r1 →μ:ζ r2 ≡ r' r →μ:ζ r'

Given an abstract process r, and assuming any identifier occurs at most twice in
r, the following defines inductively a map Mr from an abstract process to a concrete

one (all other clauses being trivial):
Mr(⟨|θ|⟩ · m)	= ⟨|◦|⟩ · Mr(m)
⎧⎨ ⟨Mr(m'), α, p⟩ · Mr(m) if ⟨θ, α¯, q⟩ · m' ∈ r

Mr(⟨θ, α, p⟩ · m) = 
⎩ ⟨٨, α, p⟩ · Mr(m)	else

Conversely, given a μ indexed family of identifiers θμ such that θμ /= θμ' if μ∩μ' /= μ, one can map concrete processes to abstract ones (again all other clauses are trivial):
Θ(⟨|◦|⟩ · m)	= ⟨|θ{m} |⟩ · Θ(m)
Θ(⟨m, α, p⟩ · m') = ⟨θ{m,m' }, α, p⟩ · Θ(m')
Θ(⟨٨, α, p⟩ · m)  = ⟨θ{m}, α, p⟩ · Θ(m)

We suppose now all concrete processes have unique memories, and all abstract pro- cesses have identifiers occurring at most twice. This is easily shown to be preserved under computations.
Proposition 7.1 If r →θ:ζ s then ∃μ : Mr(r) →μ:ζ Ms(s) and if r →μ:ζ s then
∃θ : Θ(r) →θ:ζ Θ(s).
For the first implication: if r →θ:τ s, take μ = {Ms(m1), Ms(m2)} where ⟨θ, a, p⟩ · m1, ⟨θ, a¯, q⟩ · m2 ∈ s; if r →θ:τ− s, take μ = {Mr(m1), Mr(m2)} where ⟨θ, a, p⟩ · m1, ⟨θ, a¯, q⟩ · m2 ∈ r. For the second implication, it suffices to take θ = θμ. The side condition in the par rule (see Fig. 4) holds thanks to the unicity of memories and the assumption that θμ /= θμ' whenever μ ∩ μ' /= μ.
