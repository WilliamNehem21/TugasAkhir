Electronic Notes in Theoretical Computer Science 48 (2001)
URL: http://www.elsevier.nl/locate/entcs/volume48.html pp. 1 – 26


Probabilistic behaviours of reactive agents

Antonio Brogi 1
Dipartimento di Informatica Universit`a di Pisa
Pisa, Italy


Abstract
We present a simple logic-based formalisation of the behaviours of agents capable of reacting to changes occurring in the external environment. Logic programming is chosen as the specification language of agents, and a quantitative analysis of the behaviours of reactive agents is described.


Introduction
Rationality and reactivity are two capabilities of primary importance in multi- agent systems. Agents must be able to exhibit a rational behaviour as well as to promptly and adequately react to changes occurring in the external environment.
One of the problems is that while developing a reactive agent, the environ- ment in which the agent will operate is at least partially unknown. Typically, even if the set of possible observable behaviours of the environment is known, the precise dynamic behaviour of the environment is not predictable at soft- ware development time. On the other hand, the availability of a well-founded description of the possible behaviours of a reactive program is crucial for per- forming tasks such as verification and analysis before putting the program at work with the external environment.
In this paper, we will describe a simple logic-based formalisation of the behaviours of agents that feature a combination of rational and reactive capa- bilities. We choose logic programming as the specification language of agents. Logic programming supports a declarative, high-level programming style (from algorithmic programming to databases to artificial intelligence applications) via a small number of powerful features: Nondeterminism, unification, and re- cursion. Moreover, because of their operational interpretation, logic programs can be viewed as high-level, executable specifications of reactive programs.

1 Email: brogi@di.unipi.it
◯c 2001 Published by Elsevier Science B. V. Open access under CC BY-NC-ND license.


We first show, following [4], how the possible behaviours of an agent react- ing to different environments at different times can be modeled by means of a mapping over sets of Herbrand interpretations. The obtained formal char- acterisation of the possible behaviours of reactive programs provides a firm basis for reasoning about them.
For instance, one of the properties of interest in the practice of multi- agent systems is whether a reactive agent may be able to possibly derive certain conclusions depending on the evolution of the external environment. The dual property is even more important for many applications, especially for critical ones. Namely the agent behaviour should satisfy certain mandatory requirements independently of the way in which the external environment will evolve. The notions of possible beliefs and invariant of a program were introduced in [4] to formally characterise such properties, and different ways of combining rationality and reactivity were compared one another on that basis.
The aim of this paper is to introduce quantitative aspects in the analysis of the possible behaviours of reactive agents. We start from the observation that, while the evolution of the external environment is not known a priori, some environment perceptions are indeed more probable than others. The above observation suggests that taking into account the probabilities associ- ated with environment perceptions paves the way for a probabilistic — rather than possibilistic — analysis of the behaviours of reactive agents.
We show how the formal setting introduced in [4] can be smoothly extended to model probabilistic behaviours of agents. We then introduce the notions of probabilistic beliefs and probabilistic invariant that can be exploited to perform effective, resource bounded analyses of the probabilistic behaviours of reactive agents.
Background
We will use standard notions and terminology of logic programming [3]. Since we will focus on bottom-up computations of deﬁnite logic programs, which are formally defined via the so-called immediate consequence operator T (P ), we recall here the definition of that operator.
Definition 2.1 Given a logic program P and a Herbrand interpretation I, the immediate consequence operator T (P ) is the mapping defined as follows:
T (P )(I)= {A | ∃B : A ← B ∈ ground(P ) ∧ B ⊆ I}

where B is a (possibly empty) set of atoms, and where ground(P ) denotes the set of ground instances of clauses of program P .	✷
The set T (P )(I) denotes the set of conclusions that a program P is able to derive, in a single computation step, from a set of premises I which are assumed to hold. The powers of T (P ) are defined in the standard way:

T 0(P )(I)= I
Tn+1(P )(I)= T (P ) (T n(P )(I))
Tω(P )(I)= [ T i(P )(I)
i∈ω
T (P ) is a continuous mapping from (Herbrand) interpretations to (Herbrand) interpretations and the power set P(B) of the Herbrand base B is a complete lattice under set inclusion. The immediate consequence operator has therefore a least fixpoint which coincides with the union of the finite powers of T (P ) applied to the bottom element ∅, namely: lfp(T (P )) = Tω(P )(∅).

Modeling reactive programs
Environment representation
Agents have a partial representation of the external environment and limited capabilities of interacting with it. An agent typically represents the external environment in terms of its individual perceptions of the environment. The type of such perceptions of course depends on the sensing capabilities owned by the agent.
We will focus on the way in which the behaviour of an agent may be influ- enced by its perceptions of the external environment, rather than on the way in which the agent will get such perceptions. For instance, we will abstract from the way in which a software agent accesses some piece of information available in the external environment (e.g., by receiving a message, by downloading a file, or by getting data from physical sensors).
At each moment, the external environment is hence represented by the perceptions of the agent. When agents are specified by logic programs, en- vironment perceptions can be naturally represented as Herbrand interpreta- tions. Moreover, while an agent is performing its computation, the external environment may arbitrarily and independently evolve. We therefore define an environment representation as follows.
Definition 3.1 An environment representation is a (possibly infinite) family
E = {E1, E2, E3,.. .}
of perceptions, where each perception Ei is a Herbrand interpretation.	✷
Intuitively speaking, a Herbrand interpretation Ei represents the percep- tion of the external environment that the agent may have at a given moment. Logically speaking, Ei represents a set of formulae that a program P may assume to be true when it performs a computation step by reacting to the current environment perceived as Ei.
The assumption that the environment may arbitrarily change during the program computation is mirrored by the flat structure of an environment

representation, which is a set of possibly non-related interpretations. (Namely there may exist pairs of environment perceptions which are not comparable one another under set-theoretic inclusion.)
Program behaviours
As shown in [4], the behaviour of a reactive program can be formally defined by means of a continuous mapping Tϕ over sets of interpretations, whose least fixpoint characterises the set of all possible behaviours of a program reacting to different environments at different times.
The formal definition of the mapping Tϕ is given by extending the standard immediate consequence operator T (P ) in two steps:
First to take into account the external environment, and
then to consider sets of interpretations.
Let us first consider how environment perceptions can be taken into account in the formalisation of the bottom-up behaviour of a program. At each com- putation step, a program may react to the environment, that is, to one of the environment perceptions in the environment representation E . We corre- spondingly introduce the set of extended immediate consequences ϕ(P )(I, E) of a program P , starting from a set of atoms I assumed to be true and reacting to an environment perception E. Namely, for each program P , the mapping ϕ(P ) given a pair of interpretations yields a single interpretation:
ϕ(P ): P(B) × P(B) → P(B).
The mapping ϕ(P ) defines the way in which a program P takes into account an environment perception when performing a deduction step. Different ways of defining ϕ(P ) are presented and compared in [4]. We will introduce here the simplest, and perhaps most natural, definition of ϕ(P ).
Definition 3.2 Let P be a program. For each Herbrand interpretation I and each environment perception E, we put:
ϕ(P )(I, E) = T (P )(I ∪ E).
✷
Namely the set ϕ(P )(I, E) is the set of consequences that P may draw in one deduction step by assuming the set of formulae (I ∪ E) to be true.
Example 3.3 Consider for instance a walking robot that controls its walking speed on the base of its perception of the weather. Suppose that the robot can move at two different speeds (slow or fast), and that it is able to perceive three weather conditions (sun, rain and snow). A natural specification of the speed control is to move slowly when it rains, to move fast when it is sunny, and not to move when it is snows. The speed control of such a robot can then be described by the following program P :

Slow <- Still, Sun Slow <- Still, Rain Still <- Still, Snow
Fast <- Slow, Sun Slow <- Slow, Rain Still <- Slow, Snow
Fast <- Fast, Sun Slow <- Fast, Rain Still <- Fast, Snow
where the set of environment perceptions is E = { {Sun},{Rain},{Snow} }.
If the robot is still then the effect of the environment perception {Rain}
is:
ϕ(P )({Still}, {Rain})= {Slow}.
If we now consider the situation in which the robot is walking slowly and the environment perception is {Sun} we have:
ϕ(P )({Slow}, {Sun})= {Fast}.
✷
The second extension to the immediate consequence operator consists of moving from interpretations to sets of interpretations. Indeed we want to model all possible computations of a program that may react to different en- vironment perceptions at different steps. To this end, we introduce an operator Uϕ over sets of Herbrand interpretations whose intuitive meaning is to collect the set of all possible (one-step) reactive deductions of a program starting from a set of possible interpretations and from a set of possible environment perceptions.
Definition 3.4 Given a program P , a set of Herbrand interpretations I, and an environment representation E , the mapping Uϕ is defined as follows:
Uϕ(P, E )(I) = { J | ∃E ∈ E,I ∈I : J = ϕ(P )(I, E) }.
✷
Intuitively speaking, the set of interpretations Uϕ(P, E )(I) denotes the set of all possible one-step “ϕ-evolutions” of P starting from the set I of hypotheses and reacting to one of the environment perceptions in E .
Notice that the definition of Uϕ is parametric w.r.t. the object mapping ϕ over Herbrand interpretations. If we unfold the above definition of Uϕ by using the formulation of ϕ given in Definition 3.2, we obtain:
Uϕ(P, E )(I)= { J | ∃E ∈ E,I ∈I : J = T (P )(I ∪ E) }.


Example 3.5 Consider again the simple program P and the environment rep- resentation E = { {Sun},{Rain},{Snow} } of example 3.3. We have that:
Uϕ(P, E )({{Still}}) = {{Still}, {Slow}}
and
Uϕ(P, E )({{Still}, {Slow}}) = {{Still}, {Slow}, {Fast}}.	✷

An inflationary version Tϕ of the Uϕ operator was introduced in [4] in order to obtain a fixpoint characterisation of the set of all possible reactive behaviours of a program. Namely:
Tϕ(P, E )(I) = I∪ Uϕ(P, E )(I)
The operator Tϕ(P, E ) is defined in [4] as a mapping over sets of inter- pretations, whose domain D is the power set of the power set of B without least element 2 . As shown in [4], (D, ⊆) is a cpo without bottom element, the mapping Tϕ(P, E ) is continuous on (D, ⊆), for each mapping ϕ, and therefore Tϕ(P, E ) has a least fixpoint.
The powers of (Uϕ and) Tϕ are defined in the standard way:
T 0(P, E )(I)= I
T n+1(P, E )(I)= Tϕ(P, E ) (T n(P, E )(I))
ϕ	ϕ
T ω(P, E )(I)= [ T i(P, E )(I)
ϕ	ϕ
i∈ω
Moreover, as shown in [4], the least fixpoint of Tϕ(P, E ) can be computed by repeatedly applying Tϕ(P, E ) to some initial element of the domain D. Namely, for each P , E and I:
[ T i(P, E )(I) = min{J | J = Tϕ(P, E )(J ) ∧I ⊆ J }.
i∈ω

That is, for each initial set I0 of interpretations, the least fixpoint of Tϕ(P, E ) greater than or equal to I0 can be computed by repeatedly applying Tϕ(P, E ) starting from the initial set of interpretations I0.
As illustrated in [4], the information contained in the least fixpoint of Tϕ(P, E )(I) can be analysed by viewing the least fixpoint as a directed graph whose nodes are the interpretations in the least fixpoint and where labelled edges denote relations between interpretations. More precisely, the graph contains a directed edge labelled E from node I to node J if and only if J = ϕ(P )(I, E). Namely an edge from I to J indicates that program P may derive the set J of consequences by means of a ϕ step starting from

2  The least element of P(P(B)) (viz., the empty set of interpretations) is not included in the domain since it is not a sensible argument for the Tϕ operator. Indeed, intuitively speaking, the situation “nothing is assumed to be true in the environment” corresponds to the singleton set {∅} containing only the empty interpretation, rather than to the empty set {} of interpretations.


I and reacting to the environment perception E. For instance, the graph representation of the least fixpoint of Tϕ(P, E )({Still}) for program P of example 3.3 is illustrated in figure 1.


✛Snow✘

✛Rain✘

✛Sun ✘


✤✗❄

✣✖
Rain Sun✲


✕✢Snow
✤❄
Slow


Sun✲
✛	
✢Rain
✤❄	✜
Fast


✻ 	
Snow

Fig. 1. Possible behaviours of the walking robot of example 3.3


Probabilistic behaviours of reactive agents
Motivating example
Consider an agent gambling at a roulette table. Suppose that the strategy of the agent simply consists of gambling one dollar on the red colour at each turn. Since colour bets are paid 1:1, the agent will either win or loose one dollar for each bet.
The behaviour of such an agent is specified by the following program P :
Holds(S(S(x))) <- Holds(S(x)), Red Holds(x)	<- Holds(S(x)), Black Holds(Zero)	<- Holds(Zero)
where the set of possible environment perceptions is E = { {Red},{Black} }. Suppose that the initial budget of the agent is 100$. After the first round the agent will have either 99$ or 101$, depending on the result of wheel re- volvement. After the second round the agent will have 98$, 100$, or 102$, and so on and so forth. The possible behaviours of the agent are illustrated by the
graph of Figure 2 denoting the least fixpoint of Tϕ(P, E )({{Holds(100)}}).

... ✗

✔Red✲ ✗

✔Red✲ ✛✗

✔✘Red✲ ✗

✔Red✲ ✗

✔...

H(98) ✛		H(99) ✛	
H(100) ✛		H(101) ✛	
H(102)


		
✖	✕Black✖
 	 
✕Black✚✖	✕✙Black✖

		
✕Black✖	✕


Fig. 2. Possible behaviours of the roulette player
This example highlights that while the mapping Tϕ supports the analysis of the possible behaviours of a reactive agent, it does not give any information on the probabilistic behaviours of the agent.
In order to perform a probabilistic analysis of the behaviours of P , we can make some assumptions on the probabilities of the environment perceptions.

Formally, this corresponds to introducing a probability distribution δ on E , that is, a total mapping δ from E to [0,1] such that  E∈E δ(E)= 1.
The obvious values of δ for this example 3 are
δ({Red})= .5 and δ({Black})= .5.
We observe that, according to the above distribution δ, after the first round the agent will have 99$ with probability .5 and 101$ with probability .5. After the second round, the agent will have 98$ with probability .25, 102$ with probability .25, and the initial amount of 100$ with probability .5, and so on and so forth, as illustrated by the following table:

The example suggests that taking onto account the probabilities induced by the environment perceptions may pave the way for a probabilistic analysis of agent behaviours.

From interpretations to probabilistic interpretations
We now show how the setting introduced in Section 3 can be smoothly ex- tended in order to account for a probabilistic (rather than possibilistic) anal- ysis of the behaviours of a reactive agent.
Intuitively speaking, we will associate probabilities to interpretations and we will consider mappings over (sets of) pairs:
⟨interpretation, associated-probability⟩.
As a first step, we introduce the notion of probabilistic interpretation. A prob- abilistic interpretation is simply a Herbrand interpretation with a probability associated with it.
Definition 4.1 A probabilistic interpretation is a pair ⟨I, p⟩ where I ⊆B and
p ∈ (0, 1].	✷

3 For the sake of simplicity, we do not consider here the presence of “zero” on the wheel.
Modern wheels contain two “zero” so that the probability of a red number is 16 rather than
38
16 , but this is not relevant in the scope of our discussion.


In the previous section, we have informally discussed the idea of associating a probability distribution with the set of environment perceptions of an agent. Following Definition 4.1, a probabilistic environment representation can be now formally defined as a set of probabilistic interpretations. We will consider sets of probabilistic interpretations such that the probabilities associated with the interpretations form a probability distribution, as stated by the following definition.
Definition 4.2 A set Sπ of probabilistic interpretations is complete if and only if  ⟨I,p⟩∈Sπ p = 1.	✷
Definition 4.3 A probabilistic environment representation
Eπ = {⟨E1, p1⟩, ⟨E2, p2⟩, ⟨E3, p3⟩,.. .}
is a complete set of probabilistic interpretations.	✷
For instance the probabilistic environment representation for the example discussed in section 4.1 is: Eπ = {⟨{Red}, .5⟩, ⟨{Black}, .5⟩}.
In Section 3 we introduced the mapping ϕ(P ) to model the way in which a program P reacts to a program perception E given a set of hypotheses I. Formally, the mapping ϕ(P ) given a pair of interpretations returns a single interpretation:
ϕ(P ): P(B) × P(B) → P(B).
Namely ϕ(P )(I, E) is the set of immediate consequences derived by program P starting from a set I of atoms assumed to be true and reacting to the environment perception E.
The mapping ϕ can be naturally extended to probabilistic interpretations:
ϕπ(P ): (P(B) × (0, 1]) × (P(B) × (0, 1])	→ (P(B) × (0, 1])
as follows.
Definition 4.4 Let P be a program. For each pair of probabilistic interpre- tations ⟨I, p⟩ and ⟨E, q⟩:
ϕπ(P )(⟨I, p⟩, ⟨E, q⟩)= ⟨ϕ(P )(I, E) , p × q⟩.
✷
Namely, given two probabilistic interpretations ⟨I, p⟩ and ⟨E, q⟩, the map- ping ϕπ(P ) returns the probabilistic interpretation consisting of the interpre- tation ϕ(P )(I, E) with associated probability (p×q). For instance, considering program P of Section 4.1:
ϕπ(P )(⟨{Holds(100)}, 1⟩, ⟨{Black}, .5⟩)= ⟨{Holds(99)}, .5⟩
ϕπ(P )(⟨{Holds(99)}, .5⟩, ⟨{Red}, .5⟩)= ⟨{Holds(100)}, .25⟩
ϕπ(P )(⟨{Holds(99)}, .5⟩, ⟨{Black}, .5⟩)= ⟨{Holds(98)}, .25⟩


The reason why the probabilities of I and E are multiplied in order to de- termine the probability associated with the interpretation ϕ(P )(I, E) will be better understood after introducing the collecting mapping Vϕπ . Intuitively speaking, the reason is that given two complete sets of probabilistic interpreta- tions Iπ and Eπ, the result of applying ϕπ(P ) to each pair in (Iπ×Eπ) should re- turn a complete set Jπ of probabilistic interpretations, namely	⟨J,p⟩∈Jπ p = 1. Typically an agent will start its computation from a complete set of prob- abilistic interpretations that consists of a single interpretation with associ- ated probability 1. For instance, in the case of the roulette playing agent of Section 4.1, the initial situation in which the agent starts playing with a budget of 100$ corresponds to the set of probabilistic interpretations: Iπ =
{⟨{Holds(100)}, 1⟩}.
It is worth noting that the initial set of interpretations may indeed contain more than just one probabilistic interpretation. For instance, determining the amount of the initial budget to bet may be the result of some other reactive computation of the gambling agent. A probabilistic analysis of such a computation may indicate for instance that the initial budget of the agent will be either 100$ or 200$ with the same probability. Such a situation can be represented by considering Iπ = {⟨{Holds(100)}, .5⟩, ⟨{Holds(200)}, .5⟩} as the initial set of probabilistic interpretations.

Probabilistic behaviours
We now introduce an operator Vϕπ overs sets of probabilistic interpretations in order to collect the set of all possible (one-step) reactive deductions of a program P given a set of probabilistic hypotheses and a set of probabilistic environment perceptions. Formally the operator Vϕπ maps pairs of sets of probabilistic interpretations into sets of probabilistic interpretations.
Consider again, for instance, program P of section 4.1 together with the probabilistic environment representation Eπ = {⟨{Red}, .5⟩, ⟨{Black}, .5⟩}. In- tuitively speaking, the set Vϕπ (P, Eπ)(Iπ) will contain the probabilistic in- terpretations obtained by applying ϕπ(P ) to the probabilistic interpretation
⟨{Holds(100)}, 1⟩ and to the two environment perceptions in Eπ. Namely:
Vϕπ (P, Eπ)(Iπ)= {⟨{Holds(99)}, .5⟩, ⟨{Holds(101)}, .5⟩}.
It is important to note that the mapping ϕπ(P ) is not injective, that is, it may well happen that:
ϕπ(P )(⟨I1, p1⟩, ⟨E1, q1⟩)= ϕπ(P )(⟨I2, p2⟩, ⟨E2, q2⟩)
for two different pairs of probabilistic interpretations. For this reason, a direct set-theoretic definition of Vϕπ (P, Eπ)(Iπ) as:
{⟨J, r⟩| ∃⟨E, q⟩∈ Eπ, ⟨I, p⟩∈ Iπ : ⟨J, r⟩ = ϕπ(P )(⟨I, p⟩, ⟨E, q⟩)}


would not properly collect the results of applying ϕπ(P ) to all the elements in (Iπ × Eπ). For instance, the above definition would imply that:
Vϕπ (P, Eπ)({⟨{Holds(99)}, .5⟩, ⟨{Holds(101)}, .5⟩})
=
{⟨{Holds(98)}, .25⟩, ⟨{Holds(100)}, .25⟩⟨{Holds(102)}, .25⟩}
by incorrectly ignoring that the same probabilistic interpretation
⟨{Holds(100)}, .25⟩
is produced twice by two different applications of ϕπ, viz., by
ϕπ(P )(⟨{Holds(99)}, .5⟩, ⟨{Red}, .5⟩)
and by
ϕπ(P )(⟨{Holds(101)}, .5⟩, ⟨{Black}, .5⟩)).

We therefore define the operator Vϕπ in two steps.
We first define a multi-set Mϕπ (P, Eπ)(Iπ) containing all the probabilis- tic interpretations obtained by applying the ϕπ operator to all pairs of probabilistic interpretations in (Iπ × Eπ).
We then define the Vϕπ operator in terms of the multi-set Mϕπ (P, Eπ)(Iπ). Intuitively speaking, the set Vϕπ (P, Eπ)(Iπ) is obtained by transforming the multi-set Mϕπ (P, Eπ)(Iπ) into a set where all the probabilities asso- ciated with the same interpretation are summed.
Definition 4.5 Given a program P and two sets Iπ and Eπ of probabilistic interpretations:

Mϕπ (P, Eπ)(Iπ)= {| ⟨J, r⟩| ∃⟨E, q⟩∈ Eπ, ⟨I, p⟩∈ Iπ :
⟨J, r⟩ = ϕπ(P )(⟨I, p⟩, ⟨E, q⟩) |}

Vϕπ (P, Eπ)(Iπ)= {⟨N, sN ⟩| sN = Σ{r | ⟨J, r⟩∈ Mϕπ (P, Eπ)(Iπ) ∧ J = N}
∧
sN > 0	}.

✷
Consider for instance again the gambling agent of Section 4.1. We now have that:
Mϕπ (P, Eπ)({⟨{Holds(99)}, .5⟩, ⟨{Holds(101)}, .5⟩}) =
{| ⟨{Holds(98)}, .25⟩, ⟨{Holds(100)}, .25⟩,
⟨{Holds(100)}, .25⟩, ⟨{Holds(102)}, .25⟩ |}

and:
Vϕπ (P, Eπ)({⟨{Holds(99)}, .5⟩, ⟨{Holds(101)}, .5⟩}) =
{ ⟨{Holds(98)}, .25⟩, ⟨{Holds(100)}, .5⟩, ⟨{Holds(102)}, .25⟩ }.

The powers of the Vϕπ operator are defined as usual:
0  (P, Eπ)(Iπ)= Iπ
Vn+1(P, Eπ)(I)π = Vϕ (P, Eπ) (Vn (P, Eπ)(Iπ))
Examples
Example 4.6 Consider again the gambling agent P described in Section 4.1:
Holds(S(S(x))) <- Holds(S(x)), Red Holds(x)	<- Holds(S(x)), Black Holds(Zero)	<- Holds(Zero)
together with the probabilistic environment description:
Eπ = {⟨{Red}, .5⟩, ⟨{Black}, .5⟩}
and the initial set of probabilistic interpretations:
Iπ = {⟨{Holds(100)}, 1⟩}.
Given the initial set of probabilistic interpretations Iπ and the probabilistic environment description Eπ, the operator Vϕπ (P, Eπ)(Iπ) will determine the probabilistic behaviours of the gambling agent under the specified hypotheses, as illustrated by Table 1 showing the powers of Vϕπ (P, Eπ)(Iπ).
Table 1

✷
Example 4.7 Consider again the walking robot described in Example 3.3. The robot used the following program P :
Slow <- Still, Sun
Slow <- Still, Rain

Still <- Still, Snow
Fast <- Slow, Sun
Slow <- Slow, Rain
Still <- Slow, Snow
Fast <- Fast, Sun
Slow <- Fast, Rain
Still <- Fast, Snow
to control its walking speed on the base of its perceptions of the weather, where the set of environment perception is E = { {Sun},{Rain},{Snow} }.
In order to further analyse the behaviour of the agent, we may make some further assumptions on the probabilities of the environment perceptions. For instance, we may assume that the robot will operate in an environment where snow is a quite rare event, while sun and rain alternate one another with sun slightly prevailing over rain. The assumption that in each moment the weather will be sunny with .5 probability, rainy with .4 probability and snowing with
.1 probability is formalised by the probabilistic environment description:
Eπ = {⟨{Sun}, .5⟩, ⟨{Rain}, .4⟩, ⟨{Snow}, .1⟩}
while the assumption that the robot is initially still is modelled by the initial set of probabilistic interpretations:
Iπ = {⟨{Still}, 1⟩}.

Given the initial set of probabilistic interpretations Iπ and the probabilistic environment description Eπ, the operator Vϕπ (P, Eπ)(Iπ) will determine the probabilistic behaviours of our walking robot under the specified hypotheses, as illustrated by Table 2 showing the powers of Vϕπ (P, Eπ)(Iπ). Table 2 shows that for the given probabilistic environment description, at any step n ≥ 2 the robot will be walking slow with probability .45, walking fast with probability
.45, and still with probability .1.
Table 2



The formal characterisation provided by the Vϕπ operator is particularly useful to reason on different probabilistic behaviours of reactive agents. Sup- pose for instance that the robot designers want to evaluate whether improving the stability of the robot may effectively lead to having the robot walk faster, given the environment in which it will operate. Simply stated, the question of the engineers is something like: Is it worth the effort of improving the stability the robot ? Will it really walk faster in that environment ?
At the software level, re-programming the speed control policy may simply amount to modifying clauses (5), (8) and (9) of the previous program as follows:
Slow <- Still, Sun
Slow <- Still, Rain
Still <- Still, Snow
Fast <- Slow, Sun (5’)	Fast <- Slow, Rain
Still <- Slow, Snow
Fast <- Fast, Sun (8’)	Fast <- Fast, Rain (9’)	Slow <- Fast, Snow
The new possibilistic behaviours of the agent are synthesised in the graph of Figure 3. Such graph does not however provide an answer to the question of the robot engineers.
Given the initial set of probabilistic interpretations Iπ and the probabilistic environment description Eπ, the operator Vϕπ (P, Eπ)(Iπ) can be used to de- termine the probabilistic behaviours of the walking robot under the specified hypotheses, as illustrated by Table 3 showing the powers of Vϕπ (P, Eπ)(Iπ). Table 3 shows that because of the new speed control, the probabilities with which the robot will be walking slow, fast, or be still, will vary at each step. More precisely, the table shows that the larger the number of steps the higher is the probability that the robot will be walking fast.


✛Snow✘
Rain
✛Sun ✘

✤✗❄

✣✖
Rain Sun✲


✕✢Snow
✤
Slow


Rain Sun✲
✛	
✢Snow
✤❄	✜
Fast



Fig. 3. New possible behaviours of the walking robot

✷


Table 3

Probabilistic analysis of reactive agents
Before discussing the probabilistic analysis of the behaviour of reactive agents, let us present some properties of the Vϕπ operator introduced in Section 4.3.
Properties
We first prove that if Iπ and Eπ are two complete sets of probabilistic in- terpretations, then Vϕπ (P, Eπ)(Iπ) is also a complete set of probabilistic in- terpretations, namely, the probabilities associated with the interpretations in Vϕπ (P, Eπ)(Iπ) form a probability distribution.
Proposition 5.1 For each program P,for each complete sets of probabilistic interpretations Eπ and Iπ:
Vϕπ (P, Eπ)(Iπ) is a complete set of probabilistic interpretations.
Proof. We have to show that:
Σ{p | ⟨I, p⟩∈ Vϕπ (P, Eπ)(Iπ)} = 1.
By definition of Mϕπ we have that:
Mϕπ (P, Eπ)(Iπ)= {| ⟨J, r⟩| ∃⟨E, q⟩∈ Eπ, ⟨I, p⟩∈ Iπ :
⟨J, r⟩ = ϕπ(P )(⟨I, p⟩, ⟨E, q⟩) |}
Since Eπ and Iπ are both complete sets of probabilistic interpretations by hypothesis, we have that:
Σ{p | ⟨I, p⟩∈ Iπ} = 1 and  Σ{q | ⟨E, q⟩∈ Eπ} =1 



therefore:

Σ{| r | ∃⟨E, q⟩∈ Eπ, ⟨I, p⟩∈ Iπ : r = p × q |} =1 

and hence:
{p | ⟨I, p⟩∈ Mϕπ (P, Eπ)(Iπ)} = 1.
Since for each P , Eπ and Jπ:
Σ{p | ⟨I, p⟩∈ Mϕπ (P, Eπ)(Jπ)} = Σ{p | ⟨I, p⟩∈ Vϕπ (P, Eπ)(Jπ)}
we have that:
{p | ⟨I, p⟩∈ Vϕπ (P, Eπ)(Iπ)} = 1.
✷
The immediate corollary of the above proposition is that Vn (P, Eπ)(Iπ) is a complete set of probabilistic interpretations for each value of n, when- ever the environment representation Eπ and the initial Iπ are complete sets of probabilistic interpretations.
Corollary 5.2 For each program P, for each complete sets of probabilistic interpretations Eπ and Iπ,and for each n:
Vn (P, Eπ)(Iπ) is a complete set of probabilistic interpretations.
Proof. The proof is by induction on n.
(Base case) For n = 0 the assertion holds trivially by definition of the

powers of Vϕπ
, since V0
(P, Eπ)(Iπ)= Iπ and since Iπ is a complete set of

probabilistic interpretations by hypothesis.
(Inductive case) Suppose that Vn (P, Eπ)(Iπ) is a complete set of prob- abilistic interpretations. Then Vn+1(P, Eπ)(Iπ) is also a complete set of probabilistic interpretations by Proposition 5.1 since:


Vn+1(P, Eπ)(Iπ) = Vϕ
(P, Eπ) (Vn (P, Eπ)(Iπ)).
✷


It is now worth formally establishing the existing tight correspondence be- tween the interpretations computed by the non-probabilistic operator Uϕ in- troduced in Section 3.2 and the probabilistic interpretations computed by the probabilistic operator Vϕ introduced in Section 4.3.
Informally, the following Proposition 5.3 states that if an Herbrand inter- pretation I is obtained by repeatedly applying Vϕπ to an initial set of prob- abilistic interpretations Iπ, then the same interpretation I can be obtained by applying the same number of times Uϕ to the set of Herbrand interpreta- tions contained in Iπ. To simplify notation, we will denote by Iπ/ the set of Herbrand interpretations contained in a set Iπ of probabilistic interpretations, that is: Iπ/= {I | ⟨I, p⟩∈ Iπ}.


Conversely, Proposition 5.4 establishes that any Herbrand interpretation obtained by repeatedly applying Uϕ to an initial set of interpretations I is also obtained by applying the same number of times Vϕπ to any initial set of probabilistic interpretations Iπ such that I/π= I.
Proposition 5.3 For each program P,for each sets of probabilistic interpre- tations Eπ and Iπ,and for each n:
⟨I, p⟩∈ Vn (P, Eπ)(Iπ) =⇒ I ∈ Un(P, Eπ/)(Iπ/)
ϕπ	ϕ
Proof. The proof is by induction on n:
(Base case) The base case (n = 0) trivially holds by definition of the powers of Vϕπ and Uϕ:
⟨I, p⟩∈ V0 (P, Eπ)(Iπ)
⇔	{ by definition of powers of Vϕπ }
⟨I, p⟩∈ Iπ
⇒	{ by definition of I/π }
I ∈ I/π
⇔	{ by definition of powers of Uϕ }
I ∈ U 0(P, Eπ/)(Iπ/).
(Inductive case)
⟨I, p⟩∈ Vn+1(P, Eπ)(Iπ)
⇔	{ by definition of powers of Vϕπ }
n
⟨I, p⟩∈ Vϕπ (P, Eπ) (V	(P, Eπ)(Iπ))
⇒	{ by definition of Vϕπ }
∃⟨E, q⟩∈ Eπ, ⟨J, r⟩∈ Vn (P, Eπ)(Iπ),s :	⟨I, s⟩ = ϕπ(P )(⟨J, r⟩, ⟨E, q⟩)
⇒	{ by definition of ϕπ }
∃⟨E, q⟩∈ Eπ, ⟨J, r⟩∈ Vn (P, Eπ)(Iπ):	I = ϕ(P )(J, E)
⇒	{ by definition of E/πand by inductive hypothesis }
∃E ∈ E/,πJ ∈ Un(P, E/π)(Iπ/):	I = ϕ(P )(J, E)
⇒	{ by definition of Uϕ }
I ∈ Uϕ(P, Eπ/)(Un(P, Eπ/)(I/π))
⇔	{ by definition of powers of Uϕ }
I ∈ Un+1(P, E/)π(I/)π
✷
Proposition 5.4 For each program P,let E and I be two sets of interpreta- tions and let Eπ and Iπ be two sets of probabilistic interpretations such that E/π = E and I/π= I. Then for each n:
I ∈ Un(P, E )(I) =⇒ ∃p : ⟨I, p⟩∈ Vn (P, Eπ)(Iπ)
ϕ	ϕπ
Proof. The proof is by induction on n:
(Base case) The base case (n = 0) trivially holds by definition of the powers of Vϕπ and Uϕ:

I ∈ U 0(P, E )(I)
⇔	{ by definition of powers of Uϕ }
I ∈I 
⇒	{ since I/π= I } 
∃p : ⟨I, p⟩∈ Iπ
⇔	{ by definition of powers of Vϕπ }
∃p : ⟨I, p⟩∈ V0 (P, Eπ)(Iπ)
(Inductive case)
I ∈ Un+1(P, E )(I)
⇔	{ by definition of powers of Uϕ }
I ∈ Uϕ(P, E ) (U n(P, E )(I))
⇒	{ by definition of Uϕ }
∃E ∈ E,J ∈ Un(P, E )(I):	I = ϕ(P )(J, E)
⇒	{ since E/π= E and by inductive hypothesis }
∃⟨E, q⟩∈ Eπ, ⟨J, r⟩∈ Vn (P, Eπ)(Iπ):	I = ϕ(P )(J, E)
⇒	{ by definition of ϕπ }
∃⟨E, q⟩∈ Eπ, ⟨J, r⟩∈ Vn (P, Eπ)(Iπ),p :	⟨I, p⟩ = ϕπ(P )(⟨J, r⟩, ⟨E, q⟩)
⇒	{ by definition of Vϕπ }
n
∃p : ⟨I, p⟩∈ Vϕπ (P, Eπ) (V	(P, Eπ)(Iπ))
⇔	{ by definition of powers of Vϕπ }
∃p : ⟨I, p⟩∈ Vn+1(P, Eπ)(Iπ)
✷

Probabilistic beliefs
The availability of a formal characterisation of the probabilistic behaviours of reactive programs provides a firm ground for reasoning about them.
One of the properties of interest in the practice of multi-agent systems is which are the conclusions that the agent may draw by reacting to the external environment, the evolution of the latter being a priori unknown. The notion of possible beliefs was introduced in [4] to formally characterise the set of conclusions that a program P may possibly draw, starting with an initial set of interpretations I and reacting to a set of environment perceptions E . An effective, resource bounded characterisation of the possible beliefs of a program after n steps of computation can be formalised as follows.
Definition 5.5 Let P be a program, let I and E be two sets of interpretations, and let n > 0. We put:
PB(P, E, I, n) = {A | I ∈ Un(P, E )(I) ∧ A ∈ I}.
✷
Namely PB(P, E, I, n) denotes the set of conclusions that program P may
possibly derive after n steps, starting with an initial set of interpretations I

and reacting to a set of environment perceptions E .
For instance, for the walking robot described in Example 3.3, we have that PB(P, E, I, n)= {Still, Slow, Fast} for each n ≥ 2. Notice that possible be- liefs are defined in terms of the possibilistic collecting operator Uϕ, which does not take into account the probabilities that may be associated with environ- ment perceptions. For instance, while in Example 4.7 we have shown that a revised control speed program for the robot does exhibit different probabilistic behaviours, the two programs have the same set of possible beliefs.
We therefore introduce the notion of probabilistic beliefs of a program P that starts with an initial set of probabilistic interpretations Iπ and reacts to a set of probabilistic perceptions Eπ. Probabilistic beliefs associate each possible belief with a corresponding probability as formalised by the following definition.
Definition 5.6 Let P be a program, let Iπ and Eπ be two sets of probabilistic interpretations, and let n > 0. We put:
ΠB(P, Eπ, Iπ, n) = {(A, p) | p = Σ{q | ⟨I, q⟩∈ Vn (P, Eπ)(Iπ) ∧ A ∈ I}
∧
p > 0	}.
✷
Namely ΠB(P, Eπ, Iπ, n) denotes the set of atoms that program P may derive in n steps starting from Iπ and reacting to Eπ. The probability associ- ated with each atom A is the sum of the probabilities of all the probabilistic interpretations in which A occur.
For instance, in the case of the walking robot described in Example 3.3, the set of probabilistic beliefs after 10 steps is:
ΠB(P, Eπ, Iπ, 10) = {(Still, .1), (Slow, .45), (Fast, .45)}.
Notice that, as expected, the notion of probabilistic beliefs is able to distin- guish possibilistic behaviours that are probabilistically different. For instance, the revised control speed program described in 4.7 does have a different set of probabilistic beliefs:
ΠB(Q, Eπ, Iπ, 10) = { (Still, .010994851),
(Slow, .0989005149), (Fast, .8901046341)}.
The notion of probabilistic beliefs extends the notion of possible beliefs by associating a probability to each possible belief. The relation between the two notions is formally stated by the following corollary.
Corollary 5.7 For each program P,let E and I be two sets of interpretations and let Eπ and Iπ be two sets of probabilistic interpretations such that Eπ/= E and I/π= I. Then for each n:
{A | (A, p) ∈ ΠB(P, Eπ, Iπ, n)} = PB(P, E, I, n).

Proof. The corollary descends from Propositions 5.3 and 5.4.
B ∈ {A | (A, p) ∈ ΠB(P, Eπ, Iπ, n)}
⇔
∃p : (B, p) ∈ ΠB(P, Eπ, Iπ, n)
⇔	{ by definition of probabilistic beliefs }
∃q, I : ⟨I, q⟩∈ Vn (P, Eπ)(Iπ) ∧ B ∈ I
⇔	{ by Propositions 5.3 and 5.4 }
∃I : I ∈ Un(P, E )(I) ∧ B ∈ I
⇔	{ by definition of possible beliefs }
B ∈ PB(P, E, I, n)
✷

Other useful notions can be defined in terms of the probabilistic beliefs. For instance, when analysing the probabilistic behaviours of a reactive agent, one is often more interested in determining the “most probable” beliefs of the agents rather than in examining the full set of probabilistic beliefs.
More precisely, we are typically interested in determining the probabilistic beliefs whose associated probability is above a given belief threshold t. The following corresponding notion of likely beliefs is defined as a natural refine- ment of the notion of probabilistic beliefs.
Definition 5.8 Let P be a program, let Iπ and Eπ be two sets of probabilistic interpretations, and let n > 0. We put:
LB(P, Eπ, Iπ, n, t) = {A | (A, p) ∈ ΠB(P, Eπ, Iπ, n) ∧ p ≥ t}
✷
It is easy to observe that the likely beliefs are a subset of the probabilistic beliefs of an agent since for a generic threshold t:
LB(P, Eπ, Iπ, n, t) ⊆ {A | (A, p) ∈ ΠB(P, Eπ, Iπ, n)} = PB(P, E, I, n)
while for t = 0:
LB(P, Eπ, Iπ, n, 0) = {A | (A, p) ∈ ΠB(P, Eπ, Iπ, n)} = PB(P, E, I, n).
It is worth observing that the notion of likely beliefs gives a handy repre- sentation of a subset of the probabilistic beliefs of practical use. Consider for instance again the problem of comparing the probabilistic behaviours of the walking robot when varying its speed control program. If the robot engineers consider .8 as their belief threshold, then they obtain:
LB(P, Eπ, Iπ, 10, .8)= {}
for the first control speed program of Example 3.3, and:
LB(P, Eπ, Iπ, 10, .8)= {Fast}

for the revised control speed program described of Example 4.7.

A further notion of practical utility is a specialisation of the notion of likely beliefs. Simply stated, when performing a probabilistic analysis of the agent behaviours, we are interested in determining whether the programs will have some definite beliefs.
Definition 5.9 Let P be a program, let Iπ and Eπ be two sets of probabilistic interpretations, and let n > 0. We put:
B(P, Eπ, Iπ, n) = LB(P, Eπ, Iπ, n, 1).
✷
We will see in the following section that the beliefs of a program are the basis to define the important notion of probabilistic invariant.

Probabilistic invariant
The invariant of a conventional program defines the properties that hold at each stage of the program computation. Analogously, the invariant of a reac- tive program defines the largest set of conclusions that the program will be able to draw at any time in any environment. An effective, resource bounded characterisation of the invariant of a program after n steps of computation can be formalised as follows.
Definition 5.10 Let P be a program, let I and E be two sets of interpreta- tions, and let n > 0. We put:
Inv(P, E, I, n) = {A | ∀i ∈ [1, n]: (I ∈ Ui (P, E )(I) =⇒ A ∈ I)}.
✷
Namely an atom A belongs to the invariant Inv(P, E, I, n) if A belongs to all the interpretations computed by Uϕ during all the first n computation steps. The notion of invariant can be reformulated in a probabilistic setting as follows.
Definition 5.11 Let P be a program, let Iπ and Eπ be two sets of probabilis- tic interpretations, and let n > 0. We put:

Inv(P, Eπ, Iπ, n) = {A | ∀i ∈ [1, n]: (⟨I, p⟩∈ Vi
(P, Eπ)(Iπ) =⇒ A ∈ I)}.
✷

It is worth observing that the notion of invariant can be equivalently for- mulated in terms of the beliefs of a program (see Definition 5.9). Namely, for each sets Eπ and Iπ of probabilistic interpretations, and for each n:

Inv(P, Eπ, Iπ, n) =	\
i∈[1,n]
B(P, Eπ, Iπ, i) =	\
i∈[1,n]
LB(P, Eπ, Iπ, n, 1).


It is important to observe that two definitions of invariant (Definitions 5.10 and 5.11) coincide, as stated by the following proposition.
Proposition 5.12 For each program P, let E and I be two sets of interpre- tations and let Eπ and Iπ be two sets of probabilistic interpretations such that Eπ/= E and Iπ/= I. Then for each n:
Inv(P, Eπ, Iπ, n)  =  Inv(P, E, I, n).
Proof.
A ∈ Inv(P, Eπ, Iπ, n)
⇔	{ by Definition 5.11 }
∀i ∈ [1, n]: (⟨I, p⟩∈ Vi (P, Eπ)(Iπ) =⇒ A ∈ I)}
⇔	{ by Propositions 5.3 and 5.4 }
∀i ∈ [1, n]: (I ∈ Ui (P, E )(I) =⇒ A ∈ I)}
⇔	{ by Definition 5.10 }
A ∈ Inv(P, E, I, n).
✷
The above proposition implicitly suggests that notion of invariant of Defi- nition 5.11 is not really probabilistic.
Example 5.13 Consider again the walking robot discussed in Examples 3.3 and 3.5. Suppose that the robot designers have discovered that their robot does not resist for a long time under the snow. The question of the engineers is now: Will the robot survive in the environment where it is supposed to operate? Or should we rather improve the robot resistance to ice to be reasonably certain that it will not fall KO?
The new possible behaviours of the robot are specified by the following program P :

According to the above specification, answering the engineers question reduces to checking that the program invariant contains the atom OK.

Let us consider the same probabilistic environment description employed in Examples 3.3 and 3.5:
Eπ = {⟨{Sun}, .5⟩, ⟨{Rain}, .4⟩, ⟨{Snow}, .1⟩}.
and the initial assumption that the robot is initially still and ok:
Iπ = {⟨{Still, OK}, 1⟩}.
It is easy to observe that the program has an empty invariant Inv(P, Eπ, Iπ, n) for each n > 1. Indeed, the robot may possibly reach the KO state if there is a sequence of snow perceptions. On the other hand, probabilistically speaking, if the probability that such an event will occur is low enough, we may consider OK a “probabilistic” invariant of the robot.	✷
Following the above example, we introduce the notion of probabilistic in- variant which relates the condition of invariance to a belief threshold. Infor- mally speaking, an atom belongs to the probabilistic invariant of a program if it belongs to the likely beliefs of the program for all the first n computation steps.
Definition 5.14 For each program P , let Eπ and Iπ be two sets of proba- bilistic interpretations. Then for each n:

Π-Inv(P, Eπ, Iπ, n, t) =	\
i∈[1,n]
LB(P, Eπ, Iπ, n, t).

✷

It is easy to observe that the notion of probabilistic invariant generalises the notion of invariant of Definition 5.11, as:
Inv(P, Eπ, Iπ, n) = Π-Inv(P, Eπ, Iπ, n, 1)
Example 5.15 Consider again the question of the robot engineers discussed in Example 5.13. We observe that while the (non-probabilistic) invariant of the program is empty for any n > 1, the notion of probabilistic invariant supports a real probabilistic analysis of the robot behaviours. For instance, if the robot engineers choose .95 as their belief threshold for the probabilistic invariant, then they obtain:
Π-Inv(P, Eπ, Iπ, 100, .95) = {OK}.
✷

Related work
The idea of modeling different types of reactive computations as variants of standard logic programming bottom-up computations is, to the best of our

knowledge, original. Nevertheless, our work relates to a number of other approaches proposed in the literature.
Our representation of all possible computations bears strong similarities with the possible worlds semantics of modal logics [9]. The notion of invariant defines the set of (atomic) formulae which are “necessarily” true (i.e., true in each possible world), while the set of possible beliefs defines the set of (atomic) formulae which are “possibly” true (i.e., true in at least one possible world). In spite of these similarities, our approach obviously differs from modal logics, which address other issues such as temporal reasoning or introspection. On the other hand, our semantics based on logic programming is simpler than the semantics of modal logics, and it accounts for an effective implementation as it is a proper generalisation of the standard semantics used in deductive data bases applications [17].
Several efforts have been devoted to investigate the role of computational logic in multi-agent systems (see [14] for a quite recent road map). The IM- PACT system [16] is one of the best known examples of multi-agent system relying on computational logic. Agent beliefs are represented by agent pro- grams, in the style of logic programming, while integrity constraints and action bases are used to describe the actions that individual agents can perform. A number of interesting applications of IMPACT have been illustrated, includ- ing its recent extension to deal with temporal reasoning [8]. Several other efforts have focussed on the use of computational logic to represent incom- plete information in multi-agent systems. The use of abduction to represent incomplete communication environments [15], and the use of updates to rep- resent dynamically evolving knowledge [2,12] are two promising approaches that have been recently proposed. The agent-based architecture presented in
[11] aims at reconciling rationality and reactivity, and it is probably the work
most related to ours. In [11] agents are logic programs which continuously perform an “observe-think-act” cycle, and their behaviour is defined via a proof procedure which exploits iff-definitions and integrity constraints.
A considerable amount of work has been devoted in the logic program- ming community to model open programs and their composition (see [5] for a survey). While these works share with ours the adoption of the logic pro- gramming paradigm as specification language, they focus on the composition of static programs. In contrast, we focus on the composition of a program with an external dynamic environment, and analyse its reactive, incremental computations.
Abductive logic programming [10] is another approach to modeling in- complete knowledge. In this setting, agents may abduce external hypotheses provided that they satisfy existing integrity constraints. While we focus on bottom-up semantics, abductive logic programming is defined via proof proce- dures which combine backward reasoning with integrity constraint checking. A promising direction for further developments is to employ abduction to express forms of interaction among agents, as indicated in [6,7].

Finally, a large body of research has been devoted in the last two decades to the study of concurrency. The main focus of these activities is to model process interactions abstracting from internal computations steps. In contrast our focus is on the interplay between interaction and computation. It is worth mentioning that [13] explicitly introduces a notion of external environment which resembles ours, even if in a quite different context. Also the semantics of interaction presented in [1] employs an explicit representation of the envi- ronment. That semantics is formulated in categorical terms and it is based on linear logic and game semantics.

Concluding remarks
We have presented a simple logic-based formalization of the behaviours of agents capable of reacting to changes occurring in the external environment. In particular we have focussed on modeling the probabilistic behaviours of agents reacting to environment perceptions with an associated probability distribution. We have shown how the availability of a formal characterisation supports effective, resource bounded, quantitative analyses of the probabilistic behaviours of reactive agents, as illustrated by the notions of probabilistic beliefs and probabilistic invariants discussed in Section 5.
Our formalisation does not however account for several aspects of multi- agent systems. We have not considered, for instance, the way in which an agent may affect the behaviour of the environment. Indeed, a natural extension of our setting is to include the “act” part of the “observe-think-act” cycle [11] by employing an intensional representation of the environment. This may be done by representing the environment as a set of transformations Ti(I) over interpretations, rather than as a set of interpretations, and by enabling agents to affect the interpretation I from which the environment evolves. Another important extension is the introduction of negation in our setting. Indeed the ability to deal with incomplete information is another important aspect in multi-agent systems. The use of updates to represent dynamically evolving knowledge described in [2] seems a promising approach in this direction. These extensions are scope for future work.

References
Abramsky, S., Semantics of Interaction: an Introduction to Game Semantics, in: P. Dybjer and A. Pitts, editors, Proceedings of the CLiCS 96 Summer School (1997), pp. 1–31.

Alferes, J., J. Leite, L. Pereira, H. Przymusinska and T. Przymusinski, Dynamic updates of non-monotonic knowledge bases, Journal of Logic Programming 45(1-3) (2000), pp. 43–70.


Apt, K. R., Logic programming, in: J. van Leeuwen, editor, Handbook of Theoretical Computer Science (1990), pp. 493–574, vol. B.
Brogi, A., S. Contiero and F. Turini, On the interplay between reactivity and rationality in multi-agent systems, Technical report, Department of Computer Science, University of Pisa (2001).
Bugliesi, M., E. Lamma and P. Mello, Modularity in Logic Programming, Journal of Logic Programming 19-20 (1992), pp. 443–502.
Ciampolini, A., E. Lamma, P. Mello and P. Torroni, Expressing collaborative and competitive coordination among abductive logic agents, in: F. Sadri and
K. Satoh, editors, Proceedings of the CL-2000 Workshop on Computational Logic in Multi-Agent Systems (CLIMA’00), 2000, pp. 35–43.
Dell’Acqua, P., F. Sadri and F. Toni, Combining introspection and communication with rationality and reactivity in agents, in: J. Dix, L. F. del Cerro and U. Furbach, editors, Logics in Artificial Intelligence, European Workshop, JELIA ’98, LNCS 1489 (1998), pp. 17–32.
Dix, J., S. Kraus and V. Subrahmanian, Temporal Agent Reasoning, Artificial Intelligence 127 (2001), pp. 87–135.
Hughes, G. and M. Cresswell, “A New Introduction to Modal Logic,” RoutLedge, 1996.
Kakas, A., R. Kowalski and F. Toni, Abductive logic programming, Journal of Logic and Computation 2(6) (1992), pp. 719–770.
Kowalski, R. and F. Sadri, Towards a Unified Agent Architecture that Combines Rationality and Reactivity, in: C. Zaniolo and D. Pedreschi, editors, Logic in Databases (1996), pp. 137–150.
Leite, J. A., J. J. Alferes and L. M. Pereira, Multi-dimensional dynamic logic programming, in: F. Sadri and K. Satoh, editors, Proceedings of the CL-2000 Workshop on Computational Logic in Multi-Agent Systems (CLIMA’00), 2000,
pp. 17–26.
Letichevsky, A. and D. Gilbert, A general theory of action languages, Cybernetics and System Analysis 1 (1998), pp. 16–37.
Sadri, F. and F. Toni, Computational logic and multi-agent systems: a roadmap
(1999).
URL http://www.compulog.org
Satoh, K., K. Inoue, K. Iwanuma and C. Sakama, Speculative computation by abduction under incomplete communication environments, in: Proceedings of the Fourth International Conference on Multi-Agent Systems, 2000, pp. 263–270.
Subrahmanian, V., P. Bonatti, J. Dix, T. Eiter, S. K. F. Ozcan and R. Ross, “Heterogeneous agent systems,” MIT Press, 2000.
Zaniolo, C., S. Ceri, C. Faloustos, R. Snodgrass, V. Subrahmanian and R. Zicari, “Advanced Database Systems,” Morgan Kaufmann, 1997.
