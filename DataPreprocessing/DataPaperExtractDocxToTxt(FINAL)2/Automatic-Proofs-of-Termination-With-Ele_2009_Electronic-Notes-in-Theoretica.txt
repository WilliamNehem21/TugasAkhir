

Electronic Notes in Theoretical Computer Science 258 (2009) 41–61
www.elsevier.com/locate/entcs

Automatic Proofs of Termination With Elementary Interpretations
Salvador Lucas1,2
Departamento de Sistemas Informa´ticos y Computacio´n Universidad Polit´ecnica de Valencia
Valencia, Spain

Abstract
Symbolic constraints arising in proofs of termination of programs are often translated into numeric constraints before checking them for satisfiability. In this setting, polynomial interpretations are a simple and popular choice. In the nineties, Lescanne introduced the elementary algebraic inter- pretations as a suitable alternative to polynomial interpretations in proofs of termination of term rewriting. Here, not only addition and product but also exponential expressions are allowed. Les- canne investigated the use of elementary interpretations for witnessing satisfiability of a given set of symbolic constraints. He also motivated the usefulness of elementary interpretations in proofs of termination by means of several examples. Unfortunately, he did not consider the automatic generation of such interpretations for a given termination problem. This is an important drawback for using these interpretations in practice. In this paper we show how to solve this problem by using a combination of rewriting, CLP, and CSP techniques for handling the elementary constraints which are obtained when giving the symbols parametric elementary interpretations.
Keywords: Constraint solving, elementary interpretations, program analysis, termination.


Introduction
In this paper, we are interested in termination analysis of term rewriting systems (TRSs [4]) as a suitable basis for approaching termination of more sophisticated programming languages and computational systems. Proofs of termination in term rewriting involve solving weak or strict symbolic con- straints s ≥ t or s N t between terms s and t coming from (parts of) the

1 This work has been partially supported by the EU (FEDER) and the Spanish MEC/MICINN, under grant TIN 2007-68093-C02-02.
2 Email: {slucas}@dsic.upv.es



1571-0661© 2009 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2009.12.004

rules of the TRS. Here, ≥ and N are (quasi-)orderings on terms satisfying appropriate conditions [3,6,9]. These constraints are often treated as numeric constraints [s] ≥ [t] and [s] > [t] where [s] and [t] are numeric functions obtained by interpreting the symbols f occurring in s and t as numeric func- tions [f ]. Termination tools that aim at achieving automatic termination proofs have to compute such interpretations out from the symbolic constraints associated to the termination problem. In this setting, polynomial interpre- tations are a widely used choice. In this approach, k-ary symbols f ∈ F are given parametric polynomials [f ]. For instance, consider the usual rules for the addition:
add(X, 0) →X	(1)
add(X, s(Y )) →s(add(X, Y ))	(2)
The following (parametric) polynomials are given to the symbols in the system:
[0] = z0	[s](x) = s1x + s0	[add](x, y) = a1x + a2y + a0
Variables in terms s and t (e.g., X and Y in our example) become uni- versally quantiﬁed numeric variables in polynomial constraints [s] ≥ [t] or
[s] > [t]. In contrast, the parametric coefficients a0, a1,..., z0 become exis- tentially quantiﬁed variables. For instance, following [9], in order to prove termination of R, we have to ensure that [s] > [t] for all rewrite rules s → t in R. For (2) we have [add(X, s(Y ))] = a1X + a2s1Y + a2s0 + a0 and [s(add(X, Y ))] = s1a1X + s1a2Y + s1a0 + s0. Consider the constraint
∃a1, a2, s0, s1, z0 ∈ D ∀X, Y ∈ A a1X+a2s1Y +a2s0+a0 > s1a1X+s1a2Y +s1a0+s0
where D is a (usually small) domain of coeﬃcients and A is the semantic domain of the interpretation (e.g., N, [0, +∞), etc.). In order to solve this constraint, most termination tools work on semantic domains A of nonnega- tive numbers and implement Hong and Jakuˇs’ criterion [11,8] to remove the universally quantified variables from polynomial constraints to obtain an ex- istential constraint like
∃a1, a2, s0, s1, z0 ∈ D a1 ≥ s1a1 ∧ a2s1 ≥ s1a2 ∧ a2s0 + a0 > s1a0 + s0
The idea is having an independent comparison of the different monomials (w.r.t. the semantic variables only). Then, suitable constraint solving systems are used to give specific values to the parametric coefficients [5,8,19].
Using elementary interpretations
Lescanne introduced and motivated the use of elementary algebraic interpre- tations as an alternative to polynomial interpretations [14,8,7,18] in proofs of

termination of term rewriting [15].
Example 1.1 The following specification R of the factorial function is a vari- ant of Lescanne’s leading example [16, Introduction] (add rules (1) and (2) above).
mul(0, X) → 0	(3)
mul(s(X),Y ) →add(mul(X, Y ),Y )	(4)
fact(0) →s(0)	(5)
fact(s(X)) →mul(s(X), fact(X))	(6)
Lescanne showed that termination of R cannot be proved by using polynomial interpretations as sketched above. In contrast, R can be proved terminating by using the following elementary interpretation:
[0] = 1	[s](x) = x +1	[fact](x) = (2x + 2)2x+1
[add](x, y) = x + 2y   [mul](x, y) = 2xy + 2x + y

This is compatible with the rewrite rules l → r in R, i.e., [l] > [r] for all rules l → r in R. For instance, [fact(s(X))] = (2X + 4)2X+3 and [mul(s(X), fact(X))] = (2X + 3)(2X + 2)2X+1 + 2X + 2. In Example 5.2
we prove that [fact(s(X))] > [mul(s(X), fact(X))] for all X ∈ N.
Following the usual practice in the nineties, Lescanne focused on the use of reduction orderings > which can be used to prove termination of a TRS by just comparing the left- and right-hand sides of the rules [9]. Lescanne considered elementary interpretations over the naturals and his work addresses the problem of checking the inequalities [l] > [r] which are obtained for a given interpretation which should be provided by the user. In contrast, current state- of-the-art termination tools which use polynomial interpretations: (1) use the dependency pairs (DP) method [3] to generate the constraints to be solved, (2) use polynomial interpretations over the reals [18], and (3) such interpretations are not given by the user but rather generated by the tools.
This paper aims at enabling the use of elementary interpretations in au- tomatic proofs of termination. The contribution of this paper is twofold. In Sections 3 and 4, we investigate elementary interpretations over the reals and show how to translate the standard requirements of the DP-method into sym- bolic elementary constraints over the reals. In particular, the generation of reduction pairs ( , N) (where  is a monotonic quasi-ordering 3 and N is a well-founded ordering on terms) is considered. These are the basic compo- nents of the DP-method for building proofs of termination. We also consider

3 A quasi-ordering is a reflexive and transitive relation.

the generation of reduction orderings. Our development admits the specifica- tion of monotonicity conditions which must be satisfied by the orderings. This provides a more flexible framework enabling more applications. For instance, we could want to impose such restrictions to prove termination of variants of term rewriting like context-sensitive rewriting, infinitary rewriting, innermost rewriting, outermost rewriting, etc. (see [18] for further motivation).
Our second contribution is the definition of a rule-based transformation system for solving (parametric) elementary constraints (Sections 5, 6 and 7). This is an essential part of the work which does not depend on our main application focus (termination of programs), thus being useful for dealing with elementary constraints arising from other problems. Section 8 concludes.

Preliminaries
A binary relation R on a set A is terminating (or well-founded) if there is no infinite sequence a1 R a2 R a3 ··· . Given f : Ak → A and i ∈ {1,..., k}, we say that R is monotonic on the i-th argument of f (or that f is i-monotone regarding R) if f (x1,..., xi−1, x,..., xk) R f(x1,..., xi−1, y,..., xk) whenever xR y, for all x, y, x1,..., xk ∈ A. We say that R is monotonic regarding f (or that f is R-monotone) if R is i-monotonic on the i-th argument of f for all i, 1 ≤ i ≤ k. A transitive and reflexive relation ≥ on A is a quasi-ordering. A transitive and irreflexive relation > on A is an ordering.
In this paper, X denotes a countable set of variables and F denotes a signature, i.e., a set of function symbols {f, g,.. .}, each having a fixed arity given by a mapping ar : F → N. The set of terms built from F and X is T (F, X ). A context is a term C[ ] with a ‘hole’ (formally, a fresh constant symbol). A binary relation R on terms is stable if, for all terms s, t and substitutions σ, σ(s) R σ(t) whenever s R t.
A rewrite rule is an ordered pair (l, r), written l → r, with l, r ∈T (F, X ), l /∈ X and Var(r) ⊆ Var(l). A TRS is a pair R = (F, R) where R is a set of rewrite rules. The problem of proving termination of a TRS is equivalent to finding a well-founded, stable, and monotonic (strict) ordering > on terms (i.e., a reduction ordering) which is compatible with the rules of the TRS, i.e., l > r for all l → r ∈ R [9]. Termination of rewriting can also be proved by using the dependency pairs approach [3]. Reduction pairs are used in this case. A reduction pair ( , N) consists of a stable and weakly monotonic quasi-ordering  , and a stable and well-founded ordering N satisfying either
 ◦ N ⊆ N or N ◦  ⊆ N. No monotonicity is required for N. The quasi- ordering  is used to compare the rules of the TRS and the strict ordering N is used to compare the dependency pairs, see [3] for further details.
Term (quasi-)orderings can be obtained by giving appropriate interpreta-

tions to the function symbols of a signature. Given a signature F, an F-  algebra is a pair A = (A, FA), where A is a set and FA is a set of mappings fA : Ak → A for each f ∈F where k = ar(f ). For a given valuation mapping α : X → A, the evaluation mapping [α]A : T (F, X ) → A is inductively defined by [α]A(x)= α(x) if x ∈X and [α]A(f (t1,..., tk)) = fA([α]A(t1),..., [α]A(tk)) for x ∈ X , f  ∈ F, and t1,..., tk ∈ T (F, X ). Given a term t with Var(t)= {x1,..., xn}, we write [t]A (or just [t] if A is clear from the context) to denote the function Ft : An → A given by Ft(a1,..., an) = [α(a ,...,a )]A(t)
for each tuple (a1,..., an) ∈ An, where α(a ,...,a )(xi)= ai for 1 ≤ i ≤ n.
1	n
We want to use real functions to define term (quasi-) orderings [18]. Given a signature F, an interval A ⊆ [0, +∞) (usually A = [0, +∞)), and an F- algebra over the reals A = (A, FA),  given by t  s ⇔ ∀α : X → A, [α](t) − [α](s) ≥R 0 for all t, s ∈ T (F, X ) is a stable quasi-ordering on terms. Given δ > 0, the relation >δ on terms given by t >δ s ⇔ ∀α : X → A, [α]A(t) − [α]A(s) ≥R δ is a well-founded strict ordering on terms. As discussed in [18], rather than imposing the monotonicity requirements to all arguments of all function symbols, we use sufficient conditions ensuring the monotonicity of either  or >δ for a given argument i ∈ {1,..., k} of a given k-ary symbol
f . Then, we speak of i-monotonicity of  (or weak i-monotonicity) or i-
monotonicity of >δ (strong i-monotonicity) for a given symbol f : ∂fA ≥ 0
i

ensures weak i-monotonicity of f [18, Proposition 2] and ∂fA
i
≥ 1 ensures

strong i-monotonicity of f [18, Theorem 2]. If  is guaranteed to be weakly
monotonic (for all arguments i ∈ {1,..., k} of all k-ary symbols f ∈ F), then ( , >δ) is a reduction pair for all δ > 0 [18, Proposition 4]. If >δ is strongly monotonic (again for all arguments and symbols), then >δ is a reduction ordering.

Elementary interpretations
Given a set of numbers N , the following grammar describes Lescanne’s EP - terms (or EP (N )-terms if we want to make N explicit) 4 in [16, Section 5]:
E := x | n | EE | E + E | E · E
where n ∈ N and x are numeric variables.
Remark 3.1 Lescanne’s description of EP-terms makes use of the numeric constants 0 and 1 only. This is due to his particular representation of EP- terms, where an ‘EP-monomial’ like 3x is written x + x + x, thus avoiding the explicit use of the constant 3. We do not follow this approach because:

4 Our presentation of EP-terms is slightly different from Lescanne’s, but equivalent.

We do not assume that the coefficients are given; we rather want to compute them through some constraint solving procedure. Hence, they are treated as unknowns and represented by means of parameters.
The values in N can be real (possibly negative) numbers. Hence, rep- resenting a monomial coefficient as a repetition of the monomial is not feasible anymore.
Remark 3.2 [Use of real numbers] Although natural numbers are closed un- der exponentiation, addition and product, this is not the case for other promi- nent subsets of (nonnegative) real numbers. For instance, Hilbert conjectured that ab is transcendental whenever a /∈ {0, 1} is algebraic and b is an irrational algebraic number (this is part of his seventh problem, see [10] for instance). Gelfond-Schneider’s Theorem confirms that this is the case. In particular Q is
1	√
not closed under exponentiation. For instance, 2(22 ) =2 2 is transcendental.
Hence, in sharp contrast with polynomial interpretations (see [19]), transcen- dental numbers are essential to deal with J-algebras based on EP-functions over domains of real numbers.
Linear elementary interpretations
The size and structural complexity of the parametric constraints which are ob- tained during the automatic treatment of termination problems highly depend on the shape of the parametric functions which are given to function symbols in the interpretation. The usual choice in termination provers that rely on polynomial interpretations is using linear polynomials. In this section, we introduce and investigate a subclass of elementary functions which is based on using linear polynomials in the additive and exponential components of the elementary functions: the Linear Elementary Interpretations. Each k-ary symbol f ∈J is given a function
f (x1,..., xk)= A(x1,..., xk)+ B(x1,..., xk)C(x1,...,xk )	(7)
where A = a1x1 + ··· + akxk + a0, B = b1x1 + ··· + bkxk + b0, and C =
c1x1 + ··· + ckxk + c0 are linear polynomials over the reals.
Remark 4.1 Special cases for f , depending on the shape of A, B and C are:
If A is zero (A ≡ 0), then f = BC is a ‘pure exponential’ interpretation.
If B is a constant b, then f = A + bC and, whenever b > 0 we can use negative coefficients in C without any problem.
If C is a constant c, then f is either a possibly non-linear polynomial
f = A + Bc (if c > 0 is a positive integer) or a polynomial fraction

 1 
B|c|
(if c < 0 is a negative integer). B could contain negative

coefficients also.

In this section, we assume that f (x1,..., xk) is a linear elementary func- tion (7) and formulate sufficient conditions to guarantee algebraicity and monotonicity of linear elementary interpretations on the semantic domain A = [0, +∞). Conveniently, our results are formulated as constraints in- volving the parametric coefficients a0,..., ak, b0,..., bk, c0,..., ck only. The following proposition about constraints of linear polynomials is used below (see also [11]).
Proposition 4.2 Let P = a1x1 + ··· + anxn + a0 be a linear polynomial and
α ∈ [0, ∞). Then, ∀x1,..., xn ≥ 0,P (x1,..., xn) ≥ α holds if and only if
∀i, 1 ≤ i ≤ n, ai ≥ 0 and a0 ≥ α.
Algebraicity of linear elementary interpretations
If the exponent polynomial C(x1,..., xk) takes a noninteger value c ∈ R − Z for some (x1,..., xk) ∈ Ak, then we have to ensure that B(x1,..., xk) ≥ 0 for the base polynomial B. otherwise, BC would be undefined for some points in Ak. Thus, we require that B(x1,..., xk) ≥ 0 for all x1,..., xk ∈ A. By Proposition 4.2, this is equivalent to impose bi ≥ 0 for all i,0 ≤ i ≤ k. We also need to ensure that f (x1,..., xk) ≥ 0 for all x1,..., xk ≥ 0 (algebraicity). In general, this amounts at requiring that A is non-negative: for all x1,..., xk ≥ 0, A(x1,..., xk) ≥ 0. Again, this is equivalent to impose ai ≥ 0 for all i, 0 ≤ i ≤ k.
In the following section, we investigate monotonicity of linear elementary functions. First of all, we have, for each i, 1 ≤ i ≤ k,


 ∂f



=  ∂A + BC ·  ln(B) ·  ∂C + C ·  ∂B  = ai + BC · ci ln(B)+ bi C 

which is well-defined only if B > 0, i.e., if b0 > 0. We need to consider two

relevant monotonicity conditions for each argument i of f :  ∂f
i
≥ 0 (weak

monotonicity) and  ∂f
i
≥ 1 (strong monotonicity).

Weak monotonicity of linear elementary interpretations
The following proposition provides a sufficient condition for weak i- monotonicity of linear elementary functions.
Proposition 4.3 Let f be a linear elementary k-ary function and i ∈
{1,..., k}. If ai ≥ 0, b0 > 0, cib0 + bic0 − ci ≥ 0 and  k	cibj + bicj ≥ 0, then
f is weakly i-monotone over A = [0, +∞).
Corollary 4.4 Let f be a linear elementary k-ary function and i ∈ {1,..., k}. Assume that ai ≥ 0, b0 ≥ 1 and ci ≥ 0. Then, f is weakly i-monotone over A = [0, +∞) if C ≥ 0 or bi = 0.

Example 4.5 Consider the following linear elementary functions f (x, y) = (2y + 4)4x−y+1 and g(x, y) = x + ( x + y + 1)x−2y. Both of them are weakly
monotonic:
We can apply Corollary 4.4 to f : a1 = 0, b0 = 4 ≥ 1, c1 = 4 ≥ 0, and
b1 = 0.
Corollary 4.4 does not apply to g, but Proposition 4.3 does: a1 =1 ≥ 0,
b0 =1 > 0, c1b0 + b1c0 − c1 = 0, c1b1 + b1c1 =1 ≥ 0, c1b2 + b1c2 = 0.

Strong monotonicity of linear elementary interpretations
Regarding strong monotonicity, we have the following:
Proposition 4.6 Let f be a linear elementary k-ary function and i ∈
{1,..., k}. If
ai ≥ 1, b0 > 0, cib0 + bic0 − ci ≥ 0 and  k	cibj + bicj ≥ 0, or
ai ≥ 0, b0 ≥ 1, bi = 0, C ≥ 0, ci ln(b0) ≥ 1, or
ai ≥ 0, b0 ≥ 1, ci ≥ 0, and  k	bicj ≥ bj,
then f is strongly i-monotone over A = [0, +∞).
Example 4.7 Consider the linear elementary function fact(x)= (2x+2)2x+1 in Example 1.1. We can prove strong 1-monotonicity of fact by using Propo- sition 4.6(iii): a1 = 0, b0 = 2 ≥ 1, c1 = 2 ≥ 0, b1c0 = 2 · 1 ≥ 2 = b0 and b1c1 =4 ≥ 2= b1.
Remark 4.8 [Use of negative coefficients] Regarding the possibility of using negative coefficients in (arbitrary) linear elementary interpretations, we know that this is possible in the exponent C only. If we use Proposition 4.6 to guarantee some non-trivial degree of strong monotonicity for a k-ary func- tion f (i.e., at least one of the arguments i ∈ {1,..., k} is intended to be strongly monotonic), only the first condition is compatible with such negative coefficients.
The following result avoids the logarithmic constraint in Proposition 4.6(ii).
Corollary 4.9 Let f be a linear elementary k-ary function and i ∈ {1,..., k}.
If b0 ≥ 1, bi =0 and
ai ≥ 1 and ci ≥ 0, or
ai ≥ 0,  k	cj ≥ 0, and either b0 ≥ e and ci ≥ 1 or cib0 ≥ b0 + ci,
then, f is strongly i-monotone over A = [0, +∞).

When using Corollary 4.9 in practice, instead of imposing b0 ≥ e we rather use a suitable upper approximation to e = 2.7182 ··· as in b0 ≥ 3.

Solving elementary constraints
Lescanne compares elementary expressions e and e' by using rewrite systems which either preserve its value or decrease it. His first group of rules (R in [16]) encodes well-known arithmetic properties of addition, product and exponentials:
0+ x → x	x · (y + z) → (x · y)+ (x · z)	xy+z → xy · xz
0 · x → 0	(xy)z → x(y·z)	x1 → x
1 · x → x	(x · y)z → xz · yz	x0 → 1
Actually, they can be used in both directions (as equations): every arithmetic expression e (in particular any EP -expression) which is rewritten using these rules yields an equivalent expression e': e → e' means that [e]] = [e']], where [ ] is the (intended) interpretation of elementary expressions which is obtained when variables x, y, z, constants 0, 1, and operations ‘+’, ‘·’, and exponential are interpreted as arithmethic variables, constants, and operations in the usual way.
The following rewrite rule (H in [16]) encodes a semantic transformation which yields an expression e' which is smaller than the original one:
(x + y)z ‹→ xz + yz
That is: e ‹→ e' implies that ∀x1,..., xn ∈ A, [[e]] ≥ [[e']], where x1,..., xn are the variables occurring in e and A = {2, 3,.. .} in [16]. Roughly speaking, in order to check that e > e' holds, Lescanne performs arbitrary rewrite steps on e and e' using R. He only uses H to rewrite the left-hand side e of the inequality: if e ‹→ e'', then [e]] ≥ [[e'']]; so, if we are able to prove [e'']] > [[e']] later, then [e]] > [[e' ] as desired. The idea is reaching in this way a final constraint e > e' whose satisfaction is easily established (see [16] for details).

Auxiliary results
The following result generalizes to real numbers the result encoded by rule H
for natural numbers.
Proposition 5.1 Let x, y ≥ 0 and z ≥ 1. Then, (x + y)z ≥ xz + yz. Further- more, if x, y > 0 and z > 1, then (x + y)z > xz + yz.

Example 5.2 (Continuing Example 1.1) By Proposition 5.1, for all X ≥ 0, (2X +2+ 2)2X+2 > (2X + 2)2X+2 + 22X+2 holds. Thus, we have:
[fact(s(X))] = (2X + 4)2X+3 = (2X + 4)(2X +2+ 2)2X+2
> (2X + 4) (2X + 2)2X+2 + 22X+2 
= (2X + 4)(2X + 2)2X+2 + (2X + 4)22X+2
Since 2X +4 > 2X + 3, (2X + 2)2X+2 > (2X + 2)2X+1, and (2X + 4)22X+2 >
2X +2 we have
(2X + 4)(2X + 2)2X+2 + (2X + 4)22X+2 > (2X + 3)(2X + 2)2X+1 + 2X +2 
= [mul(s(X), fact(X))] Thus, we conclude that [fact(s(X))] > [mul(s(X), fact(X))].
The following result complements Proposition 5.1.
Proposition 5.3 Let b, x, x1,..., xn ∈ R be such that xi ≥ 1 for all 1 ≤ i ≤ n,
x ≥ Σn	xi, and b ≥ 2. Then, bx ≥ Σn	bxi . If n > 1 and xj > 1 for some

1	i=1, then bx > Σn
bx .
i=1

Removing universal quantiﬁcation from elementary constraints
When using a parametric linear elementary algebra A = (A, JA) to solve a
conjunction  m  si ≥ ti ∧  n	uj N vj of symbolic constraints, we obtain a
sentence
m	n

∃c1,..., cκ ∈ D ∀x1,..., xn ∈ A
  [si] ≥ [ti] ∧  [uj] >δ [vj]

i=1	i=j
(for some δ > 0). Alternatively, we can leave δ unspecified and include a new (existentially quantified) parameter D:
m	n

∃D > 0 ∃c1,..., cκ ∈ D ∀x1,..., xn ∈ A
  [si] ≥ [ti] ∧  [uj] ≥ [vj]+ D

i=1	i=j
Now we have to witness that this sentence is satisfiable, i.e., we have to obtain a value assignment γ : K ∪ {D}→ D ∪ (0, +∞), where K = {c1,..., cκ} is the set of parametric coefficients that we are considering (which take values on D only) and D is the new parameter which takes values in (0, +∞). We have to
do this in such a way that ∀x1,..., xn ∈ A  m [si]γ ≥ [ti]γ ∧  n  [uj]γ >δ [vj]γ
holds. Here, [·]γ is the intepretation of terms which is obtained by using the

linear elementary algebra Aγ = (A, JA,γ) where the mappings fAγ in JA,γ are obtained from those in JA by giving the value γ(ci) to each parameter ci occurring in fA ∈ JA. Furthermore, δ = γ(D) (if we use the second alternative sentence above). For instance, we can start with a sentence
∃a, b, c, d, e, a', b', c', d', e',f' ∈ D ∀X ∈ A (aX+b)cX+d ≥ (e'X+f')(a'X+b')c'X+d'
As remarked in the introduction, we proceed by transforming this problem into an existential constraint solving problem


∃c1,..., cκ ∈ D


  ei da
i=1

e'i

where ei and e'i are elementary expressions built out from parametric coeffi- cients c1,..., cκ and numeric constants only. Let E(c1,..., cκ) be the set of such expressions. Furthermore, da is a comparison operator (≥, >δ, ... ). Note that:
The two kinds of variables (parametric coefficients and semantic vari- ables) have different roles in the constraints (existential vs. universal quantification).
As discussed in Remark 3.1, Lescanne’s technique assumes that the co- efficients of the monomials are implicit. Of course, this is not compatible neither with obtaining values for such coefficients by solving existential constraints involving them, nor with coefficients taking values over the rationals.
Many important properties about elementary constraints over the reals are valid under some conditions only. For instance, (x + y)z ≥ xz + yz (which corresponds to the rule H above), is guaranteed only if x, y ≥ 0 and z ≥ 1 (Proposition 5.1). If we want to use this property, we need to be able to introduce these new proof obligations as auxiliary constraints which have to be solved together with the ‘main’ ones. This does not fit standard term rewriting anymore.
The ability of handling constraints with parametric coefficients gives us more flexibility. For instance, the constraint above can be transformed by introducing a fresh constant  d defined by d +1 = d, leading to the equivalent constraint (aX+b)cX+d+1 ≥ (e'X+f')(a'X+b')c'X+d' ∧d+1 = d which can be equivalently rewritten (using R above) into (aX + b)(aX + b)cX+d ≥ (e'X + f')(a'X + b')c'X+d' ∧ d + 1 = d. Now, this can be decomposed as follows: aX + b ≥ e'X + f' ∧aX + b ≥ a'X + b' ∧cX + d ≥ c'X + d' ∧ d +1 = d. This linear constraint can be transformed now by using Hong and Jakuˇs’ criterion into a ≥ e' ∧b ≥ f' ∧a ≥ a' ∧b ≥ b' ∧c ≥


	
c' ∧ d ≥ d' ∧ d +1 = d.
In Figure 1 we introduce a new rule-based transformation system for checking and solving (parametric) elementary constraints.

Description of the transformation system.
Letters U , V , W , X, Y , and Z in Figure 1 denote arbitrary elementary expres- sions whereas C[ ] denotes a context. Making contexts explicit in the definition of the rules is in sharp contrast both with pure rewriting and CLP. Alterna- tively, we could provide the usual structural or congruence rules to propagate reductions on the syntactic structure of the constraint. Note, however, that the definition of the three rules in the Exponentials section is intention- ally asymmetric: only the left-hand sides e of constraints e ≥ e' or e > e' can be transformed by using these rules; otherwise, we could obtain a wrong approximation of the original constraint.
The meaning of the rules should be clear: they mostly rely on well-known arithmetic properties of addition, product and exponential (over the reals). Rule Add basis corresponds to Proposition 5.1; rule Add exp corresponds to Proposition 5.3 and rule Negative Exp is obvious (and necessary to deal with negative exponents).
The Introduction rules give support to the use of the ordering >δ in two different ways: by either providing an explicit (positive) value for δ or (better) by leaving it unspecified. In the second case, a reserved parameter D (which cannot be used in the parametric interpretation) is intended to represent the appropriate value for δ. This value would be obtained together with all other parameters at the end of the process. The rule K-Introd allows us to replace basic expressions by other basic expressions to our convenience. As suggested above, this can be very useful but we must be careful when using this rule because it can easily run into a nonterminating behavior. Furthermore, we need to provide the appropriate ‘conjecture’ K' which leads to some progress in the deduction and also select the appropriate target K for the replacement.
Decomposition rules play a prominent role in the system: they introduce a structural simpliﬁcation of the constraints on the basis of new comparisons between the arguments of the arithmetic operators: addition, product and exponential.
Finally, the Constraints rules give support to the simplification of goals by moving a basic constraint from the goal to the constraint part.
Remark 5.4 [Generalizing Hong and Jakuˇs’ criterion] Hong and Jakuˇs’ cri- terion for removing semantic variables from polynomial constraints is easily implemented by using Add decomp, Prod decomp and the constraint removal rules Constants, Variables, and Reflexivity. Thus, our system generalizes Hong

and Jakuˇs’ criterion to parametric elementary constraints: universally quanti- fied semantic variables are removed while an existential constraint consisting of parametric coefficients (only) is built to subsequently invoke an appropriate solver.


Transforming constraints.
As in CLP [12,13,21], we rewrite states ⟨G | C⟩ consisting of a goal G which is a conjunction of elementary constraints involving both parametric coefficients and semantic variables, and a constraint C which is a conjunction of elemen- tary constraints involving parametric coefficients only. We rewrite such states as follows: write ⟨G | C⟩ ⇒ ⟨G' | C'⟩ if either G →R G' (modulo associativity and commutativity of addition and product) and C = C', or else one of the rules in Figure 1 applies in the usual way (see [21]). A computation from an initial state ⟨G | True⟩ ends when either a state ⟨ | C⟩ is reached (successful computation), or a state ⟨G' | C'⟩, where no further rewriting step on G' is possible, is obtained (failed computation). In case of a successful computation C is an existential constraint (∃c1,..., cκ ∈ D C) which we can try to solve by using an appropriate constraint solving system [22]. In general, C is an ele- mentary constraint, but we often obtain polynomial constraints. The variable assignment {ci '→ vi | 1 ≤ i ≤ κ, vi ∈ D}∪ {D '→ δ} (for some δ > 0) which solves C and which represents an specific elementary interpretation which is compatible with all the requirements of the termination problem would be returned to the user.
Theorem 5.5 (Correctness) Let G =  N  ei da e' be such that ei, e' are
i	i
elementary expressions with parameters c1,..., cκ and variables x1,..., xn for

all i, 1 ≤ i ≤ N, and da
∈ {≥, >, >δ}. If ⟨G | True⟩ ⇒∗ ⟨  | C⟩, then

∃c1,..., cκ ∈ D ∀x1,... xn ∈ A G holds if ∃c1,..., cκ ∈ D C holds.


Termination.
Lescanne’s system R is terminating. The rules in Figure 1 are terminating if we do not use K-Introd, which introduces new expressions K ∈ E(c1,..., cκ). As discussed in Section 5.2, this rule is useful to force a given expression to adopt some particular shape which enables the application of other rules leading to further progress in the derivation (see the second example in the next section). Therefore, we should use it only under control of an appropriate heuristic.


Fig. 1. Transformation of elementary constraints


Examples
Checking constraints.

The reduction relation which only rewrites the subterms of a term s = f (s1,..., sk) which are reachable by following the replacing arguments i ∈ μ(f ) ⊆ {1,..., ar(f )} indicated by a replacement map μ : J → P(N) is called context-sensitive rewriting (CSR [17]).
Proving termination of CSR is an interesting problem with several appli- cations [20]. Consider the TRS R [20, Example 14]:

h(X) →g(X, X)	(8)
g(a, X) →f (b, X)	(9)
f (X, X) →h(a)	(10)
a →b	(11)
together with the following replacement map: μ(f ) = μ(g) = μ(h) = {1}. Proofs of termination of CSR can be obtained by using the results in [1,2] which generalize to CSR the well-known dependency pairs method [3]. In this setting, we have to consider the following rules DP(R, μ) (which are the context-sensitive dependency pairs [1,2]):
H(X) →G(X, X)	(12)
H(a, X) →F (b, X)	(13)
F (X, X) →H(a)	(14)
where F , G, and H are fresh symbols and we assume μ(F )= μ(G)= μ(H)= 
{1}. Now we use μ-reduction pairs which are pairs ( , N) such that  is μ-monotonic (i.e.,  is i-monotonic for all i ∈ μ(f ) and all symbols f ). We have to solve the following constraints [1,2]: l   r for all rules l → r in R, u  v or u N v for all rules u → v in DP(R, μ), and u N v for at least one rule u → v in DP(R, μ). The following linear elementary interpretation


2

2
is compatible with the rules of the system in the following sense:
[h(X)] ≥ [g(X, X)]	[g(a, X)] ≥ [f (b, X)]
[f (X, X)] ≥ [h(a)]		[a] ≥ [b] [H(X)] ≥ [G(X, X)]	[G(a, X)] >1 [F (b, X)]
[F (X, X)] >1 [H(a)]
As shown in Example 4.5, the linear elementary interpretations for f , g, F and G are weakly 1-monotonic, as required (for h and H it is obvious). These facts can be used to prove that R is μ-terminating, i.e., that no infinite context- sensitive rewrite sequence is possible 5 . In contrast, the use of polynomial interpretations does not lead to a proof of termination for this example.
Let us illustrate the use of the transformation rules in Figure 1 to check
these inequalities. With [h(X)] = X + 1 and [g(X, X)] = X + ( 3 X + 1)−X,

5 This conclusion is not immediate but it easily follows by using the results in [2].

we have
⟨X +1 ≥ X +( 3 X + 1)−X | True⟩
⇒Add decomp ⟨X ≥ X ∧ 1 ≥ ( 3 X + 1)−X | True⟩
⇒Reflexivity ⟨1 ≥ ( 3 X + 1)−X | True⟩
⇒Negative Exp ⟨ 3 X +1 > 0 ∧ ( 3 X + 1)X ≥ 1 | True⟩
	
2	2
⇒K−Introd ⟨ 3 X +1 > 0+0 ∧ ( 3 X + 1)X ≥ 1 | 0 + 0 = 0⟩
2	2
⇒Add decomp ⟨ 3 X ≥ 0 ∧ 1 > 0 ∧ ( 3 X + 1)X ≥ 1 | 0 + 0 = 0⟩
2	2
⇒K−Introd ⟨ 3 X ≥ 0 ∗ 0 ∧ 1 > 0 ∧ ( 3 X + 1)X ≥ 1 | 0 + 0 = 0⟩
2	2
⇒Prod decomp ⟨ 3 ≥ 0 ∧ X ≥ 0 ∧ 1 > 0 ∧ ( 3 X + 1)X ≥ 1 | 0 + 0 = 0 ∧ 0 ∗ 0 = 0⟩
2	2
⇒Constants ⟨X ≥ 0 ∧ 1 > 0 ∧ ( 3 X + 1)X ≥ 1 | 0 + 0 = 0 ∧ 0 ∗ 0 = 0 ∧ 3 ≥ 0⟩
2	2
⇒Variables ⟨1 > 0 ∧ ( 3 X + 1)X ≥ 1 | 0 + 0 = 0 ∧ 0 ∗ 0 = 0 ∧ 3 ≥ 0⟩
2	2
⇒Constants ⟨( 3 X + 1)X ≥ 1 | 0 + 0 = 0 ∧ 0 ∗ 0 = 0 ∧ 3 ≥ 0 ∧ 1 > 0⟩
2	2
⇒K−Introd ⟨( 3 X + 1)X ≥ 10 | 0 + 0 = 0 ∧ 0 ∗ 0 = 0 ∧ 3 ≥ 0 ∧ 1 > 0 ∧ 11 = 1⟩
2	2
⇒Exp decomp ⟨ 3 X +1 ≥ 1 ∧ X ≥ 0 | 0 + 0 = 0 ∧ 0 ∗ 0 = 0 ∧ 3 ≥ 0 ∧ 1 > 0 ∧ 11 = 1⟩
2	2
⇒Add decomp ⟨ 3 X ≥ 0 ∧ 1 ≥ 1 ∧ X ≥ 0 | 0 + 0 = 0 ∧ 0 ∗ 0 = 0 ∧ 3 ≥ 0 ∧ 1 > 0 ∧ 11 = 1⟩
2	2
⇒∗ ⟨  | 0 + 0 = 0 ∧ 0 ∗ 0 = 0 ∧ 3 ≥ 0 ∧ 1 > 0 ∧ 11 = 1 ∧ 1 ≥ 1⟩

where 0 + 0 = 0 ∧ 0 ∗ 0= 0 ∧ 3 ≥ 0 ∧ 1 > 0 ∧ 11 = 1 ∧ 1 ≥ 1 is trivially satisfied.

Remark 6.1 No proof for X +1 ≥ X + ( 3 X + 1)−X is possible by using the methods in [16]: it is not valid in Lescanne’s formalization due to the rational

number 3
and the negative exponent; and no rule in [16] plays the role of

Negative Exp.
Solving constraints.
Our second example illustrates the generation of coefficients. Consider the TRS R in Example 1.1. According to the previous considerations, we would give the following parametric interpretations to the function symbols (for sim- plicity, only fact is given a linear elementary interpretation):
[0] = z0	[s](x) = s1x + s0
[mul](x, y) = m11xy + m10x + m01y + m00  [add](x, y) = a1x + a2y + a0
[fact](x) = f x + f + (f' x + f' )f''x+f''
1	0	1	0  1	0
Algebraicity : As discussed in Section 4.1, we just need to ensure that all coefficients for [0], [add], [mul] and [s] are nonnegative, and that f0, f1, f0' , f1' ≥ 0.

Monotonicity : For symbols add, mul and s, which are interpreted as poly- nomials, we require a1, a2, m10, m01, s1 ≥ 1. Regarding fact, by Proposi- tion 4.6, we require f0' ≥ 1, f1, f0'', f1'' ≥ 0, f1' f0'' ≥ f0' and f1' f1'' ≥ f1' .
Constraints corresponding to the rules: We only consider the rules yield- ing non-polynomial constraints.
Rule l5 → r5, i.e., fact(0) → s(0). We have:


[l ] = f z + f + (f' z
+ f' )f''z0+f''

5	1 0	0
1 0	0  1	0

[r5] = s1z0 + s0

The application of the transformation rules in Figure 1 yields


⟨f z
+ f + (f' z
+ f' )f''z0+f'' > s z + s
| True⟩

1 0	0
1 0	0  1	0
1 0	0

⇒	⟨  | f z
+ f + (f' z
+ f' )f''z0+f'' > s z
+ s ⟩

Constants
1 0	0
1 0	0  1	0
1 0	0


Rule l6 → r6, i.e., fact(s(X)) → mul(s(X), fact(X)). We have:


[l ] = f (s X + s )+ f
+ (f′ (s X + s )+ f′ )f'' (s1 X+s0 )+f''

6	1  1
0	0	1  1
0	0  1	0

= f s X + f s + f + (f′ s X + f′ s
+ f′ )f'' s1 X+f'' s0 +f''

1 1	1 0	0	1 1
1 0	0  1	1	0

= A1X + A0 + (B1X + B0)C1 X+C0
[r ] = m (s X + s )(f X + f + (f′ X + f′ )f'' X+f'' )+

6	11  1	0	1	0	1
0  1	0

+m  (s X + s )+ m
(f X + f
+ (f′ X + f′ )f'' X+f'' )+ m

10  1
0	01  1	0	1
0  1	0	00

= f1m11s1X2 + (f1m11s0 + f0m11s1 + m10s1 + m01f1)X+
+f0m11s0 + m10s0 + m01f0 + m00

+m  s X(f′ X + f′ )f'' X+f'' + (m
s + m
)(f′ X + f′ )f'' X+f''

11 1	1
0  1	0
11 0
01	1
0  1	0

= A′ X2 + A′ X + A′ + D′ X(B′ X + B′ )C' X+C' + E′ (B′ X + B′ )C' X+C'

2	1	0	1	1
0  1	0	1	1
0  1	0

= A′ X2 + A′ X + A′ + (D′ X + E′ )(B′ X + B′ )C' X+C'

2	1	0	1	1	1
0  1	0


The application of the transformation rules in Figure 1 succeeds and yields

A'2 =0 ∧ B0 > 2 ∧ C0' > 0 ∧ C0 +2 = C0 ∧ B1 ≥ A'1 ∧ B0 ≥ A'0 ∧ B1 ≥ D1'

∧ B0 > E1' ∧ B1 ≥ B1' ∧ B0 > B0' ∧ C1 ≥ C1' ∧ C0 ≥ C0'

that is, we have to solve the following (polynomial) constraints:

A'2 = f1m11s0 + f0m11s1 + m10s1 + m01f1 = 0	(15)
B0 = f1' s0 + f0' > 2	(16)
C0' = f0'' > 0	(17)
C0 = f1''s0 + f0'' = C0 + 2		(18) A'1 = f1m11s0 + f0m11s1 + m10s1 + m01f1 ≤ f1' s1 = B1		(19) A'0 = f0m11s0 + m10s0 + m01f0 + m00 ≤ f1' s0 + f0' = B0	(20)

B1 = f1' s1 ≥ m11s1 = D1'
B0 = f1' s0 + f0' > m11s0 + m01 = E1' B1 = f1' s1 ≥ f1' = B1'
B0 = f1' s0 + f0' > f0' = B0' C1 = f1''s1 ≥ f1'' = C1'
C 0 ≥ f0'' = C0'
(21)
(22)
(23)
(24)
(25)
(26)

Note that all these constraints hold when we let the parametric coefficients take the values which are used in the linear elementary interpretation of Ex- ample 1.1 (together with C0 = 1).
Implementation issues
The implementation of the techniques described above is conceptually sim- ple, although its efficiency could highly depend on appropriate choices of the data structures and implementation languages. Comparing two polynomial expressions `a la Hong and Jakuˇs’ is pretty simple: we just perform an inde- pendent comparison of (coefficients of) monomials according to its composition in terms of variables and powers. With elementary expressions, things are not so simple. For instance, think of the elementary expressions [fact(s(X))] = (2X + 4)2X+3 and [mul(s(X), fact(X))] = (2X + 3)(2X + 2)2X+1 + 2X +2 
in Example 1.1. At first sight, the second expression is ‘more complicated’
and the first impression is that it cannot be smaller than the first one. How- ever, as shown in Example 5.2, indeed this is the case. The key point is that we can use the algebraic properties of the exponential to unfold the first ex- pression (2X + 4)2X+3 and show an equivalent (or smaller) expression whose shape is similar to the second one. In practice, when comparing elementary expressions e and e', this amounts to finding some clusters E = {E1,..., Em} and E' = {E1' ,..., En' } of subexpressions in e and e' in such a way that we can define a surjective mapping γ : E' → E such that the subexpression of e' represented by Ej' is smaller or covered by the subexpression in e represented by Ei = γ(Ej' ).
When comparing parametric expressions (which is the focus of this paper)
the problem is similar but now we do not have (many) specific numbers which can be used to do some algebraic manipulation. For this reason, the rule

K-Introd is so important: it allows us to ‘create’ new expressions including new variables and constants which are semantically related with the old ones by means of equality constraints. On the other hand, we would have to do clustering as well (but we have even more flexibility due to the possibility of introducing arbitrary constants).
Since it is well-known that exponential expressions are (ultimately) bigger than polinomial ones (disregarding the degree), a possible strategy is decom- posing e as e = p + e1 + ··· + em where p is a purely polynomial expression and the expressions ei contain some exponential subexpressions. Then, we use such ei (first) individually to establish appropriate corresponding clusters of subexpressions (additive components) in e' which satisfy the conditions above.

Conclusions and future work
In the nineties, Lescanne introduced and motivated the use of elementary alge- braic interpretations as an alternative to polynomial interpretations in proofs of termination of term rewriting. Lescanne considered elementary interpreta- tions over the naturals (actually over the subset of natural numbers starting from 2) and investigated how to check the inequalities [l] > [r] which are obtained for a given interpretation which should be provided by the user.
In this paper we have investigated elementary interpretations over the reals. We have introduced the linear elementary functions as a suitable choice for the automation of termination proofs using elementary interpretations. We have shown how the requirements of modern termination methods (e.g., the dependency pairs method) for a given termination problem are translated into parametric elementary constraints over the reals. We have defined a rule-based transformation system for checking and solving arbitrary (para- metric) elementary constraints over the reals. Using this system, universally quantified semantic variables are removed from the parametric constraints corresponding to a given termination problem while an existential constraint consisting of parametric coefficients (only) is built to subsequently invoke an appropriate solver. The obtained solution witnesses the satisfaction of the original constraint.
The most urgent future work is having an implementation of the proposed system. We have argued that this is not conceptually difficult but it could require more research before obtaining heuristics leading to an efficient and competitive system. On the other hand, the theory developed in this paper provides an appropriate guide for extending our initial proposal of linear el- ementary interpretations to more refined ones (for instance, one could allow that A, B, and C in (7) are arbitrary polynomials). The special cases enumer-

ated in Remark 4.1 could also be investigated since they have specific features which could enable a simpler implementation of constraint solving.
Acknowledgement
I thank Vicent del Olmo for the proof of Proposition 5.1. I also thank Albert Rubio, Vesna Pavlovic, and the referees for many useful comments.

References
B. Alarc´on, R. Guti´errez, and S. Lucas. Context-Sensitive Dependency Pairs. In S. Arun- Kumar and N. Garg, editors, Proc. of XXVI Conference on Foundations of Software Technology and Theoretical Computer Science, FST&TCS’06, LNCS 4337:297–308, 2006. Springer-Verlag.
B. Alarc´on, R. Guti´errez and S. Lucas, Context-sensitive dependency pairs, Technical report, Universidad Polit´ecnica de Valencia (2008), available as Technical Report DSIC-II/10/08.
T. Arts and J. Giesl. Termination of Term Rewriting Using Dependency Pairs. Theoretical Computer Science, 236:133-178, 2000.
F. Baader and T. Nipkow. Term Rewriting and All That. Cambridge University Press, 1998.
C. Borralleras, S. Lucas, R. Navarro-Marset, E. Rodr´ıguez-Carbonell, and A. Rubio. Solving Non-linear Polynomial Arithmetic via SAT Modulo Linear Arithmetic. In Proc. of CADE’09, LNAI 5663:294-305, 2009.
C. Borralleras and A. Rubio. Orderings and Constraints: Theory and Practice of Proving Termination. In H. Comon-Lundh, C. Kirchner, and H. Kirchner, editors, Rewriting, Computation and Proof, Essays Dedicated to Jean-Pierre Jouannaud on the Occasion of His 60th Birthday, LNCS 4600, 2007.
A. ben Cherifa and P. Lescanne. Termination of rewriting systems by polynomial interpretations and its implementation. Science of Computer Programming, 9(2):137-160, 1987.
E. Contejean, C. March´e, A.-P. Tom´as, and X. Urbain. Mechanically proving termination using polynomial interpretations. Journal of Automated Reasoning, 32(4):315-355, 2006.
N. Dershowitz. Termination of rewriting. Journal of Symbolic Computation, 3:69-115, 1987.
J.J. Gray. The Hilbert Challenge. Oxford University Press, 2000.
H. Hong and D. Jakuˇs. Testing Positiveness of Polynomials. Journal of Automated Reasoning
21:23-38, 1998.
J. Jaffar and J.-L. Lassez. Constraint Logic Programming. In Proc. of the 14th ACM Symposium on Principles of Programming Languages, POPL’87, pag. 111-119, ACM Press, 1987.
J. Jaffar and M.J. Maher. Constraint Logic Programming: A Survey. Journal of Logic Programming 19&20:503-581, 1994.
D.S. Lankford. On proving term rewriting systems are noetherian. Technical Report, Louisiana Technological University, Ruston, LA, 1979.
P. Lescanne. Termination of Rewrite Systems by Elementary Interpretations. In H. Kirchner and G. Levi, editors, Proc. of 3rd International Conference on Algebraic and Logic Programming, ALP’92, LNCS 632:21-36, 1992.
P. Lescanne. Termination of Rewrite Systems by Elementary Interpretations. Formal Aspects of Computing 7:77-90, 1995.

S. Lucas. Context-sensitive computations in functional and functional logic programs. Journal of Functional and Logic Programming, 1998(1):1-61, January 1998.
S. Lucas. Polynomials over the reals in proofs of termination: from theory to practice. RAIRO Theoretical Informatics and Applications, 39(3):547-586, 2005.
S. Lucas. Practical use of polynomials over the reals in proofs of termination. In Proc. of 9th International Symposium on Principles and Practice of Declarative Programming, PPDP’07, pages 39-50, ACM Press, 2007.
S. Lucas. Proving Termination of Context-Sensitive Rewriting by Transformation. Information and Computation, 204(12):1782–1846, 2006.
K. Marriot and P. Stuckey. Programming with Constraints. An Introducction. The MIT Press, 1998.
F. Rossi, P. van Beek, and T. Walsh. Handbook of Constraint Programming. Elsevier, 2006.
