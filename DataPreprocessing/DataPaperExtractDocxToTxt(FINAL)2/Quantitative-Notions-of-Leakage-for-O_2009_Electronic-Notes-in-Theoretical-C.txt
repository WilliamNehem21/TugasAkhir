

Electronic Notes in Theoretical Computer Science 249 (2009) 75–91
www.elsevier.com/locate/entcs

Quantitative Notions of Leakage for One-try Attacks
Christelle Brauna Konstantinos Chatzikokolakisb Catuscia Palamidessia
a INRIA and LIX, E´cole Polytechnique Palaiseau, France
{braun,catuscia}@lix.polytechnique.fr
b Technical University of Eindhoven Eindhoven, The Netherlands
{kostas}@chatzi.org

Abstract
Recent research in quantitative theories for information-hiding topics, such as Anonymity and Secure In- formation Flow, tend to converge towards the idea of modeling the system as a noisy channel in the information-theoretic sense. The notion of information leakage, or vulnerability of the system, has been related in some approaches to the concept of mutual information of the channel. A recent work of Smith has shown, however, that if the attack consists in one single try, then the mutual information and other concepts based on Shannon entropy are not suitable, and he has proposed to use R´enyi’s min-entropy instead. In this paper, we consider and compare two different possibilities of defining the leakage, based on the Bayes risk, a concept related to R´enyi min-entropy.
Keywords: Information-hiding, hypothesis testing, probability of error, R´enyi min-entropy.

Introduction
Information-hiding refers to a large class of problems including Secure Information Flow and Anonymity. There has been a growing interest in developing quantitative theories for this class of problems, because it has been recognized that non quanti- tative (i.e. possibilistic) approaches are in general too coarse, in the sense that they tend to consider as equivalent systems that have very different degrees of protection.
Concepts from Information Theory have revealed quite convenient in this do- main. In particular, the notion of noisy channel has been used to model protocols for information-hiding, and the flow of information in programs. The idea is that the input of the channel represents the information to be kept secret, and the output represents the observable. The noise of the channel is generated by the efforts of the protocol to hide the link between the secrets and the observable, often achieved by using randomized mechanisms.

1571-0661 © 2009 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2009.07.085

Correspondingly, there have been various attempts to define the degree of leak- age by using concepts based on Shannon entropy, notably the mutual information [14,4,7,8] and the related notion of capacity [10,9,2].
In a recent work, however, Smith has shown that the concept of mutual infor- mation is not very suitable for modeling the information leakage in the situation in which the adversary attempts to guess the value of the secret in one single try [12]. He shows an example of two programs in which the mutual information is about the same, but the probability of making the right guess, after having observed the
output, is much higher in one program than in the other. In a subsequent paper [13], Smith proposes to use a notion based on R´enyi min-entropy.
We look at the problem from the point of view of the probability of error : the probability that an adversary makes the wrong guess. We propose to formalize the notion of leakage as the “difference” between the probability of error a priori (before observing the output) and a posteriori (using the output to infer the input via the so-called MAP rule). We argue that there are at least two natural ways of defining this difference: one, that we call multiplicative, corresponds to Smith’s proposal. The other, which we call additive, is new. In both cases, we show that it is relatively easy to find the suprema, which is nice in that it allows us to consider the worst case of leakage. The worst case is also interesting because it abstracts from the input distribution, which is usually unknown, or (in the case of anonymity) may depend on the set of users.

Preliminaries
Noisy channels and Hypothesis Testing
In this section we briefly review some basic notions about noisy channels and hy- pothesis testing that will be used throughout the paper. We refer to [5] for more details.
A channel is a tuple ⟨X, Y, p(·|·)⟩ where X, Y are random variables representing, respectively, the input with possible values X = {x1, x2,..., xn} (the secrets or hypotheses) and the output with possible values Y = {y1, y2,..., ym} (the observ- ables). The distribution on X, →π = (π1,..., πn) is called a priori input distribution.
We will also use the notation p(xi) and p(yj) to indicate the probabilities of the in- put xi (i.e. p(xi) = πi) and the output yj, respectively. We will denote by p(yj|xi)
the conditional probability of observing the output yj when the input is xi. These conditional probabilities constitute what is called the channel matrix, where p(yj|xi) is the element at the intersection of the i-th row and j-th column.
The a posteriori probability p(xi|yj) is the probability that the input is xi, given that we observe the output yj. The a priori and the a posteriori probabilities of xi are related by Bayes theorem:



p(xi|yj) = 
p(yj|xi) p(xi)
p(yj)

In hypothesis testing we try to infer the true hypothesis (i.e. the value that was really given in input) from the observed output value. In general, it is not possible to determine the right hypothesis with certainty. We are interested, then, in minimizing the probability of error, i.e. the probability of making the wrong guess. We assume that the process of guessing the hypothesis is represented by a de- cision function f : Y → X , i.e. the function which gives, for every output yj, the
guessed input xi.
The (average) probability of error associated to f is given by the sum of the probabilities of guessing a wrong hypothesis for each given output, averaged by the probabilities of the outputs. Since the probability of making the wrong guess, when the output is yj, is given by 1 − p(f (yj)|yj), the average probability of error is:

PEf =	j p(yj)(1 − p(f (yj)|yj))
= 1 −	j p(yj)p(f (yj)|yj)
It is easy to see that a decision function fB minimizes the probability of error if and only if it satisfies the MAP (Maximum A Posteriori probability) criterion, namely, for each output yj it chooses an input xi for which p(xi|yj) is maximum. Formally:
fB(yj) = xi  ⇒  ∀k p(xi|yj) ≥ p(xk|yj)
It is easy to see that the probability of error associated to fB is then given by

PEB = 1 −	j p(yj) maxi p(xi|yj) By using Bayes theorem, we can rewrite PEB as:
PEB = 1 − Σj maxi(p(yj|xi) πi)

PEB is also called the Bayes risk. Note that it is a function of →π, so we will also write PEB (→π) when we need to emphasize its dependency on →π.

R´enyi entropies, Shannon entropy, and mutual information
R´enyi entropies [11] are a family of functions representing the uncertainty associated to a random variable. The R´enyi entropy of order α, with α ≥ 0 and α /= 1, is defined as


H (X) =	1
α	1 − α

log  Σ p(xi)α 


In the case of a uniform distribution all the R´enyi entropies of are equal to log n. Otherwise the entropies are weakly decreasing as a function of α. The following are

some particular cases:




H∞(X) = − log maxi p(xi)

Shannon conditional entropy of X given Y represents the average residual en- tropy of X once the value of Y is known, and it is defined as
H1(X|Y ) = − Σ p(y)H1(X|Y = y) = Σ p(xi, yj) log p(xi|yj) = H1(X, Y )−H1(Y )

where H1(X, Y ) represents the entropy of the conjunction of X and Y .
The mutual information of X and Y represents the correlation of information between X and Y . It is defined as
I(X; Y ) = H1(X) − H1(X|Y ) = H1(X)+ H1(Y ) − H1(X, Y )

It is possible to show that I(X; Y ) ≥ 0, with I(X; Y ) = 0 iff X and Y are indepen- dent.

Convexity and corner points
We recall here some basic notions of convexity. Let R be the set of real numbers. The elements λ1, λ2,..., λk ∈ R constitute a set of convex coefficients if, for every i ∈ {1,..., k}, λ ≥ 0 and  λ = 1. Given a vector space V , a convex combination of →v1, →v2,..., →vk ∈ V is any vector of the form i λi →vi where λ1, λ2,..., λk ∈ R are a set of convex coefficients.
Definition 2.1 (Convex set) A subset S of a vector space is convex if every convex combination of vectors in S is in S.
In the following we will denote by D(n) the domain of probability distributions of dimension n. It is easy to see that, for every n, D(n) is convex.
We give now the definition of convex function.
Definition 2.2 (Convex function) Given a convex subset S of a vector space V , and a function f : S → R, we say that f is convex if for any →v1, →v2,..., →vk ∈ S and any set of convex coefficients λ1, λ2,..., λk ∈ R, we have f ( i λi →vi) ≤ i λif (→vi). A function f is concave if its opposite −f is convex.
We now introduce (with a slight abuse of terminology) the concept of convex base.
Given a subset S of V , the convex hull of S, which we will denote by ch(S), is the smallest convex set containing S. Since the intersection of convex sets is convex, it is clear that ch(S) always exists.

Definition 2.3 Given two vector sets S and U , we say that U is a convex base for
S if U ⊆ S and S ⊆ ch(U ).
In the following, for a given vector →v = (v1, v2,..., vn), we will use the notation (→v, f (→v)) to denote the vector (with one additional dimension) (v1, v2,..., vn,f (→v)). Similarly, given a vector set S in a n-dimensional space, we will use the notation (S, f (S)) to represent the set of vectors {(→v, f (→v)) | →v ∈ S} in a (n + 1)-dimensional space. The notation f (S) represents the image of S under f , i.e. f (S) = {f (→v) |
→v ∈ S}.
Definition 2.4 Given a vector set S, a convex base U of S, and a function f : S → R, we say that U is a set of corner points of f if (U, f (U )) is a convex base for (S, f (S)). We also say that f is convexly generated by f (U ).
In other words, if U is a set of corner points of f , then for every →v ∈ D(n), there are elements →u , →u ,..., →u in U and λ , λ ,..., λ in R such that →v =  λ →u and
f (→v) = Σi λif (→ui).
Mutual Information and Capacity
In [12] Smith proved that the notion of mutual information (based on Shannon entropy) is not suitable to express the information leakage when the adversary tries to guess the value of the input in one single try. In fact, he showed an example of systems with the same mutual information, the same a priori uncertainty, and for which the probabilities of guessing the right input a posteriori (i.e. after observing the output) are very different.
The systems in Smith’s example are deterministic, i.e. have the property that the input determines univocally the output. For such systems, it turns out that the discrepancy observed for the mutual information does not arise in the case of the capacity. Surprisingly, indeed, Smith showed in [13] that, under a uniform input distribution, the capacity is equal to the logarithm of the ratio between the a posteriori and the a priori probability of making a right guess, which coincides with his proposal for the notion of leakage. We will come back on this point in the next section.
Unfortunately, this coincidence does not carry out to the more general case of probabilistic channels, and, worse yet, the notion of capacity suffers (in the general case) from the same problem as the mutual information. The following example illustrates the situation.
Example 3.1 Consider the following channels:


It is easy to see that the Shannon capacity of C is 1/3, while the one of D is 2/3. However, under the uniform input distribution, the ratio between the a posteriori and the a priori probability of making the right guess is the same (2).


Fig. 1. Channel matrix C

Fig. 2. Channel matrix D
Towards a more suitable notion of leakage
In the following, we are interested in quantifying the leakage of a security protocol,
i.e. the amount of information about the input that an adversary can learn by running the protocol and observing the resulting output.

Probabilities of a right guess
Before running the protocol, the probability that a given input xi occurs depends only on the a priori distribution →π, and a rational adversary will therefore assume that the most probable input, called the a priori probability of a right guess PRi (→π), will be the input having the maximum a priori probability, i.e.:
Definition 4.1 The a priori probability of a right guess is defined as

PRi (→π) = maxi πi
After running the protocol and seeing the output, the adversary may revise his guess. An adversary applying the MAP rule, when observing output yj, will choose as most probable input xi the one for which the a posteriori probability p(xi|yj) is the highest. The average of this value on all possible outputs gives the a posteriori probability of a right guess PRo(→π), which is the complement of the Bayes risk.
Definition 4.2 The a posteriori probability of a right guess is defined as

PRo(→π) =	j maxi(p(yj|xi)πi)
In the rest of this paper, we will consider only adversaries applying the MAP rule since this is the rule that gives the best result (from the point of view of the adversary).

Leakage and uncertainty
Intuitively, the leakage is the amount of information learnt by the adversary by observing the output of the protocol. Following [13], it seems natural to define it as the difference between the uncertainty about the input before observing the output, and the remaining uncertainty afterwards:
Information Leaked = Initial Uncertainty − Remaining Uncertainty	(1)
Now, the question is how to measure information, and (correspondingly) what do we actually mean by uncertainty. We consider here two possibilities. The first leads to a multiplicative notion of leakage, and it follows the proposal of Smith [13]. The second leads to an additive notion, and it is new.

Multiplicative leakage
In relation to Equation (1), Smith [13] measures the information in bits, and pro- poses to define the initial uncertainty as the min-entropy of X, H∞(X), the instance of R´enyi entropy [11] obtained for α = ∞. As for the remaining uncertainty, it would be natural to use the conditional min-entropy of X given Y . Unfortunately there is no agreement on what R´enyi’s generalization of Shannon’s conditional entropy should be, even though there seem to be a consensus towards  y p(y)Hα(X|Y = y) [1]. Smith however proposes to use the definition of H∞(X|Y ) equivalent to the one given in [6], which is
H∞(X|Y ) = − log PRo(→π)

In this way, Smith obtains a definition of leakage similar to the definition of mutual information, except that Shannon entropy is replaced by H∞:
PRo(→π)
L(X; Y ) = H∞(X) − H∞(X|Y ) = log PR (→π)
We consider a similar definition for leakage, namely the ratio between PRo(→π) and PRi (→π), which coincides with Smith’s notion apart from the absence of the log- arithm. Furthermore, in general we want to abstract from the a priori distribution, and consider the worst case, hence we are particularly interested in the supremum of such ratio.
Definition 4.3 We define the multiplicative leakage as
PRo(→π)

L×(→π) =
PRi (→π)

We will also use the notation ML× to represent the supremum of this quantity:

ML×  =  max(L×(→π))
→π
Note that PRi (→π) > 0 for every →π, hence L×(→π) is always defined.

Additive leakage
Another possible interpretation for Equation (1) is to consider the uncertainty as the probability of guessing the wrong input. The leakage then expresses how much the knowledge of the observable helps decreasing such probability. This leads to define the leakage as the difference between the probabilities of error before and after observing the output. As usual, we are particularly interested in the supremum of this difference.
Definition 4.4 We define the additive leakage as
L+(→π) = PRo(→π) − PRi (→π)
We will also use the notation ML+ to represent the supremum of this quantity:
ML+ =  max(L+(→π))
→π
Properties of the mutiplicative leakage
In this section we consider the multiplicative leakage and we study its supremum. It turns out that the supremum is very easy to compute. In fact, it coincides with the value of the leakage in the point of uniform distribution, and it is equal to the sum of the maxima of the columns. This property was also discovered independently by Geoffrey Smith and Ziyuan Meng (personal communication).
Proposition 5.1
ML× = L×(πu) =	max p(yj|xi)
i
j
where πu is the uniform distribution.
Proof
L×(π1,..., πn) =   1	 Σj maxi(p(yj|xi)πi)
≤   1	 Σj maxi p(yj|xi)(maxi πi)
= Σj maxi p(yj|xi)

n	n
= L×( 1 ,..., 1 )
n	n


Properties of the additive leakage
We turn now our attention to the additive leakage. We will see that the supremum is not always in the point of uniform distribution. However, we prove that it is in

one of the corner points of PRi . Since PRi has a finite set of corner points, and their form is known, also the additive leakage is relatively easy to compute.
First we prove a general property concerning the relation between suprema, convexity, and corner points:
Proposition 6.1 Consider two functions f, g : D(n) → R where f has a set of corner points U, and g is convex. Deﬁne h : D(n) → R as h(→v) = f (→v) + g(→v).
Let w→ ∈ D(n) be a point in which h has a maximum, i.e. for every →v ∈ D(n),
h(→v) ≤ h(w→ ). Then there exists →u ∈ U such that h(w→ ) = h(→u). Namely, the maximum value of h is in a corner point of f.
Proof

By contradiction. Suppose that for every →u ∈ U , h(→u) < h(w→ ). Since w→
∈ D(n),

there are elements →v , →v ,..., →v in U and c , c ,..., c in R such that w→ =	c →v
and f (→x) = Σi cif (→vi). Then
h(w→ ) = h(Σi ci→vi)
= f (Σi ci→vi)+ g(Σi ci→vi)
= Σi cif (→vi)+ g(Σi ci→vi)
≤ Σi cif (→vi)+ Σi cig(→vi) since g is convex
= Σi cih(→vi)
< Σi cih(w→ )	since →vi ∈ U
= h(w→ )	since Σ ci = 1 



An example of Proposition 6.1 is illustrated in Figure 3.
We now show that −PRi and PRo satisfy the hypotheses of Proposition 6.1.
The necessary property for −PRi comes from a result in [3].
Proposition 6.2 ([3], Proposition 3.9) The function PRi on D(n) is convexly generated by (U, f (U )) with U = U1 ∪ U2 ∪ ... ∪ Un where, for each r, Ur is the set of all vectors that have value 1/r in exactly r components, and 0 everywhere else.
Remark 6.3 The function −PRi has the same corner points as PRi .
We now prove that PRo satisfy the necessary property.
Proposition 6.4 PRo is convex.
Proof
Let →z be the convex combination	i λi →zi where the dimension of →z, →z1,..., →zm cor- responds to the number of input variables and →z1,..., →zm is a set of corner points.
The jth component zk of any corner point z→k corresponds to the input variable xk
j
chosen according to the MAP rule when the output variable yj is obtained.




Fig. 3. An illustration of Proposition 6.1


PRo(Σi λi →zi) = Σj maxk{p(yj|xk)(Σi λi →zi)k}
= Σj p(yj|xkj )(Σi λi →zi)kj
= Σj p(yj|xkj )(Σi λi zi,kj )
= Σj Σi λip(yj|xkj )zi,kj
= Σi λi Σj p(yj|xkj )zi,kj
≤ Σi λi Σj maxk p(yj|xk)zi,k
= Σi λiPRo(z→i)



Corollary 6.5 ML+ is reached on one of the corner points of PRi .
Proof
Since L+ = PRo − PRi and PRo is convex, Proposition 6.1 shows that if ML+ exists, it must be reached on a corner point of −PRi , which correspond to the corner points of PRi .	 

Remark 6.6 In general ML+ is not reached on the point of uniform distribution.
Example 6.7 Consider the channel whose matrix is given in Figure 4.
The calculation of L+ on the distributions corresponding to the corner points gives:



Fig. 4. Channel matrix (e ∈ [0, 1/2])

We have for every e ∈ [0, 1/2[,
0 = L+(1, 0, 0) ≤ L+(0, 1/2, 1/2) < L+(1/3, 1/3, 1/3) < L+(1/2, 1/2, 0) = 1/2
and L+(1/3, 1/3, 1/3) = L+(1/2, 1/2, 0) = 1/2 for e = 1/2. Therefore if e < 1/2, ML+ = 1/2, reached on distributions that are different from the uniform distribution (1/3, 1/3, 1/3).
Moreover, this remark holds also for symmetric matrices:
Remark 6.8 Even in case of symmetric matrices, in general ML+ is not reached on the point of uniform distribution.
Example 6.9 Consider the channel whose matrix is given in Figure 5.

Fig. 5.

Let →π = (1/r, 1/r,..., 1/r, 0,..., 0) be the a priori distribution with an equal probability of 1/r for the r first inputs. This distribution is a corner point of the

matrix, and since the matrix is symmetric, any other corner point corresponding to a distribution containing r non-null probabilities of 1/r will give the same results for PRi , PRo and L+.


PRi (→π) = 1/r



PRo(→π) =	1,...,11(1/r)(1/10)
= 11/(10r)


L+(→π) = PRo(→π) − PRi (→π)
= 1/(10r)

Therefore ML+ is reached when r has the smallest value, i.e. when r = 2. This corresponds to the distribution (1/2, 1/2, 0,..., 0) and gives ML+ = 1/20, while L+(1/11,..., 1/11) = 1/110.



Comparison
In this section, we compare the two notions of leakage. We first compare them with respect to a specific distribution, and then we consider the comparison of their worst cases.
If we consider a specific distribution, it comes out that the two notions are equivalent, in the sense that a program is better with respect to the additive notion if and only if it is better with respect to the multiplicative notion.

Proposition 7.1 Consider two programs P and P', and let L+ and L+' be the additive measures of leakage for P and P ', respectively. Analogously, let L× and L×' be the multiplicative measures of leakage for P and P', respectively. We have that, for every →π

L+(→π) ≤ L+'(→π)	⇔	L×(→π) ≤ L×'(→π)

Proof
Let PRo and PRo' be the a posteriori probability of a right guess for P and P', respectively. Analogously, let PRi and PRi ' be the a priori probability of a right

guess for P and P ', respectively. Observe that PRi (→π) = maxi πi = PRi '(→π). Hence

L+(→π)	≤	L+'(→π)	⇔	PRo(→π) − PRi (→π)	≤	PRo'(→π) − PRi '(→π)


PR (→π) − PR (→π)
⇔	max πi
i
PRo(→π) − PRi (→π)
⇔	PRi (→π)
PRo'(→π) − PRi '(→π) max πi
i
PRo'(→π) − PRi '(→π)


PRi '(→π)

PRo(→π)
⇔	PRi (→π)
PRo'(→π)
PRi '(→π)


⇔	L×(→π)	≤	L×'(→π)



Another criterion of comparison is the worst case. We consider the two notions on some examples.
Example 7.2 Let us consider a 2k × 2k channel with the 2k first natural numbers as inputs and outputs, i.e. X = Y = {0,..., 2k − 1}. Consider a random input variable X with values ranging in {0, 2k − 1}.
Consider the following program:
Program P(X)
D Input X
if X = 0 or X = 1 
then Output X
else Output one of the values {2,..., 2k − 1} chosen randomly according to the uniform distribution
This program corresponds to a channel whose matrix is given in Figure 6.

Fig. 6. Channel matrix (p = 1/(2k − 2)= 1/2k−1)

Let us consider first ML+. Because of Corollary 6.5, we know that ML+ is reached on a corner point, i.e. a distribution of the form (q1,..., q2k ) where each qi is either 0 or 1/r, and there are r elements with value 1/r in the distribution.
For every corner point →π we have PRi (→π) = 1/r, thus maximizing L+ for a given r is equivalent to maximizing PRo. From the channel matrix, one can see that the maximum value of PRo is reached on an input distribution where the two first elements are as high as possible.
Therefore, we can restrict our study to distributions of the form (1/r,..., 1/r, 0 ..., 0), i.e. distributions where the elements with value 1/r are the r first elements.
For r = 1, we have:




Thus:



For r = 2, we have:




Thus:



For r ≥ 3, we have:
PRi (1, 0,..., 0) = 1
PRo(1, 0,..., 0) = 1

L+(1, 0 ..., 0) = 0
L×(1, 0,..., 0) = 1


PRi (1/2, 1/2, 0 ..., 0) = 1/2

PRo(1/2, 1/2, 0,..., 0) = 1

L+(1/2, 1/2, 0 ..., 0) = 1/2
L×(1/2, 1/2, 0,..., 0) = 2


PRi (1/r, 1/r, 1/r, 0,..., 0) = 1/r






Thus:
PRo(1/r, 1/r, 1/r, 0,..., 0) = 1/r + 1/r + (2k − 2) ∗ (1/r) ∗ p
= 3/r

L×(1/r, 1/r, 1/r, 0,..., 0) = 3


L+(1/r, 1/r, 1/r, 0,..., 0) = 2/r
We observe that for r ≥ 3, the value of L+ decreases when r increases. Since
L+(1/3, 1/3, 1/3, 0,..., 0) = 2/3 > L+(1/2, 1/2, 0,..., 0) = 1/2 > L+(1, 0,..., 0) =
0, we have ML+ = 2/3 reached for r = 3.
In particular, ML+ > L+(1/2k,..., 1/2k) = 1/2k−1 for all k > 1.
Concerning L×, we have that, for r ≥ 3, L×(1/r, 1/r, 1/r, 0,..., 0) = 3 >
L×(1/2, 1/2, 0,..., 0) = 2 > L×(1, 0,..., 0) = 1, thus ML× = 3, reached on any

distribution (1/r, 1/r, 1/r, 0,..., 0) with r ≥ 3, and in particular on the uniform distribution, which confirms Proposition 5.1.
Example 7.3 Let us consider the following program:
Program P'(X)
D Input X
with probability 3/2k Output X
with probability 1 − 3/2k Output a value in {0, 2k − 1}\{X} chosen randomly
according to the uniform distribution
This program corresponds to a channel whose matrix is given in Figure 7.

Fig. 7. Channel matrix (p1 = 3/2k and p2 = (1 − (3/2k))/(2k − 1))
The symmetry of the matrix implies that we can restrict the study to the a priori distribution →π = (1/r, 1/r,..., 1/r, 0,..., 0), where the r elements with value 1/r are the first elements in the distribution.
In this case, for r ≥ 1:





Finally:
PRi (→π) = 1/r
PRo(→π) = r(p1/r)+ (2k − r)(p2/r)
= p1 + [(2k/r) − 1]p2

L+(→π) = p1 − p2 − 	2	

Thus L+ increases when r increases, and ML+ = 1/2k−1 is reached for r = 2k (on the uniform distribution).
L×(→π) = rp1 + (2k − r)p2
= r(p1 − p2)+ 2kp2
Since p1 > p2, L× increases when r increases, and thus ML× = 3 is obtained for r = 2k (on the uniform distribution, which confirms Proposition 5.1).
The programs P and P' have therefore the same worst-case multiplicative mea- sures of leakage ML× = 3, but the worst case of the additive measure of leakage ML+ is equal to 2/3 for P and equal to 1/2k−1 for P'.

Conclusion
We have considered two notions of leakage related to the Bayes risk. One of them, which we call multiplicative, corresponds to the notion recently proposed by Smith based on Renyi min-entropy. The other, which we call additive, is new. We have shown that the two notions are equivalent in all distributions. If we consider the distributions that give the worst case for the leakage, however, then the two notions are different. In particular, the multiplicative one has the worst case always in correspondence of the uniform distribution, while this is not the case for the additive one. So we can consider the new notion as a criterion, in addition to the one of Smith, to help assessing the degree of protection offered by a protocol or a program.

Acknowledgement
We are grateful to Pasquale Malacaria and to Geoffrey Smith for the many fruitful discussions.

References
Cachin, C., “Entropy Measures and Unconditional Security in Cryptography,” Ph.D. thesis, Swiss Federal Institute of Technology, Zu¨rich, Switzerland (1997).
URL ftp://ftp.inf.ethz.ch/pub/publications/dissertations/th12187.ps.gz

Chatzikokolakis, K., C. Palamidessi and P. Panangaden, Anonymity protocols as noisy channels, Information and Computation 206 (2008), pp. 378–401, http://www.lix.polytechnique.fr/
~catuscia/papers/Anonymity/Channels/full.pdf.
URL http://hal.inria.fr/inria-00349225/en/

Chatzikokolakis, K., C. Palamidessi and P. Panangaden, On the bayes risk in information-hiding protocols, Journal of Computer Security 16 (2008), pp. 531–571.
URL http://hal.inria.fr/inria-00349224/en/

Clark, D., S. Hunt and P. Malacaria, Quantitative information flow, relations and polymorphic types, Journal of Logic and Computation, Special Issue on Lambda-calculus, type theory and natural language 18 (2005), pp. 181–199.
Cover, T. M. and J. A. Thomas, “Elements of Information Theory,” John Wiley & Sons, Inc., 1991.
Dodis, Y., R. Ostrovsky, L. Reyzin and A. Smith, Fuzzy extractors: How to generate strong keys from biometrics and other noisy data, SIAM J. Comput 38 (2008), pp. 97–139.
URL http://dx.doi.org/10.1137/060651380

Malacaria, P., Assessing security threats of looping constructs, in: M. Hofmann and M. Felleisen, editors, Proceedings of the 34th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, POPL 2007, Nice, France, January 17-19, 2007 (2007), pp. 225–235.
URL http://doi.acm.org/10.1145/1190216.1190251

Malacaria, P. and H. Chen, Lagrange multipliers and maximum information leakage in different observational models, in: U´lfar Erlingsson and Marco Pistoia, editor, Proceedings of the 2008 Workshop on Programming Languages and Analysis for Security (PLAS 2008) (2008), pp. 135–146.
Moskowitz, I. S., R. E. Newman, D. P. Crepeau and A. R. Miller, Covert channels and anonymizing networks., in: S. Jajodia, P. Samarati and P. F. Syverson, editors, WPES (2003), pp. 79–88.
Moskowitz, I. S., R. E. Newman and P. F. Syverson, Quasi-anonymous channels, in: IASTED CNIS, 2003, pp. 126–131.
R´eny, A., On measures of entropy and information, in: Proceedings of the 4th Berkeley Symposium on Mathematics, Statistics, and Probability, 1960, pp. 547–561.


Smith, G., Adversaries and information leaks (tutorial), in: G. Barthe and C. Fournet, editors, Proceedings of the Third Symposium on Trustworthy Global Computing, Lecture Notes in Computer Science 4912 (2007), pp. 383–400.
URL  http://dx.doi.org/10.1007/978-3-540-78663-4_25

Smith, G., On the foundations of quantitative information flow, in: L. De Alfaro, editor, Proceedings of the Twelfth International Conference on Foundations of Software Science and Computation Structures (FOSSACS 2009), Lecture Notes in Computer Science 5504 (2009), pp. 288–302.
Zhu, Y. and R. Bettati, Anonymity vs. information leakage in anonymity systems, in: Proc. of ICDCS
(2005), pp. 514–524.
