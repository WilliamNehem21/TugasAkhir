Electronic Notes in Theoretical Computer Science 104 (2004) 113–128 
www.elsevier.com/locate/entcs


Lazy Algorithms for Exact Real Arithmetic
Pietro Di Gianantonio 1 ,2
Dipartimento di Matematica e Informatica Universit`a di Udine
via delle Scienze 206, I-33100 Udine, Italy
Pier Luca Lanzi 3
Dipartimento di Elettronica e Informazione Politecnico di Milano
Piazza Leonardo da Vinci 32, I-20133 Milano, Italy

Abstract
In this article we propose a new representation for the real numbers. This representation can be conveniently used to implement exact real number computation with a lazy programming languages. In fact the new representation permits the exploitation of hardware implementation of arithmetic functions without generating the granularity problem. Moreover we present a variation of the Karatsuba algorithm for multiplication of integers. The new algorithm performs exact real number multiplication in a lazy way and has a lower complexity than the standard algorithm.
Keywords: Exact real arithmatic, Karatsuba algorithm, lazy functional programming.


Introduction
Computation on real numbers is commonly solved, with a computer, using a subset of rationals. A real is represented using the classical floating point notation by a fixed size exponent and mantissa. The arithmetic based on this notation is intrinsically inexact. Errors are first introduced on data and then are propagated during computation. To cope with errors introduced by

1 Research supported by Italian MIUR project COFIN 2001013518 CoMeta.
2 Email: digianantonio@dimi.uniud.it
3 Email: lanzi@elet.polimi.it



1571-0661 © 2004 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2004.08.021


floating point representation a wide variety of methods of numerical analysis, relatively insensitive to rounding errors, have been devised. Due to the success of numerical analysis only in the latest years the alternative solutions to float- ing point arithmetic, dubbed exact real arithmetic have been studied[2,9,13]. Exact real arithmetic is the implementation of real arithmetic based on the constructive approach to classical analysis. A real number is not simply represented with an approximated value but with a function that can com- pute every approximation of the number. Thus the resulting arithmetic is error free because every result can be required with any number of fractional digits. Although computation using exact arithmetic will almost certainly re- quire more computational resources than the corresponding computation using floating-point arithmetic the plumbering cost of computer resources suggests that exact real arithmetic may become an attractive option in some scientific and engineering applications. For this reason it is already used in computa- tion where efficiency is not the primal goal such as formal testing of numerical
algorithms.
Approaches to exact arithmetic can be classified in two main branches according to the representation used for reals and to the language used to implement the arithmetical algorithms. A real number can be represented, using rational converging series, with the characteristic function which gener- ate the succession. The corresponding implementation [2] is dubbed functional implementation. A real can also be represented with an infinite sequence of digits that can be conveniently implemented using a language able to represent infinite lists such as lazy languages (e.g. Haskell, Scheme, Russell). The corre- sponding implementation is dubbed lazy implementation. One should remark that the digit notation is not the only notation used by lazy implementations, there are lazy implementations based on continuous fraction notation [12] or on the Moebius transformation [9].
This classification was first proposed by Boehm and Cartwright[3] who first realized implementations using both approaches and compared the resulting performance. Their research showed that even if real representations used in lazy implementations are more natural and elegant the resulting implemen- tation fails to be as efficient as the functional one. This is mainly caused by coerse granularity of the representation and by arithmetical algorithms used in lazy implementation that have a higher complexity order. A rappresen- tation has a coarse granularity when the finite approximations of mantissa approximated can have a number of binary digits that is is multiple of some large number (tipically 16 or 32), in a representation with coars granulariti many finite approximations of an arbitrary lengh are not allowed.
In this paper we propose a new lazy implementation for exact real arith-


metic which gives a solution to problems evidenced by previous authors. Our study starts to examine experiences and results that authors presented [1,3]. This lead us to a new representation for computation over real num- bers dubbed “Digit-Error” notation which turns out to be insensitive to the representation granularity. The algorithms for arithmetic and transcendental functions are then given. Then we focus on multiplication algorithm. Classical algorithm commonly used in lazy implementations is, in general, less efficient than the algorithm used in functional implementations. We asked to ourselves if the new representation could lead to a better algorithm. The answer to this question is given by the new multiplication algorithm presented in this paper. This is inspired to Karatsuba’s algorithm for integer multiplication and have a complexity order lower than previous algorithms used in lazy implementations. Section 2 introduce the mathematical foundations of exact arithmetic. The previous experiences on functional and lazy implementation made by Boehm and Cartwright, are the subject of Section 3. In Section 4 the new “Digit- Error” representation is introduced and it is shown how it solves granularity problem. Sections 5 is devoted to algorithms developed to implement the fundamental operation with “Digit-Error” notation, while in Section 6 the new multiplication algorithm is presented. A survey of all the implementations realized with “Digit-Error” notation is made in Section 7, while in Section 8
the results we obtained and future developments are discussed.

Formal Foundations
It is not possible to represent every real number in a computer, thus to im- plement exact real arithmetic only the subset of Representable Reals (dubbed also as Constructive, Computable or Recursive Reals) must be taken. This set contains every real for which there exists an algorithm that compute ev- ery approximation of the number. The first definition of this set was given by Turing [11] in 1937 and it has been the starting point for a great num- ber of different approaches to the study of classical analysis concepts from a constructive viewpoint. This research field has been dubbed in different ways: Constructive Analysis, Computational Analysis or Recursive Analysis. The intuition underlying Constructive Analysis is simple: every mathematical statement must have a numerical meaning, for this reason the classical real set R is substituted with the set of constructive reals. This set contains every real number commonly used and it is closed under all functions that commonly arise in analysis.
Definition 2.1 [Representable Real] A real number r is computable if there

exists a computable function fr : N → Q such that
∀n ∈ N |f (n) − r| < 1
r	n
function fr above is called functional representation for r.
Some interesting aspects of computability theory over constructive reals are given by the following proposition. Let r ∈ R represent an arbitrary computable real number. No algorithm can compute in finite time:
if r = 0;
if r > r' for any fixed r' ∈ R;
if r ∈ Q;
the first digit of the decimal expansion of r;
the first term [r♩ ∈ Z of the regular continued fraction expansion of r;
the value f (r) ∈ R of any function f which is not continuous at r.

Real Representations
An important difference between classical analysis and constructive analysis lies in the way real numbers are represented. In classical analysis different rep- resentations for real numbers define the same set R. Thus analysis, as we know it, can be built without ever having to worry about the representation chosen. This is not true for constructive analysis where, even if many representations are still equivalent, there are some exceptions. For example Dedekind cuts and Cauchy sequences do not induce the same subset of computable functions on real numbers ([10]). The choice of representation become an important matter because it the first defines the subset of real numbers used and set of computable functions.
Between the various constructive representations for real numbers used in exact real arithmetic, the one presented in Definition 1 can be taken as reference because it has been the base for the first implementation proposed ([1]). But this representation is not the best choice from the efficiency point of view. If we want to implement the arithmetic operation in a computer is convenient to exploit the integer arithmetic already implemented in the hardware. This can be obtain representing real numbers using sequence of integers in fact:
Proposition 3.1 For every representable real r there exists a computable function gr : N → Z such that
∀n ∈ N |gr(n) − r × 4n| < 1


Using (prop.1) exact real arithmetic based on representable reals is re- alized implementing reals by functions from N to Z, while algorithms are implemented by functionals. For instance the addition algorithm for two real numbers x and y is simply defined with a function fx+y such that:
∀n ∈ N |fx+y(n) − (x + y) × 4n| < 1 thus fx+y can be defined as:

(1)

fx+y
= [ fx(n + 1) + fy(n + 1) ♩
4

An alternative representation proposed in literature is based on the posi-
tional radix representation and represents a real number as potentially infinite stream of digits. Thus a constructive real is represented by a computable se- quence of integers d0.d1 .. .. The first term d0 specifies the signed whole part of the number, the remaining terms (d1d2 .. .) specify the fractional part of the number.
The lazy evaluation mechanism produces result digits on demand start- ing from digit d0. At the first time only the first digit of the result is given. Subsequent digits can be computed when needed. This type of evaluation saves computational time against classical functional evaluation mechanism. First because only strictly needed digits are computed, second and most im- portant lazy evaluation mechanism is monotonic: once a digit is computed it never changes, then computed digits can be stored in memory and do not need to be recalculated. Instead with functional implementation subsequent computation with growing accuracy must recalculate all the digits every time. Thus computational time is wasted. We refer to this fact as the recalculation problem for functional implementations.
It is a well-known fact that monotonicity of lazy evaluation mechanism makes standard arithmetic operations uncomputable with the classical deci- mal representation. Consider the following situation in the radix positional notation with decimal base. Let x denotes the numbers 0.333 .. .. There are two possible results for the multiplication by 3, namely 1.000 ... and 0.999 .. .. If the algorithm generates 1 as first digit, this happen after the algorithm has examined a finite number of digits of the argument. Suppose that the first n digits have been examined before generating 1. The addition algorithm is going to generate 1 as a first digit also when the argument is 0.3 ... 30 ... . The given result is incorrect, because it should be 0.9 ... 90   An analogous
consideration can be done if the algorithm generates 0 as first digit. Multi- plication by 3 should collect an infinite amount of information before it can generate the first digit of the answer. This is not an isolated phenomenon, similar examples can also demonstrate that the other arithmetical operations are not computable on classical representation.


A simple solution to this computability problem consists in representing a real number by a stream of positive and negative digits. Consider again the example above. The addition algorithm based on the new representation can generate 1 as first digit, if after n digits the argument becomes 0.3 ... 30 then the algorithm can generate −1 at position n + 1. The result become
1.0 ... 0(−1) = 0.9 ... 9.

Definition 3.2 A real number r is represented in negative-digit representa- tion by an integer succession s0 ... si ... such that:
∀i ∈ N+ − 10 < si < 10
r = Σ∞  si10−i

An exact real arithmetic based on negative-digit representation is best implemented when the base equals to the largest integer that the underly- ing hardware can manage. This permits faster operations on digits and best memory usage. Unfortunately exact real arithmetic based on negative-digit representation and large base evidence a granularity problem [2], that is best explained with an example. Given two real numbers x and y using negative- digit notation, in order to determine the first n fractional digits of the result x + y, it is necessary to determine the first n + 1 digits of x and the first n +1 digits of y. Consider now the computation flow to evaluate the integer part of
the result (x1 +(x2 +(... (xk−1 +xk) .. .). The program will perform k −1 addi- tions in the order defined by the parenthesis, and thus it will need to examine i fractional digits of xi to determine the integer part of the result. Thus xn
will be evaluated to n fractional digits that is typically 16n or 32n fractional bits if digits di are stored respectively as a one word or two words of memory. Instead it is clear that n fractional bits would be sufficient. Phenomena of this kind can be evidenced in many other contexts.
Another problem is evidenced using this type of representation. Algo- rithms used with lazy implementations are adapted from classical algorithms taught in grammar school. Thus complexity order is linear for addition and subtraction but quadratic for multiplication and division. This result is worse than the one obtained for implementations based on (def.1) where addition and subtraction algorithms are still linear but complexity of multiplication and division algorithms can be lowered to O(n1.59) 4 .


4 Due to recalculation problem it is not possible to give an exact valuation of complexity order for functional multiplication. O(n1.59) must be taken as lower bound.

A “Digit-Error” representation for real numbers
As stated in the previous section the granularity problem, evidenced in lazy approaches, does not depend on the nature of the arithmetic operations, nei- ther on the algorithms used. It only depends on the representation used for real numbers. For this reason our proposal for a new lazy approach to exact arithmetic begins with the definition of a new representation for computable reals.
The “Digit-Error” notation has been introduced by the first author in [4] as a first solution to granularity. This representation differs from the previous used [3] for two main features. First “Digit-Error” notation uses an enlarged set of digits, that is, from (−b, b) to (−b2, b2) where b is the base used.
Second, an integer is associated to every digit of the representation. This integer, called error digit, ranging over the interval [0, b], gives an upper bound to the numbers represented by the remaining, less significative, digits. This additional information is used by arithmetical algorithms to measure approx- imation errors that influence digits.
Definition 4.1 A real number r is represented using “Digit-Error” notation, given a base b ∈ N : b > 1, by a pair (em, m) where em ∈ Z represent the exponent and m the mantissa given by the succession
⟨d0, e0⟩, ⟨d1, e1⟩ ... 
of integer pairs such that:
−b < d0 < b
∀i ∈ N+. − b2 < di < b2
∀i ∈ N.0 ≤ ei ≤ b
∀i ∈ N.ei ≥ | Σj∈N+ di+jb−j|
r = Σi∈N dib−i
Note that with the mantissa part we can only represent numbers in the interval [−2b + 1, 2b − 1]. To represent arbitrary large real numbers the exponent is needed. To keep arguments simple we present the algorithms only for the mantissa part of the representation. Algorithms for the “mantissa– exponent” representation can been derived with minor technical problems.
It is easy to show that this definition is totally equivalent to the functional representation given in [3]. To show how the granularity problem is solved by (def.3) consider again the sum x + y: to evaluate n fractional digit of the result the algorithm for the “Digit-Error” notation will evaluate x, and y to the first n digits beyond the decimal point and the n − th error digits exn , eyn of the arguments. If error exn + eyn on digit n of the result is small enough


the result can be considered correct and no additional computation is needed, otherwise, if the error is too large the next digit of x and y will be evaluated to lower approximation errors on digits n. The granularity problem is then solved, in fact, using “Digit-Error” notation real numbers are evaluated only at the strictly requested accuracy.

Standard Algorithms
We present the main algorithms devised for “Digit-Error” representation these are similar to those presented in [3], derived from classical algorithms. A new multiplication algorithm with a complexity order less than classical is presented in Section 6 while in this section the implementation proposed in
[4] is given. For sake of simplicity we present algorithms only for the mantissa part, the complete version of the algorithms can be found in [8].
Algorithms are written using Gofer-like syntax [6].

The norm function
Function norm has been introduced to lower the approximation of the first digit of the mantissa, augmenting the known accuracy. norm is unary and corresponds to identity functions: it only modifies the representation of the argument not the represented real value itself. This function reduce error e0 of the first digit x0 adding the possible carry of digit x1 to x0 by replacing x1 with the value x1mod b.
Algorithm 1 (Function normr)
normr(⟨x0, e0⟩ : ⟨x1, e1⟩ : xtail )= ⟨x0, 2⟩ : ⟨x1, e1⟩ : xtail
where
x0 = x0 + (x1 div b)
x1 = x1 mod b
The new value for the first digit error e0 is 2, that is the upper bound for the possible error on the first digit of the new representation.

Addition (Subtraction) Algorithm
As pointed out in Section 4 the addition algorithm for negative digit nota- tion, to produce the result, has one digit of lookahead that causes granularity problems.

The algorithm presented here solves this problem using error digits.
Algorithm 2 (Addition +r)
+r(⟨x0, ex0 ⟩ : xtail , ⟨y0, ey0 ⟩ : ytail) = 
| ⟨x0 + y0, ex0 + ey0 ⟩ : +r (xtail , ytail),
if ex0 + ey0 ≤ b
| +r(normr( ⟨x0, ex0 ⟩ : xtail ) , normr( ⟨y0, ey0 ⟩ : ytail ) ),
if ex0 + ey0 >b
The norm function is used to lower accuracy error on the arguments when the result digit turn to be not enough accurate or equivalently when ex0+ey0 >
b. First digit of the sum of two reals is computed as follows. First the sum of the first error digits is computed. If ex0 + ey0 is small enough the first digit of the sum x0 + y0 is produced. Otherwise, if ex0 + ey0 is too large, that is greater than the base, function normr is applied to arguments and (alg.2) is applied again. As shown in Section 4 this algorithm does not suffer of the granularity problem.
Subtraction algorithm is similar.

Classical Multiplication
Given two real numbers x, y expressed by
∞	∞
x = Σ xib−i	y = Σ yib−i

i=0
the product x × y can be written as
x × y = (x0 + b−1xtl ) × (y0 + b−1ytl )
i=0

= x0y0 + b−1(y0xtl  + x0ytl )+ b−2ytl xtl


where


xtl1

= Σ xi+1b−i  ytl
i=0

= Σ yi+1b−i
i=0

Thus result can be computed using more simple operations such product of a real number and a digit. Implementations presented in literature are all based on this type of algorithm ([4,3]). Multiplication algorithm for “Digit-Error” notation presented in [4] is given using functions ×r and ×aux:
×r (x, y) computes (x × y)/b2
×aux (d, x, r) computes (d × x)/b2 + r/b, where d, r are digits (integers) and x is a real.


Algorithm 3 (Function ×r)
×r(⟨x0, ex0 ⟩ : xtail, ⟨y0, ey0 ⟩ : ytail)= 
| ⟨x0y0 div b2, exy ⟩ : +r(+r(×aux(x0, ytail, x0y0 mod b2),
×aux(y0, xtail, x0y0 mod b2)),
⟨0, 1+ x0y0 mod b2⟩ : ×r( xtail , ytail )),
if exy0 ≤ b
| ×r(normr(⟨x0, ex0 ⟩ : xtail ), normr( ⟨y0, ey0 ⟩ : ytail )) 
if exy0 > b
where exy =2 + (x0ey + y0ex ) div b2 Algorithm 4 (Function ×aux)
×aux( d, ⟨x0, e0⟩ : xtail , r )= 
| ⟨value div b2, error⟩ : ×aux( d, xtail , value mod b2)
if error ≤ b
| ×aux( d norm( ⟨x0, e0⟩ : xtail ), r )
otherwise
where
error =2 + (d ∗ e0) div b2
value = x0 ∗ d + r ∗ b


Division
There are two algorithms that can be used to implement division between two real numbers. The former uses the Newton’s method to compute the inverse of the divisor and then multiply the result by the dividend. This has been used with functional implementations. The second algorithm is derived from the Euclidean division algorithm adapted to work with an infinite divisor. This is the algorithm commonly used with lazy implementations, and it is the one we also used to realize division on “Digit-Error” notation.
Our implementation uses a set of auxiliary functions, namely ÷aux, remainderr, and shif t.
÷r(x, y) initializes the computation calling the function ÷aux.
÷aux(x, y, e) is the main part of the algorithm for division between x and y, the argument e is used to calculate the errors.
remainderr(x, y, d) returns the value x − yd, where the argument d is a digit.
shif t(x) returns the value xb .

The formal definition is the following.
Algorithm 5 (Quotient: ÷r)
÷r(⟨x0, e0⟩ : xtail , ⟨y0, f0⟩ : ytail) = 
| ÷aux(⟨x0, e0⟩ : xtail , norm( ⟨y0, f0⟩ : ytail ) , y0 ∗ (y0 − 2)),
if b < y0
| ÷r( shif t( ⟨x0, e0⟩ : xtail ) , shift( ⟨y0, f0⟩ : ytail ) ),
if b ≥ y0
Algorithm 6 (Quotient: ÷aux)
÷aux(⟨x0, e0⟩ : xtail , ⟨y0, f0⟩ : ytail , e ] = 
| ⟨(x0 ÷ y0), exy0 ⟩ :
÷aux(remainder( ⟨x0, e0⟩ : xtail , ⟨y0, f0⟩ : ytail , (x0 ÷ y0) ),
⟨y0, f0⟩ : ytail ,x ),
if exy0 < b
| ÷aux( norm(⟨x0, e0⟩ : xtail ) , ⟨y0, f0⟩ : ytail , x ),
if exy0 ≥ b
where exy0 = 4 + (((x0 ∗ f0)+ (y0 ∗ e0)) ÷ e)

Algorithm 7 (Division: remainderr)
remainderr(⟨x0, e0⟩ : xtail , ⟨y0, f0⟩ : ytail , d )= 
shif t( −r( ⟨x0, e0⟩ : xtail , shift( shif t( ×aux( d, ⟨y0, f0⟩ : ytail , 0))))) 
Note that the presented algorithm for division uses only the first digits of the arguments to compute the first digit of the result while it is the remain- der, obtained using the computed digit, that keeps trace of both the infinite arguments.

Transcendental Functions: sin x, cos x, ex
Other functions realized for “Digit-Error” notation are sine, cosine and expo- nential. We compute these functions using Mac Laurin series approximation:
x	x2	xn
e =1 + x +	+ ... +	+ Rn(e, x)
2	n!

x3	x5
n  x2n+1

sin x = x −		+		+ ... + (−1) 3!		5!
(2n + 1)! + Rn(sin, x)

x2	x4
n x2n

cos x =1 −		+		+ ... + (−1) 2!		4!
(2n)! + Rn(cos, x)


To compute these series in the “Digit-Error” notation is quite simple. Consider first how an approximated result for a suitable f (x) is obtained with a given accuracy from Mac Laurin Series. Given a real number r and the required precision, using the remainder R(f, x) the number of n terms that guarantee the expected accuracy is computed. Then the first n terms are added and the result is given.
Almost the same algorithm can be applied to “Digit-Error” notation: the first digit of the result is computed adding first n1 terms that assure its ex- actness. For every subsequent digit j the precision is improved adding to previous result nj terms that guarantee the exactness of the next digit. If all these operations are made using algorithms just proposed, the result produced is represented in “Digit-Error” notation.
Nevertheless, implementation of this algorithm is complicated by the com- putation of approximation error R(f, x) that in general is:



For ex the formula becomes:
θ  xn+1
R(f, x)= f

(n)
(θ)
xn+1


(n + 1)!

(2)
Rn(x)= e
θ ∈ (−x, x)
(n + 1)!

A problem is evidenced: to compute approximation error for function ex the value eθ must be evaluated. An upper bound for eθ is needed. In our imple- mentation we used:
[x|  xn+1

Rn(e, x)=3 


(n + 1)!

Thus approximation error is computed with the underlying integer arithmetic only. Unfortunately the number of terms computed using the upper bound, when x is large, is greater than the number of terms really needed with (2).

Multiplication Algorithm
As evidenced in [3] arithmetic algorithms for multiplication and division used in lazy implementations are less efficient than the ones used with functional implementations. Although the former approach does not waste computa- tional time for recalculation, due to algorithm complexity it turns out to be less efficient than the latter approach.
Owing to the similarity between (def.3) and classical positional notation the arithmetical algorithms used with lazy implementations have always been derived from classical ones. Thus complexity order is linear for addition and subtraction but quadratic for multiplication and division. Instead with func-


tional implementation is possible to use other algorithms whose complexity is considered to be less then quadratic. Multiplication algorithm for functional implementation, for example, can be derived from Karatsuba’s algorithm that is O(n1.59).
By “Digit-Error” notation it has been possible to devise a new multi- plication algorithm also inspired by the Karatsuba’s algorithm that has a complexity order equal to O(n1.83), thus less than quadratic.
In this section we present a simplified version of the algorithm devised for multiplication on “Digit-Error” representation that is completely commented in [8].
To understand how this algorithm works first it is necessary to analyze Karatsuba’s algorithm[7].

Karatsuba’s Algorithm
The Karatsuba’s algorithm for binary multiplication presented in [7] can be easily adapted to work with rational numbers represented using a given base b .
Given two real numbers x,y and a base (b > 1) such that:
2n+1	2n+1
x = Σ xib−i	y = Σ yib−i

let
i=1

2n
i=1

2n

xM = Σ xib−i	xL = Σ x2n+ib−i

i=1 2n
i=1 2n

yM = Σ yib−i	yL = Σ y2n+ib−i

i=1
the product xy can be expressed by
xy = (1 + b−2n )x  y	+
b−2n (x − x )(y	− y )+ (b−2n + b−2n+1 )x y
i=1


The result is computed using only three multiplications and three additions while classical algorithm use four multiplications. If T (n) is the time needed to multiply two numbers of n digits we have T (2n) ≤ 3T (n)+ cn for a suitable constant c. By induction it can be proved that:
T (n)= O(nlog23)

= O(n1.59)

Multiplication for “Digit-Error” Representation
There are at least two observations that can be done about the algorithm above. First it only applies to finite representations. Second the kind of re- cursion used is not suitable for lazy evaluation mechanism. In fact Karatsuba’s algorithm starts splitting the addends from the middle and repeat this process until elementary computation on single digits are done. Instead lazy evalu- ation mechanism have to examine arguments from the first digit producing result digits proportionally to the number of argument digits examined. Thus Karatsuba’s algorithm cannot be implemented, as it is, for the “Digit-Error” notation.
The modified algorithm works as follows, to compute the product of two real numbers x and y it lazily evaluates a series of values ⟩ ×k (x, y, i)⟨i∈N each one lazily evaluating the product of the approximation to the first 2i digits of x and y (x0.x1 ... x2i−1 × y0.y1 ... y2i−1). The function ×k(x, y, i) can then be implemented using the Karatsuba’s algorithm.
The approximated result computed by ×k(x, y, i) can be used to compute xy as follows. Digit j produced by ×k(x, y, i) can be given as an approximation of digit j from xy if the accuracy error computed on digit j is small enough. If it is not a more accurate approximation of digit j is taken from ×k(x, y, i + 1). In implemented the function ×k we must assure that the computation performed to evaluate the first digits of ×k(x, y, i) can be reused (does not need to be repeated) when evaluated the first digits of ×k(x, y, i + 1)¿ Only in this way we can obtain an algorithm with a complexity lower than O(n2). Let us consider now a lazy definition of the function ×k obtained from Karatsuba’s algorithm. Given two real number x and y represented by “Digit-
Error” notation using a base b , product xy can be written as
×k (x, y, i + 1) = xM (i)yM (i)+
b−2i [xM (i)yM + (yL(i) − yM (i))(xM (i) − xL(i)) + xL(i)yL(i)]+
b−2i+1 xL(i)yL(i)
where xM (i) and xL(i) are the numbers represented by the first and the second group of 2i digit in x. If we define
t(i)= xM (i)yM (i)+ (yL(i) − yM (i))(xL(i) − xM (i)) + xL(i)yL(i) s(i)= xL(i)yL(i)
then ×(x, y, i + 1) can be written as:

(3) × (x, y, i + 1) = × (x, y, i)+ b−2i t(i)+ b−2i+1 s(i).
The values t(i) and s(i) have an upper bound given a b > 6. The result of
×k(x, y, i + 1) can be used to produce 2i+2 digits of the product between x and y. The computation ×k(x, y, i+1) starts generating digits from ×k(x, y, i) whose error digits keep trace of the underlying approximation. If approxima- tion error on digit j is too large means that ×k(x, y, i) is no more sufficiently accurate to be taken as an approximation of xy. Thus remaining digits com- puted using ×k(x, y, i + 1) are added to next digits produced by ×k(x, y, i). Computation continue until 2i+1 digits from ×k(x, y, i+1) are produced adding to result from ×k(x, y, i) digits from t(i + 1) and s(i + 1).
The computation of ×k(x, y, i) can be exploited to obtain a better formu- lation for ×k(x, y, i + 1):
×k(x, y, i + 1) = ×k(x, y, 0) + b−1t(0) + b−2s(0) + ... 
+b−2i t(i + 1)+ b−2i+1 s(i + 1)

It is not difficult to prove that the complexity order of the above algorithm can be bound by the formula:
T (n)= O(n1.83)
The complexity order for this multiplication algorithm is still greater than the complexity order for Karatsuba’s algorithm. This is awarded to the different evaluation mechanism used. The complexity could be lowered [7] but the algorithm will became more involved and we think this is not worth.

Implementation
Algorithms just proposed in functional style have been realized with different programming languages to test not only performance but also expressiveness of different programming languages.
The first implementation has been done using Scheme language[5]. Start- ing from the work of [4] the original notation has been changed and the new set of mathematical function has been developed. At first the original mul- tiplication algorithm has been used. The actual code of the implementation can be find at the URL www.dimi.uniud.it/~pietro/code.

References
H.-J. Boehm. Constructive real interpretation of numerical programs. SIGPLAN Notice, 22, 7:214–221, July 87.


H.-J. Boehm and R. Cartwright. Exact real arithmetic: formulating real numbers as functions. In David Turner, editor, Research topics in functional programming, pages 43–64. Addison- Wesley, 1990.
H.-J. Boehm, R. Cartwright, M. Riggle, and M.J. O’Donell. Exact real arithmetic: a case study in higher order programming. In ACM Symposium on lisp and functional programming, 1986.
P. Di Gianantonio. A functional approach to real number computation. PhD thesis, University of Pisa, 1993.
Chris Hansen et al. MIT Scheme Reference Manual, 1991.
Mark P. Jones. An introduction to Gofer.
D. E. Knuth. The art of computer programming., volume 2/Seminumerical algorithms. Addison-Wesley, 1969.
P. Lanzi. Complessit`a degli algoritmi per l’aritmetica reale esatta. Master’s thesis, Universita` di Udine, 1994.
P. J. Potts, A. Edalat, and M. H. Escardo. Semantcis of exat real arithmetic. In IEEE Symposium on Logic in Computer Science, 1997.
A.S. Troelstra and D. van Dalen. Constructivism in Mathematics. North-Holland, Amsterdam, 1988.
A.M. Turing. On computable numbers, with an application to the entscheidungs problem. In
Proc. London Math. Soc. 42, pages 230–265, 1937.
J. Vuillemin. Exact real computer arithmetic with continued fraction. In Proc. A.C.M. conference on Lisp and functional Programming, pages 14–27, 1988.
K. Weihrauch. ”Computable Analysis, An Introduction”. Springer-Verlag, 2000.
