Available online at www.sciencedirect.com


Electronic Notes in Theoretical Computer Science 297 (2013) 75–88
www.elsevier.com/locate/entcs

Safety and Precision of Spatial Context Models for Autonomous Systems 3
Tobe Toben1
OFFIS e.V., Escherweg 2, 26121 Oldenburg, Germany
Jan-Hendrik Rakow2
Carl von Ossietzky University, 26129 Oldenburg, Germany

Abstract
A safe (i.e. collision-free) and efficient movement of a mobile autonomous system requires a correct as- sessment of the vehicles’ environment. In many systems, the spatial context is represented by means of an occupancy grid, that is, a partitioning of a two-dimensional area into finitely many cells where each cell maintains a probabilistic estimation of being occupied by some object. Often, this representation is complemented by dedicated information regarding the detected objects. We instantiate a generic framework based on a formal notion of abstraction for characterising the safety and precision of such kind of spatial context models. In this approach, the sensory perception corresponds to an abstraction function, and the concretisation function reflects the loss of information with respect to the real environment. We show that this method is able to derive both qualitative and quantitative measures for different variants of spatial context models.
Keywords: Autonomous Systems, Spatial Context Models, Safety Requirements


Introduction
A mobile autonomous system needs a good understanding of its surroundings in or- der to exhibit a safe and efficient behaviour. Typically, the system is equipped with hardware sensors and corresponding software algorithms that provide information regarding the spatial context. Many safety-relevant decisions like path planning and obstacle avoidance take this (abstract) representation of the environment as input (see e.g. [18]). By this, the correctness of the spatial context information has a direct influence on the safety level of the system [20].

1 Email: tobe.toben@btc-es.de
2 Email: jan.rakow@informatik.uni-oldenburg.de
3 This work has been supported by the Federal Ministry of Economics and Technology (BMWi) under the grant 01MA09037 and by the German Research Council (DFG) as part of the SFB/TR 14 “Automatic Verification and Analysis of Complex Systems” (AVACS).

1571-0661 © 2013 Elsevier B.V. Open access under CC BY-NC-ND license.
http://dx.doi.org/10.1016/j.entcs.2013.12.006


 


Fig. 1. Spatial context of a sample scenario in terms of (i) camera image, (ii) laserscanner data, (iii) occupancy grid and (iv) attributed objects.
Spatial Context Models
We introduce two fundamental models for spatial context information in Fig. 1. The depicted scenario is part of larger sensor-data test-suite that has been acquired in the course of the SaLsA 4 project, and the spatial representations have been con- structed using the tool-set of [16]. The top-left image shows a sample environment as observed by a camera, and we, as humans, quite easily recognise and identify the different objects in environment.
The scene was observed by LIDAR sensors (also known as “laserscanner”). The top-right picture visualises the raw data of the laserscanner located at the corner of the building (circle marking in the camera image) from a bird’s eye perspective. Each line corresponds to a laser-beam, and the end point of a line denotes the point in space where the beam hit some obstacle and was sent back to the scanner.
The first model for spatial context information is shown in the bottom-left pic- ture in terms of an occupancy grid [9]. In this representation, the area is partitioned into finitely many cells, and each cell maintains a (probabilistic) estimation of be- ing occupied. In our figure, the grey tone increases with the probability value. A second model for spatial context information is shown in the bottom-right picture. Here, information regarding the environment is given in an object-based representa- tion. To this end, related low-level measurements have been clustered into dedicated objects, and the objects have been (manually) classified into different types.
In this paper we formalise the relation between the actual environment (e.g.

4 http://www.salsa-autonomik.de

the camera image) and the derived spatial information. To obtain suitable quality notions, we instantiate and adapt a generic framework [19] for formalising and eval- uating sensory perception. This framework will be described in Section 2. It allows us to formally characterise the quality of the derived spatial context information in terms of safety and precision, and to formally express safety-related aspects which have been stated on a merely intuitive and informal level before. In this paper, we will focus on the grid-based representation (in Sect. 3) and describe how the method can be extended to an object-based representation (in Sect. 4). Section 5 concludes the paper.
Related Work
There exists a number of methods to determine the quality of occupancy grid rep- resentations in the robotics community. These methods are typically applied in order to evaluate and compare different map building algorithms with respect to a given “ideal map”. This ideal map represents the best information that can be preserved in a given data-structure (e.g. an occupancy grid of a certain size) for a given environment. The existing evaluation methods can be classified as follows:
Image-Correlation uses image processing techniques [3,4] to measure the deviation of the ideal map with the map derived by the algorithm under consideration.
Map-Scoring cell-wise compares the ideal map with the derived map. Examples of this approach are [13,5,15] and they basically differ in the metric that is used to compare the cells and to calculate the overall matching score.
Path-Execution computes a distance metric based on navigation paths [6,2]. To this end, they consider both false-positive paths, i.e. paths that are collision-free in the derived map but not in the ideal map, and false-negative paths, namely those which are collision-free in the ideal map but are considered to be unsafe in the derived map.
Also, there are approaches that do not use the ideal map as ground truth, but assess the quality of the map by correlating different sensor data [5,12].
Most closely related to our formalism are the methods based on map scoring. We however focus on formalising the conceptual aspects when relating the ground truth environments with the derived context information. By using partial order relations on the sets of environments and derived context information, we can explicitly distinguish between unsafe and imprecise deviations. By this, our framework can be seen as a unification of the different map scoring approaches in the sense that all the different metrics can be represented and motivated on a formal basis. The work of [11] also studies abstraction as part of spatial knowledge representation, however they do not formally express safety aspects.
Basic Framework
In previous work [19], we have developed a generic framework that allows for a qualitative and quantitative assessment of a sensory perception. The basic idea is

to consider the sensor as an abstraction function going from the environment to the derived context information. To this end, both the environment and the context are described by a complete lattice [7], that is, a partially ordered set (S, ±) such that each subset Sj ⊆ S has both a least upper bound, denoted HSj, and a greatest lower bound, denoted HSj.
The framework considers two functions between the environment lattice (E , ±£ ) and the context lattice (C, ±C ), namely a sensing function ς from E to C, and an interpretation function ι from C to E. The sensing function models the behaviour of a sensor by stating for each possible environment the resulting context information. The interpretation function determines for each context information the knowledge regarding the environment. In other words, the sensing function represents an abstraction from E to C, and the interpretation the corresponding concretisation function. In fact, we observed that a suitable notion of a safe and precise sensory perception in this framework coincides with (E ,ς, ι, C) being a Galois connection (see e.g. [14]), that is,
both functions ς and ι are monotone,
the composition ι ◦ ς is increasing, i.e. ∀e ∈ E : e ±£ ι(ς(e)), and
the composition ς ◦ ι is decreasing, i.e. ∀c ∈ C : ς(ι(c)) ±C c.
Example
A simple example from [19] considers a perception that is supposed to decide whether an area is occupied or free, given that either a car, a person or no object is present in this area. Hence, this simple example employs a grid representation comprising only one single cell. Both the environment and the context are modelled as powerset lattices
(E , ±£ ) := (P({car, person, nothing}), ⊆)
(C, ±C ) := (P({free, occ}), ⊆)
A safe and precise perception for this example can be obtained by the mapping
β(car)= β(person)= occ	and	β(nothing)= free
which induces a sensing function on the powerset lattices by joining all mapped contexts for a given environment, i.e. ς(E) := {β(e) | e ∈ E} for E ∈ E. The interpretation ι is determined by ς as the least upper bound of all environments that are mapped to a given context, i.e. ι(C) := {E | ς(E) ⊆ C} for C ∈ C. The resulting Galois connection for this example is shown in Figure 2.
Qualitative Measures
A perception in this framework naturally captures the inherent loss of information. In the example above, the type of object is not preserved as e.g.
ι(ς({car})) = {car, person},

T. Toben,{Jc.-aHr.,Rpaekrowso/nE,lenctorotnhicinNgo}tes in Theoretical Computer Science 297 (2013) 75–88	79
{occ, free}
{car, person}	{car, nothing}	{person, nothing}
		{occ}	{free}
{car}	{person}	{nothing}

Fig. 2. A safe and precise perception between two powerset lattices. Solid arrows show the sensing function
ς, dashed arrows the interpretation function ι. Both empty-sets are omitted.
that is, the most precise information that can be inferred after observing a car is that either a car or a person is present in the area. Likewise, it formalises an intuitive notion of safety, namely in this case that
{car} ⊆ ι(ς({car})),

that is, the outcome of the perception covers the original environment (with respect to the partial order ‘⊆’ of the environment lattice). The requirement of ς ◦ ι being decreasing ensures that the loss of information is as small as possible for the given lattices.
Given a perception P = (E ,ς, ι, C), we formalise a general notion of its safety and precision by partitioning the environment set E with respect to an environment e ∈ E into e-correct, e-imprecise and e-unsafe environments as
CorP (e) := {ej ∈ E | ι(ς(e)) = ι(ς(ej))}
ImpP (e) := {ej ∈ E | ι(ς(e)) и ι(ς(ej))}
UnsP (e) := E \  CorP (e) ∪ ImpP (e) 
The e-correct environments are those which are indistinguishable from e under the given perception. The perception of e-imprecise environments yield strictly higher elements in the lattice order, which however in particular represent e. The union of e-correct and e-imprecise environments are considered to be safe with respect to e, the rest are considered to be unsafe with respect to e (basically as they do not cover the original environment e).

Quantitative Measures
As real-world sensors are in general subject to partial wrong measurements and imperfect data processing, the sensing function ς is in general not implementable. Given a suitable description of a realistic sensor, we can obtain a quantitative notion of its safety and precision with respect to the reference perception (formalised in terms of a Galois connection) as follows.
A model of a realistic sensor yields different context information with certain probabilities. Recall that a probability distribution over a finite set X is a mapping p : X → [0, 1] such that  x∈X p(x) = 1. By D(X) we denote the set of all probability distributions over X. With this, a probabilistic sensor can be expressed

by a function ς˜ : E → D(C) that maps an environment to a probability distribution over the contexts.
For real-world sensors, the sensing function ς˜ can typically be derived from the sensors’ datasheet or computed by statistical experiments, depending on the type of sensors and the considered class of environment.
Given sensing function ς˜, we use the environment partitioning to obtain quanti- tative measures. To this end, we aggregate the probabilities of ς˜ for those context information that concretise via ι into the different parts (i.e. the unsafe, the impre- cise and the correct part) of the environment, that is,


Unsς˜(e) :=
c | ι(c)∈UnsP (e)
Impς˜(e) :=
c | ι(c)∈ImpP (e)
ς˜(e)(c)

ς˜(e)(c)

By this, we quantify the deviation of ς˜ from the reference perception P = (E ,ς, ι, C). Considering a simple example of a probabilistic sensor with


ς˜({car})({occ})= 0.9
ς˜({car})({free})= 0.02
ς˜({car})({occ, free})= 0.08

we obtain the quality measures Unsς˜({car}) = 0.02 and Impς˜({car}) = 0.08 as
{nothing} ∈ UnsP ({car}) and {car, person, nothing} ∈ ImpP ({car}).
Having introduced the basic framework we now characterise the quality of spa- tial context models, namely grid-based representations in Sect. 3 and object-based representations in Sect. 4.

Grid-based Representation
The usage of occupancy grids [9] for representing the spatial context for mobile autonomous vehicles has a long tradition. Many important problems in robotics, like map building, localisation, sensor fusion, path planning, and obstacle avoidance can be solved on a grid-based representation (see e.g. [18]).
Given a fixed area A ⊂ R2, a ﬁeld f ⊆ A denotes a set of occupied space. The set of fields is F ⊆ P(A), and we require that F is closed under set union and intersection (i.e. (F, ⊆) forms a complete lattice). The set of fields now models the set of environments as introduced the previous section.
A grid is given by a partitioning of A into a finite number of n cells Ci,... , Cn ⊆ A, and by Gn we denote the set of all possible valuations of a grid with n cells. We set G :=  n∈N Gn, and define an occupancy sensor ς : F → G to be a function that maps each field f ∈ F to a grid valuation g ∈ G. By Gbool ⊂ G we denote the set of boolean grid valuations where each cell maps to a boolean value that
indicates whether the cell is occupied or not, i.e. Gn	= Bn. With this, we define

the ideal occupancy sensor ς٨ : F → Gn
which maps a field to a boolean grid by

ς٨(f ) := (f ∩ Ci /= ∅)1≤i≤n.





Fig. 3. Space lattices of fields (7, ⊆) and 2-cell boolean grid valuations (G2 the partial order. The ideal occupancy sensor ςs induces a Galois connection.
, ±). The gray lines indicate

In the following, we use a graphical representation for fields and grid valuations. A field is given by a box representing the area A and a number of gray shapes that represent the occupied space within A. Occupied cells in a boolean grid are drawn with a hatched pattern. The ideal sensor yields
ς٨()= 	ς٨()= 	ς٨()= 	ς٨()=
ς٨()= 	ς٨()= 	ς٨()= 	ς٨()=
for a grid size of 2.
In order to apply the generic framework as introduced in Section 2 we have to construct a Galois connection (L7 ,ς, ι, LG ) where L7 and LG denote lattices that adequately describe the information order within the set of fields and grid valuations, respectively. Actually, we will consider two different variants of lattices in the following subsections, namely space lattices and the powerset lattices. In both cases, we define the sensing and interpretation functions ς and ι based on the ideal occupancy sensor ς٨. This gives us suitable reference perceptions for obtaining quantitative measures for different probabilistic variants of occupancy sensors.
Space Lattice Perception
Recall that the set of fields F is a subset of the powerset of A such that (F, ⊆) is a lattice. In particular, the top element is the field that has more space occupied by objects than any other field. We call this lattice a space lattice. A similar order can be defined on boolean grid valuations by setting


g ± gj : ⇐⇒
1≤i≤n

for g = (b1,... , bn) and gj = (bj ,... , bj ) in Gn
bi ⇒ bj

. This provides us with the space

1
lattice for boolean grid valuations (Gn
n
, ±).
bool

bool
See Figure 3 for a visualisation of both lattice constructions. It is easy to see that

Space = ((F, ⊆),ς, ι, (Gn
, ±))

with ς = ς٨ and ι(g)= S{f ∈ F | ς٨(f )= g} for g ∈ Gn	is a Galois connection. In
this setting it is safe, but imprecise, if a sensor marks more space as being occupied than the ideal sensor does. For example, we obtain the following partitioning for
∈ F:
CorSpace()= {}
ImpSpace()= {, , , , }
UnsSpace()= {, }
The unsafe fields for  are those where no object intersects the leftmost cell, while the imprecise fields are those which intersect with both cells. There is only one correct field in this example.
Probabilistic Occupancy Sensors
In practise, a sensor does not yield a boolean grid valuation but rather a probabilistic estimation for each cell [9,18,1]. Formally, each cell Ci then corresponds to a random variable over the domain Σ := {occ, free}, yielding the set of probabilistic grid

valuations Gn
⊂ Gn. For example, we consider a sensor ς˜ : F → G2
with

ς˜()= ([C1(occ)= 0.9, C1(free)= 0.1],
[C2(occ)= 0.6, C2(free)= 0.4]).
We can abbreviate this representation by only providing the probabilities for ‘occ’,
i.e. by writing ς˜(	)= (0.9, 0.6), hence the domain is Gn	= [0, 1]n. By lifting
these cell-wise probabilities to a distribution over the set of boolean grid valuation we can obtain quantitative measure of realistic occupancy sensors by the framework introduced in Section 2.


Threshold Lifting
The most simple way to obtain a lifted sensor ς˜↑ : F → D(Gn

) is to apply a

threshold τ ∈ [0, 1] that maps a probabilistic grid valuation g = (b1,... , bn) ∈ Gn

to a boolean valuation gτ ∈ Gn
by gτ := (bi ≥ τ )1≤i≤n, that is, a cell Ci becomes

true iff the probability Ci(occ) is at least τ , e.g.
(0.9, 0.6)0.3 =


Given a probabilistic sensor ς˜ : F → Gn
and a threshold τ , we obtain for each

field f ∈ F a (Dirac) distribution ς˜↑(f ) ∈ D(Gn
) with

τ	bool
ς˜↑(f )(g)= 1	if g = ς˜(f )τ


for g ∈ Gn
. Using this distribution for computing the quantitative measure gives

a definite value 1 for exactly one of the possible outcomes correct, imprecise or


Table 1
Quantitative measures of ς˜ using different liftings.
unsafe. For threshold τ = 0.3, we obtain Corς˜↑ () = Unsς˜↑ (	) = 0 and
τ	τ
Impς˜↑ (	)=1 as ι((0.9, 0.6)0.3)=	∈ ImpS (	).
Joint distribution Lifting
Alternatively, to preserve the probabilities also in the lifted sensor, we can compute the joint distribution function over the cells. This yields for each field a distribution

ς˜↑(f ) ∈ D(Gn
) with

j	bool
ς˜↑(f )(g) := 

bi · ς˜(f )i(occ)+ (1 − bi) · ς˜(f )i(free)


for g = (b1,... , bn) ∈ Gn
1≤i≤n
where ς˜(f )i denotes the i-th cell (i.e. random variable)

in the probabilistic grid valuation ς˜(f ) ∈ Gn
. For example, we obtain



ς˜↑()()= 0.1 · 0.4= 0.04
ς˜↑()()= 0.1 · 0.6= 0.06
ς˜↑(	)(	)= 0.9 · 0.4= 0.36
ς˜↑(	)(	)= 0.9 · 0.6= 0.54

and hence Unsς˜↑ ()= 0.1, Corς˜↑ ()= 0.36, and Impς˜↑ ()= 0.54.
j	j	j
Table 1 shows the measures for the probabilistic sensor ς˜ for three different
threshold values and for the lifting using the joint distribution. As expected, a low threshold yields an imprecise measure while a high threshold yields unsafe measures. The joint probability computes a correctness measure of 0.36 as the product of the “correct” probabilities of the two cells. The unsafe measure of 0.1 is basically the missing 10% probability for the first cell to its correct value 1. The remaining probability of 0.54 is the value for imprecision.
Powerset Lattice Perception
As an alternative lattice construction, we now consider a perception on the basis of
powerset lattices. We obtain a Galois connection


Power = ((P(F), ⊆),ς, ι, (P(Gn
), ⊆))



with

ς(F ) := {ς٨(f ) | f ∈ F }
ι(G) := {f | ς٨(f ) ∈ G}



{, , , ... , }


...	{	,	,	,	,
...	...	... 

{	}

{
}
{	} {	} ... {	}

{} 
{} 


Fig. 4. Powerset lattices of fields (7, ⊆) and 2-cell boolean grid valuations (G2
, ⊆).

for fields F ⊆ F and grid valuations G ⊆ Gn
. The lattices are visualised in Fig. 4.

Note that now both the sensing and interpretation function yield sets of grid valu- ations and fields, respectively. For example, we obtain the following interpretations
ι({})= {}
ι({})= {, , , , }
ι({, })= ι({}) ∪ ι({})

n
bool
)= F

that denote the set of fields that are represented by the given (set of) grid valuations. This is in contrast to the space lattice construction where the interpretation yields a single unique field, namely the least upper bound of all fields that map to the given grid valuation. For example, we obtain the following characterisation for
{} ∈ P(F):
{{}} = CorPower({})
{} ∈ UnsPower({})
{, } ∈ ImpPower({})
It is important to note the difference to the space lattice Space, e.g.
∈ ImpSpace()	versus	{} ∈ UnsPower({}),
that is, a single field f j is considered to be unsafe with respect to a different field f even if f j occupies more space than f . The notion of imprecision corresponds to the fact that a sensor does not yield a unique grid for a given field f , but returns a set of possible grids that in particular comprises ς٨(f ).
A probabilistic sensor in the powerset lattice setting is a function


ς˜ : F → D(P(Gn
)))

where each field is mapped to a probabilistic distribution over the powerset of

boolean grid valuations. By this, dedicated probability mass can be associated to a
set of grid valuations. For example, the probabilistic sensor
ς˜()({})= 0.7
ς˜()({})= 0.02
ς˜()({, })= 0.03
ς˜()({, })= 0.15
ς˜()({, , , })= 0.1
yields the following measures for safety and precision:
Corς˜({})= 0.7
Unsς˜({})= 0.02 + 0.03
Impς˜({})= 0.15 + 0.1
A similar kind of knowledge representation is proposed in the evidence theory by Dempster and Shafer [8,17]. Here, a mass function m : P(Ω) → [0, 1] over sets of hypotheses Ω allows for a natural representation of partly uncertain knowledge. The belief regarding hypotheses H ⊆ Ω is then represented by an interval where the bounds are computed by two derived functions, namely the belief and plausibility functions


Belm(H) :=
H′⊆H
m(Hj)	and	Plm(H) :=
H∩H′/=$
m(Hj).

In the case where probability mass is only assigned to singleton sets, the Dempster- Shafer framework coincides with the classical probability theory. In the other ex- tremal case of uncommitted belief, i.e. m(Ω) = 1, the vacuous belief interval ‘[0, 1]’ is derived for all basic hypotheses. The framework is in particular suited for the combination of evidences stemming from different sources, and hence provides a sound theory for multi-sensor fusion. The representation of uncertainty by assign- ing probabilities to sets of possible outcomes corresponds to the notions of our framework [19] by the equations
Uns(H)= 1 − Plm(H)   and   Imp(H)= Plm(H) − Belm(H) for a safe and precise perception where ι ◦ ς is the identity function.
We have seen that the orderings in the lattices determine the notions of safety
and precision in our framework. The ordering in the space lattice based on the amount of occupied space relates imprecision to “more cells being occupied than necessary”. From a safety perspective, this can be a useful notion in practise as navigation and collision avoidance strategies are typically only interested in the free space of the area (which is conservatively approximated by an imprecise sensor). The ordering in the powerset lattice based on set inclusion relates imprecision to “a larger set of possible grids than necessary”. By this ordering, we can explicitly


dynamic


static


Fig. 5. Two simple lattices for the perception of the objects’ type t. The wrong classification of ς˜t corresponds to an imprecise sensing as the interpretation of ‘dynamic’ covers the value ‘container’.

distinguish between uncertainty (e.g. a part of the area which is not observed by the sensor and hence is mapped to {occ, free}) and cells which are certainly occupied by some obstacle (and hence are mapped to {occ}). In the space ordering, both parts of the area would have to be set to ‘occ’ in order to obtain a safe measure.

Object-based Representation
Certain decisions for autonomous systems need additional context information be- sides occupancy. For example, collision avoidance strategies often requires knowl- edge whether the area is occupied by a static or dynamic obstacle [10,1].
In general, we consider a set of attributes A where each attribute a ∈ A comes with a value domain Da ⊆ D. Typical examples of attributes include the type of an object, its position, orientation and current speed. The value domain of the orientation attribute could for example be the range between 0 and 359 de- grees. The corresponding context description will be defined in terms of abstract domains D , accounting for the fact that a sensor is typically not able to recognise all the detailed values of the concrete domains. For example, the abstract do- main of the orientation could be the four compass directions {N, E, S, W }. The relation between the concrete and the abstract domain can be expressed by a

Galois connection, e.g. over the powersets of the domains. The abstraction function splits the set of degrees into the four abstract values as indicated in the picture on the right hand side, e.g. α({60}) = {E}. The concretisation func- tion maps each abstract value to the set of all degrees that are mapped to it, e.g. γ({E}) = {45,... , 134}. Another example for an object attribute is its type, which is a con-
315

270	W

225
0
N

S 180
45

E	90

135

crete denotation in the environment, and is e.g. mapped to a simple differentiation between static and dynamic in the abstract context representation.
Again, the notion of safety and precision for an attribute sensor is determined by the underlying ordering in the lattice structures. For example, when using the orderings for the perception of the objects’ type as shown in Fig. 5, it becomes safe (but imprecise) to classify a static object (e.g. a container in the environment) as being dynamic. Such an ordering can be useful in practise as dealing with dynamic objects is in general considered to be more risky. For the orientation attribute of objects however, there is typically no safe fall-back value, such that a natural

ordering is based on set inclusion, that is, using lattices (P({0,... , 359}), ⊆) and (P({N, E, S, W }), ⊆). With this, the sensor may yield a set of plausible values from the abstract domain whenever no definite single value can be safely determined.
More formally, the perception of an attribute a ∈ A is modelled by a Galois connection
LDa, ςa, ιa, L 
a
where the lattices LDa and L  describe the orderings on the concrete and abstract
a
domains, respectively, and ςa and ιa are the corresponding sensing and interpretation
functions. In order to extend the attribute-wise perception to a description of the overall object-based perception we can use the principle of function lattices (that is, given a set X anda lattice (Y, ±), we obtain the function lattice ([X → Y ], ≤) with point-wise ordering f ≤ f j :⇔ ∀x ∈ X : f (x) ± f j(x)). We use this construction to obtain a Galois connection for the set of attributes A as
([A → D], ≤), ςA, ιA, ([A → D ], ≤ )
where ≤ and ≤ are the orderings induced by the function lattice construction. The sensing ςA is defined point-wise as ςA(f )(a) := ςa(f (a)), analogously for the interpretation function ιA. The same construction principle can be applied in order to lift the perception to a mapping from a set of objects to their valuations of the attributes.
Analogously to the previous section, the definition of a probabilistic sensor is a mapping to a probability distribution over the abstract lattice. Typically, the probabilities are only available on the lowest level, that is, for the perception of in- dividual attributes. To lift these probabilities to the function lattices, the methods described in the previous section on grid-based representations can be employed. The general framework as described in Section 2 and demonstrated in the previ- ous section can then be applied to obtain quantitative measures for object-based representations.
Conclusion
This work shows that modelling a sensory perception in a formal framework in- volving abstraction and concretisation functions allows for a mathematically sound investigation of safety aspects. Methodologically, we propose to model the infor- mation order regarding both the environment and the context in terms of lattices. Functions going back and forth between these two lattices express the interdepen- dencies between the original and the derived information. This formalisation makes a number of safety-related aspects explicit, and can thus help to provide formally rigorous arguments regarding the overall safety of a mobile autonomous system.
Additionally, the derived measures allow for evaluating and comparing different implementations of sensory perceptions by systematically relating the real envi- ronment with the derived context information. This evaluation can be automatised whenever the ground truth regarding the environment is available, e.g. by temporar- ily using an additional ideal sensor. Our method features an explicit representation

of the underlying safety and precision measures by means of lattice structures. This is in contrast to existing approaches of map scoring where these notions are only provided on an intuitive level and are solely given by the cell comparison operators.

References
Olivier Aycard, Anne Spalanzani, Julien Burlet, Chiara Fulgenzi, Trung-Dung VU, David Raulo, and Manuel Yguel. Grid based Fusion and Tracking. In Proc. of the IEEE Int. Conf. on Intelligent Transportation Systems, 2006.
Benjamin Balaguer, Stephen Balakirsky, Stefano Carpin, and Arnoud Visser. Evaluating Maps produced by Urban Search and Rescue Robots: Lessons learned from RoboCup. Auton. Robots, 27(4):449–464, 2009.
Robert J. Baron. Mechanisms of Human Facial Recognition. International Journal of Man-Machine Studies, 15(2):137 – 178, 1981.
Andreas Birk. Learning Geometric Concepts with an Evolutionary Algorithm. In Evolutionary Programming, pages 83–90, 1996.
Jennifer Carlson, Robin R. Murphy, Svetlana Chistopher, and Jennifer Casper. Conflict Metric as a Measure of Sensing Quality. In ICRA, pages 2032–2039. IEEE, 2005.
T. Collins, J.J. Collins, and C. Ryan. Occupancy Grid Mapping: An empirical Evaluation. In Control Automation, 2007. MED ’07. Mediterranean Conference on, pages 1 –6, june 2007.
B. A. Davey and H. A. Priestley. Introduction to Lattices and Order. Cambridge University Press, Cambridge, 1990.
A. P. Dempster. A Generalization of Bayesian Inference. Journal of the Royal Statistical Society, 30(B):205–247, 1968.
Alberto Elfes. Using Occupancy Grids for Mobile Robot Perception and Navigation. Computer, 22:46– 57, 1989.
L´ıa Garc´ıa-P´erez et. al. Perception and Tracking of Dynamic Objects for Optimization of Avoidance Strategies in Autonomous Piloting of Vehicles. In C. Freksa, M. Knauff, B. Krieg-Bru¨ckner, B. Nebel, and T. Barkowsky, editors, Spatial Cognition, volume 3343 of LNCS. Springer, 2004.
Lutz Frommberger and Diedrich Wolter. Spatial Abstraction: Aspectualization, Coarsening, and Conceptual Classification. In Christian Freksa, Nora S. Newcombe, Peter G¨ardenfors, and Stefan W¨olfl, editors, Spatial Cognition, volume 5248 of Lecture Notes in Computer Science, pages 311–327. Springer, 2008.
B. Grabe, T. Ike, and M. Hoetter. Evaluation Method of Grid Based Representation from Sensor Data. In Intelligent Vehicles Symposium, 2009 IEEE, pages 1245 –1250, june 2009.
Martin C. Martin and Hans Moravec. Robot Evidence Grids. Technical Report CMU-RI-TR-96-06, Robotics Institute, Pittsburgh, PA, March 1996.
Flemming Nielson, Hanne R. Nielson, and Chris Hankin. Principles of Program Analysis. Springer- Verlag New York, Inc., Secaucus, NJ, USA, 1999.
Shane O’Sullivan. An Empirical Evaluation Of Map Building Methodologies in Mobile Robotics Using The Feature Prediction Sonar Noise Filter And Metric Grid Map Benchmarking Suite. Master’s thesis, University of Limerick, 2003.
Kai-A. Pancratz. Flexible Fusion System based on Data Stream Management Technology for Classification and Tracking using distributed Sources. Master’s thesis, Carl von Ossietzky Universit¨at, Oldenburg, Germany, 2012. to appear.
Glenn Shafer. A Mathematical Theory of Evidence. Princeton University Press, 1976.
S. Thrun, W. Burgard, and D. Fox. Probabilistic Robotics. MIT Press, 2005.
Tobe Toben. A Formal Model of Reliable Sensor Perception. In Paul Lukowicz, Kai S. Kunze, and Gerd Kortuem, editors, EuroSSC, volume 6446 of LNCS. Springer, 2010.
Andrzej Wardzinski. The Role of Situation Awareness in Assuring Safety of Autonomous Vehicles. In Janusz G´orski, editor, SAFECOMP, volume 4166 of LNCS. Springer, 2006.
