Available online at www.sciencedirect.com


Electronic Notes in Theoretical Computer Science 300 (2014) 3–20
www.elsevier.com/locate/entcs
If, not when
Dick Crouch1,2
Nuance Communications Sunnyvale, USA
Valeria de Paiva3
Nuance Communications Sunnyvale, USA


Abstract
We present a logic of verified and unverified assertions and prove it sound and complete with respect to its possible-worlds semantics. The logic, a constructive modal logic, is motivated by considerations of the interpretation of conditionals in natural language semantics, but, we claim, is of independent interest.


Motivation
One of us wrote a dissertation on the patterns of temporal reference exhibited by conditional and modal sentences in English a long time ago [1]. The other one was always fascinated by the verificationist logic that emerged, whether you were concerned with the modelling of conditionals and modals, or not. This one decided that the logic that emerged, a ‘temporal’ logic of verified and unverified assertions with curious properties, deserved a writing up of its own. Hence this note.
Whether one is concerned with the original application of this logic or not, it makes sense to explain some of the issues that motivated it. Operators that refer to tenses like past and present are self-explanatory, but logicians by and large are blissfully unaware of the subtle issues of interpretation surrounding English sentences. Consider the sentence:

1 Thanks to everyone who should be thanked
2 Email: richard.crouch@nuance.com
3 Email: valeria.depaiva@nuance.com

1571-0661 © 2013 Published by Elsevier B.V. Open access under CC BY-NC-ND license.
http://dx.doi.org/10.1016/j.entcs.2013.12.009

(1)	If I smile when I get out, the interview went well.
This is an example of deictic shift: deictic shift occurs when a tense locates an event as being past or present with respect to some time other than the speech time. At speech time both the presumed interview and smiling (or not) are in the future, but the sentence orders then as first the interview event and then the smiling (or not) event.
Assume we want to define meaning as the potential to change states of infor- mation, instead of the conditions under which something is true. If meaning is to be explicated in terms of information change, there are two levels under which temporal reference operates. First temporal references must describe how the world changes over time. But secondly they have also to explain the way the information about the world changes over time.
Typically the tenses are taken to state a relation between the time at which some assertion is made (the speech time) and the time at which the event being described occurs (the event time). The speech time then serves as the (single) deictic centre for the tenses.
An alternative is to centre tenses on the time at which an update is made to one’s stock of information, where this update is the result of the utterance of the sentence. Some kind of update time would provide the tenses deictic centre rather than the speech time. In most cases the move from speech time to update time will make no difference: normally the update occurs as soon as the utterance is made. However modal and conditional sentences do not behave in this simple fashion. They place constraints on the way that updates may be made in the future. Tenses within the scope of the modal or conditional are centred relative to these future update times leading to deictic shift. Or so goes the story in the thesis.
Moreover the update should not be considered a single operation, occurring at a single time. Instead it is necessary to decompose the update into two operations: assertion and veriﬁcation. Typically, assertion and verification occur simultane- ously, and most sentences convey verified information. Modals and conditionals by contrast allow delayed assertion and verification. If A, then B means roughly: sup- pose you were now to assert A; if and when A is verified, you will be in a position to assert B, and in due course this assertion will also be verified. Since A and B will both be tensed clauses, allowing for both assertion and verification times will lead to several possible shifted interpretations of the clauses.
Establishing the usefulness of this setting for the analysis of modals and con- ditionals was the main goal of the thesis, but our objective here is much more restricted. We simply describe the logic that emerged from the analysis, prove some properties and speculate about more general uses for it.
We shall motivate the logic in terms of information states and its application to dealing with conditionals in natural language and then define a (somewhat compli- cated) semantics for it. Then we provide a proof theory for this logic and show the required sourness and completeness. We conclude with some speculation on further uses.

Information States, Tenses and Conditionals
We will first take information states as primitive. They will not be construed as sets of propositions or formulas. It is customary in tense logic to view propositions as functions from times (and perhaps possible worlds) to truth values. But this is not how propositions in our information states behave. A proposition in an information state p is really a short-hand for saying that “p is true at t”.
It makes sense to talk about being in (possession of) a certain information state at a certain time. All being well, as time goes by this state will grow into other states that are informational extensions of the original. In reality some of the initial information may prove to be mistaken, so sometimes information may decrease over time. Just because information grows over time one should not conclude that the ordering of information extension (which we write as ±) is a temporal order. To do so would make time forward and backwards branching, but we will assume instead that time is linear, so there is only one past and one future. 4
Information states and sets of them are essentially non-temporal structures. Information states and their ordering into sets of possible extensions give a gods- eye, atemporal view of the world. But if information states are atemporal the same cannot be said for English sentences. The role of the past and present tenses can be seen as one of tying the time varying nature of sentences down to the static assertions found in the information states. We need to show how, via the tenses, the temporarily varying update potential of sentences maps onto the temporally fixed relations in information states.
We will assume a logical language L consisting of atomic sentence letters (p, q, etc ... plus the absurd sentence ⊥), four connectives (∧, ∨, → and ⇒) and three one place sentence operators (past, pres and ¬) with parentheses and usual formation rules.
We will write
s |= φ
to say that the state s can be the result of an update by a sentence φ. This means that if s |= φ then updating s with φ will have no effect, it will add no further information, hence leave one still in s. If s |= φ holds we say that φ is supported by
s. The notation s, t |= φ will be used to say that an assertion corresponding to an utterance φ made at time t is supported by a state s. Using past(p) and pres(p) to represent simple past and present tense sentences, we can describe the update effects of utterances of simple tensed sentences as follows:
s, t |= past(p) iff there is some time tp ≤ t such that the assertion p(tp) is contained in s.
s, t |= pres(p) iff p(t) is contained in s.
Now an English conditional will consist of two tensed clauses, e.g. (1) above is of

4 You don’t have to agree with this, you can just take it as a simplifying assumption.

the form
pres(p) → past(q)
the tenses of these clauses will be interpreted relative to the future states and times
sj and tj.
Back to our semantic definition, for conditional sentences we will say, to begin with, that a conditional φ → ψ uttered at time t is supported in s just in case for any state sj extending s that supports an assertion of the antecedent φ made at time tj after t, the state sj also supports an assertion of the consequent ψ made at tj.
3. s, t |= φ → ψ iff for all sj ± s and all tj ≥ t, if sj, tj |= φ then sj, tj |= ψ
Our information states consist of sets of assertions. We now divide the assertions contained in an information state into verified and unverified assertions at time t. As time goes by more unverified assertions become verified, but no verified assertion can become unverified.
What is to verify an assertion and what is the difference between verified and unverified assertion? To answer this it helps to note an obvious asymetry between the future and the past. While we can have knowledge about both past and future, the origin of our information about the past is quite different from the origin of our information about the future. With information about the past there is usually some causal chain linking a past event to present information. As for information about the future, at best, one can extrapolate on the basis of what one knows about the past and the present.
With verified information, it is normally assumed that there is some causal chain linking the information to what the information is about. When a causal chain is involved, verification of information about an event cannot precede the occurrence of the event. However, there are some cases where verification is not causal in origin. In particular, a case where a degree of prescience seems to apply is in talking about plans or pre-determined events. When talking about plans, it is not really the world that we are discussing but what is laid out in the plan. Of the plan, we have a gods- eye view, so that we can survey in a glance which events are supposed to happen when. If the plan provides our source of information about these events, then we can verify that certain events will occur, according to the plan, well in advance of the time at which those events are supposed to occur. When one says
(3)	The sun rises at 05:47 tomorrow.
one is in fact reporting on what is stated in a set of sunrise and sunset tables.
Simple, tensed sentences are normally used to convey verified information. Up- dates consist of first making an assertion and then marking it as verified. For simple sentences, these two operations take place at the same time. This means that the update effect of a sentence φ at a time t needs to be expanded out as follows:
s, t |= φ iff s, t, t |= φ
The two occurrences of t on the right hand side correspond to the assertion and

veriﬁcation times respectively. As we can see, to begin with the two times are assumed to be identical, and correspond to the time at which the sentence is uttered.
The effects of the tenses on atomic sentences may be described as follows:
s, a, v |= past(p) iff there is a time tp < a such that the assertion p(tp) is verified in s at time v.

s, a, v |= pres(p) iff there is a time tp ≥ a such that the assertion p(tp) is verified in s at time v.
Here, a stands for the assertion time and v for the verification time. An assertion p(tp) is verified in a state s at a time v if p(tp) is contained in the set of assertions that count as verified in s at v. (If we represent states as sets of assertions, at any one time this set will be split into two subsets of verified and unverified assertions).
Verified and Unverified Assertions
We now forget our motivation in terms of tenses and conditionals while still taking account of the times at which formulas are verified. In these information mod- els, each information state can be seen as a linearly ordered sequence of temporal ‘snapshots’ of the state, where different formulas are forced at different time points.
An information model M is now a quintuple
M = ⟨S, ⊆t,T, ≤,V ⟩
where S is a set of information states, s
⊆t is a relation in S × S × T
and is transitive and reflexive over S for any t T is a set of time instants, t
≤ is a (linear) temporal order over T , and
V is a valuation function
The valuation function V is a function from states, times and atomic sentences in some language L onto the (verification) values 1 or 0. This specifies for a state, time and sentence whether the sentence is verified at that time in that state.
We impose two monotonicity conditions on the valuation function V :
Monotonicity of direct veriﬁcation (‘in-state’ monotonicity):
For every state s and atomic sentence p
t1 ≤ t2 implies if V (s, t1, p)=1 then V (s, t2, p)=1 
Monotonicity of information growth (‘out-of-state’ monotonicity):
If s1 ⊆t s2 then for atomic sentences p
{p | V (s1, t, p)= 1}⊆ {p | V (s2, t, p)= 1}
{p | ∃t : V (s1, t, p)= 1}⊆ {p | ∃t : V (s2, t, p)= 1}
Monotonicity of direct verification says that once an atomic sentence is verified within a state, if remains verified in that state. Monotonicity of direct verification will turn out to apply to all sentences, and not just to atomic ones.

Monotonicity of information growth says that moving from s1 to a more fully informed state s2 at some time t verifies the same atomic sentences in s2 at t as were verified in s1 at t (condition (a)). It also says (condition (b)) that the sentences asserted in s1 but not yet verified in at t continue to be asserted in s2, though the times at which they becomes verified in s2 may differ form those in s1. Indeed, some unverified assertions in s1 may count as already verified in s2. In addition, s2 may include verified and unverified assertions that were not present at all in s1. If s2 does not contain any extra assertions (i.e. the ⊆t becomes ≈t in (a) and (b)), then the two states are informationally equivalent at t. Monotonicity of information growth does not hold for all non-atomic sentences.
In addition, a convergence of verification property is imposed:
Convergence of Veriﬁcation:
If s1 ⊆t1 s2 ⊆t2 s3,
then there is a time t3 such that t3 ≥ t1, t3 ≥ t2 and ∀t4 ≥ t3 s1 ⊆t4 s3
as well as the constraint on absurdity:
No Absurdity:
For no s or t is it the case that V (s, t, ⊥)=1 

Semantic Deﬁnitions of Connectives
We now give semantic definitions for a propositional language involving the connec- tives ∧, ∨, →, ¬ and ∼. These specify what is required for a sentence to be verified as true at a time t in a state s.
s, t |▶ p iff V (s, t, p)=1 if p is atomic
s, t |▶ φ ∧ ψ iff s, t |▶ φ and s, t |▶ ψ
s, t |▶ φ ∨ ψ iff s, t |▶ φ or s, t |▶ ψ
s, t |▶ φ → ψ iff ∀t1 ≥ t, s1 ⊇φ,t s : ∃t2 ≥ t1 such that s1, t2 |▶ ψ
s, t |▶ ¬φ iff ∀t1 ≥ t, s1 ⊇φ,t s : ∃t2 ≥ t1 such that s1, t2 |▶ ⊥
s, t |▶∼ φ iff ∀t1 ≥ t : s, t1 /|▶ φ



Minimal Information Extensions
The semantic definitions for → and ¬ rely on minimal information extensions.
A minimal information extension can be defined as follows:
s1 ⊇φ,t s iff
s1 ⊇t1 s
s1, t1 |▶ φ, and
/ ∃t2, s2 such that t ≤ t2 < t1, s ⊇t2 s2 ⊇t2 s1, and s2, t2 |▶ φ
That is, if s1 is a minimal extension of s with respect to φ at time t, then s2 is the first state extending s that verifies φ at the earliest time t1.

Negation
Two types of negation are defined: ‘out-of-state’ negation, ¬, and ‘in-state’ negation ∼. Out-of-state negation says that a sentence will never be verified in any future state at any future time. In-state negation says that a sentence will never be verified in the current state at any future time.
If a sentence ∼ φ holds in a state s at a time t, the sentence φ is not asserted by state s. (Note that the monotonicity of direct verification will ensure that if ∼ φ holds in s at any time t, it holds at all times). If ∼∼ φ holds in s at t, then it follows that at some later time t1, φ will hold in s. Thus ∼∼ φ gives a way of saying that φ is asserted by a state, though not necessarily as yet verified in that state.
As well as referring to the two negations as in-state and out-of-state negation, we can also say that ∼ amounts to a denial of assertion, while ¬ amounts to an assertion of denial.

Monotonicity
A significant feature of the forcing relation in intuitionistic logic is its monotonicity: once a sentence is forced in one state, it remains forced in all subsequent states. This holds for all sentences.
Within the information models currently being dealt with, we need to consider two distinct kinds of monotonicity: in-state monotonicity, and out-of-state mono- tonicity. In-state monotonicity holds for all sentences, but out-of-state monotonicity holds only for a restricted set of stable sentences.
Stable sentences are defined below, and are approximately those whose sub- formulas contain no odd-numbered sequences of in-state negations — thus ∼∼ φ is stable, but ψ∧∼ φ is not. Unstable sentences are ones that state that a particular sentence is not asserted in a given information state. That a sentence is not asserted in one state does not preclude it from coming to be asserted in a later state.

In-State Monotonicity
First, we show that all sentences satisfy in-state monotonicity: In-State Monotonicity:
If s, t |▶ φ then ∀t1 ≥ t : s, t1 |▶ φ
This is a direct consequence of the condition of monotonicity of direct verification (in-state monotonicity for atomic sentences) that was imposed on the valuation function in information models. For conjunction and disjunction, it is easy to see that monotonicity carries across from monotonic sentences.
For in-state negation, note that ∼ φ is only forced in state s at t if φ fails to be forced in s at any time t1 at or after t. Assuming that φ itself behaves monotonically within the state, this means that φ is forced at no time within the state, and so
~ φ is forced at all times within the state. Exactly similar arguments apply to ¬φ
— just ignore the reference to future information states in the semantic definition, and concentrate on reference to future times within the current state.

For implication, φ → ψ, assume both φ and ψ behave monotonically. Restricting attention to what must go on within the state if the semantic conditions for the implication hold at time t, we find that if φ holds at any time t1 after t, then ψ must hold at some time t2 after t1. Since φ and ψ are monotonic, if this holds at t, it will also hold at all times tj after t.





Stable Sentences
Next we define what stable sentences are.
If p is atomic, then p is stable.
If φ and ψ are stable, then φ ∧ φ and φ ∨ ψ are stable.
φ → ψ is stable if ψ is stable. (Otherwise, it is semi-stable.)
¬φ is stable.
If φ is stable, then ∼∼ φ is stable.
Anything not classified as stable by the above is unstable.
A piece of notation that will be used below is that if Γ is a set of formulas or sentences, then Stable(Γ) denotes the stable subset of Γ.





Out-of-State Monotonicity
It can be shown that all stable sentences satisfy out-of-state monotonicity: Out-of-State Monotonicity:
If s, t |▶ φ then ∀s1 ⊇t s, t1 ≥ t : s1, t1 |▶ φ
(Proof: by induction on the complexity of φ — given in Appendix.
The converse does not quite hold. There are some unstable formulas that satisfy out-of-state monotonicity: ∼ φ∨ ∼∼ φ is an example.


Proof theory
The semantic definitions presented above are sound and complete with respect to the following sequent calculus system (Proof: Appendix).



Γ ▶ φ; Γ ▶ ψ
∧I
Γ ▶ φ ∧ ψ
Γ ▶ φ ∧ ψ
∧E
Γ ▶ φ



Γ ▶ φ
∨I
Γ ▶ φ ∨ ψ
Γ ▶ φ ∨ ψ; Γ,φ ▶ χ; Γ,ψ ▶ χ
∨E
Γ ▶ χ



Stable(Γ),φ ▶∼∼ ψ
→ I
Γ ▶ φ → ψ
Γ ▶ φ; Γ ▶ φ → ψ
→ E
Γ ▶∼∼ ψ



Stable(Γ),φ ▶∼∼ ⊥
¬I
Γ ▶ ¬φ
Γ ▶⊥ 
⊥
Γ ▶ φ



Γ,φ ▶⊥ 
I
Γ ▶∼ φ

Ax


Γ ▶∼ φ∨ ∼∼ φ



Γ ▶∼∼ φ; Γ ▶ φ → ψ
∼→
Γ ▶∼∼ ψ

∼∼ ⊥
Γ ▶∼∼ ⊥

Γ ▶⊥ 

The axiom stating that ▶∼ φ∨ ∼∼ φ is a direct result of the fact that the ordering over temporal snapshots is linear, giving rise to the characteristic axiom of Gabbay’s logic KC.

Conclusions
We have shown that our notion of information models with verified and unverified assertions, originally conceived to explain conditionals in natural language semantics does not lead to something that is logically absurd. By the contrary the logic of verified and unverified assertions can be shown to have a respectable proof system, satisfying soundness and completeness. It remains to be seen how useful the logic of verified and unverified assertion is as a logic of (non-temporal) conditionals and modals.

References
Crouch, R. S.., The temporal properties of English conditionals and modals, PhD Thesis, Computer Laboratory, University of Cambridge. Available as Technical Report 325, January 1994.

Gabbay, D., Semantical Investigations in Heyting’s Intuitionistic Logic Synthese volume 148. D. Reidel, 1981.

A	Proof of Soundness and Completeness
This appendix shows that the proof theory for a logic of verified and unverified assertions presented is sound and complete with respect to the intended semantics.

Soundness
To prove soundness we must show that Γ ▶ φ ⇒ Γ |= φ
where Γ |= φ is a short hand for saying that
for any model M , state s and time t such that M, s, t |▶ σ for every σ ∈ Γ,
M, s, t |▶ φ
and Γ ▶ φ means that φ is derivable from premises Γ in the inference system
The proof proceeds by induction on the complexity of the derivation Γ ▶ φ. We will assume a fixed model M .

Atomic Derivations
Soundness of atomic derivations, φ ▶ φ, is trivial. Any model of the premise is a model of the conclusion. This provides the base case for the induction hypothesis used below.

Conjunction Introduction
Suppose we have Γ ▶ φ and Γ ▶ ψ. By the induction hypothesis, Γ |= φ and Γ |= ψ. Choose any state s and time t such that s, t |▶ Γ, from which it follows that s, t |▶ φ and s, t |▶ ψ. By the semantic definition of conjunction, s, t |▶ φ ∧ ψ. Hence it is safe to assume that Γ ▶ φ ∧ ψ.

Conjunction Elimination
Trivial.

Disjunction Introduction
Trivial.

Disjunction Elimination
We have three induction hypotheses: Γ |= φ ∨ ψ, Γ,φ |= χ, and Γ,ψ |= χ.
Let s and t be such that s, t |▶ Γ. Hence s, t |▶ φ ∨ ψ. Hence either s, t |▶ φ or s, t |▶ ψ. In the first case, s, t |▶ Γ, φ, and so by induction hypothesis, s, t |▶ χ. Similarly in the second case. Either way, s, t |▶ χ, and so Γ |= χ. Hence it is safe to assume that Γ ▶ χ.

In-State Negation Introduction
Suppose Γ,φ ▶ ⊥. By the induction hypothesis, Γ,φ |= ⊥. Since ⊥ is never verified in any state, we may therefore assume that for no state and time does s, t |▶ Γ, φ.
Suppose that s, t |▶ Γ. By monotonicity of direct verification, for all t1 ≥ t, s, t1 |▶ Γ. Since no state and time force Γ and φ, it follows that ∀t1 ≥ t, s, t1 /|▶ φ. By the semantics of in-state negation, this means that s, t |▶∼ φ. Hence Γ |=∼ φ and so it is safe to assume that Γ ▶∼ φ

In-State Negation Axiom
This is not a rule of inference but an axiom. We must show that s, t |▶∼ φ∨ ∼∼ φ
for all s, t.
According to semantic definitions,
s, t |▶∼ φ iff ∀t1 ≥ t : s, t1 /|▶ φ, and
s, t |▶∼∼ φ iff ∀t1 ≥ t, ∃t2 ≥ t1 : s, t2 |▶ φ
Since the temporal order is linear, (2) is equivalent to (2a) s, t |▶∼∼ φ iff ∃t2 ≥ t : s, t2 |▶ φ
It can be seen that (1) and (2a) are complements of one another, and so it follows that either s, t |▶∼ φ or s, t |▶∼∼ φ, for any s and t. Hence by the semantic definition of disjunction, s, t |▶∼ φ∨ ∼∼ φ for all s, t.

Note
The in-state negation axiom is in fact characteristic of ordinary intuitionistic logic with linear frames. The logic KC (Gabbay 1981:66) adds ▶ ¬φ ∨ ¬¬φ as a single extra axiom governing intuitionistic negation. KC is sound and complete with respect to intuitionistic frames where ⊆ is reflexive, transitive and linear. Since the temporal order ≤ is reflexive, transitive and linear, the in-state negation axiom is inevitable.

Implication Introduction
Suppose  that  Stable(Γ),φ  ▶∼∼  ψ.   By  the  induction  hypothesis,
Stable(Γ),φ |=∼∼ ψ. That is, if s, t |▶ Stable(Γ), φ, then ∃t1 ≥ t : s, t1 |▶ ψ.
Let s0, t0 |▶ Γ. Let s and t be a state and time forming a minimal extension of s0 and t0 with respect to φ. By out-of-state monotonicity, ∀tj ≥ t0, sj ⊇t′ s0 : sj, tj |▶ Stable(Γ),and so s, t |▶ Stable(Γ). By the induction hypothesis s, t |▶ φ and so ∃t1 ≥ t : s, t1 |▶ ψ.
These are the semantic conditions required for φ → ψ to hold in s0, t0. So it is safe to assume that Γ ▶ φ → ψ.

Implication Elimination
Suppose Γ ▶ φ and Γ ▶ φ → ψ. By the induction hypothesis, Γ |= φ and Γ |= φ → ψ. According to the semantic definition of implication, if s, t |▶ φ and

s, t |▶ φ → ψ, then there is a t1 ≥ t such that s, t1 |▶ ψ. From which we conclude that s, t |▶∼∼ ψ. Hence, Γ |=∼∼ ψ, and so it is safe to assume that Γ ▶∼∼ ψ.

Out-of-State Negation Introduction
It is possible to define out-of-state negation as ¬φ =df φ → ⊥, eliminating the need for a separate introduction rule. Its introduction rule can be shown to be sound analogously to implication introduction, noting that no state or time is ever such that s, t |▶∼∼ ⊥.

Absurdity
Suppose Γ ▶ ⊥, and so by induction hypothesis Γ |= ⊥. Since there are no states
s or times t such that s, t |▶ ⊥, one can safely assume that Γ |= φ for any φ.

Future Absurdity
Suppose Γ ▶∼∼ ⊥, and so by induction hypothesis Γ |=∼∼ ⊥. By the semantic of ∼ if s, t |▶∼∼ ⊥, then ∃t1 ≥ t such that s, t1⊥. Since there are no states or time that force ⊥, there can be no states of times that force ∼∼ ⊥. So it is safe to conclude that Γ |= ⊥ and so Γ ▶ ⊥.

Future Implication Elimination
Suppose Γ ▶∼∼ φ and Γ ▶ φ → ψ. By the induction hypothesis, Γ |=∼∼ φ and Γ |= φ → ψ. According to the semantics of ∼, if s, t |▶∼∼ φ, then ∃t1 ≥ t such that s, t1 |▶ φ. By in-state monotonicity, if s, t |▶ φ → ψ then s, t1 |▶ φ → ψ as well. By semantics of implication, ∃t2 ≥ t1 such that s, t2 |▶ ψ. And so ∃t2 ≥ t such that s, t2 |▶ ψ. Thus s, t |▶∼∼ ψ. Hence Γ |=∼∼ ψ, and so Γ ▶∼∼ ψ.
Completeness
The proof of completeness is a variation on the Henkin-style completeness proofs for intuitionistic used by Aczel, Fitting and Thomason (van Dalen 1984), and also by Veltman (1985) for Data Semantics. The method involves constructing information states that are represented as saturated sets of formulas. A number of definitions and proofs concerning saturated sets are therefore required before proving complete- ness.
Saturated Theories
Suppose that we have a language L containing a set of sentences Γ, such that Γ /▶ φ
We can construct a saturated extension of Γ relative to (an enumeration of) the sentences in L and φ, Sat(Γ, φ, L), such that
Sat(Γ, φ, L) is closed under ▶

Γ ⊆ Sat(Γ, φ, L)
If ψ ∨ χ ∈ Sat(Γ, φ, L), then either ψ ∈ Sat(Γ, φ, L) or χ ∈ Sat(Γ, φ, L)
φ /∈ Sat(Γ, φ, L)
The construction proceeds inductively as follows.
Stage 0:
Let Δ0 =Γ 
Stage k + 1:
Let ψ1 ∨ ψ2 be the first disjunction in the enumeration of L that has not so far been dealt with, where Δk ▶ ψ1 ∨ ψ2.
Then Δk+1 = Δk ∪ {ψ1} if Δk ∪ {ψ1} /▶ φ
Δk ∪ {ψ2} otherwise.
Sat(Γ, φ, L)= Sk≥0 Δk
The definition and construction, as well as the proofs that (a)–(d) hold, are taken from van Dalen 1984. We start by establishing the disjunction property, (c).


Let ψ ∨ χ ∈ Sat(Γ, φ, L), and let k be the least number such that Δk ▶ ψ ∨ χ.
Then Δi ▶ ψ ∨ χ for all i ≥ k. ψ ∨ χ cannot be treated before stage k, so suppose that it is treated at state j ≥ k. Then either ψ ∈ Δj+1 or χ ∈ Δj+1. And Δj+1 ⊆ Sat(Γ, φ, L)

(a)
Sat(Γ, φ, L) is closed under ▶. For is Sat(Γ, φ, L) ▶ ψ, then Sat(Γ, φ, L) ▶ ψ ∨ ψ.
So by property (c), ψ ∈ Sat(Γ, φ, L).

(b)
That Γ ⊆ Sat(Γ, φ, L) is evident from the construction.

(d)
Clearly, Δ0 /▶ φ. If Δk /▶ φ, then Δk+1 /▶ φ. For let φ ∨ ψ be the k + 1th disjunction treated, i.e. Δk ▶ φ ∨ ψ. Clearly, Δk ∪ {φ} ▶ φ, so ψ must be added. Moreover, Δk,ψ /▶ φ, for if it did and Δk ▶ φ ∨ ψ, then it could not be that Δk /▶ φ.

Which saturated extension of Γ one gets is dependent on the order in which the sentences in L are enumerated. When constructing sets of saturated extensions for Γ, as we will do below, it is assumed that all possible enumerations are employed.
Saturated theories will form the state snapshots used to build canonical models used to establish completeness.

Statement of Completeness Problem
To prove completeness, we must show that Γ |= φ ⇒ Γ ▶ φ
Put in contrapositive form, and expanding out the meaning of |=, this amounts to Γ /▶ φ ⇒ Γ |= φ, i.e.
Γ /▶ φ ⇒ there is a model, state and time such that M, s, t |▶ Γ but M, s, t /|▶ φ.
The general strategy for proving completeness is to construct a saturated exten- sion relative to Γ, φ and some enumeration of the language. This forms the state and time that forces Γ. We then build up temporal extensions of the state, as well as new states plus their temporal extensions, all of which are also saturated theories. We show that for any such theory, Σt , (i.e. state s taken at time t), s, t |▶ ψ iff ψ ∈ Σt . Since Σ0 is just a saturated extension of Γ relative to φ, we have Γ ⊆ Σ0,
s	0	0
but φ /∈ Σ0. This establishes the contrapositive of completeness.
Constructing State Snapshots
Suppose that we have some saturated extension of a set of sentences Γ relative to φ and a given enumeration of L. Call it Σ0, and take it as the initial snapshot of the state. Subsequent snapshots, Σi are constructed relative to the same enumeration of the language as follows:
Σi+1: Let ∼∼ ψ be the first double negation not so far dealt with, such that Σi ▶∼∼ ψ.
Construct a saturated theory from Σi ∪ {ψ} as follows
Step 0:
Let Δ0 = Σi ∪ {ψ}
Step k + 1:
Let ψ1 ∨ψ2 be the first disjunction not so far dealt with such that Δk ▶ ψ1 ∨ψ2. Δk+1 = Δk ∪ {ψ1} iff Σi ▶∼∼ ψ1 or Σi ▶ ψ1
Δk ∪ {ψ2} otherwise.
Σi+1 =	k≥0 Δk
It is straightforward to show that the conditions (a)–(c) of saturated sets apply to these temporal snapshots. The final property (d), that φ is not contained in any Σi, where φ is the sentence used in the construction of the saturated extension to Γ, does not always hold; if φ is a stable sentence, it may well get added to some Σi. But in exchange for this condition, it can be shown that the following holds:
For all Σi, if ψ ∈ Σi, then ∼∼ ψ ∈ Σ0
Constructing an Information Model
To construct an information model where Γ |= φ given that Γ /▶ φ
Construct a saturated extension, Σ0, of Γ relative to φ and some enumeration

of L, and construct a sequence of temporal snapshots, Σi
relative to the same

language enumeration.
Take Stable(Σ0) and construct saturated extensions from it relative to the absurd proposition ⊥, and temporal extensions of these saturated extensions. These form the information states of the canonical information model.
For any Σt and Σt′ formed in this, set
s
s ⊆t sj iff
Stable(Σt ) ⊆ Stable(Σt′ ), and
s	s
for any semi stable implication φ → ψ ∈ Σt , if чψ ∈ Σt′ then φ → ψ /∈
s	s
Σt′
The valuation function for atomic sentence letters coincides with the atomic sentences contained in a given state s at time t, i.e. Σt .
We need to establish the models constructed in this way are legitimate informa- tion models. It is easy to show that the relation ⊆t is transitive and reflexive from the transitivity and reflexivity of the ⊆ relation. That the relation converges (i.e if s0 ⊆t0 s1 ⊆ t1s2, then s0 ⊆t2 s2 for some t2 such that t2 ≥ t0 and t2 ≥ t1) can be seen (for a denumerable language L) by picking a time large enough that all the tem- poral extensions of s0, s1 and s2 become fixed and unchanging. The monotonicity
of the valuation function with respect to subsequent verification times follows from the fact that all the sentences contained in Σt are also included in Σt+1. Monotonic-
s	s
ity of information growth for atomic sentences arises from the fact that all atomic
sentences are classed as stable, and so will be included in all states extending a state that contains them.
Before showing that complex formulas also satisfy monotonicity of information growth where appropriate, it is necessary to establish one other thing about these canonical information models.
Partial monotonicity of semi-stable implications:

j  j	j
t′	jj  jj
jj	j

If φ → ψ ∈ Σs, then 6s ,t if s
≥t′ s, φ ∈ Σs′ and ч(Еs ,t 
such that t ≤ t  < t ,

s ⊆t′′ sjj
⊆t′′ sj
′′
and φ ∈ Σs′′ ,

then φ → ψ ∈ Σt′
Proof: (a) Suppose that чψ ∈ Σt . It can be proved that {φ → ψ, чψ}▶ чφ and so
t has no φ-supporting extensions, minimal or otherwise. And so the condition is
j	t′	t′
vacuously true. (b) Suppose s ≥t′ s, φ ∈ Σs′ and φ → ψ /∈ Σs′ . By the construction
t′	t
of the model it follows that чψ ∈ Σs′ . By (a) it can be seen that чψ /∈ Σs, which
t′	t
means that Σs′ cannot be a minimal φ-extension of Σs. That is, by the construction
of the model, there will be some Σt′′ preceding Σt′ and extending Σt in which φ
holds, and where чψ does not.
In other words, semi-stable implications persist until their consequents become false. Any minimal extension of a state in which a semi-stable implication holds to support the implication’s antecedent will lead to a state in which the implication still holds.
This result helps to nullify problems caused by the monotonicity of some unstable formulas. Recall that unstable formulas can sometimes be valid or invalid (and

hence monotonic), conjunctions or disjunctions of stable formulas with valid or invalid unstable formulas, in-state negations of these formulas, or implications into them. Taking Stable(Σ) to form the basis of extending information states might seem to miss out on some of the monotonic formulas holding in Σ.
Only implication is of any concern. Since Σ is saturated, all conjunctions and disjunctions and Σ are broken down into their component parts, and will be included in Stable(Σ), and so will be included in states extending Σ. Valid (or invalid) unstable formulas will be included (or excluded) in extensions of Σ (by the logical closure of saturated sets), allowing monotonic conjunctions and disjunctions in Σ to be reformed by logical closure. In-state negation can be pushed in so that it has scope over atomic formulas, or out-of-state negations (∼ (φ → ψ) ≡∼ ч(φ∧ ∼ ψ)). Out of state negations, чφ are monotonic, and may either be valid or invalid, in which case ∼ чφ is monotonic, or contingent, in which case ∼ чφ is non-monotonic. In the former case, validities will be included and invalidities included in states built on Stable(Σ) by logical closure, causing ∼ чφ to be excluded or included in saturations of Stable(Σ) as required. When чφ is contingent, it will not and should not be included in Stable(Σ).
With implication, note that φ → (ψ ∧ χ) is equivalent to (φ → ψ) ∧ (φ → χ), so problematic unstable monotonic conjunctions in the consequent get broken down into their component parts. This leaves φ → (ψ ∨ χ), where χ is a valid or invalid unstable formula. This is where the partial monotonicity of semi-stable implications comes to the rescue. First, let χ be valid. Then ψ ∨ χ will never become false, and so any extension of Σ will include φ → (ψ ∨ χ) by the partial monotonicity of semi- stable implications. Now let χ be invalid, and note that φ → (ψ ∨ ⊥) is equivalent to φ → ψ, which is stable if ψ is stable, and so will be included in Stable(Σ).
Forcing and Containment
To finish the completeness proof, we need to establish that
s, t |▶ ψ iff ψ ∈ Σt
To set the ball rolling, for atomic sentences we define the forcing relation as
s, t |▶ p iff p ∈ Σt , atomic p
Then by an inductive argument we show that the same holds for complex formulas. Note that Σt is deductively closed, and so ψ ∈ Σt iff Σt ▶ φ.
s	s	s

Conjunction
s, t |▶ φ ∧ ψ iff φ ∧ ψ ∈ Σt
Only if: Assume φ ∧ ψ ∈ Σt .
By ∧-E, φ ∈ Σt , ψ ∈ Σt .
s	s
By inductive hyp., s, t |▶ φ, s, t |▶ ψ.
By semantics of ∧, s, t |▶ φ ∧ ψ.
If: Assume s, t |▶ φ ∧ ψ.

By semantics of ∧, s, t |▶ φ, s, t |▶ ψ. By inductive hyp., φ ∈ Σt , ψ ∈ Σt .
s	s
By ∧-I, φ ∧ ψ ∈ Σt

Disjunction
s, t |▶ φ ∨ ψ iff φ ∨ ψ ∈ Σt
Only if: Assume φ ∨ ψ ∈ Σt .
By saturation of Σt , φ ∈ Σt , or ψ ∈ Σt .
s	s	s
By inductive hyp., s, t |▶ φ or s, t |▶ ψ.
By semantics of ∨, s, t |▶ φ ∨ ψ.
If: Assume s, t |▶ φ ∨ ψ.
By semantics of ∨, s, t |▶ φ, or s, t |▶ ψ. By inductive hyp., φ ∈ Σt , or ψ ∈ Σt .
s	s
By ∨-I, φ ∨ ψ ∈ Σt

In-State Negation
s, t |▶∼ φ iff ∼ φ ∈ Σt
Only if: Assume ∼ φ ∈ Σt
By construction of model, for all tj ≥ t, ∼ φ ∈ Σt′
By ∼-I, φ /∈ Σt′
By inductive hyp., s, tj /|▶ φ
By semantics of ∼, s, t |▶∼ φ
If: Assume s, t |▶∼ φ
By semantics of ∼, for all tj ≥ t, s, tj /|▶ φ Suppose ∼ φ /∈ Σt and derive a contradiction: By ∼-Ax, if ∼ φ /∈ Σt , then ∼∼ φ ∈ Σt
s	s
By semantics of ∼∼, Etj ≥ t. s, tj |▶ φ
Contradiction.

Implication
s, t |▶ φ → ψ iff φ → ψ ∈ Σt

Only if: Assume φ → ψ ∈ Σt


t	t′

Consider a minimal extension of Σs, Σs′ , with respect to φ.
By the partial monotonicity of semi-stable implications, φ → ψ ∈ Σt′
(If φ → ψ is

′	s′
stable it will be in Σs′ as a matter of course).
By →-E, ∼∼ ψ ∈ Σt′
By ind. hyp., sj, tj |▶ φ, sj, tj |▶∼∼ ψ
By semantics of ∼∼, Et” ≥ tj. sj, t” |▶ ψ
Since sj ≈t′ sj, Es” ≥t′ sj, Et” ≥ tj. s”, t” |▶ ψ
Since sj and tj were arbitrary, by semantics of →, s, t |▶ φ → ψ

If: Assume s, t |▶ φ → ψ
Suppose φ → ψ /∈ Σt and derive a contradiction: By →-I, Stable(Σt ),φ /▶~~ ψ

Let Σt′
be a saturated theory constructed from Stable(Γ) ∪ {φ} relative to ~~ ψ

and some enumeration of L

t′	t	t′

By construction of model, there will be such a Σs′ , where Σs ⊆t Σs′
t′	t′	t′
~~ ψ /∈ Σs′ , and likewise for any Σs′′ ≈t′ Σs′
By ind. hyp., Esj ≥t s, tj ≥ t. sj, tj |▶ φ but not Etjj ≥ tj. sj, tjj |▶ ψ
Contradiction.
Out-of-State Negation
By analogy with implication: чφ =df φ → ⊥.
Completeness
To sum up: Constructing a model from Γ /▶ φ, the state snapshot Σ0 contains Γ but not φ. Consequently 0, 0 |▶ Γ but 0, 0 /|▶ φ. So there is a model falsifying Γ |= φ. Hence Γ |= φ.
