Electronic Notes in Theoretical Computer Science 176 (2007) 3–20	
www.elsevier.com/locate/entcs
Functional Elimination of Φ-instructions
Lennart Beringer1
Lehrstuhl fu¨r Theoretische Informatik Ludwig-Maximilians-Universita¨t Mu¨nchen
Oettingenstrasse 67, 80538 Mu¨nchen, Germany

Abstract
We present a functional analogue of the elimination of Φ-instructions from Static Single Assignment (SSA) code. Extending earlier work on the relationship between SSA and functional languages we show that transformations from A-normal form (ANF) into a more restrictive form called GNF require the same compensating instructions to be inserted as are commonly inserted during the translation from SSA to machine code. Lifting the translation from the syntactic level to the type level, we introduce type systems that mediate the transition from ANF code into correctly register-allocated machine code and allow code optimisations and transformations to be performed in a typed functional setting.
Keywords: Compilation, Functional intermediate representations, Static single assignment form, Phi-elimination, Type systems for register allocation


Introduction
The Static Single Assignment (SSA) form [10] is a popular imperative representation of intermediate code, and several program analysis tasks have been shown to benefit from the usage of SSA [25,18,16]. In order to maintain the defining property which requires each variable to have a single point of definition, Φ-instructions are intro- duced which merge the content of variables at the beginning of basic blocks. During the translation from SSA to machine code, Φ-instructions are replaced by register moves in the control flow predecessors. This insertion of compensation code needs to respect the concurrent interpretation of Φ-instructions in a basic block, even if applied to the outcome of intermediate program optimisations that destroy some of the implicit structure of SSA [8].
Appel and Kelsey observed a close correspondence between SSA and restricted forms of functional programming languages [4,15]. This correspondence is charac- terised by (1) the isomorphism between mutually tail-recursive, first-order functions

1 Email: beringer@tcs.ifi.lmu.de

1571-0661 © 2007 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2007.06.003


SSA
Appel−Kelsey

ANF


 elimination	GNF conversion



imp. Grail
Coincidence of semantics

funct. Grail


Fig. 1. Syntactic Grail conversion and the elimination of Φ-instructions

and labelled basic blocks, (2) the fact that each formal parameter of such a func- tion f amounts to one Φ-instruction at the beginning of the basic block labelled f , and (3) the correspondence between syntactic (nested) scope and the notion of dominance that governs where Φ-instructions are placed. Indeed, it is possible to de- fine a language for which a functional (call-by-value) semantics with scope-directed static binding coincides with an imperative semantics with interpreted Φ-functions. As was demonstrated by Chakravarty et al. [9], the correspondence may also be used to express intermediate program analysis operating on SSA using concepts and terminology from functional languages.
Since the translation into machine code destroys the structure on which the cor- respondence rests, optimisations that cannot be performed at SSA level (coalescing of variables, register allocation, . . . ) cannot be directly modelled as the counterparts of appropriate functional manipulations. Indeed, the elimination of Φ-instructions potentially introduces additional instructions, variables and basic blocks [8,27].
In previous work [7], we introduced a syntactic discipline on functional code which recovers the correspondence in the absence of Φ-functions. We presented a language (Grail ) that does not contain Φ-instructions and may be given coinciding
functional (call-by-value) and imperative semantics, both of which are defined in an entirely standard way. Moreover, (1) functional (let-bound) variables are in bijection with imperative variables (registers), (2) a free occurrence of a variable corresponds to imperative liveness, and (3) each function call amounts to a single (jump) instruction. In particular, ”register shuffling” is explicit, and is performed in compensation instructions that precede the function call. Again, the correspondence could be used for relating program analysis frameworks: we showed that a low- level analysis for detecting when a register content is accessed exactly once could be formalised either imperatively or functionally. The solutions to the appropriate dataflow equations correspond bijectively to the derivations in a certain type system. In this paper, we show that the correspondences at the language levels extend to the translations between the levels (Figure 1). Starting from A-normal form (ANF, [14]), we define a sequence of transformation steps which yields code in Grail normal form (abbreviated GNF), a restricted form of ANF which embodies the essentials of Grail’s syntactic restrictions. In order to demonstrate that the conversion cor- responds to the elimination of Φ-instructions, we then consider the effect of each individual step on SSA. The transformation does not require programs to be in
edge-split form, but involves a weaker manipulation called branch normalisation

that is performed as the last step of the transformation. Thus, function identifiers coincide with basic block labels before and after the application of our algorithm.
As a syntactic code representation, GNF violates functional abstraction prin- ciples as α-conversion is not observed and the class of accepted programs is not closed under β-reduction. Of these two, the latter issue appears less critical and is shared with other functional intermediate languages that require function argu- ments to be variables [3,28]. The violation of α-equivalence is more severe as it precludes equational reasoning. In the second part of this paper we therefore intro- duce a family of type systems that capture different aspects of the conversion. The most restrictive of these type systems can be used to emit code that satisfies the GNF conditions while lifting the strong syntactic conditions. Given Grail’s bijec- tion between imperative registers and functional variables it is not surprising that this type system characterises programs with proper register allocation. It can thus be used as a target for arbitrary register allocation algorithms, and we show that the syntactic GNF conversion can indeed be lifted to a translation between type systems. In Grail, the allocation of registers to program variables amounts to a syntactic transformation on the functional representation. This corresponds to the structure of most imperative compilers which perform register allocation at a low level, after Φ-instructions have been eliminated [21]. In contrast, our framework allows one to study the interactions between optimisations at SSA and machine level, the insertion of compensation code during the Φ-elimination, and low-level register allocation in combination.
Summarising the contributions of this paper, we
present a syntactic translation from ANF into GNF whose correctness is stated in terms of a functional operational semantics (Section 2),
show that the translation corresponds to the elimination of Φ-functions from SSA programs, using a well-known example from the literature as our guiding example (Section 3),
present a family of type systems where variables that may imperatively be mapped to the same register may inhabit the same type, and introduce a formal code ex- traction function whose correctness is stated as a preservation result of operational behaviour (Section 4).
We conclude in Section 5 with a discussion of future and related work. An extended version of this paper is available from the author’s home page and contains the proofs of all theorems as well as some additional material [6].
Syntactic conversion into GNF
Languages ANF and SSA
Our representations of SSA and ANF are similar to those of [9], but we restrict our attention to a single procedure: function applications in ANF occur as tail calls. Given mutually disjoint sets Const of constants (including the special con- stants tt and ff and ranged over by c, d . . .) and Var of variables (ranged over by




b ::= e | b; f : e | b; f : {b}
e ::= ret t; | goto f ;
| x ← t; e
| x ← Φ(p1,..., pn); e
| if t then e else e
a ∈ ANF ::= t | f (t1,..., tn)
| let x = t in a
| if t then a1 else a2
| rec  f1(x1,..., x1 ) = a1
:

fn(xn,..., xn ) = an

p ::= f : t | start : t


t ∈ Term ::= c | x
1	nn
in a


Fig. 2. Syntax of SSA and ANF
f, g, ..., x, y . . .), the syntax of SSA and ANF is given in Figure 2. ANF-expressions can be terms, function calls (arguments must be terms), let-bindings of terms, con- ditionals, and definitions of (possibly mutually recursive) named functions. As is standard practice, we will always assume that function names f1,..., fn occurring jointly in a declaration are distinct, and that in each declaration, the formal parame- ters are distinct and different from the fi. Furthermore, we only consider first-order programs. Similar assumptions apply to the SSA code: the labelling of jointly de- fined basic blocks is unique, and the Φ-instructions in a block f carry exactly one argument g : t for each control flow predecessor g of f . The requirement that the formal arguments in each ANF function declaration be distinct means in SSA that all Φ-instructions in a basic block have distinct left-hand sides. This condition is a common requirement in functional languages, and necessary for the concurrent interpretation of all Φ-instructions in a basic block. We refer the reader to [9] for the formal definition of a translation from SSA programs into ANF expressions and a correctness argument for programs which are properly nested, i.e. programs in which the presence of Φ-functions obeys the dominance relation (see also [3] and [15]).
Our operational semantics for ANF is given by a big-step evaluation relation E ▶ a ⇓ v where E is an environment, i.e. a finite map from variables to values. Values are either constants or closures (represented as triples of formal parameters, environment, and function body):
C = ⟨[x1,..., xn], E, a⟩∈ Clos = Var list × Env × ANF
v ∈ Val = Const + Clos
E ∈ Env = Var '→fin Val
As was pointed out by Milner and Tofte [19], Aczel’s theory of non-well-founded sets can be used to justify this setup as it guarantees the existence of the three (mutually recursively defined) semantic categories, and in particular the existence of objects satisfying infinite identities like F = E [x '→ ⟨[x1,..., xn], F, a⟩]. The domain of E is denoted by dom E , and E [x '→ v] represents the environment mapping x to v and acting like E elsewhere. The rules defining E ▶ a ⇓ v are given in Figure 3.


CONST


E ▶ c ⇓ c

VAR
x ∈ dom E E ▶ x ⇓ E (x)

LET
E ▶ t ⇓ w  E [x '→ w] ▶ a ⇓ v


E ▶ let x = t in a ⇓ v

CALL E ▶ f ⇓ ⟨[x1,..., xn], F, a⟩  ∀ i. E ▶ ti ⇓ vi  F[xi '→ vi]i=1,...,n ▶ a ⇓ v
E ▶ f (t1,..., tn) ⇓ v

  E ▶ t ⇓ tt E ▶ a1 ⇓ v	
TRUE
E ▶ if t then a1 else a2 ⇓ v
	E ▶ t ⇓ f f  E ▶ a2 ⇓ v	
FALSE
E ▶ if t then a1 else a2 ⇓ v

F ▶ a ⇓ v  F = E [fi '→ ⟨[xi ,..., xi ], F, ai⟩]i=1,...,n
REC 	1	ni	
E ▶ rec  f1(x1,..., x1 )= a1 ⇓ v
1	n1
:

fn(xn,..., xn
)= an

1	nn
in a

Fig. 3. Operational semantics of ANF
We omit a formal definition of a semantics for SSA programs but recall the standard interpretation of Φ-functions: when the control flow passes from block f to block g, all Φ-instructions
x1 ← Φ(f 1 : t1,...,f 1 : t1 )
1	1	n	n
:
xk ← Φ(fk : tk,...,fk : tk )
1	1	n	n
in g are interpreted as the concurrent assignment xk ← tk where i is the unique
index with fi = f .

Grail normal form and GNF-conversion
For the purpose of this paper, an ANF program is said to be in Grail normal form
(GNF) if it satisfies the following conditions, where (iii) is optional.
all functions are fully λ-lifted.
for all functions f , all actual arguments in calls to f are variables and coincide syntactically (at each argument position) with the formal parameters in the definition of f .
both arms a1 and a2 of conditionals if t then a1 else a2 are either of the form
t or f (t1,..., tn).
The second condition is also referred to as Grail’s “calling convention”. In [7] we showed that for programs satisfying the calling convention a functional semantics closely related to E ▶ a ⇓ v coincides with a standard imperative semantics. The latter agrees with SSA semantics in the absence of Φ-instructions. The third condi- tion amounts to requiring ANF expressions to be basic blocks rather than extended basic blocks [21].
A translation of an ordinary ANF program into GNF can be achieved using the following four steps: we
α-convert variables globally so that no variable is bound more than once – binding occurs in let-statements and function declarations.

G-I (f (t ,...,t ), [x ,...,x ], x) Q f (x ,...,x ) 6i.xi = ti
1	n	1	n	1	n


G-II (f (t1,..., ti−1, xi, ti+1,..., tn), [x1,..., xn], x) Q a 6j. x
/= t

i	j
(f (t1,..., tn), [x1,..., xn], x) Q let xi = ti in a
G-III 	(f (t1,..., tn)[x/xi], [x1,..., xn], x) Q a	 (	xi /= ti


Fig. 4. Rules defining G

λ-lift all functions, i.e. turn free variables of function bodies into formal pa- rameters, update the function calls accordingly, and then move all function declarations to the top level. The resulting program contains at most one rec statement, at the outermost position.
convert each call into code satisfying the calling convention, i.e. ensure that all calls to a function declared by f (x1,..., xn) = a are literally f (x1,..., xn).
(optionally) normalise branches by inserting fresh function declarations.
The first two steps are well-known, with the two tasks in step (ii) often being referred to as parameter lifting and block floating (see for example the work by Danvy et al. [11]). Since our language is first-order, we consider λ-lifting to mean λ-lifting of arguments of ground type throughout the paper.
The purpose of the third step is to implement the effect of a (hypothetical) parallel assignment
let (x1,..., xn) = (t1,..., tn) in f (x1,..., xn)
by a sequence of unary let-bindings followed by the same call f (x1,..., xn), where x1,..., xn are the formal parameters of f . In principle, this could be achieved by emitting
let y1 = t1 in ... let yn = tn in
let x1 = y1 in ... let xn = yn in f (x1,..., xn),
where the temporary variables y1,..., yn are distinct and fresh. Instead, we propose the following algorithm G that uses only a single temporary variable. We define the result of converting G(f (t1,..., tn), x) to be a if
(f (t1,..., tn), [x1,..., xn], x) D a

can be derived using the rules given in Figure 4. Again, the xi are the formal parameters of f ’s declaration while x is fresh. The result a contains k + m let- bindings where k is the number of positions i with ti /= xi and m is the number of cycles (i.e. sequences [xi0 ,..., xil−1 ] of distinct variables from {x1,..., xn} such that xij = tij+1 mod l for 0 ≤ j < l).
The correctness of step (iii) may be stated as follows.

Theorem 2.1 Let E (f ) = ⟨[x1,..., xn], E^, ^a⟩ and
(f (t1,..., tn), [x1,..., xn], x) D a.

Then for all v, we have E ▶ f (t1,..., tn) ⇓ v ⇐⇒ E ▶ a ⇓ v.
Proof. Induction on the height of (f (t1,..., tn), [x1,..., xn], x) D a. See [6].	 

It is not difficult to see that the side conditions of the rules G-I to G-III are mutually exclusive and exhaustive. All cycles are thus resolved using the same variable x.
Note that the program that results from applying G to all function calls may violate the property established by the first step, as it may contain variables that are bound at several places.
Finally, step (iv) recovers the correspondence between function names and basic block labels. We first replace each non-normalised arm a of a conditional by

rec f (x1,..., xn) = a in f (x1,..., xn)

where x1,..., xn are the free (ground) variables of a and f is a fresh function identifier. We then repeat λ-lifting. As calls to functions introduced by branch normalisation satisfy the calling convention, programs resulting from converting an ANF program are in GNF, although variables are in general bound at more than one place. In particular, GNF does not respect α-equivalence: renaming a let-bound variable or a formal parameter of a function declaration leads (in general) to code violating the calling condition.

GNF conversion is Φ-elimination
We now demonstrate that the GNF conversion corresponds precisely to the elimina- tion of Φ-instructions from SSA code by considering the effect of the four conversion steps on code in SSA form. As running example we use Appel’s program [4] (see Figure 5). The ANF representation of this program is
let i1 = 1, j1 = 1, k1 = 0 in rec f2(j2, k2)= if k2 < 100
then rec f7(j4, k4) = f2(j4, k4) in if j2 < 20
then let j3 = i1, k3 = k2 + 1 in f7(j3, k3)
else let j5 = k2, k5 = k2 + 1 in f7(j5, k5)
else j2
in f2(j1, k1).

Step 1 : Uniqueness of variables holds by the definition of SSA.
Step 2 : Parameter-lifting i1 in f2 and f7 (all other variables are λ-lifted) and performing block-floating yields

B6









Fig. 5. Illustrating Φ-elimination (I) – program taken from [4]



B2	B6








Fig. 6. Illustrating Φ-elimination (II): λ-lifting




rec f2(i1, j2, k2) = if k2 < 100
then if j2 < 20
then let j3 = i1, k3 = k2 + 1 in f7(j3, k3, i1)
else let j5 = k2, k5 = k2 + 1 in f7(j5, k5, i1)
else j2 f7(j4, k4, i1) = f2(i1, j4, k4)
in let i1 = 1, j1 = 1, k1 = 0 in f2(i1, j1, k1).
In SSA, λ-lifting amounts to the insertion of trivial Φ-instructions x = Φ(x,..., x)
- see Figure 6, where blocks 2 and 7 contain the trivial Φ-instruction i1 = Φ(i1, i1). Note that the result is not in SSA form any longer as variable i1 now has three sites of definition.
Step 3 : The fact that λ-lifted variables automatically satisfy the calling restriction is respected by G as no trivial let-bindings let i1 = i1 in ... are introduced.
rec f2(i1, j2, k2) = 
if k2 < 100
then if j2 < 20
then let j3 = i1, k3 = k2 + 1, j4 = j3, k4 = k3 in f7(j4, k4, i1)
else let j5 = k2, k5 = k2 + 1, j4 = j5, k4 = k5 in f7(j4, k4, i1)
else j2
f7(j4, k4, i1) = let j2 = j4, k2 = k4 in f2(i1, j2, k2)
in let i1 = 1, j1 = 1, k1 = 0, j2 = j1, k2 = k1 in f2(i1, j2, k2)
In SSA, the effect of G is to make all Φ-functions trivial – see Figure 7.
Step 4 : Branch-normalisation first introduces parameter-lifted definitions for func- tions f3, f5 and f6. Since these functions have only one call site it is always possible to name the parameters such that the calling restriction is respected.

B6













Fig. 7. Illustrating Φ-elimination (III): conversion G




Fig. 8. Illustrating Φ-elimination (IV a): branch normalisation (part 1)



rec f2(i1, j2, k2) = if k2 < 100
then rec f3(i1, j2, k2)=
if j2 < 20
then rec f5(i1, k2) = let j3 = i1, k3 = k2 + 1,
j4 = j3, k4 = k3
in f7(j4, k4, i1)
in f5(i1, k2)
else rec f6(i1, k2)= let j5 = k2, k5 = k2 + 1,
j4 = j5, k4 = k5
in f7(j4, k4, i1)
in f6(i1, k2)
in f3(i1 j2 k2)
else j2
f7(j4, k4, i1) = let j2 = j4, k2 = k4 in f2(i1, j2, k2)
in let i1 = 1, j1 = 1, k1 = 0, j2 = j1, k2 = k1 in f2(i1, j2, k2)
In SSA, this amounts to inserting unary trivial Φ-instructions in B3, B5 and B6 – see Figure 8. The final phase, λ-lifting, moves functions f3, f5 and f6 to the top level and results in




Fig. 9. Illustrating Φ-elimination (IV b): branch normalisation (part 2)

rec f2(i1, j2, k2) = if k2 < 100 then f3(i1, j2, k2) else j2 f3(i1, j2, k2) = if j2 < 20 then f5(i1, k2) else f6(i1, k2)
f5(i1, k2)= let j3 = i1, k3 = k2 + 1, j4 = j3, k4 = k3 in f7(j4, k4, i1) f6(i1, k2)= let j5 = k2, k5 = k2 + 1, j4 = j5, k4 = k5 in f7(j4, k4, i1) f7(j4, k4, i1)= let j2 = j4, k2 = k4 in f2(i1, j2, k2)
in let i1 = 1, j1 = 1, k1 = 0, j2 = j1, k2 = k1 in f2(i1, j2, k2)
Figure 9 shows the result of deleting the (trivial) Φ-functions.
GNF conversion models Φ-elimination by inserting compensation code immediately prior to jumps. Although no trival assigments let x = x in ... are inserted, the resulting code could be further optimised by coalescing inserted code with in- structions that are already present in the same basic block. Furthermore, GNF conversion does not require programs to be in edge-split form 2 . Like edge-splitting, the normalisation of a branch only adds a single (jump) instruction, but in contrast to edge-splitting, it is performed as the optional last step of our transformation.
In [6], we show that our algorithm respects the concurrent interpretation of Φ-instructions, using standard examples from the literature [8].

Type systems for register allocation
In this section, we introduce a family of type systems for register allocation, in- cluding one variant that captures Grail’s calling convention. None of the systems requires function arguments to syntactically coincide with the formal parameters. We prove the operational correctness of register allocation, i.e. the fact that re- placing each register type occurring in a derivation with a fresh variable does not affect the outcome of evaluating the program. Finally, we relate the variations, and observe that the most restrictive system corresponds to GNF.

Type system
The type systems use sequents of the form Γ ▶Σ a : τ where types τ are built from register types ρ (which range over an abstract class Regs of register identifiers) using the grammar
τ ∈ Type ::= ρ | (ρ1,..., ρn) → ρ.

2 A program is in edge-split form if no control flow edge links a block with out-degree greater than one to a block with in-degree greater than one.


Const


Γ ▶Σ c : ρ
Γ!x = ρ
Var
Γ ▶Σ x : ρ
Let Γ ▶Σ t : ρ Γ, x : ρ1 ▶Σ a : ρ2 x ∈/ dom Σ Γ ▶Σ let x = t in a : ρ2
If Γ ▶Σ t : ρ  Γ ▶Σ a1 : ρ1 Γ ▶Σ a2 : ρ1
Γ ▶Σ if t then a1 else a2 : ρ1

Σ(f )= (ρ ,..., ρ ) → ρ  6i ∈ {1,..., n}.Γ ▶ t : ρ'
Call	i
Γ ▶Σ f (t1,..., tn): ρ
Γ ▶	i	i	i	i
Π ba : ρ	6i. Γ, x1 : ρ1,..., xni : ρni ▶Π ai : ρi
6i j. xi ∈/ dom Π	Π = Σ[fi '→ (ρi ,..., ρi ) → ρi]i=1,...,n

Rec	j
1	ni

Γ ▶Σ rec [fi(xi ,..., xi
) = ai]i=1,...,n in a : ρ

1	ni

Fig. 10. Rules for type system T
Γ,x : ρ!x = ρ	Γ,x : ρ, y : ρ!y = ρ


Γ ▶Σ 5 : ρ
 Γ, x : ρ ▶Σ x : ρ	Γ, x : ρ, y : ρ ▶Σ y : ρ 
Γ,x : ρ ▶Σ let y = x in y : ρ

Γ ▶Σ let x = 5 in let y = x in y : ρ
Fig. 11. Example typing derivation
Register contexts Γ are lists x1 : ρ1,..., xn : ρn where the order of entries arises from the order of assignments, and signatures Σ are partial maps from variables to first-order types (ρ1,..., ρn) → ρ. For register contexts we define the non-standard lookup operation Γ!x by
⎧
[ ]!x = undeﬁned and Γ,y : ρ!x = ⎪⎨ Γ!x	if x /= y and Γ!x /= ρ
⎪⎪⎩ undeﬁned otherwise
while dom Γ = {x|Eρ. Γ!x = ρ}, cod Γ = {ρ|Ex. Γ!x = ρ} and all operations on signatures are defined as usual. Notice that in particular, Γ,x : ρ, Δ!x = ρ implies ρ /∈ cod Δ. The typing rules for the first type system, T, are given in Figure 10. Two rules require some explanations. In rule Var, the side condition Γ!x = ρ retrieves register variables from the context in a last-in-first-out fashion. This guarantees that whenever two variables are mapped to the same register, only the most recently written variable is accessible. In rule Let, the result of evaluating the term t may may be stored in an arbitrary register. We do not require ρ1 and ρ to be identical – indeed, the case where t is a variable and ρ1 /= ρ holds corresponds to a register move. Also notice that Γ,x : ρ1 arises by extending Γ at its right-most position, again enforcing the LIFO behaviour of contexts.
As an example, Figure 11 shows the derivation of
Γ ▶Σ let x = 5 in let y = x in y : ρ
for arbitrary Γ and {x, y} ∩ Σ = ∅, demonstrating that registers may be reused as soon as their previous content becomes dead, and that registers may be shared between the source and the target of a move. In both applications of Let, the source

of the asssignment and the target are given identical types.
Definition 4.1 A signature Σ is well-formed if for all x ∈ dom Σ with Σ(x) = (ρ1,..., ρn) → ρ, the ρi are distinct. A derivation Ð : Γ ▶Σ a : τ is well-formed if Σ is well-formed, and dom Γ ∩ dom Σ = ∅.
Both conditions mentioned in this definition propagate upwards through all typ- ing rules and thus hold for any sequent of a well-formed derivation.
In addition to the type system T, we consider several variations. These are obtained by imposing one or both of the additional side conditions
6i ∈ {1,..., n}. ti = yi and	(1)
6i ∈ {1,..., n}. ρ' = ρi	(2)
on rule Call, and are denoted by Tx (condition (1)), Tρ (condition (2)), and Tx,ρ (both conditions). The four calculi can be ordered by restrictiveness into the di- amond T и Tx, Tx и Tx,ρ, T и Tρ, Tρ и Tx,ρ (Tx and Tρ are incomparable). Of particular interest are Tρ and Tx,ρ as condition (2) requires arguments to be available in the registers specified by Σ(x). It thus corresponds to Grail’s calling convention: a call x(a, b) to a function with Σ(x) = (r1, r2) → r2 is well-typed exactly if Γ ▶Σ a : r1 and Γ ▶Σ b : r2 hold, where Definition 4.1 ensures r1 /= r2.
Example 4.2 Consider two function definitions for the factorial function.
rec fac1(n, a) = let test = n < 1 in
if test then a else let m = n − 1, b = a ∗ n in fac1(m, b) rec fac2(n, a) = let test = n < 1 in
if test then a else let b = a ∗ n, m = n − 1 in fac2(m, b)
For fac1 cannot be typed in system Tρ, since Σ(fac1) = (ρn, ρa) → ρ yields ρn /= ρa, so from rule Call we obtain ρn = ρm and ρa = ρb, while the typing of the else-branch requires us to derive n : ρn, a : ρa, test : ρtest, m : ρm ▶ n : ρ for some ρ, hence ρn /= ρm. In contrast, program fac2 is typeable using the three registers ρn = ρm, ρa = ρb and ρtest.
Unless stated otherwise, statements in the remainder of this paper refer to the system T and are thus independent of the additional side conditions.
Register allocation
Each well-formed typing derivation for a program a uniquely determines a register- allocated program which is obtained by choosing a fresh variable for each register identifier ρ that occurs in the derivation and converting a so that any binding of a variable x of type ρ is replaced by the fresh variable associated to ρ.
Definition 4.3 An injective map α : Regs → Var is called a register allocation for
Ð if all sequents Γ ▶Σ a : τ in Ð satisfy cod α ∩ dom Σ = ∅.
Thus, an allocation for Ð is also an allocation for any subderivation Ð' of Ð.
The rewriting step is defined by the function Aα(.) in Figure 12, which converts a typing derivation Ð with final sequent Γ ▶Σ a : ρ into Aα(a), given allocation α.

Aα(Const	)	= c
Γ ▶Σ c : ρ


Aα( Var
Γ!x = ρ


Γ ▶Σ x : ρ

)	= α(ρ)





Aα( Let
D1 :Γ ▶Σ t : ρ
D2 : Γ,x : ρ1 ▶Σ a : ρ2 x ∈/ dom Σ

Γ ▶Σ let x = t in a : ρ2


)	= let α(ρ1) = Aα(D1) in Aα(D2)

A (If D0 :Γ ▶Σ t : ρ 6i ∈ {1, 2}. Di :Γ ▶Σ ai : ρ1 ) = ( if Aα(D0) then Aα(D1)
Γ ▶Σ if t then a1 else a2 : ρ1	else Aα(D2)

Σ(f )= (ρ1,..., ρn) → ρ
 6i ∈ {1,..., n}.Di :Γ ▶Σ ti : ρ'
Aα( Call	)	= f (Aα(D1),..., Aα(Dn))
Γ ▶Σ f (t1,..., tn): ρ

D0 :Γ ▶Π ba : ρ
6i j k. j /= k ⇒ ρi /= ρi
j	k

6i. fi ∈/ dom Γ ∪ dom Σ
6i j. xi ∈/ dom Π
Π= Σ[fi '→ (ρi ,..., ρi



) → ρi]i=1,...,n

8>< rec [fi(α(ρi ),..., α(ρi ))

Γ ▶Σ rec [fi(x1,..., xni ) = ai]i : ρ
in a

>: in Aα(D0)


Fig. 12. Register allocation: rewriting step

Example 4.4 For an allocation α with α(ρn) = α(ρm) = n, α(ρa) = α(ρb) = a, and α(ρtest) = test, the result of applying Aα(.) to fac2 is

rec fac2'(n, a) = let test = n < 1 in
if test then a else let a = a ∗ n, n = n − 1 in fac2'(n, a).

This code behaves exactly like fac2 but is in (non branch normalised) GNF.
The program Aα(Ð) again corresponds to the result of eliminating Φ-instructions and satisfies Grail’s calling convention. It also coincides semantically with a in the following sense.
Theorem 4.5 Let Ð : Γ ▶Σ a : τ be well-formed, α a register allocation for Ð, and fv (a) = ∅. Then E ▶ a ⇓ v ⇐⇒ F ▶ Aα(Ð) ⇓ v.
The claim follows from a more general result for expressions with free variables, whose proof employs an equivalence relation on environments, following the coin- ductive proof technique by Milner and Tofte. For the details, see [6].

Proof Transformations
The availability of register information in the types allows us to rephrase the GNF conversion as a translation between type systems. In Figure 13, we give a definition

if 6j. ρj = σj : Ð

if 6j. ρi /= σj and x ∈/ {yj |j /= i}∪ dom Σ: 


Ð :Γ ▶

y : σ
Φ  6j /= i. Ðcj : Γ,x : ρi ▶Σ yj : σj  Γ,x : ρi ▶Σ x : ρi !




Γ ▶Σ let x = yi in f (y1,..., yi−1, x, yi+1,..., yn): ρ
if ρi /= σi and 6k.Ej.ρk = σj , and x ∈/ {yj |j /= i}∪ dom Σ: 


Ð :Γ ▶

y : σ
Φ  6j s.t. yj /= yi :
Ðcj : Γ,x : ω ▶Σ yj : σj  Γ,x : ω ▶Σ x : ω !




Γ ▶Σ let x = yi in f (y1,..., yn)[x/yi]: ρ

Fig. 13. Proof transformation Φω for converting Ð ∈ Tx to Φω(Ð) ∈ Tx,ρ.


of such a translation from Tx to Tx,ρ, defined by three clauses. The algorithm transforms a subderivation Ð of shape

Call Ðj : Γ ▶Σ yj : σj	Σ(f ) = (ρ1,..., ρn) → ρ
Γ ▶Σ f (y1,..., yn) : ρ

into a derivation Φω(Ð) where ω is a fresh register. The side conditions on register types in all three rules mirror the syntactic side conditions of the earlier rules G — I to G — III. In rule the second clause, all derivations Ðj are valid since Γ!yj = σj /= ρi holds for all j /= i. The role of the single additional variable in rule G — III is played by the register ω in the third clause.
More formally, the relationship to algorithm G may be stated as follows:
Theorem 4.6 Let Ð : Γ ▶Σ f (y1,..., yn) : ρ and Σ(f ) = (ρ1,..., ρn) → ρ. Let α
be an allocation for Ð and ω ∈/ {ρ1,..., ρn}∪ dom Σ. Then

(Aα(Ð), [α(ρ1),..., α(ρn)], α(ω)) D Aα(Φω(Ð)).

Proof. Induction on the height of Φω(Ð). Details are given in [6].	 

Together with Theorems 2.1 and 4.5, this result establishes operational correct- ness of type-based register allocation in using Φ.
In imperative compilers, low-level optimisations that interact with register al- location need to be performed after Φ-instructions have been eliminated, and can thus not exploit the SSA structure. The typed setting allows us to phrase such peephole optimisations in a functional setting and to use the ANF structure to jus- tify them. At the level of non-register allocated ANF, Chakravarty et al. rephrased an SSA-based algorithm for performing constant propagation and unreachable code elimination as a functional manipulation, and point out the benefits of such an approach for proving the correctness of the analysis [9]. While we have not yet performed a detailed study of peephole optimisations, it is not difficult to prove the

soundness of simple transformations such as

Γ ▶Σ let x = t1 in let y = t2 in a : ρ
t2/=x,t1/=y,x/=y
—————————→	▶Σ	y	t2	x	t1	a  ρ

or of the following optimisation of the code emission function Aα(.)
Γ ▶Σ y : ρ1	Ð : Γ, x : ρ2 ▶Σ a : ρ	ρ1=ρ2

Aα( Let
) ————→ Aα(Ð)
Γ ▶Σ let x = y in a : ρ

which avoids trivial assignments let α(ρ1) = α(ρ1) in ... arising from instantiation of the Let-rule with t = y and ρ = ρ1.

Discussion
In this paper, we demonstrated that the elimination of Φ-instructions from code in SSA form corresponds to a conversion of functional programs from ANF into the more restrictive GNF format. We first introduced the conversion as a purely syntactic translation that combines well-known transformation steps such as λ- lifting with GNF conversion and branch normalisation. We then introduced a family of type systems which model intermediate program representations and are related by proof-transformations. Operational soundness was established using a simple code extraction function that if applied to the most restrictive calculus generates code that can be interpreted functionally or imperatively, without the need for Φ-instructions.
Several authors have recently proposed type-based calculi for register allocation, often using an ANF-like language [28,1,2,24]. While we have restricted our attention to a first-order language with tail-recursive calls, a generalisation to higher-order functions, where caller and callee need to agree on specific register allocation disci- plines, is clearly desirable. Indeed, [28], [1] and [2] employ effect systems to record the impact of more general function calls on registers, and similar annotations are recorded in the types of code pointers in TAL [20].
Ohori’s proof-theoretic account of register allocation [24] is based on the sequen- tial sequent calculus (SSC, [23]). Code is represented imperatively, and proof trees are of linear shape. Return instructions are modelled as axioms, and sequential program composition is modelled as the application of syntax-directed proof rules. Structural rules model variable liveness, govern the allocation process, and differ- entiate between register-based machines and stack-based machines in a style that generalises our context-lookup rules for register variables. Although a relationship with SSA is briefly discussed, no details are given in [24], but [22] explores the relationship between various proof systems and compilation into ANF. A more de- tailed proof-theoretic analysis of our translations would thus complement the work of Ohori, while being notationally closer to functional type systems than the SSC is. Also based on ANF is the type system of Thiemann, where, again, structural rules on contexts model the shadowing of register contents [28].

Agat [1] proposes a type system for a low-level explicitly register-annotated func- tional form for machines with (finite) register files and (in principle unbounded) stacks. The transition from unallocated to allocated programs is obtained by two operational semantics, the first of which ignores the register annotations and uses a functional interpretation and the second of which models an imperative semantics on register files. In contrast to our setting, program variables do not correspond directly to registers and explicit instructions are introduced that move values be- tween different locations. The soundness result of the type system states that the two semantics coincide for well-typed programs and is proven using a further oper- ational semantics that unifies the two earlier ones. The type system includes effect annotations for closures which ensure that functions expect their arguments in the correct registers and do not interfere with live locations.
Similar to these formal systems, our type system was presented as a mechanism for specifying register allocations. Obtaining allocations amounts to inferring type judgements - a task which we did not address in this paper. Although the sys- tem was described using an unstructured set of registers, it can be generalised to include several types of registers (double precision,. . . ), or memory locations, for example by introducing a kinding system. The specific behaviour of different stor- age locations would then be represented by the availability of kind-specific typing or transformation rules. Thus, the effect of techniques such as spilling could be modelled, although the optimisation task of deciding which intermediates to spill would again be a matter of type inference.
In Morrisett et al.’s Typed Assembly Language, register allocation is performed as the last transformation step [20]. As is the case for our algorithm, function calls are treated individually, but the number of generated moves is slightly higher than that of GNF conversion: a call f (t1,..., tn) expands to n move instructions to temporary registers plus n moves to the callee’s registers. Furthermore, register names do not α-convert.
Sreedhar et al. [27] propose a technique for eliminating Φ-instructions from SSA code that eliminates more move instructions than earlier mechanisms that rely on post-processing[10,8]. This algorithm is based on liveness information and a notion of interference between program variables determined by their joint occurrence in a Φ-instruction. The associated congruence classes appear similar to our register types in all type systems stronger than Tρ, but a more detailed study is needed to determine how [27]’s algorithm relates to our setting.
Recent contributions to the formal verification of compiler analysis optimisations using theorem prover include [17,26] at the intermediate level, while [12,13] verified peephole optimisation steps in PVS.
Although the syntactic view on GNF conversion models more directly the effect of eliminating Φ-instructions in compilers – indeed, one may argue that the violation of α-equivalence is a distinctive feature of low-level languages – the potential to apply (equational) reasoning techniques appears to favour a type-based formulation. In this context, the recent work of Benton [5] appears relevant. This work presented Hoare-style program logics and type systems for reasoning about dependency and

constancy information, information flow and dead code elimination in an imperative setting, exploiting the equational theory arising from interpretations of types as partial equivalence relations.
Acknowledgement
I would like to thank Alberto Momigliano for introducing me to proof techniques for coinductive semantics, and Kenneth MacKenzie and Ian Stark for commenting on earlier versions of this paper. I am also grateful to the referees, whose sugges- tions have been very valuable. This work was partially supported by the EPSRC project ReQueST (grant reference EP/C537068/1) and by the Information Society Technologies programme of the European Commission, Future and Emerging Tech- nologies under the IST-2005-015905 MOBIUS project. This paper reflects only the author’s views and the Community is not liable for any use that may be made of the information contained therein.

References
Johan Agat. Type Based Techniques for Covert Channel Elimination and Register Allocation. PhD thesis, Department of Computing Science, Chalmers University of Technology and Gothenburg University, 2000.
Torben Amtoft and Robert Muller. Inferring annotated types for inter-procedural register allocation with constructor flattening. In Proceedings of TLDI’03, SIGPLAN Notices, pages 86–97. ACM Press, January 2003.
Andrew W. Appel. Modern Compiler Implementation in ML. Cambridge University Press, 1998.
Andrew W. Appel. SSA is functional programming. ACM SIGPLAN Notices, 33(4):17–20, April 1998.
Nick Benton. Simple relational correctness proofs for static analyses and program transformations. In Neil D. Jones and Xavier Leroy, editors, Proceedings of POPL ’04, pages 14–25. ACM, January 2004.
Lennart Beringer.	Functional elimination of φ-instructions (full version).	Available at
http://www.tcs.ifi.lmu.de/~beringer.
Lennart Beringer, Kenneth MacKenzie, and Ian Stark. Grail: A functional form for imperative mobile code. In Proceedings of the 2nd EATCS Workshop on Foundations of Global Computing (FGC’03), volume 85(1) of ENTCS. Elsevier Science, June 2003.
Preston Briggs, Keith D. Cooper, Timothy J. Harvey, and L. Taylor Simpson. Practical improvements to the construction and destruction of static single assignment form. Software – Practice and Experience, 28(8):859–881, 1998.
Manuel M. T. Chakravarty, Gabriele Keller, and Patryk Zadarnowski. A functional perspective on SSA optimisation algorithms. In Procceedings of the 2nd International Workshop on Compiler Optimization Meets Compiler Verification (COCV’03), volume 82(2) of ENTCS. Elsevier Science, 2003.
Ron Cytron, Jeanne Ferrante, Barry K. Rosen, Mark N. Wegman, and F. Kenneth Zadeck. Efficiently computing static single assignment form and the control dependence graph. ACM Transactions on Programming Languages and Systems, 13(4):451–490, October 1991.
Olivier Danvy and Ulrik P. Schultz. Lambda-dropping: transforming recursive equations into programs with block structure. In Proceedings of the 1997 ACM SIGPLAN Symposium on Partial evaluation and semantics-based program manipulation (PEPM ’97), pages 90–106, New York, NY, USA, 1997. ACM Press.
A. Dold, F.W. von Henke, H. Pfeifer, and H. Rueß. Formal verification of transformations for peephole optimization. In P. Lucas J. Fitzgerald, C.B. Jones, editor, FME ’97: Formal Methods: Their Industrial Application and Strengthened Foundations, volume 1313 of LNCS, pages 459–472. Springer, September 1997.


Axel Dold and Vincent Vialard. Formal verification of a compiler back-end generic checker program. In Proc. of the Andrei Ershov Third International Conference Perspectives of System Informatics (PSI’99), number 1755 in LNCS, pages 470–480. Springer, 2000.
Cormac Flanagan, Amr Sabry, Bruce F. Duba, and Matthias Felleisen. The essence of compiling with continuations. In Proceedings of the ACM Conference on Programming Language Design and Implementation (PLDI’93), pages 237–247. ACM, 1993.
Richard A. Kelsey. A correspondence between continuation passing style and static single assignment form. ACM SIGPLAN Notices, 30(3):13–22, 1995.
Robert Kennedy, Sun Chan, Shin-Ming Liu, Raymond Lo, Peng Tu, and Fred Chow. Partial redundancy elimination in SSA form. ACM Transactions on Programming Languages and Systems, 21(3):627–676, 1999.
Sorin Lerner, Todd Millstein, and Craig Chambers. Automatically proving the correctness of compiler optimizations. In Proceedings of the In ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI 2003), pages 220–231. ACM, June 2003.
Raymond Lo, Fred Chow, Robert Kennedy, Shin-Ming Liu, and Peng Tu. Register promotion by sparse partial redundancy elimination of loads and stores. ACM SIGPLAN Notices, 33(5):26–37, 1998.
Robin Milner and Mads Tofte. Co-induction in relational semantics. Theoretical Computer Science, 87:209–220, 1991.
Greg Morrisett, David Walker, Karl Crary, and Neal Glew. From System F to typed assembly language.
ACM Transactions on Programming Languages and Systems, 21(3):527–568, May 1999.
Steven Muchnick. Compiler Design and Implementation. Morgan Kaufmann, 1997.
Atsushi Ohori. A Curry-Howard isomorphism for compilation and program execution. In J.-Y. Girard, editor, Proceedings of the 4th International Conference on Typed Lambda Calculi and Applications (TLCA’99), volume 1581 of LNCS, pages 280 – 294. Springer, April 1999.
Atsushi Ohori. The Logical Abstract Machine: a Curry-Howard isomorphism for machine code. In Aart Middeldorp and Taisuke Sato, editors, Proceedings of the 4th Fuji International Symposium on Functional and Logic Programming (FLOPS’99), volume 1722 of LNCS, pages 300 – 318. Springer, November 1999.
Atsushi Ohori. Register allocation by proof transformation. In P. Degano, editor, Proceedings of the 12th European Symposium on Programming (ESOP’03), volume 2618 of LNCS, pages 399 – 413. Springer, April 2003.
Barry K. Rosen, Mark N. Wegman, and F. Kenneth Zadeck. Global value numbers and redundant computations. In Proceedings of POPL ’88, pages 12 – 27. ACM, 1988.
Alexandru Salcianu and Konstantine Arkoudas. Machine-checkable correctness proofs for intra- procedural dataflow analyses. In Jens Knoop, George Necula, and Wolf Zimmermann, editors, Proceedings of the 4th International Workshop on Compiler Optimization Meets Compiler Verification (COCV’05), April 2005.
Vugranam C. Sreedhar, Roy Dz-Ching Ju, David M. Gillies, and Vatsa Santhanam. Translating out of static single assignment form. In Static Analysis: Proceedings of the 6th International Symposium (SAS’99), volume 1694 of LNCS, pages 194–210. Springer, September 1999.
Peter Thiemann. Formalizing resource allocation in a compiler. In Xavier Leroy and Atsushi Ohori, editors, Proceedings of the Second International Workshop on Types in Compilation (TIC’98), volume 1473 of LNCS, pages 178–193. Springer, March 2003.
