Electronic Notes in Theoretical Computer Science 125 (2005) 149–164 
www.elsevier.com/locate/entcs


Logical Semantics for the Rewriting Calculus
Aaron Stump
Dept. of Computer Science and Engineering, Washington University in St. Louis, St. Louis, MO, USA, Web: http://www.cse.wustl.edu/˜stump
Carsten Schu¨rmann
Dept. of Computer Science, Yale University, New Haven, CT, USA, Web: http://cs-www.cs.yale.edu/homes/carsten/

Abstract
The Rewriting Calculus has been proposed as a language for defining term rewriting strategies. Rules are explicitly represented as terms, and are applied explicitly to other terms to transform them. Sets of rules may be applied to (sets of) terms non-deterministically to obtain sets of results. Strategies are implemented as rules which accept other rules as arguments and apply them in certain ways. This paper describes work in progress to strengthen the Rewriting Calculus by giving it a logical semantics. Such a semantics can provide crucial guidance for studying the language and increasing its expressive power. The latter is demonstrated by adding support to the Rewriting Calculus for what we call higher-form rewriting, where rules rewrite other rules. The logical semantics used is based on ordered linear logic. The paper develops the ideas through several examples.
Keywords: Rewriting Calculus, Ordered Linear Logic, Logical Semantics, Meta-Programming

Introduction
The untyped Rewriting Calculus of H. Cirstea and C. Kirchner is a higher- order functional language of explicit rewriting [3,4]. In contrast with standard term rewriting (see, e.g., [1]), the rewriting is explicit is the sense that rewrite rules must be applied explicitly to terms to transform them. For example, in order to transform a term ¬¬p using the rule ¬¬X → X, we must evaluate the expression
(¬¬X → X) @ ¬¬p


1571-0661 © 2005 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2005.01.001


where we write @ for explicit application of a rule. The language is higher- order in the sense that rules and even sets of rules may be passed as arguments to other rules. This enables parameterized strategies to be written [6]. A very simple example taken from the cited work is
u → v → x → v @ (u @ x)
This term (call it seq ) represents the strategy of rule sequencing: rules u and v are accepted, and a new rule is returned which will transform any term x by first applying u and then applying v to the result. So evaluating seq @ (f (x) → g(x)) @ (g(x) → h(x)) @ f (a) yields h(a).
The present work aims to strengthen the Rewriting Calculus in two ways. First, a definitive definition of the Rewriting Calculus has been elusive. For example, different versions of the language have been proposed in several papers (e.g. in [3] and [5]). One example of a design choice where it is hard to see which approach to choose has to do with applications involving sets. If a set of rules {R1,... , Rn} is applied to a term T , then the result is defined to be {R1 @ T,... , Rn @ T }. This distributivity from the right of application over set formation is in accord with the idea that applying a set of rules to a term can have different results. Those results might not, for example, be joinable (if the rules are not confluent) or even semantically equivalent (e.g., if the rules are a → 0 and a → 1). The Rewriting Calculus just collects all the results in a set. So distributivity of application from the right seems reasonable. But what about distributivity from the left? If a single rule R is applied to a set of terms {T1,... , Tn}, should this evaluate to
{R @ T1,... ,R @ Tn}? It seems plausible, and would be very convenient to
transform sets of results. But consider the case where the rule (call it R) is something like {x, y} → x + y, with x and y variables. If we apply this rule to the set {2, 3}, we might expect to get 5. If we distribute the application over the target set {2, 3}, however, we will end up with {R @ 2, R @ 3}. In the version of the Rewriting Calculus from [3] (but not in the one from [5]), the expression {x, y} → x + y can evaluate to {x → x + y, y → x + y}. So we end up with the rather surprising {2+ y, x + 3, 3+ y, x + 2}, instead of 5. In the absence of another semantics for Rewriting Calculus terms, it is difficult to justify design decisions about matters like which kinds of distributivity to include in the operational semantics.
The present works also aims to strengthen the Rewriting Calculus by studying how to support what we call higher-form (to distinguish it from higher-order) rewriting. Higher-form rewriting enables rules to rewrite rules. A simple if somewhat artificial example is that of a rule which just reverses the left and right hand sides of a rule. So f (x) → g(x) would be rewritten to


its reverse, g(x) → f (x). A natural way to try to write rule reversal would be as something like (x → y) → (y → x). The problem that quickly be- comes apparent, however, is in dealing with the pattern variables of rules. In the Rewriting Calculus, the arrow is considered to be a binding construct [3]: all variables free in the left hand side (lhs) are considered bound by the ar- row and subject to instantiation during pattern matching. As usual, terms are considered equivalent up to renaming of bound variables. So the term (x → y) → (y → x) is equivalent to (x → y) → (z → x), because the second occurrence of y is bound by the last arrow. And clearly this latter rule will not have the desired operational effect.
One attempt to improve this situation was made in [2], where arrow ex- pressions are allowed to carry with them (typed) contexts declaring which variables are bound by the arrow and which are free. So we can write a rule like (x →∅ y) →{x,y} (y →∅ x) where the subscripts of ∅ on the two arrows lower in the term show that the variables x and y are not bound by them; the
{x, y} subscript on the topmost arrow shows that x and y are bound there. But on the account given in [2], this rule is sufficient for reversing only ground rules like f (a, b) →∅ g(b). We cannot use the proposed rule to reverse a rule with its own non-empty pattern variable context like f (x, y) →{x,y} g(y), be- cause the proposed rule requires ∅ for the context of the rule to be reversed. While it is possible to come up with an ad hoc operational semantics to al- low higher-form rewriting, it again becomes difficult to justify certain design choices which arise.
The solution proposed here to these problems is to give what we call a logi- cal semantics for the Rewriting Calculus. This semantics explains the meaning of constructs from term rewriting by interpreting them as logical constructs. In particular, we will interpret terms as logical formulas, and rewriting as log- ical entailment. Logic is a good place to look for a semantics for the Rewriting Calculus, given the origins of term rewriting in equational logic. Connecting the Rewriting Calculus to logic in a deep way can help guide the design of the language. We begin with a logical semantics for standard first-order term rewriting (Section 2). This semantics generalizes, with one modification, to interpret higher-form rewriting (Section 3). Finally (Section 4), we define the operational semantics of the Rewriting Calculus using our logical semantics, and compare it to the operational semantics given in [3]. Our semantics re- quires several seemingly minor extensions to well-understood logics. These extensions have not been satisfactorily studied yet, and so this remains work in progress.

Logical Semantics for First-Order Term Rewriting
We begin by giving a logical semantics for traditional unsorted first-order term rewriting. The intuition for our logical semantics has several ingredi- ents. First, we note that performing a single step of rewriting involves using exactly one rule exactly once. The linearity restrictions suggest a linear logic. Second, if we wish to give a logical interpretation to semantically non-confluent rule sets like {a → 0, a → 1}, we can hardly interpret → as equality and set formation as conjunction. For then we would be rewriting with something whose logical interpretation was equivalent to false. Since false implies any- thing, all rewrites would be logically justified using such a rule set. It makes more semantic sense to view a rule set as a resource which can be specialized exactly once to any of its rules. Finally, of course, syntactic pattern matching naturally suggests instantiation of universal quantifiers.
To give a semantics for term rewriting, we first adopt a definition of it (cf. [1,8]). We havea single sort I for all terms, together with a finite signature Σ of function symbols, each with a fixed arity. Terms are built from Σ and a countable set of variables in the usual way. The set of free variables FV(X) of a term X is defined as usual, as is the set of positions of a term. A rewrite rule is a pair of terms, written L → R, where we require L not to be a variable and FV(R) ⊂ FV(L). We extend FV to rules and sets of rules in the obvious way. We then say that term σ(L) rewrites to σ(R) at the top-level position using rule L → R iff σ is a substitution with domain including FV(L). We state
that f (t1,... , tn) rewrites to f (t' ,... , t' ) at position i · π using such a rule iff
1	n

ti rewrites to t' at position π using that rule, and tj ≡ t'
for all j /= i. We also

i	j
state that t rewrites to t' using a rule iff it does so at some position. Then
t rewrites to t' using a finite set of rules Y (notation: t ⇒R t') iff t rewrites to t' using one of the rules from Y. Finally, if t rewrites to each of t1,... , tn using Y, we write t ⇒R {t1,... , tn}. Notice that as a degenerate case of this last stipulation, we have t ⇒R ∅ for all t and Y.
We now define our interpretation of terms, rules, and sets of rules. To model first-order terms as resources in the sense of linear logic, we must inter- pret them as formulas. So our interpretation [I ] of the single sort I of terms is O, the type of propositions. This forces us to model function symbols as higher-order (because taking in propositions) predicate symbols; we will view them as curried. We use ~ as the symbol for function space constructor, to reserve other arrow notations for more central concepts. The higher-order extension of our base fragment of standard intuitionistic linear logic (for what follows, we rely on [12]) is given in Figure 1. In that Figure, Γ is interpreted as a multiset of formulas. Our base fragment has just the operators 6, —◦, &, and T. We need additionally the congruence rule (Congr) so that we can




	
A ▶ A(Ax)	Γ ▶ T(TI)	(1)
Γ ▶ A—◦B

Γ ▶ p[A]—◦p[B (Congr)



Γ,A ▶ B


Γ ▶ A—◦B(—◦I)
Γ ▶ A—◦B	Γ' ▶ A

Γ, Γ' ▶ B	(—◦E)



Γ ▶ A	Γ ▶ B
Γ ▶ A&B	(&I)	(2)
Γ ▶ A1&A2
Γ ▶ Ai	(&E)




(3)
Γ ▶ [y/x]A
Γ ▶ 6x :	(6I)
Γ ▶ 6x : O.A
Γ ▶ [t/x]A (6E)



(1) p an atomic context, (2) i ∈ {1, 2}, (3) y not free in Γ
Fig. 1. Our fragment of linear logic + (Congr)

[[x]] := x, for x a variable [[f (t1,... , tn)]] := f [[t1]] ... [[tn]]
[[t1 → t2]] := 6x1 : O	6xn : O.[[t1]]—◦[[t2]],
where {x1,.	xn} = FV(t1 → t2)
[[{t1,... , tn}]] := [[t1]]&	&[[tn]]
[[t ⇒R t']] := [[Y]] ▶ [[t]]—◦[[t']]
Fig. 2. Interpretation of rewriting into linear logic

rewrite at positions other than the top one. The side condition on (Congr) is that p is an atomic context, which we define to be being a ground term without connectives (i.e., a term built just from application and symbols from our signature) containing a single hole. A rule similar to (Congr) is admis- sible in our base fragment, but we lack further justification for (Congr) at present. Our interpretation is now given by Figure 2. The intention is for the rewriting judgment t ⇒R X to hold, where X is a term or set of terms, iff its interpretation is derivable.


For the interpretation of sets of terms, we understand the following degen- erate cases by convention (the last one because T is the unit for &):
[[{t}]] := [[t]] [[∅]] := T
Example: Suppose Y is a → b. Then the rewriting judgment f (a, c) ⇒R f (b, c) holds, and its interpretation is derivable (where we take atomic context (f  c) in the use of (Congr)):


a—◦b ▶ a—◦ (Ax)
a—◦b ▶ (f a c) —◦ (f b c (Congr)
Example: Suppose Y is {f (x, g(y)) → h(y),f (g(y), x) → h(b)}. Then the rewriting judgment f (g(a), g(a)) ⇒R {h(a), h(b)} clearly holds. The cor- responding sequent is easily observed to be derivable:
(6x : O.6y : O.f x (g y)—◦(h y)) &
(6x : O.6y : O.f (g y) x—◦(h b))	▶ f (g a) (g a)—◦(h a) & (h b)
We now prove completeness and restricted soundness of our semantics with respect to first-order rewriting. Note that we are viewing first-order rewriting as “ground truth” and our semantics as an attempt to express that ground truth in another way. Thus, it is correct to speak of completeness as the property that if a rewriting judgment holds, its interpretation is derivable (if it is true, then we can express it); and of soundness as the property that if the interpretation of a rewriting judgment is derivable, the judgment holds (if we express it, then it is true).
Theorem 1 (Completeness) Suppose X is a term or set of terms, and the rewriting judgment t ⇒R X holds. Then its interpretation [[Y]] ▶ [[t]]—◦[[X]] is derivable.
Proof. By induction on the derivation of the rewriting judgment. If the rewriting step combines several results into a set of results, we use our induc- tion hypothesis and the appropriate number of uses of (&I). If the rewriting step combines 0 results, then we use (TI). If the rewriting step uses rule (L → R) ∈ Y, the induction hypothesis gives us (writing 6∗ for universal closure of a formula) 6∗[[L]]—◦[[R]] ▶ [[t]]—◦[[X ]. The result then easily follows from the elementary fact that Y ▶ 6∗[[L]]—◦[[R ]. If the rewriting step applies


a rule at position π other than the top-level one, the induction hypothesis and (Congr) give us what we need. If the rewriting step is at the top-level, we instantiate the universal quantifiers for the interpretation of the rule in accordance with the matching substitution.	 
Theorem 2 (Restricted Soundness) Suppose that using (Congr) at most once, at the very end of the derivation, the sequent [[Y]] ▶ [[t]]—◦[[t']] is derivable. Then t ⇒R t' holds.
Proof. We may assume a derivation of [Y]] ▶ [[t]]—◦[[t' ] without (Congr) is normal, in the usual proof-theoretic sense. Elimination rules may be applied to the axiom [Y]] ▶ [[Y] to obtain a sequent of the appropriate form. No intro- duction rules then apply to give a sequent in the appropriate form. Applying elimination rules corresponds to choosing a rewrite rule and instantiating it. This corresponds to rewriting t to t' at the top level. Applying (Congr) cor- responds to rewriting at a position in a surrounding term.	 
Whether or not soundness holds without the restriction on the use of (Congr), in the next Section we cast off all restrictions on the uses of the rules to obtain a more general notion of rewriting. So of course, we cannot rely on our (restricted) soundness theorem in what follows. But that is indeed what we want. We have motived our semantics by showing that it is complete and sound (in a restricted way) for a well-understood form of rewriting. We then generalize the semantics in order to guide the definition of higher-form rewriting.

Logical Semantics for Higher-Form Rewriting
We can develop the linear logical semantics of the previous Section to support a much more general kind of rewriting than traditional first-order rewriting. We can support higher-form rewriting, where rules can rewrite other rules. This paradigm has the potential to enable rewriting meta-programs like completion or termination analysis to be written in the same language as the rewriting system itself, without reflection (cf. [7]).
To define higher-form rewriting, we first allow arbitrary signatures built from type O using ~. Now that we are leaving the first-order case, we need to use λ-abstractions, as is standard in higher-order logic (although this feature needs to be studied in combination with linearity). We need to make one refinement to the logic of Figure 1 to get a sensible notion of rewriting. We must interpret Γ as a list of formulas, rather than a multiset. This is necessary, for otherwise, if Y is the ground rule p → q → r, then our semantics will say

that q rewrites to p → r using Y. This is because the sequent
p—◦q—◦r ▶ q—◦(p—◦r)
is derivable in linear logic. But its derivation makes essential use of the ability to exchange the order of assumptions in the context. If we disallow this, the system given in Figure 1 becomes a fragment of the ordered linear logic of Polakow [11], if we interpret —◦ as his ordered → connective (and retain the interpretation of & as a linear but not ordered connective). In ordered linear logic, the order in which hypotheses are used matters. In our fragment, hy- potheses must be consumed (using (—◦E)) in the order they were introduced. An example from [11] which helps get a feel for ordered linearity is the fol- lowing. Using the rules of Figure 1 where Γ is interpreted as a list, we cannot derive ▶ p—◦(p—◦q)—◦q. Any normal derivation (and these are sufficient for ordered linear logic [11]) would have to end with the following:


p, (p—◦q) ▶ q


p ▶ (p—◦q)—◦q

▶ p—◦(p—◦q)—◦q(—◦I)
(—◦I)

The obvious step to add above this derivation would be a use of (—◦E). But the only possible one for which we could finish the derivation would be:

p—◦q ▶ p—◦q	p ▶ p
p—◦q, p ▶ q	(—◦E)
And this has the assumptions in the context in its conclusion in the wrong order.
Narrowing Versus Rewriting
Just as in the previous Section, we define t ⇒R t' to hold iff its interpretation [[Y]] ▶ [[t]]—◦[[t' ] is derivable in our logic. We then define the multi-step rewrit-
ing relation ⇒∗ simply as the reflexive transitive closure of ⇒R. We adopt
the notation of our logic as the language of rewriting, enabling us to dispense with the uses of [· ]. One important consequence of this definition must be pointed out. Our definition actually supports narrowing, not just rewriting. For example, suppose our single rule is 6x : O.f (h(x))—◦g(h(x)). Then we can readily show that the term 6x : O.f (x) rewrites to 6x : O.g(h(x)), since 6x : O.f (x) ▶ 6x : O.f (h(x)) is derivable.


In addition to the traditional kind of narrowing, our semantics supports another kind of narrowing, which we might call result narrowing. Sets of terms can be rewritten just by rewriting a proper subset. For example, our definition allows f (a) & f (b) & g(c) to be rewritten to g(a) & g(b) using rewrite rule 6x : O.f (x) —◦ g(x). The fact that one term (here, g(c)) in a set of terms “gets stuck” (i.e., cannot be rewritten) does not cause the whole set of terms to get stuck. Result narrowing supports equational rewriting as it is done in the Rewriting Calculus. There, if an expression can be rewritten to more than one result using a given rule, due to the use of a non-unitary matching algorithm; then the set of all those results is returned. If some of those results cannot be rewritten later in evaluation, then they may just be dropped.
Provable Equivalence and Strongest Results
The rewriting relation we have defined needs some cleaning up. The operator & is associative, commutative, idempotent, and has unit T. So equivalent sets of terms can be presented in many different ways. Furthermore, (6I) can be used to introduce arbitrarily many trivial universal quantifiers, binding vari- ables not free in the result. We refine our notion of rewriting by considering terms modulo provable equivalence. It should be possible to choose an intu- itively sensible canonical representative for each induced equivalence class, but this must be explored in future work. Even with this refinement, we do not have a deterministic rewriting relation. For example, if Y is (a—◦b) &(a—◦c), then a ⇒R b and a ⇒R c. To obtain a deterministic relation, we can addi- tionally stipulate that for t ⇒R t' to hold, t' must be strongest, in the sense that for any other t'' such t ⇒R t'' holds, we have ▶ t'—◦t''.
We spend the rest of this Section exploring our higher-form rewriting rela- tion. For readability, we sometimes write applications like (X Y ) and some- times like X(Y ). We associate —◦ and & to the right, and application to the left.

Example: Code Generation for Exponentiation
Consider the problem of generating, from a number y, the rule exp x → x ∗ ... ∗ x ∗ 1, where the rhs has y occurrences of x. This is a simple meta- programming example taken from [9]. Note that it is quite different from the problem of simply computing x raised to the power y. We can solve this meta-programming problem quite elegantly in our new higher-form version of term rewriting. The signature and rules we need are given in Figure 3.
Proposition 1 Suppose n is built just from 0 and S. Then we have in(n) ⇒∗
out(6x : O.exp x—◦x ∗ ... ∗ x ∗ S(0)), where x ∗ ... ∗ x ∗ S(0) has n occurrences



Signature:

in : O ~ O

∗ : O ~ O ~ O [inﬁx]

out : (O ~ O) ~ O  0: O

build : O ~ O
exp : O ~ O
S : O ~ O



Rules Y :
(in(0) —◦ out(6x : O.exp x—◦S(0))) &
(6n : O.in(S(n)) —◦ build(in(n))) &
(6u : O ~ O.build(out(6x : O.exp x—◦u(x))) —◦
out(6x : O.exp x—◦x ∗ u(x)))
Fig. 3. Code Generation for Exponentiation
of x.
Proof. The proof is by induction on the structure of n. If n is 0, we need, of course, just:


Y ▶ Y(Ax)
Y ▶ in(n)—◦out(6x : O.exp x—◦S	(&E) If n is S(n'), we first have



Y ▶ Y(Ax)


Y ▶ 6n : O.in(S(n)) —◦ build(in(n))

Y ▶ in(S(n'))—◦build(in(n'))	(6E)
(&E) twice

So we have in(S(n')) ⇒R build(in(n')). By our induction hypothesis, we have
derivations for each step in in(n') ⇒∗ out(6x : O.exp x—◦x ∗ ... ∗ x ∗ S(0)),
where there are n' copies of x in the ... expression. We extend each of those

derivations using (Congr) to get derivations for each step of


build(in(n')) ⇒∗
build(out(6x : O.exp x—◦x ∗ ... ∗ x ∗ S(0)))

Finally, we have




Y ▶ Y(Ax)
Y ▶ 6u : O ~ O.build(out(6x : O.exp x—◦u(x)))
—◦ out(6x : O.exp x—◦x ∗ u(x))
Y ▶ build(out(6x : O.exp x—◦x ∗ ... ∗ x ∗ S(0)))
—◦ out(6x : O.exp x—◦x ∗ (x ∗ ... ∗ x ∗ S(0)))



(6E)
(&E) twice

The term with which we have instantiated u in the use of (6E) is λx : O.x ∗
... ∗ x ∗ S(0). We take our formulas to be β-normal forms, and so carry out the β-reduction tacitly in the derivation. By the definition of the reflexive transitive closure of ⇒R, the rewritings we have demonstrated can now be combined to get the desired result.	 

Example: Counting Bound Variables in λ-Calculus
Figure 4 defines an encoding function mapping terms of untyped λ-calculus into our rewriting language. The encoding uses higher-order abstract syntax, a well-known representation technique where bound variables of the object language (here, untyped λ-calculus) are represented as bound variables of the meta-language (here, our rewriting language) [10]. Here, the binding is accomplished using 6. The last clause of the definition is for a single constant symbol c; we need just one for a representative example. Every λ-calculus term gets mapped to a formula (but not vice versa).
Figure 5 gives a signature and (numbered) rules for counting the number of occurrences of bound variables in a λ-calculus term. Standard rewrite rules for addition are not shown, and we abbreviate unary numerals using decimal. Note that this sort of computation cannot usually be implemented in a rewriting or functional programming language without using reflection. An example is given in Figure 6, where a sequence of rewritings to count the number of occurrences of bound variables in the encoding of the term λx.λy.((c x) x) is shown. Each rewriting step is labeled with the number of the rule used. Several steps implicitly use the fact the if x /∈ FV(M ), then 6x : O.M ◦—◦ M .


Signature: lam : O ~ O,  app : O ~ O ~ O

[[λx.M ]] := lam (6x : O.[[M ]])
[[M N ]] := app [[M ]] [[N ]]
[[x]]	:= x, for x a variable [[c]]	:= c
Fig. 4. Encoding of untyped λ-calculus

Signature: num : O ~ O,  +: O ~ O ~ O,  S : O ~ O,  0: O

6u : O ~ O.num(lam (6x : O.u(x))) —◦ 6x : O.num(u(x))
6M : O.6N : O.num(app M N ) —◦ num(M ) + num(N )
6M : O ~ O.6N : O ~ O.(6x : O.M (x) + N (x)) —◦
((6x : O.M (x)) + (6x : O.N (x)))
(6x : O.num(x)) —◦ S(0)
num(c) —◦ 0
Fig. 5. Rules to count bound variable occurrences in λ-calculus terms
Example: Congruence and &
Suppose our rules are Y ≡ (f (a)—◦d) & (f (b)—◦e). Then we have Y ▶ f (a&b) —◦ d&e; one half of the derivation is shown in Figure 7. So f (a&b) ⇒R d&e holds. On the other hand, if we let Y' ≡ (d—◦f (a)) & (e—◦f (b)), then we do not have Y' ▶ d&e —◦ f (a&b). The reason is that while we can derive
▶ p[a&b] —◦ p[a]&p[b] for atomic contexts p using the (Congr) rule, we cannot derive ▶ p[a]&p[b] —◦ p[a&b].

The Rewriting Calculus
We use our logical semantics to define the Rewriting Calculus. We take Rewriting Calculus terms to be terms of the ordered linear logic we have been considering, with an additional construct @ for explicit rule application. The evaluation relation t ⇒ρ t' of the Rewriting Calculus is defined to be


num(lam (6x : O.lam (6y : O.(app (app c x) x))))
⇒1	6x : O.num(lam (6y : O.(app (app c x) x)))
⇒1	6x : O.num(app (app c x) x)
⇒2	6x : O.num(app c x) + num(x)
⇒2	6x : O.(num(c) + num(x)) + num(x)
⇒3	(6x : O.num(c) + num(x)) + (6x : O.num(x))
⇒4	(6x : O.num(c) + num(x)) + 1
⇒3	((6x : O.num(c)) + (6x : O.num(x))) + 1
⇒4	(num(c) + 1) + 1
⇒5	(0 + 1) + 1
⇒arith 2

Fig. 6. Counting uses of bound variables in λx.λy.((c x) x)









f (a)—◦d ▶ f (a)—◦d
a&b ▶ a&b


a&b ▶ a

▶ f (a&b)—◦f (a)(Congr)	f (a&b) ▶ f (a&b)


f (a&b) ▶ f (a)
f (a)—◦d, f (a&b) ▶ d


f (a)—◦d ▶ f (a&b)—◦d



Fig. 7. Example derivation using congruence

the congruence closure of the relation stating how explicit rule applications x@y are evaluated, where x and y are both of type O. Note that x is not of functional type, because we are modeling rewrite rules as formulas. For ground terms x and y, we stipulate that x@y evaluates to z where y ⇒x z. To generalize this to terms with free variables, we require that σ(y) ⇒σ(x) σ(z), for all substitutions σ for those free variables. This should be achievable by requiring ▶ 6∗x—◦y—◦z. Since in the Rewriting Calculus, rules are applied



(OpOnSet) f (v1,... , {u1,... , um},... , vn) =⇒ {f (v1,... , u1,... , vn),... ,
f (v1,... , um,... , vn)}
(Flat)	{v1,... , {u1,... , um},... , vn} =⇒ {v1,... , u1,... , um,... , vn}
where σ1,... , σn are all substitutions satisfying σ(l) ≡ t
Fig. 8. Cirstea-Kirchner definition of the Rewriting Calculus

only at the top level of terms, we must restrict the use of the (Congr) rule of Figure 1 when establishing y ⇒x z. We require that the context Γ be empty for (Congr) to be applied. This rules out rewriting at positions other than the topmost one in terms, but it still allows us to derive ▶ p[a&b]—◦p[a]&p[b].
Our definition of the Rewriting Calculus’s evaluation relation is to be con- trasted with the definition given in [3, Section 2], as the congruence closure of the relation defined by the rules reproduced in Figure 8. Two rules which are redundant in the presence of the others are omitted. The rules are largely concerned with manipulation of sets of results (which are treated up to as- sociativity, commutativity, and idempotence). Of the rules not involving @, we find that (SwitchR), (Flat) and (OpOnSet) are sound with respect to our semantics, in the sense that the interpretation of the lhs indeed logically en- tails the interpretation of the rhs. The lhs and rhs of (SwitchR) and (Flat) are, in fact, logically equivalent, although those of (OpOnSet) are not. Our semantics also agrees with (Fire), (Distrib) and (Batch). But (SwitchL) is not sound with respect to our semantics, since in general u1& ... &un—◦v does not imply (and is not implied by) (u1—◦v) & ... & (un—◦v).
One detail of these observations is worth drawing out in more detail. The rules (except (SwitchL)) are sound with respect to our semantics even when the sets involved are empty. Recall that we interpret ∅ as T. Note, further, that since Γ ▶ T for any context Γ, we always have t ⇒R T, for all t and
Y. Consider now, say, the rule (Batch). When the set involved is empty, the interpretation of this rule is that v @ T rewrites to T. Indeed, T is the strongest formula G such that v ▶ T —◦ G holds. Similarly, for the rule (Dis-


trib), we have T @ v—◦T, and T is again the strongest implied formula. This is a nice further confirmation that the logical semantics is appropriate for the Rewriting Calculus (minus (SwitchL)).
It would be quite interesting to determine whether or not the rules of Fig- ure 8 are complete for our logical semantics (assuming just first-order instead of higher-form rewriting), or perhaps complete under some restrictions.

Conclusion
We have considered a logical semantics for traditional rewriting and also what we call higher-form rewriting, where rules may rewrite rules. The semantics is based on ordered linear logic, with some higher-order extensions. Terms are interpreted as formulas, and rewriting as ordered linear entailment. All but one operational rule of the Rewriting Calculus as given by Cirstea and Kirchner are sound with respect to the proposed semantics.
There is clearly much future work to be done. Although relatively minor, the proposed higher-order extensions to ordered linear logic must be studied. Extending the work to multi-sorted systems would seem to require different “flavors” of the propositional type O corresponding to different sorts, which is not standard. But the main goal is to devise an effective operational semantics which is sound and hopefully complete with respect to the proposed logical semantics. We would then have achieved our goal of a semantically motivated definition of the Rewriting Calculus which supports what promises to be a powerful meta-programming paradigm of higher-form rewriting.
Acknowledgments: Thanks to the anonymous reviewers for helpful com- ments on earlier drafts of this paper, and to Horatiu Cirstea, Germain Faur´e, Claude Kirchner, Luigi Liquori, Benjamin Wack, and other members of the PROTHEO team for many excellent discussions on the Rewriting Calculus.

References
F. Baader and T. Nipkow. Term Rewriting and All That. Cambridge University Press, 1998.
G. Barthe, H. Cirstea, C. Kirchner, and L. Liquori. Pure patterns type systems. In Principles of Programming Languages. ACM, 2003.
H. Cirstea and C. Kirchner. The Rewriting Calculus - Part I. Logic Journal of the Interest Group in Pure and Applied Logics, 9:363–399, May 2001. Also available as Technical Report A01-R-203, LORIA, Nancy (France).
H. Cirstea and C. Kirchner. The Rewriting Calculus - Part II. Logic Journal of the Interest Group in Pure and Applied Logics, 9:401–434, May 2001. Also available as Technical Report A01-R-204, LORIA, Nancy (France).


H. Cirstea, C. Kirchner, and L. Liquori. Matching Power. In A. Middeldorp, editor, Proceedings of the 12th International Conference on Rewriting Techniques and Applications, LNCS, Utrecht (The Netherlands), 2001. Springer-Verlag.
H. Cirstea, C. Kirchner, L. Liquori, and B. Wack. Rewrite strategies in the rewriting calculus. In B. Gramlich and S. Lucas, editors, Proceedings of the Third International Workshop on Reduction Strategies in Rewriting and Programming , Valencia, Spain, June 2003. Electronic Notes in Theoretical Computer Science.
M. Clavel, F. Dur´an, S. Eker, and J. Meseguer. Building equational proving tools by reflection in rewriting logic. In Cafe: An Industrial-Strength Algebraic Formal Method. Elsevier, 2000.
J. Meseguer. Conditional Rewriting Logic as a Unified Model of Concurrency. Theoretical Computer Science, 96(1):73–155, 1992.
A. Nanevski. Meta-programming with names and necessity. In Proceedings of the 7th ACM SIGPLAN International Conference on Functional Programming, pages 206–217, 2002.
F. Pfenning and C. Elliott. Higher-order abstract syntax. In ACM SIGPLAN Symposium on Language Design and Implementation, 1988.
J. Polakow. Ordered Linear Logic and Applications. PhD thesis, Carnegie Mellon University, 2001.
A. Troelstra. Lectures on Linear Logic. Center for the Study of Language and Information, 1992.
