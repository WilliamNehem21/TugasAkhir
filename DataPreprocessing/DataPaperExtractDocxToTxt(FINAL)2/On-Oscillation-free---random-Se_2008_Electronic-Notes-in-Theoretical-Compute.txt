

Electronic Notes in Theoretical Computer Science 221 (2008) 287–297
www.elsevier.com/locate/entcs
On Oscillation-free ε-random Sequences
Ludwig Staiger
Institut fu¨r Informatik
Martin-Luther-Universita¨t Halle-Wittenberg D–06099 Halle, Germany

Abstract
In this paper we discuss three notions of partial randomness or ε-randomness. ε-randomness should display all features of randomness in a scaled down manner. However, as Reimann and Stephan [15] proved, Tadaki
[22] and Calude et al. [3] proposed at least three different concepts of partial randomness.
We show that all of them satisfy the natural requirement that any ε-non-null set contains an ε-random infinite word. This allows us to focus our investigations on the strongest one which is based on a priori complexity.
We investigate this concept of partial randomness and show that it allows—similar to the random infinite words—oscillation-free (w.r.t. to a priori complexity) ε-random infinite words if only ε is a computable number. The proof uses the dilution principle.
Alternatively, for certain sets of infinite words (ω-languages) we show that their most complex infinite words are oscillation-free ε-random. Here the parameter ε is also computable and depends on the set chosen.
Keywords: ω-words, partial randomness, prefix complexity, a priori complexity, oscillation-free infinite words


Introduction
Partial randomness was investigated in the papers by Tadaki [22] and Calude et al. [3]. It is a linear generalisation of Marin-Lo¨f’s concept of random sequences [13]. The concept of partial randomness tries to specify sequences as random to some degree ε, 0 < ε ≤ 1, where the case ε = 1 coincides with Martin-Lo¨f randomness. In [22] and [3] several different generalisations of the concepts for random sequences were given. It turned out that some of them are equivalent, and there remained three approaches which were shown to be inequivalent recently by Reimann and Stephan [15].
To define random sequences (infinite words) Martin-Lo¨f introduced the concept of sequential test and declared an infinite word as random if it withstands all se- quential tests. It became clear soon that random infinite words are those which do

1 Email: staiger@informatik.uni-halle.de

1571-0661 © 2008 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2008.12.024

not allow an unbounded increase of capital in a fair coin-tossing game when using semi-computable gambling strategies (see [16]). Schnorr [16] combined martingales (the capital functions in the game) with order functions to relativise the degree of randomness and in Section 17 of this book he considered martingales combined with exponential order functions, an idea which came up later in [19] and in a somewhat disguised form as s-gales in Lutz’s papers [11,12].
A different characterisation of Martin-Lo¨f random sequences using the concept of Kolmogorov complexity was obtained by Levin, Schnorr and Chaitin. They used variants of Kolmogorov complexity. For a detailed description of the variants of Kolmogorov complexity see [24] and [10, Section 4.5.5]. Notably simple character-
isations were obtained using prefix complexity (KP), monotone complexity (Km) and a priori complexity (KA). 2
A simple idea what could be an example of a binary 1 -random infinite word is the following. Take ξ = x1x2 ··· xi ··· to be a (1-)random infinite word and dilute it by inserting zeros at every other position to obtain ξ' = x10x20 ··· xi0 ·· ·. This idea, of dilution was already used by Daley [5] to ‘construct’ infinite words having a Kolmogorov complexity function of a certain behaviour and appeared later in [18,12,3] to describe infinite words with large complexity oscillations.
As one observes easily the Kolmogorov complexity of the n-length prefix of a diluted word ξ' is about the complexity of the ε· n-length prefix of the original word
ξ where ε is the dilution coefficient (e.g. ε = 1 in the above example). This was
a motivation to consider the relative Kolmogorov complexity of an infinite word as the the limit of the quotient of the complexity of the n-length prefix and the length n (see [1,17,18]). Later it was discovered that the existence of Levin’s universal semi-computable semi-measure [25] proves that this idea of relative Kolmogorov complexity coincides with Lutz’s [12] constructive dimension (see [20] and the re- mark on p. 223 of [19]).
In our discussion on ε-randomness we will not pursue all lines indicated above but focus on Martin-Lo¨f tests and prefix and a priori Kolmogorov complexities. Ob- serve that universal semi-computable semi-measures and universal semi-computable martingales are in one-to-one correspondence and give rise to the definition of a pri- ori complexity (see Section 2.1).
We first show that partial randomness based on on Martin-Lo¨f tests and pre- fix and a priori Kolmogorov complexities all satisfy the natural requirement that non-null sets w.r.t. a related measure always contain partial random infinite words. Having shown that all these concepts are in some sense natural we focus on the strongest one, the one based on strong Martin-Lo¨f tests or as shown in [3], equiva- lently, on a priory complexity.
For a priori complexity (1-)random infinite words show an oscillation-free be- haviour (cf. [23]). This need not be true for ε-random infinite words (cf. [12,3]). We investigate whether one can prove oscillation-freeness for partial random infi- nite words, too. We present proofs that, though non-1-random infinite words may

2 We follow here, except for the monotone complexity, the notation of [24] who use KP, KM, and KA, whereas Li and Vit´anyi [10] use K, Km and KM, respectively.

display large complexity oscillations, ε-random infinite words having oscillation-free behaviour exist for all computable ε > 0.
We give two methods of ‘construction’ (or presentation) of such infinite words. The first is by dilution of 1-random infinite words, and the second by ‘choosing’ most complex infinite words in suitably defined sets of infinite words.

Notation and Preliminaries
In this section we introduce the notation used throughout the paper.  By N =
{0, 1, 2,.. .} we denote the set of natural numbers and by Q the set of rational numbers. Let X be an alphabet of cardinality |X| = r ≥ 2. By X∗ we denote the set of finite words on X, including the empty word e, and Xω is the set of infinite strings (ω-words) over X. Subsets of X∗ will be referred to as languages and subsets of Xω as ω-languages.
For w ∈ X∗ and η ∈ X∗ ∪Xω let w·η be their concatenation. This concatenation product extends in an obvious way to subsets W ⊆ X∗ and B ⊆ X∗ ∪ Xω. For a language W let W∗ := i∈N Wi, and by Wω := {w1 ··· wi ··· : wi ∈ W \ {e}} we denote the set of infinite strings formed by concatenating words in W . Furthermore
|w| is the length of the word w ∈ X∗ and pref (B) is the set of all finite prefixes
of strings in B ⊆ X∗ ∪ Xω. We shall abbreviate w ∈ pref (η) (η ∈ X∗ ∪ Xω) by w ± η, and η[0..n] is the n-length prefix of η provided |η|≥ n. A language W ⊆ X∗ is referred to as preﬁx-free provided w ± v and w, v ∈ W imply w = v.
We denote by B/w := {η : w· η ∈ B} the left derivative of the set B ⊆ X∗ ∪Xω. A language W ⊆ X∗ is regular provided its set of left derivatives {W/w : w ∈ X∗} is finite. In the sequel we assume the reader to be familiar with basic facts of language theory. As usual, the class of recursively enumerable languages is denoted by Σ1, the class containing their complements by Π1. Thus, Σ1 ∩ Π1 is the class of recursive languages.
We consider the set Xω as a metric space (Cantor space) (Xω, Q) of all ω-words over the alphabet X where the metric Q is defined as follows.
Q(ξ, η) := inf{r−|w| : w и ξ ∧ w и η} .
This space is a compact, and C(F ) := {ξ : pref (ξ) ⊆ pref (F )} turns out to be the
closure of the set F (smallest closed subset containing F ) in (Xω, Q).

Randomness and Kolmogorov complexity
A semi-measure on Xω is defined by a function (called semi-measure on X∗)
ν : X∗ → [0, ∞) having the following property:

(1)
ν(e) > 0 and ν(w) ≥ Σx∈X
ν(wx) for all w ∈ X∗ .

This defines via Mν(w · Xω) a pre-measure Mν on the balls w · Xω which can be extended to all Borel subsets of Xω (cf. [6]). The usual Lebesgue measure on Xω is obtained via the (semi-)measure μ(w) := r−|w|.

Recall further that a function f : X∗ → (−∞, ∞) is called left computable if the set of lower bounds {(w, q) : q ∈ Q∧q < f (w)}∈ Σ1. Levin proved in [25] that there is a universal left computable semi-measure M, that is, for every left computable semi-measure ν there is a constant cν such that ∀w(w ∈ X∗ → ν(w) ≤ cν · M(w)).
We briefly recall the concept of Kolmogorov complexity of finite words. For a more comprehensive introduction see the textbooks [2] and [10]. To this end let ϕ : X∗ → X∗ be a partial-recursive function. The complexity of a word w ∈ X∗ with respect to ϕ is defined as
Kϕ(w) := inf{|π| : π ∈ X∗ ∧ ϕ(π) = w}.
It is well known that there is an optimal partial-recursive function U : X∗ → X∗, that is, a function satisfying that for every partial-recursive function ϕ
∃cϕ∀w(w ∈ X∗ → KU(w) ≤ Kϕ(w)+ cϕ)
If one considers only partial-recursive functions ϕ with prefix-free domain dom(ϕ) ⊆
X∗ we obtain in the same way an optimal partial-recursive function C.
Proposition 2.1 There is a partial recursive function C : X∗ → X∗ with preﬁx- free domain dom(C) such that for every partial-recursive functions ϕ with preﬁx-free domain dom(ϕ) there is a constant cϕ such that
∀w(w ∈ X∗ → KC(w) ≤ Kϕ(w)+ cϕ) .
Following [10] the complexity KP := KC will be called preﬁx complexity.
From Levin’s universal left computable semi-measure one derives the a priori
complexity KA(w) := − logr M(w) (cf. [10,23,24,20]). Finally, we recall the concept of Martin-Lo¨f-tests.
Definition 2.2 A recursively enumerable set V ⊆ X∗ × N is referred to as a se- quential Martin-Lo¨f-test provided Vi+1 · Xω ⊆ Vi · Xω, where Vi := {v : (v, i) ∈ V}, and Mμ(Vi · Xω) < 2−i.
An ω-word is called Martin-L¨of-random (ML-random) provided ξ ∈/   Vi · Xω
i∈N
for all sequential Martin-Lo¨f-tests.
Then the following equivalences are known (see e.g. [2,10] and [23]).
Theorem 2.3 Let ξ ∈ Xω. Then the following conditions are equivalent.
ξ is Martin-Lo¨f-random.
KP(ξ[0..n]) ≥ae n − O(1),

lim
n→∞
KP(ξ[0..n]) − n = ∞, and

KA(ξ[0..n]) ≥ae n − O(1).
ε-randomness
In this part we briefly summarise the results of [22] and [3] on ε-randomness and Reimann’s and Stephan’s hierarchy result [15]. First we relativise the concept of Martin-Lo¨f test in two ways.

Definition 2.4 A recursively enumerable set V ⊆ X∗ × N is referred to as an
Martin-L¨of-ε-test provided
Vi+1 · Xω ⊆ Vi · Xω, and
∀i(μ(ε)(Vi) :=	r−ε·|v| < r−i).
v∈Vi
A set V ⊆ X∗ × N is called a strong Martin-Lo¨f-ε-test if it satisfies (i) and (ii’) ∀i ∀C(C ⊆ Vi ∧ C is prefix-free → μ(ε)(C) < r−i).
We call ξ ∈ Xω (strongly ) Martin-L¨of-ε-random if and only if ξ ∈/	Vi · Xω for all
i∈N
(strong) Martin-Lo¨f-ε-tests.
In fact, every Martin-Lo¨f-ε-test is a strong Martin-L¨of-ε-test, the attribute strong refers to the fact (supported by Theorem 2.8 below) that not every ML-ε- random ω-word is also strongly ML-ε-random. The following equivalences between Martin-Lo¨f-ε-tests and Kolmogorov complexity are known.
Lemma 2.5 ([22]) Let 0 < ε ≤ 1 be computable. Then an ω-word ξ ∈ Xω is ML-ε-random if and only if KP(ξ[0..n]) ≥ae ε · n − O(1).
Lemma 2.6 ([3]) Let 0 < ε ≤ 1 be computable. Then an ω-word ξ ∈ Xω is strongly ML-ε-random if and only if KA(ξ[0..n]) ≥ae ε · n − O(1).
Another possibility is to generalise condition 3 of Theorem 2.3.
Definition 2.7 ([22]) An ω-word ξ ∈ Xω is strongly Chaitin-ε-random provided

lim
n→∞
KP(ξ[0..n]) − ε · n = ∞.

The hierarchy of these notions was finally established in the paper by Reimann and Stephan..
Theorem 2.8 ([15]) Let 0 < ε < 1 be a rational number. Then every ML-ε- random ω-word is strongly Chaitin-ε-random, and every strongly Chaitin-ε-random ω-word is strongly ML-ε-random, and none of these implications can be reversed.
Here the question arises which one of the concepts of ε-randomness is a natural generalisation of (1-)randomness. For 1-randomness it is known that every Lebesgue non-null set F ⊆ Xω contains a random ω-word. A similar condition for ε < 1 can be formulated using Hausdorff dimension and measure.
We recall the definition of the Hausdorff measure and Hausdorff dimension of a subset of (Xω, Q) (see e.g. [6,7]). In the setting of languages this can be read as follows (see e.g. [18]). For F ⊆ Xω and 0 ≤ γ ≤ 1 the equation

​
Lγ(F ) := lim
l→∞
inf  Σ r−γ·|w| : F ⊆ W · Xω ∧ ∀w(w ∈ W → |w|≥ l),
w∈W

defines the γ-dimensional metric outer measure on Xω. The measure Lγ satisfies the following.
Corollary 2.9 If Lγ(F ) < ∞ then Lγ+δ(F ) = 0 for all δ > 0.

Then the Hausdorff dimension of F is defined as
dim F := sup{γ : γ = 0 ∨ Lγ(F ) = ∞} = inf{γ : Lγ(F ) = 0} .
Theorem 2.10 ([14]) Let F ⊆ Xω and Lε(F ) > 0. Then for every constant
c > − log|X| Lε(F ) there is a ξ ∈ F such that KA(ξ[0..n]) ≥ ε · n − c.
This theorem proves that, for computable ε, every Lε-non-null set contains a strongly ML-ε-random ω-word.
A similar theorem proving that, for computable ε, every Lε-non-null set contains a strongly Chaitin-ε-random ω-word can be found in [3, Corollary 5.6].

Oscillation-free ε-random ω-words
Random ω-words ξ satisfy, except for the lower bounds mentioned in Theorem 2.3 also the upper bounds KP(ξ[0..n]) ≤ n + KP(ι(n)) + O(1), where ι(n) is the nth word in a recursive enumeration of X∗, and KA(ξ[0..n]) ≤ n + O(1) (see [2,10,23]). For ω-words of lower complexity low upper bounds on the complexity need not be true. As it was mentioned in the introduction, there are ω-words having large complexity oscillations.
Tadaki showed that there are strongly Chaitin-ε-random ω-words ξ having

κ(ξ) := lim sup
n→∞
KP(ξ[0..n])
n
≤ ε.  In this section we want to show that it is

possible, for computable reals 0 < ε < 1, to ‘construct’ ε-random ω-words satis- fying KA(ξ[0..n]) ≤ ε · n + O(1), that is, ε-random ω-words having no oscillation
w.r.t. the a priori complexity KA.
We derive two methods. The first one is a generalisation of the dilution principle and uses prefix-monotone recursive mappings ϕ : X∗ → X∗. The second one selects maximal complex ω-words in suitably chosen constructively given subsets of Xω.

A generalised dilution principle
In this section we consider preﬁx-monotone mappings, that is, mappings ϕ : X∗ → X∗ satisfying ϕ(w) ± ϕ(v) whenever w ± v. We call a function g : N → N a modulus function for ϕ provided |ϕ(w)| = g(|w|) for all w ∈ X∗. This, in particular, implies that |ϕ(w)| = |ϕ(v)| for |w| = |v| when ϕ has a modulus function.
Every prefix-monotone mapping ϕ : X∗ → X∗ defines as a limit a partial map- ping ϕ :⊆ Xω → Xω in the following way: pref (ϕ(ξ)) = pref (ϕ(pref (ξ))) when- ever ϕ(pref (ξ)) is an infinite set, and ϕ(ξ) is undefined when ϕ(pref (ξ)) is finite.
We obtain our first result.
Theorem 3.1 Let ϕ : X∗ → X∗ be a one-to-one preﬁx-monotone recursive function with strictly increasing modulus function g : N → N. Then ϕ : Xω → Xω is also one-to-one and
|KA(ϕ(ξ)[0..g(n)]) − KA(ξ[0..n])|≤ O(1) for all ξ ∈ Xω and all n ∈ N .
Proof. The mapping ϕ is one-to-one because w ∈ X∗, x, y ∈ X and x /= y imply that ϕ(wx) and ϕ(wy) are incomparable w.r.t. ±.

In order to prove KA(ϕ(ξ)[0..g(n)]) ≥ KA(ξ[0..n]) − c we consider the semi- measure ν : X∗ → [0, ∞) defined by ν(w) := M(ϕ(w)). It is immediate that ν is left computable. Since M(ϕ(w)) ≥ v∈Xg'(w) M(ϕ(w) · v) ≥ x∈X M(ϕ(wx)) where g'(w) := g(|w|) − g(|w|− 1) the function ν is indeed a semi-measure 3 . Thus M(ϕ(w)) = ν(w) ≤ c · M(w) yields the assertion.
To prove the converse, we define
ν'(e) := M(e)	and
ν'(v) := Σϕ(w)±v,|v|>g(|w|−1) M(w)  for v /= e. 
In particular, ν'(ϕ(w)) = M(w). The sum is finite, thus ν' is left computable. Moreover we have
Σ ν'(vy)= Σ	Σ	M(w)

y∈X
y∈X
ϕ(w)±vy
|vy|>g(|w|−1)

,,,,⎨
ϕ(Σw)±v
|v|>g(|w|−1)
M(w)	, if |v| > g(|w|− 1) and

'

, Σ Σ
where ϕ(w ) = v, 
M(w'x) , 

,, y∈X x∈X ϕ(w'x)±vy
if |v| = g(|w|− 1) .

The sum in the former case is ν'(v). In the latter case, ϕ(w'x) ± ϕ(w')y implies
ϕ(w'x) /± ϕ(w')y' whenever y, y' ∈ X, y' /= y. Consequently, y is uniquely de-
termined by x and the sum simplifies to Σ	Σ	M(w'x) ≤ Σ M(w'x) ≤

M(w') = ν'(v).
x∈X ϕ(w'x)±vy
x∈X

Now, M(w) = ν'(ϕ(w)) ≤ c' · M(ϕ(w)) yields KA(ϕ(ξ)[0..g(n)]) ≤ KA(ξ[0..n]) −
logr c'.	 
We need still the following technical result on computable reals ε, 0 < ε < 1.
Lemma 3.2 Let ε, 0 < ε < 1, be computable. Then there are c1, c2 > 0 and an increasing recursive function g : N → N such that 0 < g(n + 1) − g(n) ≤ c1 and
|n − ε · g(n)|≤ c2, for all n ∈ N.
For the sake of completeness we give a proof.
Proof. The function g : N → N can be defined as follows.
g(0) := 0 and
g(n + 1) := g(n) + min{k : k ∈ N ∧ k ≥ 1 ∧  n+1  < ε}
Thus 0 ≤ ε · g(n) − n ≤ ε and 0 < g(n + 1) − g(n) ≤ 1+ 1 , for all n ∈ N. Moreover,
g is a computable function provided ε, 0 < ε < 1, is a computable real number. 
For the particular g constructed in the proof of Lemma 3.2 we have g(n) ≤
l < g(n + 1) if and only if [ε · l♩ = n. This yields the following consequence of

3 We set g(−1) := 0.

Theorem 3.1.
Theorem 3.3 Let ε, 0 < ε < 1 be a computable number. Then there is a a one- to-one preﬁx-monotone recursive function ϕ : X∗ → X∗ with strictly increasing modulus function g : N → N such that
|KA(ϕ(ξ)[0..l]) − KA(ξ[0..[ε · l♩])|≤ O(1)
for all l ∈ N and all ξ ∈ Xω satisfying KA(ξ[0..n + 1]) ≤ KA(ξ[0..n]) + O(1).
In particular, if we choose ξ ∈ Xω to be random then ϕ(ξ) is non-oscillating strongly ML-ε-random.
We conclude this section by an example which shows that not requiring these strong assumptions on the mappings ϕ in Theorem 3.1 and on the modulus in Lemma 3.2 may lead to large complexity oscillations in ϕ(Xω).
Example 3.4 Let mi := Σ2i  j! a sequence of rapidly growing natural numbers
and define the prefix-monotone mapping ϕ : {0, 1}∗ → {0, 1}∗ as follows.
ϕ(e) := e
ϕ(wa) := ,⎨ ϕ(w)a	, if |ϕ(w)a| ∈/ {mi : i ∈ N} and ,
, ϕ(w)a0(2i+1)! , if |ϕ(w)a| = mi.
that is, ϕ dilutes the input by rarely inserting very long blocks of zeros.  Then

ϕ({0, 1}ω) =  ∞
{0, 1}(2i)! · 0(2i+1)!.

Now, one easily observes that the ω-word x ‘constructed’ in [3, Example 5.2] belongs to ϕ({0, 1}ω). For every δ > 0 this ω-word has infinitely many prefixes w и x with KP(w) ≤ δ · |w| and infinitely many prefixes v и x with KP(v) ≥ (1 −δ) · |v|.

Maximally complex ω-words
In [18] it was shown that for regular ω-languages F ⊆ Xω and (simple) Kolmogorov complexity most complex ω-words in F show the same (scaled down by a factor dim F ) behaviour of their complexity function K(ξ[0..n]) as (1-)random ω-words. In this section we transfer this result to the a priori complexity KA.
As usual, we call an ω-language F ⊆ Xω regular provided there are an n ∈ N and
regular languages Wi, Vi, i = 1,..., n, such that F =  n	Wi · V ω. As mentioned
in [18, Theorem 1.8] the languages Vi can be chosen to be prefix-free.
The lower bound can be derived via Theorem 2.10 from [18, Theorem 4.7].
Lemma 3.5 ([18]) If F	⊆	Xω  is a non-empty regular ω-language then
Ldim F (F ) > 0.
Corollary 3.6 Let F ⊆ Xω be regular and dim F > 0. Then F contains a strongly ML-dim F-random ω-word.
For the proof of the upper bound we need some more known facts on regular
ω-languages and their Hausdorff dimension.

Lemma 3.7 If V ⊆ X∗ is a non-empty preﬁx-free regular language then there is a unique value 1 ≥ γ ≥ 0 such that v∈V r−γ·|v| = 1 and this value satisﬁes γ = dim V ω.
The following identity is useful to estimate the Hausdorff dimension of a regular
ω-language.

(5)
dim n
Wi · V ω = max{dim V ω : i = 1,..., n}

Before proceeding to our upper bound we mention still that also the a priori com- plexity of an ω-word does not increase much by pre-multiplication with a finite word.
∀w∃cw(KA((w · ξ)[0..n]) ≤ KA(ξ[0..n]) + cw)
Now we can prove our results. Similar results hold for simple Kolmogorov complex- ity (see [18, Theorem 4.8]).
Theorem 3.8 Let F ⊆ Xω be a regular ω-language and let dim F > 0. Then for every ξ ∈ F there is a cξ such that KA(ξ[0..n]) ≤ dim F · n + cξ.
In view of Lemma 3.7 and Eqs. (5) and (6) the proof of our theorem follows from the subsequent lemma which shows that for regular ω-languages of a special shape we can do better.
Lemma 3.9 Let V ⊆ X∗ be a preﬁx-free regular language having at least two ele- ments. Then for the unique value γ > 0 such that v∈V r−γ·|v| = 1 there is a c > 0 such that KA(ξ[0..n]) ≤ γ · n + c for every ξ in the closure of V ω, C(V ω), that is, for all ξ with pref (ξ) ⊆ pref (V ω).
Proof. Let γ > 0 be the unique solution of	v∈V r−γ·|v| = 1. We define a com- putable measure ν on X∗ as follows.
ν(w) := r−γ·|w| if w ∈ V ∗,
ν(w) := Σwv∈V r−γ·|w·v| if w ∈ pref (V ),
ν(w) := 0 if w ∈/ pref (V ∗) = V ∗ · pref (V ), and
ν(w) := ν(u) · ν(v) if w = u · v with u ∈ V ∗ and v ∈ pref (V ) \ V .
Observe that, for w ∈ V ∗ ∩ pref (V ) = V ∪ {e}, (i) and (ii) coincide and that the decomposition in (iv) is unique because V is prefix-free.
In view of (ii) the identity	ν(wx) = ν(w) is obvious for w ∈ pref (V ) \ V . Then the general identity  x∈X ν(wx) = ν(w) follows from the inductive definition of ν.
Now, consider ν(w) :=   wv∈V r−γ·|w·v| = r−γ·|w| ·  v∈V/w r−γ·|v| for w ∈
pref (V ) \ V . Since V is regular, the set {V/v : v ∈ X∗} is finite. Thus, the minimum c' := min{Σv∈V/w r−γ·|v| : w ∈ pref (V ) \ V } exists and is positive. Then
in view of (iv), we obtain ν(w) ≥ c' · r−γ·|w| for w ∈ pref (V ∗).
On the other hand c · M(w) ≥ ν(w) for a suitable c > 0 and all w ∈ X∗. This

yields KA(w) ≤ γ · |w|− logr  c
for all w ∈ pref (V ∗) = pref (V ω).	 

It would be desirable to extend this construction to a broader class of ω- languages, but already for very simple classes of non-regular ω-languages a gen- eral construction fails. Here the corresponding examples can be taken from [18,21]
and the estimates for the asymptotic complexities κ(ξ) := lim sup KP(ξ[0..n]) and
n→∞	n
κ(ξ) := lim inf KP(ξ[0..n]) in [18, Section 6] yield ω-words with large complexity os-
n→∞	n

cillations, that is, having κ(ξ) − κ(ξ) > 0:
Example 3.10 Let X := {0, 1, 2, 3} and set W :=	∞
n=1

{0, 1}n · 23n.  For this

prefix-free linear language of simple structure we have dim Wω = 1 ([21]) and thus κ(ξ) ≤ 1 for all ξ ∈ Wω. On the other hand, Corollary 6.11 and Eq. (6.13) of [18] show that there are ξ ∈ Wω with κ(ξ) ≥ 1 .

Acknowledgement
I would like to thank one of the referees for not believing that any notion of ε-randomness can display all the features of 1-randomness which made me change the original title “What is true ε-randomness?”.

References
A. A. Brudno, Topological entropy, and complexity in the sense of A. N. Kolmogorov. (Russian) Uspehi Mat. Nauk 29 (1974), 157–158.
Cristian S. Calude, “Information and Randomness: An Algorithmic Perspective”, Second Edition, Revised and Extended, Springer-Verlag, Berlin, 2002.
C. S. Calude, L. Staiger, and S. A. Terwijn. On partial randomness, Annals of Applied and Pure Logic,
138 (2006), 20 – 30.
G. J. Chaitin, A theory of program size formally identical to information theory, J. Assoc. Comput. Mach., 22 (1975), 329–340.
R.P. Daley, The extent and density of sequences within the minimal-program complexity hierarchies, J. Comput. System Sci. 9 (1974), 151–163.
G. A. Edgar, “Measure, Topology, and Fractal Geometry”. Springer, 1990.
K. Falconer, “Fractal Geometry. Mathematical Foundations & Applications”, Wiley & Sons, New York, 1990.
F. Hausdorff. Dimension und ¨außeres Maß, Mathematische Annalen 79 (1919) 157-179.
L. A. Levin, On the notion of a random sequence, Soviet Math. Dokl., 14 (1973), 1413–1416. (Translated from the Russian version.)
Ming Li and P. M.B˙ . Vit´anyi. “An Introduction to Kolmogorov Complexity and Its Applications”. Second Edition, Springer, 1997.
J.H. Lutz, Gales and the constructive dimension of individual sequences, In Proc. 27th International Colloquium on Automata, Languages, and Programming, Springer-Verlag, Heidelberg, 2000, 902–913.
J.H. Lutz, The dimensions of individual strings and sequences, Inform. and Comput. 187 (2003), 49-79.
P. Martin-L¨of, The definition of random sequences. Information and Control 9 (1966), 602–619.
J. Mielke, Refined Bounds on Kolmogorov Complexity for ω-languages, this volume.


J. Reimann, and F. Stephan, On hierarchies of randomness tests, in: Mathematical Logic in Asia, Proceedings of the 9th Asian Logic Conference, Novosibirsk, World Scientific, Singapore 2006.
C.-P. Schnorr, “Zuf¨alligkeit und Wahrscheinlichkeit”, Lect. Notes in Math. 218, Springer-Verlag, Heidelberg, 1971.
L. Staiger, Complexity and entropy, In “Mathematical Foundations of Computer Science”, Proc. 10th Intern. Symposium, (J. Gruska and M. Chytil, eds.), Lecture Notes in Comput. Sci. No. 118, Springer- Verlag, Berlin 1981, 508–514.
L. Staiger, Kolmogorov complexity and Hausdorff dimension, Inform. and Comput. 103 (1993), 159– 194.
L. Staiger, A tight upper bound on Kolmogorov complexity and uniformly optimal prediction, Theory Comput. Systems 31 (1998), 215–229.
L. Staiger, Constructive dimension equals Kolmogorov complexity. Inform. Process. Lett. 93 (2005), 149–153
L. Staiger, Infinite iterated function systems in Cantor space and the Hausdorff measure of ω- power languages, Intern. J. Found. Comput. Sci. 16 (2005), 787–802.
K. Tadaki, A generalization of Chaitin’s halting probability Ω and halting self-similar sets, Hokkaido Math. J. 31 (2002), 219–253.
V. A. Uspensky, A. L. Semenov, and A. Kh. Shen, Can an individual sequence of zeros and ones be random?, Russian Math. Surveys, 45:1 (1990), 121–189. (Translated from the Russian version.)
V. A. Uspensky, and A. Kh. Shen, Relations between varieties of Kolmogorov complexities, Math. Systems Theory 29 (1996), 271-292.
A. K. Zvonkin, and L. A. Levin. Complexity of finite objects and the development of the concepts of information and randomness by means of the theory of algorithms, Russian Math. Surveys 25 (1970), 83–124.
