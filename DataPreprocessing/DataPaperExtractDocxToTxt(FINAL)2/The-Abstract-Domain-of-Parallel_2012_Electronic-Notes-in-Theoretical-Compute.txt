Available online at www.sciencedirect.com


Electronic Notes in Theoretical Computer Science 287 (2012) 17–28
www.elsevier.com/locate/entcs
The Abstract Domain of Parallelotopes
Gianluca Amato Francesca Scozzari
Universit`a “G. d’Annunzio” di Chieti-Pescara – Italy

Abstract
We propose a numerical abstract domain based on parallelotopes. A parallelotope is a polyhedron whose constraint matrix is squared and invertible. The domain of parallelotopes is a fully relational abstraction of the Cousot and Halbwachs’ polyhedra abstract domain, and does not use templates. We equip the domain of parallelotopes with all the necessary operations for the analysis of imperative programs, and show optimality results for the abstract operators.
Keywords: Abstract interpretation, numerical domains, polyhedra, parallelotopes.

Introduction
In recent years, we have seen many different proposals of numerical domains derived from Cousot and Halbwachs’ [7] polyhedra abstract domain. Weakly relational do- mains, such as octagons [10] and logahedra [8], have proved to be quite efficient, but the assertions that can be discovered using these domains are limited by many syntactic restrictions. In order to handle more expressive constraints, Sankara- narayanan et al. have proposed a different approach called template polyhedra [12], which is a generalization of most weakly relational domains. For each program, the authors fix a priori a constraint matrix A and consider all the polyhedra of the type Ax ≤ b. The choice of the matrix is what differentiates template polyhedra from other domains, where the matrix is fixed for all the programs (such as intervals or octagons) or varies freely (such as polyhedra). Abstract operators on template polyhedra have been defined by means of linear programming and can be computed in polynomial time.
Along the same direction there are the proposals of generalized template poly- hedra [5], which combine template polyhedra and bilinear forms, and template parallelotopes [1,3], which are a special case of template polyhedra. A parallelo- tope is a polyhedron defined by at most n linearly independent constraints, where

1 Email: amato@sci.unich.it, scozzari@sci.unich.it


1571-0661 © 2012 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2012.09.003

n is the number of variables. This amounts to say that the constraint matrix of a parallelotope is squared and invertible. In the special case of template parallelo- topes, it is possible to derive efficient abstract operators, without resorting to linear programming tools. While template polyhedra seem to be a valid alternative to polyhedra from the point of view of efficiency, and to weakly relational domains from the point of view of expressivity, a general method to find ”good” templates still does not exist. We are aware of only two proposals for generating templates, one in Sankaranarayanan et al. original paper [12] based on a syntactic inspection of the program, and another one based on the statistical analysis of partial execution traces [1,3].
In this paper we try a different approach to balance expressivity and efficiency. Instead of restricting the syntactic form of constraints, we limit the number of constraints to n linearly independent ones. It turns out that our abstract objects are parallelotopes, as in [1,3], but with the fundamental difference that the constraint matrix is not fixed a priori but may change freely, as for the polyhedra domain. We provide the basic abstract operators, and show that the domain of parallelotopes can be equipped with very efficient abstract operations, whose complexity is comparable to that of octagons.
When defining the abstract operators, the main problem we need to face is that many concrete operations are not closed with respect to parallelotopes. Moreover, in many cases there is no unique best parallelotope which approximates the result of the concrete operation. Therefore, we need to carefully choose, even resorting to ap- propriate heuristics, an approximating parallelotope which brings a good precision in the overall analysis.


Notation
Linear Algebra
We denote by R¯ the set of real numbers extended with +∞ and −∞. Addition and multiplication are extended to R¯ in the obvious way, with the exception that 0 times
±∞ is 0. We use boldface for elements v of R¯ n. Any vector v ∈ R¯ n is intended
as a column vector, and vT is the corresponding row vector. Given u, v ∈ R¯ n, and
a relation da ∈ {<, >, ≤, ≥, =}, we write u da v if and only if ui da vi for each i ∈ {1,..., n}. Given u ∈ Rn and i ∈ {1,..., n}, we write u[i '→ x] to denote a vector v such that vi = x and vj = uj for j /= i.
If A = (aij) is a matrix, we denote by AT its transpose. If A is invertible, A−1 denotes its inverse, and GL(n) is the group of n × n invertible matrices. The identity matrix in GL(n) is denoted by In and the standard basis of Rn is denoted by {e1,..., en}. Clearly, any 1 × n-matrix can be viewed as a vector: in particular, we denote by ai∗ the row vector given by the i-th row of any matrix A, and by a∗i the column vector given by the i-th column of A.

Abstract interpretation
In this paper we adopt a framework for abstract interpretation which is weaker than the common one based on Galois connections (see [6, Section 7]). Given two pre- ordered sets (C, ≤C)— the concrete domain — and (A, ≤A)— the abstract domain
— we establish an abstraction–concretization relationship between them with the use of a concretization map, which is a monotone function γ : C → A. We say that a ∈ A is a correct approximation of c ∈ C when c ≤C γ(a). Given c ∈ C, there are many possible abstractions. The most interesting ones are those which are minimal
w.r.t. the ordering ≤A.
A function fα : A → A is a correct abstraction of f : C → C when it preserves correctness of approximation, i.e. when c ≤ γ(a) implies f (c) ≤C γ(fα(a)). It is γ-complete when γ ◦ fα = f ◦ γ. It is minimal when, for any a ∈ A, there exists no b ∈ A such that f (γ(a)) ≤A b <A fα(a), i.e. when fα(a) is a minimal correct approximation of f (γ(a)).

Parallelotopes
A set P ⊆ Rn is a parallelotope 2 when there is a matrix A ∈ GL(n) and vectors
l, u ∈ R¯ n such that
P = {x ∈ Rn | l ≤ Ax ≤ u} .	(1)
A parallelotope is a closed convex set.
Definition 3.1 (Representation of parallelotopes) A	representation	of parallelotopes is a tuple P = ⟨A, l, u⟩ such that A ∈ GL(n), l, u ∈ R¯ n and l ≤ u. We denote by ParTopen the set of all the representations of parallelotopes in Rn.
The matrix A is called the constraint matrix, while l and u are the lower and up- per bounds respectively. We denote by γ(P ) the corresponding parallelotope which, according to Eq. 1, is γ(P )= {x ∈ Rn | l ≤ Ax ≤ u}. We say that a parallelotope P is definable over A ∈ GL(n) if there is a representation for P whose constraint matrix is A.
For every non-empty parallelotope P there is a representation P such that γ(P )= 
P. We have ruled out the case l /≤ u because this would considerably complicate the formalism. When we need a representation for the empty parallelotope, we will use the symbol ϵ, with the proviso that γ(ϵ) = ∅. However, in most cases we will only consider non-empty parallelotopes.
It is worth noting that there are many different representations which correspond to the same parallelotope. In the following, when this does not cause ambiguities, we will use a representation P in place of the parallelotope γ(P ), and we will refer to representations of parallelotopes simply as parallelotopes.

2 In the mathematical literature, a parallelotope is generally considered to be bound, while we are also considering unbounded ones.

Minimization and maximization over a parallelotope
Given a box 3 B = ⟨In, l, u⟩ and a vector c ∈ Rn, we have that


inf cT x =  inf

cT x = cT v	where	vi
= (li	if ci ≥ 0

(2)

x∈5
l≤x≤u
ui	otherwise.

The computational complexity of this operation is O(n). The minimization operator for parallelotopes may be obtained by viewing a parallelotope as a box over a non- canonical coordinate system.
Proposition 3.2 Given a parallelotope P = ⟨A, l, u⟩ and a vector c ∈ Rn, we have that
inf cT x = inf cT A—1y.	(3)
x∈P	l≤y≤u
The computational complexity is O(n3).
Symmetric properties hold for the maximization operators.
Approximation by parallelotopes
Given a set C ∈ Rn, we are interested in approximating C with a parallelotope P ⊇ C. In general, there is not a least parallelotope P which contains C, but there are several (possibly infinite) minimal parallelotopes with such a property. Among them, the choice may be done according to some heuristic.
Things change if we fix the matrix A and consider only the parallelotopes de- finable over A, as in [3]. In this case the least parallelotope exists. As a particular case, given a parallelotope P in Rn and a matrix A ∈ GL(n), it is interesting to seek the least parallelotope containing P and definable over A.
Definition 3.3 (Approximation operator) The approximation operator on parallelotopes αA : ParTopen → ParTopen is deﬁned as
αA(P ) d=ef ⟨A, l, u⟩	where	li = inf ai∗x ,	ui = sup ai∗x .	(4)

x∈P
x∈P

Theorem 3.4 Given a parallelotope P and A ∈ GL(n), αA(P ) is the least paral- lelotope deﬁnable over A which contains P. The computational complexity is O(n3).
Ordering of parallelotopes
It is possible to define a pre-order over representations of parallelotopes in such a way that P ≤ P j iff γ(P ) ⊆ γ(Pj). The idea is that if γ(P ) ⊆ γ⟨Aj, lj, uj⟩, then γ⟨Aj, lj, uj⟩ should contain the least parallelotope definable over Aj which contains γ(P ).

3 We represent a box as a parallelotope with the identity constraint matrix.

Definition 3.5 Given parallelotopes P = ⟨A, l, u⟩ and Pj = ⟨Aj, lj, uj⟩, we deﬁne
P ≤ Pj iff lj ≤ ljj and ujj ≤ uj, where ⟨Aj, ljj, ujj⟩ = αA’(P ).
Theorem 3.6 Given parallelotopes P and Pj, we have that P ≤ P j iff γ(P ) ⊆
γ(Pj). Moverover, ≤ is a pre-order. The computational complexity is O(n3).
This theorem allows us to state the precise abstract framework we use in this paper. The concrete domain is the powerset of Rn, ordered by set inclusion. The abstract domain is the set ParTopen ∪ {ϵ}, where the ordering over parallelotopes is extended to ϵ in such a way that ϵ ≤ P for each P ∈ ParTopen. Finally, we take γ as concretization map.

Abstract operators on parallelotopes
We now consider the operations on ℘(Rn) commonly used when defining the col- lecting semantics of imperative programming languages, and for each of them we introduce a correct approximation on parallelotopes. Computing operations on par- allelotopes essentially amounts to:
choosing a resulting constraint matrix A;
computing bounds l and u to get a correct approximation of the result.
Once A is fixed, computing the best bounds is quite easy. However, there are generally several possible alternatives for A, which lead to results which are set- theoretically incomparable. From a theoretical perspective, in evaluating the pre- cision of an abstract operator, we will look for the following properties, in order of preference:
γ-completeness, if possible, i.e. when the result of the concrete operator is a parallelotope;
minimality, i.e. we compute one of the minimal parallelotopes which approxi- mate the concrete result;
relative optimality, i.e. we fix a matrix A and compute the least parallelotope definable over A which approximates the concrete result.
It is easy to check that γ-completeness implies minimality which, in turn, implies relative optimality. The choice between competing minimal parallelotopes may only be done under the basis of heuristic considerations, and validation requires extensive tests.

Invertible linear assignment
Linear assignment is used to analyze the behavior of the statement xi = c1x1 + ... + cnxn + b. The concrete linear assignment operation assign(i, c, b): ℘(Rn) → ℘(Rn) is defined as
assign(i, c, b)(X)= {x[i '→ cT x + b] | x ∈ X}.

If ci /= 0, then assign(i, c, b) is invertible and, most importantly, maps a parallelotope to a parallelotope. In this special case, it is possible to implement the abstract operator along the line of [7]. Intuitively, the operation assign(i, c, b) corresponds to the assignment xj = cT x + b, where xj is the value of xi after the assignment. From
i	i
this equation, it is possible to recover xi as a function of xj and the other elements

of x, namely xi = (xj − Σ

j/=i
cjxj − b)/ci. Replacing the variable xi with the above

definition we get the solution.
Definition 4.1 Given c ∈ Rn such that ci /= 0 and b ∈ R, we deﬁne the abstract linear assignment assignα(i, c, b) as


assignα(i, c, b)⟨A, l, u⟩ = ⟨A − 1 a
ci  ∗i
(c − ei)T , l + b a
ci  ∗i
b
, u + a∗i⟩ . ci

Theorem 4.2 The operation assignα(i, c, b) is correct and γ-complete. The com- putational complexity is O(n2).
The case when ci = 0 will be treated after the non-deterministic assignment.
Non-deterministic assignment
Consider the non-deterministic assignment operation forget(i) : ℘(Rn) → ℘(Rn) defined as
forget(i)(C)= {x + αei | x ∈ C,α ∈ R} .
First note that, even if P is a parallelotope, forget(i)(P) may fail to be a parallelo- tope.
A naive definition of forgetα(i)(⟨A, l, u⟩) would replace the bounds of the lines j such that aji /= 0 with −∞ and +∞. However, this generally yields a gross approximation.
Example 4.3 Consider the parallelotope given by the inequalities 0 ≤ x1 + x2 ≤ 0 and 0 ≤ x1 − x2 ≤ 0, which consists of a single point {(0, 0)}. After a non- deterministic assignment to x2, if we apply the naive procedure described above, we get −∞ ≤ x1 + x2 ≤ +∞ and −∞ ≤ x1 − x2 ≤ +∞ which is the entire space. However, by adding the two inequalities, we get the new constraint 0 ≤ 2x1 ≤ 0, which does not contain x2 and thus is preserved by non-deterministic assignments.
Therefore, we need to make explicit the constraints hidden in P which do not contain the variable xi we want to forget. The problem is that, in general, there are more entailed constraints than we can represent with a parallelotope. We need a way to choose between competing constraints.
Example 4.4 Consider the parallelotope given by the inequalities −1 ≤ x1 + x2 + x3 ≤ 1, −1 ≤ x1 + x2 − x3 ≤ 1 and −1 ≤ x1 − x2 + x3 ≤ 1. By considering all the pairs of inequalities and simplifying, we get the implicit constraints −1 ≤ x2 ≤ 1,
−1 ≤ x3 ≤ 1 and −1 ≤ x2 − x3 ≤ 1. The problem is that the linear forms x2, x3 and x2 − x3 are not linearly independent, hence we cannot keep all of them in

the result. Note that although x2 − x3 is a linear combination of x2 and x3, the constraint −1 ≤ x2 −x3 ≤ 1 is not implied by the other two: we lose precision when we omit one of them.
In order to overcome the above problems, we propose the following operator. First note that we may ignore the rows in P which are unbounded (i.e. with infinite lower and upper bounds) or whose i-th entry is zero: the first remain unbounded, while the second are not affected by the assignment. Thus, in the following, we will focus on the remaining rows only, whose indexes are in J = {j | aji /= 0, lj /=
−∞ ∨ uj /= ∞}. The idea is to transform the rows in J in such a way that they remain independent and there is exactly one row whose i-th entry is not zero. Thus, we choose a row r ∈ J and consider the linear combinations R = {ajiar∗ − ariaj∗ | j ∈ J \ {r}} ∪ {ar∗}. Since the rows in J are linearly independent, it follows that their linear combinations are still linearly independent, and thus R is a set of |J| linearly independent rows. Moreover, all the rows in R are independent from the rows of A not in J. Combining them together, we get the resulting matrix Aj. The last step is to ensure that P j ≥ P , by computing the new bounds (with the exception of ar∗ which must become an unbounded row).
The main question is how to choose the index r in J. Our intuition is that it is better to choose an index r such that both lr and ur are finite, possibly equal, since we will get better bounds in P j. In fact, when we choose a row r whose lower and upper bounds coincide, then the forgetα(i) abstract operator is γ-complete. The detailed procedure is shown in Algorithm 1.

Algorithm 1 The forgetα(i) abstract operator
Require: ⟨A, l, u⟩ ∈ ParTopen, i ∈ {1,..., n}
1: J = {j | aji /= 0, lj /= —∞ ∨ uj /= ∞}
2: if J = ∅ then
3:	return ⟨A, l, u⟩
4: end if
5: ⟨A′, l′, u′⟩ → ⟨A, l, u⟩
6: J0 → {j ∈ J | lj = uj ∈ R}
7: J1 → {j ∈ J | lj , uj ∈ R}
8: if J0 /= ∅ then
9:	r → an element in J0
10: else if J1 /= ∅ then
11:	r → an element in J1
12: else
13:	r → an element in J
14: end if
15: for all j ∈ J \ {r} do

16:	a′
→ ajiar∗ — ariaj∗

17:	(mr, Mr) → if aji < 0 then (ur, lr) else (lr, ur) 18:	(mj , Mj ) → if —ari < 0 then (uj , lj ) else (lj , uj ) 19:	l′ → ajimr — arimj
20:	u′ → ajiMr — ariMj
21: end for
22: l′ → —∞
23: u′ → +∞
24: return ⟨A′, l′, u′⟩


Theorem 4.5 The operator forgetα(i) described in Algorithm 1 is correct and min- imal. It is γ-complete when J0 /= ∅. The computational complexity is O(n2).

Non-invertible assignment
We consider again the assignment operator assign(i, c, b) when ci = 0. In this case, all the constraints involving the variable xi need to be discharged after the assignment, possibly replaced by other implied constraints. Note that if ci = 0 we have assign(i, c, b) = assign(i, c, b) ◦ forget(i). This suggests to use the abstract forget operation to make implied constraints explicit.

Algorithm 2 The non-invertible assignα(i, c, b) abstract operator

Require: ⟨A, l, u⟩ ∈ ParTopen, i ∈ {1,..., n}, c ∈ Rn, b ∈ R, ci =0 1: ⟨A′, l′, u′⟩ → forgetα(i)⟨A, l, u⟩

2: choose an index j with a′
/=0 

3: for all s such that a′
/= 0 and s /= j do

4:	a′ → a′
— a′ /a′ a′

s∗	s∗
5: end for
si  ji  j∗

6: a′ → ei — c
7: l′ → b
8: u′ → b
9: return ⟨A′, l′, u′⟩

The procedure is shown in Algorithm 2. Given a parallelotope P , we first com-

pute ⟨Aj, lj, uj⟩ = forgetα(i)(P ) and choose a row j in Aj with aj
/= 0. Lines 3–5

ensure that aj
is the unique line with a non-zero i-th element. They do not change

the parallelotope, since operate on unbounded rows. Then, we may replace aj
with ei − c , lj and uj with b. Since the j-th row of A is unbounded, we do not lose precision when we replace it. Thanks to the steps 3–5, the final matrix Aj is invertible.
Theorem 4.6 The operator assignα(i, c, b) described in Algorithm 2 is correct and minimal. The computational complexity is O(n2).
Reﬁnement by linear inequality
Given b ∈ Rn and c ∈ R, consider the operation over ℘(Rn) given by
refine(b, c)(X)= {x | x ∈ X ∧ xT c ≤ b} ,
which we will call linear reﬁnement. In general, the linear refinement of a parallelo- tope is not a parallelotope.

Algorithm 3 The refineα(c, b) abstract operator
Require: ⟨A, l, u⟩ ∈ ParTopen, c ∈ Rn, b ∈ R
1: y → solution of AT y = c
2: if Ej. yj /=0 Λ li = —∞ Λ ui = +∞ then
3:	aj∗ → c
4:	uj → b
5:	return ⟨A, l, u⟩
6: else
7:	⟨In, l′, u′⟩ → refineα(y, b)⟨In, l, u⟩ {using operator on boxes} 8:	return ⟨A, l′, u′⟩
9: end if

Given a parallelotope P = ⟨A, l, u⟩, we first investigate if there exists an un- bounded row of A such that, if we replace that row with c, then the matrix is still

invertible. This amounts to computing a vector y ∈ Rn such that AT y = c and look for an index j such that yj /= 0. When it does not exists, we simply compute the least parallelotope P j containing refine(c, b)(P ) and definable over A. We re- call from [3] that, if refine(y, b)⟨In, l, u⟩ = ⟨In, lj, uj⟩, then P j = ⟨A, lj, uj⟩. Hence, we may use the known refine operator over boxes to define a refine operator over parallelotopes.
Theorem 4.7 The operator refineα(c, b) described in Algorithm 3 is correct and relatively optimal. The computational complexity is O(n3).

Union
Let us come to the abstract union of parallelotopes. If we fix a matrix M , the least parallelotope definable over M which contains the parallelotopes PA = ⟨A, l, u⟩ and PB = ⟨B, j, k⟩ can be easily obtained by αM(PA) and αM(PB) simply selecting, for each row in M , the least lower bound and the greatest upper bound. By choosing M to be either A or B, we can use this method for a simple and fast implementation of abstract union. The biggest drawback of this choice is that it does not generate new constraints.
We now propose a more complex variant of abstract union, inspired by the recently developed inversion join operator [11]. The main idea of the algorithm is to generate a bunch of candidate linear forms. The corresponding constraints are obtained from the candidate linear forms by computing the lowest and upper bounds on PA and PB. We then assign to each constraint a priority.
In general, the candidate linear forms are not linearly independent. At the end, we will select exactly n linearly independent constraints, according to their priorities (where 0 is the highest one).
The priority is chosen according to the values of the bounds. In order of pref- erence, we will select: equality constraints, constraints which are saturated both in PA and PB, and so on. This order is mostly dictated by heuristic considerations. Algorithm 4 computes the bounds and assigns the priorities for a given linear form v.

Algorithm 4 Bounds and priorities for the linear form v (Sketch)
Require: PA, PB ∈ ParTopen, v ∈ Rn
1: lv → inf{x ∈ PA | vT x} 2: uv → sup{x ∈ PA | vT x} 3: jv → inf{x ∈ PB | vT x} 4: kv → sup{x ∈ PB | vT x}
5: if lv = uv = jv = kv then
6:	p → 0
7: else if lv = jv ∈ R and uv = kv ∈ R then
8:	p → 1
9: else if ... then
.

10:
. {other tests}

11: else
12:	p → +∞ 13: end if
14: return ⟨min(lv, jv ), max(uv, kv ), p⟩

We now describe how to generate the candidate linear forms for the abstract

union. Obvious candidates are the rows of the matrices A and B. Moreover, we also generate new linear forms using (a part of) the inversion join algorithm. Given two constraints in PA and/or PB, the inversion join computes a new linear form obtained as a linear combination of the two constraints, under the condition that they form an inversion. The complete procedure is illustrated in Algorithm 5.

Algorithm 5 The abstract union operator
Require: PA = ⟨A, l, u⟩ ∈ ParTopen, PB = ⟨B, j, k⟩ ∈ ParTopen
1: Q → ∅ {a priority queue} 2: for all i ∈ {1,..., n} do
3:	⟨c, d, p⟩ → result of Algorithm 4 applied to ai∗
4:	add ⟨ai∗, c, d⟩ to Q with priority p
5: end for
6: same procedure of lines 2–5 applied to rows in B
7: for all v1, v2 rows of A and B do
8:	{here we check if v1 and v2 form an inversion} 9:	h1 → inf{x ∈ PA | v1x}
10:	h2 → inf{x ∈ PA | v2x}
11:	i1 → inf{x ∈ PB | v1x}
12:	i2 → inf{x ∈ PB | v2x}
13:		if h1, i1, h2, i2 ∈ R and v1, v2 are linearly independent and ((h1 < i1 Λ h2 > i2) ∨ (h1 > i1 Λ h2 < i2)) then
14:	{we know that v1 and v2 form an inversion}
15:	w → v1 + h1−i1 v2 {w is the linear form obtained by inversion join}
2	2
16:	⟨c, d, p⟩ → result of Algorithm 4 applied to w
17:	add ⟨w, c, d⟩ to C with priority p
18:	end if
19: end for
20: same procedure of lines 7–18 applied to upper bounds
21: same proc. of lines 7–18 applied to lower bounds for v1 and upper bounds for v2 22: same proc. of lines 7–18 applied to upper bounds for v1 and lower bounds for v2 23: ⟨R, l′, u′⟩ → empty set of constraints
24: while |R| < n do
25:  extract ⟨w, c, d⟩ from C with maximal priority 26:  if w is linearly independent from R then
27:	add ⟨w, c, d⟩ to ⟨R, l′, u′⟩
28:  end if
29: end while
30: return ⟨R, l′, u′⟩


Theorem 4.8 The abstract union operator described in Algorithm 5 is correct and relatively optimal. The computational complexity is O(n4).

Widening
Given two parallelotopes PA and PB, we first compute αA(PB) = ⟨A, jj, kj⟩ and then apply, separately for each row in A, a standard widening which extrapolates unstable bounds to infinity. We define ⟨A, l, u⟩∇⟨B, j, k⟩ = ⟨A, lj, uj⟩ where, for each i ∈ {1,..., n}, we have that:


lj =
j
i
li	otherwise
uj =
j
i
ui	otherwise.


We will combine this widening operator with delayed widening, to ensure that the union operator is initially applied, and new constraints can be generated.

Experiments and conclusions
We show some simple examples to give a rough idea of the potentialities and limits of the new domain, using our implementation of parallelotopes in RANDOM [4,2]. Consider the program cousot78 in Figure 1, taken from [7]. The parallelotope





i = i+4 else {
j = j+1 i = i+2
} } } 
j = j+3	}
}
}


Fig. 1. Example programs

domain is able to prove that, in the last line of the while, the inequalities i + 2j ≥ 6 and j ≥ 0 hold. However, since it is not able to represent more than two constraints, it cannot prove that 2j − i ≤ −2. For the program karr76, taken from [9], it can prove the invariants 3i − j + k = 1 and i ≥ 2. Finally, the program absval, taken from [10], is an example where our domain performs poorly, since it cannot prove that, inside the last if, x is between −69 and 69.
While the theoretical work is mostly complete, and we also got interesting and non-trivial minimality results, more work should be devoted to evaluate the domain in practice and to study its combination with other numerical domains. Encouraged by the results of our early experiments, we plan to conduct an extensive test of the parallelotope domain, in order to improve the heuristics (especially the choice of pri- orities in Algorithm 4, which seems of utter importance to achieve good precision), and to better understand its weak points. In some cases, the limit on the number of constraints appears too restrictive. For instance, in the cousot78 example we were not able to prove that i ≥ 2, essentially because we are already using two constraints to prove 2i − j ≤ −2 and j ≥ 0. We strongly believe that the domain of parallelotopes could benefit from being coupled with intervals or with a weakly relational domain, such as octagons, to keep track of additional constraints, while remaining fully relational.

References
Amato, G., M. Parton and F. Scozzari, Deriving numerical abstract domains via principal component analysis, SAS 2010, Proceedings, LNCS 6337, Springer, 2010 pp. 134–150.
Amato, G., M. Parton and F. Scozzari, A tool which mines partial execution traces to improve static analysis, RV 2010. Proceedings, LNCS 6418, Springer, 2010 pp. 475–479.
Amato, G., M. Parton and F. Scozzari, Discovering invariants via simple component analysis, Journal of Symbolic Computation 47 (2012).

Amato, G. and F. Scozzari, Random: R-based Analyzer for Numerical DOMains, LPAR-18, 2012. Proceedings, LNCS 7180, Springer, 2012 pp. 375–382.


Col´on, M. and S. Sankaranarayanan, Generalizing the template polyhedral domain, in ESOP 2011, Proceedings , LNCS 6602, Springer 2011 pp. 176–195.
Cousot, P. and R. Cousot, Abstract interpretation frameworks, Journal of Logic and Computation 2
(1992), pp. 511–549.
Cousot, P. and N. Halbwachs, Automatic discovery of linear restraints among variables of a program, in: POPL ’78, Proceedings (1978), pp. 84–97.
Howe, J. M. and A. Simon, Logahedra: A new weakly relational domain, in ATVA 2009, Proceedings., LNCS 5799, Springer, 2009 pp. 306–320.
Karr, M., Affine relationships among variables of a program, Acta Informatica 6 (1976), pp. 133–151.
Min´e, A., The octagon abstract domain, Higher-Order and Symbolic Computation 19 (2006), pp. 31– 100.
Sankaranarayanan, S., M. Colo´n, H. B. Sipma and Z. Manna, Efficient strongly relational polyhedral analysis, in VMCAI, Proceedings., LNCS 3855 (2006), pp. 111–125.
Sankaranarayanan, S., H. B. Sipma and Z. Manna, Scalable analysis of linear systems using mathematical programming, in VMCAI, Proceedings., LNCS 3385, Springer, 2005 pp. 25–41.
