	Electronic Notes in Theoretical Computer Science 170 (2007) 165–184	
www.elsevier.com/locate/entcs

Quantum Programs With Classical Output Streams
(Extended Abstract)
Dominique Unruh1
Institut fu¨r Algorithmen und Kognitive Systeme, Universita¨t Karlsruhe Am Fasanengarten 5, 76131 Karlsruhe, Germany

Abstract
We show how to model the semantics of quantum programs that give classical output during their execution. That is, in our model even non-terminating programs may have output. The modelling interprets a program as a measurement process on the machines state, with the classical output as measurement result. The semantics presented here are fully abstract in the sense that two programs are equal in semantics if and only if they give the same outputs in any composition.
Keywords: Quantum programming languages, denotational semantics, classical output streams.


Introduction
Most (quantum) algorithms take a (classical or quantum) input, calculate, and finally give a (classical or quantum) output. However, this paradigm does not capture the case where a program outputs data before its termination. Then even a non-terminating program may have outputs (possibly an infinitely long one). An example for such a program would be e.g. one that enumerates some set.
One possible way to model such a behaviour might be to model a program as a classical process operating on a quantum state, giving rise to a stochastic process (examples for this approach can be found in [3,2,8,7]). Such a language

1 Email: unruh@ira.uka.de




1571-0661 © 2007 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2006.12.016

could then be augmented by operations for giving classical output, and the stochastic process would induce a probability distribution on the outputs.
However, there is a drawback to such a hybrid approach. Due to the laws of quantum mechanics, there are different probability distributions of quantum states that principally cannot be distinguished. Therefore two pro- grams might have different semantics although they have exactly the same observable behaviour. This problem was tackled by [6], where semantics of a quantum programming language where presented which did not model a clas- sical stochastic process on quantum data, but instead represented the state of the program directly by a density operator, an established formalism describ- ing probabilistic mixtures of quantum states. Since two density operators are equal if and only if the ensembles are indistinguishable, this yielded to fully abstract semantics in the sense that two programs have the same semantics if and only if they show the same behaviour in any larger context. However, these semantics did not have the possibility of modelling streams of classical output.
We follow the philosophy adapted by [6] and present fully abstract seman- tics for quantum programs with classical output streams. The idea underlying the model is to consider the execution of a program to be a physical measure- ment process on the state of the program. Such a measurement process takes a quantum state as input (the initial state of the system), returns a classical measurement result (the output during the programs execution) and leaves the system in a new state. Such a measurement process can be described by the es- tablished PMVM formalism (cf. Section 1.1). Of course, for a non-terminating program the notion of the state after the execution is not defined, so these programs are to be modelled by measurements without a post-measurement state, so-called POVMs (cf. Section 1.1).
We show how to combine the PMVM and POVM formalisms to allow for programs that sometimes terminate and sometimes do not. The situation is slightly complicated by the fact that non-terminating programs may have an uncountable number of possible output sequences. Fortunately, the modelling of POVMs and PMVMs presented in [1] (see also Section 1.1) is able to handle such a situation.
The most interesting construct presented here is that of loops. If non- terminating programs may have outputs, the approach of defining a loop as a least fixpoint is not straightforward. Therefore we present an alternative approach where the semantics of a loop are uniquely defined by some intuitive axioms (see Section 7).
In this extended abstract, we give complete formal definitions, but omit all proofs.

Notation and quantum mechanical formalism
Note that this summary of quantum mechanical formalism does not provide an introduction to quantum mechanics. It is mainly intended to state the nomenclature used in this paper. For a gentler introduction see e.g., [4] or [5], and [1] for the case of POVMs/PMVMs with uncountably many outcomes.
By ,  and  we denote the natural numbers (including 0, >0 other- wise), the integers and the complex numbers, respectively. If A is a non-empty set, by A∗ we denote the set of all finite, by A∞ the set of all infinite, and by Aseq the set of all finite or infinite sequences over A. The empty word is written ε. Given two sequences a and b, ab denotes the concatenation (if a is
infinite, ab = a).
When a countable set A is regarded as a measurable space, all its subsets are measurable. When the set A∗, A∞, or Aseq is regarded as a measurable space, the set of its measurable sets is the σ-algebra generated by the sets of the form {ω : α is prefix of ω} for α ∈ A∗.
Pure quantum states are elements of some Hilbert space H with unit norm.
A pure state is written |Ψ⟩. Its adjoint is ⟨Ψ|. A Hilbert space of the form X for some set X has a distinguished base, the computational base {|i⟩ : i ∈ X}. An operation on a pure state that results in a new pure state is represented by a unitary transformation (or in general by an isometric one, if the operation is not surjective).
To represent mixed states (i.e., states about which we have incomplete in- formation), we use density operators, which are symmetric, positive operators on H of trace at most 1. A mixture of (at most countably many) states |Ψi⟩ with probabilities pi is represented as i pi|Ψi⟩⟨Ψi|. Each density operator corresponds to at least one mixture (with total possibility ≤ 1). Quantum processes on density operators are represented by quantum superoperators, i.e., completely positive maps on density operators which do not increase the trace. Trace-preserving superoperators we call probability preserving.
Given a density operator ρ over some composite Hilbert space HA ⊗ HB, the partial trace trA ρ is a density operator over HB which represents the state of the second subsystem, if the first subsystem is lost.
Measurements on density operators are either modelled as POVMs or PMVMs. If the state of the system after the measurement is undefined, a POVM is used. A POVM E with outcomes in a set Ω assigns a positive sym- me tric operator E(A) on H to any measurable subset A of Ω, s.t.  i E(Ai)= 
 
in the weak operator topology), E(∅) = 0, and tr E(A)ρ ≤ tr ρ for all mea-
surable A ⊆ Ω and density operators ρ. If tr E(A)ρ = tr ρ for all density operators, we call E probability preserving. Given a state ρ, the probability

of measuring some a ∈ A is given by tr(E(A)ρ).
In the case that the state of the system after the measurement is defined, one has to use PMVMs. A PMVM F assigns a superoperator F(A) to each measurable A ⊆ Ω, s.t.  i F(Ai) = F( i Ai) for any countable collection of disjoint sets (where the sum converges in the strong topology), F(∅) = 0, and tr F(A)(ρ) ≤ tr ρ for all measurable A ⊆ Ω and density operators ρ. If tr F(Ω)(ρ) = tr ρ for all density operators, we call F probability preserv- ing. Given a state ρ, the probability of measuring some a ∈ A is given by tr F(A)(ρ), and the resulting state under that condition is  F(A)(ρ) .

Modelling a program’s operation
We will now discuss how the operation of a program can be modelled. We first start by modelling terminating programs. Such a program takes a state (the initial state of the machine, represented by a density operator), gives some (classical) output, and returns a new density operator, the state of the machine after program execution. This behaviour can easily be modelled by a PMVM, which takes the initial to the resulting state and has a sequence of outputs as its measurement outcome. However, a non-terminating program could not be modelled thus, since such a program does not have a resulting state. Therefore, it is better modelled as a POVM, which takes the initial state and gives us a probability distribution of output sequences, but not the state after application.
We can now model terminating programs and non-terminating programs. However, we need to model programs, which do sometimes but not always terminate. Such a program we express as a mixed measurement, which we define as follows:
Definition 2.1 (Mixed measurement) Let H be a Hilbert space. A mixed measurement M with outcomes in Ω over H is a pair (M fin,M nt), where M fin is a PMVM over H and M nt a POVM over H with outcomes in Ω.
Given a density operator ρ, the probability that the measurement termi- nates (i.e., there is a state after the application of the measurement), and that the outcome of the measurement lies in a measurable set A ⊆ Ω, is given by
tr M fin(A)(ρ), and the resulting state is  Mfin(A)(ρ) .
The probability that the measurement does not terminate and has an out- come in A, is tr M nt(A)ρ.
We will usually take the Hilbert space H as implicitly given.
Since it does not make sense to talk about measurements, where the prob- ability of getting any result is greater than 1, we usually have to restrict

mixed measurements to be probability preserving or reducing, as given by the following definition:
Definition 2.2 (Probability preserving)  A mixed measurement M is
probability preserving if for all density operators ρ it is
tr M fin(A)(ρ)+ tr M nt(A)ρ  = tr ρ.
We call M probability reducing if for all ρ it is
tr M fin(A)(ρ)+ tr M nt(A)ρ ≤ tr ρ.
Using this notation, we can now model programs that may or may not terminate, by considering them to be a measurement which yields the classical output of the program as a result.
Definition 2.3 (Program) Let a countable alphabet Σ be fixed. Let ε de- note the empty word in Σseq.
A program P is a probability preserving mixed measurement with values in Σseq, 2 satisfying the additional requirement
Pfin {x ∈ Σseq : x is infinite} = 0.
When P is only probability reducing, we call P a partial program instead.
The additional requirement in this definition results from the fact that no terminating program can have an infinitely long output.
We finish this section by defining some very simple programs.
First, consider the program noop, which does nothing and terminates im- mediately. Since noop has a probability of 0 for non-termination on any initial state, we get noopnt(A) = 0 for all A. And since the output is always ε (the

empty in Σseq), we get noopfin(A) = 0 for ε ∈/
A. Finally, the state is not

modified, so we have noopfin(A) = 1 for ε ∈ A (since 1 is the identity on the density operators).
Second, consider the program loop, which does not terminate and has no output. Following a similar reasoning as with noop, we see that loopfin(A)= 0 for all A, and loopnt(A) = 1 if and only if ε ∈ A, and loopnt(A)= 0 otherwise.
Finally, consider the simple program print x for x ∈ Σ∗, which outputs x and then terminates. Again, as with noop we have (print x)nt = 0. But, since x is output, we get (print x)fin(A) = 1 if and only if x ∈ A. This program can of course only give constant outputs; in Section 6 we show how
to output the result of a measurement.

2 Σseq is the set of all possible outputs of a program.

We collect these examples in the following
Definition 2.4 (Elementary programs) Let x ∈ Σ∗. Then the programs
noop, loop, print x are defined by (for all measurable A ⊆ Σseq)


noopfin(A)=	1,	ε ∈ A,
0,	ε ∈/ A,
noopnt(A)= 0,

loopfin(A)= 0,	loopnt(A)=	1,	ε ∈ A,
0,	ε ∈/ A,

(print x)fin(A)=	1,	x ∈ A,
0,	x ∈/ A,
(print x)nt(A)= 0.


It is easy to see that all these are in fact programs (as by Def. 2.3).

Elementary operations
Besides the elementary programs presented in the preceding section, a very basic kind of quantum programs is the application of unitary transformations to the state of the system. Since such an application does not terminate and does not give output, the following definition is straightforward:
Definition 3.1 (Unitary transformations on the program’s state) Let
U be an isometric transformation 3 on H. Then the program U is defined by



Ufin
(A)(ρ)= 
U ρU †,	ε ∈ A,
0,	ε ∈/ A,

Unt
(A)ρ =0 

for all density operators ρ over H.
That this notion is well-defined, is shown by the following
Lemma 3.2 Let U be an isometric transformation. Then U exists and is indeed a program.
Most often, one does not want to apply a unitary transformation to the whole of H, but only to some registers.

3 Isometries are a more general case than unitary transformations. In particular, they need not be surjective. Mostly we will only use unitaries, therefore the name of the definition.

To be able to define this, we will assume for the rest of this section that
H has the following structure:


H =
x∈V
Tx .

Here V is a list of variable names and Tx an arbitrary countable set (the type of the variable). So H is decomposed into several quantum registers with names x ∈ V . Typical types might be bits, denoted by the set bit := {0, 1}, booleans, denoted by bool := {true, false}, or integers, denoted by the set int := .
Using this decomposition, we can define the application of a unitary trans- formation on several variables:
Definition 3.3 (Unitary transformations on variables) Let x1,... , xn be pairwise different variable names from V . Let further U be an isometric transformation on Tx1 ⊗ ··· ⊗ Txn . Then let Φ be the canonical unitary isomorphism (that only reorders the coefficients) between H and


Tx1 ⊗ ··· ⊗ Txn  ⊗
x∈V \X
Txn	with X := {x1,... , xn}.

Then U (x1,... , xn) is the unitary transformation Φ−1 ◦ (U ⊗ 1) ◦ Φ (here 1 is

the identity on 

x∈V \X
Txn ), and U(x1,... , xn) is U (x1,... , xn) interpreted

as a program as in Definition 3.1.
If n = 1, we write short U x1 for U(x1).
So U(x1,... , xn) simply means that U is applied to the Hilbert space cor- responding to the variables x1,... , xn.
Another very important operation is the (classical) assignment to quantum registers. E.g., when we write a := 5 we mean that in the register a the value 5 is prepared. This is easily formalised using the partial trace. Consider a Hilbert space H decomposing into two spaces H = HA ⊗ HB. Then preparing the state |φ⟩ in HA is the operation mapping a density operator ρ over H to
|φ⟩⟨φ|⊗ trA ρ, where trA is the partial trace tracing out the space HA. This can easily be generalised to assignments to variables:
Definition 3.4 (Constant assignments) Let x1,... , xn be pairwise differ-
ent variable names from V , and (a1,... , an) ∈  n	Tx . Let
i
HA := Tx1 ⊗ ··· ⊗ Txn ,
HB :=	Txn  with X := {x1,... , xn},
x∈V \X

and Φ : H → HA ⊗ HB be as in Definition 3.3. Further trA denote the partial trace tracing out HA.
We define the superoperator S over H assigning (a1,... , an) to (x1,... , xn):
S(ρ) := Φ† |a1,... , an⟩⟨a1,... , an|⊗ trA(Φ ρ Φ†) Φ for all density operators ρ over H.
Then (x1,... , xn) := (a1,... , an) is the program P defined by

Pfin(E)=	S,	ε ∈ E,
0,	ε ∈/ E,
Pnt(E)= 0.
We also write x := a for (x) := (a).
The intuitive meaning of x := a is to assign a to x, and the intuitive mean- ing of the statement (x1,... , xn) := (a1,... , xn) is to assign ai to xi. Note however that using this definition, only the assignment of constant values is possible. In Section 6 we show how to assign the outcome of a measurement. Note that the constructs in this section rely on the implicit or explicit
definition of the variable names V and the types Tx. To make these explicit,
we may use the following convention: A program with H =  x∈V	T , and
x
variable names V and types Tx is prefixed by
var x : Tx;
for each x ∈ V .
We present two examples for the constructs presented in this section:
var n:int; n=5;
This is a program over the Hilbert space H =  which always terminates, gives no output, and where the state after the execution is |5⟩⟨5| (independent of the initial state).
1 0 0 0 
0 1 0 0 
0 0 0 1 
0 0 1 0 
Then
var a:bool; var b:bool; var c:bool; CNOT(a,b); CNOT(c,b)

is a program over the Hilbert space H = bool ⊗ bool ⊗ bool. It flips the second bit first conditioned on the first and then conditioned on the third bit. 4
Admittedly, these constructs are quite rudimentary, they mainly serve to give a minimal set of elementary operations to be able to use the control- related constructs in the following sections. A concept of variables with a richer type-system and scoping would greatly improve the usability of the concepts described here and would be interesting future work.
Note further that it seems very restrictive that only constant assignments are possible in this language. However, in Section 6 it is shown how to assign the outcomes of measurements to variables.

Probabilistic sum
The simplest operation on programs is the probabilistic sum. Let P and Q be programs, and p ∈ [0, 1], then P⊕p Q denotes the program resulting by running P with probability (1 − p) and Q with probability p. It is easy to see that this intuition is satisfied by the following definition:
Definition 4.1 (Binary probabilistic sum) Let P and Q be programs (or partial programs), and p ∈ [0, 1]. Then we define the program (the partial program) P ⊕p Q by
(P ⊕p Q)fin := (1 − p) Pfin + p Qfin,
(P ⊕p Q)nt := (1 − p) Pnt + p Qnt.

We can even easily generalise this definition to an arbitrary number of summands:
Definition 4.2 (Probabilistic sum) Let I be a countable set. Let Pi (i ∈ I)


the probabilistic sum is the program (partial program)
   p P  fin := Σ p Pfin,
i piPi defined by


	
   p P  nt := Σ p Pnt.
	

4 In this example, we use the sequential composition of CNOT(a,b) and CNOT(c,b). This we be formally introduced only in Section 5.

A question naturally arising would be, whether the probabilistic sum is always defined, especially for infinitely many summands. The following lemma answers this question positively.
Lemma 4.3 Let I be a countable set. If all Pi (i ∈ I) are programs, and
p = 1, then   p P exists, is uniquely deﬁned and a program.
If all Pi are partial programs, and i∈I pi ≤ 1, then i piPi exists, is uniquely deﬁned and a partial program.
Example: Using this constructor, and the program print from the pre- ceding section, we can formulate a program, which outputs a random bit:
print 0 ⊕ 1 print 1.
2
Sequential composition
Probably the most important construction in any imperative programming language is sequential composition, i.e., the successive application of pro- grams. To achieve this goal, we first formulate the composition of mixed measurements.
Let P and Q be mixed measurements. What does the composition QP (Q applied after P ) mean intuitively? First we measure P , yielding outcome xP . Then, if P terminates, we measure Q, yielding outcome xQ. The overall out- come of this experiment shall then be (xP , xQ) or xP (depending on whether Q has been applied or not). This intuition easily gives us the following properties of QP , which turn out to define QP (cf. Definition 2.1):
Definition 5.1 (Sequential composition of mixed measurements) Let P and Q be mixed measurements with outcomes in ΩP resp. ΩQ. Then QP is the mixed measurement with outcomes in (ΩP × ΩQ) ∪ ΩP satisfying the following equalities for all density operators ρ and all measurable AP ⊆ ΩP , AQ ⊆ ΩQ:
(QP )fin(AP × AQ)(ρ)= Qfin(AQ) P fin(AP )(ρ) ,
tr(QP )nt(AP × AQ)ρ = tr Qnt(AQ)P fin(AP )(ρ), tr(QP )nt(AP )ρ = tr P nt(AP )ρ.
The following lemma justifies calling these properties a definition:
Lemma 5.2	Let P and Q be mixed measurements with outcomes in ΩP
resp. ΩQ.
If QP exists, it is uniquely deﬁned by Deﬁnition 5.1.

If ΩP and ΩQ can be embedded in compact metrisable spaces, the compo- sition QP exists.
If ΩP = ΩQ = ΩΣ, the composition QP exists.
If P and Q are probability preserving (reducing), so is QP (if existent).
At a first glance, one might think that this definition already gives us the sequential composition of programs. However consider the following example: Let Ps output s ∈ Σ∗. Then we expect the composition of Pab and Pc to have the same operational semantics as the composition of Pa and Pbc, namely Pabc. However, using Definition 5.1 we get PcPab, which yields with probability 1 the
outcome (ab, c) /= abc. Similarly, PbcPa outputs (a, bc) /= abc. This problem can be solved by defining the composed program Pa; Pbc to result from applying the composed mixed measurement PcPab and then “forget” about the structure of the outcome, i.e., we map (ab, c) to abc, and more generally (x, y) to the concatenation xy.
In order to formalise this idea, we first have to define what it means to apply a function f to the result of a mixed measurement P . Note that P fin(A), P nt(A) describe the behaviour of the measurement restricted to the case that
the outcome x lies in A. Then P fin(f −1(A)), P nt(f −1(A)) describe the be- haviour of the measurement restricted to the case that f (x) ∈ A. Considering this, one easily understands the following definition:
Definition 5.3 (Function application to mixed measurements)  Let
P be a mixed measurement with outcomes in Ω. Let further f : Ω → Ω˜ be
a measurable function. Then we define the mixed measurement f (P ) with

outcomes in Ω˜
by setting (for all measurable A ⊆ Ω˜):
 f (P ) fin(A) := P fin f −1(A) ,
 f (P ) nt(A) := P nt f −1(A) .

If f has a domain containing but not equaling Ω, we slightly generalise the definition by setting f (P ) := f |Ω(P ).
The following lemma is then obvious:
Lemma 5.4 Let P be a mixed measurement with outcomes in Ω. Let further

f :Ω → Ω˜
be a measurable function.

The mixed measurement f (P ) exists and is uniquely deﬁned by Deﬁni- tion 5.3.
If P is probability preserving (reducing), so is f (P ). We now have the means to formulate the

Definition 5.5 (Sequential composition of programs)  Let flatten be the function taking a (finite or infinite) sequence over Σseq and returning the concatenation of the elements of the sequence. 5
Then we define the sequential composition P; Q of two programs (partial programs) by
P;Q := flatten(QP),
where on the right hand side P and Q are treated as mixed measurements.
We are now able to formulate simple programs like
print a; print b	(outputs ab),
print a; loop	(outputs a, but does not terminate),
However, two questions arise naturally: Is P; Q in fact a program, and is the operator ; associative, as one would expect? The following lemma answers these questions positively and thus justifies Definition 5.5.
Lemma 5.6 Let P, Q, R be programs (partial programs). Then
P;Q exists, is uniquely deﬁned, and is a program (partial program).
It is {P;Q};R = P;{Q;R}. 6
It is P;noop = noop;P = P.
Using the notion of composition, we can now formalise the claim that the semantics presented here are fully abstract: 7
Lemma 5.7 Let P /= Q be programs. Then there are programs S, T and a measurable set A ⊆ Σseq of outputs, s.t. the probabilities that S;P;T or S;Q;T has an output in A are different for any initial state ρ. Formally:
tr(S;P;T)fin(A)(ρ) + tr(S;P;T)nt(A)ρ
/= tr(S;Q;T)fin(A)(ρ) + tr(S;Q;T)nt(A)ρ.


5 In this definition, we use flatten only on (Σseq)2. However, in Definition 7.1 we will need to apply flatten to (Σseq)seq.
6 Note that for grouping programs, we use curly braces instead of parentheses, as common in many programming languages like C, Java, etc.
7 Formally, to state that our semantics are fully abstract, one would need operational semantics to compare with. However, the lemma shows that with respect to a reasonable notion of observable behaviour the semantics are indeed fully abstract.

Branching programs
It would be quite hard to formulate interesting program code without the possibility of branching. We will first discuss the simplest constructor for branching programs, the if-statement, and then proceed to a more general construction, the switch-statement.
Let B be a PMVM with two possible outcomes: true and false, rep- resenting a Boolean test on the state of the program (e.g., measuring two registers, and returning whether they are equal). Then the program “if (B) P else Q” has the following intuitive representation: First, we apply the mea- surement B, then, if the outcome is true, we run P, otherwise Q. The output of “if (B) P else Q” is that of P or Q, respectively.
Using the semantics described in Definition 2.1, we easily see that this behaviour is captured by the following
Definition 6.1 (Branching using if) Let B be a probability preserving (reducing) PMVM with outcomes in {true, false}. Let further P and Q be programs (partial programs). Then
R := if (B) P else Q
is the program (partial program) satisfying (for all measurable A ⊆ Σseq and all density operators ρ):
Rfin(A)(ρ)= Pfin(A) B(true)(ρ) + Qfin(A) B(false)(ρ) tr Rnt(A)ρ = tr Pnt(A)B(true)(ρ)+ tr Qnt(A)B(false)(ρ)
Further “if (B) P” stands for “if (B) P else noop”.
This definition is supported by the following
Lemma 6.2 If P and Q are programs (partial programs), and B a probability preserving (reducing) PMVM with outcomes in {true, false}, then “ if (B) P else Q” and “ if (B) P” exist, are uniquely deﬁned, and are programs (partial programs).
This lemma follows easily from the more general Lemma 6.4.
As an example, we formulate a small program which sets a qubit to 0 and outputs its previously measured content, using only measurements and unitary operations:
var a:bit; if (a=0) print 0 else { NOT a; print 1 }

Here NOT denotes the bit-flip, and a=0 is the PMVM measuring a and yielding true if and only if the outcome is 0. The formal notation for elementary tests like a=0 is introduced in Section 6.1.
A more general construct which has if as a special case is the switch- statement. Later in this section we will see that its additional power is helpful in formulating quantum programs.
Consider a PMVM M with outcomes in a countable set C, and a family of programs P(c) indexed by c ∈ C. Then we can interpret the program switch (M as c) P(c) to describe the following experiment: First, we measure the program’s state using M. Let c ∈ C denote the outcome of that measurement. Then we execute P(c). Quite analogous to Definition 6.1, we get
Definition 6.3 (Branching using switch) Let M be a probability preserv- ing (reducing) PMVM with outcomes in a countable set C. Let further each P(c) (c ∈ C) be a program (partial program). Then the program (partial pro- gram) R := switch (M as c) P(c) is defined by satisfying for all measurable A ⊆ Σseq and all density operators ρ:
Rfin(A)(ρ)= Σ P(c) fin M({c})(ρ) 
tr Rnt(A)ρ = tr	P(c) ntM({c})(ρ)
c∈C
The convergence notion used in these equations is that of weak convergence. 8
Lemma 6.4 Under the conditions of Deﬁnition 6.3, the following holds:
If all P(c) are programs (partial programs), and B is probability pre- serving (reducing), then “ switch (M as c) P(c)” is a program (partial program).
If B has outcomes in {true, false}, then:
switch (M as b) P(b)  =	if (M) P(true) else P(false)
The reader may now ask, what we need such a switch-statement for, since a finite branching can be realised using if-statements, and an infinite branching does not really reflect the possibilities in practical programming. However, the following example may show the use of the switch-statement as a tool in specifying program behaviour.
In Definition 2.4 we have introduced the program print x, which outputs the constant word x. In many cases this is not sufficient, since one may want

8 Since the sums are increasing norm-bounded sequences of symmetric operators, strong, weak and ultra-weak convergence coincide.

to simply output the result of a measurement. This can easily be formulated using only switch and print. Assume M to be a PMVM with outcomes in A, and f : A → Σ∗ to assign labels to the outcomes. Then the following program measures M and outputs the outcome:
switch (M as x) print f(x)
Similarly, the assignment of constant values from Definition 3.4 can be ex- tended to allow for assignments of measurement outcomes:
switch (M as x) a := x
assigns the outcome of measuring M to variable a.
To ease reading of the program code, we will often write the shorter P(M) instead of the less handy switch (M as c) P(c). So the programs just pre- sented will get the more intuitive forms print f(M) and a := M.
Note however that when using this shorthand notation, one has to ensure that no ambiguity ensues. E.g., one must keep in mind that “P(M); Q(M)” shall always denote “switch (M as c) P(c); switch (M as c) Q(c)”, and that a statement containing two implicit switch-statements is only well- defined if the PMVMs commute. So P(M,N) could be
switch (M as m) switch (N as n) P(m,n)
or
switch (N as n) switch (M as m) P(m,n)
which are only identical if M and N commute. So if in doubt, explicitly write switch. Also, a program like a:=f(b) could be read as switch (f(b) as x) a:=x (measure f(b) and assign the outcome to a) or switch (b as x) a:=x (measure b and assign f(b) to a). Our convention is to assume the latter case.

Elementary tests
In order to be able to use the above if statement, we still need some means to specify elementary tests. In the preceding section, we just assumed some PMVM with boolean outcomes to be given, here we will present a method how to specify these. Similarly to the case of unitary transformations, we can define measurements on functions of variables:
Given some variables x1,... , xn and a function f on the types of these vari- ables, we define f (x1,... , xn) to be the measurement that measures the value of f (x1,... , xn) without measuring x1,... , xn (e.g., measuring x1 ⊕ ··· ⊕ xn

would measure the parity of x1,... , xn without performing a complete mea- surement). With such a measurement, getting measurement result m means projecting the state onto the subspace Hm of states where f (x1,... , xn)= m. We mold this into a formal definition:
Definition 6.5 (Elementary measurements on variables) Let x1,... , xn be pairwise different variable names from V , and M a countable set. Further let f : Tx1 × ··· × Txn → V be a function.
Then for m ∈ M , let Bm be the set of all elements e of the computational basis of H = ⊗x∈V Tx satisfying:
e = ⊗x∈V |vx⟩	with	f (vx1 ,... , vxn )= m.
Then we can define Hm to be the subspace of H generated by Bm, and Pm
to be the orthogonal projection onto Hm. And finally this defines a PMVM
f(x1,... , xn):
f(x1,... , xn)(A)(ρ) := Σ PmρP †
m∈A
for any density operator ρ ∈H and any A ⊆ M .
The following lemma states the well-definedness of the above construct:
Lemma 6.6 With the notation of Deﬁnition 6.5, if the variables x1,... , xn are pairwise different, f(x1,... , xn) is a probability preserving PMVM with outcomes in M.
With M = {true, false}, the above construct is suitable for use with the
if statement. We give an example:
var a:bit; var b:bit; a:=0; b:=0;
H2a; H2b;
if (a=b) NOT a;
Here H2 denotes the Hadamard-transform on one qubit, and NOT the bit-flip. If the test a=b fails, a and b are entangled to have opposite values. Otherwise, they are entangled to have the same value, but a gets flipped, so after the if statement they have opposite values, too. So the above example generates an EPR pair.
Of course, such PMVMs can also be used in conjunction with switch. So e.g.,
var i:int; switch (i as c) { case (i*i=4): print "X"; }

and
var i:int; switch (i*i as c) { case (i=4): print "X"; }
are different programs. While the first completely measures i, the second directly measures the square of i, i.e., ignores the sign, so if e.g., i is in superposition between 2 and −2, this superposition is not destroyed.
Like in Section 3, the notation for elementary measurements given here is only rudimentary. The development of more powerful concepts would be interesting future work.

Loops
In this exposition, one control structure is still missing, without which hardly any useful program can be written: the loop.
Assume that a program P and a probability preserving PMVM B with outcomes in {true, false} are given (cf. Definition 6.1). Then the program while (B) P shall intuitively represent the following experiment: Repeatedly measure B. While B yields true, apply P. When B yields false, stop. The overall output shall be the concatenation of the outcomes of all invocations of P.
In order to get a formal definition of the above while-program, let us first consider the intermediary case, where the outcome of the loop is not the concatenation of the outputs of P, but the possibly infinite list of these outputs. I.e., let R denote the following experiment: Repeatedly measure B. While B yields true, apply P. When B yields false, stop. The overall output shall be the (finite or infinite) sequence of the outcomes of all invocations of P.
It turns out to be quite difficult to write the infinite process in the intuitive definition of R in terms of sums and products of operators (as we did e.g. in Definitions 5.1 and 6.3), since no intuitive notion of convergence springs to mind where the following would be meaningful: 9
if (B) {P; if (B) {P; ··· if (B) {P; loop}··· }} = while (B) P
`	n t˛im¸ es	x

9 In fact, there are metrics on the set of partial programs such that the above statement is meaningful and equivalent to Definition 7.1, and even allows the definition of while (B) P where B and P are only probability reducing. However, we believe that these metrics can not as easily be justified as the axiomatic approach below, and therefore present the (probably more natural) axiomatic approach instead.

Another common approach would be to define R to be the lowest fixpoint of X '→ if (B) { P; X }. However, at fails when using the natural operator- theoretic ordering on mixed measurements. 10 Of course, there may be other orders which can be used for defining loops of programs with classical output.
We will try an alternative approach and postulate some axioms, which should hold for R, and will then show that these indeed define R.
First, observe that always one (and only one) of the following cases is bound to occur:
The loop terminates after n ≥ 0 invocations of P.
The n-th invocation of P does not terminate (n ≥ 1).
Every invocation of P terminates, but B always yields true (so the loop does not terminate either).
Note that the only case where R terminates is the first one. Therefore we can at least write down, what we expect from Rfin: For any n ≥ 0, any initial state ρ, and all measurable Ai ⊆ Σseq, it holds
n
Rfin(A1 × ··· × An)(ρ)= B(false) ◦	Pfin(Ai) ◦ B(true) (ρ).
i=1
Here  n	Xi means the composition Xn ◦ ··· ◦ X1.
Similarly, the case where R does not terminate, but has only a finite number of outputs is covered by case ii, which we can formalise as follows:
tr Rnt(A1 × ··· × An) ρ
  tr Pnt(An) B(true) ◦  n−1 Pfin(Ai) ◦ B(true) (ρ),	n ≥ 1

The last case is more difficult. In order to approach that case, we first note that by requiring R to be probability preserving (which seems a sensible thing to do, since both P and B are), we get
tr Rnt (Σseq)∞ ρ =1 − tr Rfin (Σseq)∗ (ρ) − tr Rnt (Σseq)∗ ρ.	(1)
Now consider the following event: B always yields true (i.e., the loop runs an infinite number of iterations), and in the first n iterations P has output in the

10 The natural operator-theoretic order is given by: A ≥ B if A − B is a mixed measurement (all mixed measurements are positive). The problem consist in having a difference between the least mixed measurement 0 and the program loop. Both are solutions to the equation X = if (B) { P; X }, but loop is the fixpoint we are looking for, while 0 is the least one.

set A1 × ··· × An. When ρ' is the state after the first iterations (conditioned on the outputs being in A1 × ··· × An, and B yielding true in the first n iterations), then the conditional probability that the loop will run an infinite number of iterations (with arbitrary further output) is just tr Rnt (Σseq)∞ ρ'. Writing this as a formula we get the last of our axioms for R:

n
tr Rnt A1×·· ·×An×(Σseq)∞ ρ = tr Rnt (Σseq)∞	Pfin(Ai)◦B(true) (ρ),
i=1
which by (1) defines the left hand side.
Note that using these axioms define Rfin and Rnt on A1 × ··· × An and A1×·· ·×An×(Σseq)∞ (for all n ≥ 1, Ai measurable), i.e., on a set of generators the sigma-algebra of (Σseq)seq. Therefore we can hope that these axioms will define a unique and existent R (this is positively answered by Lemma 7.2
below). Then we can finally define the while-program by concatenating R’s outputs, i.e., while (B) P := flatten(R).
Collecting the axioms stated in the above text, we get the following defi- nition:
Definition 7.1 (Loops) Let P be a program and B a probability preserving PMVM with outcomes in {true, false}.
Then let R be the probability preserving mixed measurement with out- comes in (Σseq)seq satisfying

n
Rfin(A1 × ··· × An) ρ = B(false) ◦	Pfin(Ai) ◦ B(true) (ρ).
i=1
tr Rnt(A1 × ··· × An) ρ
  tr Pnt(An) B(true) ◦  n−1 Pfin(Ai) ◦ B(true) (ρ),	n ≥ 1

tr Rnt A1 × ··· × An × (Σseq)∞ ρ

= tr Rnt (Σseq)∞    Pfin(Ai) ◦ B(true) (ρ).
We then define while (B) P := flatten(R).
The next lemma tells us that while (B) P is in fact a definition.
Lemma 7.2 Let the situation be as in Deﬁnition 7.1. Then R and while
(B) P always exist, are uniquely deﬁned and while (B) P is a program.

The following fact constitutes some evidence that the previous definition in fact complies with the intuitive meaning of a while-program:
Lemma 7.3 (Unrolling while-loops) Let P and B be as in Deﬁnition 7.1. Then
while (B) P	=	if (B) { P; while (B) P }
Of course, P is not uniquely described by the equation in this lemma. We give a simple example of a while-loop:
var o : bit; o := 1;
while (o=1) {
H2o; print 1 }
This program has a one-bit-variable o which is initially initialised to |1⟩. Then its is repeatedly measured in the computational basis, until the outcome does not equal 1. Each time 1 is measured, a H2-transformation is applied to o and the symbol 1 is output.

Acknowledgements
We thank the anonymous referee and Peter Selinger for helpful comments. This work was founded by the European Project ProSecCo IST-2001-39227.

References
Davies, E. B., “Quantum Theory of Open Systems,” Academic Press, London, 1976.
Gay, S. J. and R. Nagarajan, Communicating quantum processes, in: P. Selinger, editor, 2nd International Workshop on Quantum Programming Languages, 2004, pp. 91–107.
Lalire, M. and P. Jorrand, A process algebraic approach to concurrent and distributed quantum computation: operational semantics, in: P. Selinger, editor, 2nd International Workshop on Quantum Programming Languages, 2004, pp. 109–126.
Nielsen, M. and I. Chuang, “Quantum Computation and Quantum Information,” Cambridge University Press, Cambridge, 2000.
Preskill, J., Lecture notes for physics 229: Quantum information and computation (1998), online available at http://www.theory.caltech.edu/people/preskill/ph229/.
Selinger, P., Towards a quantum programming language, Mathematical Structures in Computer Science 14 (2004), pp. 527–586.
Selinger, P. and B. Valiron, A lambda calculus for quantum computation with classical control, in: Proceedings of the Seventh International Conference on Typed Lambda Calculi and Applications. Springer LNCS 3461, 2005, pp. 354–368.
Valiron, B., Quantum typing, in: P. Selinger, editor, 2nd International Workshop on Quantum Programming Languages, 2004, pp. 163–178.
