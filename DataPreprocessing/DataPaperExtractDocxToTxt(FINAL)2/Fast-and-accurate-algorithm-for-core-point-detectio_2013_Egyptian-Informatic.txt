
ORIGINAL ARTICLE

Fast and accurate algorithm for core point detection in fingerprint images
G.A. Bahgat a,*, A.H. Khalil b, N.S. Abdel Kader b, S. Mashali a

a Department of Computers and Systems, Electronic Research Institute, Giza, Egypt
b Department of Electronics and Electrical Communications, Faculty of Engineering, Cairo University, Giza, Egypt

Received 19 July 2012; revised 17 January 2013; accepted 29 January 2013
Available online 27 February 2013

Abstract The core point is used to align between the fingerprints in the fingerprint authentication systems faster than the conventional techniques. To speed up the processing for the real time appli- cations, it is more convenient to implement the image processing algorithms using embedded mod- ules that can be used in the portable systems. To do this, the algorithm should be characterized by a simple design for easier and more feasible implementation on the embedded modules. The proposed work, in this paper, presents a mask that locates the core point simply from the ridge orientation map. The introduced algorithm detects the core point at the end of the discontinuous line appearing in the orientation map presented by a gray-scale. A property is presented and supported with a mathematical proof to verify that the singular regions are located at the end of this discontinuous line. The experimental results, on the public FVC2002 and FVC2004 databases, show that the pro- posed mask exhibits an average increase in the correct core point detection per fingerprint by 17.35%, with a reduction in the false detection by 51.23%, compared to a fast edge-map based method. Moreover, the execution time is reduced by an average factor of 1.8.
© 2013 Faculty of Computers and Information, Cairo University. Production and hosting by Elsevier B.V. All rights reserved.



Introduction

The fingerprint authentication systems are widely used nowa- days. They are embedded in many commercial systems, such as some laptops and mobile phones. The embedded systems

* Corresponding author. Tel.: +20 2 01006182248. E-mail address: gabahgat@ieee.org (G.A. Bahgat).
Peer review under responsibility of Faculty of Computers and Information, Cairo University.
usually use low cost hardware digital modules such as FPGA [1,2] or DSP [3]. Fingerprint authentication systems are also used in many airport countries worldwide. Besides, their use is very crucial in the forensics field, where the latent in the crime scenes are needed to be recognized. Most of these appli- cations are real-time systems that require the execution of the authentication procedure in a time less than one second. Glo- bal features such as the singular points (SPs), the core and the delta points, are used in the alignment between the two com- pared fingerprints [4–6]. A more reliable point is the core point (CP) that is defined for all types of the fingerprint. Without the alignment, all the minutiae features set, of the two fingerprints, are compared, which is the conventional technique used. But,


1110-8665 © 2013 Faculty of Computers and Information, Cairo University. Production and hosting by Elsevier B.V. All rights reserved. http://dx.doi.org/10.1016/j.eij.2013.01.002

16	G.A. Bahgat et al.


with this alignment, the minutiae feature set is aligned relative to the CP for each fingerprint, thus, reducing the computa- tional time, considerably [7].
The fingerprint consists of line patterns called ridges. The ridges flow smoothly in parallel. They exhibit high curvature at the singular regions (SRs) [8]. There are two types; the loop and the delta shapes as shown in Fig. 1. The loop is the inner- most recurving ridge; the ridge must recurve back to its origi- nating direction. It can exist in two forms as shown in Fig. 2. The upper loop convex part points upwards. An upper core point is defined on the upper loop. It is usually located in the central area of the fingerprint [9]. The lower loop convex part points downwards. It exists only in the presence of an upper loop. Delta region is the region where the ridges flow di- verges into two different directions [4,10]. A delta point is de- fined as the center of the three different directions of the ridge flow [5] as shown in Fig. 1. The upper core point is simply called the core point (CP). There are a number of definitions, presented in the literature, for the CP. It is defined as the top- most point of the innermost ridge line [8]. In other developed



















Figure 1  A fingerprint image with a loop and a delta region.
























Figure 2  Upper and lower loop shapes in a fingerprint image.
work, it is defined as the point with the highest curvature in the fingerprint ridges [11,12]. Henry definition and forensics definitions [14] partially coincide with these definitions except that the CP is defined at the shoulder of the loop away from the delta point. The manual extracted points are always defined on a ridge. The fingerprint images are classified into five classes according to the presence of the SPs [8]. The left loop and the right loop contain one core and one delta point. The whorl type contains two cores and two delta points. The arch type is classified into three subclasses. The tented arch contains one core and one delta points. The up-thrust arch contains no loop, but there is a small sudden change in the ridges. The plain arch does not contain any SPs.
There are several categories of the SP detection methods [8], where the CP is one of the SPs; methods based on the Poincare Index (PI) [15], methods depends on the local characteristics of the ridge orientation [16,17], methods locate the intersection of the different ridge orientation partitions [11], and methods that detect the orientation map and the SPs simultaneously using a mathematical model such as the 2D Fourier Expansion (FOMFE) [18]. The PI method [8] is the classical approach of the SP detection. It is defined as the sum of the orientation change along a closed circle. Depending on this sum value, the presence of a SP and its type is determined. Its advantages are: the simplicity of design, robustness to the image rotation and the determination of the singularity type [19]. But, it is sensi- tive to noise. There are methods that use complex filters to de- tect the points of symmetry in the complex valued tensor orientation field [17]. But their accuracy is low in the CP detec- tion in the arch type fingerprint. A more robust, but complex, filter is recently presented called the semi-radial symmetry filter followed by removing the spurious points using an orientation variation-based feature [20].
A recent category of the CP detection methods are presented in [12,21–23]. This category works on the line appearing in the ridge orientation map, presented by a gray-scale with an angle range of (0° 6 h < 180°). This line is generated from the discon- tinuity between the angle values 0° and 180°. An edge-map based method detects the discontinuous line (DL) using the edge detec- tion method [12,21], it locates the CP by analyzing the orienta- tion consistency around the end points of the DL. The edge- map based method can detect the CP with high speed. Another method locates the CP with the highest curvature value along the DL [22]. Partitioning-based methods are close to this new category [11]. The orientation map is quantized into a specified number of orientation levels, and then the intersection points with these partitions are studied to detect the SPs.
In the direction of using a simple design that is a more con- venient for the hardware implementation, two candidate SP detection methods are presented in [24]. It is based on applying the masking techniques directly on the orientation map. The first uses a (2 · 2 pixels) mask. It is fast, but with a low accu- racy. The second mask is with extra conditions to increase the accuracy. The candidate SP type is checked by a PI with a large radius. Their execution time is less than that of PI method by a factor of 0.12, but with almost the same accuracy. The proposed work detects directly the CP from the orien- tation map, by searching on the end of the DL; where the ori- entation exhibits a certain pattern. Our aim is to scan the orientation map faster to locate the CP in order to use the sys- tem in real-time environment. Besides, the design should be hardware-oriented. The low cost programmable embedded

Fast and accurate algorithm for core point detection in fingerprint images	17


modules, such as FPGA, require a simple design. Thus, the ap- proach used, in the proposed work, applies a masking tech- nique. First, a property is presented and proved to verify the presence of the SR at the end of the DL in the orientation map. Then, the distributions of the orientation values are ana- lyzed at the DL and around the CP, to detect the orientation distribution around the CP, and thus to generate the core mask. The fingerprint image is divided into blocks. Intensity mean and variance thresholding followed by morphological operations are used to segment the fingerprint blocks. The gra- dient-based method [8] is used to measure the ridge orientation map, followed by an adaptive smoothing technique [9] to in- crease its accuracy. Then the CP mask is applied. If more than one point is detected, the orientation consistency, used in the orientation smoothing, is used to choose the point with mini- mum consistency value. If no point is detected, the point with minimum consistency value along the DL is chosen. The CP orientation is measured using the method given in [9]. The mask is tested on the databases: FVC2002 DB1 and DB2 set
(A) [25], and FVC2004 DB1 set (B) [26]. The results show that the proposed mask needs less detection time with less false alarm rate and higher core detection rate than the edge-map based method.
The rest of this paper is organized as follows: Section 2 pre- sents the developed aspect of the singular point detection. In Section 3, the orientation map is analyzed. Section 4 describes the proposed core detection procedure. The experimental re- sults are given and discussed in Section 5. Finally, the conclu- sion is presented in Section 6.
Developed aspect for singular point detection

In this section, a property related to the SP detection is gener- alized, followed by a new property presented that verifies the existence of the SR at the end of the DL.
A property locates the SPs at the intersection of the fault lines [11]; where the fault lines are the lines generated when quantizing the orientation map into a number of levels. The fault lines are the separations between the homogeneous regions as shown in Fig. 3. The property is defined as:

Property 1. ‘‘Fault lines only intersect at the singular points when a directional image is quantized into three directions’’.
The proof of this property is given in [11], where it mentions that as the number of the quantized orientation levels (N) increases, the intersection points become out of focus and














Figure 3 Quantized orientation map (a) by 4 levels, (b) by 9 levels.

the minimum number of levels to obtain the SPs is three (N = 3). Knowing that the fingerprint ridges are not directed, the orientation values are defined in the range of ((0° 6 h < 180°), and a property is introduced that generalizes Property 1 as follows:

Property 2. ‘‘The fault lines intersect at the singular region when an orientation map is quantized into a number of levels greater than two (N > 2)’’.

Proof. The proof is made on the two types of the SR sepa- rately as follows:
The core region is defined in the orientation map as the head part of the innermost loop [22]. Let the orientation value of the points (xc, yc) located on the curving part of the inner- most loop be u(xc, yc). Since, the loop is defined as a continu- ous ridge that recurves back to its original direction [14]; the set of the orientation values on the loop can be given by:
u(xc; yc )= {(HL + 0◦) ... (HL + 180◦)}	(1)
where HL is the orientation angle of the main direction of the
loop. Thus, the orientation values at the curved part of the innermost loop scan all the orientation values. Consequently, the fault lines generated from the quantization of the orienta-
tion map into an infinite number of levels N = ∞, will inter-
sect at the core region.
As for the delta region, it is formed from the divergence of two parallel ridges forming a third directional flow. Since the ridges flow is of continuous slope, then the set of the orienta- tion values of the points (xD, yD) in the delta region can be gi- ven by:
u(XD; YD)= {{ui ... (ui + a)} ∪ {(ui + a) .. . (ui + a + b)}
∪ {(ui + a + b) ... ui}}	(2)
divergence, a ∈ (0◦; 180◦) is the orientation value at the point where ui is the orientation of the two parallel ridges before the and b ∈ (0◦; 180◦) is the orientation value at the point where where the first parallel ridge is parallel to the third direction, the second parallel ridge is parallel to the other part of the
third direction. Thus, the orientation values at the delta region scan all the orientation values. Consequently, the fault lines generated from the quantization of the orientation map into
an infinite number of levels (N = ∞), will intersect at the delta
region. 

The SP is located inside the SR. Due to the limit of the ori- entation measurement, the problem of out of focus occurs as shown in Fig. 3, where the fault lines converge at one point for four levels of quantization (N = 4), but the out of focus oc- curs for nine levels of quantization (N = 9). But it is located into one region. The SP is also located at the ends of the DL generated in the orientation map [12,21,23]. There is a differ- ence between the fault lines and the DLs. The fault lines are the lines generated from quantizing the orientation map into a number of levels, if the number of levels is 2, the fault line will be a continuous line with no end inside the fingerprint area, and if the number of levels is 3, there will be 3 lines inter- secting at the SPs. On the other hand, the DLs are generated from the discontinuity of the orientation values between 0° and 180° only, and thus, they will always end at the SPs (in




18	G.A. Bahgat et al.

is divided into blocks of size w · w; where w is slightly greater than the ridge width. Then, the average orientation ho(i, j), of each block, is calculated. The conventional method, for the orientation map calculation, is the gradient-based method [8]. Its equation is given by:
h	p	1	  2 · Gxy 	(6)
where 0° 6 ho < 180°. Gxy, Gxx, Gyy are computed by averag- ing the x and y gradient components $x and $y respectively), over a window of size w · w, as follows:

b	b
Gxx(x; y)=	∇x(x + hy + k)
(7)

h=—b k=—b
b	b
Gyy(x; y)=	∇x(x + hy + k)2	(8)
h=—b k=—b


Figure 4	Orientation map before smoothing.
b	b
Gxy(x; y)=	∇x(x + hy + k)· ∇y(x + hy + k)	(9)

general). But no theoretical aspect is given for such hypothesis. To overcome this shortage, the following new property is introduced and proved as follows:

Property 3. ‘‘The singular region of a fingerprint is located at the end of the discontinuous line of the orientation map provided that the ends are not located on the fingerprint border’’.

Proof. The line generated from the discontinuity of the orien- tation map around values 0° and 180° can be defined by the following two regions:
Ra : ha(Xa; Ya) where (0◦ 6 ha(Xa; Ya) 6 a◦)	(3)
Rb : hb(Xb; Yb) where (b◦ 6 hb(Xb; Yb) < 180◦)	(4)
where the region Ra of orientation values ha(xa, ya) at one side
of the DL, the other region Rb is of orientation values hb(xb, yb) are at the other side of the line, and a < b. The end of this line will be at a third region Rc of orientation values defined by:
Rc : hc(Xc; Yc)where(a◦ < hc(Xc; Yc) < b◦)	(5)
From the core region Eq. (1) and the delta region Eq. (2), the
SR contains the three regions ((3)–(5)). Thus, the SR is located at the end of the DL. h
Fig. 4 shows the location of the core point and the delta point at the end of the DL.

Orientation map analysis

The local ridge orientation is defined as the angle h(x, y) made by the ridges (or the ridges and valleys [4]), crossing through a small neighborhood centered at point (x, y), with the horizon- tal axis. The orientation h(x, y) can be calculated on each pixel in the fingerprint image, thus forming an orientation map that is called a high resolution map [4]. The neighborhood will overlap in this case. For less computational time, the orientation can be calculated block-wise, such that the image
h=—b k=—b
the block (i, j), $ is the simple Sobel filter [27], b = (w/2—1). w where x and y are the pixel coordinates of the center point of should be an odd number to calculate the average on a normal
distribution over the window. Ref. [6] also supports choosing the window size to be an odd integer to avoid the bias in dis- crete computation. The ridge orientation map is shown in Fig. 4 in a gray-scale presentation. The axis of the orientation values is the standard axis; the x-axis points to the right and the y-axis points upwards. It is also displayed by short lines on the fingerprint image as shown in Fig. 5.
An adaptive smoothing technique [9] based on the orienta- tion consistency is used to increase the accuracy of the orienta- tion map, and, consequently, increase the accuracy of the CP detection. It smoothes the orientation map and, at the same time, does not affect the accuracy of the CP location. The ori- entation consistency describes how well the ridge orientations, in a neighborhood, are consistent with the dominant orientation in the neighborhood. The SP is located at the local






















Figure 5  A zoomed version of Fig. 1 around the singular points.

minima of the orientation consistency. The smoothed orienta- tion map is obtained by [9]:

1	0B
(k;Xl)∈X(s)
sin(2ho(k; l))1C

hs(i; j)= 2 arctanB@ X
cos(2h (k; l))CA	(10)
200

(k;l)∈X(s)
where, hs(i, j) is the smoothed orientation of the block (i, j) and
X(s) is the surrounding neighborhood of the block, which is defined by the (2s + 1) · (2s + 1) outside surrounding blocks, and s is the consistency level. The orientation consistency equation is given by:
vuﬃ ﬃﬃﬃﬃﬃﬃﬃXﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ!ﬃﬃﬃﬃ2ﬃﬃﬃﬃﬃﬃ ﬃﬃﬃﬃﬃﬃﬃXﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ!ﬃﬃﬃﬃ2ﬃ
100
0
0
20

80
60
40	40
60	20
80 0

cons(i; j; s)= t
(k;l)∈X(s)
cos(2ho(i; j))	+
M
(k;l)∈X(s)
sin(2ho(i; j))
(11)
Figure 7	3D graph of the orientation map. The x and y axes are the dimensions of the fingerprint image.

where M is the number of the surrounding blocks. The
smoothed orientation map is shown in Fig. 6. A 3D graph of the smoothed orientation map is displayed at Fig. 7. The origin is equivalent to the left upper corner in Fig. 6 and the z-axis represents the orientation values in degrees. The CP is sur- rounded by a white circle. It has a circular ramp shape.
The orientation values, at the sides of the upper DL of a high resolution version of Fig. 6, are shown in Fig. 8. The sam- ples, beginning from the upper point till the CP, are plotted. From the figure, it can be shown that the right side, of the upper DL, has an average value near 180°. The left side of the line has an average value near 0°. The orientation values, of the sides of the DL, converge when getting close to the CP. The point of convergence is where the two sides of the loop are parallel; and so they have the same orientation values. The CP is at the sample 143 in Fig. 8. It is the location where the orientation value increases gradually from the low value,

3.5

3

2.5

2

1.5

1

0.5

0


0	50	100	150
The position of the meausred point on the DL

near 0° values, till 90°. Then, the orientation values continue to increase when recurving back to the other side of the DL, near 180° values in a counterclockwise direction. This analysis
Figure 8	The orientation values along a discontinuous line.








Figure 9	The orientation values at the CP (in radians) showed on an orientation map.














Figure 6	Smoothed orientation map. The CP is circled.
of the CP is consistent with the analysis presented on the orientation field of a zero-pole model [15].
The orientation values of the blocks around the CP are shown in Fig. 9. The upper middle block has a value near 0° and the upper right block has a value near 180°. The three low- er blocks values are near, which is equivalent to the parallel sides’ part of the loop. The orientation values increases in a counterclockwise direction in the blocks around the CP from near 0° to near 180°. This orientation pattern is satisfied for all the CPs extracted manually from the learning set of images (set B) from the database FVC2002 DB1. A sample of these



pattern values are shown in Fig. 10. Fig. 10a displays the ori- entation values above the CP, where the values are either high (160° 6 ho < 180°) or low (0° 6 ho < 50°). Fig. 10b displays the orientation values along the left side of the CP. The values range is (18° 6 ho < 120°), with an average around 60°. Fig. 10c displays the orientation values below the CP, where the values average increased, with an average around 80°. There are peaks near 0° and 180°. These extreme values appear when the CP is located at a low quality region. They represent a noise. Fig. 10d displays the orientation values along the right side of the CP, where the average of the values is increased, with an average around 100°. The orientation values range is broad because the loop can be of the left type or the right type. Thus, the parallel sides of the loop can points to the left or points to the right, respectively. These orientation values are consistent with the proof of Property 3. The DL can be consid- ered as the tangent point of an imaginary horizontal line touching the ridge lines. Thus, the end of the DL is at the peak of the innermost loop; the upper CP.
Our aim is to use a fast technique in detecting the CP. This can be achieved by designing a mask that scans the orientation map for the detected orientation pattern, mentioned, around the CP. The mask parameters are generated from the distribu- tion of the orientation values around the CP as shown in the following section.
Proposed core point detection

In this section, the proposed mask is presented, and then the whole procedure of the CP detection is given. The presented core detection mask searches on the lower end of the upper DL in the ridge orientation map that is equivalent to the peak point on the upper innermost loop.
The construction of the proposed mask

A mask set arranged in a square shape is presented, as shown in Fig. 11a. The length of this square shape is n. It is applied on the segmented smoothed orientation map hss The CP mask val- ues are generated after analyzing the orientation distribution around the CP (Fig. 10), while neglecting the peaks that could be generated by noise in the CP region. As an example for illustration, the structure of the CP mask is given in Fig. 11b. This figure illustrates the outer blocks arranged in an anti-clockwise direction from R1 to R16. The operation of the proposed mask is as follows:

For each segmented smoothed orientation hss(i, j) block, the orientation values of the surrounding blocks h(Rk), are checked if it is in the determined range or not according to the following equation:



180
160
140
120
100
80
60
40
20
00	10	20	30	40	50	60	70	80
Image label
(a)
180
160
140
120
100
80
60
40
20
00	10	20	30	40	50	60	70	80
Image label
(c)
140

120

100

80

60

40

20

00	10	20	30	40	50	60	70	80
Image label
(b)
180
160
140
120
100
80
60
40
20
00	10	20	30	40	50	60	70	80
Image label
(d)


Figure 10	The distribution of the orientation values for selected blocks around the core point. (a) Upper block, (b) left block, (c) lower block and (d) right block.


	
(a)	(b)

Figure 11	The proposed mask set structure. (a) The general structure on the orientation map with size n, (b) the surrounding blocks tested by the mask set for n = 5.




Rk : Ck
=	1	if Lk 6 h(Rk) < Hk	(12)
0  otherwise

where k is the index of the block in the mask set, Ck is the out- put of the conditional operation, Lk is the lowest allowed ori- entation value for the block Rk, and Hk is the value, below which the orientation value for the block is allowed. The num- ber of blocks that satisfy the required range is counted accord- ing to the following equation:
4(n—1)
A(i; j)=   Ck	(13)
k=1
where A(i, j) is the accumulation of the conditional mask re-
((n · n)—1), a primary CP block is detected. sponse for the block (i, j). If the result is equal to (n · n), or
If there is one or more primary CP block detected, go to step 3. Otherwise, the CP is considered absent, which is the case of the arch type, and go to step 4.
If there is one detected CP block, the coordinates of the CP block (iCP, jCP) is transferred into the CP location in (xCP, yCP) pixel as follows:






Figure 12	Block diagram of the core point detection using the proposed mask.



xcp = icp × w ycp = jcp × w
(14)

If there is more than one CP block, the block with mini-
mum consistency value given in (11) is chosen to be the CP according to the following equation:
CPblock = (iCP; jcp)= argmin{cons(i; j) : A(i; j)= a}	(15)
i;j
Then, end.

The DL is detected by the edge detection method given in [12], and the CP is defined as the point located on the DL with minimum consistency value by (15), followed by (14) to obtain the final location of the CP.

The core point detection procedure


The CP detection procedure is as shown in Fig. 12. The finger- print image is divided into blocks of size w · w. Then, the
Figure 13	The orientation map after applying the segmentation mask.



segmentation is applied on each block. The segmentation is de- fined as the separation between the fingerprint areas (fore- ground) from the image background. It is applied on the orientation map to prevent the false detection of the CP. The mean of each block is calculated relative to the global mean of the image and the variance of each block is calculated rela- tive to the difference between the global, maximum and mini- mum, variance value. The block is segmented if the relative mean is less than an upper limit (mth), and the relative vari- ance is smaller than a lower limit (vth). Morphological opera- tions are applied that include dilation and erosion to fill the holes in the foreground and isolate the points in the back- ground [19]. The structuring element size is (str). The seg- mented smoothed orientation map is given in Fig. 13. The parameters are chosen based on a minimum error procedure. The gradient-based method [8] is applied on each block, as given in equations ((6)–(10)) with averaging window size w · w. An adaptive smoothing technique [9] using (11) is used to smooth the orientation map. The proposed CP mask set, of size n · n blocks, scans the segmented orientation map. Then, the CP orientation is calculated using the method given in [9].

. Experimental results and discussion

The FVC2002 databases [25], DB1 and DB2, and FVC2004 [26] DB1 set (B) are used to test the performance of the CP detection methods. The fingerprints in FVC2002 DB1 and FVC2004 DB1 are taken by an optical sensor, with a resolution of 500 · 500 dpi. The images size is 500 · 500 pixels for FVC2002 and 640 · 480 for FVC2004. DB2 database is taken by a capac- itive sensor, with the same resolution. The images size is 256 · 364 pixels. The databases contain two sets. Each set con- tains 8 impressions. The 8 impressions are taken in different skin conditions; normal, dry and wet conditions. The learning set FVC2002 DB1 set (B) is used to determine the threshold values of the segmentation method, and to measure the orientation val- ues around the CP, and thus, the proposed mask parameters are designed. The testing set is taken FVC2002 DB1 set (A) and DB2 set (A), and FVC2004 DB1 set (B).
The fingerprint images is divided into blocks of size w = 5 pixels [9]. This size is slightly greater than the ridge width. To select suitable values for the segmentation parame- ters. The segmentation method parameters (mth, vth and str) differs in each database. A manual segmentation of 16 images
from FVC2002 set (B) is done. The segmentation parameters are chosen to minimize the error between the manual seg- mented blocks and the blocks segmented using the segmenta- tion algorithm. The parameters values are: mth = 5, vth = 0.1 and str = 3 pixels.
The CP pattern size tested is 3 · 3 and 5 · 5 blocks. The mask size of 3 · 3 pixels (n = 3) is sensitive to noise. Its accuracy is lower than the edge-map based method. Thus, the proposed mask size is taken 5 · 5 (n = 5) pixels as shown in Fig. 11. The orientation values limit of each block hL(Rk)= [Lk, Hk], are given in degrees as follows: hL(R1) = {[0, 50] U [120, 180]}, hL(R2) = [0, 80],   hL(R3) = [15, 90],   hL(R4) = [15, 95],
hL(R5) = [15, 100],  hL(R6) = [20, 120],  hL(R7) = [20, 115],
hL(R8) = [25, 125], hL(R9) = [40, 140], hL(R10) = [40, 150],
hL(R11) = [40, 160], hL(R12) = [40, 165], hL(R13) = [60, 175],
hL(R14) = [100, 180], hL(R15) = [122, 180] and hL(R16) =
{[120, 180] U [0, 40]}.
The accuracy of the CP detection methods are measured by the following measures:
Core detection rate: It is the ratio of the number of the CPs detected by the algorithm, to the number of the CPs
detected manually.
False alarm rate: It is the ratio of the number of the false CPs detected by the algorithm, to the number of the CPs
detected manually. The false points are far from the CP location.
Fingerprint correct detection rate: It is the ratio of the num-
ber of fingerprints, with correctly detected one CP using the
algorithm, to the total number of the fingerprints.

The location of the detected CPs is compared with the man- ual inspected CPs. The Euclidian distance between the manu- ally located CP position and the position calculated by the algorithm is defined as the distance error of the CP location [9,20]. If the distance error is less than the ridge-to-ridge dis- tance, approximately 10 pixels, the localization is considered to be accurate assuming that the error is caused by the human vision. If the distance error is between 10 and 20 pixels, the dis- tance error is considered as a small error that can be caused by both the human vision and the algorithm. If the distance error is between 20 and 40 pixels, it is considered as a significant er- ror, which may affect the subsequent processing steps. If the distance is larger than 40 pixels, the CP is considered a false de-



1	1

0.8	0.8

0.6	0.6


0.4

0.2

0
0	20	40	60	80
Allowed distance error
(a)
0.4

0.2

00	20	40	60	80
Allowed distance error
(b)


Figure 14	The experimental results of the FVC2002 databases, (a) DB1B and (b) DB2B.






1


0.8


0.6


0.4


tected point. In order to demonstrate the performance of our method, we compare the performance of the proposed CP detection method with that of the fast edge-map based meth- od, which is the same category of the proposed method. The performance comparison is shown in Fig. 14 between the pro- posed mask without the DL detection, for FVC2002 DB1 and DB2 set A databases. The accuracy increases by increasing the allowed distance error, then it begins to approximately satu- rate after a 40 pixels distance error. The proposed mask accu- racy outperforms the results of the edge-map based method. Also, the performance comparison is also shown in Table 1 with the addition of the DL detection. FVC2004 database con- tains more arch type fingerprints, thus, the proposed method including the DL detection performs better. The mask pro- vides a less false alarm rate and a higher core detection rate, for allowed distance error greater than 10 pixels. The latency of detection is taken by a length of less than 40 pixels. The experimental results show that the proposed method exhibits an increase in the correct CP detection rate per fingerprint, by 14.78% in FVC2002 DB1 (A), 29.57% in FVC2002 DB2
(A), and 7.7% in FVC2004 DB1 (B) compared to the edge-map based method, besides, a reduction in the false alarm rate by 66.63% in FVC2002 DB1 (A), 58.5% in FVC2002 DB2
(A), and 28.57% in FVC2004 DB1 (B). Moreover, the average execution time of the CP detection methods per fingerprint is also shown in Table 2. It is reduced by the proposed method by a factor of 1.99 in FVC2002 DB1 (A), 2.27 in FVC2002 DB2 (A), and 1.19 in FVC2004 DB1 (B). The accuracy of the CP orientation, according to the method given in [9], is shown in Fig. 15. A detected CP on the orientation map is shown in Fig. 16. The methods are implemented by MATLAB and are executed on Intel(R) Core(TM) i3 CPU
2.27 GHZ.
The proposed method is more immune to noise. It is more accurate because the proposed mask checks more conditions
0.2


0
0	pi/16	pi/8	pi/4
Allowed angle difference
Figure 15	Experimental results of the core point orientation on FVC2004 DB1 (B).























Figure 16	A detected CP by the proposed mask on an orientation map.

on the orientation map around the CP. Besides, the design of the mask, which is based on matching conditions, rather




24	G.A. Bahgat et al.

References
























Figure 17	Detected CP in a fingerprint up-thrust arch type.


than performing operations on the orientation data, decreases the execution time. This would be more suitable for the digital hardware implementation. The mask achieves better core detection even without segmentation, compared to the edge- map based method. But the false alarm rate is increased. The proposed method detects the CP for, the tented and the up- thrust arch type as shown in Fig. 17. The addition of the DL detection to the mask increases the accuracy, but reduces the execution time. The CPs, located at the fingerprint border or outside the border (not present in the fingerprint image), are considered absent. In this case, it is assumed that the alignment will be made using the conventional technique. The total num- ber of manually extracted CPs in FVC2002 is: 779 in DB1A, and 754 in DB2A out of 800 images, and 80 images in FVC2004 DB1B. The main error cause is generated by the dis- torted areas in the fingerprint images, which cause an error in the orientation map.

Conclusion

The singular region location, at the end of the discontinuous line of the orientation map, is verified using a proved property. The orientation around the core point is analyzed. A proposed mask for the core point detection has been developed. It is characterized by scanning the ridge orientation map of the fin- gerprint image directly. Thus, the execution time is reduced by an average factor of 1.8 and the mask suites for the real-time applications. The mask design depends on a simple computed procedure that is easier and more feasible for the hardware implementation. It is more immune to noise, since it exhibits an average increase in the correct core point detection rate per fingerprint, by 17.35% for the tested databases that is formed of images with different sensors and image sizes. More- over, there is an average reduction in the false alarm rate by a 51.23%, compared to a fast edge-map based method.
Arjona R, Baturone I, A digital circuit for extracting singular points from fingerprint images. In: Eighteenth IEEE international conference on electronics, circuits and systems (ICECS), Lebanon; 2011. p. 627–30.
Neji N, Boudabous A, Hahrrat W, Masmoudi N. Architecture and FPGA implementation of the CORDIC algorithm for the fingerprint recognition systems. In: Eighth international multi- conference on systems, signals and devices (SSD), Tunisia; 2011.
p. 1–5.
Su XH, Yin LQ, Gao L, Zhang ZX. The design of fingerprint identification system based on TMS320VC5402. Adv Mater Res J 2012;542–543:1339–42.
Bazen AM, Gerez SH. Systematic methods for the computation of the directional fields and singular points of fingerprints. IEEE Trans Pattern Anal Mach Int 2002;24(7):905–19.
Park CH, Lee JJ, Smith MJT, Park KH. Singular point detection by shape analysis of directional fields in fingerprints. Pattern Recogn 2006;39(5):839–55.
Chaglong J, Hakil K. Pixel-level SP detection from multi-scale gaussian filtered orientation field. Pattern Recogn 2010;43(11):3879–90.
Chan KC, Moon YS, Cheng PS. Fast fingerprint verification using subregions of fingerprint images. IEEE Trans Circ Syst Vid Technol 2004;14(1):95–101.
Maltoni D, Maio D, Jain AK, Prabhakar S. Handbook of fingerprint recognition. 2nd ed. Springer; 2009, chapter 3.
Liu M, Jiang X, Kot AC. Fingerprint reference point detection. EURASIP J Appl Signal Process 2002;4:498–509.
Dass SC. Markov random field models for directional field and singularity extraction in fingerprint images. IEEE Trans Image Process 2004;13(10):1358–67.
Huang CY, Liu LM, Hung DCD. Fingerprint analysis and singular point detection. Pattern Recogn Lett 2007;28(15): 1937–45.
Cao G, Sun QS, Mao Z, Mei Y. Detection of core points in fingerprint images based on edge map. In: International confer- ence on electronic computer technology (ICECT), Macao; 2009.
p. 126–9.
Hoover J. The science of fingerprints classification and uses, Federal Bureau of Investigation; 2006.
Weng D, Yin Y, Yang D. Singular point detection based on multi- resolution in fingerprint images. Neurocomputing 2011;74: 3376–88.
Wang X, Li J, Niu Y. Definition and extraction of stable points from fingerprint images. Pattern Recogn 2007;40(6):1804–15.
Chikkerur S, Ratha N. Impact of singular point detection on fingerprint matching performance. In: Workshop on automatic identification advanced technologies; 2005. p. 207–12.
Wang Y, Hu J, Phillips D. A fingerprint orientation model based on 2D fourier expansion (FOMFE) and its application to singular-point detection and fingerprint indexing. IEEE Trans Pattern Anal Mach Int 2007;29(4):573–85.
Zhou J, Chen F, Gu J. A novel algorithm for detecting singular points from fingerprint images. IEEE Trans Pattern Anal Mach Int 2009;31(7):1239–50.
Le T, Van H. Fingerprint reference point detection for image retrieval based on symmetry and variation. Pattern Recogn 2012;45(9):3360–72.
Cao G, Mao Z, Sun QS. Core-point detection based on edge maps in fingerprint images. J Electron Imaging 2009;18(1):1–4.
Mohammadi S, Farajzadeh A. Reference point and orientation detection of fingerprints. In: Second international conference on computer and electrical engineering (ICCEE), United Arab Emirates; 2009. p. 469–73.



Ahmadyfard A, Nosrati MS. A novel approach for fingerprint singular point detection using 2 D-wavelet. In: International conference on computer and system and applications (AICCSA), Jordan; 2007. p. 688–91.
Bahgat GA, Khalil AH, Mashali S. Singular point detection using a matching candidate in fingerprint images. In: First international conference on new paradigms in electronics and information technologies (PEIT011), Egypt; 2011.
http://bias.csr.unibo.it/fvc2002/ (accessed January 2010).
http://bias.csr.unibo.it/fvc2004/ (accessed December 2012).
Gonzalez RC, Woods RE. Digital image processing, 2nd ed.; 2001. [chapter 3].
