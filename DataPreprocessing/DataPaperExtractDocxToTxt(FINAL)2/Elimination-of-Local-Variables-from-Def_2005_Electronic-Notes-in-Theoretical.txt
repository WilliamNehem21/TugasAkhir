Electronic Notes in Theoretical Computer Science 137 (2005) 5–24	
www.elsevier.com/locate/entcs


Elimination of Local Variables from Definite Logic Programs *
Javier A´lvez 1	and Paqui Lucio 2
Departamento de Lenguajes y Sistemas Inform´aticos Universidad del Pa´ıs Vasco
San Sebasti´an, Spain

Abstract
In logic programming, a variable is said to be local if it occurs in a clause body but not in its head atom. It is well-known that local variables are the main cause of inefficiency (sometimes even incompleteness) in negative goal computation. The problem is twofold. First, the negation of a clause body that contains a local variables is not expressible without universal quantification, whereas the abscence of local variables guarantees that universal quantification can be avoided to compute negation. Second, computation of universal quantification is an intrinsically difficult task. In this paper, we introduce an effective method that takes a definite logic program and transforms it into a local variable free (definite) program. Source and target programs are equivalent w.r.t. three-valued logical consequences of program completion. In further work, we plan to extend our results to normal logic programs.
Keywords: local variables, logic programming, program transformation.


Introduction
Local variables are very often used in logic programs to store intermediate results that are passed from one atom to another in a clause body. It is well- known that local variables cause several problems for solving negative goals, since they give raise to unavoidable universal quantification in the negation of a clause body. Depending on the LP or CLP approach, universal quantification

 This work has been partially supported by Spanish Projects TIC 2001-2476-C03 and TIN2004-079250-C03-03.
1 Email: jibalgij@si.ehu.es
2 Email: jiplucap@si.ehu.es



1571-0661 © 2005 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2005.01.037


affects simple goals or constrained goals. In the so-called intensional negation (cf. [2]) for the LP approach, universal quantification prevents from achieving a complete goal computation mechanism. Afterwards, constructive negation was introduced in [4,5] and extended in [8,16] to a complete and sound op- erational semantics for the whole class of normal logic programs in the CLP framework. Intensional negation was also extended to CLP in [3] where a complete operational semantics is provided. The computational mechanisms proposed in [3,8,16] deal with universally quantified (constrained) goals that, in general, are not easy to compute in an efficient manner. Besides, the nega- tion technique is introduced in [14] and local variable absence is claimed as a sufficient condition for the completeness of the technique.
In this paper, we present an effective transformation method for eliminat- ing local variables from definite logic programs. The underlying aim is to im- prove the performance of a practical implementation of constructive negation (cf. [1]). Efficiency is achieved because: (1) the negative query is computed
w.r.t. an equivalent definite logic program that does not contain any local variable, hence universal quantification is avoided; and (2) the target program is built at compilation time. We would like to remark that the transformed program (without local variables) must only be used to compute negative lit- erals, using the original one for positive literals. Source and target programs are equivalent w.r.t. the standard Clark-Kunen semantics for normal (in par- ticular, definite) logic programs. In further work, we plan to extend our results to normal logic programs.
Our method is unfold/fold-based in the sense that its correctness is given by an unfold/fold transformation sequence. Besides, the transformation relies in a preliminary partition of the argument positions inside the atoms. This partition, called mode speciﬁcation, associates a mode (input/output) to each argument position. Mode specifications are automatically inferred according to the local variables that are going to be eliminated. The mode specifica- tion is only used during local variable elimination and it has neither to do with restricting user-goals nor with the dataflow that is assumed by the pro- grammer. Mode analysis and specification is used for several purposes such as compiler optimization, parallel goal-evaluation, etc. (for instance, [7,10]), which are far from the aim of this work. The elimination method requires a previous syntactical normalization of the program with respect to its local variable occurences.
Outline of the paper. In the next section, we give some preliminary defi- nitions. Program normalization is presented in Section 3. The fourth section introduces the notion of mode specification. In Section 5, we show how to eliminate the local variables from a definite program in several phases. Fi-


nally, we give some conclusions and reflections about the presented, future and related work.

Preliminaries
Every program P is built from symbols of a signature Σ ≡ {FS Σ, PS Σ} of function and predicate symbols respectively, and variables from X. Both function and predicate symbols have associated a number n ≥ 0, called its arity. A Σ-term is either a variable or a n-ary function symbol of FS Σ applied to n Σ-terms. A bar is used to denote tuples, or finite sequences, of objects, like x as abbreviation of the n-tuple of variables x1,... , xn. Concatenation of sequences is denoted by the infix operator . and ⟨ ⟩ stands for the empty sequence. We use the symbols \ and ∩ as binary infix operators for differ- ence and intersection over sequences respectively, with the obvious meaning. From now on r, s, t, u denote terms and x, y, z variables, possibly with bar and sub/super-scripts.
A substitution σ is a mapping from a finite set of variables, called its domain, into a set of terms. It is assumed that σ behaves as the identity for the variables outside its domain. As usual, functional composition of substitutions is denoted by their juxtaposition. The most general uniﬁer of a set of terms
{s1,... , sn}, denoted by mgu(s), is an idempotent substitution σ such that σ(si) ≡ σ(sj) for all 1 ≤ i, j ≤ n and for any other substitution θ with the same property, θ ≡ σ'σ holds for some substitution σ'.
A Σ-atom p(t) is a n-ary predicate symbol p ∈ PS Σ applied to a n-tuple of Σ-terms t; we say (in abuse of language) that p(t) is an n-ary atom. We also use the two logical constants True and F alse as atoms. Form(Σ) stands for the set of first-order Σ-formulas that can be built using predicate symbols from PS Σ∪{=}, connectives form {¬, ∧, ∨, →, ↔} and quantifiers from {∀, ∃}. The universal closure of a formula ϕ is denoted by ϕ∀. The three-valued logical consequence relation between set of Σ-formulas and Σ-formulas is denoted by the infix symbol |=3.
A (definite) clause C is an expression of the form a : − K where a (head) is an atom and K ≡ a1,... , am (body) is a conjunction of atoms ai for 1 ≤ i ≤ m. When the body is empty (or equivalent to True), the clause a is called a fact. Let α be any syntactic object, we denote by Var (α) the sequence of all the variables that occur in α. In a clause, a variable is local if it occurs in its body but not in its head. Local variables are divided into auxiliary and isolated depending on the number of atoms where they occur in. An auxiliary variable occurs in more than one atom, whereas an isolated variable occurs in just one atom. Anyway, every (non-auxiliary) local variable can be transformed into


an auxiliary variable (see next section). For α being a clause or any object (atom, term, etc) that occurs in a clause, we denote by AuxVar (α) the set of auxiliary variables in α. Similarly, Aux Var (α) denotes the set of non-auxiliary variables.
A (definite) program P is defined by a collection of (definite) clauses. We use the term Σ-program whenever the signature is relevant. For a predicate p, we denote by DefP (p) the set of all clauses in P with head p. All definitions in this paper are given modulo reordering of the clause bodies and standardiza- tion apart is always assumed. Given p, q ∈ PS Σ and a Σ-program P , we say that p directly depends on q if q occurs in some clause in DefP (p). By reflexive transitive closure of this relation, we obtain the set DpdP (p) such that, w.r.t. program P , p depends on all predicates in DpdP (p) (p ∈ DpdP (p) for every p). Besides, MRP (p) ≡  {q | q ∈ DpdP (p) and p ∈ Dpd P (q)} is the set of all mutu-
	
The standard declarative meaning of normal (in particular, definite) logic programs is the program completion (proposed by Clark in [6]), interpreted in three-valued logic (as proposed in [11]), that is also known as Clark-Kunen se- mantics. The predicate completion formula of a predicate p such that DefP (p) ≡
{p(ti) : − qi(si)|i ∈ 1..m} is the sentence:

∀x( p(x) ↔  ∃yi(x = ti ∧ qi(si)) )
i=1

where each yi ≡ Var (ti) . Var (si). The Clark’s completion of a program P , namely Comp(P ), consists of the universal closure of the set P ∗ of the pred- icate completion formulas for every p ∈ PS Σ together with the free equality theory FET (Σ). Program transformation preserves some equivalence relation on programs. Different equivalence relations are induced by the different se- mantics (see [12] for a systematic comparison). Since we plan to extend our results to normal programs, we are interested in completion semantics. Shep- herdson’s operators TP and FP (for a program P ) were introduced in [15] and provide a characterization of the three-valued logical consequences of program completion.
Definition 2.1 ([15]) Let p ∈ PS Σ be deﬁned by a set of clauses DefP (p) as above:

TP (p(x)) ≡ F alse	TP


(p(x)) ≡   ∃yi(x = ti ∧ TP (qi(si)))

0	n+1
n
i=1 m

FP (p(x)) ≡ F alse	FP
(p(x)) ≡  ¬∃yi(x = ti ∧ ¬F P (qi(si)))

0	n+1
n
i=1


where yi ≡ Var (ti) . Var (si). Besides, T ( True) ≡ True and F ( True) ≡ F alse
n
for all n. The extension to connectives and quantiﬁers is the obvious one. 
Notice that TP (p(x)) and FP (p(x)) are formulas (in first-order logic with
k	k
equality) that represent the successes and failures of the atom p(x) which can
be derived from P in k steps. Facts produce the one level successes since their clause body is True.
Theorem 2.2 For any normal (in special, deﬁnite) program P and any sen- tence ϕ, Comp(P ) |=3 ϕ ⇔ there exists n ∈ N such that FET (Σ) |=3 TP (ϕ).

Proof. Lemma 4.1 in [15] proves the equivalence Φn
|=3 ϕ ⇐⇒ FET (Σ) |=3

TP (ϕ) for all n ∈ N, where Φn
is the n-iteration of Fitting’s immediate con-

n	P
sequence operator ΦP (cf. [9]). Besides, Kunen’s Theorem 6.3 in [11] proves
that Comp(P ) |=3 ϕ ⇐⇒ there exists n ∈ N such that Φn |=3 ϕ.	 
As a consequence, the three equivalence relations that are induced on the set of programs by Fitting’s and Shepherdson’s operators and by logical con- sequence of program completion have the same strength. TF -equivalence is a useful representative of these three notions. Below, we give a more precise def- inition of the TF -equivalence (∼=TF ) relation on programs. A strictly stronger equivalence relation is given by logical equivalence of program completions. That means to require FET (Σ) |=3 Comp(P1) ↔ Comp(P2) for the equiva- lence of the programs P1 and P2. The interested reader is referred to [12] for an example of TF -equivalent programs whose completions are not logically equivalent.
Definition 2.3 Let P1 and P2 be two Σ-programs:

P1 ≤TF P2 iff for all p ∈ PS 1
∩ PS 2
and for all k ∈ N, there exists

k' ∈ N such that FET (Σ) |= (TP1 (p(x)) → TP2 (p(x)) ∧ FP1 (p(x)) →

FP2 (p(x)))∀
3	k	k'	k

P1 =∼TF P2 iff P1 ≤TF P2 and P2 ≤TF P1.	 
Intuitively, TF -equivalent programs have equivalent sets of answers, but not necessarily obtained at the same iteration step. We transform a Σ-program into a TF -equivalent Σ'-program without local variables where Σ' ⊇ Σ.

Normalization
Program normalization is a preliminary treatment of the local variables occur- rences which enables the subsequent elimination method. Here, we explain in detail the syntactic requirements of normalization and we also show that any definite logic program can be transformed into a TF -equivalent normalized

one.
The syntactic restriction affects single clauses.

Definition 3.1 A clause C ≡ p(t) : − q1(s1),... , qn(sn) is normalized iff it satisﬁes the following two conditions:
Every local variable y exactly occurs in the atoms qi−1(si−1) and qi(si) for some 2 ≤ i ≤ n and does not occur anymore in C
Let mi be the arity of the predicate qi then, for every 2 ≤ i ≤ n − 1 and every 1 ≤ j ≤ mi, either AuxVar (si ) ⊂ AuxVar (si−1) or AuxVar (si ) ⊂
j	j
AuxVar (si+1).	 
Then, normalization is extended from clauses to programs in the obvious way.

Definition 3.2 A program P is normalized iff every clause C ∈ P is normal- ized.	 
Theorem 3.3 Every deﬁnite logic program P can be transformed into a TF- equivalent normalized program P '.

Proof. Let suppose that the clause C ≡ p(t) : − q1(s1),... , qn(sn) ∈ P is not normalized. Then, there are two possibilities, depending on the condition in Definition 3.1 that does not hold.
If condition (i) does not hold, there exists at least a local variable y that violates it. Let qi(si) (1 ≤ i ≤ n) be the leftmost atom of C where the local
variable y occurs in. We replace the atom qi+1(si+1) with q'	(ri+1) where:

'
i+1
is a new predicate

ri+1 ≡ si+1 . y . y'
y' is a new local variable.
The definition of the new predicate q'


is given by the clause q'


(z') ≡ qi+1(z)

where z' ≡ z . x . x and x /∈ z. In addition, we replace the atom qk(sk) with qk(sk)[y'/y] for every i +2 ≤ k ≤ n. Note that for i = n, we only need to add a new atom p'(y) where p' is a new predicate that is defined by the single clause p'( ). The local variable y does already satisfy the first condition, since it occurs in two consecutive atoms and does not occur anymore in the clause. The process ends since either the number of local variables which violate the condition (i) decreases (that is, y' satisfies the condition (i)) or this number does not decrease but the new local variable y' occurs in the atom that is one step closer to the end of the clause body. Besides, source and target programs are proved to be TF -equivalent by unfolding the new atoms.
If condition (ii) is violated, we suppose (without loss of generality) that condition (i) holds for every clause in the program. Then, let qi(si) be the left-

most atom of C such that for some 1 ≤ j ≤ m (being m the arity of the pred- icate qi) AuxVar (si ) ∩ AuxVar (si−1) /≡ ∅ and AuxVar (si ) ∩ AuxVar (si+1) /≡ ∅.
j	j
We replace the atom qi(si) with q'(ri) where:
q' is a new predicate
x ≡ AuxVar (si ) ∩ AuxVar (si−1),
ri ≡ ti . x . x',
x' is a tuple of new variables that corresponds with x
ti is obtained by substituting si [x'/x] for si in si.
j	j
The definition of q' is given by the clause q'(z') : − qi(z) where z' ≡ z . x . x and
i	i
x ∩ z ≡ ∅. In addition, we replace the atom qi+1(si+1) with q'	(ri+1) where

'
i+1
is also a new predicate and ri+1 ≡ si+1 . x'. The definition of the predicate

'
i+1
is given by the clause q'	(z') : − qi+1(z) where z' ≡ z . x and x ∩ z ≡ ∅. In

the resulting clause C', the term ri in the atom p'(ri) satisfies the condition (ii)
j	i
since now AuxVar (ri ) ⊂ AuxVar (ri+1) and AuxVar (ri) ∩ AuxVar (ri−1) ≡ ∅.
j	j

Furthermore, the new introduced tuples of terms in atoms q'(ri) and q'
(ri+1)

i	i+1
also satisfy the condition (ii). Besides, condition (i) is preserved in the clause
C'. This process also ends since the number of terms that violate the condition
(ii) strictly decreases at each step. As above, the programs P and P ' are proved to be TF -equivalent by unfolding the new atoms.	 



As a consequence, the problem of local variable elimination is reduced to auxiliary variable elimination. From now on, normalization is always assumed in programs. In particular, normalized programs does not contain any isolated variables. Moreover, every auxiliary variable always occurs in two consecutive atoms in a normalized clause.
Example 3.4 Consider the following program P:
E3.4.1 : preorder(nil, [ ])
E3.4.2 : preorder(tree(x1, x2, x3), x4) : − preorder(x2, y1), preorder(x3, y2), append([x1|y1], y2, x4)
The clause E3.4.2 is not normalized because the local variable y1 does not sat- isfy the condition (i) of Deﬁnition 3.1. We obtain a TF-equivalent normalized program by substituting the next two clauses for the clause E3.4.2: 
E3.4.3 : preorder(tree(x1, x2, x3), x4) : − preorder(x2, y1), preorder'(x3, y2, y1, y' ), append([x1|y' ], y2, x4)
1	1
E3.4.4 : preorder'(x1, x2, w, w) : − preorder(x1, x2)	 

Mode Specification

In order to define the mode specification, it is worthwhile to distinguish be- tween the argument position j and the corresponding argument uj for some 1 ≤ j ≤ m in a given atom p(u1,... , um). Then, each argument position is associated to a mode, that can be either input (in) or output (out). The resulting partition of the n argument positions in p(u) is a mode speciﬁcation.
Definition 4.1 The mode specification in an m-ary atom a, denoted by ms(a), is either ⊥ or a m-tuple (ms1(a),... , msm(a)) ⊆ {in, out}m. ms(a) is unde- fined if it is ⊥. Otherwise, it is defined.	 
For example, if the mode specification (out, in, out, in) is in the atom p(f (a, y), g(a), y, x), then ⟨g(a), x⟩ is the order-preserving sequence of argu- ments occurring in input positions, whereas ⟨f (a, y), y⟩ corresponds with the output positions.
For the rest of the paper, we adopt the following notation that allows us to implicitly represent the mode specification in an atom.
Notational Convention 4.2 Suppose some ﬁxed mode speciﬁcation ms(p(u)). The atom p(u) is written as pQuI d uO¢ to denote that uI and uO are the order- preserving subsequences of u that respectively correspond with the input and the output positions.	 
For instance, in the previous example, the atom p(f (a, y), g(a), y, x) whose mode specification is (out, in, out, in) is written as pQ⟨g(a), x⟩ d ⟨f (a, y), y⟩¢.

Definition 4.3 Let P be a program and C ≡ p(t) : − q1(s1),... , qn(sn) ∈ P be a clause, the mode specification in the clause C, denoted by ms(C), is a n + 1-tuple ( ms(p(t)), ms(q1(s1)),... , ms(qn(sn)) ). If ms(p(t)) and ms(qi(si)) are deﬁned for each 1 ≤ i ≤ n then ms(C) is total. Otherwise, ms(C) is partial.	 
We would like to remark that mode specifications are about positions, but not about terms being their actual holders. Notice that the same term (in particular, variable) could occur in distinct atoms (or, even, in the same atom) in positions with different modes. Moreover, the mode specification does not restrict the goals and has nothing to do with the dataflow that is assumed by the programmer.
In this section, we will explain how to automatically infer the mode spec- iﬁcation in the atoms of a program. This inference will be directed by the auxiliary variables that are going to be eliminated. To start with, the fol- lowing two definitions set the criteria for inferring the mode specification in a clause regarding the occurrence of the auxiliary variables. Intuitively, auxil-


iary variables take a value in their leftmost occurrence atom (mode out) that is used in the remaining atoms (mode in).

Definition 4.4 Let C ≡ p(t) : −q1(s1),... , qn(sn) be a clause and mi the arity of the atom qi, the mode specification in the j-th argument position of the atom qi(si) for 1 ≤ j ≤ mi, denoted by msj(qi(si)), such that AuxVar (si ) /≡ ∅ is:
msj(qi(si)) := in if AuxVar (si ) ⊂ AuxVar (si−1)
msj(qi(si)) := out if AuxVar (si ) ⊂ AuxVar (si+1)	 
However, the mode specification in the argument positions where no auxiliary variable occurs in is defined according to a given mode specification in the clause head atom.

Definition 4.5 Let C ≡ p(t) : − q1(s1),... , qn(sn) be a clause such that ms(p(t)) is deﬁned and mi be the arity of the predicate qi, the mode speci- fication in the j-th argument position of the atom qi(si) for 1 ≤ j ≤ mi, denoted by msj(qi(si)), such that AuxVar (sj) ≡ ∅ is:
msj(qi(si)) := in if AuxVar (si ) ∩ AuxVar (tI) /≡ ∅ 
msj(qi(si)) := out if AuxVar (si ) ∩ AuxVar (tI) ≡ ∅	 
In the sequel, given a mode specification in an atom p(u) of a program P , we extend it to the clauses that define all the predicates that are mutually recursive with p, that is, to MRDefP (p). This extension is made in different phases. First, ms(p(u)) is extended to the set of clauses DefP (p). Second, we collect the mode specifications in the atoms of predicates h ∈ MRP (p). Finally, each collected mode specification is extended to DefP (h). In the next section, we will see how the starting mode specification ms(p(u)) is obtained.
Definition 4.6 Let P be a program and ms(p(u)) be a mode speciﬁcation, the mode specification of DefP (p) w.r.t. ms(p(u)), denoted by MS[DefP (p)\ms(p(u))], consists of the mode speciﬁcation ms(C) in each clause C ≡ p(t) : − K ∈ DefP (p) where ms(p(t)) ≡ ms(p(u)), according to Deﬁnitions 4.4 and 4.5.	 
Definition 4.7 Let P be a program and ms(p(u)) a mode speciﬁcation in an atom of P, the set of mode specifications in DefP (p) w.r.t. ms(p(u)), denoted by LMS[DefP (p)\ms(p(u))], is deﬁned by:
{ (h, ms(h(s))) | h ∈ MRP (p) and ms(h(s)) ∈ MS[DefP (p)\ms(p(u))] }

The set of mode specifications in MRDefP (p) w.r.t.	ms(p(u)), denoted by
LMS[MRDefP (p)\ms(p(u))], is obtained by transitive closure.	 
Definition 4.8 Let P be a program and ms(p(u)) be a mode speciﬁcation in an atom of P, the mode specification in MRDefP (p) w.r.t. ms(p(u)), denoted

by MS[MRDefP (p)\ms(p(u))], is deﬁned by:
{ MS[DefP (h)\ms(h(s))] | ms(h(s)) ∈ LMS[MRDefP (p)\ms(p(u))] }

It is important to stress that there exists a unique MS[MRDefP (p)\ms(p(u))] for each ms(p(u)).
Example 4.9 Given the normalized program P in Example 3.4, the mode speciﬁcation in MRDefP (preorder) w.r.t. (in, out) is (in the Notational Con- vention 4.2 for implicitly representing it):
E4.9.1 : preorderQnil d [ ]¢
E4.9.2 : preorderQtree(x1, x2, x3) d x4¢ : − preorderQx2 d y1¢, preorder'Qx3, y1 d y2, y' ¢, appendQ[x1|y' ], y2 d x4¢
1	1
E4.9.3 : preorder'Qx1,w d x2, w¢ : − preorderQx1 d x2¢
where LMS[MRDefP (preorder)\(in, out)] is:
{ (preorder, (in, out)), (preorder', (in, out, in, out)) }
Notice that, in this case, each predicate is associated to a unique mode speciﬁ- cation, although in general there can be several mode speciﬁcations associated to each one.	 

The Elimination Method
Next, we present a method for transforming definite logic programs in order to eliminate the auxiliary variables while preserving TF -equivalence. We devoted the first two subsections to explain in detail the two main subtasks of this transformation method: to transform the definition of a predicate p into a tail recursive definition (w.r.t. a mode specification, see below) and to eliminate the auxiliary variables that are located in the leftmost atom where some of them occur in. The algorithm that, using these two subtasks, accomplishes the auxiliary variable elimination is introduced in the third subsection.

Tail Recursive Transformation
In Prolog, a predicate is said to be tail recursive whenever the recursive call is the rightmost in every recursive clause that defines the predicate. However, we define a slightly stronger notion by relating tail recursion to the mode specification and by imposing some extra syntactic restrictions.
Definition 5.1 The deﬁnition of a predicate p in a program P is tail re- cursive w.r.t. a mode specification ms(p(u)) iff for each pair (h, ms(h(u')) ∈


LMS[MRDefP (p)\ms(p(u))], h ≡ p and DefP (h) consists of clauses of the follow- ing two forms (w.r.t. MS[DefP (h)\ms(h(u')]):

(1 ) hQtI d tO¢ : − K
(2 ) hQsI d z¢ : − L, hQrI d z¢

where h /∈ DpdP (q) (that is, q /∈ MRP (p)) for every atom q(u') in K and L, and
z is a fresh tuple of pairwise distinct variables.	 
That is, as well as the standard condition of recursion in the rightmost atom, we also demand that, in the recursive clauses (2), the same tuple of pairwise distinct variables (namely z) occurs in output arguments of both the head and the rightmost body atom. Notice that only direct recursion is considered in our definition. These restrictions will be useful during the auxiliary variable elimination process.
Next, we show how to transform the definition of a predicate into a TF - equivalent tail recursive one w.r.t. a mode specification. It is based on the well-known technique that uses a stack for storing the recursive calls. Here, we use new constants with predicate names and clauses as super/sub-scripts to be stored in the stack for representing them.
Definition 5.2 Let P be a program and ms(p(u)) be the mode speciﬁcation in an atom that occurs in P, the tail recursive definition of p w.r.t. ms(p(u)), denoted by TailRDefP [p\ms(p(u))], consists of (where, in each clause, z is a m-tuple of fresh variables and m is the number of output positions in ms(p(u))):
A clause (really, a fact):
(1 ) p trQz, [] d z¢
where p tr is a new predicate.
For each (h, ms(h(s))) ∈ LMS[MRDefP (p)\ms(p(u))], a clause:
(2 ) hQxd z¢ : − p trQx, [ch] d z¢
where the constant ch is associated to ms(h(s)), x is a k-tuple of new vari- ables and k is the number of output positions in ms(h(s)).
For each hQsI d sO¢ : − q1Qr1 d r1¢,... , qnQrn d rn¢ ∈ MS[MRDefP (p)\ms(p(u))]
such that {q1,... qn}∩ MRP (p) ≡ ∅, a clause:
(3 ) p trQsI, [ch|S] d z¢ : − q1Qr1 d r1¢, ... , qnQrn d rn¢, p trQsO,S d z¢
For each hQsI dsO¢ : − q1Qr1 dr1¢, ... , qnQrn drn¢ ∈ MS[MRDefP (p)\ms(p(u))],
namely ms(C), such that {q1,... qn}∩ MRP (p) /≡ ∅, two clauses 3 :
(4 ) p trQsI, [ch|S] d z¢ : − p trQsI, [w1, cC ,... , wn, cC , w, cC|S] d z¢
q1	qn	h

3 By convention, r0 ≡ sI.

(5 ) p trQrn, [w, cC|S] d z¢ : − p trQsO,S d z¢
O	h
and, for each 1 ≤ j ≤ n, a clause of the form (6 ) if qj /∈ MRP (p) and a clause of the form (7 ) if qj ∈ MRP (p):
(6 ) p trQrj−1, [wj, cC |S] d z¢ : − q Qrj d rj ¢,p trQrj,S d z¢
O	qj	j	I	O	o
(7 ) p trQrj−1, [wj, cC |S] d z¢ : − p trQrj , [c  |S] d z¢

O	qj
where:
I	qj

each constant cC is associated to qjQsj d sj ¢ in ms(C)
qj	I	O
the constant cC is associated to ms(C) itself
  n	 h			n

wj ≡ vj ∪ (Aux Var (rj . rj ) \ Aux Var (rj−1)) if q /∈ MR
(p) (type (6 ))

I	O	O	j	P
wj ≡ vj ∪ (Aux Var (rj ) \ Aux Var (rj−1)) if q ∈ MR (p) (type (7 ))
I	O	j	P

vj ≡ Aux Var (rj . rj ) ∩  n	Aux Var (rk . rk)	 
Roughly speaking, the clauses of the form (2 ) store the initial call for each (h, ms(h(s))) ∈ LMS[MRDefP (p)\ms(p(u))], whereas the clause (1 ) gives the output value when no recursive call remains. The clauses of the form (3 ) encode the non-recursive clauses and the clauses of the form (4 ) and (5 ) the recursive ones (each clause (5 ) gives the output value of the original clause). Notice that the clauses are encoded in different ways according to the each pair (h, ms(h(s))) ∈ LMS[MRDefP (p)\ms(p(u))]. The clauses of the form (6 ) and (7 ) are used for rebuilding the set of terms of each atom depending on the mode specification in it. In addition, the variables stored in the stack ensure that the links between atoms through (non-auxiliary) variables are kept.
Theorem 5.3 Let P be a program and ms(p(u)) the mode speciﬁcation in an atom that occurs in P, the programs P and P \DefP (p)∪TailRDefP [p\ms(p(u))] are TF-equivalent.

Proof. Let P0 be obtained by adding to P \ DefP (p) one set of clauses of the following form for each pair (h, ms(h(u'))) ∈ LMS[MRDefP (p)\ms(p(u))]:
C5.3.1: hQxd z¢ : − h'Qx, [ch] d z¢
C5.3.2∗ : h'QsI, [ch] d sO¢ : − q1Qr1 d r1¢, ... , qnQrn d rn¢
C5.3.3∗ : h'QsI, [ch] d z¢ : − h'Qr1, [w1, cC ] d r1¢, ... , h'Qrn, [wn, cC ] d rn¢,

I
h'Qrn, [w, cC] d z¢
q1	O
I	qn	O

O	h
C5.3.4∗ : h'Qrn, [w, cC] d sO¢
h
C5.3.5∗ : h'Qrj , [wj, cC ] d rj ¢ : − qjQrj d rj ¢
I	qj	O	I	O
where the constants and the sets of variables are obtained as in Definition 5.2, and the clauses that are marked with an asterisk * denote schemes on one or more syntactic objects. In concrete, each one of the previous sets consists of a single clause C5.3.1, a clause C5.3.2∗ for each non-recursive clause in


MRDefP (p) and a clause C5.3.3∗, a clause C5.3.4∗ and n clauses C5.3.5∗ for each recursive clause in MRDefP (p) (being n the number of atoms in the corre- sponding clause). For technical convenience, we consider that the predicates h ∈ MRP (p) (except for p) are renamed in the previous sets of clauses.
The programs P and P0 are TF -equivalent since by unfolding the n + 1 body atoms in the clauses of the form C5.3.3∗ and then unfolding the atom h'Qx, [ch] d x¢ in each clause of the form C5.3.1∗ we obtain P (eliminating the repeated clauses).
Next, we define the program P1 from P0 by introducing a new predicate
p tv that is defined by:
C5.3.6: p tvQx, [] d x¢
C5.3.7:  p tvQx1, [x2|S] d x¢ : − h'Qx1, [x2] d x3¢, p tvQx3,S d x¢
Trivially P0 ∼=TF P1. Now, we unfold in the clauses of the form C5.3.5∗
the atoms qjQvj d vj ¢ such that qj ∈ MRP (p) and then we unfold the atom
h'Qx1, [x2] d x3¢ in the clause C5.3.7, obtaining the program P2. DefP (p tv) and DefP2 (p tv) are equal except for the clauses of the form (4 ) (see Definition 5.2). In the program P2, the corresponding clauses are of the form:
C5.3.8∗ : p tvQsI, [ch|S] d x¢ : − h'Qv1, [w1, cC ] d v1¢, ..., 
I	q1	O
h'Qvn, [wn, cC ] d vn¢, h'Qvn, [w, cC] d y¢, p tvQy, S d x¢
I	qn	O	O	h
It suffices to fold n + 1 times the rightmost couple of atoms in these clauses using the clause C5.3.7, obtaining the program P3. At each folding step, we get a new atom of predicate p tv that is used in the next step. At the end of this process, DefP (p tv) and DefP3 (p tv) are equal and, therefore, the obtained program is also identical to P \ DefP (p) ∪ TailRDefP [p\ms(p(u))] (eliminating the superfluous predicates).
Finally, it is important to remark that, since P is normalized, the links between the auxiliary variables are preserved in the transformed program. 
Example 5.4 Given the normalized program P in Example 3.4, the tail re- cursive deﬁnition of pveovdev w.r.t. (in, out) consists of 4 :
E5.4.1 :  pvdv tvQx, [] d x¢
E5.4.2 :  pveovdevQxd x¢ : − pvdv tvQx, [c1] d x¢
E5.4.3 : pveovdev'Qx1, x2 d x¢ : − pvdv tvQx1, x2, [c2] d x¢ E5.4.4 : pvdv tvQnil, [c1|S] d x¢ : − pvdv tvQ[ ],S d x¢ E5.4.5 :  pvdv tvQtvee(x1, x2, x3), [c1|S] d x¢ : −
pvdv tvQtvee(x1, x2, x3), [[ ], c3, [x3], c4, [x1], c5, [ ], c6|S] d x¢ E5.4.6 :  pvdv tvQtvee(x1, x2, x3), [[ ], c3|S] d x¢ : − pvdv tvQx2, [c1|S] d x¢

4 For brevity, we use numbers, instead of predicates names, as constant sub-scripts.


E5.4.7 : pvdv tvQy1, [[x3], c4|S] d x¢ : − pvdv tvQy1, x3, [c2|S] d x¢ E5.4.8 : pvdv tvQy3, y2, [[x1], c5|S] d x¢ : − appendQ[x1|y3], y2 d y¢,
pvdv tvQy, S d x¢
E5.4.9 :  pvdv tvQx4, [[ ], c6|S] d x¢ : − pvdv tvQx4,S d x¢
E5.4.10 : pvdv tvQy, x1, [c2|S] d x¢ : − pvdv tvQy, x1, [[ ], c7, [[y], c8|S] d x¢ E5.4.11 : pvdv tvQy, x1, [[ ], c7|S] d x¢ : − pvdv tvQx1, [c1|S] d x¢
E5.4.12 : pvdv tvQx2, [[y], c8|S] d x¢ : − pvdv tvQy, x2,S d x¢	 
Notice that for every program P and after transforming the definition of a predicate p in this way, no other predicate is mutually recursive to p. That is, MRP ' (p) ≡ {p} being P ' the obtained program.

A Single Step of Auxiliary Variable Elimination
The second subtask is to eliminate the auxiliary variables that are located in the leftmost atom where some auxiliary variables occur in. With this aim, we have to infer the mode specification in the above mentioned atom and the next one. The Definition 4.4 already fixes the mode specification in the argument positions where auxiliary variables occur in. In the remaining ones, the mode specification that is inferred by Definition 4.5 is subject to the mode specification in the clause head atom, that is undefined for the time being. Therefore, the mode specification in these positions is inferred as follows.

Definition 5.5 Let C ≡ p(t) : − q1(s1), ... , qn(sn) be a normalized clause such that ms(p(t)) is undeﬁned, qi(si) be the leftmost atom that contains some auxiliary variables for 1 ≤ i ≤ n and let mi and mi+1 be the arities of the predicates qi and qi+1 respectively, the mode specification in the j-th argu- ment position of qi(si) for 1 ≤ j ≤ mi, denoted by msj(qi(si)), such that AuxVar (si ) ≡ ∅ is in. In the same way, the mode specification in the j-th argument position of qi+1(si+1) for 1 ≤ j ≤ mi+1, denoted by msj(qi+1(si+1)), such that AuxVar (si+1) ≡ ∅ is out.	 
Thus, due to Definitions 4.4 and 5.5, the mode specification in the leftmost atom that contains some auxiliary variables and in the next one is defined.
Example 5.6 Consider the normalized clause E3.4.3 that is in Example 3.4. pveovdev(x2, y1) is the leftmost atom that contains some auxiliary variables. To be precise, the auxiliary variable y1. The mode speciﬁcation in this atom and in the next one, that is the atom pveovdev'(x3, y2, y1, y' )), is (in, out) and (out, out, in, out) respectively.	 
Next, we replace the clause where the auxiliary variables occur in with the set of clauses that is given in the following definition. We proceed in this way on the condition that the definition of the leftmost atom predicate is tail


recursive w.r.t. the inferred mode specification according to Definitions 4.4 and 5.5. Notice that Theorem 5.3 guarantees that this condition holds.
Definition 5.7 Let C ≡ h(u) : − M, p Qti d ti ¢,p	Qti+1 d ti+1¢, N ∈ P be a
i  I	O	i+1  I	O
clause such that p Qti d ti ¢ is the leftmost atom that contains some auxiliary
i  I	O

variables and Def
(q ) is tail recursive w.r.t. p Qti d ti ¢, the set of auxiliary

i	i  I	O
variable free clauses of C in P, denoted by AVF P (C), consists of (where x is
a m-tuple of fresh variables and m is the number of terms in ti+1):
A clause:
(1 ) h(u) : − M, p'Qti , wI d ti+1, wO¢, N
I	O
where p' is a new predicate, wI ≡ Aux Var (ti ) \ Aux Var (ti . ti+1) and wO ≡
O	I	O
Aux Var (ti+1) \ Aux Var (ti . ti+1).
I	I	O
For each piQvI d vO¢ : − K ∈ DefP (pj) (non-recursive clauses), a clause:



(2 ) p'QvIσ, wIσ d x, wOσ¢ : − K, p
where σ ≡ mgu(vO, ti ).
i+1
Qti+1σ d x¢



For each piQsI d x¢ : − L, piQs' d x¢ ∈ DefP (pi) (recursive clauses), a clause:
(3 ) p'QsI, wI d x, wO¢ : − L, p'Qs' , wI d x, wO¢	 
Note that, since the tuples ti and ti+1 have disappeared, the involved auxiliary
O	I
variables have been eliminated. Again, the set of variables wI and wO ensure
that the links between atoms through (non-auxiliary) variables are kept.
Theorem 5.8 Let C ≡ h(u) : − M, p Qti d ti ¢,p	Qti+1 d ti+1¢, N ∈ P be a
i  I	O	i+1  I	O
clause such that p Qti d ti ¢ is the leftmost atom that contains some auxiliary
i  I	O

variables and Def
(q ) is tail recursive w.r.t. p Qti d ti ¢. The programs P and

P	i	i  I	O
P \ {C}∪ AVF P (C) are TF-equivalent.


Proof. Starting from the program P , we obtain P0 by introducing a new predicate p' that is defined by the single clause:
C5.8.1:  p'Qx, wI d x, wO¢ : − p Qxd ti ¢, p	Qti+1 d x¢

where:
i	O	i+1 I

x is a m-tuple of fresh variables and m is the number of terms in ti
x is a n-tuple of fresh variables and n is the number of terms in ti+1
the sets of variables wI and wO are obtained as in Definition 5.7
the mode specifications in p Qxdti ¢ and p	Qti+1 d x¢ coincide with the ones
i	O	i+1  I
in the atoms p Qti d ti ¢ and p	Qti+1 d ti+1¢ of the clause C.

i  I	O
i+1  I	O


The programs P and P0 are trivially TF -equivalent. Since DefP (pi) (and
therefore, Def (p )) is tail recursive w.r.t. p Qxd ti ¢, by unfolding this atom
P0	i	i	O
in the clause C5.8.1 we get clauses of the following two forms 5 :

C5.8.2∗ : p'QvIσ, wIσ d x, wOσ¢ : − K, p

i+1
Qti+1σ d x¢

C5.8.3∗ : p'QsI, wI d x, wO¢ : − L, p Qs' d ti ¢, p	Qti+1, wI d x, wO¢
i  I	O	i+1  I
where σ ≡ mgu(vO, ti ). We now fold each clause of the form C5.8.3∗ using
C5.8.1, obtaining clauses of the following form:

C5.8.4∗ : p'QsI, wI d x, wO¢ : − L, p'Qs' , wI d x, wO¢
By folding the clause C using the clause C5.8.1, we get:
C5.8.5:  h(u) : − M, p'Qti , wI d ti+1, wO¢, N
I	O
The resulting program P1 is defined by the set of clauses:
P1 ≡ (P0 \ {C, C5.8.1}) ∪ {C5.8.5}∪ C5.8.2∗ ∪ C5.8.4∗
considering C5.8.2∗ and C5.8.4∗ to be sets of clauses. Since the programs P1 and P \ {C}∪ AVF P (C) are syntactically equal, P and P \ {C}∪ AVF P (C) are TF -equivalent.	 
Example 5.9 Let P be the program in Example 5.4, it only remains to elim- inate the auxiliary variable y from the clause E5.4.8: 
pvdv tv(y3, y2, [[x1], c5|S], x) : − append([x1|y3], y2, y), pvdv tv(y, S, x)
According to Deﬁnitions 4.4 and 5.5, the mode speciﬁcation in the atoms that share the variable y is appendQ[x1|y3], y2 d y¢ and pvdv tvQy d S, x¢ re- spectively. Let DefP (append) consist of (representing the mode speciﬁcation appendQ[x1|y3], y2 d y¢):
E5.9.1 :  appendQ[ ],x d x¢
E5.9.2 :  appendQ[x1|x2], x3 d [x1|x4]¢ : − appendQx2, x3 d x4¢
Since DefP (append) is not tail recursive w.r.t. appendQ[x1|y3], y2 d y¢, we sub- stitute TailRDefP [append\appendQ[x1|y3], y2 d y¢] for DefP (append):
E5.9.3 :  app tvQx, [] d x¢
E5.9.4 : appendQx1, x2 d x¢ : − app tvQx1, x2, [c9] d x¢ E5.9.5 : app tvQ[ ], x, [c9|S] d x¢ : − app tvQx, S d x¢ E5.9.6 : app tvQ[x1|x2], x3, [c9|S] d x¢ : −
app tvQ[x1|x2], x3, [[ ], c10, [x1], c11|S] d x¢
E5.9.7 : app tvQ[x1|x2], x3, [[ ], c10|S] d x¢ : − app tvQx2, x3, [c9|S] d x¢ E5.9.8 : app tvQx4, [[x1], c11|S] d x¢ : − app tvQ[x1|x4],S d x¢

5 As before, the asterisk is used to denote clause schemes.

As it is explained in the next subsection, we substitute app tv([x1|y3], y2, [c9], y)
for append([x1|y3], y2, y) in the clause E5.4.8 and we get:
E5.9.9 : pvdv tv(y3, y2, [[x1], c5|S], x) : − app tvQ[x1|y3], y2, [c9] d y¢, pvdv tvQy d S, x¢
Finally, AVF P (E5.9.9 ) consists of:
E5.9.10 : pvdv tv(y3, y2, [[x1], c5|S], x) : − app tv'Q[x1|y3], y2, [c9] d S, x¢ E5.9.11 : app tv'Qx, [] d S, x¢ : − p tvQx d S, x¢
E5.9.12 : app tv'Q[ ], x, [c9|S] d x1, x2¢ : − app tv'Qx, S d x1, x2¢ E5.9.13 : app tv'Q[x1|x2], x3, [c9|S] d x1, x2¢ : −
app tv'Q[x1|x2], x3, [[ ], c10, [x1], c11|S] d x1, x2¢
E5.9.14 : app tv'Q[x1|x2], x3, [[ ], c10|S] d x1, x2¢ : −
app tv'Qx2, x3, [c9|S] d x1, x2¢
E5.9.15 : app tv'Qx4, [[x1], c11|S] d x1, x2¢ : − app tv'Q[x1|x4],S d x1, x2¢ 

An Auxiliary Variable Elimination Algorithm
Making use of the previous two transformations, we give an algorithm for eliminating the auxiliary variables from a definite logic program. Remember that normalization is always assumed.
Roughly speaking, the algorithm in Figure 1 works as follows. For each
clause C ≡ h(u) : − M, p Qti d ti ¢,p	Qti+1 d ti+1¢, N , we select the leftmost
i  I	O	i+1  I	O
atom that contains some auxiliary variables and the next one. The mode
specification in these atoms, p Qti dti ¢ and p	Qti+1 dti+1¢, is inferred according
i  I	O	i+1  I	O
to Definitions 4.4 and 5.5. Besides, the mode specification in p Qti d ti ¢ is
i  I	O
extended to MRDefP (pi) according to Definitions 4.4, 4.6, 4.7 and 4.8 when
necessary. Then, there are two main cases:
If pi does not depend on h (line 5), we substitute the set of clauses AVF P (C) (see Definition 5.7) for the clause C. If necessary (line 6), we transform

Def
(p ) into TailRDef [p \p Qti d ti ¢] (see Definition 5.2) and substitute

p tvQti , [c ] d ti ¢ for p Qti d ti ¢ in the clause C, where p
tv is the new

predicate that is introduced by the transformation.

If p
depends on h (line 12), Def (p ) is not tail recursive w.r.t. p Qti d ti ¢

i	P	i
i  I	O

because recursion is not restricted to the rightmost atom. Since ms(h(u)) is

defined after extending p Qti d ti ¢ to MRDef (p ), we transform Def
(h) into

i  I	O	P	i	P
TailRDefP [h\ms(h(u))]. This transformation eliminates the clause C from
the program P . Therefore, a different clause is selected in the next step.
In the former case (pi /∈ MRP (h)), the involved auxiliary variables are eliminated by substituting AVF P (C) for the clause C. In the latter case



Fig. 1. An Auxiliary Variable Elimination Algorithm
(pi ∈ MRP (h)), the transformation of DefP (h) into TailRDefP [h\ms(h(u))] ensures that recursion is restricted to the rightmost most in every clause C' ∈ MRDefP (h). Therefore, this transformation is performed at most once for each predicate in the program and, after that, auxiliary variables are di- rectly eliminated according to the first case.
It is important to stress that the transformation to tail recursive itself of- ten eliminates many of the auxiliary variables (see Example 5.4 where two auxiliary variables are eliminated). In addition, after the tail recursive trans- formation of h, when a clause D /∈ DefP (h) is selected, the clauses in DefP (h) can never be affected by the auxiliary variable elimination process.
Although no transformational step introduces new auxiliary variables, un- fortunately we do not have a formal termination proof. Hence, further inves-


tigations must be done to achieve a total correctness proof for the presented algorithm.


Conclusions

The presented method can be automatically applied to every definite logic program and eliminates its auxiliary (local) variables. Each definite clause (with auxiliary variables) is replaced with a set of definite clauses with new predicates. As a result, the negative version of the target program does not require universal quantification. Hence, much efficiency is gained in negative goal computation. However, positive goals should be computed with respect to the source program since, in general, the new predicates that are introduced by the transformation reduce the efficiency of the positive goal computation. The aim of the present work is to prove the existence of a general algorithm for auxiliary variable elimination in definite logic programs. Much work and further improvements should be made on implementation and experimentation in order to obtain more efficient target programs.
A method for eliminating local (there called unnecessary) variables from definite logic programs was introduced in [13]. Their main aim was to eliminate the redundant computations that are made by means of local variables. Hence, the target program yields more efficient SLD-computations. This motivation is essentially different from ours. They present different strategies for guiding the application of unfold/fold transformations in order to achieve local variable elimination. The strategies are syntactically based and only guarantee the complete elimination of local variables for a very restricted subclass of definite logic programs. To the best of our knowledge, there is no other published result on the elimination of this kind of variables in logic programs.
We plan to extend our results to normal logic programs. By now, we think that full generality could not be achieved in this case. However, we believe that the method can be easily adapted for a wide subclass of normal logic programs. Future work also includes the extension to constraint logic programming.


Acknowledgement
We are very grateful for the helpful comments we receive from our referees.

References
A´lvez, J., P. Lucio, F. Orejas, E. Pasarella and E. Pino, Constructive negation by bottom- up computation of literal answers, in: SAC ’04: Proceedings of the 2004 ACM Symposium on Applied Computing, 2004, pp. 1468–1475.
Barbuti, M., P. Mancarella, D. Pedreschi and F. Turini, A transformational approach to negation in logic programming, Journal of Logic Programming 8 (1990), pp. 201–228.
Bruscoli, P., F. Levi, G. Levi and M. C. Meo, Compilative constructive negation in constraint logic programs, in: S. Tison, editor, Proc. of the Trees in Algebra and Programming 19th Int. Coll.(CAAP ’94), LNCS 787 (1994), pp. 52–67.
Chan, D., Constructive negation based on the completed database, in: R. A. Kowalski and K. A. Bowen, editors, Proc. of the 5th Int. Conf. and Symp. on Logic Progr. (1988), pp. 111–125.
Chan, D., An extension of constructive negation and its application in coroutining, in: E. Lusk and R. Overbeek, editors, Proc. of the NACLP’89 (1989), pp. 477–493.
Clark, K. L., Negation as failure, in: H. Gallaire and J. Minker, editors, Logic and Databases
(1978), pp. 293–322.
Debray, S. K. and D. S. Warren, Automatic mode inference for logic programs, Journal of Logic Programming 5 (1988), pp. 207–229.
Drabent, W., What is failure? an approach to constructive negation, Acta Informatica 32
(1995), pp. 27–59.
Fitting, M., A Kripke-Kleene semantics for logic programs, Journal of Logic Programming 2
(1985), pp. 295–312.
King, A., K. Shen and F. Benoy, Lower-bound time-complexity analysis of logic programs, in:
J. Maluszynski, editor, International Symposium on Logic Programming (1997), pp. 261 – 276.
Kunen, K., Negation in logic programming, Journal of Logic Programming 4 (1987), pp. 289– 308.
Maher, M. J., Equivalences of logic programs, in: J. Minker, editor, Foundations of deductive databases and logic programming (1988), pp. 627–658.
Proietti, M. and A. Pettorossi, Unfolding - deﬁnition - folding, in this order, for avoiding unnecessary variables in logic programs, Theoretical Computer Science 142 (1995), pp. 89– 124.
Sato, T. and H. Tamaki, Transformational logic program synthesis, in: Proceedings of International Conference on Fifth Generation Computer Systems, 1984, pp. 195–201.
Shepherdson, J., Language and equality theory in logic programming, Technical Report No. PM-91-02, University of Bristol (1991).
Stuckey, P. J., Negation and constraint logic programming, Information and Computation 118
(1995), pp. 12–33.
