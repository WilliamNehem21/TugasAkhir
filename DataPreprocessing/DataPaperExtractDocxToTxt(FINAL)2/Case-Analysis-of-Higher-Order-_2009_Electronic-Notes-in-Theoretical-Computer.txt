

Electronic Notes in Theoretical Computer Science 228 (2009) 69–84
www.elsevier.com/locate/entcs

Case Analysis of Higher-Order Data
Jana Dunfield and Brigitte Pientka
School of Computer Science, McGill University 3480 rue University, Montr´eal, QC H3A 2A7, Canada
bp@cs.mcgill.ca


Abstract
We discuss coverage checking for data that is dependently typed and is defined using higher-order abstract syntax. Unlike previous work on coverage checking for closed data, we consider open data which may depend on some context. Our work may therefore provide insight into coverage checking in Twelf, and serve as a basis for coverage checking in functional languages such as Delphin and Beluga. More generally, our work is a foundation for proofs by case analysis in systems that reason about higher-order abstract syntax.
Keywords: higher-order abstract syntax, coverage checking

Introduction
Over the past decade, programming and reasoning with and about data structures that contain binders has received widespread attention in programming languages and automated reasoning systems. Higher-order abstract syntax (HOAS) is a sim- ple and elegant technique for handling binders. The central idea is easily explained: instead of representing object variables explicitly, we use meta-language variables. For example, the object-level formula ∀x. (x = 1) ⊃ ¬(x = 0) can be represented as forall λx. (eq x (Suc Zero)) imp (not (eq x Zero)). This avoids the need to implement common and tricky machinery such as capture-avoiding substitution, renaming and fresh name generation. When we implement proofs, higher-order ab- stract syntax allows us to think of hypothetical derivations, i.e. derivations that depend on assumptions as higher-order functions, where the application of a sub- stitution lemma corresponds to a function application. For example, in natural deduction (Fig. 1), the hypothetical typing derivation for implication introduction can be elegantly modeled using higher-order functions.
The power of HOAS encodings has been shown within the logical framework LF
[5] and its implementation in Twelf [13]. Recently, HOAS encodings are supported in functional programming languages such as Elphin [17], Delphin [14], and Beluga [12]. In these systems, we analyze higher-order data using pattern matching and case

1571-0661/© 2008 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2008.12.117



Numbers N, M ::= x
| 0
| suc N
Propositions A ::= N = M
| A ⊃ B
| ∀x.A
Natural Deduction  Γ ▶ nd A
nat : type . Zero: nat.
Suc : nat → nat.
o	: type .
eq	: nat → nat → o. imp : o → o → o. forall: (nat → o) → o.
nd: o → type .

Γ,u : nd A ▶ nd B
Γ ▶ nd A ⊃ B
⊃Iu
impi:(nd A → nd B)
→ nd (A imp B).

Γ ▶ nd A ⊃ B	Γ ▶ nd A ⊃E
Γ ▶ nd B
Γ ▶ nd [a/x]A
∀Ia
Γ ▶ nd (∀x.A)
impe: nd (A imp B) → nd A
→ nd B.
alli: (Π a:nat. nd (A a))
→ nd (forall λx. A x).

(u : nd A) ∈ Γ
Γ ▶ nd A	Hyp
Γ ▶ (∀x.A)

Γ ▶ nd [N/x]A ∀E
alle: nd (forall λx. A x)
→ nd (A N).


Fig. 1. Natural deduction and its HOAS encoding

expressions. This requires us to validate that the patterns are exhaustive Similarly, proof assistants for HOAS-based reasoning that split a goal into different cases must ensure that the cases are exhaustive. This issue arises in Twelf’s induction theorem prover [15], and in systems such as Bedwyr [1] and Abella [4].
In the first-order, simply-typed setting, analyzing data by cases is straightfor- ward. We can just consider all declared constants of a given type. To illustrate, in Figure 1 we define a simple logic with equality on numbers in the usual style of LF [5]. The cases for the proposition A are clear: they are exactly the three proposition forms listed in the grammar. However, for numbers we do not just need cases for 0 and suc N , but also a case for a variable x. A similar situation comes up with higher-order data, such as derivations in natural deduction. An encoding based on higher-order abstract syntax does not represent the rule Hyp explicitly. Instead, this base case will be implicit. Thus, generating all cases requires that we consider the context and its possible elements.
Our main contribution is a theoretical framework for generating an exhaustive set of cases for objects that may refer to assumptions, i.e. open objects. Previous work on coverage checking handled closed terms [2,16], or open terms within regular worlds [15, pp. 197–213]. Our work is the first theoretical treatment of coverage in the setting of contextual modal type theory. We believe our theory is a first step toward demystifying coverage checking in Twelf, an operation that is mysterious to many users. More immediately, our work is a foundation for languages such as Beluga [12] that case-analyze open data. We prove a property of coverage soundness that is needed to prove progress in Beluga.
We will begin with an example in the language Beluga, which supports pro- gramming with LF encodings in a functional setting. To emphasize the issues due to open terms, we will concentrate on the simply typed setting in this example. However, our formal framework treats dependently typed terms, which makes the

rec cntVN : Π ψ:(nat)∗. nat[ψ,x:nat] → int =
Λ ψ ⇒ fn n ⇒ case n of box(ψ,x. x]) ⇒ 1
| box(ψ,x. p[idψ]) ⇒ 0
| box(ψ,x. Zero) ⇒ 0
| box(ψ,x. Suc U[idψ,x]) ⇒ cntVN [ψ| box(ψ,x. U[idψ,x])
rec cntV : Π ψ:(nat)∗. o[ψ,x:nat] → int =
Λ ψ ⇒ fn f ⇒ case f of
box(ψ,x. eq U[idψ,x] V[idψ,x]) ⇒  cntVN [ψ| box(ψ,x. U[idψ,x])
+ cntVN [ψ| box(ψ,x. V[idψ,x])
| box(ψ,x. imp U[idψ,x] V[idψ,x]) ⇒ cntV [ψ| box(ψ,x. U[idψ,x])
+ cntV [ψ| box(ψ,x. V[idψ,x])
| box(ψ,x. forall(λy.W[idψ,x,y])) ⇒ cntV[ψ,y:nat| box(ψ,y,x. W[idψ,x,y])

Fig. 2. Counting free variables using pattern matching and HOAS

problem harder. The structure of types can be observed, and this makes coverage checking undecidable, since any set of patterns will cover all terms of an empty type and emptiness is undecidable.

Motivation
To motivate the problem, we consider a simple program in the Beluga language [12] that counts the free occurrences of some variable x in a formula. For example,
∀y.(x = y) ⊃ (suc y = suc x) has two free occurrences of x. The data language here is first-order logic with quantification over natural numbers, as defined in Figure 1, and we analyzes HOAS data via pattern matching. Using this example, we then discuss in more detail the problem of coverage.
We will write two functions to solve this problem. The function cntV will re- cursively analyze formulas. When it reaches a natural number expression, it will call a second function cntVN. We use modal types such as o[x:nat, y:nat], which describes a formula that can refer to the variables x and y of type nat. The formula ((eq x y) imp (eq (Suc x) (Suc y)) has this type.
When cntV recursively reaches a formula with a universal quantifier, the set of free variables grows. Hence, we need to abstract over the contexts in which the formula makes sense. Context variables ψ provide this ability.
The function cntV (Fig. 2) takes in a context ψ of natural numbers, a formula f, and returns an integer. Just as types classify data objects and kinds classify types, we introduce schemas to classify contexts. In the type declaration for the function cntV we say that the context variable ψ has the schema (nat)∗, meaning that ψ stands for a data-level context whose form is x1:nat,.. .,xn:nat. We use single capital letters U, V, W for contextual variables, which are instantiated via higher-order pattern matching.
We examine the second function, cntV, first. It is built by a context abstraction Λ ψ that introduces the context variable ψ and binds every occurrence of ψ in the body. Next, we introduce the computation-level variable f of type o[ψ,x:nat]. In

the body of the function cntV we case-analyze objects of type o[ψ,x:nat]. The box construct separates data-level terms (data objects) from computation-level terms. Since formulas are constructed by equality eq, implication imp and quantification forall, we have cases for each of these.
When we encounter an object built from a constructor eq, imp, or forall, we must extract the subexpression(s) underneath. Pattern variables are characterized by a closure U[σ] consisting of a contextual variable U and a postponed substitution σ. As soon as we know what the contextual variable stands for, we apply the substitution σ. In the example, the postponed substitution associated with U is the identity substitution which essentially corresponds to α-renaming. We write idψ for the identity substitution with domain ψ. Intuitively, one may think of the substitution associated with contextual variables which occur in patterns as a list of variables which may occur in the hole. Thus, in U[idψ] the contextual variable U can be instantiated with any formula that either is closed (does not refer to any bound variable in the context ψ) or contains a bound variable from ψ. Since subformulas can refer to all variables in ψ,x:nat, we write U[idψ, x].
In the first case, for eq, we call cntVN to count the occurrences of x in the natural numbers U[idψ,x] and V[idψ, x], explicitly passing ψ with cntV [ψ|.
The second case for imp is similarly structured, calling cntV instead of cntVN.
In the third case, for box(ψ,x. forall (λy.W[idψ,x,y])), we analyze the quantified formula under the assumption that y is a natural number. To do this, we pass an extended context (ψ,y:nat) to cntV. The variable x appears last in box(ψ,y,x. ... ), to match the argument type o[... ,x:nat].
The function cntVN counts the occurrences of a variable x in an object of type nat[ψ,x:nat], considering four cases. The first case, box(ψ,x. x), matches an occurrence of x. The second case, box(ψ,x. p[idψ]), matches a variable that is not x and occurs in ψ. For this case, we use a parameter variable p (using a small letter to distinguish it from a meta-variable). This represents a bound data-level variable. The substitution idψ associated with p characterizes the possible instantiations of
p. The remaining cases are straightforward.
Basic idea of coverage on open data
In this paper, we provide the foundation for ensuring that case expressions which analyze elements of type A[Ψ] via pattern matching cover all possible elements of this type. For example, in the function cntVN we ensure that the set of patterns
{x, p[idψ], Zero, Suc U[idψ, x]} covers the type nat[ψ, x:nat]. In cntV, the set
{eq U[idψ,x] V[idψ,x], imp U[idψ,x] V[idψ,x], forall (λy.U[idψ,x,y])} covers all elements of type o[ψ,x:nat].
This set of patterns for covering the type o[ψ,x:nat] is by no means the only one. Instead of explicitly counting the occurrences of x in a natural number of type nat[ψ,x:nat], we could have used higher-order pattern matching to enforce variable dependencies, refining the pattern eq U[idψ,x] V[idψ,x] into the four cases
{eq U[idψ] V[idψ], eq U[idψ,x] V[idψ], eq U[idψ] V[idψ,x], eq U[idψ,x] V[idψ,x]}



Fig. 3. The data level
exactly distinguishing (1) x occurs in neither U[idψ] nor V[idψ], (2) x occurs in U[idψ,x] but not in V[idψ], (3) x occurs in V[idψ,x] but not in U[idψ], and (4) x occurs in both U[idψ,x] and V[idψ,x].
More generally, we provide a formal framework for answering the following ques- tion: Does a set of patterns cover the type A[Ψ]? Alternatively, our framework provides a general way of generating a set of patterns thereby providing a founda- tion for splitting an object of type A[Ψ] into different cases. We emphasize that while we illustrate the problem in the setting of Beluga, where contexts are explicit, the problem is similar in systems such as Delphin and Twelf, where we also must generate all objects of type A in a context Ψ.

Background
Since we are interested in testing whether a set of patterns covers a given data object, we concentrate on the data level. For the computation level, see [12].
We support the logical framework LF plus dependent pairs Σ. Our data layer closely follows contextual modal type theory [10], extended with parameter variables and context variables [12], and finally with Σ types. Perhaps most importantly, we formalize schemas, which classify contexts. We only characterize normal terms since only these are meaningful in the logical framework [18,10]. This is achieved by a syntactic distinction between normal terms M and neutral terms R. The syntax guarantees that terms contain no β-redexes, and the typing rules guarantee that all well-typed terms are fully η-expanded.
We distinguish between three 1 kinds of variables (Figure 3): Ordinary bound variables x and y are used to represent data-level binders and are bound by λ- abstraction. These variables are declared in a context Ψ. Contextual variables stand for open objects, and include meta-variables u and v, which represent general open objects, and parameter variables p that can only be instantiated with an ordinary bound variable. Contextual variables are introduced in computation-level case expressions, and can be instantiated via pattern matching. They are associated with a postponed substitution σ. The intent is to apply σ as soon as we know the object the contextual variable should stand for. The domain of σ thus includes

1 Prior work also considered substitution variables, which we omit here for brevity.

the free variables of that object, and the type system statically guarantees this. Contextual variables are declared in a meta-level context Δ.
Our foundation supports context variables ψ which allow us to reason abstractly with contexts, and write recursive computations that manipulate higher-order data. Unlike some other uses of context variables [8], a context may contain at most one context variable 2 . As types classify objects, and kinds classify types, we introduce the notion of schemas W that classify contexts Ψ. Context variables’ schemas are given in a schema context Ω. We define schemas in Section 3.2.
Substitutions σ are built of normal terms (in σ ; M ) and atomic terms (in σ, R). We do not make the domain explicit, which simplifies the theoretical development and avoids having to rename the domain of a given σ. We also have a first-class notion of identity substitution idψ. We write [σ]N for substitution application.
We assume that type constants and object constants are declared in a signature S as pure LF objects—data of dependent function type. We suppress the signature since it is the same throughout all derivations. As a notational convenience, we generalize pairs to n-ary tuples, writing proj# R for the kth projection of R. For example, the second element of a triple is proj# R = proj1(proj2 R).

Data-level typing
We type data-level terms bidirectionally. Normal objects are checked against a given type in the judgment Ω; Δ; Ψ ▶ M ⇐ A, while neutral objects synthesize their type: Ω; Δ; Ψ ▶ R ⇒ A. Substitutions are checked against their domain: Ω; Δ; Ψ ▶ σ ⇐ Φ. For readability, we omit the schema context Ω in the subsequent development since it is constant, and assume that Δ and Ψ are well-formed.
We give the typing rules for data-level terms in Figure 4. We assume that data- level type constants a together with constants c have been declared in a signature. We will tacitly rename bound variables, and maintain that contexts and substitu- tions declare no variable more than once. Note that substitutions σ are defined only on ordinary variables x, not on modal variables u. We also require the usual conditions on bound variables. For example, in ΠI the bound variable x must be new and cannot already occur in Ψ. This can always be achieved via α-renaming.

The typing rules for neutral terms use hereditary substitutions [··· ]a
which preserve

canonical forms [10]. Hereditary substitution is defined recursively, considering both the structure of the term to which the substitution is applied and the type A of the object being substituted. Due to lack of space, we relegate the details to [3, appendix]. We omit the subscripts for readability in what follows.
Since hereditary substitution is decidable and the rules in Figure 4 are syntax- directed, data-level typing is decidable.


2 Lifting this restriction would require tracking dependencies of context variables on each other: in ψ, x:A, ψ', the context substituted for ψ' could depend on x or even on variables in ψ. Ensuring that α-renaming holds in the presence of multiple context variables and dependent types appears difficult.



Data-level normal terms
Δ; Ψ, x:A ▶ M ⇐ B
Δ; Ψ ▶ λx. M ⇐ Πx:A.B ΠI

Δ; Ψ ▶ M1 ⇐ A1	Δ; Ψ ▶ M2 ⇐ [M1/x]a A2
ΣI

Δ; Ψ ▶ (M1, M2) ⇐ Σx:A1.A2

Δ; Ψ ▶ R ⇒ P '	P ' = P
Δ; Ψ ▶ R ⇐ P
Data-level neutral terms
turn

	x:A ∈ Ψ	 var		c:A ∈ Σ	 con	u::A[Φ] ∈ Δ	Δ; Ψ ▶ σ ⇐ Φ mvar


Δ; Ψ ▶ x ⇒ A
Δ; Ψ ▶ c ⇒ A
Δ; Ψ ▶ u[σ] ⇒ [σ]a A

p::A[Φ] ∈ Δ	Δ; Ψ ▶ σ ⇐ Φ param	Δ; Ψ ▶ R ⇒ Πx:A.B	Δ; Ψ ▶ N ⇐ A ΠE

Δ; Ψ ▶ p[σ] ⇒ [σ]a A	Δ; Ψ ▶ R N ⇒ [N/x]a B
Δ; Ψ ▶ R ⇒ Σx:A1.A2 ΣE		Δ; Ψ ▶ R ⇒ Σx:A1.A2	 ΣE2

Δ; Ψ ▶ proj1R ⇒ A1
Δ; Ψ ▶ proj2R ⇒ [proj1R/x]a A2

Data-level substitutions	Δ; Ψ ▶·⇐·	Δ; ψ, Ψ ▶ id  ⇐ ψ

Δ; Ψ ▶ σ ⇐ Φ	Δ; Ψ ▶ R ⇒A'	[σ]a A=A'
Δ; Ψ ▶ (σ, R) ⇐ (Φ, x:A)
 Δ; Ψ ▶ σ ⇐ Φ	Δ; Ψ ▶ M ⇐ [σ]a A
Δ; Ψ ▶ (σ ; M ) ⇐ (Φ, x:A)




Context schemas
Fig. 4. Data-level typing and substitutions

As the earlier example illustrated, contexts play an important part in programming with open data objects. In particular, any contexts that are explicitly constructed and passed will belong to a specific context schema. In the earlier example, the schema (nat)∗ represented contexts of the form x1:nat,... , xn:nat. But we allow much more expressive contexts. For instance, when reasoning about natural de- ductions, the rule ⊃Iu adds an assumption of the form u:(nd A) for some concrete proposition A. The inductive definition Γ' ::= · | Γ', x:nat, | Γ', u:(nd A) corresponds to the schema (nat + (all A:o. nd A))∗.
We use + to denote a choice of possible elements in a context, and all allows us to describe an assumption for all possible propositions A. One concrete instance of this schema is x:nat, u:nd (eq x x), which arises when describing the derivation of forall (λx. (eq x x) imp (eq (Suc x) (Suc x))).
We give the grammar of schemas in Figure 5. Schemas are built of elements F1,... , Fn, each of the form all Θ˜. Σy1:B˜1,... , yj:B˜j . ˜b, where Θ˜ = x1:C˜1,... xk:C˜k . In other words, for any instantiation of Θ˜ (that is, any substitution for x1,... , xk), the element is of ΣΠ-type, where we first introduce some Σs, followed by Πs, with no subsequent Σs. This restriction makes it easier to describe the inhabitants of the type. Twelf has a similar restriction on worlds. In Beluga, computation typing [12] guarantees that contexts matching this grammar are the only contexts created dur- ing computation.
To check a context Ψ against a schema (F1+·· ·+Fn), we check that each element
x:A in Ψ is an instance of a schema element Fk = all Θ˜. Σy1:B˜1,... , yj:B˜j . B˜, with

Element types
A˜ ::= Πx:A.A˜ | a N1 ... Nn

Schema elements F ::= all x1:B˜1,... xk:B˜k. Σy1:A˜1,... , yj:A˜j .A˜
Schemas	W ::= (F1 + ··· + Fn)∗
Context Ψ checks against schema W
for some k



Ω; Δ ▶· ⇐ W
ψ::W ∈ Ω Ω; Δ ▶ ψ ⇐ W
Ω; Δ; Ψ ▶ A ∈ Fk	Ω; Δ ▶ Ψ ⇐ (F1 + ··· + Fn)∗


Ω; Δ ▶ Ψ, x:A ⇐ (F1 + ··· + Fn)∗

Type A is an instance of schema element F = all Θ˜. ΣΦ˜. B˜ Θ˜ = x1:C˜1,... , xn:C˜n	σ = u1[id(Ψ)]/x1,... , un[id(Ψ)]/xn
˜	˜	.	˜ ˜
Ω; Δ, u1::C1[Ψ],... , un::Cn[Ψ]; Ψ ▶ A = [σ]ΣΦ.B / (θ, Δ)
Ω; Δ; Ψ ▶ A ∈ all Θ˜. ΣΦ˜. B˜
Fig. 5. Schemas

all variables in Θ˜ instantiated such that x:A is an instance of Fk. The rule in Figure
.
5 uses higher-order pattern matching. The judgment A = B / (θ, Δ) means that θ
is a substitution such that [θ]]B = A.

Coverage checking
In this section, we present a theory for coverage checking. A derivation of a coverage judgment is a proof that every closed term of a given type A[Ψ] is an instance of at least one of a given set of patterns; in Beluga, this is the set of patterns guarding the branches of a case expression. Any set of patterns covers all terms of an empty type, and emptiness is undecidable [6, p. 179]. In Beluga, empty types should be very rare. In any case, since any algorithm must be incomplete, completeness of the theory is not essential.
Coquand [2] and Schu¨rmann and Pfenning [16] described coverage checking for closed terms, while Schu¨rmann [15, pp. 197–213] formulated coverage for open terms within regular worlds. Our theoretical treatment of coverage is the first in the setting of contextual modal type theory, where objects are closed with respect to explicit contexts that include context variables. This leads to a clean development of coverage.
To see that a set of patterns Z (in Beluga, the guards of a case expression) covers a given type, we usually need to split the type into an equivalent set of more precise patterns. To see that Z = {Zero, Suc u} covers all (closed) terms of type nat[·], we need to split nat[·] into the pattern set Z' = {Zero, Suc u1}. Now it is obvious that Z covers nat[·], because Z'—the result of splitting nat[·]—is α-equivalent to Z.
More generally, suppose we want to check that Z covers nat[Ψ]. If Ψ /= ·, we are dealing with open data, so when we split, we must consider variables as well as constructors. Suppose the type is nat[ψ, x:nat, y:o], where ψ represents a context of schema (o + nat)∗. The split then includes the constructors, parameter

variables denoting the generic case for variables from ψ (one variable for each schema element), and the concrete variables x and y:


  constructors of nat
¸	x`	˛
Zero, Suc u[idψ, x, y],
variables of ψ
¸	x`	˛
(p1[idψ]: o), (p2[idψ]: nat),
x:nat, y:o
¸x`˛
x, y


Not all of the variables are actually possible: p1[idψ] is of type o, but we are ana- lyzing type nat. The concrete variable y is similarly impossible. This gives the set
{Zero, Suc u[idψ, x, y], p2[idψ], x}.
For some sets Z we would also need to split Suc’s argument u[idψ, x, y] into its constituent constructors and variables. Decisions about when to split are not determined by our theory; such decisions are embodied in a nondeterministic choice between rules Obj-split and Obj-no-split. Our system is thus the foundation for a coverage checking algorithm.
After some remarks on substitutions and higher-order pattern unification, we state some key metatheoretical results, and then describe the coverage rules.
We write [θ ] for a contextual substitution substituting for u and p variables in Δ. The judgment Ω; Δ' ▶ θ ⇐ Δ says that θ is a contextual substitution with domain Δ and range Δ', under the schema context Ω. We write ρ as an abbreviation for (1) a context substitution on the schema context Ω, substituting for context variables ψ, and (2) a contextual substitution θ. The judgment Ω'; Δ' ▶ ρ : (Ω; Δ) says that the domain of ρ is (Ω; Δ) and its range is Ω'; Δ'. In the rules, we write data-level substitutions as [M/x]A. This is actually hereditary substitution, but we omit the types. See [3, appendix] for details.
We allow higher-order patterns in the sense of Miller [7], in which instantiated meta-variables must be applied to distinct sets of bound variables. Thus, contextual variables are associated with a substitution such as xΦ(1)/x1,... , xΦ(n)/xn. Match- ing is decidable and efficient [11]. The proof of the following is a simple extension of the one in [11].
Theorem 4.1 (Soundness of higher-order pattern unification)
If P and Q are well-formed types under Ω; Δ; Ψ, and Ω; Δ; Ψ ▶ Q o P / (θ, Δ'), then Ω; Δ' ▶ θ :Δ and Ω; Δ'; [[θ]]Ψ ▶ [[θ]]P = [[θ]]Q and θ is the most general uniﬁer, that is, for all ·; · ▶ ρ : (Ω; Δ) there exists ρ' such that ρ = [[ρ']]θ.
Lemma 4.2 (Object inversion) If ·; ·;Ψ ▶ R ⇐ P and ▶ Ψ: W then either
R = c N1 ... Nk where S(c)= Πx1:A1. ··· Πxk:Ak.P ' and [σ]P ' = P, or
R = x N1 ... Nk where (x : Πx1:A1. ··· Πxk:Ak.P ') ∈ Ψ and [σ]P ' = P, or
R = (proj# y) N1 ... Nk where (y : Σy1:A˜1,... ym:A˜m.A˜m+1) ∈ Ψ
and [σ]P ' = P and [proj# y/y1,... , proj# y/yl]A˜l+1 = Πx1:B1	Πxk:Bk.P '
1	l
where 1 ≤ l ≤ m,
where σ = N1/x1,... , Nk/xk.
Proof. By case analysis and inversion on the derivation of ·; ·;Ψ ▶ R ⇐ P .	 

Overview of coverage judgments

Given the set of guards in a case expression, Z, we assume each pattern ζ ∈ Z has the form ΠΔ'. box(Ψˆ .M ): A[Ψ'], where Δ' gives the types of contextual variables u and p in M (which will be bound to objects and variables, respectively, when a case expression is evaluated), where M has type A[Ψ']. Thus, a pattern in a case ex- pression is not simply Suc u[idψ, x], but Πu::nat[ψ, x:nat]. box(ψ, x. Suc u[idψ, x]) :
nat[ψ, x:nat]. In this example, and in many situations, Δ' and A[Ψ'] could be omit- ted in the source program and reconstructed. However, a dependently-typed Δ' such as u::(nd (eq x x))[x:nat] actually restricts u to match only natural-deduction proofs of eq x x. Similarly, a dependently-typed A can constrain the entire pattern.
The most essential coverage judgment, Ω; Δ; Ψ ▶ Obj(A) D covered-by Z, means that every object of type A is matched by at least one pattern in Z. For example, if we have a derivation of Ω; ·; ψ, x:nat, y:o ▶ Obj(nat) D covered-by Z then Z covers the type nat[ψ, x:nat, y:o].
Such a derivation has subderivations of the general form Ω; Δ; Ψ ▶ Obj(A) D J , which analyzes A and gives the result as input to J , which is (algorithmically) a kind of continuation. The earlier judgment is an instance of this form: it analyzes A and then “continues with” covered-by Z.
The splitting operation discussed earlier manifests as subderivations of Ω; Δ; Ψ ▶ M : A D J . Here, M is a term that plays the role of a pattern, with free variables u[σ]. Omitting contexts for clarity, a derivation where A = nat[·] would look like


M1
¸ x` ˛
	
A1
¸ x` ˛
M2
¸x`˛
A2
¸ x` ˛

Zero : na.t[·] D J	Suc u[·]: n.at[·] D J
	.	.	
Obj(nat[·]) D J


In general, M1,... , Mn collectively cover all possible terms of type A. That is, the subderivations correspond to a split into n patterns. In the example, n = 2.




covered-by: the leaves of a coverage derivation

We said that Obj(A) D covered-by Z means to analyze A and “continue with” covered-by Z. So, having analyzed A, splitting as necessary, we eventually come to subderivations of Mk : Ak D covered-by Z. These are the outermost branches of the derivation tree, and are the only places where Z is examined. Such subderiva- tions all have the same structure: Covered-By-Z picks out one pattern ζ from the




ˆ	.	'
ˆ'	'	'	'

Ω ▶ (ΠΔ.box(Ψ.M ): A[Ψ]) = (ΠΔ .box(Ψ .M ): A [Ψ ]) / (θ, Δ)
Ω ▶ ΠΔ.box(Ψˆ .M ): A[Ψ] covered-by (ΠΔ'.box(Ψˆ .M '): A'[Ψ'])
Covered-By-ζ




Ω; Δ; Ψ ▶ Q //o P	App-/o/
Ω; Δ; Ψ ▶ App⟨R⟩(Q > P ) D J
Ω; Δ; Ψ ▶ Q o P / (θ, Δ')
Ω; Δ'; [[θ]]Ψ ▶ [[θ]]R : [[θ]]P D [[θ]]J
Ω; Δ; Ψ ▶ App⟨R⟩(Q > P ) D J App-o

Ω; Δ; Ψ ▶ App⟨R M ⟩([M/x]B > P ) D J
Ω; Δ; Ψ ▶ M : A D neutral⟨R⟩(x.B > P ) D J
Ω; Δ; Ψ ▶ Obj(A) D neutral⟨R⟩(x.B > P ) D J
Ω; Δ; Ψ ▶ App⟨R⟩(Πx:A.B > P ) D J	App-Π
for 0 ≤ i ≤ m:
Ω; Δ; Ψ ▶ App⟨proj# R⟩([proj#R/x1,... , proj#R/xi]A˜i+1 > P ) D J

i	1	i
App-Σ

Ω; Δ; Ψ ▶ App⟨R⟩(Σx1:A˜1,... , xm:A˜m.A˜m+1 > P ) D J

Ω ▶ ΠΔ.box(Ψˆ .M ): A[Ψ] covered-by ζk
Ω; Δ; Ψ ▶ M : A D covered-by {ζ ,... ,ζ } Covered-By-Z
1	n

Ω; Δ; Ψ ▶ (λx. M ): (Πx:A1.A2) D J
Ω; Δ; Ψ, x:A1 ▶ M : A2 D lam D J
Ω; Δ; Ψ ▶ (M, N ): Σx:A1.A2 D J
Ω; Δ; Ψ ▶ N : [M/x]A2 D pair2 (M :A1, x.•) D J
Ω; Δ; Ψ ▶ Obj([M/x]A2) D pair2 (M :A1, x.•) D J
Ω; Δ; Ψ ▶ M : A1 D pair1 (•, x.A2) D J



Ω; Δ; Ψ, x:A1 ▶ Obj(A2) D lam D J
Ω; Δ; Ψ ▶ Obj(Πx:A1.A2) D J	Obj-Π
Ω; Δ; Ψ ▶ Obj(A1) D pair1 (•, x.A2) D J
Ω; Δ; Ψ ▶ Obj(Σx:A1.A2) D J	Obj-Σ

Ω; Δ; Ψ ▶ MVars(P ) D J
Ω; Δ; Ψ ▶ Obj(P ) D J	Obj-no-split
Ω; Δ; Ψ ▶ App⟨x1⟩(ΣΨ˜1.A˜1 > P ) D J
˜	˜	˜	˜	.

Ψ= ψ, x1:ΣΨ1.A1,... , xk:ΣΨk.Ak
Ω(ψ)= F1 + ··· + Fm
Ω; Δ; Ψ ▶ PVars⟨ψ : F1⟩ > P D J
.
Ω; Δ; Ψ ▶ PVars⟨ψ : Fm⟩ > P  D J
.
Ω; Δ; Ψ ▶ App⟨xk⟩(ΣΨ˜k.A˜k > P ) D J
Ω; Δ; Ψ ▶ App⟨c1⟩ ( S(c1) > P ) D J
.
Ω; Δ; Ψ ▶ App⟨cn⟩ (S(cn) > P ) D J

Ω; Δ; Ψ ▶ Obj(P ) D J	Obj-split

Fig. 6. Coverage checking rules

set Z, and then Covered-By-ζ checks that Mk is an instance of ζ. 3
ˆ	.
Ω ▶ (ΠΔ.box(Ψ. Mk): Ak[Ψ]) = ζ  / (θ, Δ) Covered-By-ζ
Ω ▶ ΠΔ.box(Ψˆ . Mk): Ak[Ψ] covered-by ζ



Ω; Δ; Ψ ▶ Mk : Ak D covered-by {... ,ζ,... }
Covered-By-Z

We assume that the pattern ζ includes an explicit meta-variable context Δ', explicit
data-level names Ψˆ ', and an explicit type A'[Ψ']. Thus, the premise of Covered-By-ζ

ˆ	.	'
ˆ'	'	'	'

is Ω ▶ (ΠΔ.box(Ψ. Mk): Ak[Ψ]) = (ΠΔ .box(Ψ .M ): A [Ψ ]) / (θ, Δ). This says
that Mk is an instance of M ' realized by θ, that is, Mk = [[θ]]M '. If each Mk is an instance of some pattern in Z, then Z covers all inhabitants of A.
Rules deriving Obj(A) D J
Having explained the high-level structure of coverage derivations and the details of the leaves, we can discuss the rules with conclusions of the form Obj(A) D J . These are the four rules at the bottom of Figure 6.
If A = Πx:A1.A2, we use Obj-Π to peel off the Π and analyze A2. The lam is added because after analyzing A2, we need to put back the Π and add a λ:
Ω; Δ; Ψ ▶ (λx. M ): (Πx:A1.A' ) D J

Ω; Δ; Ψ ▶ M : A'
.
D lam D J

Ω; Δ; Ψ, x:A1 ▶ Obj(A2) D lam D J
Ω; Δ; Ψ ▶ Obj(Πx:A .A ) D J	Obj-Π
1	2
Note that since splitting A2 may produce several patterns, we may have more sub- derivations (λx. ... ): (Πx:A1. ··· ) than just the one shown.
If A = Σx:A1.A2, rule Obj-Σ first analyzes A1 and then A2. The rules in Figure 6 are laid out vertically, in the same order as they appear in a derivation.
For base types P , we can either not split (rule Obj-no-split) or split (rule Obj-split). The latter rule is less complicated than it may look. The point is to split into pat- terns R N1 ... Nm, where R is a parameter p[σ] (left-hand premises), variable x (upper-right-hand premises), or constructor c (lower-right-hand premises),
The simplest of these are the premises App⟨ck⟩(S(ck) > P ) for constructors c. These cover all constructors ck, even those for base types that are incompatible with P —those will be discarded further up the derivation.
Deriving premises of the form Ω; Δ; Ψ ▶ App⟨R⟩(S(ck) > P ) D J is somewhat involved, since we need to generate all spines (lists of arguments) N1 ... Nm. Here, the P denotes that we are constructing objects of type P . The constructor type S(ck) must have the form Πx1:A1. ··· Πxm:Am.Q, where Q is a base type. In deriving

3 Note that we need matching, not just equality, in Covered-By-ζ. Suppose Z = {(u1[·], Zero), (Zero, u2[·])}. To show that (Zero, Suc v2[·]) is covered (by the second pattern in Z), we need to split the first component, and to show that (Suc v1[·], Zero) is covered (by the first pattern in Z), we need to split the second component. This results in a set of patterns including (Zero, Zero), which is not equal to any pattern in Z.



Θ˜ = y1:B˜1,... , yn:B˜n and Φ˜ = x1:A˜1,... , xj:A˜j
σ = u1[idψ]/y1,... , un[idψ]/yn	ΔΘ = u1::B˜1[ψ],... , un::B˜n[ψ] for 0 ≤ i ≤ j:
σ' = (proj# p[idψ])/x1,... , (proj# p[idψ])/xi
1	i

Ω; Δ, ΔΘ, p::[σ]((ΣΦ˜.A˜j+1)[ψ]); Ψ ▶ App⟨proj#
Ω; Δ; Ψ ▶ PVars⟨ψ : all Θ˜. ΣΦ˜.A˜
p[idψ]⟩([σ'][σ]A˜i+1 > P ) D J
PVars
⟩ > P D J

j+1



ValidWk(Ω; Δ ▶ P [Ψ])
= {Ψ1,... , Ψn}
Ω; Δ, u::P [Ψ1]; Ψ ▶ (u[id(Ψ1)] : P ) D J
.
Ω; Δ, u::P [Ψn]; Ψ ▶ (u[id(Ψn)] : P ) D J

Ω; Δ; Ψ ▶ MVars(P ) D J	MVars
Fig. 7. Coverage checking rules (continued)
this, we use App-Π, which uses Obj(A1) to analyze A1, and (through neutral) adds the resulting inhabitants M1 of A1 to ck.
Doing this for each xi:Ai yields subderivations of App⟨ck N1 ... Nm⟩(Q > P ), for various spines N1 ... Nm. If Q and P do not unify (written Q //o P in rule App-//o) we have a trivial coverage subderivation, but if Q and P do unify under some θ, then we can use App-o, which has a premise [θ]]R : [[θ]]P D [[θ]]J .
Returning to rule Obj-split itself, the premises App⟨xk⟩(B > P ) D J for variables are structurally similar to those for constructors. However, unlike S(ck), the variable type B could contain Σs, so we use App-Σ to take projections out of the tuple.
The remaining premises of Obj-split have the form PVars⟨ψ : F ⟩ > P D J , characterizing the generic variable cases.

PVars⟨ψ : F ⟩ > P D J : Parameter variables
Exactly one rule concludes PVars⟨.. .⟩, the rule PVars in Figure 7. In PVars, we gen- erate a parameter variable for each schema element. We first create a meta-variable for each all -quantified variable in the element. For example, if F = all A:o.nd A, then p[idψ] has type nd u[idψ] where u is a (fresh) meta-variable. In general, we get the type of a parameter from the element all Θ˜.ΣΦ˜.A˜ by generating a substitution σ' that instantiates all variables in Θ˜ with meta-variables, and applying σ' to ΣΦ˜.A˜. Then we use the ideas for concrete variables. Again, since [σ']ΣΦ˜.A˜ is inhabited by tuples, we consider all possible projections.

MVars(P ) D J : General case for all ground instances of P
The premise of rule Obj-no-split is MVars(P ), which is derivable only by rule MVars
(Figure 7). This rule does not recursively analyze the given type P . Instead, it

produces patterns u[id(Ψk)], which any object of type P [Ψk] matches. 4
Simply generating u[id(Ψ)] does not suffice if the user wrote cases with different contexts, as when eq U[idψ, x] V[idψ, x] is written as four cases {eq U[idψ] V[idψ], eq U[idψ, x] V[idψ],  eq U[idψ] V[idψ,x],  eq U[idψ, x] V[idψ, x]}.
In fact, we generate all valid weakenings of Ψ. A weakening Ψ' ⊆ Ψ has zero or more assumptions from Ψ (preserving order). These contexts are weaker because they provide less information. Not all weakenings make sense; for example, remov- ing x:nat from (x:nat, y:(eq x x)) yields (y:(eq x x)), which is dependent on an undeclared x. The valid weakenings ValidWk(Ω; Δ ▶ A[Ψ]) of a context Ψ with respect to a type A are those that are well-formed and make A well-formed.
Coverage soundness
Roughly, the soundness result we need is that, if ·; ·;Ψ ▶ Obj(A) D covered-by Z, then for every M of type A there is a pattern in Z that matches M . That theorem will not be difficult once we have a key lemma, which will guarantee that if D derives Obj(A) D J then, for every ground M ' of type A, there is within D a derivation of Mi : A D J , where M ' is an instance of Mi. Put another way, the lemma states that the illustration from Section 4.1 is accurate.
Once we have this lemma, soundness is straightforward: if J = covered-by Z, the lemma gives a subderivation D' of ... ▶ M : A D covered-by Z, and inversions bring us to the premise of Covered-By-Z.
To state the lemma precisely, we first observe that the judgment form Ω; Δ; Ψ ▶ Obj(A) D J allows for nonempty Ω and Δ. However, at runtime, we only have concrete contexts, so Ω is empty. Also, objects are ground, containing no contextual variables u and p, so Δ is empty. We can of course have a nonempty Ψ, though since Ω is empty, Ψ will contain no context variables.
Thus, the antecedent that M ' has type A can be ground: ·; ·; [[ρ]]Ψ ▶ M ' ⇐ [[ρ]]A, where Ω and Δ are grounded by ·; · ▶ ρ : (Ω; Δ). In addition, the domain of D' need not exactly match the domain of D. In fact, the type in D' will be [θ]]A, where θ is a substitution from Δ to Δ'. This is consistent with the intuition that types become more precise as we move into subderivations.
As we have θ from Δ to Δ', and ρ from (Ω; Δ) to ground (·; ·), the lemma also asserts the existence of a ρ' from (Ω; Δ') to ground, so that ρ = [[ρ']]θ.
In part (2) of the lemma, we reason correspondingly about App derivations.
Lemma 4.3 (Coverage Soundness)
If D :: Ω; Δ; Ψ ▶ Obj(A) D J and ·; ·; [[ρ]]Ψ ▶ M ' ⇐ [[ρ]]A and ·; · ▶ ρ : (Ω; Δ)
then there exist θ and M such that Ω; Δ' ▶ θ ⇐ Δ
and D' :: Ω; Δ'; [[θ]]Ψ ▶ M : [[θ]]A D [[θ]]J	where D' < D
and Ω; Δ'; [[θ]]Ψ ▶ M ⇐ [[θ]]A and there exists ρ' s.t. ρ = [[ρ']]θ and M ' = [[ρ']]M .
If D :: Ω; Δ; Ψ ▶ App⟨R⟩(A˜ > P ) D J and Ω; Δ; Ψ ▶ R ⇒ A˜

and ·; · ▶ ρ : (Ω; Δ) and for all spines N ' ,... ,N '
of some length n such that

1	n

4  The operation id(Ψ) unrolls Ψ. For example, id(ψ, x:nat)= idψ, x. See [3, appendix] for details.

·; ·; [[ρ]]Ψ ▶ ([[ρ]]R) N ' ... N ' ⇐ [[ρ]]P ,
1	n
then D' :: Ω; Δ'; [[θ]]Ψ ▶ [[θ]](R N1 ... Nn): [θ]]P D [[θ]]J
and for all i we have [[ρ]]Ni = N ' and there exists ρ' s.t. ρ = [[ρ']]θ.
Proof. By complete induction on the height of D.	 
Theorem 4.4 (Coverage Soundness)
If ·; ·;Ψ ▶ M ' ⇐ A and ·; ·;Ψ ▶ Obj(A) D covered-by Z
then there exists ζ ∈ Z such that ζ = (ΠΔk.box(Ψˆ . Mk): Ak[Ψk])

'	ˆ	.
'	'	'

and ·▶ (ΠΔ .box(Ψ.M ): A[Ψ]) = ζ / (θk, Δ ) where M = [[ρ ]][[θk]]Mk.
Proof. By Lemma 4.3, inversion, and correctness of higher order matching. 

Conclusion
Most previous work on coverage checking, such as Coquand’s work [2] in the setting of Agda and later refinements of this approach [6,9], dealt with closed data objects. In the setting of logical frameworks, theoretical work on coverage also concentrated on closed objects [16]. In contrast, we have presented a framework for coverage checking terms that depend on assumptions in a given context. Schemas and pa- rameter variables allow us to analyze generic cases for all objects represented by a context variable.
We have concentrated on the Beluga language, but systems like Delphin and Twelf have to address a very similar issue. In Twelf, contexts are characterized by world declarations. However, there is an important difference between worlds and schemas. In Twelf, to count free occurrences of a variable, we would write a relation. But there is no way to write a generic base case for all possible variables occurring in a context represented by ψ. Instead, we must introduce dynamic extensions for each variable encountered when we traverse a binder. Thus, the world declaration not only captures the bound variables introduced when we traverse a binder, but also a base case for each binder. Consequently, some of the base cases are scattered, and world declarations tend to be more complicated than our schema declarations. It also makes world and coverage checking significantly more complicated.
Delphin has no explicit context variables and distinguishes parameters at the type level, rather than the syntax level. Nevertheless, we believe our framework could provide insights into the Delphin coverage checker [14] as well.
We plan to implement a coverage algorithm based on the ideas in this paper within the Beluga prototype.

References
David Baelde, Andrew Gacek, Dale Miller, Gopalan Nadathur, and Alwen Tiu. The Bedwyr system for model checking over syntactic expressions. In Frank Pfenning, editor, 21st Conference on Automated Deduction, number 4603 in LNAI, pages 391–397. Springer, 2007.
Thierry Coquand. Pattern matching with dependent types. In Informal Proceedings of Workshop on Types for Proofs and Programs, pages 71–84. Dept. of Computing Science, Chalmers Univ. of Technology and G¨oteborg Univ., 1992.


Jana Dunfield and Brigitte Pientka. Case analysis of higher-order data. Extended online version of this paper. http://complogic.cs.mcgill.ca/beluga , June 2008.
Andrew Gacek, Dale Miller, and Gopalan Nadathur. Combining generic judgments with recursive definitions. In F. Pfenning, editor, 23rd Symposium on Logic in Computer Science. IEEE Computer Society Press, 2008.
Robert Harper, Furio Honsell, and Gordon Plotkin. A framework for defining logics. Journal of the ACM, 40(1):143–184, January 1993.
Conor McBride. Dependently Typed Functional Programs and Their Proofs. PhD thesis, University of Edinburgh, 2000. Technical Report ECS-LFCS-00-419.
Dale Miller. A logic programming language with lambda-abstraction, function variables, and simple unification. Journal of Logic and Computation, 1(4):497–536, 1991.
Andrew McCreight and Carsten Schu¨rmann. A meta-linear logical framework. In 4th International Workshop on Logical Frameworks and Meta-Languages (LFM’04), 2004.
Ulf Norell. Towards a practical programming language based on dependent type theory. PhD thesis, Department of Computer Science and Engineering, Chalmers University of Technology, September 2007.
Aleksandar Nanevski, Frank Pfenning, and Brigitte Pientka. Contextual modal type theory. ACM Transactions on Computational Logic, 9(3), 2008.
Brigitte Pientka. Tabled higher-order logic programming. PhD thesis, Department of Computer Science, Carnegie Mellon University, 2003. CMU-CS-03-185.
Brigitte Pientka. A type-theoretic foundation for programming with higher-order abstract syntax and first-class substitutions. In 35th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages (POPL’08), pages 371–382. ACM, 2008.
Frank Pfenning and Carsten Schu¨rmann. System description: Twelf — a meta-logical framework for deductive systems. In H. Ganzinger, editor, Proceedings of the 16th International Conference on Automated Deduction (CADE-16), pages 202–206. Springer LNAI 1632, 1999.
Adam Poswolsky and Carsten Schu¨rmann. Practical programming with higher-order encodings and dependent types. In Proceedings of the 17th European Symposium on Programming (ESOP ’08), March 2008.
Carsten Schu¨rmann. Automating the Meta Theory of Deductive Systems. PhD thesis, Department of Computer Science, Carnegie Mellon University, 2000. CMU-CS-00-146.
Carsten Schu¨rmann and Frank Pfenning. A coverage checking algorithm for LF. In D. Basin and
B. Wolff, editors, Proceedings of the 16th International Conference on Theorem Proving in Higher Order Logics (TPHOLs’03), volume 2758 of Lecture Notes in Computer Science, pages 120–135, Rome, Italy, 2003. Springer.
Carsten Schu¨rmann, Adam Poswolsky, and Jeffrey Sarnat. The ∇-calculus. Functional programming with higher-order encodings. In Pawel Urzyczyn, editor, Proceedings of the 7th International Conference on Typed Lambda Calculi and Applications (TLCA’05), volume 3461 of Lecture Notes in Computer Science, pages 339–353. Springer, 2005.
Kevin Watkins, Iliano Cervesato, Frank Pfenning, and David Walker. A concurrent logical framework I: Judgments and properties. Technical Report CMU-CS-02-101, Department of Computer Science, Carnegie Mellon University, 2002.
