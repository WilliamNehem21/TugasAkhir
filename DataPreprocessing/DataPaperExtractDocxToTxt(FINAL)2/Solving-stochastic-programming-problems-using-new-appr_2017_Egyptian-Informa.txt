



FULL-LENGTH ARTICLE
Solving stochastic programming problems using new approach to Differential Evolution algorithm

Ali Wagdy Mohamed

Operations Research Department, Institute of Statistical Studies and Research, Cairo University, Giza 12613, Egypt

Received 2 October 2015; revised 24 August 2016; accepted 27 September 2016
Available online 27 October 2016

Abstract This paper presents a new approach to Differential Evolution algorithm for solving stochastic programming problems, named DESP. The proposed algorithm introduces a new trian- gular mutation rule based on the convex combination vector of the triangle and the difference vec- tor between the best and the worst individuals among the three randomly selected vectors. The proposed novel approach to mutation operator is shown to enhance the global and local search capabilities and to increase the convergence speed of the new algorithm compared with conven- tional DE. DESP uses Deb’s constraint handling technique based on feasibility and the sum of con- straint violations without any additional parameters. Besides, a new dynamic tolerance technique to handle equality constraints is also adopted. Two models of stochastic programming (SP) problems are considered: Linear Stochastic Fractional Programming Problems and Multi-objective Stochas- tic Linear Programming Problems. The comparison results between the DESP and basic DE, basic particle swarm optimization (PSO), Genetic Algorithm (GA) and the available results from where it is indicated that the proposed DESP algorithm is competitive with, and in some cases superior to, other algorithms in terms of final solution quality, efficiency and robustness of the considered prob- lems in comparison with the quoted results in the literature.
© 2016 Production and hosting by Elsevier B.V. on behalf of Faculty of Computers and Information,
Cairo University. This is an open access article under the CC BY-NC-ND license (http://creativecommons.
org/licenses/by-nc-nd/4.0/).



Introduction

Stochastic or probabilistic programming (SP) deals with situa- tions where some or all of the parameters of the optimization

E-mail address: aliwagdy@gmail.com
Peer review under responsibility of Faculty of Computers and Information, Cairo University.
problem are described by random or probabilistic variables rather than by deterministic quantities [1]. The mathematical models of these problems may follow any particular probabil- ity distribution for model coefficients [2]. The main objective is to find the optimal value for model parameters influenced by random event. The basic idea used in stochastic programming is to convert the stochastic problem into an equivalent deter- ministic problem which can be solved by using an appropriate classical and/or modern numerical technique. SP is widely used in many real-world decision making problems of management science, engineering, and technology. Also, it has been applied to various areas such as finance [3], manufacturing product


http://dx.doi.org/10.1016/j.eij.2016.09.002
1110-8665 © 2016 Production and hosting by Elsevier B.V. on behalf of Faculty of Computers and Information, Cairo University. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).



and capacity planning [4], electrical generation capacity plan- ning [5], supply chain management [6], water resource alloca- tion modeling [7], portfolio selection [8], project selection [9],
transportation [10], Telecommunications [11], energy planning
[12], healthcare management [13] and marketing [14]. A con- strained linear stochastic fractional programming (LSFP) problem involves optimizing the ratio of two linear functions subject to some constraints in which at least one of the prob- lem data is random in nature with nonnegative constraints on the variables. In addition, some of the constraints may be deterministic. Thus, the LSFP framework attempts to model uncertainty in the data by assuming that the input or a part thereof is specified by a probability distribution, rather than being deterministic [15]. There are many algorithms to solve LSFPP such as [16–19]. Moreover, SP has been applied to the problems having multiple, conflicting and non- commensurable objectives where generally there does not exist a single solution which can optimize all the objectives [20]. Various algorithms to solve Multiobjective Stochastic Linear Programming (MOSLP) problems have been discussed in the literature [20–23]. On the other hand, over the last three dec- ades, Evolutionary Algorithms (EAs) have been developed to solve nonlinear, high-dimensional and complex computational optimization problems. Virtually, EAs have been originally proposed to overcome the challenges of global optimization problems such as nonlinearity, non-convexity, non- continuity, non-differentiability, and/or multimodality, while
equality constraints is also adopted, (3) the crossover rate in
[27] is given by a dynamic nonlinear increased probability scheme, but in this work, the crossover rate is fixed 0.95. (4) The triangular mutation rule is only used in this work, but in the previous work [27], the triangular mutation strategy is embedded into the DE algorithm and combined with the basic mutation strategy DE/rand/1/bin through a nonlinear decreas- ing probability rule. (5) In previous work [27] a restart mech- anism based on Random Mutation and modified BGA mutation is used to avoid stagnation or premature conver- gence, whereas this work does not. The remainder of this paper is organized as follows: Section 2 presents the problem of our interest and the Deb’s procedure for handling constraints. In Section 3, the standard DE algorithm is introduced with a review of its operators and parameters. Next, in Section 4, the proposed DESP algorithm is described. The problem defi- nitions are given in Section 5. In Section 6, the effectiveness of the proposed method, the experimental settings and numerical results are discussed. Finally, the conclusions and future works are drawn in Section 7.

Problem statement

In general, constrained optimization problem can be expressed as follows (without loss of generality minimization is consid- ered here):

→	→
traditional numerical optimization techniques had difficulties
ffin	(1)

with these problems. Differential Evolution (DE) is a stochas- tic population-based search method, proposed by Storn and Price [24]. DE is considered the most recent EAs for solving real-parameter optimization problems [25]. While DE shares similarities with other EAs, it differs significantly in the sense that in DE, distance and direction information is used to guide the search process [26]. In this research, two models of stochas- tic programming (SP) problems are considered: Linear Stochastic Fractional Programming Problems and Multi- Objective Stochastic Linear Programming Problems. For LSFPP and MOSLP, the models proposed by Charles and
Minimize  f(x);	x = (x1; x2; ... ; xn)∈ 
Subject to:
→
gj(x) 6 0;  j = 1; ... ; q	(2)
→
hj(x)= 0;  j = q + 1; .. . ; m	(3)
→
where x ∈ X C S, X is the feasible region, and S is an
n -dimensional rectangular space in ffin defined by the paramet- ric constraints li 6 xi 6 ui; 1 6 i 6 n where li and ui are lower and upper bounds for a decision variable xi, respectively.
→
For  an  inequality  constraint  that  satisfies  gj (x) 6 0

→	→

Dutta [19] and by Charles et al. [20], respectively, are followed.
The deterministic equivalent models of these two classes of stochastic programming models are solved using a new approach to Differential Evolution algorithm, named DESP. The proposed algorithm introduces a new triangular mutation
(j ∈ 1; .. . ; q) at any point x ∈ X, we say it is active at x. All
→
equality constraints hj(x)= 0; (j = q + 1; ... ; m) are consid-
ered active at all points of X. Most constraint-handling approaches used with EAs tend to deal only with inequality constraints. Therefore equality constraints are transformed

rule based on the convex combination vector of the triangle	→


viduals among the three randomly selected vectors. The pro- posed novel approach to mutation operator is shown to enhance the global and local search capabilities and to increase the convergence speed of the new algorithm compared with conventional DE. DESP uses Deb’s constraint handling tech- nique based on feasibility and the sum of constraint violations without any additional parameters. Besides, a new dynamic tolerance technique to handle equality constraints is also adopted. The results obtained by DESP algorithms are com- pared with basic versions of DE and PSO and also with the results quoted in the literature [19,20]. It is worth noting that although this work is an extension and modification of our previous work in [27], there are significant differences as fol- lows: (1) previous work in [27] is proposed for unconstrained problems, whereas this work is proposed for constrained prob- lems. Hence, (2) a new dynamic tolerance technique to handle
e is the tolerance allowed (a very small value) [28]. In order
to handle constraints, we use Deb’s constraint handling proce- dure. Deb [29] proposed a new efficient feasibility-based rule to handle constraint for genetic algorithm where pair-wise solu- tions are compared using the following criteria:

Between two feasible solutions, the one with the highest fit- ness values wins.
If one solution is feasible and the other one is infeasible, the feasible solution wins.
If both solutions are infeasible, the one with the lowest sum of constraint violation is preferred.

As a result, Deb [29] has introduced the superiority of fea- sible solutions selection procedure based on the idea that any individual in a constrained search space must first comply with



the constraints and then with the objective function. Practi- cally, Deb’s selection criterion does not need to fine-tune any parameter. Typically, from the problem formulation above, there are m constraints and hence the amount of constraint violation for an individual is represented by a vector of m dimensions. Using a tolerance (e) allowed for equality con-



3.3. Mutation

At generation G, for each target vector xG, a mutant vector
vG+1 is generated according to the following:
vG+1 = xG + F * xG — xG ;	r1 – r2 – r3 – i	(8)

→
vidual x on the jth constraint is calculated by
with randomly chosen indices r1; r2; r3 ∈ {1; 2; ... ; NP}. F is a
real number to control the amplification of the difference vec-

→	( max(0; gj (→x ));	j = 1; .. . ; q
tor xG — xG . According to Storn and Price [34], the range of

cvj( x )= 
max(0; h ( x ) — e); j = q + 1; .. . ; m
(4)
r2	r3



If a decision vector or an individual x satisfies the jth con-
→
straint, cj(x) is set to zero. As discussed [30], in order to con-
sider all the constraints at the same time or to treat each constraint equally, each constraint violation is then normalized by dividing it by the largest violation of that constraint in the population. Thus, the maximum violation of each constraint in the population is given by
using (7) or new other repair method.

3.4. Crossover

The binomial crossover, the target vector is mixed with the mutated vector, using the following scheme, to yield the trial vector uG+1.

c j	= max
max	x→∈s
→
cj(x)
(5)


G+1
ij
G+1
ij
xG;	rand(j) > CR and j – randn(i);

(9)

These maximum constraint violation values are used to normalize each constraint violation. The normalized constraint violations are added together to produce a scalar constraint
→
violation c(x) for that individual which takes a value between
0 and 1
ij
where j = 1; 2; .. . ; D, rand(j)∈ [0; 1] is the jth evaluation of a uniform random generator number. CR ∈ [0; 1] is the cross- over rate, randn(i)∈ {1; 2; ... ; D} is a randomly chosen index
which ensures that uG+1 gets at least one element from vG+1;

i	i
otherwise, no new parent vector would be produced and the
m	→

→	 1 X cj(x)

 

population would not alter.





Methodology

Differential Evolution (DE)
DE adapts a greedy selection strategy. If and only if the trial vector uG+1 yields as good as or a better fitness function value
than xG, then uG+1 is set to xG+1. Otherwise, the old vector xG is

i	i	i	i


This section provides a brief summary of the basic Differential Evolution (DE) algorithm. In simple DE, generally known as
retained. The selection scheme is as follows (for a minimization
problem):
( uG+1; f uG+1 6 f(xG)

→
of NP vectors Xi, 6i = 1; 2; ... ; NP, and is randomly generated
according to a uniform distribution within the lower and upper boundaries  xL; xU . After initialization, these individuals are
evolved by DE operators (mutation and crossover) to generate a trial vector. A comparison between the parent and its trial vector is then done to select the vector which should survive to the next generation [33]. DE steps are discussed below:

Initialization

In order to establish a starting point for the optimization pro- cess, an initial population must be created. Typically, each decision variable in every vector of the initial population is assigned a randomly chosen value from the boundary constraints:

x0 = xL + randj · xU — xL	(7)

where randj denotes a uniformly distributed number between [0, 1], generating a new value for each decision variable.
i	xG;	otherwise
A detailed description of standard DE algorithm is given in Fig. 1.

DESP algorithm

All evolutionary algorithms, including DE, are stochastic population-based search methods. Accordingly, there is no guarantee that the global optimal solution will be reached con- sistently. Furthermore, they are not originally designed to solve constrained optimization problems. Nonetheless, adjust- ing control parameters such as the scaling factor, the crossover rate and the population size, alongside with developing an appropriate mutation scheme and coupling with suitable and effective constraint-handling techniques can considerably improve the search capability of DE algorithms. Moreover, the possibility of achieving promising and successful results in complex numerical and engineering constrained optimiza-


cations are introduced in order to significantly enhance the overall performance of the standard DE algorithm.



Figure 1  Description of standard DE algorithm. rand [0, 1) is a function that returns a real number between 0 and 1. randint (min, max) is a function that returns an integer number between min and max. NP, GEN, CR and F are user-defined parameters. D is the dimensionality of the problem.


Triangular mutation

Practical experience through many developed evolutionary algorithms and experimental investigation prove that the suc- cess of population-based search algorithms is based on main- taining a balance between two contradictory aspects: exploration and exploitation [35]. Moreover, the mutation
the local search tendency, to improve the global exploration ability and to accelerate the convergence of standard DE tech- nique, a new triangular mutation rule is proposed based on the convex combination vector of the triangle and the difference vector between the best and the worst individuals among the three randomly selected vectors. The modified mutation scheme is as follows:

scheme plays a vital role in the DE search capability and the
mG+1 = x¯G + 2F · xG
— xG
	(11)

convergence rate. However, even though the DE algorithm
has good global exploration ability, it suffers from weak local
i;j
c;j
best;j
worst;j

exploitation ability and its convergence velocity is still too low
where x¯G is a convex combination vector of the triangle and

as the region of the optimal solution is reached [36]. Clearly,
G
best
G
worst
are the best and the worst individuals among

from the mutation Eq. (8), it can be observed that three vectors are randomly chosen for mutation and the base vector is then randomly selected among the three. Consequently, the basic mutation strategy DE/rand/1/bin is able to maintain popula- tion diversity and global search capability, but it slows down
the three randomly selected vectors, respectively. F is a uni-
form random variables, u(0; 1) returns a real number between
0 and 1 with uniform random probability distribution and G is the current generation number. This modification is intended
to replace the random base vector xG in Eq. (8) by the convex
1

the convergence of DE algorithms. Hence, in order to enhance
combination vector x¯G
and the remaining two vectors are

replaced by the best and worst vectors of the three randomly selected vectors to yield the difference vector. The mutation operation in Eq. (11) is originally performed according to the following mutation equation:
mG+1 = x¯G + F · xG  — xG   + F · xG  — xG
region of each x¯G in the direction of xG — xG for each mutated vector. In a nutshell, it concentrates the exploitation of some sub-regions of the search space. Thus, it has better local search tendency so it accelerates the convergence speed of the proposed algorithm. Besides, the global exploration



where xG

G
best,j

G
better

G
worst,j

G
worst
	(12)
are the tournament best, better and
many different sizes and shapes of triangles in the feasible region through the optimization process. Thus, the proposed directed mutation balances both global exploration capability

worst three randomly selected vectors, respectively. The con- vex combination vector x¯G of the triangle is a linear combina- tion of the three randomly selected vectors and is defined as follows:
and local exploitation tendency.

Modification of scaling factor

x¯G = w1 · xG
G
better
G
worst
(13)
In the mutation Eq. (8), the constant of differentiation F is a scaling factor of the difference vector. It is an important

where the real weights w satisfy w P 0 and	3 w = 1. Where the real weights wi are given by wi = p /P3  p ,
parameter that controls the evolving rate of the population. Regarding global unconstrained optimization, in the original

i = 1, 2, 3.  Where  p1 = 1,  p2 = rand(0.5, 1)  and  p3 =
rand(0, 0.5), rand(a, b) are functions that return a real number
between a and b, where a and b are not included. For constrained optimization problems at any generation g > 1, the tournament selection of the three randomly selected vectors and assigning weights follow one of the following three scenarios that may exist through generations, Without loss of generality, we only consider minimization problems:
Scenario 1: If the three randomly selected vectors are feasi- ble, then sort them in ascending according to their objective
chosen to be a value in [0, 2]. The value of F has a considerable influence on exploration: small values of F lead to premature convergence. Besides, it can lead to speed up the convergence, and high values slow down the search [36]. In this paper, for the difference vector in the mutation Eq. (11), it can be seen that it is a directed difference vector from the worst to the best vectors in the entire population. Hence, F must be a positive value in order to bias the search direction for all trial vectors in the same direction. Therefore, F is introduced as a uniform random variable within (0, 1]. Instead of keeping F constant

function values and assign w1, w2, w3 to xG
G
better
and
during the search process, F is set as a random variable for

G
worst
, respectively.
each trial vector so as to perturb the random base vector by

Scenario 2: If the three randomly selected vectors are infea-
sible, then sort them in ascending order according to their con- straint violation (CV) values and assign w1, w2, w3 to xG ,
different directed weights. Therefore, the new directed muta-
tion resembles the concept of gradient as the difference vector is oriented from the worst to the best vectors [37,38].

G
better
G
worst
, respectively.

Scenario 3: If the three randomly selected vectors are mixed
(feasible and infeasible), then the vectors are sorted by using the three criteria: (a) Sort feasible vectors in front of infeasible solutions, (b) sort feasible solutions according to their objec- tive function values, and (c) sort infeasible solutions according to their constraint violations. Accordingly, assign w1, w2, w3 to
Equality constraint approach

For any feasible region limited by a set of constraints, if one of these constraints is represented by equality, the feasible region becomes a line segment. Furthermore, if all these constraints
are equality constraints, then the feasible region is reduced

G
best
G
better
G
worst
, respectively. Obviously, from mutation
to a point i.e. the intersection point of all constraints. There-

Eqs. (11) and (13), it can be observed that the incorporation
fore, although the equality constraints are transformed into

of the objective function value and constraints violation in	→



part of the mutation is formed by the three sides of the triangle
in the direction of the best vector among the three randomly selected vectors. Therefore, the directed perturbation in the proposed mutation resembles the concept of gradient as the difference vector is oriented from the worst to the best vectors [36]. Thus, it is considerably used to explore the landscape of the objective function being optimized in different sub-region around the best vectors within constrained search-space through optimization process. Secondly, the convex combina- tion vector x¯G is a weighted sum of the three randomly selected vectors where the best vector has the highest contribution. Therefore, x¯G is extremely affected and biased by the best vec- tor more than the remaining two vectors. Consequently, the global solution can be easily reached if all vectors follow the direction of the best vectors besides they also follow the oppo- site direction of the worst vectors among the randomly selected vectors. Indeed, the new mutation process exploits the nearby
the tolerance allowed (a very small value), it still makes the fea-
sible region very small compared with the search space, which exacerbates the optimization process using any evolutionary algorithm to find the feasible solutions. As a result, the larger the tolerance value, the more reliable feasible solutions found [28,39]. In other words, the temporary increase in the feasible space during the initial generations of the search process there will be some feasible individuals from the beginning of the optimization process. Then, by reducing the search space after some generations by decreasing the tolerance value (e), the algorithm will improve the previous feasible solutions to fit into the new feasible region and satisfy the new equality con- straints. Hence, in order to deal with equality constraints, the researchers introduce the new approach that dynamically changes the value of (e) through generations. The tolerance value (e) is adapted and decreased through generations by using the following mathematical expression:

—1 * (log10 (4)/log10 (10)),  0.00 6 G/GEN < 0.05
—1 * (log10 (3)/log10 (10)),  0.05 6 G/GEN < 0.10
> —1 * (log10 (2)/log10 (10)), 0.10 6 G/GEN < 0.15

 

the feasible space is rapidly decreased during the initial 20% of total generations of the search process in constant rate of 5% of total generations. However, to remove the improper



1,	0.20 6 G/GEN < 0.40
2,	0.40 6 G/GEN < 0.60
3,	0.60 6 G/GEN < 0.80

(14)

where e(t)= 10—Factor, G is the current generation number, GEN is the maximum number of generations. As can be easily derived from the above expression, as G/GEN increases toward 1, the tolerance value e(t) decreases from 4 to reach
10—(4) and stays fixed in the later generations. In other words, as G/GEN increases, the widening feasible region considerably shrinks to the true feasible region. Indeed, as number of equal-
ity constraints increases, the initial tolerance has also a signif- icant impact in creating the suitable initial feasible region that can attract too many infeasible points which can be improved through generations to be feasible. Moreover, as previously discussed, it can be observed that, the temporary increase in
erations during the remaining generations. The description of DESP is presented in Fig. 2.

Problem definition

This section is divided into two subsections; in Section 1, the problem formulation of LSFPPs is given and the general model of the multi-objective SP problems with two test exam- ples is given in Section 2.

Linear Stochastic Fractional Programming model

A linear stochastic fractional programming (LSFP) problem involves optimizing the ratio of two linear functions subject to some constraints in which at least one of the problem data is random in nature with non-negative constraints on the vari- ables. Additionally, some of the constraints may be determin- istic [40]. The LSFP framework attempts to model uncertainty



Figure 2	Description of DESP algorithm.



in the data by assuming that the input or a part there of is spec- ified by a probability distribution, rather than being determin- istic. The problem of optimizing sum of more than one ratios of function is called stochastic sum-of-probabilistic fractional programming (SSFP) problem when the data under study are random in nature. The following section gives the general model of the SSFP problems.
The mathematical model of a stochastic SSFP problem can be expressed as follows [19]:
k
max R(X)=  Ry(X),
Subject to:
a11x1 + a12x2 + a13x3 6 b1, a31x1 + a32x2 + a33x3 6 20,
x1 + x2 + x3 6 b3,
5x1 + 3x2 + 4x3 6 15, x1, x2, x3 P 0
The deterministic model of the above problem may be given as follows:
Max F(x)= k1 + k2 + k3
Subject to:
(k + 2k + 4k — 17)x + (k + k + k — 19)x


where R (X)= Ny (X)+ay , y = 1, 2,.. ., k.
y	y
+ (k1 + 4k2 + 7k3 — 23)x3 + 2k1 + 10k2 + 5k3
+ 1.645q(ﬃﬃkﬃﬃﬃ2ﬃﬃ+ﬃﬃﬃﬃﬃ0ﬃﬃ.ﬃﬃ5ﬃﬃkﬃﬃ2ﬃﬃ)ﬃﬃxﬃﬃﬃ2ﬃﬃ+ﬃﬃﬃﬃﬃ(ﬃﬃ0ﬃﬃ.ﬃ5ﬃﬃﬃkﬃﬃ2ﬃﬃﬃ+ﬃﬃﬃﬃ2ﬃﬃkﬃﬃﬃ2ﬃﬃ)ﬃﬃxﬃﬃ2ﬃﬃﬃ+ﬃﬃﬃﬃ(ﬃﬃ2ﬃﬃkﬃﬃﬃ2ﬃﬃ+ﬃﬃﬃﬃﬃ3ﬃﬃkﬃﬃﬃ2ﬃﬃ)ﬃxﬃﬃﬃ2ﬃ 6 12,

Subject to:
 Xn	!
2	3  1
(4x1 + 2x2 + 4x3)
2	3  2
2	3  3

ij j	i	i
j=1
+ 1.645
0.5x1 + 0.25x2 + 0.5x3 + 0.25 6 12,
qﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ

Xn	(6x1 + 4x2 + 6x3)+ 1.28

 	



x2 + 0.5x2 + 0.75x2 6 20,

where 0 6 Xn×1 = ¨xj¨ ⊂ Rn is a feasible set and R : Rn → Rn,
Test example 3 (SSFP3)


Tm×n

= t(1) ,
2
Max R(X)= 

cy1x1 + cy2x2 + ay





(1)
m×1

= b(1) ,	i = 1, 2, ... , m,	j = 1, 2, ... , n;
y=1 dy1x1 + dy2x2 + by
Subject to: a11x1 + a12x2 + a13x3 6 27, 5x1 + 3x2 + x3 6 12,
x1, x2, x3 P 0.

b(2)
= b(2) ,	i = m + 1, .. . , h; a , b
are scalars.
The deterministic model of the above problem may be given



Ny(X)= Xcyjxj and Dy(X)= Xdyjxj

	


Subject to:

In this model, out of Ny(X), Dy(X), T and b(1) at least one may be a random variable.
S={X | Eqs. (15) and (16), X P 0, X ⊂ Rn} is non-empty,
(20 — 2k1 + 4k2)x1 + (16 — 3k1 — 2k2)x2 + (12 — 5k1 — 2k2)
— 10k1 — 12k2
— 1.28q(ﬃﬃkﬃﬃﬃ2ﬃﬃ+ﬃﬃﬃﬃﬃkﬃﬃ2ﬃﬃﬃ+ﬃﬃﬃﬃ1ﬃﬃﬃ0ﬃﬃ)ﬃﬃxﬃﬃﬃ2ﬃﬃ+ﬃﬃﬃﬃﬃ(ﬃ2ﬃﬃﬃkﬃﬃ2ﬃﬃﬃ+ﬃﬃﬃﬃkﬃﬃﬃ2ﬃﬃ+ﬃﬃﬃﬃﬃ4ﬃﬃ)ﬃﬃxﬃﬃﬃ2ﬃﬃ+ﬃﬃﬃﬃﬃ(ﬃﬃ3ﬃﬃkﬃﬃ2ﬃﬃﬃ+ﬃﬃﬃﬃ2ﬃﬃﬃkﬃﬃ2ﬃﬃﬃ+ﬃﬃﬃﬃ5ﬃﬃﬃ)ﬃﬃxﬃﬃ2ﬃﬃ P 3,


Test Example 1 (SSFP1)
(3x1 + 4x2 + 8x3)+ 1.645q2ﬃﬃﬃxﬃﬃﬃ2ﬃﬃ+ﬃﬃﬃﬃﬃxﬃﬃ2ﬃﬃﬃ+ﬃﬃﬃﬃxﬃﬃﬃ2ﬃ 6 27, 5x1 + 3x2 + x3 6 12,


2  c x + c x + a
Max R(X)= 
x1, x2, x3, k1, k2 P 0.
1	2	3

y=1 dy1x1 + dy2x2 + by
Subject  to:  a11x1 + a12x2	6 1, a21x1 + a22x2 6 b2, 16x1+
x2 6 4, x1, x2 P 0.
The deterministic model of the above problem may be given as follows:
Max F(x)= k1 + k2
Subject to:
(k1 + 2k2 — 5)x1 + (k1 + 3k2 — 4)x2
qﬃﬃﬃ2ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ2ﬃﬃ


For more details on the above examples, please refer [19].

Multi-Objective Stochastic Linear Programming model

The mathematical model of the MOSLP problem used in this study is given in the following subsection.
The general mathematical model of a constrained MOSLP may be given as [20]:
n
Maximize zk =	ckxj,	k = 1, 2, .. . , k
j=1

(2x1 + x2)+ 1.645qxﬃﬃﬃ2ﬃﬃﬃ+ﬃﬃﬃﬃﬃxﬃﬃ2ﬃﬃ 6 1, (3x1 + 4x2)
 Xn	Xn	Xn	!

+ 0.84q2ﬃﬃﬃxﬃﬃﬃ2ﬃﬃ+ﬃﬃﬃﬃﬃ3ﬃﬃﬃxﬃﬃ2ﬃﬃﬃ+ﬃﬃﬃﬃﬃ2ﬃﬃ 6 3, 16x1 + x2 6 4, x1, x2, k1, k2 P 0.

j=1

j=1

j=1



Test example 2 (SSFP2)
where 0 < p < 1 is usually close to 1. It has been assumed that

3	the parameters a and c are deterministic constants and b are

Max R(X)= X  cy1x1 + cy2x2 + ay

ij	j	j





Test example 1(MOSLP1)
Maximize z1 = 5x1 + 6x2 + 3x3, Maximize z2 = 6x1 + 3x2 + 5x3, Maximize z3 = 2x1 + 5x2 + 8x3
Subject to
P(3x1 + 2x2 + 2x3 6 b1) P 0.90, P(2x1 + 8x2 + 5x3 6 b2) P 0.98,
P(5x1 + 3x2 + 2x3 6 b3) P 0.95, P(0.5x1 + 0.5x2 + 0.25x3 6 b4) P 0.90,
P(8x1 + 3x2 + 4x3 6 b5) P 0.99, x1, x2, x3 P 0.
Here, b1 follow power Function distribution, b2 follow Par- eto distribution, b3 follow Beta distribution, b4 follow Weibull distribution, and b5 follow Bure type XII distribution. The problem is converted to deterministic model as follows:
Maximize z1 = k1(5x1 + 6x2 + 3x3)+ k2(6x1 + 3x2 + 5x3)
+ k3(2x1 + 5x2 + 8x3)
Subject to

Test example 2(MOSLP2)
Maximize z1 = 3x1 + 8x2 + 5x3, Maximize z2 = 7x1 + 4x2 + 3x3, Maximize z3 = 6x1 + 7x2 + 10.5x3
Subject to
P(5x1 + 4x2 + 2x3 6 b1) P 0.95, P(7x1 + 3x2 + x3 6 b2) P 0.95, P(2x1 + 7x2 + 3x3 6 b3) P 0.95, P(2x1 + 3x2 + 2.5x3 6 b4) P 0.95, P(5x1 + 2x2 + 1.5x3 6 b5) P 0.95, x1, x2, x3 P 0.
Here, b1 follow power Function distribution, b2 follow Par- eto distribution, b3 follow Beta distribution of the first kind, b4 follow Weibull distribution, and b5 follow Bure type XII distri- bution. The problem is converted to deterministic model as follows:
Maximize z1 = k1(3x1 + 8x2 + 5x3)+ k2(7x1 + 4x2 + 3x3)
+ k3(6x1 + 7x2 + 10.5x3)
Subject to
 y2  y2 — 100  y3 — 5  e2y4 — 1   3y2

				

Experimental settings and numerical results

In this section the computational results of DESP are dis- cussed as well in comparison with other algorithms.

Parameter settings

The three main control parameters of DESP algorithm, popu- lation size NP is 50 with exception to MOSLP2 with 75 as the number of decision variables increases (11 decision variables), crossover rate Cr is fixed 0.95 and F is a random variable fol- lowing uniform distribution as aforementioned. For each algo- rithm, the stopping criterion is to terminate the search process when one of the following conditions is satisfied:

the maximum number of generations is reached (assumed 1000 generations),
|fmax — fmin| < 10—4 where f is the value of objective function.

A total of 50 runs for each experimental setting were con- ducted and the best solution throughout the run was recorded as global optimum. Results obtained by the DESP versions are compared with LDE [2], basic DE, basic PSO and also previ- ously quoted results [19,20]. The results provided by these approaches were directly taken from [2]. Refer to [2] for more details about LDE algorithms.

Numerical results

DESP algorithm is compared with basic DE, basic PSO and LDE algorithms through various performance metrics like average fitness function value and standard deviation (SD). To compare the convergence speed of algorithms, we consid- ered the average number of function evaluations (NFEs).

Result analysis of SSFP

In order to study the performance of the proposed algorithm DESP on stochastic sum-of-fractional programming (SSFP) problems, performance comparison of DESP algorithm with basic DE, basic PSO, LDE algorithms and results in [19] is




5x1 + 4x2 + 2x3 = y1, 7x1 + 3x2 + x3 = y2 ,
2x1 + 7x2 + 3x3 = y3,
2x1 + 3x2 + 2.5x3 = y , 5x1 + 2x2 + 1.5x3 = y ,
of deterministic model (F(X)), optimal decision variable values,
standard deviation and average NFEs.
For the best results obtained by DESP, the constraints are

4
k1 + k2 + k3 = 1,
x1, x2, x3, y1, y2, y3, y4 , y5, k1, k2, k3 P 0.
5	[0, 0, —0.495616788561048, —0.597382431501665] to ensure
that it is feasible solution, and the objective function value is 1.83246. It can be seen from Table 1 that DESP, LDE1,








LDE2 and DE are able to find the optimal solution consis- tently in all runs but DESP has the lower standard deviation. Moreover, DESP has the better ‘‘best” objective function value than this obtained in [19] which is slightly infeasible solution. It is to be noted that the improvement percentage of DESP in terms of NFEs in comparison with DE, LDE1, LDE2 and PSO is 70.9%, 60.7%, 15.12% and 87.5%, respectively. There- fore, DESP is considered the most efficient with the smallest (NFE).
For the best results obtained by DESP, the constraints are  [0,  0,  —1.944514465098703,  —0.053585156014804,
—3.999177179444022] to ensure that it is feasible solution, and the objective function value is 15.2256. It can be seen from Table 2 that DESP, LDE2 and DE are able to find the optimal solution consistently in all runs but DESP has the lower stan- dard deviation. Besides, although the improvement percentage of LDE1 in terms of NFEs in comparison with DESP is 55.35%, the best solution obtained by LDE1 is inferior to the best solution obtained by DESP. Moreover, DESP has the better ‘‘best” objective function value than those obtained by PSO and [19]. It is to be noted that the improvement per- centage of DESP in terms of NFEs in comparison with DE, LDE2 and PSO is 73.8%, 0.027% and 75.98%, respectively. Therefore, DESP is considered the most efficient with the smallest (NFE).
For the best results obtained by DESP, the constraints are [0, —13.058526571600890, 0] to ensure that it is feasible solu- tion, and the objective function value is 2.330846. It can be seen from Table 3 that DESP and LDE2 are able to find the optimal solution consistently in all runs but DESP has the lower standard deviation. However, LDE2 is considered the most efficient with the smallest (NFEs). Besides, although the improvement percentage of DE and LDE1 in terms of
NFEs in comparison with DESP is 0.03% and 0.09%, respec- tively, which is not a significant difference for the comparison, the best solutions obtained by DE and LDE1 are inferior to the best solution obtained by DESP. Moreover, DESP has the better ‘‘best” objective function value than that obtained by PSO. The improvement percentage of DESP in terms of NFEs in comparison with PSO is 86.78%. Moreover, it must be noted that the best solution obtained by [19] is infeasible solution  as  the  constraints  are  [23.999557387890611,
—14.216684855751021, 0], and the objective function value is 3.6584.

Results analysis of MOSLP

In order to study the performance of the proposed algorithm DESP on Multi-objective Stochastic Linear Programming Problems (MOSLP) problems, performance comparison of DESP algorithm with basic DE, basic PSO, LDE algorithms and results in [20] is given in Tables 4 and 5 in terms of best objective function value of deterministic model (F(X)), optimal decision variable values, standard deviation and average NFEs.
For the best results obtained by DESP, the constraints are [—3.077116474765064,  —0.000000085756271,  —1.4790101
31249243,   —0.533838884207691,   —3.567129578475143,
—0.000000137249561] to ensure that it is feasible solution, and the objective function value is 12.9312. It can be seen from Table 4 that DESP and PSO are able to find the optimal solu- tion consistently in all runs but DESP has the lower standard deviation. Thus, DESP is more robust than PSO. Besides, the improvement percentage of DESP in terms of NFEs in com- parison with PSO is 43.66%. Additionally, the best solutions obtained by DE and LDE1, LDE2 and the quoted result





[20], where the problem is solved by Genetic Algorithm (GA), are inferior to the best solution obtained by DESP regardless of their average NFEs. The improvement percentage of DESP in terms of objective function value in comparison with DE, LDE 1, LDE 2 and quoted result [20] is 136.2%, 127%,
1.07% and 152%, respectively.
Actually, this problems is very difficult to solve as it has the following common features: moderate dimensionality (eleven decision variables) which is almost twice the number of deci- sion variables in MOSLP 1 problem (six decision variables), nonlinear objective functions, more than one equality con- straint (six constraints) and one nonlinear inequality con- straint, and feasibility metric of zero as the feasible region is reduced to a point i.e. the intersection point of all constraints. Thus, it is very difficult to generate feasible solutions during the initial search process with these types of problem. How- ever, by using large tolerance value i.e. by widening the true feasible area, more feasible solutions can be generated to sat- isfy the equality constraints in the initial generation. Then,
43902, —0.000030808461554, —0.000098702360594, —0.000
000037835539] to ensure that it is the feasible and optimal solution (the intersection point of all equality constraints), and the objective function value is 16.689347. Thus, regardless of the average (NFEs) of all compared algorithms, DESP algo- rithm is superior to others in terms of objective function value and it is the only algorithm that is able to find new and the optimal solution to MOSLP 2 problem while the results obtained by others are infeasible solutions. In order to verify the efficiency of the proposed dynamic tolerance rule to handle equality constraints, another version of DESP algorithm, named DESP1, solves the MOSLP 2 problem without using

16
14
12
10

through generation, while the initial feasible region is con- tracted, the algorithm improves the previous feasible solutions to satisfy the re-defined feasible space. As a result, it can be deduced that the proposed equality constrained approach is mainly responsible for the poor or good performance of DESP with equality constrained problems with initial tolerance value of e(t)= 4. From Table 5, it can be obviously seen that the best results obtained by DESP are the optimal solution for this
8
6
4
2
0
DE	LDE1	LDE2	PSO	Ref.[19]	DESP
Algorithms
 SSFP1
 SSFP2  SSFP3

challenge problem as the constraints are —0.000000065533720,
—0.000008358091382, —0.000001611376663, —0.0000002908
Figure 3	Performance of DE, LDE1, LDE2, PSO, Ref. [19] and DESP algorithms in terms of objective function value for SSFPs.


18
16
14
12
10
8
6
4
2
0
DE	LDE1	LDE2	PSO	Ref.[20]  DESP
Algorithms








 MOSLP1  MOSLP2
rithm performs better in constrained SP problems with different types, complexity and dimensionality; it performs better with regard to the search process efficiency, the final solution quality, the convergence rate, and robustness, when compared with other algorithms. Finally, the performance of the DESP algorithm is superior to and competitive with other compared algorithm. Besides, it is noteworthy to mentioning that DESP algorithm finds the optimal solution for the most difficult MOSLP problem due to the proposed procedure for handling equality constraints. This proves that The DESP algorithm is considered as perfect alternative for solving SP problems. Several current and future works can be developed from this study. Firstly, current research effort focuses on

Figure 4 Performance of DE, LDE1, LDE2, PSO, Ref. [19] and DESP algorithms in terms of objective function value for MOSLPs.

the proposed rule, applying a constant tolerance value of 0.0001 along the whole search process. Table 5 presents the results of DESP without new dynamic tolerance rule using the same parameter settings. The presented results in Table 5 show that DESP1 was only able to find the best solution which is very close to the optimal solution but it was not able to reach it consistently in all runs as the standard deviation is 3.250082. Consequently, it can be deduced that the proposed dynamic tolerance rule has the main role in solving constrained prob- lems with equality constraints. However, the improvement per- centage of DESP1 in terms of objective function value in comparison with DE, LDE 1, LDE 2, PSO and quoted result
[20] is 222.62%, 214.45%, 197.69%, 214.45% and 476.9%,
respectively. Thus, it is clearly that DESP1 is superior with others in solving this challenge problem. Based on the above analysis, results and comparisons, it can be concluded that DESP is able to consistently find the global optimal in all stochastic programming problems with a very small standard deviation and with a relatively small average (NFEs) which indicates that the proposed DESP has a remarkable ability to solve considered stochastic programming problems with a perfect performance in terms of high quality solution, rapid convergence speed, efficiency and robustness. Besides, its per- formance is superior and competitive with all compared algo- rithms. Finally, it is noteworthy that the optimal solution of MOSLP 2 which is the most difficulty constrained problem is found. Figs. 3 and 4 show the performance of DESP, DE, LDE, PSO algorithms and the quoted results in [19,20] in terms of objective function value for SSFPs and MOSLPs, respectively.

Conclusions and future work

Stochastic programming (SP) is a framework for modeling optimization problems that involve uncertainty. In this research, two models of SP problems were considered: (i) SSFPs and (ii) MOSLPs problems. The deterministic equiva- lent models of these two classes of stochastic programming models are solved using a new approach to Differential Evolu- tion algorithm, called DESP. The proposed DESP algorithm has been compared with basic DE, basic PSO, LDE1, LDE2 and the quoted algorithm from the literature. The experimen- tal results and comparisons have shown that the DESP algo-
how to control the crossover rate by self-adaptive mechanism. Besides, another benchmark constrained and mixed integer programming problems will be solved using DESP. Addition- ally, future research will investigate the performance of the DESP algorithm in solving unconstrained and constrained multi-objective optimization problems as well as real world applications. Additionally, the promising research direction is joining the proposed triangular mutation with evolutionary algorithms, such as genetic algorithms, harmony search and particle swarm optimization, as well as foraging algorithms such as artificial bee colony, bees algorithm and ant colony optimization.

References

Rao SS. Engineering optimization: theory and practice. 4th ed. Hoboken (NJ): John Wiley & Sons Inc.; 2009.
Thangaraj R, Pant M, Bouvry P, Abraham A. Solving stochastic programming problems using modified differential evolution algorithms. Log J IGPL 2012;20(4):732–46.
Carino DR, Kent T, Meyers DH, Stacy C, Sylvanus M, Turner AL, et al. The Russell-Yasuda Kasai model: an asset liability model for a Japanese insurance company using multistage stochastic programming. Interfaces 1994;24(1):29–49.
Eppen GD, Martin RK, Schrage L. A scenario approach to capacity planning. Oper Res 1989;37(4):517–27.
Murphy FH, Sen S, Soyster AL. Electric utility capacity expansion planning with uncertain load forecasts. IIE Trans 1982;14(1):52–9.
Fisher M, Hammond J, Obermeyer W, Raman A. Configuring a supply chain to reduce the cost of demand uncertainty. Prod Oper Manage 1997;6(3):211–25.
Abdelaziz FB, Mejri S. Application of goal programming in a multi-objective reservoir operation model in Tunisia. Eur J Oper Res 2001;133(2):352–61.
Abdelaziz FB, Aouni B, Fayedh RE. Multi-objective stochastic programming for portfolio selection. Eur J Oper Res 2007;177(3):1811–23.
Mukherjee K, Bera A. Application of goal programming in project selection decision - a case study from the Indian coal mining industry. Eur J Oper Res 1995;82(1):18–25.
Yang L, Feng Y. A bicriteria solid transportation problem with fixed charge under stochastic environment. Appl Math Mod 2007;31(12):2668–83.
Sen S, Doverspike RD, Cosares S. Network planning with random demand. Telecommun Syst 1994;3(1):11–30.
Birge JR, Rosa CH. Modeling investment uncertainty in the costs of global CO2 Emission policy. Eur J of Oper Res 1995;83(3):466–88.
Abdelaziz FB, Masmoudi M. A multiobjective stochastic program for hospital bed planning. J Oper Res Soc 2012;63(4):530–8.



Bhattacharya UK. A chance constraints goal programming model for the advertising planning problem. Eur J Oper Res 2009;192(2):382–95.
Charles V, Yadavalli VSS, Rao MCL, Reddy PRS. Stochastic fractional programming approach to a mean and variance model of a transportation problem. Math Prob Eng 2011, 12pages 657608.
Charles V, Dutta D. A method for solving linear stochastic fractional programming problem with mixed constraints. Acta Cienci Indica Math 2004;30(3):497–506.
Charles V, Dutta D. Linear stochastic fractional programming problem with branch-and-bound technique. In: Proceedings of national conference on mathematical and computational models. Coimbatore (India): PSG College of Technology; 2001.
p. 31–139.
Charles V, Dutta D, Appal RK. Linear stochastic fractional programming problem. In: Proceedings of international confer- ence on mathematical modeling. India: University of Roorkee; 2001. p. 211–7.
Charles V, Dutta D. Linear stochastic fractional programming with sum-of-probabilistic-fractional objective. Optim Online; 2005. http://www.optimizationonline.org.
Charles V, Ansari SI, Khalid MM. Multi-objective stochastic linear programming with general form of distributions. Int J Oper Res Optim 2011;2(2):261–78.
Suwarna H, Biswal MP, Sinha SB. Fuzzy programming approach to multiobjective stochastic linear programming problems. Fuzzy Set Syst 1997;88(1):173–81.
Baba N, Morimoto A. Stochastic approximations methods for solving the stochastic multiobjective programming problem. Int J Syst Sci 1993;24(4):789–96.
Caballero R, Cerda´E, Munoz MM, Rey L, Stancu MIM. Efficient solution concepts and their relations in stochastic multi- objective programming. J Optim Theory Appl 2001;110(1):53–74.
Storn R, Price K. Differential evolution - a simple and efficient adaptive scheme for global optimization over continuous spaces. Technical report TR-95-012. ICSI; 1995.
Storn R, Price K. Differential evolution - a simple and efficient heuristic for global optimization over continuous spaces. J Global Optim 1997;11(4):341–59.
Engelbrecht AP. Fundamentals of computational swarm intelli- gence. John Wiley & Sons Ltd; 2005.
Mohamed AW. An improved differential evolution algorithm with triangular mutation for global numerical optimization. Comput Ind Eng 2015;85:359–75.
Mohamed AW, Sabry HZ. Constrained optimization based on modified differential evolution algorithm. Inf Sci 2012;194:171–208.
Deb K. An efficient constraint handling method for genetic algorithms. Comput Method Appl Mech 2000;186(2–4):311–38.
Venkatraman S, Yen GG. A generic framework for constrained optimization using genetic algorithms. IEEE Trans Evol Comput 2005;9(4):424–35.
Storn R, Price K. Differential evolution a simple and efficient heuristic for global optimization over continuous spaces. J Global Optim 1997;11(4):341–59.
Mohamed AW, Sabry HZ, Abd-Elaziz T. Real parameter optimization by an effective differential evolution algorithm. Egypt Inf J (Elsevier) 2013;14:37–53.
Das S, Suganthan PN. Differential evolution: a survey of the state-of-the-art. IEEE Trans Evol Comput 2011;15(1):4–31.
Price KV, Storn RM, Lampinen JA. Differential evolution - a practical approach to global optimization. Berlin: Springer; 2005.
Mohamed AW. An efficient modified differential evolution algorithm for solving constrained non-linear integer and mixed- integer global optimization problems. Int J Mach Learn Cyber 2015:1–19. http://dx.doi.org/10.1007/s13042-015-0479-6.
Feoktistov V. Differential evolution. In: Search of solutions. Springer; 2006.
Mohamed AW, Sabry HZ, Khorshid M. An alternative differential evolution algorithm for global optimization. J Adv Res 2012;3(2):149–65.
Mohamed AW. RDEL: restart differential evolution algorithm with local search for global numerical optimization. Egypt Infom J 2014;15:175–88.
Brest J. Constrained real-parameter optimization with e-self- adaptive differential evolution. In: Mezura-Montes Efre´n, editor. Constraint-handling in evolutionary computation. Studies in computational intelligence, vol. 198. Berlin: Springer; 2009. p. 73–93, chapter 4, ISBN 978-3-642-00618-0.
Charles V. E-model for transportation problem of linear stochas- tic fractional programming. Optim Online; 2007. http://www. optimizationonline.org.
