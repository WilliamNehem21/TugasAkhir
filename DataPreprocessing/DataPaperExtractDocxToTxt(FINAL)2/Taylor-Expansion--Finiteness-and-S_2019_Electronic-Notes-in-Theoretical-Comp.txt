Available online at www.sciencedirect.com


Electronic Notes in Theoretical Computer Science 347 (2019) 65–85
www.elsevier.com/locate/entcs
Taylor Expansion, Finiteness and Strategies 1
Jules Chouquet2
IRIF UMR 8243
Universit´e Paris Diderot, Sorbonne Paris Cit´e, CNRS, France

Abstract
We examine some recent methods introduced to extend Ehrhard and Regnier’s result on Taylor expansion: infinite linear combinations of approximants of a lambda-term can be normalized while keeping all coefficients finite. The methods considered allow to extend this result to non-uniform calculi; we show that when focusing on precise reduction strategies, such as Call-By-Value, Call-By-Need, PCF or variants of Call-By-Push-Value, the extension of Ehrhard and Regnier’s finiteness result can hold or not, depending on the structure of the original calculus.
In particular, we introduce a resource calculus for Call-By-Need, and show that the finiteness result about its Taylor expansion can be derived from our Call-By-Value considerations. We also introduce a resource calculus for a presentation of PCF with an explicit fixpoint construction, and show how it interferes with the finiteness result. We examine then Ehrhard and Guerrieri’s Bang Calculus which enjoys some Call-By-Push-Value features in a slightly different presentation.
Keywords: Lambda calculus, Call-By-Value, Bang Calculus, Call-By-Need, Linear logic, Taylor expansion, PCF


Introduction

The past decade saw the appearance a revival of Girard’s quantitative semantics of λ-calculus, with proposals of new models, and extensions of the existing results to various calculi: other operational semantics (Call-by-Value, PCF, Call-By-Push- Value) or non-deterministic extensions (probabilistic [11,14], algebraic [28]). A crucial feature of quantitative interpretation is the analyticity of the functions denoting the λ-terms. Girard’s original model of normal functors [15] used set-valued power series representing analytic maps between modules. Linear logic’s birth is presented as a result of this study, and still plays a central role in quantitative semantics’ recent works [3,27].

1 This work is funded by the french ANR project RAPIDO (ANR-14-CE25-0007). The author thanks the anonymous reviewers for their useful comments, Lionel Vaux-Auclair and Michele Pagani for their advices, and is very grateful to Christine Tasson for her help and support.
2 Email: Jules.Chouquet@irif.fr   URL: https://www.irif.fr/~chouquet

https://doi.org/10.1016/j.entcs.2019.09.005
1571-0661/© 2019 The Author(s). Published by Elsevier B.V.
This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).

The models that have since been proposed in that direction have permitted the study of precise operational and quantitative properties of the calculus, such as execution time [6], or probabilities [11,14]. The relation between such aspects of the calculus and the power series-oriented semantics has been, in particular, exhibited clearly with the introduction of an interface between the syntax and the semantics: following models like Ehrhard’s finiteness spaces [7], Ehrhard and Regnier constructed a variant of λ-calculus which corresponds to the multilinear approximations of the analytic maps in the models. This variant, called resource calculus, and coming from Boudol’s calculi with multiplicities [2], is the multilinear fragment of differential λ-calculus [12], and comports multilinear terms — where “linear” has to be understood in the computational sense: the available resources are used exactly once during the computation. For example, the λ-term (λxxx)y, which calls for the duplication of the argument, will be approximated by the resource term
⟨λx⟨x⟩[x]⟩[y, y], where ⟨m⟩n stands for the multilinear application of a term to a
multiset of terms: if the term in function position calls for k arguments (in our example, λx⟨x⟩[x] calls for 2 arguments), then the multiset in argument position must contain k terms (in our example, [y, y], for k = 2), otherwise the reduction leads to a nullary sum of terms.
This resource calculus is said to be an interface between the original calculus and the model because it allows to mimic the identities of quantitative semantics through Taylor expansion construction, which is the subject of the present paper. Taylor expansion is a syntactic analogue to the well-known Taylor formula, and consists also in the correspondence between a non-linear object (in the model: an analytic function; in the syntax: a pure λ term) and a sum (generally infinite) of multilinear approximants (in the model: multilinear maps; in the syntax: resource terms). In ordinary λ-calculus, the key case of the definition of Taylor expansion concerns
essentially the application, since it contains the non-linear part of λ-calculus, and can be presented as follows: T (MN ) = Σk∈N  1 ⟨T (M )⟩T (N )k where T (N )k is
a multiset of k copies of T (N ). The construction is also linear in two ways: all
summands are resource terms, and syntactic constructs commute with sums. A model is compatible with Taylor expansion if the interpretation of M is the same as the interpretation of T (M ). This is a property shared by structures like the weighted relational model [21], finiteness spaces [7], probabilistic coherent spaces [5], convenient vector spaces [18] in which most of recent quantitative studies have been produced. However, this treatment of λ-calculus interpretation brings a difficulty: Taylor expansion is a potentially infinite weighted sum, and there is no guarantee that coefficients remain finite under reduction. Indeed, the notion of reduction we put on resource terms has to allow the simultaneous calculus of an unbounded number of redexes in order to simulate β-reduction.
Consider for instance MN →β MNj. The resource approximants of this term are of the shape ⟨m⟩[n1,..., nk] (with m being an approximant of M , and the ni being approximants of N ), and we have to reduce all the ni in one step to reach a term
⟨m⟩[nj ,..., nj ] which approximates MNj. Consider now a family (mi)i∈N such that
1	k
for all i, mi is a resource term of the shape ⟨λx[x]⟩[⟨λx[x]⟩[... ⟨λx[x]⟩[y]]], with i

applications of the identity to the variable y. All these terms reduce in parallel to y, and if we define a parallel reduction ⇒ over infinite linear combinations of terms,
then we are led to let appear an infinite coefficient: Σi∈N mi ⇒∞ · y which is not
always defined in the models we consider (when the semimodule we work on is not
built on a complete semiring, as is the case for example in the weighted relational model [21], all sums are not guaranteed to converge). Moreover, keeping coefficients finite is important as it implies, for instance, that the calculation of a value always terminates. A way to ensure that infinite coefficient do not appear is to show that each term has a finite number of antireducts in the combinations we consider, which is not the case in the above example. The first result concerning this issue is Ehrhard and Regnier’s one: they proved that when dealing with pure non-uniform λ-calculus, coefficients stay finite under reduction and that normalization and Taylor expansion commute [13]. The problem of extending this finiteness result to other calculi has been very studied recently. Indeed, solving it is a necessary step to ensure that one can provide a quantitative interpretation of the calculus, consistent with the algebraic behaviour of the models mentioned above. Ehrhard extended that result to a non-uniform variant of System F, putting a finiteness structure on the resource terms [8]. This methods then was extended by Pagani, Tasson and Vaux-Auclair to all strongly normalizable terms in a calculus endowed with non-deterministic sums [23]. Then, Vaux-Auclair brought an even more general approach, dealing with algebraic λ-calculus, and extending the argument to weakly-normalizable terms [28,29]. We used with Vaux-Auclair the method of that latter paper to study Taylor expansion of linear logic proof nets in a comparable way [4].
The key result concerning Taylor expansion, namely, the definability of a parallel reduction on it, demands technical proofs, which differ depending on the structure of the original calculus. We propose here the study of different calculi, with different operational semantics: Call-By-Value, Bang Calculus [10], Call-By-Need [1], and PCF [25].
Our present contribution is to show that in those various calculi, the finiteness results hold, up to a convenient definition of the resource calculi and to the choice of arguments depending on those calculi’s precise features. Call-By-Value Taylor expansion has already been defined by Ehrhard [9], and shown to be compatible with B¨ohm trees by Kerinec, Manzonetto and Pagani [17], but in a qualitative way (i.e. coefficients are not considered). We show in Section 2.1 that a parallel reduction is definable on Taylor expansion with coefficients, and this remains true if we provide an algebraic extension of Call-By-Value calculus, because the method used by Vaux-Auclair can be adapted to this setting.
We also define in Section 2.2 a resource calculus adapted to Call-By-Need reduction, and observe that the specificities of its operational semantics implies that its Taylor expansion consists in the same set of resource terms as Call-By-Value one.
For the two calculi of Section 2 and for the Bang calculus, the finiteness result is proven thanks to a combinatorial study of the parallel reduction and the size of resource terms in the Taylor expansion, following Vaux-Auclair’s method [29]. The key result is then about cardinalities of sets, size of terms, and concerns the sets

underlying to Taylor expansion. This implies in particular that uniformity is not a necessary property for the proofs to be valid, and that algebraic extensions of the calculus would not interfere with the arguments.
The situation is different in presence of an explicit fixpoint. We focus on PCF calculus to study the consequences of endowing the syntax with a fixpoint operator in a typed setting. We consider a presentation of PCF extract from Ehrhard, Pagani and Tasson’s work [11], and we are motivated by the quantitative semantics they provide for it. The presence of the fixpoint is here crucial, since the argument used before cannot apply anymore, for a reason linked to the fact that there is no way to give a finiteness structure interpreting terms with fixpoints (see e.g. Tasson and Vaux-Auclair for a detailed examination of this point [26]). In order to show that Taylor expansion and parallel reduction are still definable in this setting, we have to provide an argument relying on a coherence relation between resource terms following Ehrhard and Regnier [13]. It is sufficient to prove the finiteness result in a uniform setting, but this reveals the fact that, when dealing with both an explicit fixpoint and non-uniformity (such as non-deterministic choice, probabilities), the finiteness result becomes false: we can build a term whose Taylor expansion contains an infinity of resource terms reducing at the same time.
We then consider in Section 4 Ehrhard and Guerrieri’s Bang Calculus [10] (see also Guerrieri and Manzonetto [16]), which is a linear logic-inspired calculus subsuming Call-By-Name and Call-By-Value disciplines, and for which Taylor expansion has been defined in the introductory paper [10]. The Bang Calculus can be seen as an untyped variant of Levy’s Call-By-Push-Value. We discuss in conclusion the distinctions and difficulties appearing when switching from the former to the latter.



Terminology
We denote as N the set of positive integers, whose elements will often be written k, l, ... . For k ∈ N, Sk is the set of permutations of {1,..., k}. We use the notation [m1,..., mk] for the multisets, and [m,..., m]k, or just [m]k for the multiset with k occurrences of the same term m. We use the standard additive
notation [m1,..., mk]+ [mk+1,..., mk+l] to represent the multiset [m1,..., mk+l]. Multisets [m1,..., mk] might be denoted m or −→m.
We consider degx(m) the degree of x in m as the number of free occurrences of x in m, for any term m in any of the calculi we introduce. We might represent distinct occurrences of x by x1,..., xk, especially when dealing with resource reductions.
For any set X, we consider the multiset construction X! = {[x1,..., xk] | k ∈ N, xi ∈ X}. For any lambda term or resource term μ, its size #μ is defined in the usual way : #x = 1, #λxμ = #μ + 1, #(μμj)= #μ + #μj + 1, #[μ1,..., μk]= 
Σi∈{1,...,k} #μi.
In the following, the lower script ()U will often stand for Call-By-Value calculus, ()b for Bang calculus, and ()need for Call-By-Need. ()rU , ()rb and ()rneed refer to corresponding resource calculi.

Call-By-Value and Call-By-Need
Call-By-Value

Kerinec, Manzonetto and Pagani show that defining a natural coherence relation between Call-By-Value resource terms introduced by Ehrhard [9] leads to consider Taylor expansion as maximal cliques for this relation [17] (Prop. 3.16). With that result together with Ehrhard and Regnier’s methods [13], we can expect that finiteness of antireducts in Taylor expansion is provable, and more precisely that for a given resource term m, and a given ΛU -term N , {n ⇒rU m | n ∈ TU (N )} contains always at most one element, where ΛU represents the Call-By-Value calculus, TU its Taylor expansion, and ⇒rU is a parallel Call-By-Value resource reduction.
But, one of our motivations is to endow ΛU with non-deterministic sums, or with coefficients, so that uniformity will be lost. In such a setting, the coherence method no longer applies since it relies precisely on uniformity. Similarly to Vaux-Auclair [29], we use a technique to bound the number of antireducts of a given term in Taylor expansion, independently of uniformity hypothesis. This opens the path to the study of Call-By-Value Taylor expansion as power series with coefficients, since it ensures that coefficients remain finite under parallel reduction of combinations of terms. Moreover, Taylor normal form is always well-defined in such a setting.
Definition 2.1 [Call-By-Value calculus ΛU ]
V ::= x | λxM	ΛU : M, N ::= V | MN 

The reduction rule is the following : (λxM )V →βV M [V/x], and closed by abstraction and application contexts.
Definition 2.2 [Call-By-Value resource calculus ΔU [9]]
ΔU : m, n ::= [x1,..., xk] | [λx1m1,..., λxkmk] | mn

The reduction rule is the following 3 , closed by application and abstraction contexts, and where x1,..., xl represent l distinct occurrences of x:
[λxm][n1,..., nl] →rU m1[nf (1)/x1,..., nf (l)/xl] if l = degx(m1), f ∈ Sl
The term [λy1m1,..., λykmk][n1,..., nl] has no reduct if k /= 1.
Definition 2.3 [Call-by-Value Taylor expansion [9]] Taylor expansion is defined as a function from ΛU to sets of terms of ΔU :
TU (λxM )= {[λxm1,..., λxmn]; n ∈ N, mi ∈ TU (M )}
TU (x)= {[x,..., x]k | k ∈ N}

3 We differ from the usual presentations, since instead of having a term reducing in a finite sum of resource terms, our reduction is non-deterministic and corresponds to a relation between a term and the support of its usual reduct.

TU (MN )= {mn | m ∈ TU (M ),n ∈ TU (N )}
The method we use here consists in setting a measure on resource terms that is bounded for all terms belonging in Taylor expansion of some ΛU -term. This measure is defined below, and corresponds to the number of nested applications in a term. We show that this notion of depth will be sufficient to establish that for any integer k, resource term m, and ΛU -term M , {mj ⇒rU m | ApD(mj) ≤ k} is finite. Here,
⇒rU is the parallel Call-By-Value resource reduction which has to be introduced for the following reason: it permits to simulate →βV in resource calculus (in particular, it reduces all terms of a multiset in one step), it is confluent, and allows to keep a
bound on applicative depth so as to apply our argument to iterated reduction, as we shall see.
Definition 2.4 [Applicative depth] For any term m of ΔU , we define its applicative depth ApD(m) as follows :  ApD([x1,..., xk]) = 0, ApD([λx1n1,... λxnnk]) =
max{ApD(ni) | i ∈ {1,..., k}}, ApD(mmj) = max{ApD(m), ApD(mj)} + 1. We do the same for terms of ΛU : ApD(x) = 0, ApD(λxM ) = ApD(M ), and ApD(NNj)= max{ApD(N ), ApD(Nj)} + 1.
Lemma 2.5 Let M be a term of ΛU . Then for all m ∈ TU (M ), ApD(m) ≤
ApD(M ).
Proof. By induction on M :
If M = x, then m = [x,..., x]k, and ApD(m)= ApD(M )= 0.
If M = λxN , then m = [λxn1,..., λxnk], and ApD(m) = max{ApD(ni) | i ∈
{1,..., k}}. By induction hypothesis, for all i, ApD(ni) ≤ ApD(N ). Then
ApD(m) ≤ ApD(M ).
	If M = NNj, then m = nnj, and ApD(m)= max{ApD(n), ApD(nj)} + 1. By induction, ApD(n) ≤ ApD(N ) and ApD(nj) ≤ ApD(Nj), then ApD(m) ≤ ApD(M ).
2
As explained in introduction, the notion of reduction we focus on must be a parallel one. Indeed, it is straightforward that for resource terms in Taylor expansion of some Call-By-Value term, the reduction →rU is not sufficient to simulate →βV .
j
Indeed, if we consider M →βV M , and n = [λx1m1,..., λxkmk] ∈ TU (λxM ), if
k > 1, there is generally 4 no nj ∈ ΔU such that n →rU nj and nj ∈ TU (λxMj). In
order to examine resource dynamics that correspond to →βV reduction, and thus to semantics identities, we must introduce the following parallel resource reduction:
Definition 2.6 [Parallel reduction of resource terms ⇒rU ]
m ⇒rU m for all m ∈ m
If mi ⇒rU mj for all i ∈ {1,..., k}, then [m1,..., mk] ⇒rU [mj ,... mj ]
i	1	k

4 It can happen that the mi are already in fV (M′), for example if M, M′ are values and the mi are empty bags.

If m ⇒rU mj and n ⇒rU nj, mn ⇒rU mjnj.
If mi ⇒rU mj for all i ∈ {1,..., k}, n ⇒rU nj, and k = degx(n) then we set

[λxn][m1,..., mk] ⇒rU nj[mj
/x1,..., mj
/xk] for any permutation f ∈ Sk.

Note that ⇒rU is strictly included in the reflexive transitive closure of →rU . The redexes created during the reduction are not reduced by ⇒rU . For example, one can

check that for m = [λx[x][z]][λy[y]], m →∗
reduced further in the same parallel step.
[z], but m ⇒rU [λy[y]][z] and cannot be

The following lemma ensures that the applicative depth of resource terms allows to bound the loss of size during parallel reduction, and that this measure is still bounded after one reduction step: we will then be able to extend the argument to iterated reduction.
Lemma 2.7 There exist non decreasing functions ϕ : (N×N) → N and ψ : N → N such that for any m, n ∈ ΔU , if m ⇒rU n, then #m ≤ ϕ(#n, ApD(m)). Moreover, ApD(n) ≤ ψ(ApD(m)).
The proof can be obtained as an adaptation of Vaux-Auclair’s result [29] (Lemma 26, ϕ(k, l)= 4lk and ψ(k)= 2kk), to a Call-By-Value setting, as we sketch below:
The idea here is to prevent an unbounded collapse of the size under parallel reduction. A critical example of what we call a collapse (because the size reduces drastically, since an unbounded number of variables disappear) is the set: X =
{[λx1x1][[λx2x2][... [λxkxk][z]] ... ]]] | k ∈ N}. We observe that for all m ∈ X, m ⇒rU [z]. There is no way to give a bound to the size of antireducts of [z] in X, and we can immediately see that the applicative depth is not bounded in X either. Vaux-Auclair observed that the collapse depends on the depth of antireducts, and that the cardinality of multisets does not interfere with it. Then, since Taylor expansion consists of sets of terms of unbounded multisets, but of bounded depth, it
excludes subsets of terms like X in the above example.
The adaptation of this result to Call-By-Value is then a corollary of Lemma
2.5 and relies on the structure of the sets TU (M ), having the necessary properties for Lemma 2.7 to be valid. We conclude by observing that ⇒rU has the same combinatorial properties that the unrestricted parallel resource reduction of Vaux- Auclair’s works, since it is strictly included in it and behaves in the same way: it is a particular case of Ehrhard and Regnier’s resource reduction.

Corollary 2.8 Let n ∈ ΔU , k ∈ N and M ∈ ΛU . {m ∈ TU (M ) | m ⇒k
n} is

ﬁnite.
Proof. It is sufficient to observe that for any given k ∈ N, {m ∈ ΔU | #m ≤ k}
is finite. Then, by Lemma 2.5, terms in {m ∈ TU (M ) | m ⇒rU n} have a bounded

applicative depth. We then show by induction on k that {m ⇒k
n | ApD(m) ≤ l} is

finite for any l. By Lemma 2.7, we conclude for k = 1. Then, the result can be iterated

since if m ⇒k+1 n, m ⇒rU mj ⇒k
n. By Lemma 2.7, ApD(mj) ≤ ψ(ApD(m)), we

rU	rU
apply induction hypothesis and conclude for all k ∈ N.	2
Let us consider now a quantitative version of Taylor expansion as a power series

with coefficients T q(M )= Σ

m∈fV (M )
 T q(M ) 
·m, where T q(M ) 
represents the

coefficient of m in T q(M ) taken in some semiring S. Motivated by the quantitative semantics identities which identify the denotation of M with its Taylor normal form, we want to define this object, but we have first to tackle a difficulty: the

combination tnf(M )= Σ
m∈fV (M )
 T q(M ) 
· nf(m) (where nf is the normal form

operator, always defined for resource terms, since resource reduction induces a strict
decrease of the size of terms) might contain terms with infinite coefficients. It is the

case if {m ∈ TU (M ) | (T q(M )i)m /= 0,m ⇒∗
nf(m)} is infinite.

U	rU
Let us define a reduction relation between infinite linear combination of terms denoted as: Σi∈I aimi ⇒ Σi∈I aini if mi ⇒rU ni for all i ∈ I, and if for all ni,
{j ∈ I | mj ⇒rU ni, aj /= 0} is finite. Corollary 2.8 ensures that the reduction
T q(M ) ⇒ ξ is well-defined for any combination ξ. In particular, the simulation of
U	q	q
a reduction M →βV N through a reduction TU (M ) ⇒ TU (N ) is well-defined. If M

is normalizable, and M →k
V
nf(M ), we can also deduce immediately T q(M ) ⇒k

tnf(M ) and that for all m ∈ |tnf(M )| (|tnf(M )|being the support of tnf(M )), we
have (tnf(M ))m finite.
As a further study in that direction, we shall mention Kerinec, Manzonetto and Pagani’s works [17], that defines Call-By-Value B¨ohm trees and establish BT (TU (M )) = tnf(M ) in a qualitative setting. We leave as a future work the quantitative extension of this equation, but we have set the possibility of dealing with finite coefficients in the reduction of Call-By-Value Taylor expansion.

Call-By-Need

Our resource-oriented study of strategies of reductions calls to observe the particular setting of Call-By-Need, which is a strategy that optimises the number of reduction steps: in Call-By-Need, the reduction does not proceed to useless or inefficient reduction as in Call-By-Value and Call-By-Name. Assume M → Mj: useless reduction would be the Call-By-Value evaluation of M in N = (λyx)M , because N →β y and M →βV (λyx)Mj →βV y: Call-By-Name strategy proceeds to the erasure of the argument, which is optimal regarding to the number of reduction steps. An inefficient reduction would be the Call-By-Name reduction of the most external redex in Nj = (λxxx)M before the evaluation of M , because Nj →β MM →β MjM →β MjMj while N →βV (λxxx)Mj →βV MjMj: Call-By- Value is optimal in this case. Call-By-Need is optimal in both cases, since it prohibits the reduction of terms like (λyM )N if y has no free occurrences in M , or in general if N is doomed to be erased in a further reduction. And if not, Call-By-Need demands N to be reduced to a value before substituted in M . We give some intuitions sufficient to make some observations :
	We can define a resource calculus corresponding to Call-By-Need, in which the reduction rules enjoy the property of optimization explained in the above paragraph (neither useless nor inefficient reductions).
Taylor expansion in this setting leads to the identical construction as the Call-By-

Value one. The distinction between the two calculi is not visible at this level, but when observing the evaluation steps and the distinct normal forms 5 .
We introduce a resource calculus able to simulate Call-By-Need reduction: our terms are approximants of Call-By-Need syntax introduced by Pedrot and Saurin [24], which is shown to be equivalent to Ariola and Felleisen’s original calculus [1]. We formalize this simulation in Appendix A, but the intuition is sufficient here to understand the remarks below.
Pedrot and Saurin’s calculus presents Call-By-Need reduction in a quite con- cise syntax, since the constraints on the reduction are contained in the contexts and the marking of lambdas: a term λxt will be rewritten lxt when it is in the function position of a redex, or shall be reduced to one. Then, the contexts e are able to characterize reducible redexes in the following sense: a term of the shape
e[lxe[[x,..., x]]]c[−→v ] is a term where the bag of variables x is at a place where it
won’t be erased. Then, the argument, if it is a value, can be substituted. We detail neither this dynamics nor the sharing properties, and refer to Pedrot and Saurin’s paper for explanations of the calculus, because those properties at the resource level are similar: the reader can nonetheless ascertain that the definition of the contexts ensures that the reduction enjoys the optimization properties described in the above paragraph.
Definition 2.9 [Call-By-Need resource calculus Δneed]
terms : t, u ::= [v1,..., vk] | tu | lxt	values : v ::= x | λxt
contexts : c ::= [] | c1[lxc2]t	e ::= [] | et | lxe | c[lxe1[[x,..., x]]e2
Reduction rules:
c[[λxt]] →rneed c[lxt]
c[[λx1t1,..., λxktk]]u →rneed 0 if k /=0 
c1[lxe[[x1,..., xk]]c2[[v1,..., vm]] →rneed 0 if m < k e[t] →rneed e[tj] if t →rneed tj
c1[lxe[[x1,..., xk]]c2[−→v ] →rneed c2[c1[lxe[[v1,..., vk]]]−→v j] for all [v1,..., vk]+ −→v j = −→v

From a resource point of view, which is ours, the first observation is that the terms above correspond to Call-By-Value ones. Indeed, if we omit the terms with marked lambdas lxt, the syntax is the same, and the distinction is all contained in operational semantics. In particular, if we define Taylor expansion of Call-By-Need following that presentation, we shall proceed exactly as we did for Call-By-Value. Corollary 2.8 would apply immediately when the convenient notion of parallel reduction is defined. It is not hard to examine the dynamics and to conclude that bounds about size and depth can be established for this calculus.

5 We shall precise that Call-By-Need and Call-By-Value normal forms are distinct, since Call-By-Need is observationally equivalent to weak Call-By-Name (where no reductions are allowed under lambda’s). This was established for instance, and in an elegant way by Kesner [19].

One can consider an approximation relation between Call-By-Need terms and Δneed, defined informally as follows : m  M if m has recursively the same shape than M (following notation used by Tsukada, Asada and Ong to define Taylor expansion [27]). See the appendix for a formal presentation. One can then consider some λ-term M , and convince oneself that {m ∈ Δneed | m  M} and TU (M ) are exactly the same sets. In particular, if we define a parallel, confluent extension of
→rneed, say ⇒need, the following proposition is easily derived from considerations of Section 2.1:
Proposition 2.10 Let M be a term of Call-By-Need, and n ∈ Δneed. {m  M |
m ⇒need n} is ﬁnite.
It is sufficient to observe that the reduction can be seen as a particular case of resource reduction, in the sense that we can bound the growing of applicative depth under parallel reduction, and that there is no arbitrary collapse during parallel reduction : the arguments differ from Call-By-Value in the management of the contexts and of the sharing properties of the calculus, but that do not intervene in the key properties we need.
We give below an example of Call-By-Need Taylor expansion to illustrate the interaction between Call-By-Need reduction and our resource constructions.
Example 2.11 Consider the following λ term : M = (λz(λxy)(II)(zz))(II), where I = λxx. We can already see that the most external abstraction calls for a duplication of the evaluation (II) if we stand in a Call-By-name discipline, while the subterm (λxy)(II) calls for a useless evaluation of (II) if we are in a Call-By-Value discipline. The Call-By-Need evaluation starts by reducing the rightmost (II) to I, and then, other reductions are forbidden, except a possible garbage collection rule that leads immediately to the term yI, which is the common normal form of M .
Let us consider Taylor expansion of M , and see how Call-By-Value and Call-By- Need differ in the reductions (we omit terms of the shape [λx1,..., λxn]t, since they
reduce to 0 in both calculi):


fV (M )= 
→−
k ∈N
nhλz hλx[y]k i [λx[x]k ][λx′[x′]k ]k
λx'  [z]kz [z]k' i [λw[w]k
w ][λv[v]kv ]kλv o

If we follow the reduction, we are led to observe that there is only one term of the above sum that reduces to the normal resource term [y][λv[v]] 6 : It is the point of

TU (M ) where kx, kλ′
= 0, kz, kj , ky = 1, kw, kλv, kv = 2. Call-By-Need reduction

is more permissive in this sense, since all cardinalities are acceptable for kλx′ and kx : those terms are the arguments of the function subterm λx[y], and shall never be evaluated, but erased by the garbage collection, if considered. In Call-By-Value reduction, if kλx′ and kx are not null, there will be an evaluation (a useless one, corresponding to the reduction of the intern II to I in M ) before ending with the reduction to 0.

6 Notice that this a single example taken among the infinite set fV (yI).

PCF

We announced in the introduction that the results we exhibited for Call-By-Value and Call-By-Need are valid even in the presence of an explicit fixpoint, but we are forced to change our proof method. Indeed, Ehrhard already observed that an explicit fixpoint prevents the calculus to be endowed with a finiteness structure [7]. Since resource calculus’ purpose is to mimick the identities of the semantics, it is not surprising that the finiteness property of the reduction of Taylor expansion becomes false when an explicit fixpoint is added to the syntax. The intuition behind this remark is that it contains potentially an infinite number of applications, and then its interpretation explodes the cell of finiteness structures, and the resource calculus necessary to simulate this dynamic contains approximants of the fixpoint construction, but those approximants are of unbounded applicative depth.
We propose the study of a calculus endowed with such an explicit fixpoint constructor. We focus on a variant of Plotkin’s PCF similar to Ehrhard Pagani and Tasson calculus [11].
A quantitative model of that language has already been proposed by Ehrhard and Tasson in the category of probabilistic coherence spaces [5,11]. In this model, the derivation operation is not always defined, but the Taylor formula, which takes the derivatives only at zero, is valid and is then subject to our considerations.
There is a ground type ι corresponding to integers, and the syntax of types is given by :
σ, τ, . . . ::= ι | σ → τ

Definition 3.1 [PCF ] Let k range over N and x over a countably infinite set of variables.
M, N, ... ::= k | x | suc(M ) | λxM | MN | If (M, N, z · Nj) | fix(M ) Reduction rules :
(λxM )N →pcf M [N/x]	fix(M ) →pcf M (fix(M )) If (k + 1, M,x · N ) →pcf N [k/x]		If (0, M,x · N ) →pcf M suc(k) →pcf k +1 
We define evaluation contexts E, for all terms T, U .
E ::= [] | EM | ME | If (E, M, x · N ) | suc(E) | λxE
and we set as an additional reduction rule E[M ] →pcf E[Mj] for each M, Mj such that M →pcf Mj.
Definition 3.2 [PCF resource calculus ΔPCF]
ΔPCF : m, n ::= x | k | λxm | ⟨m⟩[n1,..., nk] | (m = mj) · n

Reduction rules:
⟨λxm⟩[n1,..., nk] →rpcf m[nf (1)/x1,..., nf (k)/xk] for all f ∈ Sk if degx(m)= k.
(m = k) · n →rpcf n if m = k.
We define evaluation contexts e, for all terms m, n of ΔPCF :
e ::= [] | ⟨e⟩m | ⟨m⟩e | [e, m1,..., mk] | (e = k) · m | λxe

and set the additional rule e[m] →rpcf e[mj] if m →rpcf mj by one of the above rules.
We define for all n ∈ N a set of terms fixn as follows, with fix0 = ∅:
fixn+1 = λx⟨x⟩ [⟨f1⟩[x]l ,..., ⟨fk⟩[x]l ] | k, l1,..., lk ∈ N, ∀i ≤ k : fi ∈ fixn}.
We can now define the sets of resource terms corresponding to Taylor expansion of
PCF:

Tpcf(x)= {x}
Tpcf(k)= {k}
Tpcf(suc(M )) = {(m = k) · k +1 | m ∈ Tpcf(M ),k ∈ N}
Tpcf(λxM )= {λxm | m ∈ Tpcf(M )}
Tpcf(MN )= {⟨m⟩n | m ∈ Tpcf(M ), n ∈ Tpcf(N )!}
Tpcf(fix(M )) = {⟨f⟩m | f ∈  k∈N fixk, m ∈ Tpcf(M )!}
Tpcf(If (M, N, x · Nj)) = {(m = 0) · n | m ∈ Tpcf(M ),n ∈ Tpcf(N )} ∪ {(m =
k + 1) · nj[k/x] | m ∈ Tpcf(M ), nj ∈ Tpcf(Nj),k ∈ N}
Remark 3.3 A first notable observation we do with respect to the considerations of Section 2.1 is that the first property of Call-By-Value Taylor expansion (Lemma 2.5) is no more valid in PCF. Indeed, provided we extend the definition of applicative depth to ΔPCF, in the natural way, for all n ∈ N, the set fixn is made of terms whose applicative depth belongs to {1,..., n}. We conclude immediately that for any term M ∈ PCF, if M has a subterm of the shape fixx(M ), then Tpcf(M ) is a set of terms of unbounded applicative depth.
We are not able anymore to adapt Vaux-Auclair’s method to PCF. Notice that this point would hold in every calculus with explicit fixpoint, and a similar study could be done with PCF, for example. We have to come back to Ehrhard and Regnier’s works [13] if we hope to achieve the wanted finiteness results. This implies that our framework will be uniform, and that the argument would not apply to an algebraic, or even non-deterministic setting, since uniformity would be lost. The extension of the result to such a system remains an open question. In the following, we introduce a binary coherence relation and use Ehrhard and Regnier’s method in order to establish that it fits to specific constructions as conditional and explicit fixpoint in our resource construction ΔPCF.

Example 3.4 [Probabilistic PCF] Consider Ehrhard and Tasson’s probabilistic PCF [11], which is an extension of PCF with, in particular a coin constructor, which reduction rule is the following: coin(p) → 0 with probability p, and coin(p) → 1 with probability 1 − p, for all p ∈ [0, 1]. The natural extension of Taylor expansion to
this new setting is T j (coin(p)) = {0, 1} 7 , (which is a non-uniform set, according to
Definition 3.5). Let us consider now the following term: M = fix(If (coin(p), λxx, z ·
λxy)) for some fixed p. The conditional reduces to λxx with probability p, and to

λxy with probability (1 − p). If we develop the definition of T j
, we can observe

that T j (M ) contains as a subset X = {⟨f⟩[(0 = 0) · λxx]k + [(1 = 1) · λxy] | k ∈
N,f ∈ fixk+1} (the argument of f is the sum of the two multisets). The normal form of Tpcf(M ) is not empty since each element of X eventually reduces to y. But

precisely, y has then an infinite number of antireducts in X, hence in T j
(M ), which

contradicts our finiteness result. Notice that it does not mean that the coefficient

of y would be necessarily infinite, in the weighted definition of T j
, but that the

finiteness result is not general anymore and shall be replaced by a close study of the coefficients involved in Taylor expansion establishing the convergence, or divergence of the weighted infinite sums of terms. For further details about Taylor expansion of probabilistic lambda calculus, we refer to the recent study of Dal Lago and Leventis [20].

Uniformity and coherence
We define a binary coherence relation between elements of ΔPCF, which is shown to be stable under parallel reduction ⇒pcf, and is such that Taylor expansion of a term in PCF defines always a clique for this relation. This will lead us to infer the finiteness result : for all n ∈ ΔPCF,M ∈ PCF, {m ∈ Tpcf(M ) | m ⇒pcf n} has at most one element.
Definition 3.5 [Coherence on resource terms of ΔPCF]
x ¨ x for all x.
k ¨ kj if k = kj.
λxm ¨ λxmj if m ¨ mj.
⟨m⟩n ¨ ⟨mj⟩nj if m ¨ mj and n ¨ nj.
(m = k) · n ¨ (mj = kj) · nj if m ¨ mj and k = kj → n ¨ nj
[m1,... mk] ¨ [mk+1,..., mk+l] if ∀i, j ∈ {1,...,k + l}, mi ¨ mj.
Lemma 3.6 For all term M of PCF, Tpcf(M ) is a clique for the relation ¨.
Proof. The proof is by induction on M . We only detail the fixpoint case, other constructions following from straightforward induction steps. Let M = fix(N ). Tpcf(M )= {⟨f⟩n; f ∈ ∪k∈Nfixk, n ∈T (N )!}. Induction hypothesis implies that it is sufficient to prove that ∪k∈Nfixk is a clique. Let f ∈ fixk and fj ∈ fixl for k, l ∈ N.

7 Because we do not need to consider the coefficients for the argument. Otherwise, the definition is
f ′ (coin(p)) = p · 0+ (1 — p) · 1.

If k = l, then by induction (starting from 1 because fix0 = ∅):
If k, l = 1, then f = fj = λx⟨x⟩[] (fix1 is a singleton).
If k = l = kj + 1, then f = λx⟨x⟩[⟨f1⟩x,..., ⟨fl′ ⟩x], with for all i ∈ {1,..., lj},
f ∈ fix ′ and fj = λx⟨x⟩[⟨fj ⟩x,..., ⟨fj ⟩x] with for all j ∈ {1,..., ljj}, fj ∈ fix ′ .
i	k	1	l′′	j	k
By induction hypothesis, fi ¨ fj for all i ∈ {1,..., lj} and all j ∈ {1,..., ljj}.
Moreover, all bags x are pairwise coherent. So, f ¨ fj.
If k > l. Then, by induction on k :

If k = 1, then fj = λx⟨x⟩[] and f = λx⟨x⟩n for n ∈ fix!
. By definition, [] ¨ n

for all n, so f ¨ fj.
If k > 1 then f = λx⟨x⟩[⟨f1⟩x,..., ⟨fl′ ⟩x], where for all i ∈ {1,..., lj}, fi ∈ fixl—1.
Moreover, fj = λx⟨x⟩[⟨fj ⟩x,..., ⟨fj ⟩x] where for all j ∈ {1,..., ljj}, fj ∈ fix	.
1	l′′	j	k—1
By induction hypothesis, fi ¨ fj for all i ∈ {1,..., lj} and all j ∈ {1,..., ljj},

because fi ∈ fixl—1, fj
∈ fixk—1 and l − 1 > k − 1. Bags x being pairwise

coherent, we have f ¨ fj.
2
The coherence relation we introduced allows to compare terms having the same shape. In particular, if two terms are coherent and are redexes, there is a way to have a pair of reductions leading to reducts also pairwise coherent, even if coherence is not preserved by reduction in general. This point is made explicit in the following lemma.
The constraint we set on the two reductions is to avoid pairs like ⟨λxm⟩n ¨
⟨λxmj⟩nj, reducing respectively to m[nf (1)/x1,..., nf (k)/x ] and to ⟨λxm⟩njj if
nj →rpcf njj. In this case, the two reducts are obviously not pairwise coherent.

Lemma 3.7 Let m, mj, n, nj such that m ¨ mj, and either:
m = ⟨λxr⟩u, mj = ⟨λxrj⟩uj, n = r[u1/xf (1),..., uk/xf (k)]
and nj = rj[uj /xf′(1),..., uj ′ /xf′(k′)]
1	k
m = (u = (j, v)) · r, mj = (uj = (jj, vj)) · rj, n = r and nj = rj.
m = e[u], mj = e[uj], n = e[r] and nj = e[rj] with the pair of reductions n →rpcf r uj →rpcf rj follows any of the above schemes.
Then n ¨ nj. If moreover n = nj, then m = mj.
Proof. We refer to Ehrhard and Regnier’s proof of Theorem 10 [13] for the first redex case. The other reductions follow by a straightforward induction.	2
Our goal now is to show, thanks to the previous results, that if for some M , two terms m, mj ∈ Tpcf(M ) reduce to a same term n, then m = mj. We establish this for parallel resource reduction ⇒pcf defined below.
Definition 3.8 [Parallel reduction of PCF resource terms]
m ⇒pcf m for all m ∈ ΔPCF.
If mi ⇒pcf mj for all i ∈ {1,..., n} then [m1 ..., mn] ⇒pcf [mj ,.  mj ].
i	1	n

If m ⇒pcf mj, [n1 ..., nk] ⇒pcf [nj ,... nj ] degx(m) = k, and f ∈ Sk, then
1	k
⟨λxm⟩[n1,..., nk] ⇒pcf mj[nj /xf (1),..., nj /xf (k)].
1	k
If m ⇒pcf mj then λxm ⇒pcf λxmj
If m ⇒pcf mj and n ⇒pcf nj, then (m = k) · n ⇒pcf (mj = k) · nj
If m ⇒pcf mj and n ⇒pcf nj then (m = k) · n ⇒pcf nj if m = k.
If m ⇒pcf mj and n ⇒pcf nj then ⟨m⟩n ⇒pcf ⟨mj⟩nj.
Lemma 3.9 Let m, mj, n, nj such that m ¨ n, m ⇒pcf mj and n ⇒pcf nj. If mj = nj
then m = n.
Proof. The proof is by induction on m. The contextual reductions follow from induction hypothesis, and redex cases follow from Lemma 3.7. We only give the initialisation and examples of such two reductions, the other calling for identical arguments.
If m = x then mj = n = nj = x.
If m = λxs, then n = λxr for s ¨ r, mj = λxsj for s ⇒pcf sj and nj = λxrj for r ⇒pcf rj. By induction hypothesis, and since sj = rj, we have s = r and then m = n.
If m = ⟨λxr⟩[s1,..., sn] and mj = rj[sj /xf (1),..., sj /xf (k)], then we observe
1	k
that there exist v ¨ r, wi ¨ si such that n = ⟨λxv⟩[w1/xg(1),..., wl/xg(l)].
Since m ⇒pcf mj, by a classical standardization argument, m →rpcf mjj = r[s1/xf (1),..., sk/xf (k)] ⇒pcf mj and n →rpcf njj = v[w1/xg(1),..., wl/xg(l)] ⇒pcf nj. We can now apply Lemma 3.7 and deduce that mjj ¨ njj, and conclude by induction hypotheses as above.
2
By combining Lemmas 3.7 and 3.9, we obtain the following result which was our goal, and which is a particular case of the finiteness property of Taylor expansion :
Corollary 3.10 Let n ∈ ΔPCF, and M a term of PCF. #{m ∈ ΔPCF; m ∈ Tpcf(M ),m ⇒ n}≤ 1.
We can then reproduce the arguments we set for Call-By-Value to state that a quantitative version of Taylor expansion makes sense, with respect to the finiteness of coefficients keeping true under reduction, and then in Taylor normal form.
The Bang calculus

Pursuing the investigation of the relations between Taylor expansion and re- duction strategies, Ehrhard and Guerrieri introduced a fine grain calculus that permits the embedding of Call-By-Name and Call-By-Value in it [10]. Guerrieri and Manzonetto studied more recently the correspondence between these embeddings and the respective operational semantics of Call-By-Name and Call-By-Value [16]. We briefly explain how our finiteness result applies in this particular setting.

A motivation behind this study is to approach a calculus close to Levy’s Call-By- Push-Value[22]. In order to do so, a first step is to study then Bang Calculus that has similar properties to Call-By-Push-Value, with respect to the embeddings of distinct strategies of evaluation. We are interested in Call-By-Push-Value because Ehrhard and Tasson provided an interpretation of it in probabilistic coherent spaces, and extending our results to a Call-By-Push-Value resource calculus would generalize the construction for all the evaluation strategies that can be embedded here. This extension in discussed in the conclusion.
Bang calculus also differs from PCF because of PCF being typed, in order to stay consistent with Ehrhard, Pagani and Tasson’s model, while Ehrhard and Guerrieri use reflexive objects of shape X ∼= !X & (!X  X) in the semantics, so as to work is an untyped setting.
This Bang calculus denoted as Λb and the corresponding resource calculus denoted as Δb are defined below. In addition to the usual β-reduction rule, the calculus is endowed with a dereliction/promotion rule ()!/der, which “opens” a multiset, giving access to its content. It is equivalent to the opening of a box in Linear Logic proof nets,
Definition 4.1 [Bang Calculus Λb [10]]
V ::= x | M !	Λ! : M, N ::= λxM | der(M ) | MN 
The reduction rules are the following : der(M !) →b M	(λxM )V →b M [V/x]
Definition 4.2 [Bang resource calculus Δb [10]]
Δb : m, n ::= x | λxm | ⟨m⟩n | [m1,..., mk] | der(m) The reduction rules are the following :
der([m]) →rb m	⟨λxm⟩y →rb m[y/x]
⟨λxm⟩[n1,..., nk] →rb m[n1/xf (1),..., nk/xf (k)] if k = degx(m) and f ∈ Sk
The Call-By-Name and Call-By-Value embeddings ()name and ()val of usual pure
λ-calculus into the Bang calculus run as follows:
xname = der(x)	xval = x
(λxM )name = λxM name	(λxM )val = (λxM val)!
(MN )name = (M name)(N name)!	(MN )val = (der(M val))N val
These two embeddings follow the well-known translations of intuitionistic implication A → B to linear logic formulas !A  B (Call-By-Name) and !A  !B (Call-By- Value). This is a striking feature of linear logic to permit the distinction between the two evaluation strategies through the management of exponentials formulas. The multiset construction of Taylor expansion defined below is then directed by the promotion construct ()!, while, roughly speaking, in Call-By-Name or Call-By-Value, it was directed by the intuitive distinction function/argument.

Definition 4.3 [Bang Calculus Taylor expansion [10]]
fb(x)= x	fb(λxM )= {λxm | m ∈ fb(M )}
fb(MN )= {⟨m⟩n | m ∈ fb(M ),n ∈ fb(N )}	fb(der(M )) = {der(m) | m ∈ fb(M )}
fb(M !)= {[m1,..., mk] | k ∈ N, ∀i : mi ∈ fb(M )}

We can observe that for any ⟨λxm⟩n ∈ Tb(((λxM )N )val), reducing the external redex is possible if and only if N is a value. Indeed, in this case, n is a multiset. Otherwise, n must be evaluated before the external redex. On the other hand, if
⟨m⟩n ∈ Tb (((λxM ) N )name), then n is always a multiset and the external redex can always be reduced. We even have, for any term M of pure λ-calculus, a close correspondence between Tb(M val) and TU (M ), up to some technical differences related to the dereliction and the variables, but the multiset structure is the same. This remark also holds for usual Call-By-Name Taylor expansion T (M ) defined by Ehrhard and Regnier, and Tb(M name). We can now announce the finiteness result for the Bang calculus, because we can naturally define a parallel reduction ⇒rb included in the reflexive transitive closure of →rb, necessary for simulate β-reduction.

Proposition 4.4 Let M ∈ Λ!, n ∈ Δ!, k ∈ N. {m ∈ Tb(M ) | m ⇒k
n} is ﬁnite.

We do not detail the proof, because it would rely on the same ingredients and arguments we set for Call-By-Value: it is not difficult to observe that for all M ∈ Λ!, Tb(M ) enjoys the necessary properties for proposition 4.4 to be established. Notice that we did not consider here any σ-rules, as Guerrieri and Ehrhard, but it will be necessary in further works in order to study issues about normal forms, and clashes during the reduction. An observation of Definition 4.3 is sufficient to see that the applicative depth of terms in Tb(M ) cannot exceed the depth in M , and the argument about the size, leading to Lemma 2.8 in the Call-By-Value calculus appears valid for the Bang calculus too. In other words, the applicability of the method does not depend essentially on the choice of a reduction strategy, because in particular the depth of resource terms appearing in Taylor expansion does not depend on how we deal with exponentials.
Conclusion and perspectives

We introduced the necessary definitions to study Taylor expansion in various settings which demand respectively distinct proof methods. A possible extension of this work is to generalize these results in a common setting thanks to our work with Vaux-Auclair on linear logic-proof nets [4]. Indeed, there exist already well- known embeddings of Call-By-Name and Call-By-Value into proof nets, and the results about Taylor expansion become then a syntactic work, of presenting these translations and proving that they commute with Taylor expansion (e.g. that Taylor expansion of the proof net coming from a Call-By-Value translation corresponds to the translation of Call-By-Value Taylor expansion of Section 2.1). But a construction of proof nets corresponding to Call-By-Need, Bang Calculus and to PCF would be of great interest in that perspective.

The other direction of work that is suggested by our study is to define Taylor expansion for Levy’s Call-By-Push-Value [22]. Indeed, we saw with Bang Calculus that a calculus endowing Call-By-Name and Call-By-Value can be simulated by a resource calculus, and that the finiteness property of its Taylor expansion can be adapted from Call-By-Name and Call-By-Value constructions, and that the extension to an explicit exponential and dereliction causes no damage to the good behaviour of our proof methods. On the other hand, we saw with PCF that we can deal with a typed setting with explicit fixpoint, if we come back to arguments relying on coherence between resource terms. Then we have good hope to extend our results to a linear logic-based variant of Call-By-Push-Value, interpreted in Ehrhard and Tasson’s work [14]. But we cannot proceed easily in that way, because of the expressivity of the calculus, and the management of types both making it difficult to introduce a resource calculus with an adequate notion of reduction. In particular, an application (λxM )V is a redex if V has a positive type (that is !, ⊗, or ⊕). This implies that the quantitative interpretation of V will not always correspond to the exponential, and hence will not always be considered as a multiset, from a resource point of view, but can be a pair (v1, v2) for example, if V is of a product type. In that case, Ehrhard and Tasson use semantical arguments (relied to the presence of morphisms of coalgebras in the model) to state that positive types are freely duplicable, but giving an account of this property in the syntax is not a trivial task and calls for a detailed construction of a particular resource calculus, that cannot be easily imported from the existent ones, where only the reducible applications have always an argument interpreted by an exponential, and thus approximated by a multiset.

References
Z. M. Ariola, M. Felleisen, J. Maraist, M. Odersky, and P. Wadler. The call-by-need lambda calculus. In Conference Record of POPL’95, 1995.
G. Boudol. The lambda-calculus with multiplicities (abstract). In CONCUR’93, 1993.
S. Castellan, P. Clairambault, H. Paquet, and G. Winskel. The concurrent game semantics of probabilistic PCF. In LICS 2018, Oxford, UK, July 09-12, 2018, pages 215–224, 2018.
J. Chouquet and L. Vaux Auclair. An application of parallel cut elimination in unit-free multiplicative linear logic to the Taylor expansion of proof nets. In CSL 2018, 2018.
V. Danos and T. Ehrhard. Probabilistic coherence spaces as a model of higher-order probabilistic computation. Inf. Comput., 209(6):966–991, 2011.
Daniel de Carvalho. Execution time of lambda-terms via denotational semantics and intersection types.
CoRR, abs/0905.4251, 2009. arXiv:0905.4251.
T. Ehrhard. Finiteness spaces. Mathematical Structures in Computer Science, 15(4):615–646, 2005.
	T. Ehrhard. A finiteness structure on resource terms. In LICS 2010, 11-14 July 2010, Edinburgh, United Kingdom, 2010.
	T. Ehrhard. Collapsing non-idempotent intersection types. In Computer Science Logic CSL 2012, pages 259–273, 2012.
T. Ehrhard and G. Guerrieri. The bang calculus: an untyped lambda-calculus generalizing call-by-name and call-by-value. In Principles and Practice of Declarative Programming, 2016.


	T. Ehrhard, M. Pagani, and C. Tasson. Full abstraction for probabilistic PCF. CoRR, abs/1511.01272, 2015. arXiv:1511.01272.
T. Ehrhard and L. Regnier. The differential lambda-calculus. Theor. Comput. Sci., 309(1-3):1–41, 2003.
	T. Ehrhard and L. Regnier. Uniformity and the Taylor expansion of ordinary lambda-terms. Theor. Comput. Sci., 403(2-3):347–372, 2008.
	T. Ehrhard and C. Tasson. Probabilistic call by push value. CoRR, abs/1607.04690, 2016. arXiv: 1607.04690.
	J-Y. Girard. Normal functors, power series and lambda-calculus. Annals of Pure and Applied Logic, 37(2):129, 1988.
Giulio Guerrieri and Giulio Manzonetto. The bang calculus and the two girard’s translations. CoRR, abs/1904.06845, 2019. URL: http://arxiv.org/abs/1904.06845, arXiv:1904.06845.
E. Kerinec, G. Manzonetto, and M. Pagani. Revisiting Call-by-value Bo¨hm trees in light of their Taylor expansion. CoRR, abs/1809.02659, 2018. arXiv:1809.02659.
M. Kerjean and C. Tasson. Mackey-complete spaces and power series - a topological model of differential linear logic. Mathematical Structures in Computer Science, 28(4):472–507, 2018.
	D. Kesner. Reasoning about call-by-need by means of types. In Foundations of Software Science and Computation Structures - 19th International Conference, FOSSACS 2016, 2016.
Ugo Dal Lago and Thomas Leventis. On the Taylor expansion of probabilistic λ-terms. CoRR, abs/1904.09650, 2019. URL: http://arxiv.org/abs/1904.09650, arXiv:1904.09650.
J. Laird, G. Manzonetto, G. McCusker, and M. Pagani. Weighted relational models of typed lambda- calculi. In LICS 2013, pages 301–310, 2013.
	P. B. Levy. Call-by-push-value: Decomposing call-by-value and call-by-name. Higher-Order and Symbolic Computation, 19(4):377–414, 2006.
M. Pagani, C. Tasson, and L. Vaux. Strong normalizability as a finiteness structure via the Taylor expansion of lambda-terms. In FOSSACS 2016, pages 408–423, 2016.
	P-M. P´edrot and A. Saurin. Classical by-need. In Programming Languages and Systems - 25th European Symposium on Programming, ESOP 2016, pages 616–643, 2016.
	Gordon D. Plotkin. LCF considered as a programming language. Theor. Comput. Sci., 5(3):223–255, 1977.
	C. Tasson and L. Vaux. Transport of finiteness structures and applications. Mathematical Structures in Computer Science, 28(7):1061–1096, 2018.
T. Tsukada, K. Asada, and C.-H. L. Ong. Species, profunctors and Taylor expansion weighted by SMCC. In LICS 2018, Oxford, UK, July 09-12, 2018, pages 889–898, 2018.
	L. Vaux. The algebraic lambda calculus. Mathematical Structures in Computer Science, 19(5):1029–1059, 2009.
	L. Vaux. Taylor expansion, β-reduction and normalization. In 26th EACSL Annual Conference on Computer Science Logic, CSL 2017, Stockholm, Sweden, pages 39:1–39:16, 2017.

A	Call-By-Need approximation
Definition A.1 [Call-By-Need calculus Λneed [24]]
Terms : T,U ::= x | λxT | lxT | TU 
Values : V ::= λxT
Contexts : C ::= [] | C1[lxC2]T
E ::= [] | ET | lxE | C[lxE1[x]]E2
Reduction rules : C[λxT ]U →need C[lxT ]U
C1[lxE[x]]C2[V ] →need C2[C1[lxE[V ]]V ]

Definition A.2 [Resource approximation of Call-By-Need calculus]
Approximation of Λneed terms:
[x,..., x]  x
[λxt1,..., λxtk]  λxT if ∀i ∈ {1,..., k}, ti  T
tu  TU if t  T et u  U
lxt  lxT if t  T .
Approximation of contexts C. c  C if :
c = C = []
c = c1[lxc2]t, C = C1[lxC2]T , c1  C1, c2  C2 et t  T .
Approximation of contexts E. e  E if :
e = E = []
e = lxe2,E = lxE2, et e2  E2
e = e2t, E = E2T, e2  E2 et t  T
e = c[lxe2[[x,..., x]]]e3,E = C[lxE2[x]]E3, e2  E2, e3  E3 et c  C.
Lemma A.3 If t  T and c  C, then c[t]  C[T ]
Proof. Induction on contexts :
c = [], straightforward by the hypothesis t  T
c = c1[lxc2]u. By definition, C = C1[lxC2]U with ci  Ci and u  U . By induction hypothesis, we have c2[t] C2[T ]. We extend (by definition of ) to lxc2[t] lxC2[T ]. By induction hypothesis on c1, and because u U , we deduce c1[lxc2[t]]u  C1[lxC2[T ]]U.
2
Lemma A.4 If e  E and t  T, then e[t]  E[T ]
Proof. Similar induction on contexts e.	2
Lemma A.5
If t  T and T = C[U ], then there exists u  U and c  C such that t = c[u].
If t  T and T = E[U ], then there exists u  U and e  E such that t = e[u].
Proof. (i) induction on C.
If C = [], then T = U , and t fits.
If C = C1[lxC2]T j, then by definition of  , if t  T , t = stj with s  C1[lxC2[U ]] and tj T j. By induction hypothesis on C1, s = c1[lxw] with c1  C1 and w C2[U ]. Similarly, by induction hypothesis on C2, w = c2[u] with c2  C2 and u  U .
We then have t = c1[lxc2[u]]tj, and ci  Ci,u  U, tj  T j.
: similar induction on E;	2
Lemma A.6 Let T →need U. For all t  T, either t →rneed 0, or there is some
u  U such that t →rneed u.
Proof. Induction on the reduction:

T = C[λxTj]T jj, and U = C[lxT1]T2. By Lemma A.5, if t  T , there exist t1,... tk tj, tjj T jj, c C such that t = c[[λxt1,... λxtk]]tjj. If k = 1, t →rneed 0. Otherwise, t →rneed c[lxt1]tjj  U .
T = C1[lxE[x]]C[V ], U = C[C1[lxE[V ]]V ].  By Lemma A.5, if t  T , then
t = cj[lxe[[x1,..., xk]]c[[v1,..., vk]+ −→v ] with cj  Cj,c  C, e  E, ∀i : vi  V . We have t →rneed c[c1[lxe[[v1,..., vk]]]−→v ]  U
2
Lemma A.7 Let T →need U. For all u  U, there exists t  T such that t → u.
Proof. Induction on the reduction.
U = C[lxUj]U jj et T = C[λxUj]U jj. By Lemma A.5, if u  U , then u = c[lxuj]ujj for some c C, uj Uj, ujj ujj. It is then sufficient to consider t = c[[λxuj]]ujj, because in that case, t  T .
U = C[C1[lxE[V ]]V ], T = C1[lxE[x]]C[V ] : similar argument.
2
