Electronic Notes in Theoretical Computer Science 206 (2008) 3–21	
www.elsevier.com/locate/entcs

An Abstract Analysis Framework for Synchronous Concurrent Languages based on source–to–source Transformation
M. Alpuentea,5 ,1	M.M. Gallardob,5 ,2	E. Pimentelb,5 ,3
A. Villanuevaa,5 ,4
a Dept. SIC
Technical University of Valencia Valencia, Spain
b Dept. LCC University of Málaga Málaga, Spain

Abstract
A pretty wide range of concurrent programming languages have been developed over the years. Coming from different programming traditions, concurrent languages differ in many respects, though all share the common aspect to expose parallelism to programmers. In order to provide language level support to pro- gramming with more than one process, a few basic concurrency primitives are often combined to provide the main language constructs, sometimes making different assumptions. In this paper, we analyze the most common primitives and related semantics for the class of synchronous concurrent programming languages, i.e., languages with a global mechanism of processes synchronization. Then, we present a generic framework for approximating the semantics of the main constructs which applies to both, declarative as well as imper- ative concurrent programming languages. We determine the conditions which ensure the correctness of the approximation, so that the resulting abstract semantics safely supports program analysis and verification.


Introduction
Concurrent programming languages are programming languages that use language constructs for concurrency. Two main approaches exist to concurrency: the syn- chronous and the asynchronous models. Asynchronous models are based on the assumption that system components running in parallel proceed at different rates.

1 Email: alpuente@dsic.upv.es
2 Email: gallardo@lcc.uma.es
3 Email: ernesto@lcc.uma.es
4 Email: villanue@dsic.upv.es
5 This work has been partially supported by the EU (FEDER) and the Spanish MEC, under grants TIN2004-7943-C04-01, TIN2007-68093-C02-02 and TIN2007-67134

1571-0661© 2008 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2008.03.072

Synchronous models differ from asynchronous ones since they assume that all sys- tem components share the same clock and are perfectly synchronized. Synchronous languages [2,7] such as Esterel [3], StateCharts [10], and Argos [11] are imperative, whereas the relational languages Signal [9] and tccp [14], and the functional language Lustre [5] are declarative. Synchronous languages typically offer primitives to deal with negative information, namely to instantaneously test absence of signals. These languages are also based on the strong synchronous hypothesis, meaning that each reaction of the reactive system is assumed to be instantaneous, and then takes no time. This provides a deterministic semantics of concurrency as well as a formal straightforward interpretation of temporal statements. While the synchronous hy- pothesis is considered unrealistic when communication time cannot be neglected, it makes sense when programming reactive systems, i.e., systems which continu- ously interact with the environment: operating systems, real–time control software, client/server applications, and web services typically fall in this category. In this context, to “take no time” is understood in two ways: the environment remains in- variant during the reaction, and all sub–processes react instantaneously at the same time.
There are numerous advantages to the synchronous approach. The main one is that the temporal semantics is simplified, thanks to the so–called logical time ab- straction: all the parallel processes evolve simultaneously, along a common discrete time scale. This leads to clear temporal constructs and easier time reasoning. On the contrary, asynchronous programs are generally not temporally predictable. An- other key advantage is the reduction of state–space explosion, thanks to the discrete logical time abstraction: the system evolves in a sequence of discrete steps, and nothing occurs between two successive steps. A first consequence is that program debugging, testing, and validating is made easier. In particular, formal verification of synchronous programs is possible with techniques like model checking.
Similarly to sequential languages, abstract interpretation is commonly applied to analyzing properties of concurrent languages statically. Since abstraction usually involves adding non–determinism, applying abstract interpretation to synchronous languages raises specific problems which are related to synchronization. The sus- pension behavior of concurrent programs has been studied in different programming languages and paradigms [6,15]. When we approximate the semantics of concurrent languages by abstract interpretation, it can happen that the original program sus- pends whereas by using the abstract semantics it does not; hence synchronization in the abstract model might be damaged, as shown in Example 3.2 below. Depending on the concurrent model that we consider, this lack of precision of the approxima- tion does not generally imply incorrectness of the abstract semantics [15]. However, it is always the case when dealing with strongly synchronized processes and partial information (see [1]). This is why both, correctness and accuracy must be considered when defining the abstract semantics of a concurrent language. Trying to achieve a correct abstract semantics has also a payoff related to the precision of the abstract model, since excessively abstracting the original semantics may lead to generating very imprecise abstract models containing execution paths which do not correspond

to any real behavior.
The inspiration for this work comes from [1,8]. With regard to [8], we generalize the abstract semantics of Promela to the case of a generic language that we define by combining a set of basic primitives; however, in this work we have only considered the synchronous approach to concurrency, whereas the synchronous as well as the asynchronous nature of Promela are considered in [8]. Our abstract framework can be parametrized for different languages, and allows us to analyze how the basic primitives must be abstracted to achieve precision while ensuring 1) the correctness of the approximation, and 2) the possibility to define the abstraction as a source– to–source transformation.
In this paper, we analyze the most common primitives and related semantics for the class of synchronous concurrent languages. Then, we present a generic frame- work for approximating the semantics of the main constructs which applies to both, declarative and imperative concurrent programming languages. We determine the conditions which ensure the correctness of the approximation so that the resulting abstract semantics safely supports accurate program analysis and verification.

The synchronous approach
Semantics for concurrent languages are usually given by means of Plotkin’s struc- tural operational semantics (SOS) [12], where processes behavior is described by labeled transitions systems, namely graphs with nodes (states) representing process configurations and labeled arcs representing atomic computation steps. A tuple con- sisting of two nodes and an arc connecting them is called a transition. A trace is a sequence of transition steps.
In this section, we define some basic notions appearing in the semantics of all concurrent synchronous languages, disregarding the differences linked to particular syntax or combinations of constructs in a particular language, and concretely to the declarative or imperative nature of the language.
System states
Let us denote with State the set of system states. We are general when speak- ing about states since we intend to consider both, states as valuations of vari- ables (imperative–style), and states as conjunctions of constraints (constraint–based style). Thus, each state s ∈ State is either the set of program variables bound to their actual value (when dealing with imperative languages), or a set of constraints (in a constraint–based language). Anyway, we assume that, given a set of vari- ables V , state ∃V s represents the state s with the information about variables in
V removed, called hiding–variables operation. In addition, we suppose that State contains an element ϵ representing the empty state, that is, the state that does not provide any information. Clearly, if V is the set of variables appearing in state s,
∃V s = ϵ.
We assume that states may be composed by means of ⊕ : State × State →
State . Operator ⊕ models the change of state. We assume that ⊕ is idempotent,

that is, ∀s ∈ State , s ⊕ s = s. The definition of ⊕ depends on the execution model considered. For instance, for the constraint–based, declarative synchronous model shown in [4], where maximal parallelism is implemented, composition of states (stores) s⊕s' is usually defined as sHs' where H is the lub operator in the underlying lattice of constraints. Stores increase monotonically during program execution, that is, the information registered is never canceled. However, other declarative languages in the cc paradigm such as the model in [13] differ from this behavior, being the evolution of the store non–monotonic.
In the imperative framework, the ⊕ operator is usually defined as a destructive update, i.e., the value of a given variable at one time instant is substituted by a new value at the subsequent time instant. This implies that the order in which updates are executed does matter, since different choices for the ordering might produce different results.
Since in most paradigms composition of states is an idempotent operation, we assume it so in this paper. In addition, we assume that the empty state ϵ works as the neutral element for ⊕, that is, ∀s ∈ State , s ⊕ ϵ = ϵ ⊕ s = s. Finally, in order to properly deal with the hiding–variables operation, we assume that for each set of variables V , and for each states s, s' ∈ State , s ⊕ ∃V s = ∃V s ⊕ s = s, and
∃V (s ⊕ s') ≡ ∃V s ⊕ ∃V s'.
Basic actions
Basic actions are those atomically executed by the program. In most languages, the set of basic actions mainly boils down to a test (also called ask ) action and an update (also called tell ) action. Let us denote Ask and Tell the sets of test actions and update actions of a language, respectively. Intuitively, the elements of Tell represent the language actions that may modify the program states, whereas the actions in Ask represent the checking of guards used to implement control instructions and synchronization. We assume that the language supports the empty test true: true ∈ Ask.
Finally, we assume that semantic functions effect : Tell × State → State and test : Ask × State → {false, true } define the behavior of the basic actions of the language. Intuitively, effect represents the effect of a specific update action when executed on a particular state, whereas test checks if the condition specified by a basic test action can be derived from a specific state (i.e., the condition is fulfilled). Note that effect depends on the specific implementation of the operator ⊕, which is the operator that makes states evolve.
In order to correctly model control flow instructions, we assume that each test a ∈ Ask is complemented by another action ¬a ∈ Ask which represents that a does not hold, i.e., the test fails 6 . Although negation is not uniformly treated within the different programming models, under the considered assumptions, the following

6 The ¬a action must not be confused with the action which semantically can be interpreted as the opposite of a. For example, assume a constraint–based system where variable X has the value X ∈ [0, 10], i.e., the value of variable X can be any of the values in the considered interval. The opposite test of X > 5 is X ≤ 5, and none of them follows. However, the fact that X > 5 doesn’t hold allows us to conclude that ¬X > 5 does hold.

holds
test (a, S) ⇔ ¬test(¬a, S)
Thus, the 3-uple ⟨State , test , effect⟩ (called semantic context ) defines the seman- tics of the basic actions of the language.
In the synchronous approach, the execution of basic actions take time, and this is the way time passes. Figure 1 shows the language syntax we choose for the description.















Fig. 1. Syntax of the synchronous language
Intuitively, a program is a set of declarations together with an initial action Action. A declaration can be seen as a procedure definition proc(x¯), where parame- ters can be passed to the body, Action. In the body of a declaration, we can specify the following actions: a! updates the state, A; B executes the action A and, once finished, continues by executing the action B, A||B concurrently executes actions A and B. The Global Choice checks whether the current state satisfies any of the guards, and chooses one among the associated actions to be executed in the subse- quent time instant. The Instantaneous Choice differs from the Global Choice since the associated action starts at the same time instant the guard is checked. The Local Declaration defines local variables to actions. The Conditional executes the

action associated to the then-branch provided the condition is satisfied; otherwise executes the action in the else-branch. Finally, procedure call proc(v¯) passes values in v¯ to the action in its body. Action error models an erroneous execution, whereas end represents when a thread normally finishes.
As will be apparent later, the following notion of labeling is instrumental to reason about processes synchronization. Actions in program P = D[A0] can be unequivocally labeled with elements of a set L of labels. Assume that func- tion nLab : → L returns a new fresh label at each invocation.  Then, given D = {proci(x¯){Ai}|1 ≤ i ≤ n}, function lab defined below constructs the set of labeled declarations lab(D)= {proci(x¯){lab(nLab(), Ai)}|1 ≤ i ≤ n}.
lab(l, error)= (lerror )error lab(l, end)= (lend )end lab(l, a!) = (l)a!
lab(l, A; B)= lab(l, A); lab (nLab(), B)
lab(l, A||B)= lab(l, A)||lab (nLab(), B)
lab(l, Σ(ai? → Ai)= (l) Σ(ai? → lab(nLab(), Ai))
i∈I	i∈I
lab(l, if a? then A else B)= (l)if a? then lab(nLab(), A) else lab(nLab(), B)
lab(l, ∃xA)= ∃xlab(l, A)
lab(l, proc(v¯)) = (l)proc(v¯)
lab(l, Σ(ai? →∗ Ai)= (l) Σ(ai? →∗ lab(nLab(), Ai))
i∈I	i∈I
Operational Semantics
Figure 2 defines the operational semantics of the language given by a transition relation between configurations. Each configuration records both the current state and the set of instructions to be executed. The transition relation is parametric
w.r.t. S = ⟨State , test , effect ⟩. Different states, and/or different definitions for test and effect determine different transition relations →S. In the figure, ai(i = 1,... , n), a,b ∈ Ask and c ∈ Tell. We assume that the parallel and choice actions are commutative, i.e., the order in which the different actions are represented does not affect the final result. Action A[v/x] represents the action A where the formal parameters x have been substituted by the actual parameters v.
Definition 2.1 A pair Λ ≡ ⟨A, s⟩ denotes a program configuration where A is the program to be executed and s the current state.
In the semantics, we assume that each action is labeled with the label that points to the program instruction to be subsequently executed. In rule R-S1, operator end is labeled with the special tag lend ∈ L. Similarly, when an inconsistent state is reached, a transition to a state with action error is performed. Given a configuration
⟨A, s⟩, A being the parallel composition of operators A1||··· ||An, we denote with
pLab(A) the ordered sequence l1||··· ||ln of labels of operators in A. In rule R-S6,



Fig. 2. Operational semantics of a synchronous language
sL is the local store of A; initially sL is the state ϵ ∈ State , i.e., the neutral element of operator ⊕, and it accumulates the information known by A.
Let us assume that semantic contexts S  = ⟨State , test , effect ⟩ and S' =
⟨State ', test ', effect '⟩ give us two different transition relations →S and →S' for a given program D[A0], and let ∼⊆ State × State ' be a binary relation. Then we reformulate the classic notion of simulation as follows:
Definition 2.2 Transition relation →S' is a ∼-simulation of →S iff for each S-

transition ⟨A, s1⟩ →S ⟨B, s2⟩, if ⟨A', s' ⟩ is a configuration such that s1 ∼ s'
and

1	1

pLab(A) = pLab(A') then there exists a S'-transition ⟨A', s' ⟩ →S'  ⟨B', s' ⟩ with
1	2
s2 ∼ s' , and pLab(B)= pLab(B').
Assume S = ⟨State , test , effect ⟩. Given a synchronous program P of the form D[A0], and an initial state s0 ∈ State , the trace based semantics of P determined by the transition relation →S, denoted by T (S)(D)(⟨A0, s0⟩), is the set of maximal traces of the form ⟨A0, s0⟩ →S ⟨A1, s1⟩ →S ··· that can be constructed from initial configuration ⟨A0, s0⟩.
Consider S = ⟨State , test , effect⟩ and S' = ⟨State ', test ', effect '⟩, such that →S'
is a ∼-simulation of →S. It is easy to prove that T (S')(D)(⟨A' , s' ⟩) is a correct
0	0
∼-simulation of T (S)(D)(⟨A0, s0⟩), that is, for each trace ⟨A0, s0⟩ →S ⟨A1, s1⟩ →S
··· in T (S)(D)(⟨A0, s0⟩), there exists a trace ⟨A' , s' ⟩ →S'  ⟨A' , s' ⟩ →S'  ··· in
0	0	1	1
T (S')(D)(⟨A' , s' ⟩) such that ∀i ≥ 0.si ∼ s', and pLab(Ai)= pLab(A' ).
0	0	i	i
Abstraction of Basic Actions
Abstracting states
As it is well known, abstract interpretation may be equivalently defined by upper closure operators (ucos) and Galois insertions. An uco ρ : ℘(State ) → ℘(State ) is a monotonic (ss1 ⊆ ss2 ⇒ ρ(ss1) ⊆ ρ(ss2)), idempotent (ρ(ρ(ss)) = ρ(ss)) and extensive (ss ⊆ ρ(ss)) operator. Given s ∈ State , and an uco ρ over (℘(State ), ⊆), ρ({s}) is the best ρ-abstraction of s. Moreover, if ρ({s}) ⊆ ss, then ss is a different less precise abstraction of state s.
In order to simulate abstract operator ⊕, we define ⊕ρ : Stateρ × Stateρ → State ρ as ss1 ⊕ρ ss2 = ρ({s1 ⊕ s2|s1 ∈ ss1, s2 ∈ ss2}). Observe that this definition guarantees that ρ({s1 ⊕ s2}) ⊆ ρ({s1}) ⊕ρ ρ({s2}).
Assume that ι : ρ(℘(State )) → Stateα is an isomorphism for a given abstract domain Stateα; then, (℘(State ), State α, ιρ, ι−1) is a Galois insertion, ιρ and ι−1 being the abstraction and concretization functions. In the sequel, we denote ιρ and ι−1 with α and γ.
Now operator ⊕α may be defined as:
sα ⊕α sα = ι(ι−1(sα) ⊕ρ ι−1(sα))
1	2	1	2
Abstracting actions
Once the domain has been abstracted, we have to abstract the basic actions of the language, i.e., updates and tests. Assume that ρ is an uco defining an abstraction over states as explained above. We define the abstract test test ρ : Ask × ℘(State) →
{false, true} and effect effectρ : Tell × ℘(State ) → ℘(State ) functions as follows:
test ρ(a, ss)=   test (a, s)
s∈ss

effectρ(b, ss)= ρ({effect (b, s),s ∈ ss})

Assuming that α and γ are the abstraction and concretization functions re- lating ℘(State ) and State α as described above, the preceding definitions may be reformulated as the functions test α : Ask × Stateα → {false, true } and effectα : Tell × State α → Stateα:

test α(a, sα)=	 
s∈γ(sα)
test (a, s)

effectα(b, sα)= α({effect (b, s),s ∈ γ(sα)})
Following the terminology used in Section 2.2, we have given an abstract semantic context Sα = ⟨State α, test α, effectα⟩ to the basic actions of the language, which determines the abstract transition relation →Sα . Let us define the natural binary relation between concrete and abstract states as
s ∼α sα ⇐⇒ ρ({s}) ⊆ ι−1sα
that is, s ∼α sα iff sα is an abstraction of s or, inversely, iff s is a concretization of sα. In the rest of the paper, we assume that relation ∼α is preserved under the hiding–variables operation ∃V , that is, if s ∼α sα then ∃V s ∼α ∃V sα.
Now we can easily prove the following result:
Proposition 3.1 If s1 ∼α sα and s2 ∼α sα then s1 ⊕ s2 ∼α sα ⊕α sα.
1	2	1	2
Proof. By definition of ⊕ρ, we have that ρ({s1 ⊕ s2}) ⊆ ρ({s1}) ⊕ρ ρ({s2}). By hypothesis, ρ({s1}) ⊆ ι−1(sα) and ρ({s2}) ⊆ ι−1(sα), hence we deduce that
1	2
ρ({s1}) ⊕ρ ρ({s2}) ⊆ ι−1(sα) ⊕ρ ι−1(sα). Now, by definition of ⊕α, we have that
1	2
ι−1(sα) ⊕ρ ι−1(sα) = ι−1(sα ⊕α sα). Therefore, we obtain that ρ({s1 ⊕ s2}) ⊆
1	2	1	2
ι−1(sα ⊕α sα), as desired.	 
1	2
Although the function test α above aimed at preserving the concrete behavior, we have that, in general, →Sα is not a ∼α-simulation of →S as shown in the following example.
Example 3.2 Consider the set of states State = {X = n|n ∈ N}, where X is a variable ranging over the natural numbers. Let α : State → Stateα be the usual even/odd abstraction, where State α = {X mod 2 = 0,X mod 2 /= 0}.
Clearly, given S = ⟨State , test , effect ⟩, where function test is the ordinary test for variable values, we have that
⟨if (X = 4)? then P else Q || A,X = 2⟩ →S ⟨Q’ || A’,X = 2⟩
However, considering the abstract semantic context Sα = ⟨State α, test α, effectα⟩, where  test α  is  defined  as  specified  above,  we  have  that  action
⟨if (X = 4)? then P else Q || A, X = 2⟩ cannot evolve by means of →Sα to any configuration of the form ⟨Q’ || A’, s⟩. In fact, since test α(X = 4,X mod 2 = 0) holds, the only possible transition is
⟨if (X = 4)? then P else Q || A,X = 2⟩ →Sα ⟨P’ || A’,X = 2⟩

and, clearly, P /= Q implies pLab(Q || A) /= pLab(P || A).
The problem is that function test α is an over–approximation of test and may return true even if the concrete version returns false . This is critical in synchronous languages, since it may lead to losing the synchronization between the parallel op- erators (as illustrated in the example), and the concrete and abstract semantics produce completely different traces. Since the abstract program cannot produce a trace that simulates the concrete one, the abstract relation →Sα is incorrect.

Correct Abstraction of Actions
Let P = D[A0] be a program. Consider a semantic context £ = ⟨State , test , effect ⟩ together with an abstraction function α : State → Stateα, which determines an abstract semantic context £α = ⟨State α, test α, effectα⟩. In this section, we show how to construct an abstract program Pα = α(D)[α(A0)] such that, for each ini- tial state s0 ∈ State, 7 (£α)(α(D))(⟨α(A0), α(s)⟩) is a correct ~α-simulation of 7 (£)(D)(⟨A0, s0⟩). The key point of this transformation is to guarantee that the new abstract program α(D)[α(A0)] may be executed under the same semantic con- text £ as the original program D[A0]. Recall that our main interest is to define a source–to–source transformation, which allows us to exploit the maturity, generality and sophistication of other eventually existing processing techniques and tools for the source language.
In order to effectively define a source–to–source transformation from concrete programs into abstract ones, we need that each abstract element in State α be in fact an element in State, that is, State α must be a proper subset of State . In this way, each abstract execution consists of a sequence of elements in State . For instance, in Example 3.2, the set of abstract states Stateα could be defined as the subset
{X = 0,X = 1} of State, X =0 and X =1 representing the even and odd values for variable X, respectively.

Implementing the abstract basic actions
The first step to implement abstraction by source–to–source transformation consists in constructing abstract versions of the basic actions by reusing the concrete test and effect functions given by the original semantics of the language. For this purpose, we have to combine standard actions so that they behave like the abstract ones, provided that the corresponding correctness conditions are satisfied.
Let α : Ask → Ask be the abstraction function 7 for tests. For each a ∈ Ask, we need to find an action α(a) ∈ Ask such that, for all sα ∈ State, test α(a, sα) ⇐⇒ test (α(a), sα). Recall that it is possible to apply the function test to abstract states since State α ⊆ State. For instance, considering the simple even/odd example given above, test X mod 2 = 0 can be easily abstracted into test X = 0.

7 By abusing notation, we use the same name for the abstract function applied to the different elements of the language: states, actions, etc.

Similarly, let α : Tell → Tell be the abstraction function for tell actions. For each b ∈ Tell, we need to find α(b) ∈ Tell such that, for all sα ∈ State , effectα(b, sα)= effect(α(b), sα). This means that the abstract action has the same effect than abstracting the result of the concrete action. Following the previous examples, concrete tell action X = X +1 may be transformed into the abstract tell action X = (X + 1) mod 2.
In order to obtain an effective approximation of the semantics based on abstract interpretation, some sensible decisions would be made at this level which depend on the specific language and are not considered here. These decisions regard in particular how to abstract both, the domain as well as the basic actions. In the following section we discuss how the operators can be generally abstracted. The accuracy of these abstractions directly determines the amount of non real traces added to the abstract model.
Abstracting operators
When abstracting a synchronous language, the main problem for the correctness of the abstract model is the preservation of the suspension behavior of the program; in the asynchronous model this problem does not show up.
In the following, we focus on the abstraction of those actions that are more critical in the sense that their execution can suspend. This includes the global choice action. As we are going to see, also the conditional operator must be handled with particular care. Actually, we are able to abstract the conditional operator without altering the notion of time of the source language only if the language being abstracted does provide an instantaneous choice operator. Below we clarify this point.
Now we are ready to define the abstract versions of the different actions of the language given in Figure 2 in terms of actions of the very same language, i.e., without introducing any new operator that didn’t exist in the original language. Observe that the abstraction function α takes into account the labels of the program to be trans- formed. This is necessary to ensure the correctness of the transformation. It is worth noting that, in the following transformation scheme, we simulate suspensions that occur in the concrete set by replicating configurations in the abstract model. That is, our transformation guarantees that, whenever a concrete configuration ⟨A, s⟩ suspends, the corresponding abstract configuration ⟨α(A), sα⟩ is replicated in the subsequent time instant.
Error The abstraction of the error operator is straightforward:
α((lerror )error)= (lerror )error
End The abstraction of the end operator is also immediate:
α((lend )end)= (lend )end
c! The abstraction of the c! operator is:
α((l)c!) = (l)α(c)!

Sequence The abstraction of the sequentialization is defined as follows:
α((la)A; (lb)B)= (la)α(A); (lb)α(B)
Parallel The abstraction of the parallel operation is given by:
α((la)A||(lb)B)= (la)α(A)||(lb)α(B)
Global choice We abstract the behavior of this operator by using the conditional

operator. Let A ≡ (l)Σn
α(A)= (l)if α(¬a1)? then
··· 
ai? → (li)Ai, then

if α(¬an)? then
true? →∗ (l)(Σn

α(ai)? → (li)α(Ai))

+
true? →∗ p
else (l)(Σn  α(ai)? → (li)α(Ai))

··· 
else (l)(Σn
α(ai)? → (li)α(Ai))

where the procedure p is defined as p{α(A)}. Let us justify the structure of the abstraction of the global choice operator in order to ensure correctness w.r.t. the suspension behavior. Note that, in order to achieve correctness, we must ensure that whenever the concrete execution of the program suspends, there exists at least one abstract execution that also suspends; otherwise, the abstract program wouldn’t include the whole set of possible executions of the concrete program. Note also that, whenever the condition α(¬a1) is not satisfied by an abstract state sα, we know that there exist no concretization of sα which satisfies ¬a1. In the concrete model, this means that condition a1 is satisfied, and thus the choice operator won’t suspend. However, in case the above condition α(¬a1) is satisfied by sα, we cannot ensure anything. Therefore, for the case when all conditions α(¬ai) are satisfied, we must consider both possibilities: suspension and evolution.
Instantaneous choice The abstraction of this operator is similar to that of the
global choice. Let A ≡ (l)Σn  ai? →∗ (li)Ai, then

α(A) ≡ (l)if α(¬a1)? then
··· 
if α(¬an)? then
true? →∗ (l)(Σn



α(ai)? →∗ (li)α(Ai))

+
true? →∗ p
else (l)(Σn  α(ai)? →∗ (li)α(Ai))

··· 
else (l)(Σn
α(ai)? →∗ (li)α(Ai))

where procedure p is defined as p{α(A)}.

Conditional For the abstraction of the conditional operator, and in order to pre- serve the execution time of the program, the language is required to have an operation that models the instantaneous guarded choice (like →∗), i.e., a global choice operator performing the test of guards instantaneously (see the operational semantics of this operator in Figure 2). For a language which would not have such an operator, we could try to use the non–instantaneous version of the global choice; unfortunately, in order to achieve a source–to–source transformation we would need to apply a kind of time expansion similar to the one in [1] which will cause the execution of the abstract program to take more time than the intended one. The abstraction of the conditional operator is given by
α((l)if a? then (la)A else (lb)B)= (l)if α(¬a)? then
α(a)? →∗ (la)α(A)
+
true? →∗ (lb)α(B)
else (la)α(A)
The intuition behind this encoding is as follows. If we are sure that the con- dition a is satisfied by any concretization of the current abstract state, i.e., no concretization satisfies ¬a (condition α(¬a) does not hold), then we can simply execute α(A), which corresponds to the then-branch of the original action (la- beled la). However, if there exists the possibility that a was not satisfied in the concrete model, then we produce two traces by means of a choice operator. The first one can only be executed provided there exists at least the possibility that a was true in the concrete model. If this possibility does not exist, then only the second branch can be followed, executing the α(B) action which corresponds to the else-branch of the original conditional action (labeled lb).
Local declaration The abstraction of the local declaration is straightforward:
α((l)∃x¯A)= (l)∃x¯α(A)
Procedure call The abstraction of the procedure call operator is also immediate:
α((l)proc(v¯)) = (l)proc(v¯)
Finally, to complete the method, we define the abstraction of programs as fol- lows.  Given a program P of the form D[A0] and let D = {proci(x¯){Ai}|1 ≤ i ≤ n} with n declarations, then the abstract version of D is defined as α(D) = 
{proci(x¯){α(Ai)}|1 ≤ i ≤ n} whereas the abstract version of the program P is
α(P )= α(D)[α(A0)].
We aim to prove that the abstract versions of the actions given above produce abstract programs that correctly simulate the corresponding concrete ones. We need the following proposition that ensures that, whenever an operator cannot proceed in the concrete framework, the abstract version may proceed to a configuration where the stored information does not change.
Proposition 4.1 Let £ = ⟨State , test , effect ⟩ be a concrete semantic context. Given

an abstraction function α : State → State α, let Stateα be an abstract set of states, and consider the abstract semantic context £α = ⟨State α, test α, effectα⟩. Given an operator A and a state s ∈ State , if ⟨A, s⟩ /→S , then ∀sα ∈ Stateα such that s ~α sα, there exists s'α ∈ State s.t. ⟨α(A), sα⟩ →Sα ⟨α(A), s'α⟩ and s ~α s'α.
Proof. We proceed by induction on the structure of operator A. We only consider operators that may suspend. In order to simplify the presentation, we have dropped labels from the operators in configurations.
A ≡ A1; A2. By rule R-S2a, if ⟨A, s⟩ /→S then ⟨A1, s⟩ /→S. By induction hypoth- esis, we know that ⟨α(A1), sα⟩ →Sα ⟨α(A1), s'α⟩ and s ~α s'α. Now, applying rule R-S2a, we have that ⟨α(A1); α(A2), sα⟩ →Sα ⟨α(A1); α(A2), s'α⟩.
A ≡ A1||A2. By rules R-S3a and R-S3b, if ⟨A, s⟩ /→S then ⟨A1, s⟩ /→S and
⟨A2, s⟩ /→S. By induction hypothesis, we know that ⟨α(A1), sα⟩ →Sα ⟨α(A1), s'α⟩,
⟨α(A2), sα⟩ →Sα ⟨α(A2), s''α⟩, and s ~α s'α,s ~α s''α. Now, by applying rule R- S3a, we have that ⟨α(A1)||α(A2), sα⟩ →Sα ⟨α(A1)||α(A2), s'α ⊕α s''α⟩. Finally, since ⊕ is idempotent, by Proposition 3.1 we deduce that s ~α s'α ⊕α s''α.

n
i=1
(ai? → Ai). Using the semantic rules, if ⟨A, s⟩ /→S then we know that

there exist no index j, 1 ≤ j ≤ n, such that test (aj, s) holds, or equivalently,
∀1 ≤ j ≤ n, test (¬aj, s) holds. Let us consider the construction of α(aj) given in Section 4.1. Since s ~α sα, we deduce that ∀j, test (α(¬aj), sα) holds. Now, by definition we have
α(A)= (l)if α(¬a1)? then
··· 
if α(¬an)? then

true? →∗ (l)(Σn
α(ai)? → (li)α(Ai))

+
true? →∗ p
else (l)(Σn  α(ai)? → (li)α(Ai))

··· 
else (l)(Σn
α(ai)? → (li)α(Ai))

By applying rule R-S5a (n times) and rules R-S8a, and R-S7, we deduce that
⟨α(A), sα⟩ →Sα ⟨α(A), sα⟩.

n
i=1
(ai? →∗ Ai). This case is similar to the previous one.

A ≡ ∃sL A. To prove this case, we first note that sL is the local state accumulated during the computation of A, and that V is the set of local variables in A. Thus, by definition, we have that ∃V sL = ϵ. Applying rule R-S6, if ⟨∃sL A, s⟩ /→S
then ⟨A, ∃V s ⊕ sL⟩ /→S. Let sα, sα ∈ State α such that sL ~α sα and s ~α sα.
L	L
Then, by Proposition 3.1, ∃V s⊕sL ~α ∃V sα ⊕sα. Now, by applying the induction
hypothesis, we have that ⟨α(A), ∃V sα ⊕ sα⟩ →Sα ⟨α(A), s'α⟩, and ∃V s ⊕ sL ~α s'α.
L	sα
Using again rule R-S6 in the abstract set, we deduce that ⟨∃ L α(A), sα⟩ →Sα

s'α
V
α	'α

⟨∃V  α(A),s  ⊕ ∃V s  ⟩. To finish this proof, we have to demonstrate that s ~α
sα ⊕ ∃V s'α. Since ∃V s ⊕ sL ~α s'α, then we have that ∃V s ⊕ ∃V sL ~α ∃V s'α. As ∃V sL ≡ ϵ, we have that ∃V s ~α ∃V s'α. Finally, since s ≡ ∃V s ⊕ s and, by

hypothesis, s ~α sα, by Proposition 3.1 we deduce that s ~α sα ⊕ ∃V s'α, as desired.

Now we are ready to prove the following result, which ensures that the abstract versions of actions given above produce abstract programs that correctly simulate the corresponding concrete ones.
Theorem 4.2 Let P  = Decl[A0] be a synchronous program and assume that
£ = ⟨State , test , effect⟩ is a semantic context. Given an abstraction function α : State → State α, let State α be an abstract set of states, and consider the ab- stract semantic context £α = ⟨State α, test α, effectα⟩. Then the trace–based semantic 7 (£α)(α(Decl))(⟨α(A0), α(s0)⟩) is a correct ~α-simulation of 7 (£)(Decl)(⟨A0, s0⟩).
Proof. We must prove that each transition step in the concrete semantics is mimicked by a corresponding abstract transition step. More specifically, given two labeled operators (l)A and (l')B and two states s1, s2 ∈ State such that
⟨(l)A, s1⟩ →S ⟨(l')B, s2⟩ if sα ∈ Stateα is an abstraction of s1, that is, s1 ~α sα, then
1	1
there exists sα ∈ Stateα such that s2 ~α sα and ⟨(l)α(A), sα⟩ →Sα ⟨(l')α(B), sα⟩.
2	2	1	2
Note that we have defined the abstraction of actions in such a way that the set of
labels in the abstract program is the same as in the concrete one. We proceed by induction on the structure of operator A.
(l)A ≡ end, (l)A ≡ error. Both cases hold trivially.
(l)A ≡ (l)c!. By definition of ~α, to prove this case it suffices to observe that, if
s ~α sα, then ∀c ∈ Tell, effect (c, s) ~α effectα(c, sα).
(l)A ≡ (l)A1; (l2)A2. First	observe	that,	by	definition,	(l)α(A)	≡
(l)α(A1); (l2)α(A2).	Now, there are two possibilities:	(1) If ⟨(l)A1, s⟩ →S
⟨(lend)end, s1⟩ then by rule R-S2b we have that ⟨(l)A1; (l2)A2, s⟩ →S ⟨(l2)A2, s1⟩. By induction hypothesis, we know that if s ~α sα, then ⟨(l)α(A1), sα⟩ →Sα
⟨(lend)end, sα⟩ and s1 ~α  sα.	Applying rule R-S2b again, we obtain that
1	1
⟨(l)α(A1); (l2)α(A2), sα⟩ →S ⟨(l2)α(A2), sα⟩, as desired.
The second possibility (2) is when ⟨(l)A1; (l2)A2, s⟩ →S ⟨(l3)A3; (l2)A2, s'⟩ where s' is the arrival state in the transition ⟨(l)A1, s⟩ →S ⟨(l3)A3, s'⟩. The expected result is proved as in (1), but now using rule R-S2a to proceed with the concrete and abstract configurations.
(l)A ≡ (l)A1||(l2)A2. Observe again that, similarly to the previous case, by def- inition (l)α(A) ≡ (l)α(A1)||(l2)α(A2).  We consider again two cases: (1) If
⟨(l)A1, s⟩ →S ⟨(l3)A3, s1a⟩ and ⟨(l2)A2, s⟩ →S ⟨(l4)A4, s1b⟩, then by rule R- S3a ⟨(l)A1||(l2)A2, s⟩ →S ⟨(l3)A3||(l4)A4, s1⟩ with s1 = s1a ⊕ s1b. By in- duction hypothesis we know that if s ~α sα, then (i) ⟨(l)α(A1), sα⟩ →Sα
⟨(l3)α(A3), sα ⟩ and s1a ~α sα , and (ii) ⟨(l2)α(A2), sα⟩ →Sα ⟨(l4)α(A4), sα ⟩ and
1a	1a	1b
s1b ~α sα . By applying R-S3a we obtain that ⟨(l)α(A1)||(l2)α(A2), sα⟩ →Sα
⟨(l3)α(A3)||(l4)α(A4), sα ⊕α sα ⟩ as desired since, by Proposition 3.1, s1a ⊕ s1b ~α

α ⊕α sα .
1a	1b

The second possibility (2) is presented when one of the parallel operators can-

not proceed. That is, by rule R-S3b, ⟨(l)A1||(l2)A2, s⟩ →S ⟨(l3)A3||(l2)A2, s' ⊕ s⟩ with ⟨(l)A1, s⟩ →S ⟨(l3)A3, s'⟩ and ⟨(l2)A2, s⟩ /→S. By applying Proposition 4.1, we have that ⟨(l2)α(A2), sα⟩ →Sα ⟨(l2)α(A2), s''α⟩, and s ~α s''α. By in- duction hypothesis, if s ~α sα, then there exists an abstract state s'α, such that ⟨(l)α(A1), sα⟩ →Sα ⟨(l3)α(A3), s'α⟩. Now, using the rule R-S3a to pro- ceed in the abstract configuration, we obtain that ⟨(l)α(A1)||(l2)α(A2), sα⟩ →Sα
⟨(l3)α(A3)||(l2)α(A2), s'α ⊕α s''α⟩. Finally, by Proposition 3.1, s' ⊕s ~α s'α ⊕α s''α, and the desired result follows.
(l)A ≡ (l) Σn (ai? → (li)Ai). Observe that, by definition,

(l)α(A)= (l)if α(¬a1)? then
··· 
if α(¬an)? then
true? →∗ (l)(Σn



α(ai)? → (li)α(Ai))

+
true? →∗ p
else (l)(Σn  α(ai)? → (li)α(Ai))

··· 
else (l)(Σn
α(ai)? → (li)α(Ai))

By hypothesis, we can safely assume that operator A does not suspend. Then, by rule R-S4, we know that there exist a test (aj, s) that holds for some index j. Given an abstract state sα such that s ~α sα, we can deduce the two following
assertions.
By rule R-S4, ⟨(l) Σn  (ai? → (li)Ai), s⟩→ ⟨(lj )Aj, s⟩.
Consider the construction of α(a) given in Section 4.1. Since s ~α sα, then
test (aj, s) implies test (α(aj ), sα).
Now consider the configuration C ≡ ⟨(l)α(A), sα⟩. We may consider two cases. First (1), when test (α(¬ak), sα) holds for all k > 0. In this case, by rules R-S5a (applied n times), R-S8a and R-S4, and using assertion (b), we deduce that C →Sα ⟨(lj)α(Aj ), sα⟩. In the second case, assume that test (α(¬ak), sα) does not hold for some k≥1, and that test (α(¬ai), sα) holds for all i < k. Then, by rules R-S5a (applied k − 1 times), R-S5b and R-S4 we deduce C →Sα ⟨(lj)Aj, sα⟩ as desired.
(l)A ≡ (l) Σn  (ai? →∗ (li)Ai). This proof is similar to the previous one.
(l)A ≡ (l)if a? then (l1)A1 else (l2)A2. Observe that, by definition, (l)α(A)  ≡
(l)if α(¬a)? then (α(a)? →∗ (l1)α(A1)+ true? →∗ (l2)α(A2)) else (l1)α(A1).
We consider two cases: the case when the condition a holds, and the case when it doesn’t. In the first case (1), assuming that test (a, s) holds and that
⟨(l1)A1, s⟩ →S ⟨(l3)A3, s'⟩, given an abstract state sα such that s ~α sα, we may deduce the following assertions:
By rule R-S5a, ⟨(l)if a? then (l1)A1 else(l2)A2, s⟩ →S ⟨(l3)A3, s'⟩
By induction hypothesis, since s	~α	sα,  then ⟨(l1)α(A1), sα⟩	→Sα
⟨(l3)α(A3), s'α⟩ and s' ~α s'α.
Consider the construction of α(a) given in Section 4.1. Since s ~α sα, we have

that test α(a, s) implies test (α(a), sα).
Consider now configuration C ≡ ⟨(l)if α(¬a)? then (α(a)? →∗ (l1)α(A1) + true? →∗ (l2)α(A2)) else (l1)α(A1), sα⟩. We can proceed in two ways. First, if test α(α(¬a), sα) holds then, using points (b) and (c) above, and rules R-S5a and R-S8a, we may deduce that C →Sα ⟨(l3)α(A3), s'α⟩, as desired. Second, if test α(α(¬a), sα) does not hold then, using point (b) and rule R-S5b, we obtain again that C →Sα ⟨(l3)α(A3), s'α⟩.
For the second case (2), assume that test (a, s) does not hold and that
⟨(l1)A2, s⟩ →S ⟨(l3)A3, s'⟩. Given an abstract state sα such that s ~α sα, we deduce the following assertions:
By rule R-S5b, ⟨(l)if a? then (l1)A1 else(l2)A2, s⟩ →S ⟨(l3)A3, s'⟩
By induction hypothesis, since s  ~α  sα, then ⟨(l1)α(A2), sα⟩  →Sα
⟨(l3)α(A3), s'α⟩ and s' ~α s'α.
By definition of test given in Section 2.2, ¬test (a, s) is equivalent to test (¬a, s). Now, consider the construction of α(¬a) given in Section 4.1. Since s ~α sα, we have that test (¬a, s) implies test (α(¬a), sα).
Finally, if C is the configuration defined above, using rules R-S5a and R-S8a
and points (b) and (c), we have C →Sα ⟨(l3)α(A3), s'α⟩.
(l)A ≡ ∃V (l)A1. Observe that, by definition, (l)α(A) ≡ ∃V (l)α(A1). By rule R-

S6 we have that ⟨∃sL A , s⟩ → 
'
⟨∃ A ,s ⊕ ∃ s ⟩ provided ⟨A , ∃
s ⊕ s ⟩ → 

V	1	S	V	1	V
1	V	L	S

⟨A' , s'⟩, where sL is the local store; initially sL is state ϵ ∈ State , the neutral
element of operator ⊕. Given sα and sα such that s ~α sα and sL ~α sα,
by Proposition 3.1 we know that s ⊕ sL ~α sα ⊕α sα. Moreover, by definition, state ∃V s represents the state s with the information about variables V removed, and if s ~α sα, then ∃V s ~α ∃V sα.  By induction hypothesis, we have that
⟨α(A1), ∃V sα ⊕α sα⟩ →Sα ⟨α(A' ), s'α⟩ and s' ~α s'α. Now, by rule R-S6 again,
sα L	1 'α
we have that ⟨∃ L A1, sα⟩ →α ⟨∃s α(A1), sα ⊕α ∃V s'α⟩. Then, by applying again
V	S	V
Proposition 3.1 we have that s ⊕ ∃V s' ~α sα ⊕α ∃V s'α as desired.
A ≡ proc(v¯). The proof of this case is trivial.

Conditions to the source–to–source transformation
A popular approach to implement abstraction is based on using source–to–source transformations. This approach is very convenient since it makes possible to reuse existing analysis and verification tools and techniques for the programming language at hand.
An important advantage of the framework presented so far is that it allows us to analyze the conditions which ensure that a given language can be abstracted by means of a source–to–source transformation. Actually, if the programming language does not provide an instantaneous choice action, then no source–to–source trans- formation can be given which preserves the timing of programs. This allows us to overcome one of the main problems found in [1], where the execution of the abstract program generally needs more time than the concrete one.

Program abstraction implies a lack of precision. In particular, when a condition is checked in the concrete program, it may occur that the abstract version answers both positively and negatively. Therefore, since we are not sure about the condition satisfaction, both behaviors (when the condition holds and when it does not) must be considered. To this end, the non–determinism is used: a choice between the two runs is defined. In general this means than, in the presence of the conditional operator or, whenever some kind of check is done in the original source language, a suitable non–deterministic operator must be used in the abstract version.
Moreover, since the check action and the body of the conditionals run in the same time instant, the non–deterministic operator must be able to execute the check and the body of the conditional operator also at the same time instant. This is why we need an instantaneous choice operator to abstract programming languages which have a conditional operator.
Note that, even if the source–to–source transformation was not possible, it may still be interesting to abstract a particular programming language to perform some kind of analysis or verification. The only drawback is that we won’t be able to reuse the analysis or verification tools that may exist for the original language.

Concluding remarks
Abstract model checking is becoming one of the most promising approaches to im- prove the automatic verification of large systems. In this paper, we have defined a generic framework for applying abstract verification and analysis methods including model checking techniques to concurrent languages with maximum parallelism and a synchronous semantics for communication. When abstracting the language, the (abstract) primitives as well as the language constructs have a different intended semantics with respect to the original language. As a consequence, the resulting approximation is required to satisfy some correctness properties in order to safely support accurate program analysis and verification.
Powerful tools for automated analysis and verification of properties, for instance model–checking tools, have been defined for different concurrent languages. As a way to get the benefits provided by these tools when abstract interpretation techniques are applied, an interesting possibility is to implement the model abstraction as a source–to–source transformation, which would allow us to reuse existing these tools. Following this approach, a translation scheme has been proposed that interprets the abstract actions into the original language. Moreover, a characterization of the conditions on the source language ensuring that the abstraction can be defined as a source–to–source transformation has also been provided.
We have applied the transformation methodology both in an imperative and a declarative context: a generalized semantics of Promela for abstract model check- ing was defined in [8], whereas in [1] an abstract semantics was defined for the timed concurrent constraint programming language tccp.
As future work we plan to extend our abstraction technique to the asynchronous model of concurrency.

References
M. Alpuente, M. M. Gallardo, E. Pimentel, and A. Villanueva. A semantic framework for the abstract model checking of tccp programs. Theoretical Computer Science, 346(1):58–95, 2005.
A. Benveniste, P. Caspi, S. Edwards, N. Halbwachs, P. Le Guernic, and R. de Simone. The synchronous languages twelve years later. Proceedings of the IEEE, 91:64–83, 2003.
G. Berry and G. Gonthier. The esterel synchronous programming language: Design, semantics, implementation. Science of Computer Programming, 19(2):87–152, 1992.
F. S. de Boer, M. Gabbrielli, and M. C. Meo. A Timed Concurrent Constraint Language. Information and Computation, 161:45–83, 2000.
P. Caspi, D. Pilaud, N. Halbwachs, and J. Place. Lustre: a declarative language for programming synchronous systems. In ACM Symposium on Principles of Programming Languages (POPL ’87), 1987.
M. Codish, M. Falaschi, K. Marriot, and W. Winsborough. A Confluent Semantic Basis for the Analysis of Concurrent Constraint Logic Programs. Journal of Logic Programming, 30(1):53–81, 1997.
S. A. Edwards, N. Halbwachs, R. v. Hanxleden, and T. Stauner, editors. Synchronous Programming
- SYNCHRON’04. Number 04491 in Dagstuhl Seminar Proceedings. Internationales Begegnungs- und Forschungszentrum fuer Informatik (IBFI), Schloss Dagstuhl, Germany, 2005.
M. M. Gallardo, P. Merino, and E. Pimentel. A generalized semantics of promela for abstract model checking. Formal Aspects of Computing, 16(3):166–193, 2004.
P. L. Guernic, T. Gautier, M. L. Borgne, , and C. de Marie. Programming real-time applications with SIGNAL. Proceedings of the IEEE, 79(9):1321–1335, September 1991.
David Harel. Statecharts: A visual formalism for complex systems. Science of Computer Programming, 8(3):231–274, June 1987.
F. Maraninchi. The argos language: Graphical representation of automata and description of reactive systems, 1991.
G. Plotkin. A structured approach to operational semantics. Technical Report DAIMI FN-19, Computer Science Department, Aarhus University, 1981.
V. Saraswat, R. Jagadeesan, and V. Gupta. Foundations of timed concurrent constraint programming, 1994.
V. A. Saraswat, R. Jagadeesan, and V. Gupta. Foundations of Timed Concurrent Constraint Programming. In Proc. 9th Annual IEEE Symposium on Logic in Computer Science, pages 71–80, New York, 1994. IEEE.
E. Zaffanella, R. Giacobazzi, and G. Levi. Abstracting Synchronization in Concurrent Constraint Programming. Journal of Functional and Logic Programming, 1997(6), November 1997.
