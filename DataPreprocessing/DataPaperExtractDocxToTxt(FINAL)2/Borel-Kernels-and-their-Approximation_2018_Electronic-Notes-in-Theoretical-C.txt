Available online at www.sciencedirect.com


Electronic Notes in Theoretical Computer Science 341 (2018) 91–119
www.elsevier.com/locate/entcs

Borel Kernels and their Approximation, Categorically
Fredrik Dahlqvist1,2 Alexandra Silva2
Department of Computer Science University College London
Vincent Danos	Ilias Garnier3
CNRS, ENS-PSL, INRIA	ENS-PSL

Abstract
This paper introduces a categorical framework to study the exact and approximate semantics of probabilistic programs. We construct a dagger symmetric monoidal category of Borel kernels where the dagger-structure is given by Bayesian inversion. We show functorial bridges between this category and categories of Banach lattices which formalize the move from kernel-based semantics to predicate transformer (backward) or state transformer (forward) semantics. These bridges are related by natural transformations, and we show in
particular that the Radon-Nikodym and Riesz representation theorems - two pillars of probability theory - define natural transformations.
With the mathematical infrastructure in place, we present a generic and endogenous approach to approxi- mating kernels on standard Borel spaces which exploits the involutive structure of our category of kernels. The approximation can be formulated in several equivalent ways by using the functorial bridges and natural transformations described above. Finally, we show that for sensible discretization schemes, every Borel ker- nel can be approximated by kernels on finite spaces, and that these approximations converge for a natural choice of topology.
We illustrate the theory by showing that our approximation scheme can be used in practice as an ap- proximate Bayesian inference algorithm and as an approximation scheme for programs in the probabilistic network specification language ProbNetKAT.
Keywords: Probabilistic programming, probabilistic semantics, Markov process, Bayesian inference, approximation


Introduction
Finding a good category in which to study probabilistic programs is a subject of active research [22,17,6,21]. In this paper we present a dagger symmetric monoidal

1 Email: f.dahlqvist@ucl.ac.uk
2 This work was partially supported by ERC grant ProfoundNet.
3 This work was partially supported by ANR project REPAS.

https://doi.org/10.1016/j.entcs.2018.11.006
1571-0661/© 2018 The Author(s). Published by Elsevier B.V.
This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).

category of kernels whose dagger-structure is given by Bayesian inversion. The advantages of this new category are two-fold.
Firstly, the most important new construct introduced by probabilistic program- ming, viz. Bayesian inversion, is interpreted completely straightforwardly by the
†-operation which is native to our category. In particular we never leave the world of kernels and we therefore do not require any normalization construct. Consider for example the following simple Bayesian inference problem in Anglican ([24])
( defquery  example 
( let  [x ( sample  ( normal  0  1))]
( observe  ( normal  x  1)  0.5)
( > x  1)))
The semantics of this program is built easily and compositionally (by functoriality of †) in our category:
The second line builds a Borel space equipped with a normally distributed prob- ability measure – an object (R, μ) of our category.
The (normal x 1) instruction builds a Borel kernel – a morphism f : (R, μ) →
(R, ν) in our category.
The observe statement builds the Bayesian inverse of the kernel – the morphism
f† : (R, ν) → (R, μ) in our †-category.
Finally, the kernel f† is evaluated, i.e. the denotation of the program above is f†(0.5)(]1, ∞[). Since f† is only defined μ-a.s., we understand the formal ex- pression f†(0.5)(]1, ∞[) as the evaluation of some representative of f† at (0.5) and (]1, ∞[). The choice of representative is μ-a.s. irrelevant, which justifies the notation. Note also that Anglican cleanly separates the modelling process from the inference process. The snippet of code above belongs to the modelling level, whereas the choice of a representative of f† – that is to say of an inference al- gorithm – belongs to the inference level, which is specified separately. We only claim to provide a semantics at the modelling level.
Secondly, since Bayesian inference problems are in general very hard to compute (although the one given above has an analytical solution), it makes sense to seek approximate solutions, i.e. approximate denotations to probabilistic programs. As we will show, our category of kernels comes equipped with a generic and endogenous approximating scheme which relies on its involutive structure and on the structure of standard Borel spaces. Moreover, this approximation scheme converges for any choice of kernel for a natural choice of topology.

Main contributions and structure of the paper.
Sections 2-6 align in a chain of logical dependencies culminating in our Con- vergence of Approximations Theorem (Theorem 6.3) which relies on the framework developed in §2, the link with operators developed in §3-4 which allows us to access a natural operator topology, and the presentation of our approximation scheme in
§5. More precisely, our main contributions can be summed up section by section as

follows:
We build a category Krn of Borel kernels (§2) and we show how two kernels which agree almost everywhere can be identified under a categorical quotient operation. This technical construction is what allows us to define Bayesian inversion as an involutive functor, denoted †. This is a key technical improvement on [6] where the †-structure 4 was hinted at but was not functorial. We show that Krn is a dagger symmetric monoidal category.
We introduce the category BLσ of Banach lattices and σ-order continuous positive operators as well as the K¨othe dual functor (−)σ : BLop → BLσ (§3). These will play a central role in studying convergence of our approximation schemes.
We provide the first 5 categorical understanding of the Radon-Nikodym and the Riesz representation theorems. These arise as natural transformations between functors relating kernels and Banach lattices (§4).
We show how the †-structure of Krn can be exploited to approximate kernels by averaging (§5). Due to an important structural feature of Krn (Th. 2.1) every kernel in Krn can be approximated by ﬁnite kernels.
We describe a natural class of approximations schemes where the sequence of approximating kernels converges to the kernel to be approximated. The notion of convergence is given naturally by moving to BLσ and considering convergence in the Strong Operator Topology (§6).
We show how Bayesian inference can be performed approximately by showing that the †-operation commutes with taking approximations. This provides the basis for an approximate Bayesian inference algorithm which we apply to a simple Anglican program. A second application, as an approximation scheme for the denotation of ProbNetKAT programs [13,20] is given in the Appendix.
All the proofs can be found in the Appendix.

Related work.
Quasi-Borel sets have recently been proposed as a semantic framework for higher- order probabilistic programs in [22]. The main differences with our approach are: (i) unlike [22,21] we never leave the realm of kernels, and in particular we never need to worry about normalization. This makes the interpretation of observe statements,
i.e. of Bayesian inversion, simpler and more natural. However, (ii) unlike the quasi- Borel sets of [22], our category is not Cartesian closed. We can therefore not give a semantics to all higher-order programs. This shortcoming is partly mitigated by the fact that the category of Polish spaces, on which our category ultimately rests, does have access to many function spaces, in particular all the spaces of functions whose domain is locally compact. We can thus in principle provide a semantics to higher-order programs, provided that λ-abstraction is restricted to locally compact

4 Suggested to us by Chris Heunen.
5 To the best of our knowledge.

spaces like the reals and the integers, although this won’t be investigated in this paper.
The approximation of probabilistic kernels has been a topic of investigation in theoretical computer science for nearly twenty years (see e.g. [10,8,9,4]), and for much longer in the mathematical literature (e.g. [5]). Our results build on the formalism developed in [4] with the following differences: (i) we can approximate kernels, their associated stochastic operator (backward predicate transformer), or their associated Markov operator (forward state transformer) with equivalent ease, and move freely across the three formalisms. (ii) Given a kernel f : X d Y , we can define its approximation fj : Xj → Y j along any quotients Xj of X and Y j of Y as in [4], but we can also ‘internalize’ the approximation as a kernel f∗ : X → Y of the original type. Morally fj and f∗ are the same approximation, but the second approximant, being of the same type as the original kernel, can be compared with it. In particular it becomes possible to study the convergence of ever finer approximations, which we do in Section 6. Finally, (iii) we opt to work with Banach lattices rather than the normed cones of [18,4] because it allows us to formulate the operator side of the theory very naturally, and it connects to a large body of classic mathematical results ([2,25]) which have been used in the semantics of probabilistic programs as far back as Kozen’s seminal [16].
A category of Borel kernels
In [6] the first three authors presented a category of Borel kernels similar in spirit to the construction of this section, but with a major shortcoming. As we will shortly see, our category Krn of Borel kernels can be equipped with an involutive functor – a dagger operation † in the terminology of [19] – which captures the notion of Bayesian inversion and is absolutely crucial to everything that follows. In [6] this operation had merely been identified as a map, i.e. not even as a functor. In this section we show that Bayesian inversion defines a †-structure on a more sophisticated – but measure-theoretically very natural – category of kernels.
Standard Borel spaces and the Giry monad
A standard Borel space – or SB space for short – is a measurable space (X, S) for which there exists a Polish topology T on X whose Borel sets are the elements of S, i.e. such that S = σ(T ) (see e.g. [15] for an overview). Let us write SB for the category of standard Borel spaces and measurable maps. One key structural feature of SB is the following:
Theorem 2.1 Every SB object is a limit of a countable co-directed diagram of ﬁnite spaces.
Proof. This is a consequence of the Isomorphism Theorem (Theorem 15.6 of [15]): two SB spaces are isomorphic iff they have the same cardinality. Uncountable SB spaces are thus all isomorphic to the Cantor space 2N which is the limit of the countable co-directed diagram (2n)n∈N with the connecting morphisms pn+1,n :

2n+1 → 2n truncating binary words of length n +1 at length n. Similarly all SB-spaces of cardinality ℵ0 are isomorphic to the one-point compactification of N, which is the limit of the countable co-directed diagram (n)n∈N with the connecting morphisms pn+1,n : n+1 → n, i '→ min(i, n). The case of finite SB spaces is trivial.2
The Giry monad was originally defined in two variants [14]:
As an endofunctor GPol of Pol, the category of Polish spaces, one sets GPol(X, T ) to be the space of Borel probability measures over X together with the weak topology. This space is Polish [15, Th 17.23], and the Portmanteau Theorem [15, Th 17.20]) gives multiple characterizations of the weak topology.
As an endofunctor GMeas of Meas, the category of measurable spaces: GMeas(X, S) is the set of probability measures on X together with the initial σ-algebra for the maps evA : GMeas(X, S) → R,μ '→ μ(A),A ∈ S.
In both cases the Giry monad is defined on an arrow f : X → Y as the map f∗ which sends a measure μ on X to the pushforward measure f∗μ on Y , defined as G(f )(μ)(B)= f∗μ(B) := μ(f−1(B)) for B a measurable subset of Y . We want to define the Giry monad on the category SB of standard Borel spaces (and measurable maps), and the two versions of the Giry monad described above offer us natural ways to do this: given an SB space (X, σ(T )) we can either compute GPol(X, T ) and take the associated standard Borel space, or directly compute GMeas(X, σ(T )). Fortunately, the two methods agree.
Theorem 2.2 ([15], Th 17.24) Let B : Pol → SB denote the functor sending a Polish space (X, T ) to its associated SB-space (X, σ(T )) and leaving morphisms unchanged, then
GMeas ◦ B = B ◦ GPol.
We define the Giry monad on SB spaces to be the endofunctor G : SB → SB defined by either of the two equivalent constructions above. The monadic data of G is given at each SB space X by the unit δX : X → GX, x '→ δx, the Dirac δ measure at x, and the multiplication mX : G2X → GX, P '→ λA. GX evAdP. We refer the reader to [14] for proofs that δX and mX are measurable.

The construction of Krn
Let us denote by SBG the Kleisli category associated with the Giry monad (G, δ, m). We denote Kleisli arrows, i.e. Markov kernels, by X d Y , and we call such an arrow deterministic if it can be factorized as an ordinary measurable function followed by the unit δ. Kleisli composition is denoted by •. The category ∗↓ SBG has arrows
∗ d X as objects, where ∗ is the one point SB space (the terminal object in SB). An arrow from μ : ∗ d X to ν : ∗ d Y is a SBG arrow f : X d Y such that ν = f • μ, i.e. such that ν(A) = X f (x)(A)dμ for any measurable subset A of Y . This situation will be denoted in short by f : (X, μ) d (Y, ν), and we will call a pair (X, μ) a measured SB space.
We construct a quotient of ∗↓ SBG, such that two ∗↓ SBG arrows are identified

if they disagree on a null set w.r.t. the measure on their domain. For g, gj : (X, μ) d
(Y, ν), we define N (g, gj)= {x ∈ X | g(x) /= gj(x)}.


Lemma 2.3 N (g, gj) is a measurable set.


Proof. By Dinkyn’s π-λ theorem, two finite measures are equal if and only if they agree on a π-system generating the σ-algebra. Any standard Borel space admits such a countable π-system (any countable basis for a Polish topology generating the σ-algebra). Let {Bn}n∈N be such a π-system. Then, for all x ∈ X, g(x) /= gj(x) ⇔
∃n.g(x)(Bn) /= gj(x)(Bn). Hence,


N (g, gj) = ∪n{x ∈ X | g(x)(Bn) /= gj(x)(Bn)}
= ∪n{x ∈ X | evB (g(x)) /= evB (gj(x))}
= ∪n(evB ◦ g − evB ◦ gj)—1(R \ {0})



By definition of the measurable structure of G(Y ), evBn
g −evBn
gj is measurable,

hence N (g, gj) is also measurable.	2



We now define a relation ∼ on Hom((X, μ), (Y, ν)) by saying that for any two arrows g, gj : (X, μ) d (Y, ν), g ∼ gj if μ(N (g, gj)) = 0.  This clearly defines an equivalence relation on Hom((X, μ), (Y, ν)). In order to perform the quotient of the category ∗ ↓ SBG modulo ∼, we need to check that it is compatible with composition.


Proposition 2.4 If g ∼ gj, then h • g • f ∼ h • gj • f.


Proof. We first show that if g ∼ gj, then h• g ∼ h• gj. Clearly, for any space V and any deterministic function u : Y → V , N (u◦g, u◦gj) ⊆ N (g, gj). By definition of the Kleisli category, h• g = mZ ◦ G(h) ◦g and similarly for h• gj. Taking u = mZ ◦ G(h), we obtain that μ(N (h • g, h • gj)) ≤ μ(N (g, gj)).
It is now enough to show that λ(N (g • f, gj • f )) = 0. Let us reason contraposi-

tively. We have:

λ(N (g • f, gj • f ))	> 0
⇔	∫w∈W 1N (g•f,g′•f )(w) dλ	> 0


→En	∫	1
′	dλ	> 0

→	∫w∈W |(g • f )(w)(Bn) − (gj • f )(w)(Bn)| dλ > 0
⇔	∫w∈W ∫x∈X |g(x)(Bn) − gj(x)(Bn)| df (w) dλ > 0
⇔	∫x∈X |g(x)(Bn) − gj(x)(Bn)| dμ	> 0

EX+⊆X
→
x∈X+ g(x)(Bn) − gj(x)(Bn) dμ	> 0

→	∫x∈X+ 1g(—)(Bn)>g′(—)(Bn)(x) dμ	> 0
→	∫x∈X+ 1N (g,g′)(x) dμ	> 0
The last line implies μ(N (g, gj)) > 0, a contradiction.	2
Definition 2.5 Let Krn be the category obtained by quotienting ∗ ↓ SBG hom- sets with ∼.
The following Theorem is of great practical use and generalizes the well-known result for deterministic arrows.
Theorem 2.6 (Change of Variables in Krn) Let f : (X, μ) d (Y, ν) be a Krn-morphism. For any measurable function φ : Y → R, if φ is ν-integrable, then φ • f (x)= Y φ df (x) is μ-integrable and

φ dν =
Y	X
φ • f dμ

Proof. If φ is ν-integrable, there exists a monotone sequence {φn} of simple functions such that φn ↑ φ and	Y φndν  →	Y φdν < ∞.	By definition each

1Bi dν = ν(Bi)=	f (x)(Bi)dμ =	1Bi df (x)dμ =	(1Bi • f )dμ
Y	X	X  Y	X
From which it follows that


φndν =
Y
∫X ∫Y

Σi=0

αi1Bi df (x)dμ =

(φn • f )dμ
X

and the result follows from the Monotone Convergence Theorem (MCT).	2

The symmetric monoidal structure of Krn
The symmetric monoidal structure of Krn is defined on a pair of objects (X, μ), (Y, ν) by the Cartesian product and the product of measures, i.e. (X, μ) ⊗ (Y, ν) = (X × Y, μ ⊗ ν).  On pairs of morphisms f : (X, μ) d (Y, ν) and fj : (Xj, μj) d (Y j, νj) it is defined by (f ⊗ fj)(x, xj) := f (x) ⊗ fj(xj). The un- itors, associator and braiding transformations are given by the obvious bijections.
The dagger structure of Krn
Krn has an extremely powerful inversion principle:
Theorem 2.7 (Measure Disintegration Theorem, [15], 17.35) Let
f : (X, μ) d (Y, ν) be a deterministic Krn-morphism, there exists a unique morphism f† : (Y, ν) d (X, μ) such that
f • f† = id(Y,ν).	(1)
The kernel f† is called the disintegration of μ along f . As our notation suggests, the disintegration depends fundamentally on the measure μ over the domain, how- ever we will omit this subscript when there is no ambiguity. The following lemma relates disintegrations to conditional expectations.
Lemma 2.8 ([7]) Let f : (X, μ) → (Y, ν) be a deterministic Krn-morphism, let
σ(f ) be the σ-algebra generated by f, and let φ : X → R be measurable, then μ-a.e.
φ • f† • f = E [φ | σ(f )]
We can extend the definition of (−)† to any Krn-morphism f : (X, μ) d (Y, ν) in a functorial way, although f† will not in general be a right inverse to f . The construction of f† is detailed in [6], but let us briefly recall how it works. The category SB has products which are built in the same way as in Meas via the product of σ-algebras 6 . Given any kernel f : (X, μ) d (Y, ν), we can canonically construct a probability measure γf on the product X × Y of SB-space by defining it on the rectangles of X × Y as
γf (A × B)=	1A(x) · f (x)(B) dμ.	(2)
x∈X

Equivalently, γf = (δX ⊗ f ) • ΔX • μ, where ΔX : X → X × X is the diagonal map. Letting πX : X × Y → X and πY : X × Y → Y be the canonical projections, we observe that GπX (γf ) = μ and GπY (γf ) = ν: in other words, γf is a coupling of

μ and ν. The disintegration of γf along πY is a kernel π†
: (Y, ν) → (X × Y, γf ).

Finally we define:
f† = πX • π† .	(3)



6 Unlike the category Krn, which does not have products.

The following Krn diagram sums up the situation:


f
π†	s z,

πY	ss zz,_

(X, μ), X (X × Y, γ,f ) π†
(Y, ν)

,ss _πX	s	Y
f†


where π†
is explicitly given by (δX ⊗ f ) • ΔX . The following property characterizes

the action of (−)† on Krn-morphisms:
Theorem 2.9 For all f : (X, μ) d (Y, ν), f† : (Y, ν) d (X, μ) is the unique Krn
morphism satisfying for all measurable sets A ⊆ X, B ⊆ Y the following equation:
1A(x) · f (x)(B) dμ =	f†(y)(A) · 1B(y) dν	(4)
x∈X	y∈Y

Proof. It follows by definition of f† and from the disintegration theorem that
f†(y)(A) · 1B(y) dν = γf (A × B),	(5)
y∈Y
from which Eq. 4 follows easily. It remains to prove that this uniquely characterizes f†. Let us reason contrapositively. Assume there exists g : (Y, ν) d (X, μ) verifying for all A, B measurable y∈Y g(y)(A) · 1B(y)= γf (A × B) as in Eq. 5 and such that ν(N (f†, g)) > 0 (assuming we take some representative of f†). Let {An}n∈N be a countable π-system generating the σ-algebra of X. It is enough to test equality of measures on X on this π-system. Therefore, N (f†, g) = ∪n{y | f†(y)(An) /= g(y)(An)}. Since ν(N (f†, g)) > 0, there must exist a k ∈ N such that ν({y |
f†(y)(Ak) /= g(y)(Ak)}) > 0. Therefore, N + = {y | f†(y)(Ak) > g(y)(Ak)} must

also have positive measure for ν. But then,
k
g(y)(A ) · 1	(y) /= γ (A × N +),
y∈Y	Nk	k

a contradiction.	2
In view of Eq. (4), we will call f† the Bayesian inversion of f , and refer to (−)† as the Bayesian inversion operation on Krn. It will be crucial throughout the rest of this paper. It is important to see that f† absolutely depends on the choice of μ and not only on f seen as a function. We can now improve on [6] and show that (−)† is indeed a †-operation in the strict categorical meaning of the term.
Theorem 2.10 Krn is a dagger symmetric monoidal category, with (−)† given by Bayesian inversion.
Proof. Let us first show that (−)† is a functor Krn → Krnop, i.e. that id†	=
id(X,μ) and that for any f : (X, μ) d (Y, ν) and g : (Y, ν) d (Z, ρ) we have (g • f )† = f† ◦ g†.
Let (X, μ) be an object of Krn and idX,μ the corresponding identity. By Th. 2.9, it is enough to prove, for all A, Aj measurable subsets of X, that
∫x∈X 1A(x) · idX,μ(x)(Aj) dμ = ∫x∈X idX,μ(x)(A) · 1A′ (x) dμ.

We have:


1A(x) · idX,μ(x)(Aj) dμ =	1A(x) · 1A′ dμ = μ(A ∩ Aj)
x∈X	x∈X

The same calculation on the right hand side of the first equation yields trivially the same result. Hence the equality is verified.
Now, on to compatibility w.r.t. composition. In sight of Th. 2.9, it is enough to show that for all A ⊆ X, C ⊆ Z,

(g • f )(x)(C) · 1A(x) dμ =	1C(z) · (f† • g†)(z)(A) dρ
x∈X	z∈Z

In the following, for X a measurable space, we denote by SF (X) the set of simple functions over X (finite linear combinations of indicator functions of measurable sets). We will use repeatedly the monotone convergence theorem (MCT). The left hand side of the above equation can be re-written as:



(1)
=
(2) ∫

x∈X
y∈Y limn→∞ gn(y) df (x)
 ∫
· 1A(x) dμ



where (1) is because gn ↑ g(−)(C), gn ∈ SF (Y ) and (2) by monotone convergence. Note that the n-indexed family x '→ y∈Y gn(y) df (x) is pointwise increasing. There- fore,

(1)	∫	 Σkn	n	n 

= limn→∞ Σkn
αn ∫


x∈X
f (x)(Cn) · 1A(x) dμ

(2)	Σkn	n ∫	n	†

= limn→∞
(∗) ∫
i=1 αi
†
y∈Y 1Ci (y) · f
(y)(A) dν

=
(3) ∫
y∈Y g(y)(C) · f (y)(A) dν

(∗)	Σkn	n ∫	n
(2)	Σkn	n ∫	†	n
= limn ∫	1C(z) · ∫	Σkn  βn1Dn (y) dg†(z) dρ

(∗) ∫
z∈Z
∫
y∈Y
†
i=1 i	i
†

=	z∈Z 1C(z) · (f† • g†)(z)(A) dρ
where (∗) is by monotone convergence, (1) is because gn ∈ SF (Y ), (2) is by Th. 2.9 and (3) is because fn ↑ f†(−)(A), fn ∈ SF (Y ). We have proved the sought identity.

Finally let us show that (−)† is involutive, i.e. that for any f : (X, μ) d (Y, ν), (f†)† = f . This follows easily by two applications of Th. 2.9): we have
∫x∈X 1A(x) · (f†)†(x)(B) dμ = ∫y∈Y f†(y)(A) · 1B(y) dν
= ∫x∈X 1A(x) · f (x)(B) dμ;
and since adjoints are unique, f = (f†)†.
The fact that (f ⊗g)† = f† ⊗g† follows immediately from the definitions and the property of disintegrations given by Th. 2.9. The fact that the associator, unitors and braiding transformations are unitary follows immediately from the fact that they are deterministic isomorphisms and Th. 2.7.	2

Banach lattices
It is well-known that kernels can alternatively be seen as predicate – i.e. real- valued function –transformers, or as state – i.e. probability measure – transformers. The latter perspective was adopted by Kozen in [16] to describe the denotational semantics of probabilistic programs (without conditioning). We shall see in this section and the next, that the predicate and state transformer perspectives are dual to one another in the category of Banach lattices, a framework incidentally also used in [16]. For an introduction to the theory of Banach lattices we refer the reader to
e.g. [2,25].
An ordered real vector space V is a real vector space together with a partial order ≤ which is compatible with the linear structure in the sense that for all u, v, w ∈ V, λ ∈ R+
u ≤ v ⇒ u + w≤v + w	and	u ≤ v ⇒ λu ≤ λv

An ordered vector space (V, ≤) is called a Riesz space if the poset structure forms a lattice. A vector v in a Riesz space (V, ≤) is called positive if 0 ≤ v, and its absolute value |v| is defined as |v| = v ∨ (−v). A Riesz space (V, ≤) is σ-order complete if every non-empty countable subset of V which is order bounded has a supremum.
A normed Riesz space is a Riesz space (V, ≤) equipped with a lattice norm, i.e. a map · : V → R such that:
|v|≤ |w| implies  v  ≤ w  .	(6)
A normed Riesz space is called a Banach lattice if it is (norm-) complete, i.e. if every Cauchy sequence (for the norm ·) has a limit in V .
Example 3.1 For each measured space (X, μ) – and in particular Krn-objects – and each 1 ≤ p ≤ ∞, the space Lp(X, μ) is a Riesz space with the pointwise order. When it is equipped with the usual Lp-norm, it is a Banach lattice. This fact is often referred to as the Riesz-Fischer theorem (see [2, Th 13.5]). We will say that

p, q ∈ N ∪ {∞} are H¨older conjugate if either of the following conditions hold: (i) 1 < p, q < ∞ and 1 + 1 = 1, or (ii) p = 1 and q = ∞, or (iii) p = ∞ and q = 1.
p	q
Theorem 3.2 (Lemma 16.1 and Theorem 16.2 of [25]) Every Banach lattice is σ-order complete.
There are two very natural modes of ‘convergence’ in a Banach lattice: order convergence and norm convergence. The latter is well-known, the former less so. An order bounded sequence {vn}n∈N in a σ-complete Riesz space (e.g. a Banach lattice) converges in order to v if either of the following equivalent conditions holds:

v = lim inf vn := 


vm,	v = lim sup vn := 
		

vm.



For a monotone increasing sequence vn, this definition simplifies to v =  n vn, which is often written vn ↑ v.
In a general σ-complete Riesz space, order and norm convergence are disjoint concepts, i.e. neither implies the other (see [25, Ex. 15.2] for two counter-examples). However if a sequence converges both in order and in norm then the limits are the same (see [25, Th. 15.4]). Moreover, for monotone sequences norm convergence implies order convergence:
Proposition 3.3 ([25] Theorem 15.3) If {vn}n∈N is an increasing sequence in a normed Riesz space and if vn converges to v in norm (notation vn → v), then vn ↑ v.
In a Banach lattice we have the following stronger property.
Proposition 3.4 (Lemma 16.1 and Theorem 16.2 of [25]) If {vn}n∈N is a sequence of positive vectors in a Banach lattice such that supn  vn  converges, then
n vn exists and   n vn  =  n  vn  .
It can also happen that order convergence implies norm convergence. A lattice norm on a Riesz space is called σ-order continuous if vn ↓ 0 (vn is a decreasing sequence whose infimum is 0) implies vn  ↓ 0.
Example 3.5 For 1 ≤ p < ∞, the Lp-norm is σ-order continuous, and thus order convergence and norm convergence coincide. However, for p = ∞ this is not the case as the following simple example shows. Consider the sequence of essentially bounded functions vn = 1[n,+∞[: it is decreasing for the order on L∞(R, λ) with the constant function 0 as its infimum, i.e. vn ↓ 0. However vn  =1 for all n.
Many types of morphisms between Banach lattices are considered in the liter- ature but most are at least linear and positive, that is to say they send positive vectors to positive vectors. From now on, we will assume that all morphisms are positive (linear) operators. Other than that, we will only mention two additional properties, corresponding to the two modes of convergence which we have examined. The first notion is very well-known: a linear operator T : V → W between normed

vector spaces is called norm-bounded if there exists C ∈ R such that Tv  ≤ C v 
for every v ∈ V . The following result is familiar:
Theorem 3.6 An operator T : V → W between normed vector spaces is norm- bounded iff it is continuous.
Thus norm-bounded operators preserve norm-convergence. The corresponding order-convergence concept is defined as follows: an operator T : V → W between σ-order complete Riesz spaces is said to be σ-order continuous if whenever vn ↑ v, Tv = T vn. It follows that we can consider two types of dual spaces on a Banach lattice V : on the one hand we can consider the norm-dual :
V ∗ = {f : V → R | f is norm-continuous} and the σ-order-dual :
V σ = {f : V → R | f is σ-order continuous}
The latter is sometimes known as the K¨othe dual of V (see [11,25]). The two types of duals coincide for a large class of Banach spaces of interest to us.
Theorem 3.7 If a Banach lattice V admits a strictly positive linear functional and has a σ-order-continuous norm, then V ∗ = V σ.
Example 3.8 The result above can directly be applied to our running example: given a measured space (X, μ) and an integer 1 ≤ p < ∞, the Lebesgue integral provides a strictly positive functional on Lp(X, μ), and we already know from Ex- ample 3.5 that Lp(X, μ) has a σ-order-continuous norm. It follows that
Lp(X, μ)∗ = Lp(X, μ)σ
Moreover, it is well-known that if (p, q) are H¨older conjugate and 1 < p, q < ∞, then Lp(X, μ)∗ = Lq(X, μ), and thus Lp(X, μ)σ = Lq(X, μ). It is also known that L1(X, μ)∗ = L∞(X, μ), and thus L1(X, μ)σ = L∞(X, μ).
However Theorem 3.7 does not hold for L∞(X, μ) since the L∞-norm is not σ- order continuous, as was shown in Example 3.5. It is well-known that L∞(X, μ)∗ /= L1(X, μ), and in fact L∞(X, μ)∗ can be concretely described as the Banach lattice ba(X, μ) of charges (i.e. finitely additive finite signed measures) which are absolutely continuous w.r.t, μ on X (see [12, IV.8.16]). However, as is shown in e.g. [25,4]
L∞(X, μ)σ = L1(X, μ)	(7)
As Examples 3.5 and 3.8 show, the (−)σ operation brings a lot of symmetry to the relationship between Lp-spaces since Lp(X, μ)σ = Lq(X, μ) for any H¨older conjugate pair 1 ≤ p ≤ ∞. For this reason we will consider the category BLσ whose objects are Banach lattices and whose morphisms are σ-order continuous positive operators. Note that the K¨othe dual of a Banach lattice is a Banach lattice, and it easily follows that (−)σ in fact defines a contravariant functor BLop → BLσ which

acts on morphisms by pre-composition. As we will now see, BLσ is the category in which predicate and state transformers are most naturally defined.
From Borel kernels to Banach lattices
The aim of this section is two-fold. First, we establish functorial bridges between Borel kernels (i.e. Krn) and operators on Banach lattices (i.e. BLσ). This will allow us to describe the convergence of a sequence of approximating kernels in terms of operator topology in §6. Second, we show that the functors between Krn and BLσ also provide an interesting structural insight into some of the most important results in classical probability theory, in particular we show that the Radon-Nikodym and Riesz representation theorems can be described as natural transformations.
The functors Sp and Tp.
For 1 ≤ p ≤ ∞, the operation which associates to a Krn-object (X, μ) the space Lp(X, μ) can be thought of as either a contravariant or a covariant functor. We define the functors Sp : Krn → BLop, 1 ≤ p ≤ ∞ as expected on objects, and on Krn-morphisms f : X d Y via the well-known ‘predicate transformer’ perspective:
Sp(f ): Lp(Y, ν) → Lp(X, μ),φ '→ λx.	φ df (x)= φ • f
Y
This defines a functor (see [6]). We define the covariant functors Tp : Krn →
BLσ, 1 ≤ p ≤∞ as Tp = Sp ◦ (−)†.
The functor M ·.
An ideal of a Riesz space V is a sub-vector space U ⊆ V with the property that if |u|≤ |v| and v ∈ U then u ∈ U . An ideal U is called a band when for every subset D ⊆ U if  D exists in V , then it also belongs to U . Every band in a Banach lattice is itself a Banach lattice. Of particular importance is the band Bv generated by a singleton {v}, which can be described explicitly as
Bv = {w ∈ V | (|w|∧ n |v|) ↑ |w|}
Example 4.1 Let X be an SB-space and ca(X) denote the set of measures of bounded variation on X. It can be shown ([2, Th 10.56]) that ca(X) is a Banach lattice. The linear structure on ca(X) is as expected, the Riesz space structure is given by
(μ ∨ ν)(A)= sup{μ(B)+ ν(A \ B) | B measurable ,B ⊆ A}
and the dual definition for the meet operation. The norm is given by the total variation i.e.


μ  = sup
 Σn


|μ(Ai)| {A1,..., An} a meas. partition of X

Given μ ∈ ca(X), the band Bμ generated by μ is just the set of measures of bounded variation which are absolutely continuous w.r.t. μ. In particular Bμ is a Banach lattice.
We can now define the functor M · : Krn → BLσ by:
M ·(X, μ) := Bμ
M ·f : M ·(X, μ) → M ·(Y, ν),ρ '→ f • ρ
We will usually write M ·(X, μ) as M μ(X).
Proposition 4.2 Let f : (X, μ) d (Y, ν) be a Krn arrow. Let ρ be a ﬁnite measure on X such that ρ  μ. Then f • ρ  ν, and thus M · deﬁnes a functor.
Proof. Let B ⊆ Y be a measurable set. By definition, we have (f • ρ)(B) =
X evB ◦ f dρ where we recall that evB : G(X) → R+ is the evaluation morphism.
Let {f B}n∈N be an increasing chain of simple functions converging pointwise to
evB ◦ f such that for each n, f B = Σkn  αn1An with αn ≥ 0. By the MCT,
n	i=1 i	i	i
∫	kn
	


Similarly,

ν(B)= (f • μ)(B)= lim ∫
kn
f B dμ = lim

αnμ(An).

n	X  n
n		i	i i=1

Notice that since the integral is linear and the sequence {f B}n is increasing, the
sequences {∫X f B dρ}n and {∫X f B dμ}n are also increasing. Assume ν(B) = 0.
Then for all n, X f B dμ = 0. We deduce that for all n, for all 1 ≤ i ≤ kn, either
αn =0 or μ(An) = 0. Using that ρ  μ, we deduce that for all 1 ≤ i ≤ kn, either
i	i	∫


Radon-Nikodym is natural.
We now present a first pair of natural transformations which will establish a natural isomorphism between the functors T1 and M ·. First, we define the Radon- Nikodym transformation rn : M · → T1 at each Krn-object (X, μ) by the map


rn(X,μ)
: M  μ(X) → L1(X, μ),	rn

(X,μ)
dρ
(ρ)= 
dμ

where dρ/dμ is of course the Radon-Nikodym derivative of ρ w.r.t. μ. The fact that this transformation defines a positive operator between Banach lattices is simply a restatement of the usual Radon-Nikodym theorem [12, III.10.7.], combined with the well-known linearity property of the Radon-Nikodym derivative. To see that it is also σ-order-continuous, consider a monotone sequence μn ↑ μ converging in order

to μ in M ν(X). This means that for any measurable set A of X, limn→∞ μn(A)= μ(A). Since (dμn/dν)n∈N is bounded in L1-norm the function g = n dμn/dν exists and is simply the pointwise limit g(x) = limn→∞ dμn/dν(x). It now follows from the monotone convergence theorem (MCT) that

∫ gdν =∫


lim
dμn dν = lim ∫
dμn dν = lim μ

(A) = μ(A)

in other words, g = dμ/dν and rn is well-defined. That rn is also natural has – to our knowledge – never been published.
Theorem 4.3 The Radon-Nikodym transformation is natural.
Proof. We start by proving the following Lemma
Lemma 4.4 For any f : (X, μ) d (Y, ν), φ ∈ L1(Y, ν), and BX ⊆ X measurable
∫	 ∫ φdf (x)  dμ = ∫ φ(y)f†(y)(BX ) dν
Proof. We start by showing the equation on characteristic functions. If BY is measurable in Y , we have

∫BX
 ∫Y

1BY df (x)	dμ =	f (x)(BY ) dμ
BX

=	1BY
Y
(y)f†(y)(BX ) dν	Eq. (4)

Since φ is measurable and integrable, there exists a sequence φn ↑ φ of simple functions such that limn Y φn dν < ∞, and the results follows by the linearity of integration and the MCT.	2
We can now prove the naturality of rn. Let f : (X, μ) d (Y, ν) bea Krn-morphism; we have on the one hand

rn(Y,μ) ◦ M ·(f )(ρ)(y)= rn(Y,ν)(
X
f (x)(−) dρ)(y)

and on the other
T1(f†) ◦ rn(X,μ)
= d X f (x)(−)dρ (y)	(∗)
dν


(ρ)(y)= T (f†)  dρ  (y)
dρ
=	df (y)	(∗∗)

X dμ
To show the equality of these two maps in L1(Y, ν) it is enough to show that they are equal ν-a.e. To see this, we show that (∗∗) satisfies the condition to be the

Radon-Nikodym derivative (∗). Let BY be a measurable subset of Y . We have from the well-known property of Radon-Nikodym derivatives:

∫BY
d X f (x)(−) dρdν =
dν	x∈X

f (x)(BY

) dρ



Moreover, we have
∫BY


dρ
df
X dμ



(1)
(y) dν =
(2)
=




x∈X


x∈X


dρ
dμ (x)f (x)(BY ) dμ
f (x)(B) dρ

where (1) is by Lemma 4.4 and (2) is a well-known property of Radon-Nikodym derivatives.	2
Secondly, we define the Measure Representation transformation mr : T1 → M ·
at each Krn-object (X, μ) by the map mr(X,μ) : T1(X, μ) → M	(X, μ) defined as

mr(X,μ)(f )(BX )=	fdμ
BX

This is a very well-known construction in measure theory, and the fact that mr(X,μ) is a σ-order continuous operator between Banach lattices is immediate from the linearity of integrals and the MCT.
Theorem 4.5 The Measure Representation transformation is natural.
Proof. We start with the following elementary lemma.
Lemma 4.6 If ψ, φ ∈ L1(X, μ) then

ψφ dμ =	ψ d(mr(M,μ)φ)
X	X

Proof. The proof of naturality now follows easily: it is enough to show the equality in the case where ψ = 1BX for a measurable subset BX of X, and the result then extends to all measurable functions by linearity of integrals and the MCT. We have


1BX φ dμ =
BX

φdμ := mr(M,μ)(φ)(BX )

=	1BX  d(mr(M,μ)(φ))
X
2
To show naturality we now let f : (X, μ) d (Y, ν) bea Krn-morphism, φ ∈ L1(X, μ)

and BY measurable in Y
mr(Y,ν)T1(f†)(φ)(BX  )
= mr(Y,ν)(φ • f†)(BY )
=	φ • f† dν
BY
=	φdf †(y) dν
BY	X
=	f (x)(BY )φ(x) dμ	Lemma 4.4
X
=	f (x)(BY ) d( d(mr(X,μ)(φ))	Lemma 4.6
X
= M ·f ◦ mr(X,μ)(φ)(BY )
2

Riesz representations are natural.
We now present a second pair of natural transformations which will establish a natural isomorphism between (−)σ ◦ S∞ and M ·. First, we define the Riesz Representation transformation rr : (−)σ ◦ S∞ → M · at each Krn-object (X, μ) by the map rr(X,μ) : (−)σ ◦ S∞(X, μ) → M ·(X, μ) defined as
rr(X,μ)(F )(BX )= F (1BX )
This construction is key to a whole collection of results in functional analysis commonly known as Riesz Representation Theorems (see [2] Chapter 14 for an overview). One can readily check that the Riesz Representation transformation is well-defined: rr(X,μ)(F )(∅) = F (0) = 0 and the σ-additivity of rr(X,μ)(F ) fol- lows from the σ-order-continuity of F . To see that rr(X,μ)(F )  μ, assume that μ(BX ) = 0, then clearly 1BX  = 0 μ-a.e., i.e. 1BX  = 0 in L∞(X, μ), and thus F (1BX )= 0.
Theorem 4.7 The Riesz Representation transformation is natural.
Proof. Again, we start with a simple but helpful Lemma.
Lemma 4.8 Let F ∈ (S∞(X, μ)σ and φ ∈ S∞(X, μ), then
F (φ)= ∫X φ d(rr(X,μ)(F ))
Proof. Starting with characteristic functions, let φ = 1B for some measurable subset B of X. We then have
F (1B) := rr(X,μ)(F )(B)= ∫X 1B d(rr(X,μ)(F ))

We can then extend the result to simple functions by linearity and to all functions in L∞(X, μ) by the MCT.	2
To show naturality we now let f : (X, μ) d (Y, ν) be a Krn-morphism, F ∈
(S∞(X, μ))σ and BY measurable in Y . We have
M ·f ◦ rr(X,μ)(F )(BY )=	f (x)(BY ) d(rr(X,μ)(F ))
X
= F (f (·)(BY ))	Lemma 4.8

= F (
X
1BY df (·))

= F (1BY • f )
= rr(Y,ν)(F (−• f ))(BY )
= rr(Y,ν) ◦ (T1f )σ(F )(BY )
2
Finally, we define the Functional Representation transformation fr at each Krn- object (X, μ) by the map fr(X,μ) : M ·(X, μ) → (−)σ ◦ S∞(X, μ) by
fr(X,μ)(μ)(φ)=	φdμ
X
This construction is also completely standard in measure theory, although it has never to our knowledge been seen as a natural transformation.
Theorem 4.9 The Functional Representation transformation is well-deﬁned, i.e.
fr(X,μ) is a σ-order continuous positive operator, and is natural.
Proof. We start by showing that fr is well defined. The linearity of fr(X,μ) is easily checked on simple functions and extended by the CMT. Positivity is also immediate. For the σ-order continuity, let μm ↑ μ, φ ∈ L∞(X, μ), and φn ↑ φ be a monotone approximation of φ by simple functions. We need to show that

lim
X

φ dμm =
X

φ dμ

For note first that the doubly indexed series X φndμm is monotonically increasing in m, since the μm are monotonically increasing. Note also that the differences
dmn :=	φn dμm+1 −	φn dμm
X	X
are monotonically increasing in n. Indeed we have

 ∫X

φn+1 dμm+1 −
X
φn+1 dμm  − ∫

φndμm+1 −
X

φn dμm 

=	(φn+1 − φn) dμm+1 −
X	X
(φn+1 − φn) dμm > 0

since the sequences φn and μm are monotonically increasing. Since dmn is monoton- ically increasing in n we can apply the CMT to dmn seen as a function of m w.r.t. the counting measure, i.e.



lim
n→∞
m
∞
dmn =
m

lim
n→∞


dmn

which is to say, by taking partial sums
Σ	∫

n→∞ m→∞
k=1
n→∞ m→∞ X m

= lim
m→∞
kΣ=1
lim
n→∞
dkn

= lim lim ∫

φn dμm

m→∞ n→∞  X
which concludes the proof that fr is well-defined.
We now prove naturality. Let f : (X, μ) d (Y, ν) be a Krn-morphism, ρ ∈ M  μ(X) and φ ∈ S∞(Y, ν) we then have

fr(Y,ν) ◦ M ·f (ρ)(φ)= ∫

=
Y

φ d(M ·f (ρ)(φ))
(φ • f ) dρ	Theorem 2.6

= S∞(f ) ∫ (−) dρ (φ)
= S∞(f ) ◦ fr(X,μ)(ρ)(φ)
2

Natural Isomorphisms
We have now defined the following four natural transformations:

T  mr  zM  ·   fr  z(S  )σ
1 ¸crn	¸crr	∞
In fact, both pairs form natural isomorphisms which can be restricted to arbitrary H¨older conjugate pairs (p, q).
Theorem 4.10 rn and mr are inverse of one another, in particular there exists a
natural isomorphism between M  μ(X) and L1(X, μ).
Proof. The fact that rn(X,μ) and mr(X,μ) are inverse of each other is just a restate- ment of the two well-known equalities for Radon-Nikodym derivatives:


d — φ dμ = φ and		dρ dμ	BX  dμ
dμ = ρ(BX )

2
Theorem 4.11 rr and fr are inverse of each other, in particular there exists a
natural isomorphism between M  μ(X) and (L∞(X, μ))σ.
Proof. Let (X, μ) be a Krn-object, let F ∈ (L∞(X, μ))σ and let φ ∈ L∞(X, μ). We have
fr(X,μ) ◦ rr(X,μ)(F )(φ)=	φ d(rr(X,μ)(F )) = F (φ)
X
where the last equality follows from Lemma 4.8. Similarly, we have
rr(X,μ) ◦ fr(X,μ)(ρ)(BX )= fr(X,μ)(ρ)(1BX ) =	1BX dρ = ρ(BX )
X
2
We can now conclude that the isomorphism proved in Theorem 6 of [6] is in fact natural.
Corollary 4.12 There exists a natural isomorphism between T1 := S1 ◦ (−)† and
(−)σ ◦ S∞.
We can in fact restrict this result to any H¨older conjugate pair (p, q):
Theorem 4.13 For 1 ≤ p ≤∞ with H¨older conjugate q, the natural transformation
rn ◦ rr restricts to a natural transformation (−)σ ◦ Sq → Tp.
Proof. The case p = 1 has been treated already, for the case of 1 < p < ∞, see for example the proof of Theorem 4.4.1 of [3]. Finally for the case of p = ∞, see Proposition 3.3 of [4].	2
The correspondence between the various categories and functors discussed in this section are summarized by

(—)σ
M
(8)

BLop ¸c fr	 ¸c mr	 Krnop

σ ,¸
rr	z	rn	z ,

S∞	(—)†
Krn
Approximations
In this section we develop a scheme for approximating kernels which follows nat- urally from the †-structure of Krn. Consider f : (X, μ) d (Y, ν) and a pair of

deterministic maps p : (X, μ) → (Xj, p∗μ) and q : (Y, ν) → (Y j, q∗ν) (typically these maps coarsen the spaces X and Y ).


(X, μ,)¸
f	 z 
p,q	 (zY , ν,) ¸	(9)


†	†
μ	ν

cjιz
	 zcjιz

(X , p∗μ)
fp,q
(Y , q∗ν)

The †-structure of Krn allows us to define the new kernels
fp,q := q† • q • f • p† • p	: X d Y	(10)

ν	μ
fp,q := q • f • p†
: Xj d Y j	(11)

The supscript notation is meant to indicate that the approximation lives ‘upstairs’ in Diagram (9) and conversely for the subscripts. Intuitively, fp,q and fp,q take the average of f over the fibres given by p, q according to μ and ν (see §7 for concrete calculations). The advantage of (11) is that we can approximate a kernel on a huge space by a kernel on a, say, finite one. The advantage of (10) is that although it is more complicated, it is morally equivalent and has the same type as f , which means that we can compare it to f .
A very simple consequence of our definition is that Bayesian inversion commutes with approximations. We shall use this in §7 to perform approximate Bayesian inference.
Theorem 5.1 Let f : (X, μ) d (Y, ν), let p : X → Xj and q : Y → Y jn be a pair of deterministic maps, then
(f†)q,p = (fp,q)† and (f†)q,p = (fp,q)†

In practice we will often consider endo-kernels f : X d X with a single coars- ening map p : X → Xj to a ﬁnite space. In this case (10) simplifies greatly.
Proposition 5.2 Under the situation described above
fp := p† • p • f • p† • p = f • p† • p	(12)
ν	μ	μ

In the case covered by Proposition 5.2, the interpretation of fp is very natural: for each x ∈ X the measure f (x) is approximated by its average over the fibre to which x belongs, conditioned on being in the fibre. For fibres with strictly positive μ-probability, this is simply
fp(x)(A)=  y∈p−1(p(x)) f (y)(A) dμ
μ(p—1(p(x))

However (12) also covers the case of μ-null fibres. Note also that in the case where fp = f , the map p corresponds to what is known as a strong functional bisimulation for f .
Approximating is non-expansive.
It is well-known that conditional expectations are non-expansive and we know from Lemma 2.8 that pre-composing by p† • p as in (12) amounts to conditioning. The following lemma is an easy consequence.
Lemma 5.3 Let f : (X, μ) d (Y, ν) and q : X → Xj be a deterministic quotient, then for all 1 ≤ p ≤∞ and φ ∈ Lp(Y, ν)
 Spfq(φ)   ≤ Spf (φ) 
Compositionality of approximations.
In the case where we wish to approximate a composite kernel g • f , it might be convenient, for modularity reasons, to approximate f and g separately. This does not entail any loss of information provided the quotient maps are hemi- bisimulations, in the following sense. Let p : X → Xj,q : Y → Y j,r : Z → Zj be deterministic quotients and let f : (X, μ) d (Y, ν),g : (Y, ν) d (Z, ρ) be com- posable kernels. We say that q is a left hemi-bisimulation for f if f = q† • q • f , and conversely that it is a right hemi-bisimulation for g if g = g • q† • q holds. In either case, one can verify using Theorems 2.7 and 5.1 that approximation commutes with composition, i.e. that (g • f )p,r = gq,r • fp,q.
Discretization schemes.
We will use (11) and (12) to build sequences of arbitrarily good approximations of kernels. For this we introduce the following terminology.
Definition 5.4 We define a discretization scheme for an SB-space X to be a count- able co-directed diagram (ccd) of finite spaces for which X is a cone (not necessarily a limit).
If (Xi)i∈I is a discretization scheme of X and pi : X → Xi are the maps making X a cone, then it follows from the definition that if i < j, σ(pi) ⊆ σ(pj) where σ(pi) is the σ-algebra generated by pi. For each i ∈ I the finite quotient pi defines a measurable partition of X whose disjoint components p—1({k}),k ∈ Xi we will call cells. By Theorem 2.1 every SB-space has a discretization scheme for which it is not just a cone but a limit. In practice we will work with discretization schemes linearly ordered by N. In this case the sequence (X, σ(pn))n∈N defines what probabilists call a ﬁltration and we will denote the approximation fpn given by (12) simply by fn.
Convergence
We now turn to the question of convergence of approximations. There appears to be little literature on the subject of the convergence of approximations of Markov

kernels. One rare reference is [5]. Via the functor Sp defined above in Sections 3 and 4 we can seek a topology in terms of the operators associated to a sequence of kernels. Indeed, following [5], we will prove convergence results for the Strong Operator Topology (SOT).
Definition 6.1 We will say that a sequence of kernels fn : X d Y converges to f : X d Y in strong operator topology, and write fn−→sf , if S1fn converges to S1f in the strong operator topology, i.e. if


lim
n→∞
 S1fn(φ) − S1f (φ)  1 =0 

Proving convergence.
The following key lemma is a consequence of L´evy’s upward convergence Theo- rem ([23, Th. 14.2]) .
Lemma 6.2 Let f : (X, μ) d (Y, ν) be a Krn-morphism and let pn : X → Xn,n ∈
N be a discretization scheme such that for BX the Borel σ-algebra of X we have
BX = σ ( n σ(pn)), and let A ⊆ Y be measurable, then for fn := f • p • pn
†


lim
n→∞
fn(x)(A)= f (x)(A)

for μ-almost every x ∈ X. Moreover,


lim
n→∞
 S1fn(1A) − S1f (1A)  1 =0 

Proof. The map f (−)(A): X → R defines a random variable, and the discretiza- tion scheme defines a filtration σ(pn) ⊆ σ(pn+1) whose union is BX . Following Lemma 2.8 and Proposition 5.2 we have
fn(x)(A) := f (x)(A) • p† • pn = E [f (x)(A) | σ(pn)]
We thus have a sequence fn(−)(A) of random variables X → R which is adapted to the filtration σ(pn),n ∈ N by construction. We can now compute for any m < n 
E [fn(x)(A) | σ(pm)]
=f (x)(A) • p† • pn • p† • pm
n	m
(1)	†	†
= f (x)(A) • pn • pn • (pnm • pn) • pm

(2)
†	†	†

= f (x)(A) • pn • pn • pn • pnm • pm
(3)	†	m

= f (x)(A) • pm • pm = f
(x)(A)

where (1) is by definition (5.4), (2) is by Thm (2.10) and (3) is by Theorem (2.7). We have thus shown that fn(−)(A) is a martingale for the filtration generated by the discretization scheme, and the result now follows from L´evy’s upward convergence Theorem ([23, Th. 14.2]) since f (x)(A)= E [f (x)(A) | σ (  n σ(pn))].	2

Theorem 6.3 (Convergence of Approximations Theorem) Under the con- ditions of Lemma 6.2, for μ-almost every x ∈ X


lim
n→∞
fn(x)(A)= f (x)(A)

for all Borel subsets A. Moreover,


lim
n→∞
 S1fn(φ) − S1f (φ)  1 =0 

for any φ ∈ L1(X, ν). In other words fn−→sf.
Proof. Let (Bn)n∈N be a countable basis for the Borel σ-algebra of X, which we assume w.l.o.g. is closed under finite unions and intersections. It follows from Lemma 6.2 that for each Bn, limk fk(x)(Bn)= f (x)(Bn) for all x ∈ X \ Nn where μ(Nn) = 0. It follows that for every x ∈ X \ i Ni
lim fk(x)(Bn)= f (x)(Bn)
k→∞

for all basic Borel sets Bn, and μ( i Ni) = 0. Now we use the π − λ-lemma with (Bn)n∈N as our π-system. We define
L := {C | fn(x)(C) → f (x)(C) for all x ∈ X \ ∪iNi}
and show that it is a λ-system. Clearly each Bn ∈ L. Suppose C ∈ L, it is then immediate that Cc ∈ L. Now consider a sequence Ci ∈ L with Ci ⊆ Ci+1, and let

C∞ := ∪∞
Ci. We want to show that
lim fn(x)(C∞)= lim lim fn(x)(Cm) n	n	m
(∗)	n

= lim lim f (x)(Cm)
m	n
= lim f (x)(Cm)
m
= f (x)(C∞)
where (∗) is the only step we need to justify. To show the iterated limits can be switched, note first that since
|fn(x)(Cm) − f (x)(C∞)| = |fn(x)(Cm) − f (x)(Cm)+ f (x)(Cm) − f (x)(C∞)|
≤ |fn(x)(Cm) − f (x)(Cm)| + |f (x)(Cm) − f (x)(C∞)|
since the two terms converge separately, for any ϵ > 0 we can find N > 0 s. th. for all m, n ≥ N , |fn(x)(Cm) − f (x)(C∞)| < є/2 + є/2 = ϵ. Thus lim(m,n)→∞ fn(x)(Cm)= f (x)(C∞).
Now note also that for all m0 ∈ N the sequence fn(x)(Cm0 ) converges to f (x)(Cm0 ) (by definition of L), and it is not hard to see that f (x)(Cm) converges to f (x)(C∞). Conversely for all n0 ∈ N, the sequence fn0 (x)(Cm) converges to

fn0 (C∞) (by virtue of fn0 (x) being a measure). For є/2 > 0 we can find N > 0 such that for all m, n > N , |fn(x)(Cm) − f (x)(C∞)| < є/2. We can also find M > 0 such that for all m > M , |fn(x)(Cm) − fn(x)(C∞)| < є/2. By taking the maximum of N and M it is clear that for all m, n above this maximum
|fn(x)(C∞) − f (x)(C∞)|
≤ |fn(x)(C∞) − fn(x)(Cm)| + |fn(x)(Cm) − f (x)(C∞)| < ϵ 
We have thus shown that


lim  lim
fn(x)(Cm) =	lim	fn(x)(Cm)

m→∞ n→∞
(m,n)→∞
= f (x)(C∞) = lim
lim
fn(x)(Cm).

n→∞ m→∞
Thus L is a λ-system, and it follows from the π − λ-lemma that σ((Bn)n∈N) ⊆ L 
which concludes the proof of pointwise almost everywhere convergence.
For the proof of L1-convergence we start by showing that


lim
n→∞
 Spfn(1A) − Sp(1A) 
= 0	(13)

for any Borel subset A. For this we use exactly the same reasoning as above. The only difference is that we need to check that


lim
X
|fn(x)(C∞) − f (x)(C∞)| dμ =0 

For this we use the fact that we have just shown fn(x)(C∞) → f (x)(C∞) pointwise almost everywhere, and that |fn(x)(C∞) − f (x)(C∞)| ≤ 1 with 1 μ-integrable. It follows by dominated convergence that
lim	|fn(x)(C∞) − f (x)(C∞)| dμ
X
= ∫	lim |fn(x)(C∞) − f (x)(C∞)| dμ =0 
X n→∞
which concludes the proof of (13). To extend the result to simple functions and then to arbitrary functions φ ∈ L1(X, ν) is routine.	2
Note that operators of the shape Spfn obtained from a discretization scheme are ﬁnite rank operators. Thus, we, in fact, also obtained a theorem to approximate stochastic operators by stochastic operators of ﬁnite rank for the SOT topology. In general, we cannot hope for convergence in the stronger norm topology since the identity operator – which is stochastic – is a limit of operators of finite rank in the norm topology iff the space is finite dimensional.
Note also that the various relationships established in Section 4 allow us to move from an approximation of a kernel to an approximation of the corresponding Markov operator. Since a discretization scheme making fn−→sf will also make


 	
Fig. 1. Log-likelihood of f 5,3	Fig. 2. Log-likelihood of f 6,10	Fig. 3. Approximate posteriors
(f†)n−→sf†, it follows from Theorem 4.10 that we get a finite rank approximation of the Markov operator M ·(f ).
Application: Approximate Bayesian Inference
Consider again the inference problem from the introduction. There one needed to invert f (x) = N (x, 1) with prior μ = N (0, 1). We can use Theorem 5.1 to see how our approximate Bayesian inverse compares to the exact solution which in this simple case is known to be f†(0.5) = N (1/4, 1/2). To do this, we use a doubly indexed discretization scheme:
qmn : R → 2 × m × n +2 
defining a window of width 2m centred at 0 divided in 2mn equal intervals; with the remaining intervals (−∞, −m] and (m, ∞) each sent to a point (hence the +2 above).
Since all classes induced by qmn have positive μ-mass, approximants can be computed simply as:
fm,n([k])([l]) = μ[k]—1	N (x, 1)([l]) dμ
x∈[k]
where [k], [l] range over classes of qmn. The corresponding stochastic matrices are shown in Fig. 1 and 2 for m, n = 5, 3 and 6, 10 respectively.
Since these approximants are finite, their Bayesian inverse can be computed directly by Bayes theorem (i.e. taking the adjoint of the stochastic matrices):


fm,n†
([l])([k]) =
μ[k] · fm,n([k])([l])


ν[l]
(14)

with ν = f∗(μ). Commutation of inversion and approximation guarantees that the
fm,n† converge to f†.
Indeed, Fig. 3 shows the the Lebesgue density of fm,n†(0.5) for m, n = 3, 2 (in dashed blue) and 7, 5 (dashed red). The latter approximant is already hardly distinguishable from the exact solution (solid black).
It must be emphasized that this example is meant only as an illustration and does not constitute a universal solution to the irreducibly hard (not even computable

in general [1]) problem of performing Bayesian inversion. Also, not all quotients are equally convenient: what makes the approach computationally tractable is that the fibres are easily described and the measure conveniently evaluated on such fibres.
Conclusion
We have presented a framework for the exact and approximate semantics of first- order probabilistic programming. The semantics can be read off either in terms of kernels between measured spaces, or in terms of operators between Lp spaces. Either forms come with related involutive structures: Bayesian inversion for (mea- sured) kernels between Standard Borel spaces, and K¨othe duality for positive linear and σ-continuous operators between Banach lattices. Functorial relations between both forms can themselves be related by way of natural isomorphisms. Our main result is the convergence of general systems of finite approximants in terms of the strong operator topology (the SOT theorem). Thus, in principle, one can com- pute arbitrarily good approximations of the semantics of a probabilistic program of interest for any given (measurable) query. Future work may allow one to derive stronger notions of convergences given additional Lipschitz control on kernels, or to develop approximation schemes that are adapted to the measured kernel of in- terest. More ambitiously perhaps, one could investigate whether MCMC sampling schemes commonly used to perform approximate Bayesian inference in the context of probabilistic programming could be seen as randomized approximations of the type considered in this paper.

References
N. L. Ackerman, C. E. Freer, and D. M. Roy. Noncomputable conditional distributions. In LICS 2011, pages 107–116, 2011.
C. Aliprantis and K. Border. Infinite dimensional analysis, volume 32006. Springer, 1999.
V. I. Bogachev. Measure Theory I. Springer, 2006.
P. Chaput, V. Danos, P. Panangaden, and G. Plotkin. Approximating Markov Processes by averaging.
Journal of the ACM, 61(1), January 2014.
K. Choo-Whan. Approximation theorems for Markov operators. Probability Theory and Related Fields, 21(3):207–214, 1972.
F. Clerc, V. Danos, F. Dahlqvist, and I. Garnier. Pointless learning. In FoSSaCS, pages 355–369. Springer, 2017.
F. Dahlqvist, V. Danos, I. Garnier, and O. Kammar. Bayesian Inversion by Omega-Complete Cone Duality (Invited Paper). In CONCUR 2016, volume 59 of LIPIcs, pages 1:1–1:15. Schloss Dagstuhl, 2016.
V. Danos, J. Desharnais, and P. Panangaden. Conditional expectation and the approximation of labelled Markov processes. In International Conference on Concurrency Theory, pages 477–491. Springer, 2003.
J. Desharnais, V. Gupta, R. Jagadeesan, and P. Panangaden. Metrics for labelled Markov processes.
TCS, 318(3):323–354, 2004.
J. Desharnais, R. Jagadeesan, V. Gupta, and P. Panangaden. Approximating labeled Markov processes. In LiCS 2000, pages 95–106. IEEE, 2000.

J. Dieudonn´e. Sur les espaces de Ko¨the. Jour. dAnalyse Math., 1(1):81–115, 1951.
N. Dunford, J. T. Schwartz, W. G Bade, and R. G. Bartle. Linear operators I. Wiley-interscience New York, 1971.
N. Foster, D. Kozen, K. Mamouras, M. Reitblatt, and A. Silva. Probabilistic netkat. In ESOP 2016, pages 282–309. Springer, 2016.
M. Giry. A categorical approach to probability theory. In Categorical Aspects of Topology and Analysis, number 915 in Lecture Notes In Math., pages 68–85. Springer-Verlag, 1981.
A. S. Kechris. Classical descriptive set theory, volume 156 of Graduate Text in Mathematics. Springer, 1995.
D. Kozen. Semantics of probabilistic programs. Journal of computer and system sciences, 22(3):328– 350, 1981.
D. Kozen. Kolmogorov extension, martingale convergence, and compositionality of processes. In LiCS 2016, pages 692–699, 2016.
P. Selinger. Towards a semantics for higher-order quantum computation. In Proceedings of the 2nd International Workshop on Quantum Programming Languages, TUCS General Publication, volume 33, pages 127–143, 2004.
P. Selinger. Dagger compact closed categories and completely positive maps. Electronic Notes in Theoretical computer science, 170:139–163, 2007.
S. Smolka, P. Kumar, N. Foster, D. Kozen, and A. Silva. Cantor meets Scott: Domain-theoretic foundations for probabilistic network programming. In POPL 2017, 2017.
S. Staton. Commutative semantics for probabilistic programming. In European Symposium on Programming, pages 855–879. Springer, 2017.
S. Staton, H. Yang, F. Wood, C. Heunen, and O. Kammar. Semantics for probabilistic programming: higher-order functions, continuous distributions, and soft constraints. In LICS, 2016, pages 525–534, 2016.
D. Williams. Probability with martingales. Cambridge University Press, 1991.
F. Wood, Jan W. van de Meent, and V. Mansinghka. A new approach to probabilistic programming inference. In International conference on Artificial Intelligence and Statistics, pages 1024–1032, 2014.
A. C. Zaanen. Introduction to operator theory in Riesz spaces. Springer, 2012.
