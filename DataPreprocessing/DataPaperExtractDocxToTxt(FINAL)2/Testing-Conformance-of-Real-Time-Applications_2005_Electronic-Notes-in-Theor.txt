Electronic Notes in Theoretical Computer Science 113 (2005) 23–43  
www.elsevier.com/locate/entcs


Testing Conformance of Real-Time Applications by Automatic Generation of Observers
Saddek Bensalem, Marius Bozga, Moez Krichen, Stavros Tripakis
Verimag
Centre Equation, 2, avenue de Vignate, 38610 Gi`eres, France

Abstract
We propose a new methodology for automated testing of real-time applications in general and robotic applications in particular. The starting point is a high-level specification which can be automatically translated into a network of timed automata. Analog or digital-clock observers are then generated from the timed automata specification. The system under test (SUT) is instru- mented to export observable events and corresponding time-stamps. The traces generated by the SUT are fed to the observer (on-the-fly or off-line). The latter checks whether each trace conforms to the specification. The approach has been applied to the K9 Martian Rover executive of NASA.
Keywords: Testing, Timed automata, Planning, Martian Rover

Introduction
Computer-aided verification of programs has been studied for decades by the formal method research community. Different models and specification lan- guages have been proposed to describe systems and express desired proper- ties about them in a precise way. The expressivity and the applicability of such models to various domains has been studied. It has been realized quite early, however, that the approach suffers from two fundamental problems of in- tractability. First, undecidability, because of Turing-machine expressiveness of many infinite-state models. Second, intractability because of state-explosion, that is, prohibitively large state spaces to be explored. A large effort then con- centrated in tackling these problems, resulting in a number of significant ad- vances. Powerful theorem-proving techniques, (semi-)automatic abstractions,


1571-0661 © 2004 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2004.01.036


symbolic representations of state space, on-the-fly algorithms, compositional and assume-guarantee methods, etc. Despite these, intractability remains a major obstacle to the applicability of formal verification.
Another major obstacle is the fact that for a number of systems, a formal model simply does not exist and is too difficult or costly to build.
A complementary or alternative approach widely used in the industry to- day is testing. Testing is less ambitious than verification, in the sense that it only aims at finding bugs, and not at proving correctness. Indeed, most test methods are not complete (i.e., the system cannot be guaranteed to be correct even if it passes all tests). Nevertheless, confidence in the correctness of the system increases as the number of successful tests increases [27]. This feature of testing is particularly appealing to the industry, because it allows engineers to decide how much effort to put in validation, in contrast to an “all-or-nothing” verification approach.
Moreover, testing does not require a model of the system under test (SUT). Most testing methods are “black box”, in the sense that the only knowledge about the SUT is its interface to the outside world (set of inputs and outputs). A model of the specification is necessary for automated test generation, how- ever, this model is usually finite state and much smaller than a model of the SUT. This, and the feature above, makes testing tractable.
In this paper, we propose a new methodology of dynamic testing for real- time applications. It is dynamic in the sense that it makes use of instrumenta- tion of the SUT and of run-time verification technology. The class of systems we are targetting includes all systems where a specification exists and can be translated into (or given directly as) a network of timed automata (TA) [2]. Many instances of such systems can be found in the domain of robotics. There, a plan defines the steps to be performed to achieve a mission, and also gives detailed information about order, timing, etc., of these steps. The plan is fed as an input to an execution platform (the term includes software, middleware and hardware) which must implement it, by performing the specified steps in the specified timing and order. Thus, the plan can be taken to be the specification and the platform executing this plan to be the SUT.
Our methodology is illustrated in Figure 1 and is described in detail in Section 2. Let us briefly summarize it here. The starting point is a plan, which is taken to be a high-level specification. This plan is automatically translated into a TA model. From the latter an observer is automatically synthesized. The observer is also a testing device, that is, it checks whether a sequence of observations (with time-stamps) conforms to the specification. The execution platform is instrumented, so that it can be interfaced with the observer. This interface must essentially export observable events and time-


stamps for these events. The final step is the testing itself. It can be done: (1) either on-the-fly, by running the plan on the instrumented execution platform and feeding the observations to the observer; (2) or off-line, by generating a set of “log-traces” from the execution platform, then feeding these traces to the observer one by one.
The main advantage of our method is that it is potentially fully-automatic. Plans can be automatically translated into networks of TA [1]. Observers for TA can be generated automatically, as we show here. For the case study reported in this paper, we relied on the help of Klaus Havelund and Rich Washington at NASA, for the instrumentation of the execution platform and the generation of the traces. However, it should be possible to automate this part as well, in the general case, by identifying a mapping between platform events and specification events, and automatically scanning the code, adding event/time-stamp exporting commands to the identified platform events. Fi- nally, the observation/testing process is automatic as well.
The rest of the paper is organized as follows. Section 2 presents the methodology in detail. Section 3 gives a short review of the model of timed automata. Section 4 describes plans and their translation to networks of TA. Section 5 shows how observers can be generated automatically from TA. Sec- tion 6 discusses the application of our method on the K9 Rover case study. Section 7 contains conclusions and plans for future work.

Related work
[4] report work very much related to ours. Their scheme is also based on the instrumentation of the SUT and the runtime analysis of the instrumented SUT using an observer. The starting point of their method is a test-input generator, which generates inputs to the instrumented SUT. These inputs are also fed to a property generator, which generates properties that the SUT must satisfy on these particular inputs. The properties and the execution traces are fed to an observer, which checks whether the former are satisfied by the latter. The test-input generator and the property generator are specifically written for the application to be tested, while the instrumentation package and the observer are generic tools used on different applications. In one of the two case studies reported in [4], namely, the K9 rover controller, the inputs are plans like the ones we use in this paper (see Section 6). The test-input generator generates all possible plans up to given number of nodes and bounds on timing constraints.
The differences between our work and the work of [4] are as follows:
[4] include a test-input generator and an instrumentation package in their tool-chain. Our work is still incomplete in these aspects. For the K9 rover


case study, we have relied on NASA personnel and tools for the input plans, instrumentation and generation of traces.
In [4], a set of untimed temporal logic properties are automatically generated from each plan (recently, the work has been extended to real-time temporal- logic [7]). As stated in [4], “property generation is the difficult step in [the] process” and “[the] set of properties does not fully represent the semantics of the plan, but the approach appearred to be sufficient to catch a large amount of bugs”.
In our work, plans are translated into networks of timed automata. This is a fully-automatic and efficient process, which captures the full semantics of a plan [1]. Notice that, once generated, the TA corresponding to a plan can be also used for other purposes than generating an observer. For instance, to check whether the plan meets certain properties, measure delays of various sub-stages, and so on.
The observer tools used in [4,7] (DBRover [13], JPax [15,8], Eagle [6,5]), are generic tools. In our work, we automatically generate an observer for each plan. This has the potential of optimizing the observer for the particular plan.
In conclusion, we believe that our work represents an alternative that is worth pursuing.

Methodology
Our methodology is mainly focused at testing robotic applications, such as the NASA K9 Rover (see Section 6). Such applications are often structured in two layers. A high-level planning layer and a low-level execution layer. The planning layer follows an input plan, which is a detailed description of the steps needed to accomplish the mission at hand. The planning layer issues commands to the execution layer, which tries to implement them and returns the results, including status information about success or failure. The planning layer then plans the next steps depending on this feedback and the instructions in the plan.
A number of planning languages for robotic applications exist, see, for instance [20,17,18,24,22,21,14]. These languages allow to specify the ordering of the steps, their timing, how to handle exceptions or failures, and so on. Thus, they can be seen as the specification of the mission. A correct execution platform must then meet this specification. Our objective is to check this by testing. More precisely, our methodology is illustrated in Figure 1. It consists of the following phases:




automatic translation v
input

,	v	,

Execution Platform

gener,ation v	,


,	v	,

Observer (
execution
Instrumented


v
yes/no
observation/ testing
Execution
 Platform 

diagnostics
Fig. 1. Methodology

Automatic generation of a timed-automaton specification from the plan.
Automatic generation of an observer from the timed-automaton specifi- cation.
Instrumentation of the system under test, that is, the execution platform.
Execution and testing of the instrumented execution platform.
In the figure, solid arrows represent model and program transformations and dashed arrows represent data flow (output/input). We elaborate on each of the above phases in what follows.
The first step is to translate the plan in the form of a timed automaton, or a network of timed automata (TA). The translation must preserve the semantics of the plan, that is, the semantics of the TA and of the plan must be equivalent. It may also be the case that the TA deﬁnes the semantics of the plan in a formal way, as in [1] and this paper.
Having obtained the TA specification A, the next step consists in gener- ating automatically an observer for A. The observer is a testing device. It observes the system under test (SUT) and checks whether the trace generated by the SUT conforms to A. The observed traces are sequences of observable events and associated time-stamps. The accuracy of the time-stamps depends on the accuracy of the clocks of the observer. In this paper, we consider two types of observers (we follow the terminology of [16]). Analog observers, which can observe real-time precisely, and digital (or periodic-sampling) observers, which measure time with a clock ticking at a given period. Digital-clock ob- servers are clearly more realistic to implement, since in practice the observer will only have access to a finite-precision clock. However, analog-clock ob- servers are still useful, for instance, when the implementation is discrete-time but its time step is not known a-priori.
An observed trace conforms to A if it can possibly be generated by A.


Notice that A is typically modeled as a network of TA, which induces non- determinism and internal communication between the automata. These are artifacts of the model, irrelevant to the external behavior and to the speci- fication itself. Thus, we “hide” them, by considering them as unobservable events. This means that the observer checks if the observed trace is a possible observation resulting from some trace of A.
The third step is the instrumentation of the execution platform. It aims at interfacing the latter with the testing device (the observer). Two possibilities exist here. Either testing is performed on-the-fly (or on-line), that is, during execution of the platform, which is connected to the observer at real-time. Or it is performed off-line, that is, by first executing the platform multiple times to obtain a set of log-traces, then feeding these traces to the observer. In both cases, the instrumented platform must be able to expose a set of observable events to the observer. In the case of testing off-line, the platform must also record the time-stamps of these events. For testing on-line, time-stamping can be done by the platform or by the observer. In the latter case, possible interfacing delays must be taken into account.
Instrumentation can be done manually or automatically. Depending on the complexity of the SUT, it can be a non-trivial task. Care should be taken so that the instrumentation does not itself alter the behavior of the system. For instance, the overhead of added code should be minimal, so as not to affect execution times of the tasks in the system. These are problems inherent in any instrumentation process, and are beyond the scope of this paper.
The final step is the testing procedure per-se. The traces generated by the instrumented platform are fed to the observer, either in real-time (for on-the- fly testing) or off-line. The observer checks conformance of each trace. If a trace is found non-conforming to the specification, the SUT is non-conforming. Otherwise, no conclusion can be made. However, confidence to the correctness of the SUT is increased with the number of tests. Obtaining a representative set of tests, so that some coverage criterion is met is an issue in any testing method (e.g., see [27]), and is beyond the scope of the present paper.

Preliminaries
Timed sequences, projections and digitizations
Let N be the set of non-negative integers. Let R be the set of non-negative rational numbers.
Consider a finite set of actions Σ. RT(Σ) (resp., DT(Σ)) is defined to be the set of all finite-length real-time sequences (resp., discrete-time sequences) over Σ, that is, sequences of the form (a1, t1) ··· (an, tn), where n ≥ 0, for all


1 ≤ i ≤ n, ai ∈ Σ and ti ∈ R (resp., ti ∈ N), and for all 1 ≤ i < j ≤ n, ti ≤ tj. ϵ will denote the empty sequence. ti will be called the time-stamp of ai. Notice that time-stamps are relative to the beginning of a sequence. Thus, when concatenating sequences, they need to be adjusted. More precisely,
given ρ = (a1, t1) ··· (an, tn) and σ = (b1, t' ) ··· (bm, t' ), ρ · σ is the sequence
1	n

(a1, t1) ··· (an, tn)(b1, tn + t' ) ··· (bm, tn + t'
). The time spent in a sequence ρ,

1	m
denoted time(ρ), is the time-stamp of the last action (zero if the sequence is
empty). For example, time((a, 0.1)(b, 1.2)) = 1.2.
Given Σ' ⊆ Σ and ρ ∈ RT(Σ) (resp., DT(Σ)), the projection of ρ to Σ', denoted PΣ' (ρ), is a sequence in RT(Σ ) (resp., DT(Σ )), obtained by “erasing” from ρ all pairs (ai, ti) such that ai /∈ Σ'. For example, if Σ = {a, b}, Σ' = {a} and ρ = (a, 0)(b, 1)(a, 3), then PΣ' (ρ) = (a, 0)(a, 3). For a set of sequences L ⊆ RT(Σ) (or L ⊆ DT(Σ)), PΣobs (L)= {PΣobs (ρ) | ρ ∈ L}.
Consider δ ∈ R, δ > 0, and ρ ∈ RT(Σ). The digitization of ρ with respect to δ, denoted [ρ]δ, is a sequence in DT(Σ), obtained by replacing every pair (ai, ti) in ρ by (ai, [ti ♩), where [x♩ is the integral part of x. For example, if ρ = (a, 0.1)(b, 0.9)(c, 1)(d, 2.3), then [ρ]1 = (a, 0)(b, 0)(c, 1)(d, 2) and [ρ]0.5 =
(a, 0)(b, 1)(c, 2)(d, 4). For a set of sequences L ⊆ RT(Σ), [L]δ = {[ρ]δ | ρ ∈ L}.

Timed automata
We use timed automata (TA) [2] with deadlines to model urgency [23,9]. A timed automaton over Σ (TA) is a tuple A = (Q, q0, X, Σ, E) where Q is a finite set of locations; q0 ∈ Q is the initial location; X is a finite set of clocks; E is a finite set of edges. Each edge is a tuple (q, q', ψ, r, d, a), where q, q' ∈ Q are the source and destination locations; ψ is the guard, a conjunction of constraints of the form x#c, where x ∈ X, c is an integer constant and # ∈ {<, ≤, =, ≥, >}; r ⊆ X is the clock reset; d ∈ {lazy, delayable, eager} is the deadline; and a ∈ Σ is the action. Intuitively, eager transitions must be executed as soon as they are enabled and waiting is not allowed; lazy transitions do not impose any restriction on time passing; finally, when a delayable transition is enabled, waiting is allowed as long as time progress does not disable it. We will not allow eager edges with guards of the form x > c.
A TA A defines an infinite labeled transition system (LTS). Its states are pairs s = (q, v), where q ∈ Q and v : X → R is a clock valuation. →0 is the valuation assigning 0 to every clock of A. SA is the set of all states and sA = (q0,→0) is the initial state. There are two types of transitions:
discrete transitions of the form (q, v) →a A (q', v'), where a ∈ Σ and there is an edge (q, q', ψ, r, d, a), such that v satisfies ψ and v' is obtained by resetting to zero all clocks in r and leaving the others unchanged;


timed transitions of the form (q, v) →t  (q, v + t), where t ∈ R,t > 0 and there is no edge (q, q'', ψ, r, d, a), such that: either d = delayable and there exist 0 ≤ t1 < t2 ≤ t such that v + t1 |= ψ and v + t2 |= ψ; or d = eager and v |= ψ.
We use notation such as s →a  , s /→a  , ..., to denote that there exists s'
A
such that s →a	s', there is no such s', and so on. This notation extends to

sequences in RT(Σ): s →є
A s and if s →
s' and s' →t
a	s'', then s ρ·(a,t)
s''.

A state s ∈ SA
is reachable if there exists ρ ∈ RT(Σ) such that sA
ρ
→A s.

The set of reachable states of A is denoted Reach(A).
The set of traces of a TA A over Σ is defined to be

(1)
Traces(A)= {ρ ∈ RT(Σ) | sA
ρ
→A}.

Let Σobs ⊆ Σ be a set of observable actions. The actions in Σ \ Σobs are called unobservable. The set of observed traces of A with respect to Σobs is defined to be
ObsTraces(A, Σobs )= PΣobs (Traces(A)).
Given δ ∈ R, δ > 0, the set of δ-digital observed traces of a TA A is defined to be
DigTraces(A, Σobs, δ)= [ObsTraces(A, Σobs )]δ.
Notice that Traces(A) ⊆ RT(Σ), ObsTraces(A, Σobs ) ⊆ RT(Σobs ) and
DigTraces(A, Σobs, δ) ⊆ DT(Σobs ).


Generating timed-automata from plans
In this section we describe how to obtain TA models from plans. We give the construction for the concrete language of plans performed by the K9 Rover executive, which is actually our case study (see section 6). Nevertheless, TA models are general enough to capture most of the constraints expressed in plan languages.
For the K9 Rover application, a plan is a hierarchical structure of actions that the executive must perform. Traditionally, plans are deterministic se- quences of actions. However, increased autonomy requires added flexibility. The plan language therefore allows branching based on conditions that need to be checked, and also for flexibility with respect to the starting time of an action. We give here an example of a language used in the description of the plans that the executive must execute.



Plan →	Node
Node →	Block | Task Block →	(block
NodeAttr
:node-list (Node ... Node)) Task →	(task
NodeAttr
:action Symbol) NodeAttr →	:id Symbol
:start-condition Condition
:waitfor-condition Condition




(block
:id node0
:continue-on-failure
:start-condition ((1 5))
:end-condition ((1 30))
:node-list ( (block
:id node1
:continue-on-failure
:start-condition (1 5)) (block
:id node2
:continue-on-failure
:start-condition (+1 +5)
:end-condition (+1 +30)
)

:maintain-condition Condition	)
:end-condition Condition	)
[:continue-on-failure]
Condition →	(time [+] StartTime [+] EndTime)
Fig. 2. The concrete grammar of plans (left) and a plan example (right).

Plan Syntax
A plan is a node, a node is either a task, corresponding to an action to be executed, or a block, corresponding to a logical group of nodes. Figure 2 shows the grammar for the language that we considered to describe plans. All node attributes except the node id are optional. Each node may specify a set of conditions. The start condition (that must be true at the beginning of the node execution), the wait-for conditions (wait while the condition is not true), the maintain condition (that must be true through the execution of the node) and the end condition (that must be true at the end of the node execution). Each condition includes information about relative or absolute time window, indicating a lower and upper bound on the time. The continue-on-failure flag indicates what the behavior will be if a node failure is encountered.
We propose hereafter a compilation method allowing to obtain from a plan (that is, a syntactic object) a network of timed automata (that is, a semantic model) encoding all the accepted, reasonable executions of that plan.
For sake of simplificity, we consider the following abstract syntax for plans.
Definition 4.1 (plan syntax)
A plan P is a tuple (N, δ, λ, n0) where
N is a ﬁnite set of nodes
δ : N → N ∗ is the node decomposition function, deﬁned such that the image

set relation δˆ = {(n, n')|n' ∈ δ(n)} satisﬁes
acyclicity: 6n ∈ N. n /∈ δˆ+({n})

disjointness: 6n1, n2 ∈ N, n1 /= n2.
δˆ+({n1}) ∩ δˆ+({n2})= ∅

λ : N → Σ ×f4 ×У is the node labeling function, where Σ is a set of action labels, f = {[l, u] | l, u ∈ N} is the set of interval constraints, and У are the booleans. That is, λ(n) = (an, (sn, wn, mn, en), fn) where an is the action symbol, sn, wn, mn, en are respectively the start, wait-for, maintain and end timed constraints, and fn is the continue-on-failure flag associated to the node n.
n0 ∈ N is the main (or start) node of the plan

Plan Semantics
Nodes are executed sequentially. For every node, execution proceeds through the following steps :
Wait until the start condition is satisfied; if the current time passes the end of the start condition, the node times out and this is a node failure.
The execution of a task proceeds by invoking the corresponding action. The action takes exactly the time specified in the :duration attribute. The action’s status must be fail, if :fail is true or the time conditions are not met; otherwise, the status must be success. The execution of a block simply proceeds by executing each of the node in the node-list in order.
If the time exceeds the end condition, the node fails.
On a node failure occuring in a sequence, the value of the enclosing block node’s continue-on-failure flag is checked. If true, execution proceeds to the next node in the sequence. If false, the node failure is propagated to the block enclosing the node and so on. If the node failure passes out to the top level block of the plan, the execution is aborted.
We present now the semantics of nodes and plans in terms of timed au- tomata. The semantics is constructive in the sense that, automata can be ef- fectively constructed, depending on syntactical description of the nodes. The semantics is also compositional in the sense that, the semantics of the plan is obtained directly by composing of timed automata associated to nodes.
Let us first introduce some notations for some given plan P = (N, δ, λ, n0). The set of actions ΣP contains the set of synchronisation actions beginn, abortn, f ailn, endn defined for all nodes n, and the set of elementary actions an, defined for task nodes n of the plan P .
The set of clocks XP = {xn | n ∈ N} contains one clock xn for each node
n of the plan. This clock xn is set to 0 when the execution of the node n


	
Fig. 3. Timed automaton for the common part (left), for the task specific part (right, up) and the pattern for the block specific part (right, down).


begins. If cn = [l, u] is some constraint of the node n, we will note with [cn]] the timed guard (l ≤ xn ∧ xn ≤ u). We note also with afterc the constraint [−∞, u] where the lower bound of c has been removed.
To each node n of P we associate a timed automaton over clocks XP and actions ΣP . The automaton encodes the sequential behaviour described by the node execution algorithm. Note that since the execution algorithm is deterministic, the timed automata obtained are deterministic.
Definition 4.2 (node semantics) Figure 3 illustrates the translation. Let n be a node with δ(n) = n1...nk and λ(n) = (an, (sn, wn, mn, en), fn). The semantics of the node n is described by the timed automaton for the common part, shown in the left of the ﬁgure. The speciﬁc part is ﬁlled according to node attributes as follows. For a task node (δ(n) = ϵ), as shown in the top-right part of the ﬁgure. For a block node with continue on failure (fn = true), as shown in the bottom-right part of the ﬁgure. For a block node without continue on failure (fn = f alse), as shown in the bottom-right part of the ﬁgure, except that the transition labeled ?f ailni leads back to the right-most bottom location. For the sake of simplicity, we represent eager transitions using solid lines and lazy transitions using dashed lines. ! and ? denote communication via CSP-like message passing.



Fig. 4. A plan and its translation to a network of three timed automata.
Finally, the semantics of the entire plan P is given by the parallel com- position i.e, the network of timed automata defined for all of its nodes. Note that, the product automaton is deterministic too.
Definition 4.3 (plan semantics) Let P = (N, δ, λ, n0) be a plan, XP the set of clocks and ΣP the set of actions deﬁned by P. Let Ani be the timed automata over XP and ΣP associated to nodes ni ∈ N. The semantics of the plan P is given by the network An0 ||An1 ||...||Ank.
An example of a plan and the corresponding timed automata are given in Figure 4.

Generating observers from timed-automata
In this section, we define two kinds of observers for a TA specification A. They are distinguished by their observation capabilities with respect to time. The


first, called analog observers (the terminology is taken from [16]) can observe a set of observable actions and the exact time-stamps of these actions. Thus, these observers can be thought of possessing a “perfect”, real-time clock, which they can consult immediately upon observing an action. The second, called digital observers (or periodic-sampling observers) can also observe a set of observable actions, but they only have access to a digital clock, that is, a counter that ticks with a given period δ. Thus, when observing an action a which occurred at real-time t, the digital observer only knows the current value of its periodic clock, i.e., [ t ♩.
The objective of the observers is to determine whether a given trace (gen- erated by a system under observation) could be possibly generated by the specification A. If so, then the system under observation passes this test, otherwise, it fails.

Analog and digital observer deﬁnition
Let us formalize the above notions. Let A be a TA over Σ and let Σobs ⊆ Σ be a set of observable actions.
An analog observer for A with respect to Σobs is a total function
O : RT(Σobs ) → {0, 1}
such that
6ρ ∈ RT(Σobs ) . O(ρ)= 1 ⇔ ρ ∈ ObsTraces(A, Σobs ) .
Thus, an analog observer performs nothing else but a membership test: does the observation ρ belong to the language of A, i.e., ρ ∈ ObsTraces(A, Σobs ). Notice that A has no acceptance conditions in our setting, thus, its language is prefix-closed. Also notice that observers are required to be determinis- tic, that is, to provide the same answer each time they are given the same observation. Thus, analog observers can be seen as deterministic machines accepting the language of A. It follows, from the fact that timed automata are non-determinizable in general [2], that an analog observer cannot always be represented as a timed automaton. Moreover, checking whether this is the case for a particular automaton is undecidable [26].
A digital observer (or periodic-sampling observer) for A with respect to Σobs and δ > 0 is a total function
D : DT(Σobs ) → {0, 1}
such that
6ρ ∈ DT(Σobs ) .  D(ρ)=1 ⇔ ρ ∈ DigTraces(A, Σobs, δ) .


Automatic observer generation using the state-estimation technique
We next show how, given a timed automaton A, analog and digital ob- servers can be automatically generated for A. The method relies on the state- estimation technique proposed in [25], where it was applied to fault detection. State estimation consists in computing, given an observation, the set of states of A which “match” this observation, that is, the set of all possible states which can be reached by some trace which yields the observed trace. If the state estimate remains non-empty all along the observation, then the latter can indeed be generated by A, since there exists at least one trace of A matching the observation. If, however, the state estimate becomes empty,
then the observation cannot be generated by A.
State estimation is not more expensive than reachability analysis. In fact, in some cases it is cheaper. 1 As shown in [25,19], state estimates can be represented using standard data structures for TA, such as DBMs [12], and can be computed using various versions of symbolic successor operators, depending on the desired estimator (analog or digital).
Generating analog observers
Consider a timed automaton A over Σ and a set of observable actions Σobs ⊆ Σ. The analog state-estimator for A with respect to Σobs is the total function SEa : RT(Σobs ) → 2Reach(A), defined as follows:


SE (ρ)= {s | ∃σ ∈ RT(Σ) . sA →σ
s ∧ P
(σ)= ρ}.

a	0	A
Σobs

SEa(ρ) contains all states where A can possibly be after executing a sequence which yields the analog observation ρ.
Now, define



O(ρ)= ⎧⎨ 1, if SEa(ρ) /= ∅
⎩ 0, otherwise

It follows easily from the definitions that O defined as above is a valid analog observer for A w.r.t. Σobs .
We proceed to discuss how SEa can be computed. Let S be a set of states of A. Let a ∈ Σ and t ∈ R. Define the following operators:



asucc(S, a)= {s' | ∃s ∈ S . s →a	s'}
tsucc(S, t)= {s' | ∃s ∈ S . ∃ρ ∈ RT(Σ \ Σ


obs


ρ
) . time(ρ)= t ∧ s →A


s'}



1  The worst-case complexity of the membership problem in timed automata is studied in [3]. There, it is shown that for automata without epsilon-transitions (i.e., fully ob- servable), the problem is NP-complete whereas for automata with epsilon-transitions the problem is PSPACE-complete (i.e., as hard as reachability).


asucc(S, a) contains all states which can be reached by some state in S after performing action a. tsucc(S, t) contains all states which can be reached by some state in S via a sequence ρ which contains no observable actions and takes exactly t time units.
The following proposition shows how SEa(ρ) can be computed recursively on ρ.
Proposition 5.1
SEa(ϵ)= tsucc({sA}, 0)
SEa(ρ · (a, t)) = asucc(tsucc(SEa(ρ),t − time(ρ)), a)
Generating digital observers
Consider a timed automaton A over Σ and a set of observable actions Σobs ⊆ Σ. Let δ ∈ R, δ > 0. The digital state-estimator for A with respect to Σobs and δ is the total function SEd : DT(Σobs ) → 2Reach(A), defined as follows:


SE (ρ)= {s | ∃σ ∈ RT(Σ) . sA →σ
s ∧ [P
(σ)]
= ρ}.

d	0	A
Σobs	δ

SEd(ρ) contains all states where A can possibly be after executing a sequence which yields the digital observation ρ.
Now, define



D(ρ)= ⎧⎨ 1, if SEd(ρ) /= ∅
⎩ 0, otherwise

It follows easily from the definitions that D defined as above is a valid digital observer for A w.r.t. Σobs and δ.

tick!
x = 10
eager
tick!
9 ≤ x ≤ 11
delayable

)v。 x := 0
perfectly periodic
)v。 x := 0 with skew

Fig. 5. Two possible Tick automata.

We proceed to discuss how D can be computed. We first form the product of A with a Tick automaton like the one shown on the left of Figure 5. This automaton models the digital clock of the observer, assumed to be perfectly periodic with period δ = 10. Other Tick automata can also be used, like the one on the right of the figure, to model phenomena such as clock skew or drift. (Notice that, in these cases, the definition of DigTraces must be modified.) Let the product automaton be Atick = A  Tick. We assume that


tick is a new observable event, not in Σ. Let S be a set of states of Atick. Define the following operator:
usucc(S)= {s' | ∃s ∈ S . ∃ρ ∈ RT(Σ \ Σ	) . s →ρ	s'}.
usucc(S) contains all states which can be reached by some state in S via a sequence ρ which contains no observable actions. Notice that, by construction of Atick, the duration of ρ is bounded: since tick is observable and has to occur after at most 1 time unit, time(ρ) ≤ 1.
For a ∈ Σ ∪ {tick}, define:
dsucc(S, a)= asucc(usucc(S), a).
dsucck(·, a), for k ∈ N, denotes the application of dsucc(·, a) k times. That is,
dsucc0(·, a) is the identity function and dsucck+1(·, a)= dsucc(dsucck(·, a), a).
The following proposition shows how SEd(ρ) can be computed recursively on ρ.
Proposition 5.2
SEd(ϵ)= {sAtick }
SEd(ρ · (a, k)) = dsucc(dsucck(SEd(ρ), tick), a)
Implementation
We have implemented a prototype observer generation tool, called TTG, on top of the IF environment [10]. The IF modeling language allows to specify systems consisting of many processes communicating through message passing or shared variables and includes features such as hierarchy, priorities, dynamic creation and complex data types. The IF tool-suite includes a variety of tools for simulation, model checking and test generation. TTG is written in C++ and uses the basic libraries of IF for parsing and symbolic reachability of timed automata with deadlines.
TTG takes as main input the specification automaton, written in IF lan- guage, and generates an off-line observer. The observer takes as input a trace and the set of unobservable actions of the original IF specification. The ob- server can function either as an analog observer (default) or as a digital ob- server (-d option).

Case Study
Our case study is the Mars rover controller K9, and in particular its executive subsystem, developed at NASA Ames. It is an experimental platform for autonomous wheeled vehicles called rovers, targeted for the exploration of the Martian surface. K9 is specifically used to test out new autonomy software,


ExecTimeChecker
 

...	 
 
  

//

 


ExecCondChecker

	 //


, 


/
Database

 (System state)	J
Fig. 6. The K9 Rover Architecture.
such as the Rover Executive. The Rover Executive provides a flexible means of commanding a rover through plans that control the movement, experimental apparatus, and other resources of the Rover - also taking into account the possibiliy of failure of command actions.
The Rover executive is a software prototype written in C++ by researchers at NASA Ames. It is a multi-threaded program that consists of approximately 35,000 lines of C++ code, of which 9600 lines of code are related to actual functionality. The C++ code was manually translated into Java and C to experiment with tools using three technologies: static analysis, model checking and runtime analysis [11,4].
System Description
The Rover executive is made up of :
A main coordinating component named Executive. It provides the main control over how the plan is executed. Executive waits for a plan to be available, and signals at the end of the plan execution. So, the PlanWatcher signals when a plan is ready, and waits for end of execution to send a new plan.
The component for monitoring the state condition ExecCondChecker consists of two threads, the database monitor DBMonitor just keeps watching for changes in the database and the thread Internal decides what needs to be done about it.
ExecTimerChecker is the component for monitoring temporal conditions. It consists of two threads ExecTimer and ExecTimerWaiter. Both are respec-

start node0 922
start node1 1932
success node1 1932
start node2 2942
success node2 2942
success node0 2942
Fig. 7. A trace corresponding to the plan of Figure 4.


tively very similar to DBMonitor and Internal
The ActionExecution thread is responsible for issuing the commands to the Rover. It consists of a list of methods internalDoAction, doAction, stopAction, and abortAction. ActionExecution runs the internalDoAction method, the other methods are just called by the Executive on its own thread by simple calls.
Database simply receives calls to its methods. All accesses to the database through its methods are controlled by a lock.
Synchronization between these threads is performed through mutex and con- ditions variables.


Results
Due to intellectual property restrictions, we did not have access to the execu- tion platform of the K9 Rover. However, NASA provided us with a set of one hundred plans and traces, generated by the K9 Rover execution platform. We applied our method, using the plan-to-IF translator to obtain IF models for each plan, and TTG to generate an observer for each IF model of a plan. The observer was then used to check the traces.
One of the plans is shown in Figure 4. Time units in the plan are in seconds. A trace generated by the execution platform with input this plan is shown in Figure 7 (times in the trace are in milliseconds). The trace says that node 0 starts at time 922, node 1 starts at time 1932 and completes successfully at the same time, and so on. This trace does not conform to the specification, because the latter requires that node 2 finishes at least 1 second after it starts (fifth line of the block of node 2 in the plan). TTG takes a few seconds to generate the observer (this is a C++ code generation process, compilation and linking with IF libraries). The observer needs less than a second to qualify this claim as non-conforming. In general, all traces were checked in a matter of seconds.

Conclusions and future work

We have proposed a methodology for testing conformance of an important class of real-time applications in an automatic way. The class includes all applications for which a specification is available and can be translated into a network of timed automata. In particular, the class includes robotic applica- tions where specifications are considered to be the plans describing the robot mission. Such plans can be automatically translated to timed automata [1].
The method relies on the automatic generation of an observer from the specification, on the one hand, and on the instrumentation of the system to be tested, on the other hand. The testing process consists in feeding the traces generated by the instrumented system to the observer, which is a testing device, used to check conformance of a trace to the specification. We have validated the approach on the NASA K9 Rover case study.
Regarding future work, we plan to study the instrumentation and trace generation problems. As mentioned above, instrumentation should be possible to automate, by identifying a mapping between execution platform events and specification events, and automatically scanning the code, adding event/time- stamp exporting commands to the identified platform events. Trace generation has a lot of similarities to test-case generation, since the system under test must be run a number of times, with different inputs, to obtain a set of traces. Input coverage and other techniques can be employed here to obtain an adequate set of traces. In fact, it is an interesting question how to define coverage in the case where the inputs are plans.
We also plan to study the representation of observers as finite automata (timed or untimed). This is not always possible, because timed automata are non-determinizable in general [2]. Moreover, checking whether a particular TA is determinizable and determinizing it is algorithmically impossible in general [26]. Identifying classes of TA (e.g. those generated from plans) for which the above problems are solvable is a possible step in this direction.
Finally, we envisage extending our approach to other high-level specifica- tion languages and experimenting with more case studies.


Acknowledgement

We would like to thank Klaus Havelund and Rich Washington from NASA for their help with the instrumentation of the K9 Rover application. Also, Dimitra Giannakopoulou from NASA for explaining the application.

References
A. Akhavan, S. Bensalem, M. Bozga, and E. Orfanidou. Experiment on verification of a planetary rover controller, 2003. Submitted.
R. Alur and D. Dill. A theory of timed automata. Theoretical Computer Science, 126:183–235, 1994.
R. Alur, R.P. Kurshan, and M. Viswanathan. Membership questions for timed and hybrid automata. In RTSS’98, 1998.
C. Artho, D. Drusinsky, A. Goldberg, K. Havelund, M. Lowry, C. Pasareanu, G. Rosu, and
W. Visser. Experiments with test case generation and runtime analysis. In 10th International Workshop on Abstract State Machines (ASM’03), March 2003.
H. Barringer, A. Goldberg, K. Havelund, and K. Sen. Eagle does Space Efficient LTL Monitoring. Submitted for publication, October 2003.
H. Barringer, A. Goldberg, K. Havelund, and K. Sen. Eagle Monitors by Collecting Facts and Generating Obligations. Submitted for publication, October 2003.
H. Barringer, A. Goldberg, K. Havelund, and K. Sen. Rule-Based Runtime Verification. In Proceedings of Fifth International Conference on Veriﬁcation, Model Checking and Abstract Interpretation, January 2004 – to appear in LNCS, August 2003.
S. Bensalem and K. Havelund. Deadlock Analysis of Multi-threaded Java Programs. Submitted for publication, December 2003.
S. Bornot, J. Sifakis, and S. Tripakis. Modeling urgency in timed systems. In Compositionality, volume 1536 of LNCS. Springer, 1998.
M. Bozga, J.C. Fernandez, L. Ghirvu, S. Graf, J.P. Krimm, and L. Mounier. IF: a validation environment for timed asynchronous systems. In E.A. Emerson and A.P. Sistla, editors, Proc. CAV’00, volume 1855 of LNCS, pages 543–547. Springer Verlag, 2000.
G. Brat, D. Giannakopoulou, A. Goldberg, K. Havelund, M. Lowry, C. Pasareanu, A. Venet, and W. Visser. Experimental evaluation of v&v tools on martian rover software. In SEI Software Model Checking Workshop, 2003.
D.L. Dill. Timing assumptions and verification of finite-state concurrent systems. In J. Sifakis, editor, Automatic Veriﬁcation Methods for Finite State Systems, Lecture Notes in Computer Science 407, pages 197–212. Springer–Verlag, 1989.
D. Drunsinsky. The temporal tover and the ATG rover. volume 1885 of LNCS, pages 323–330, 2000.
R. Goldman. Model-based planning and real-time execution in the CIRCA framework. In AI Planning and Scheduling (AIPS’02), 2002.
K. Havelund and G. Ro¸su. Monitoring Java Programs with Java PathExplorer. In K. Havelund and G. Ro¸su, editors, Proceedings of the First International Workshop on Runtime Veriﬁcation (RV’01), volume 55 of Electronic Notes in Theoretical Computer Science, pages 97–114, Paris, France, July 2001. Elsevier Science. Extended version to appear in the journal Formal Methods in System Design.
T. Henzinger, Z. Manna, and A. Pnueli. What good are digital clocks? In ICALP’92, LNCS 623, 1992.
F. Ingrand, R. Chatila, R. Alami, and F. Robert. PRS: A high level supervision and control language for autonomous mobile robots. In IEEE Intl. Conf. on Robotics and Automation, 1996.
K. Konolige, K. L. Myers, E. H. Ruspini, and A. Saffiotti. The Saphira architecture: A design for autonomy. Journal of experimental & theoretical artiﬁcial intelligence, 9(1):215–235, 1997.


M. Krichen and S. Tripakis. Black-box conformance testing for real-time systems, 2003. Submitted.
D.M. Lyons. Representing and analyzing action plans as networks of concurrent processes.
IEEE Transactions on Robotics and Automation, 1993.
N. Muscettola, G.A. Dorais, C. Fry, R. Levinson, and C. Plaunt. IDEA: Planning at the core of autonomous reactive agents. In AI Planning and Scheduling (AIPS’02), 2002.
J. Peterson, G. Hager, and P. Hudak. A language for declarative robotic programming. In
IEEE Conf. on Robotics and Automation, 1999.
J. Sifakis and S. Yovine. Compositional specification of timed systems. In 13th Annual Symposium on Theoretical Aspects of Computer Science, STACS’96, pages 347–359, Grenoble, France, February 1996. Lecture Notes in Computer Science 1046, Spinger-Verlag.
R. Simmons and D. Apfelbaum. A task description language for robot control. In Intelligent Robotics and Systems, 1998.
S. Tripakis. Fault diagnosis for timed automata. In Formal Techniques in Real Time and Fault Tolerant Systems (FTRTFT’02), volume 2469 of LNCS. Springer, 2002.
S. Tripakis. Folk theorems on the determinization and minimization of timed automata. In
Formal Modeling and Analysis of Timed Systems (FORMATS’03), LNCS. Springer, 2003.
H. Zhu, P. Hall, and J. May. Software unit test coverage and adequacy. ACM Computing Surveys, 29(4), 1997.
