Available online at www.sciencedirect.com


Electronic Notes in Theoretical Computer Science 319 (2015) 199–216
www.elsevier.com/locate/entcs
Conditioning in Probabilistic Programming
Nils Jansen Benjamin1 Lucien Kaminski1 Joost-Pieter Katoen1 Federico Olmedo1
RWTH Aachen University, Aachen, Germany
Friedrich Gretz2 Annabelle McIver2
Macquarie University, Sydney, Australia

Abstract
In this paper, we investigate the semantic intricacies of conditioning in probabilistic programming, a major feature, e.g., in machine learning. We provide a quantitative weakest pre–condition semantics. In contrast to all other approaches, non–termination is taken into account by our semantics. We also present an operational semantics in terms of Markov models and show that expected rewards coincide with quantitative pre–conditions. A program transformation that entirely eliminates conditioning from programs is given; the correctness is shown using our semantics. Finally, we show that an inductive semantics for conditioning in non–deterministic probabilistic programs cannot exist.
Keywords: Probabilistic Programming, Semantics, Conditional Probabilities, Program Transformation

Introduction
In recent years, interest in probabilistic programming has rapidly grown [9,11]. This is due to its wide applicability, for example in machine learning for describing distri- bution functions; Bayesian inference is pivotal in their analysis. It is used in security for describing both cryptographic constructions such as randomized encryption and experiments defining security properties [4]. Probabilistic programs, being exten- sions of familiar notions, render these fields accessible to programming communities. A rich palette of probabilistic programming languages exists including Church [8] as well as modern approaches like probabilistic C [23], Tabular [10] and R2 [22].
Probabilistic programs are sequential programs having two main features: (1) the ability to draw values at random from probability distributions, and (2) the

٨ This work was supported by the Excellence Initiative of the German federal and state government.
1  Emails: {nils.jansen, benjamin.kaminski, katoen, federico.olmedo}@informatik.rwth-aachen.de
2 Emails: annabelle.mciver@mq.edu.au, friedrich.gretz@students.mq.edu.au

http://dx.doi.org/10.1016/j.entcs.2015.12.013
1571-0661/© 2015 The Authors. Published by Elsevier B.V.
This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).

ability to condition the value of variables in a program through so–called obser- vations. The semantics of languages without conditioning is well–understood: In his seminal work, Kozen [19] considered denotational semantics for probabilistic programs without non–determinism or observations. One of these semantics—the expectation transformer semantics—was adopted by McIver and Morgan [21], who added support for non–determinism; a corresponding operational semantics is given in [13]. Other relevant works include probabilistic power–domains [17], semantics of constraint probabilistic programming languages [15,14], and semantics for stochastic λ–calculi [26].
Semantic intricacies. The difficulties that arise when program variables are conditioned through observations is less well–understood. This gap is filled in this paper. Previous work on semantics for programs with observe statements [22,16] do neither consider the possibility of non–termination nor the powerful feature of non–determinism. In contrast, we thoroughly study a more general setting which accounts for non–termination by means of a very simple yet powerful probabilis- tic programming language supporting non–determinism and observations. Let us first analyze a few examples illustrating the different problems. We start with the problem of non–termination; consider the two program snippets
x := 2	and	{x := 2} [1/2] {abort} .
The program on the left just assigns the value 2 to the program variable x, while the program on the right tosses a fair coin—which is modeled through a probabilistic choice—and depending on the outcome either performs the same variable assign- ment or diverges due to the abort instruction. The semantics given in [22,16] does not distinguish these two programs and is only sensible in the context of terminating programs. A programmer writing only terminating programs is already unrealistic in the non–probabilistic setting. Our semantics does not rely on the assumption that programs always terminate and is able to distinguish these two programs.
To discuss observations, consider the program snippet Pobs1
{x := 0} [1/2] {x := 1}; observe (x=1),
which assigns zero to the variable x with probability 1/2 while x is assigned one with the same likelihood, after which we condition to the outcome of x being one. The observe statement blocks all invalid runs violating its condition and renormalizes the probabilities of the remaining valid runs. This differs, e.g., from program anno- tations like (probabilistic) assertions [25] as we will see later. The interpretation of the program is the expected outcome conditioned on the valid runs. For Pobs1 , this yields the outcome 1 · 1—there is one valid run that happens with probability one, with x being one.
More involved problems arise when programs are infeasible meaning all runs are blocked. Consider a slight variant of the program above, called Pobs2 :
{x := 0; observe (x=1)} [1/2] {x := 1; observe (x=1)}

The left branch of the probabilistic choice is infeasible. Is this program equivalent to the sample program Pobs1 ? It will turn out that this is the case, meaning that setting an infeasible program into context can render it feasible.
The situation becomes more complicated when considering loopy programs that may diverge. Consider the following two programs:
Pdiv :	x := 1; while (x=1) {x := 1}
Pandiv :	x := 1; while (x=1) {{x := 1} [1/2] {x := 0}; observe (x=1)}
Program Pdiv diverges as x is set to one in every iteration. This yields a null expected outcome. Due to the conditioning on x=1, Pandiv has just a single (valid)— non–terminating—run, but this run almost surely never happens, i.e. it happens with probability zero. The conditional expected outcome of Pandiv can thus not be measured. Our semantics can distinguish these programs while programs with (probabilistic) assertions must be loop–free to avoid similar problems [25]. Other approaches insist on the absence of diverging loops [5]. Neither of these assumptions are realistic.
Non–determinism is a powerful means to deal with unknown information, as well as to specify abstractions in situations where implementation details are unim- portant. This feature turns out to be intricate in combination with conditioning. 3 Consider the program Pnondet
{{x := 5} 2 {x := 2}} [1/4] {x := 2}; observe (x>3),
where with probability 1/4, x is set either to 5 or to 2 non–deterministically (denoted
{x := 5} 2 {x := 2}), while x is set to 2 with likelihood 3/4. Resolving the non– deterministic choice in favor of setting x to five yields a conditional expectation of 5 for x, obtained as 5 · 1/4 rescaled over the single valid run of Pnondet . Taking the right branch however induces two invalid runs due to the violation of the condition x>3, yielding a non–measurable conditional outcome.
Contributions. The above issues—non–termination, loops, and non–determi- nism—indicate that conditioning in probabilistic programs is far from trivial. This paper presents a thorough semantic treatment of conditioning in a probabilistic extension of Dijkstra’s guarded command language (known as pGCL [21]), an ele- mentary though foundational language that includes (amongst others) parametric probabilistic choice. We take several semantic viewpoints.
We first provide a conditional version of a weakest pre–condition (wp) semantics
`a la [21]. This is typically defined inductively over the structure of the program. We show that combining both non–determinism and conditioning cannot be treated in this manner. To treat possibly non–terminating programs, due to e.g., diverging loops or abortion, this is complemented by a weakest liberal pre–condition (wlp) semantics. Moreover, our w(l)p semantics is backward compatible with the original

3 As stated in [11], “representing and inferring sets of distributions is more complicated than dealing with a single distribution, and hence there are several technical challenges in adding non–determinism to probabilistic programs”.

pGCL semantics for programs without conditioning; this does not apply to alterna- tive approaches such as R2 [22].
Furthermore, Markov Decision Processes (MDPs) [24] are used as the basis for an operational semantics. This semantics is simple and elegant while covering all aforementioned phenomena, including non–determinism. We show that conditional expected rewards in the MDP–semantics correspond to (conditional) wp in the de- notational semantics, extending a similar result for pGCL [13].
Finally, we present a program transformation which entirely eliminates condi- tioning from any program and prove its correctness using our semantics.
Summarized, after introducing pGCL (Section 2), we give a denotational seman- tics for fully probabilistic programs (Section 3). We provide the first operational se- mantics for imperative probabilistic programming languages with conditioning and both probabilistic and non–deterministic choice (Section 4). Our semantics enables us to prove the correctness of a program transformation that eliminates observe statements (Section 5). Finally, we show that it is not possible to provide an induc- tive semantics for programs that include both conditioning and non–determinism (Section 6).
An extended version of this paper including all proofs and further program transformations for eliminating observe statements is available in [12].

The Programming Language
In this section we briefly present the probabilistic programming language used for our development. The language is an extension of the probabilistic guarded command language (pGCL) of McIver and Morgan [21]. The original pGCL is given by syntax
P ::= skip | abort | x := E | P; P | ite (G) {P} {P}
| {P} [p] {P} | {P} 2 {P} | while (G) {P}

and constitutes a plain extension of Dijkstra’s guarded command language (GCL) [7] with a binary probabilistic choice operator. Here, x belongs to V, the set of program variables; E is an arithmetical expression over V; G a Boolean expression over V; and p a real–valued parameter with domain [0, 1]. Most of the pGCL instructions are self–explanatory; we elaborate only on the following: {P} [p] {Q} is a proba- bilistic choice where program P is executed with probability p and program Q with probability 1−p; {P} 2 {Q} is a non–deterministic choice between P and Q; finally abort is syntactic sugar for the diverging program while (true) {skip}.
To model probabilistic programs with conditioning we extend pGCL with ob- servations, leading to the conditional pGCL (cpGCL). At the syntactic level, an observation is introduced with the instruction observe (G), G being a Boolean ex- pression over V. The effect of such an instruction is to block all invalid program executions violating G and rescale the probability of the remaining executions so that they sum up to one.

As an illustrative example consider the following pair of programs:
P1 :	{x := 0} [p] {x := 1}; {y := 0} [q] {y := −1}
P2 :	{x := 0} [p] {x := 1}; {y := 0} [q] {y := −1}; observe (x+y=0)
Program P1 admits all (four) runs, two of which satisfy x=0; for this program the probability of x=0 is p. Program P2—due to the observe statement requiring x+y=0—admits only two runs, only one of them satisfying x=0; for this program the probability of x=0 is    pq    .
Note that there exists a connection between the observe statement used in our work and the well–known assert statement. Both statements observe (G) and assert (G) block all runs violating G. The crucial difference, however, is that observe (G) normalizes the probability of the unblocked runs while assert (G) does not, yielding then a sub–distribution of total mass possibly less than one [20,4].

Denotational Semantics for Conditional pGCL
In this section we recall the expectation transformer semantics of pGCL and extend it to conditional programs in the fully probabilistic fragment of cpGCL.

Expectation Transformers in pGCL
Expectation transformers are a quantitative version of predicate transformers [7] used to endow probabilistic pGCL programs a formal semantics. Loosely speaking, they capture the average or expected outcome of a program, measured w.r.t. a utility or reward function over the set of final states. To make this more precise, let S be the set of program states, where a program state is a variable valuation. Now assume that P is a fully probabilistic program, i.e. a program without non–deterministic choices. Intuitively, we can think of P as a mapping from an initial state σ ∈ S to a distribution of final states JP )(σ); its formal semantics is captured by a transformer wp[P ], which acts as follows: Given a random variable f : S → R≥0, wp[P ](f ) maps every initial state σ to the expected value EJP )(σ)(f ) of f with respect to the distribution of final states JP )(σ). Symbolically,
wp[P ](f )(σ) = EJP )(σ)(f ) .

In particular, if f = χA is the characteristic function of some event A, wp[P ](f ) retrieves the probability that the event occurred after the execution of P . (Moreover, if P is a deterministic program in GCL, EJP )(σ)(χA) is {0, 1}–valued and we recover the ordinary notion of predicate transformers introduced by Dijkstra [7].)
For a program P including non–deterministic choices, the execution of P yields a set of final distributions. To account for this, we assume that wp[P ](f )(σ) gives the tightest lower bound infμ∈JP )(σ) Eμ(f ) for the expected value of f . This corresponds with the notion of a demonic adversary resolving the non–deterministic choices.

We follow McIver and Morgan [21] and use the term expectation to refer to a ran- dom variable mapping program states to real values. The expectation transformer wp then transforms a post–expectation f into a pre–expectation wp[P ](f ) and can be defined by induction on the structure of P , following the rules in Figure 1. The transformer wp also admits a liberal variant wlp, which differs from wp in the way in which non–termination is treated.
Formally, the transformer wp operates on unbounded expectations in E = S →
∞ and wlp operates on bounded expectations in E≤1 = S → [0, 1]. Here R∞
denotes the set of non–negative real values with the adjoined ∞ value. In order
to guarantee the well–definedness of wp and wlp we need to provide E and E≤1 the structure of a directed–complete partial order. Expectations are ordered pointwise,
i.e. f ± g iff f (σ) ≤ g(σ) for every state σ ∈ S. The least upper bound of directed subsets is also defined pointwise.
In the remainder we make use of the following notation related to expectations. We use bold fonts for constant expectations, e.g. 1 denotes the constant expecta- tion 1. Given an arithmetical expression E over program variables we simply write E for the expectation that in state σ returns σ(E). Given a Boolean expression G over program variables we use χG to denote the {0, 1}–valued expectation that returns 1 if σ |= G and 0 otherwise.

Conditional Expectation Transformers
We now study how to extend the notion of expectation transformers to conditioned probabilistic programs without non–determinism in cpGCL. To illustrate the in- tuition behind our solution, consider the following scenario: Assume we want to measure the probability that some event A occurs after the execution of a condi- tioned program P . Since P contains observations, its execution leads to a condi- tional distribution μ|O of final states. Now the conditional probability that A occurs (given that O occurs) is given as the quotient of the probabilities Pr[μ ∈ A ∧ O] and Pr[μ ∈ O]. Motivated by this observation, we introduce an expectation transformer cwp[·]: E × E≤1 → E × E≤1, whose application cwp[P ](χA, 1) will yield the desired pair of probabilities (Pr[μ ∈ A ∧ O], Pr[μ ∈ O]). We are only left to define a transformer cwp[P ] that computes the corresponding quotient. Formally, we let
cwp[P ](f ) , cwp1[P ](f, 1) ,
cwp2[P ](f, 1)
where cwp1[P ](f, g) (resp. cwp2[P ](f, g)) denotes the first (resp. second) component of cwp[P ](f, g). If cwp2[P ](f, 1)(σ)= 0, then cwp[P ](f ) is not well–defined in σ (in the same way as the conditional probability Pr(A | B) is not well–defined 4 when Pr(B) = 0) and we say that program P is infeasible from state σ, meaning that all its executions are blocked by observations.
As so defined, cwp[P ](f ) represents the weakest conditional pre–expectation of

4 In the continuous setting we could define a conditional density even when conditioning on events with 0 measure using the Radon–Nikodym theorem. However, our programs generate discrete distributions only.



P	wp[P ](f )	cwp[P ](f, g)

skip	f	(f, g)
abort	0	(0, 1)
x := E	f [x/E]	(f [x/E], g[x/E])
observe (G)	— not defined —	χG · (f, g)
P1; P2	(wp[P1] ◦ wp[P2])(f )	(cwp[P1] ◦ cwp[P2])(f, g)
ite (G) {P1} {P2}  χG · wp[P1](f )+ χчG · wp[P2](f )	χG · cwp[P1](f, g)+ χчG · cwp[P2](f, g)
{P1} [p] {P2}	p · wp[P1](f )+ (1−p) · wp[P2](f )	p · cwp[P1](f, g)+ (1−p) · cwp[P2](f, g)
{P1} 2 {P2}	λσ• min{wp[P1](f )(σ), wp[P2](f )(σ)}  — not defined —
while (G) {Pj}	μ fˆ•  χG · wp[Pj](fˆ)+ χчG · f	μ±,±(fˆ, gˆ)• χG · cwp[Pj](fˆ, gˆ)+ χчG · (f, g)

P	wlp[P ](f )	cwlp[P ](f, g)

abort	1	(1, 1)
while (G) {Pj}	ν fˆ• χG · wp[Pj](fˆ)+ χчG · f	ν±,±(fˆ, gˆ)• χG · cwp[Pj](fˆ, gˆ)+ χчG · (f, g) 

Fig. 1. Definitions for the wp/wlp and cwp/cwlp operators. The wlp (cwlp) operator differs from wp (cwp) only for abort and the while–loop. Multiplication h · (f, g) is meant componentwise yielding (h · f, h · g). Likewise, addition (f, g)+ (f ′, g′) is meant componentwise yielding (f + f ′, g + g′).

P with respect to post–expectation f and cwp[·] generalizes the transformer wp[·] to conditioned programs. The weakest liberal conditional pre–expectation cwlp[P ](f ) is defined analogously, in terms of the transformer cwlp[P ]: E≤1 × E≤1 → E≤1 × E≤1. We are only left to provide definitions for cwp[P ] and cwlp[P ]. Both trans- formers are defined by induction on the structure of P , following the rules in Fig- ure 1. Let us briefly explain these rules. cwp[skip] behaves as the identity since skip has no effect. cwp[abort] maps any pair of post–expectations to the pair of constant pre–expectations (0, 1). Assignments induce a substitution on expec- tations, i.e. cwp[x := E] maps (f, g) to pre–expectation (f [x/E], g[x/E]), where h[x/E](σ) = h(σ[x/E]) and σ[x/E] denotes the usual variable update on states. cwp[P1; P2] is obtained as the functional composition (denoted ◦) of cwp[P1] and cwp[P2]. cwp[observe (G)] restricts post–expectations to those states that satisfy G; states that do not satisfy G are mapped to 0. cwp[ite (G) {P1} {P2}] behaves either as cwp[P1] or cwp[P2] according to the evaluation of G. cwp[{P1} [p] {P2}] is obtained as a convex combination of cwp[P1] and cwp[P2], weighted according to p. cwp[while (G) {Pj}] is defined using standard fixed point techniques. 5 The cwlp transformer follows the same rules as cwp, except for the abort and while statements.	cwlp[abort] takes any post–expectation to pre–expectation (1, 1); cwlp[while (G) {P}] is defined in terms of a greatest rather than a least fixed point. Observe that Figure 1 presents no rule for the non–deterministic choice operator.
Therefore our conditional expectation transformers cwp/cwlp can only handle fully
probabilistic cpGCL programs. In Section 6 we elaborate on this limitation.
Example 3.1 Assume we want to compute the expected value of the expression

5 We define cwp[while (G) {P }] as the least fixed point w.r.t. the order (±, ±) in E × E≤1 . This way we encode the greatest fixed point in the second component w.r.t. the order ± over E≤1 as the least fixed point
w.r.t. the dual order ±.

10+x after executing program Pj given as:
1: {x := 0} [1/2] {x := 1};
2: ite (x = 1) {y := 0} [1/2] {y := 2}	{y := 0} [4/5] {y := 3} ;
3: observe (y=0)
The computation of cwp[Pj](10+x, 1) goes as follows:

cwp[Pj](10+x, 1)= cwp[Pj
= cwp[Pj
= cwp[Pj
= cwp[Pj
](cwp[observe (y=0)](10+x, 1))
](f, g) where (f, g)= χy=0 · (10+x, 1)
](cwp[ite (x=1) {.. .} {.. .}](f, g))
](χx=1 · (h, i)+ χx/=1 · (hj, ij)) where

(h, i)= cwp[{y := 0} [1/2] {y := 2}](f, g)= 1 · (10 + x, 1) , and

1) = 27 , 13	.
The expected value of 10+x is then given by cwp[P j](10+x)= 27 / 13 = 135 ≈ 10.38.
4  20	13
In the rest of this section we investigate some properties of the expectation transformer semantics (of the fully probabilistic fragment) of cpGCL. As every fully probabilistic pGCL program is contained in cpGCL, we begin by studying the relation between the w(l)p–semantics of pGCL and the cw(l)p–semantics of cpGCL. To that end, we extend the w(l)p operator to cpGCL by the clauses wp[observe (G)](f )= χG · f and wlp[observe (G)](f )= χG · f . Our first result says that cwp (resp. cwlp) can be decoupled as the product wp × wlp (resp. wlp × wlp).
Lemma 3.2 (Decoupling of cw(l)p) Let P be a fully probabilistic cpGCL pro- gram, f ∈ E and fj,g ∈ E≤1. Then cwp[P ](f, g) = wp[P ](f ), wlp[P ](g) and cwlp[P ](fj, g)= wlp[P ](fj), wlp[P ](g) .
Our next result shows that the cwp–semantics is a conservative extension of the wp–semantics for the fully probabilistic fragment of pGCL. The same applies to the weakest liberal pre–expectation semantics.
Theorem 3.3 (Compatibility with the w(l)p–semantics) Let P be a fully probabilistic pGCL program, f ∈ E, and g ∈ E≤1. Then wp[P ](f ) = cwp[P ](f ) and wlp[P ](g)= cwlp[P ](g).
Proof. By Lemma 3.2 and the fact that wlp[P ](1)= 1 (see Lemma 3.4).	2
We now show that cwp and cwlp preserve the so–called healthiness conditions of wp and wlp.
Lemma 3.4 (Healthiness conditions of cwp and cwlp) For every fully proba- bilistic cpGCL program P with at least one feasible execution (from every initial state), every f, g ∈ E and non–negative real constants α, β:
f ± g implies cwp[P ](f ) ± cwp[P ](g) and likewise for cwlp (monotonicity).

cwp[P ](α · f + β · g)= α · cwp[P ](f )+ β · cwp[P ](g) (linearity).
cwp[P ](0)= 0 and cwlp[P ](1)= 1.
Proof. Using Lemma 3.2 one can show that the transformers cwp and cwlp inherit these properties from wp and wlp. For details see [12, p. 15].	2
We conclude this section by discussing alternative approaches for providing an expectation transformer semantics for P ∈ cpGCL. By Lemma 3.2, the transformers cwp[P ] and cwlp[P ] can be recast as

f '→
wp[P ](f )
wlp[P ](1)
and	f '→
wlp[P ](f )
,
wlp[P ](1)

respectively. An alternative is to normalize using wp instead of wlp in the denomi- nator, yielding the two transformers


i) f '→
wp[P ](f )
wp[P ](1)
and	ii) f '→
wlp[P ](f )
.
wp[P ](1)

Transformer ii) is not meaningful, as the denominator wp[P ](1)(σ) may be smaller than the numerator wlp[P ](f )(σ) for some state σ ∈ S. This might lead to proba- bilities exceeding one. Transformer i) normalizes w.r.t. the terminating executions. This interpretation corresponds to the semantics of the probabilistic programming language R2 [22,16] and is only meaningful if programs terminate almost surely (i.e. with probability one). A noteworthy consequence of adopting transformer i) is that observe (G) is equivalent to while (¬G) {skip} [16], see the discussion in Section 5. Let us briefly compare the four alternatives by means of a concrete program P :
abort [1/2] {x := 0} [1/2] {x := 1}; {y := 0} [1/2] {y := 1}; observe (x=0 ∨y=0)
P tosses a fair coin and according to the outcome either diverges or tosses a fair coin twice and observes at least once heads (y=0 ∨ x=0). We measure the probability that the outcome of the last coin toss was heads according to each transformer:


wp[P ](χy=0) = 2
wlp[P ](χy=0) = 6
wp[P ](χy=0) = 2
wlp[P ](χy=0) =2 

wlp[P ](1)	7
wlp[P ](1)	7
wp[P ](1)	3
wp[P ](1)

As mentioned before, the transformer ii) is not significant as it yields a “probability” exceeding one. Note that our cwp–semantics yields that the probability of y=0 after the execution of P while passing all observe–statements is 2 . As shown before, this is a conservative and natural extension of the wp–semantics. This does not apply to the R2–semantics, as this would require an adaptation of rules for abort and while.
Operational Semantics for Conditional pGCL
This section presents an operational semantics for cpGCL using Markov decision processes (MDPs) as underlying model. We begin by recalling the notion of MDPs.

For that, let Distr (S) denote the set of distributions μ : S → R over S with
s∈S μ(s)= 1.
Definition 4.1 An MDP is a tuple R = (S, sI , Act , P, L) with a countable set of states S, an initial state sI ∈ S, a finite set of actions Act , a transition probability function P : S × Act → Distr (S) with  s′∈S P(s, α)(sj) = 1 for all (s, α) ∈ S ×Act and a labeling function L : S → 2AP for a set of atomic propositions AP .
A function r : S → R≥0 is used to add rewards to an MDP. A path of R is a finite or infinite sequence π = s0α0s1α1 ... such that si ∈ S, αi ∈ Act , s0 = sI, and P(si, αi)(si+1) > 0 for all i ≥ 0. The i-th state si of π is denoted π(i). The set of all paths of R is denoted by PathsR. PathsR(s) is the set of paths starting in s and PathsR(s, sj) is the set of all finite paths starting in s and ending in sj. This is also lifted to sets of states. We sometimes omit superscript R in PathsR.
MDPs operate by a non–deterministic choice of an action α ∈ Act that is enabled at state s and a subsequent probabilistic determination of a successor state according to P(s, α). For resolving the non–deterministic choices, so–called schedulers are used. Here, deterministic and memoryless schedulers suffice which are functions S: S → Act . Let Sched R denote the class of all such schedulers for R.
For MDP R, the fully probabilistic system SR induced by a scheduler S ∈ Sched R is called the induced Markov Chain (MC) on which a probability measure over paths is defined. The measure PrY for MC R is given by PrY : PathsY → [0, 1] ⊆ R with PrY(πˆ) =  n—1 P(si, si+1), for a finite path πˆ = s0 ... sn. This is lifted to infinite paths using the standard cylinder set construction, see [2, Ch. 10]. The cumulated reward of a finite path πˆ = s0 ... sn is given by r(πˆ)=  n—1 r(si). Note that in our special setting the cumulated reward will not be infinite.
We consider reachability properties ♦ T for a set of target states T ⊆ S where
T also denotes all paths that reach T from the initial state sI. Analogously, the set ¬♦ T contains all paths that never reach a state in T .
First, consider reward objectives for MCs. The expected reward for a count- able set of paths ♦ T is given by ExpRewY (♦ T ) = πˆ∈♦ T PrY(πˆ) · r(πˆ). For a reward bounded by one, the notion of the liberal expected reward also takes the mere probability of not reaching the target states into account: LExpRewY (♦ T )= ExpRewY (♦ T )+ PrY(¬♦ T ). To exclude the probability of paths that reach “un- desired” states, we let U = {s ∈ S | ∈ L(s)} and define the conditional expected reward for the condition ¬♦ U by 6


CExpRewY
(♦ T | ¬♦ U )  ,
ExpRewY (♦ T ∩ ¬♦ U ) PrY(¬♦ U )	.

Reward objectives for MDPs are now defined using a demonic scheduler S ∈ Sched R minimizing probabilities and expected rewards for the induced MC SR. For the ex- pected reward this yields ExpRewR (♦ T ) = inf	ExpRewSR (♦ T ). For con-

6 Note that strictly formal one would have to define the intersection of sets of finite and possibly infinite paths by means of a cylinder set construction considering all infinite extensions of finite paths.

ditional expected reward properties, the value of the quotient is minimized:
ExpRewSR (0 T ∩ ¬0 U )

CExpRewR (0 T | ¬0 U ) ,	inf
S∈Sched R
.
PrSR(¬0 U )

The liberal reward notions for MDPs are analogous. Regarding the quotient min-
imization we assume “ 0 < 0” as we see 0 —being undefined—to be less favorable
than 0. For details about conditional probabilities and expected rewards see [3].
The structure of the operational

MDP ofa cpGCL program is depicted on the right. Terminating runs even- tually end up in the ⟨sink ⟩ state; other runs are diverging (never reach
⟨sink ⟩). A program terminates either successfully, i.e. a run passes a C– labelled state, or terminates due to a


⟨init ⟩
⟨ ⟩


⟨sink ⟩

violation of an observation, i.e. a run passes ⟨ ⟩. Squiggly arrows indicate reaching certain states via possibly multiple paths and states; the clouds indicate that there might be several states of the particular kind. The C–labelled states are the only ones with positive reward. Note that the sets of paths that eventually reach ⟨ ⟩, or C, or diverge are pairwise disjoint.
Definition 4.2 [Operational cpGCL semantics] The operational semantics of P ∈ cpGCL for σ ∈ S and f ∈ E is the MDP Rf JP ) = (S, ⟨P, σ⟩, Act , P, L, r), such that S is the smallest set of states with ⟨ ⟩∈ S, ⟨sink ⟩∈ S, and ⟨Q, τ⟩, ⟨↓, τ⟩∈ S for Q ∈ pGCL and τ ∈ S. ⟨P, σ⟩∈ S is the initial state. Act = {left, right} is the set of actions. A state of the form ⟨↓, τ⟩ denotes a terminal state in which no program is left to be executed. P is formed according to SOS rules given in [12, p. 5].
For some τ ∈ S, the labelling and the reward function is given by:



L(s) ,
{C},	if s = ⟨↓, τ⟩
{sink },	if s = ⟨sink ⟩
{ },	if s = ⟨ ⟩
⎪⎩∅,	otherwise,

r(s) ,

f (τ ),	if s = ⟨↓, τ⟩
0,	otherwise .

To determine the conditional expected outcome of program P given that all ob- servations are true, we need to determine the expected reward to reach ⟨sink ⟩ from the initial state conditioned on not reaching ⟨ ⟩ under a demonic scheduler. For

Rf JP ) this is given by CExpRew
Rf JP )
(0sink | ¬0 ). Recall for the condition ¬0 

that all paths not eventually reaching ⟨ ⟩ either diverge (thus collect reward 0) or pass by a C–labelled state and eventually reach ⟨sink ⟩. This gives us:

S f

CExpRew
Rf JP )
(0sink | ¬0 ) =	inf
ExpRew Rσ JP ) (0sink ∩ ¬0 )



f	S f

S∈Sched Rσ JP )
Pr Rσ JP )(¬0 )

S f

=	inf
ExpRew
S
Rσ JP ) (0sink )
.
f

f
S∈Sched Rσ JP )
Pr RσJP )
(¬0 )



The liberal version CLExpRew
Yf JP )
(0sink | ¬0 ) is defined analogously.

Example 4.3 Consider the program P ∈ cpGCL:
{{x := 5} 2 {x := 2}} [q] {x := 2}; observe (x>3)
where with parametrized probability q a non–deterministic choice between x being assigned 2 or 5 is executed, and with probability 1−q, x is directly assigned 2. Let for readability P1 = {x := 5} 2 {x := 2}, P2 = x := 2, P3 = observe (x>3), and P4 = x := 5. The operational MDP Rx JP ) for an arbitrary initial variable valuation σI and post–expectation x is depicted below:
⟨P, σI ⟩



⟨P4; P3, σI ⟩

left
⟨P1; P3, σI ⟩

right
⟨P2; P3, σI ⟩


	


⟨↓; P3, σI[x/5]⟩


5
⟨P3, σI[x/5]⟩

⟨↓, σI[x/5]⟩

 
⟨sink ⟩
⟨↓; P3, σI[x/2]⟩
⟨ P3, σI[x/2]⟩  ⟨ ⟩

The only state with positive reward is sj := ⟨↓, σI[x/5]⟩ and its reward is indicated by number 5. Assume first a scheduler choosing action left in state ⟨P1; P3, σI ⟩. In the induced MC the only path accumulating positive reward is the path π going from ⟨P, σI ⟩ via sj to ⟨sink ⟩ with r(π) = 5 and Pr(π)= q. This gives an expected reward of 5 · q. The overall probability of not reaching ⟨ ⟩ is also q. The conditional expected reward of eventually reaching ⟨sink ⟩ given that ⟨ ⟩ is not reached is hence

5·q
q
= 5. Assume now the demonic scheduler choosing right at state ⟨P1; P3, σI ⟩.

In this case there is no path having positive accumulated reward in the induced
MC, yielding an expected reward of 0. The probability of not reaching ⟨ ⟩ is also 0. The conditional expected reward in this case is undefined (0/0) and thus the right branch is preferred over the left branch. In general, the operational MDP need not be finite, even if the program terminates almost–surely (i.e. with probability 1).
We now investigate the connection to the denotational semantics of Section 3, starting with some auxiliary results. First, we establish a relation between (liberal) expected rewards and weakest (liberal) pre–expectations.
Lemma 4.4 For any fully probabilistic P ∈ cpGCL, f ∈ E,g ∈ E≤1, and σ ∈ S:


ExpRew
Yf JP )
(0⟨sink ⟩)= wp[P ](f )(σ)	(i)

LExpRew
Yg JP )
(0⟨sink ⟩)= wlp[P ](g)(σ)	(ii)

Moreover, the probability of never reaching ⟨ ⟩ in the MC of program P coincides with the weakest liberal pre–expectation of P w.r.t. post–expectation 1:
Lemma 4.5 For any fully probabilistic P ∈ cpGCL, g ∈ E≤1, and σ ∈ S we have
Yg JP )
Pr σ	(¬0 )= wlp[P ](1)(σ).
We now have all prerequisites in order to present the main result of this section: the correspondence between the operational and expectation transformer seman- tics of fully probabilistic cpGCL programs. It turns out that the weakest (liberal) pre–expectation cwlp[P ](f )(σ) (resp. cwlp[P ](f )(σ)) coincides with the conditional (liberal) expected reward in the RMC Rf JP ) of terminating while never violating an observe–statement, i.e., avoiding the ⟨ ⟩ states.
Theorem 4.6 (Correspondence theorem) For any fully probabilistic P  ∈
cpGCL, f ∈ E, g ∈ E≤1 and σ ∈ S,


CExpRew CLExpRew
Yf JP ) Yg JP )
(0sink | ¬0 ) = cwp[P ](f )(σ)
(0sink | ¬0 ) = cwlp[P ](g)(σ) .

Proof. The proof makes use of Lemmas 4.4, 4.5, and Lemma 3.2 which are themselves proven by induction on the structure of P .  For details see [12, p. 13-14, 16-21].	2

Program Transformation
In this section we present a program transformation for removing observations from fully probabilistic cpGCL programs and use the expectation transformer semantics from Section 3 to prove the transformation correct. Intuitively, the presented pro- gram transformation “hoists” the observe statements while updating the probabili- ties of the probabilistic choices. Given a fully probabilistic program P ∈ cpGCL, the
transformation delivers a semantically equivalent observe–free program Pˆ ∈ pGCL
and—as a side product—an expectation hˆ ∈ E≤1 that captures the probability that the original program establishes all observe statements. For an intuition, reconsider
the program from Example 3.1. The transformation yields program
{x := 0} [8/13] {x := 1}; ite (x=1) {{y := 0} [1] {y := 2}}{{y := 0} [1] {y := 3}}
and expectation hˆ = 13 . By eliminating dead code in both probabilistic choices
and coalescing the branches in the conditional, we can simplify the program to
{x := 0} [8/13] {x := 1}; y :=0 
As a sanity check note that the expected value of 10+x in this program is equal

to 10 ·  8
+ 11 ·  5
= 135 , which agrees with the result obtained by analyzing the



T (skip,f)	= (skip,f)
T (abort,f)	= (abort, 1)
T (x := E, f )	= (x := E, f [E/x])
T (observe (G),f)	= (skip, χG · f )
T (ite (G) {P} {Q},f ) = (ite (G) {Pj} {Qj}, χG · fP + χчG · fQ) where
(P j, fP )= T (P, f ), (Qj, fQ)= T (Q, f )
T ({P} [p] {Q},f)	= ({Pj} [pj] {Qj},p · fP + (1−p) · fQ) where
(P j, fP )= T (P, f ), (Qj, fQ)= T (Q, f ), pj = 	p·fP	
P	Q
T (while (G) {P},f)	= (while (G) {Pj},fj) where
fj = ν X• (χG · (π2 ◦T )(P, X)+ χчG · f ) , (P j, )= T (P, fj)
T (P ; Q, f )	= (P j; Qj,fjj) where (Qj,fj)= T (Q, f ), (P j,fjj)= T (P, fj)

Fig. 2. Program transformation for eliminating observe statements in fully probabilistic cpGCL programs.
original program. Formally, the program transformation is given by a function
T : cpGCL × E≤1 → pGCL × E≤1 .

To apply the transformation to a program P we need to determine T (P, 1), which gives the semantically equivalent program Pˆ and the expectation hˆ.
The transformation is defined in Figure 2 and works by inductively comput- ing the weakest pre–expectation that guarantees the establishment of all observe– statements and updating the probability parameter of probabilistic choices so that the pre–expectations of their branches are established in accordance with the origi- nal probability parameter. The computation of these pre–expectations is performed following the same rules as the wlp operator. The correctness of the transforma- tion is established by the following Theorem, which states that a program and its transformed version share the same terminating and non–terminating behavior.
Theorem 5.1 (Program Transformation Correctness) Let P be a fully prob- abilistic cpGCL program that admits at least one valid run for every initial state and let T (P, 1) = (Pˆ, hˆ). Then for any f ∈ E and g ∈ E≤1, we have wp[Pˆ](f ) = cwp[P ](f ) and wlp[Pˆ](g)= cwlp[P ](g).
Proof. See [12, p. 21].	2
A similar program transformation has been given by Nori et al. [22]. Whereas they use random assignments to introduce randomization in their programming model, we use probabilistic choices. Consequently, they can hoist observe– statements only until the occurrence of a random assignment, while we are able to hoist observe–statements over probabilistic choices and completely remove them from programs. Another difference is that the semantics of Nori et al. only ac- counts for terminating program behaviors and thus they can guarantee the correct- ness of the program transformation for almost–surely terminating programs only. Our semantics is more expressive and enables establishing the correctness for non– terminating program behavior, too.

Denotational Semantics for Full cpGCL
In this section we argue why (under mild assumptions) it is not possible to provide a denotational semantics in the style of conditional pre–expectation transformers (CPETs for short) for full cpGCL, i.e. including non–determinism. To show this, it suffices to consider a simple fragment of cpGCL containing only assignments, ob- servations, probabilistic and non–deterministic choices. Let x be the only program variable that can be written or read in this fragment. We denote this fragment by cpGCL—. Assume D is some appropriate domain for representing conditional expectations of the program variable x with respect to some ﬁxed initial state σ0 and let J · ) : D → R ∪ {⊥} be an interpretation function such that for any d ∈ D we have that Jd) is equal to the (possibly undefined) conditional expected value of x.
Definition 6.1 [Inductive CPETs] A CPET is a function cwp∗ : cpGCL— → D

such that for any P ∈ cpGCL—
, Jcwp[P ]) = CExpRew
Rx JP )
0
(0 sink | ¬0 ). cwp∗

is called inductive, if there exist two functions K : cpGCL— × [0, 1] × cpGCL— → D and N : cpGCL— × cpGCL— → D, such that for any P1, P2 ∈ cpGCL— we have cwp∗[{P1} [p] {P2}] = K(cwp∗[P1], p, cwp∗[P2]) and cwp∗[{P1} 2 {P2}] =
N (cwp∗[P1], cwp∗[P2]), where ∀d1, d2 ∈ D• N (d1, d2) ∈ {d1, d2}.
This definition suggests that the conditional pre–expectation of {P1} [p] {P2} is de- termined only by the conditional pre–expectation of P1 and P2, and the probability
p. Furthermore the above definition suggests that the conditional pre–expectation of {P1} 2 {P2} is also determined by the conditional pre–expectation of P1 and P2 only. Consequently, the non–deterministic choice can be resolved by replacing it ei- ther by P1 or P2. While this might seem like a strong limitation, the above definition is compatible with the interpretation of non–deterministic choice as demonic choice: The choice is deterministically driven towards the worst option. The requirement N (d1, d2) ∈ {d1, d2} is also necessary for interpreting non–deterministic choice as an abstraction where implementation details are not important.
As we assume a fixed initial state and a fixed post–expectation, the non– deterministic choice turns out to be deterministic once the pre–expectations of P1 and P2 are known. Under the above assumptions (which do apply to the wp and wlp transformers) we claim:
Theorem 6.2 There exists no inductive CPET.
Proof. [Sketch] (for details, see [12, p. 11]). By contradiction: Consider the pro- gram P = {P1} [1/2] {P5} with
P1 :	x :=1 
P5 :	{P2} 2 {P4}
P2 :	x :=2 
P4 :	{observe false} [1/2] {P3}
P3 :	x := 2.2



⟨P⟩
	

⟨P1⟩
1
⟨P5⟩



⟨P2⟩
2
⟨P4⟩
	
	⟨P3⟩
2.2

Fig. 3. Schematic depiction of the RMDP Rx JP )


A schematic depiction of the Rx JP ) is given in Figure 3. Assume there exists an inductive CPET cwp∗ over some appropriate domain D. With the program given above, one can get to the contradiction Jcwp∗[P5]) = Jcwp∗[P4]) > Jcwp∗[P2]) = Jcwp∗[P5]).	2

As an immediate corollary of Theorem 6.2 we obtain the following result:
Corollary 6.3 We cannot extend the cwp or cwlp rules in Figure 1 for non– deterministic programs such that Theorem 4.6 extends to full cpGCL.
This result is related to Varacca and Winskel’s work [27], who have already noticed the difficulties that arise when trying to integrate non–determinism and probabili- ties, even in the absence of conditioning. When conditioning is taken into account, Andr´es and van Rossum [1] have also observed that positional schedulers—i.e. the kind of schedulers implicitly considered in the expectation transformer semantics— are not sufficient for minimizing probabilities. In contrast to our work, their devel- opment is done in the context of temporal logics.

Conclusion and Future Work
This paper presented an extensive treatment of semantic issues in probabilistic pro- grams with conditioning. Major contributions are the treatment of non–terminating programs (both operationally and for weakest liberal pre–expectations), our results on combining non–determinism with conditioning, as well as the presented program transformation. We firmly believe that a thorough understanding of these seman- tic issues provides a main cornerstone for enabling automated analysis techniques such as loop invariant synthesis [5,18], program analysis [6] and model checking [3] to the class of probabilistic programs with conditioning. Future work consists of investigating conditional invariants and a further investigation of non–determinism in combination with conditioning.

Acknowledgment
We would like to thank Pedro D’Argenio and Tahiry Rabehaja for the valuable discussions preceding this paper.

References
Andr´es, M. E. and P. van Rossum, Conditional probabilities over probabilistic and nondeterministic systems, in: Proc. of TACAS, LNCS 4963 (2008), pp. 157–172.
Baier, C. and J. Katoen, “Principles of Model Checking,” MIT Press, 2008.
Baier, C., J. Klein, S. Klu¨ppelholz and S. M¨arcker, Computing conditional probabilities in Markovian models efficiently, in: Proc. of TACAS, LNCS 8413 (2014), pp. 515–530.
Barthe, G., B. K¨opf, F. Olmedo and S. Z. B´eguelin, Probabilistic relational reasoning for differential privacy, ACM Trans. Program. Lang. Syst. 35 (2013), p. 9.
Chakarov, A. and S. Sankaranarayanan, Expectation invariants for probabilistic program loops as fixed points, in: Proc. of SAS, LNCS 8723 (2014), pp. 85–100.
Cousot, P. and M. Monerau, Probabilistic abstract interpretation, in: H. Seidl, editor, Proc. of ESOP, LNCS 7211 (2012), pp. 169–193.
Dijkstra, E. W., “A Discipline of Programming,” Prentice Hall, 1976.
Goodman, N. D., V. K. Mansinghka, D. M. Roy, K. Bonawitz and J. B. Tenenbaum, Church: a language for generative models, in: Proc. of UAI (2008), pp. 220–229.
Goodman, N. D. and A. Stuhlmu¨ller, “The Design and Implementation of Probabilistic Programming Languages.” (electronic), 2014, http://dippl.org.
Gordon, A. D., T. Graepel, N. Rolland, C. V. Russo, J. Borgstro¨m and J. Guiver, Tabular: a schema- driven probabilistic programming language, in: Proc. of POPL (2014), pp. 321–334.
Gordon, A. D., T. A. Henzinger, A. V. Nori and S. K. Rajamani, Probabilistic programming, in: Proc. of FOSE (2014), pp. 167–181.
Gretz, F., N. Jansen, B. L. Kaminski, J.-P. Katoen, A. McIver and F. Olmedo, Conditioning in probabilistic programming, CoRR abs/1504.00198 (2015).
Gretz, F., J.-P. Katoen and A. McIver, Operational versus weakest pre-expectation semantics for the probabilistic guarded command language, Perform. Eval. 73 (2014), pp. 110–132.
Gupta, V., R. Jagadeesan and P. Panangaden, Stochastic processes as concurrent constraint programs, in: Proc. of POPL (1999), pp. 189–202.
Gupta, V., R. Jagadeesan and V. A. Saraswat, Probabilistic concurrent constraint programming, in:
Concurrency Theory, LNCS 1243 (1997), pp. 243–257.
Hur, C.-K., A. V. Nori, S. K. Rajamani and S. Samuel, Slicing probabilistic programs, in: Proc. of PLDI
(2014), pp. 133–144.
Jones, C. and G. D. Plotkin, A probabilistic powerdomain of evaluations, in: Logic in Computer Science
(1989), pp. 186–195.
Katoen, J.-P., A. McIver, L. Meinicke and C. C. Morgan, Linear-invariant generation for probabilistic programs, in: Proc. of SAS, LNCS 6337 (2010), pp. 390–406.
Kozen, D., Semantics of probabilistic programs, J. Comput. Syst. Sci. 22 (1981), pp. 328–350.
Kozen, D., A probabilistic {PDL}, Journal of Computer and System Sciences 30 (1985), pp. 162 – 178.
McIver, A. and C. Morgan, “Abstraction, Refinement And Proof For Probabilistic Systems,” Springer, 2004.


Nori, A. V., C. Hur, S. K. Rajamani and S. Samuel, R2: an efficient MCMC sampler for probabilistic programs, in: Proceedings of the Twenty-Eighth AAAI Conference on Artificial Intelligence, 2014, pp. 2476–2482.
Paige, B. and F. Wood, A compilation target for probabilistic programming languages, in: Proc. of ICML, JMLR Proceedings 32 (2014), pp. 1935–1943.
Puterman, M., “Markov Decision Processes: Discrete Stochastic Dynamic Programming,” John Wiley and Sons, 1994.
Sampson, A., P. Panchekha, T. Mytkowicz, K. S. McKinley, D. Grossman and L. Ceze, Expressing and verifying probabilistic assertions, in: Proc. of PLDI (2014), p. 14.
Scott, D. S., Stochastic λ-calculi: An extended abstract, J. Applied Logic 12 (2014), pp. 369–376.
Varacca, D. and G. Winskel, Distributing probability over non-determinism, Mathematical. Structures in Comp. Sci. 16 (2006), pp. 87–113.
