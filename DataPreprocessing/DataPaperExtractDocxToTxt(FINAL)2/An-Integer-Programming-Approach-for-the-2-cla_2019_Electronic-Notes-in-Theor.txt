Available online at www.sciencedirect.com


Electronic Notes in Theoretical Computer Science 346 (2019) 321–331
www.elsevier.com/locate/entcs

An Integer Programming Approach for the 2-class Single-group Classification Problem
Ricardo C. Corrˆea1
Universidade Federal Rural do Rio de Janeiro Departamento de Ciˆencia da Computa¸c˜ao
Av. Governador Roberto Silveira S/N, 26020-740 Nova Iguac¸u - RJ, Brazil
Manuela Blaum, Javier Marenco 2
Universidad Nacional de General Sarmiento, Instituto de Ciencias
J. M. Guti´errez 1150, Malvinas Argentinas, (1613) Buenos Aires, Argentina
Ivo Koch 3
Universidad Nacional de General Sarmiento, Instituto de Industria
J. M. Guti´errez 1150, Malvinas Argentinas, (1613) Buenos Aires, Argentina
Marcelo Mydlarz 4
Universidad Nacional de General Sarmiento, Instituto de Industria
J. M. Guti´errez 1150, Malvinas Argentinas, (1613) Buenos Aires, Argentina
CONICET, Argentina

Abstract
Two sets XB, XR ⊆ Rd are linearly separable if their convex hulls are disjoint, implying that a hyperplane separating XB from XR exists. Such a hyperplane provides a method for classifying new points, according to the side of the hyperplane in which the new points lie. In this work we consider a particular case of the 2-class classification problem, which asks to select the maximum number of points from XB and XR in such a way that the selected points are linearly separable. We present an integer programming formulation for this problem, explore valid inequalities for the associated polytope, and develop a cutting plane approach coupled with a lazy-constraints scheme.
Keywords: classification, integer programming, polyhedral combinatorics


1 Email: correa@ufrrj.br
2 Email: mblaum@ungs.edu.ar, jmarenco@ungs.edu.ar
3 Email: ikoch@ungs.edu.ar
4 Email: mmydlarz@ungs.edu.ar

https://doi.org/10.1016/j.entcs.2019.08.029
1571-0661/© 2019 The Author(s). Published by Elsevier B.V.
This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).

Introduction
Classification problems with supervised learning involve separating training samples into categories, in such a way that future samples can be automatically categorized based on the categorization of the training samples. In this work, we are interested in a particular case of the 2-class classification problem, an optimization problem that arises within this context.
We are given a set X = {x1,..., xm}⊆ Rd of samples (also referred to as points) and a partition of the index set [m] := {1,..., m} into two classes B and R, defining subsets XB = {xi : i ∈ B} and XR = {xj : j ∈ R}. The sets of points XB and XR are said to be linearly separable if and only if conv(XB) ∩ conv(XR)= ∅, where conv(X) denotes the convex hull of X. The linear separability of XB and XR is characterized by the fact that no vector (λ1,..., λm) ≥ 0 satisfies
Σ λixi = Σ λjxj,	and	Σ λi = Σ λj = 1.

i∈B
j∈R
i∈B
j∈R

The objective of the 2-class single-group classiﬁcation problem is to determine sub- sets of XB and XR that are linearly separable, maximizing the sum of their cardi- nalities. Formally, we want to find XS ⊆ XB and XT ⊆ XR maximizing |XS| + |XT |, and such that XS and XT are linearly separable. The points in XO := X\(XS ∪ XT ) are called outliers, and the objective function of the problem implies that |XO| is to be minimized.
A wide range of continuous optimization methods for this problem, including linear and quadratic programming, have been developed in the last years [4,6,8]. More recently, integer linear programming tools started to be used in conjunction with continuous methods [7,9,10,11]. The 2-class single-group classification problem is a particular case of the 2-class classiﬁcation problem introduced in [3]. In this more general setting, besides the set of points X partitioned into classes XB and XR, we are given numbers nB, nR ∈ Z+, and the goal is to find a set XO as small as possible of outliers so that XB \ XO and XR \ XO can be partitioned into nB and nR subsets, respectively, and each of the nB subsets of XB \ XO is linearly separable from each of the nR subsets of XR \ XO.
Corrˆea, Delle Donne, and Marenco [5] consider a mixed integer programming formulation for the 2-class classification problem, and explore facet-inducing in- equalities for the associated polytope. Here we present a pure integer program- ming formulation (i.e., containing binary variables only) for the 2-class single-group classification problem, extending and strengthening the results presented in [5] to this particular setting. Our goal is to study the combinatorics associated with the problem, with the objective of designing efficient integer-programming based com- putational procedures for this problem. Besides the theoretical interest, such a study is of practical relevance since the obtained computational methods could be used within general classification tools. In order to give a first evaluation of this potential, we also present preliminary computational results for this formulation.
The remainder of this paper is organized as follows. Section 2 presents the integer

programming formulation for the problem and a general family of valid inequalities for the associated polytope. Section 3 shows the lazy-constraints scheme used to tackle the exponential number of constraints in the model. Section 4 introduces a separation procedure for these inequalities, and Section 5 reports our computational experience. Finally, Section 6 provides final remarks.
Integer programming formulation and valid inequal- ities
The mixed integer programming formulation presented in [5] includes binary vari- ables representing the assignment of points to groups, and continuous variables rep- resenting the hyperplanes that separate each pair of groups from different classes. In this work, we consider a formulation that only resorts to variables of the first kind, that is, binary variables representing the assignment of points to groups. Since we consider a single group for each class of points, these binary variables determine the selected points (i.e., points that are not declared to be outliers). The formulation can be extended to the multi-group case in a straightforward way.
For i ∈ [m], we introduce the binary variable zi representing whether xi is
chosen (z = 1) or not (z = 0). The 2-class single-group classification problem can be modeled as the problem of maximizing Σi∈B zi + Σj∈R zj subject to the constraint that the sets {xi : zi = 1,i ∈ B} and {xj : zj = 1,j ∈ R} are linearly
separable. Given an instance I = (X, B, R) of the problem, we call PI the convex
hull of the points z ∈ {0, 1}m satisfying the linear separability constraints. These constraints imply that any feasible solution z satisfies the S, T-inequality
Σ zi + Σ zj ≤ |S| + |T|− 1	(1)
i∈S	j∈T
for every S ⊆ B and every T ⊆ R such that XS and XT are not linearly separable. These inequalities restrict the selected points from each class to indeed correspond to a feasible solution, and –together with the integrality constraints– can be used as constraints defining PI . As we will show below, the inequality (1) is facet-inducing when XS and XT are minimal with respect to being linearly inseparable (i.e., when XS \ {xi} and XT \ {xi} are linearly separable for every i ∈ S ∪ T ).
Given two non-empty sets S ⊆ B and T ⊆ R such that XS and XT are not lineary separable, any minimum cardinality set N ⊂ S ∪ T such that XS \ XN and XT \ XN are linearly separable, plays a key role. We call N an N-set of S, T and define N (S, T ) := {N ⊆ S ∪ T : N is an N -set of S, T}, and, for i ∈ S ∪ T ,
νS,T (i) := min{|N| : i ∈ N and N ∈ N (S, T )}, or ∞ if no N ∈ N (S, T ) contains i.
We denote νS,T (i) by νi when S and T are clear from the context. This setting gives rise to what we call the N-inequality associated with S and T :

Σ 1 − zi + Σ 1 − zj

≥ 1,	(2)

νi
i∈S
νj
j∈T

where the coefficient of (1 − zi) is null if νi = ∞. This inequality generalizes facet- inducing inequalities explored in [5], corresponding to the cases where νi = 1 for every i ∈ S ∪ T . The following result, adapted from [5], illustrates this situation.
Theorem 2.1 ([5]) The inequality (2) deﬁnes a facet of P£ if (|T | =1 or (|T | =2 and xT ∩ conv(xS)= ∅)) and S is minimal with respect to the property conv(xT ) ∩ conv(xS) /= ∅ (i.e., conv(xT ) ∩ conv(xS′ )= ∅ for every Sj Ç S).
A more general result is given by the following theorem, also settling a question raised in [5]. To state this result, let GS,T = (S ∪ T, E) denote the safe graph of S, T in which an edge ij exists if there exist two N -sets Ni and Nj of equal size ν such that NiΔNj = {i, j} and νk = ν, for all k ∈ Ni ∪ Nj. Observe that νi = νj for each edge ij of GS,T , and by transitivity, νi′ = νj′ for each pair of vertices ij and jj connected in GS,T . In other words, νi = νj if i and j are two vertices in a

same connected component of GS,T . Let Gν
ν S,T
ν S,T
) denote the subgraph

of GS,T induced by V ν	= {i ∈ S ∪ T | νi = ν}.
Theorem 2.2 The inequality (2) is valid for P£. Moreover, if

for every ν ∈ N, V ν
= ∅ or ν =1 or (|V ν
| > 1 and Gν
is connected), and

for every i ∈ B \ S (resp. j ∈ R \ T ), there exists t ∈ S ∪ T and an N-set N with |N| = νt and νk = νt for every k ∈ N such that XS∪{i} \ XN and XT \ XN (resp. XS \ XN and XT ∪{j} \ XN ) are linearly separable,
then (2) deﬁnes a facet of P£.
It is interesting to note that the minimality hypothesis in Theorem 2.1 implies the hypothesis (ii) of Theorem 2.2. It is worth remarking that the facetness con- ditions specified by Theorem 2.2 hold for many simple structures, including those depicted in Fig. 1 for d = 2 and d = 3.
Checking for feasibility
Since the number of constraints in the model is exponential, we resort to the fol- lowing lazy constraint scheme in order to quickly detect infeasible integral points. According to [5], a fractional solution z¯ belongs to the linear relaxation of the integer programming formulation if and only the following linear programming formulation
max	2M − (M + 1) Σ υiz¯i + Σ υjz¯j 

i∈B
s.t.	Σ υixi = Σ υjxj
j∈R

i∈B	j∈R
Σ υi = Σ υj
i∈B	j∈R
υi ≤ z¯i,	i ∈ B
υj ≤ z¯j,	j ∈ R
(υB, υR) ≥ 0

1
1


(a)
Σ4
i=1
zi ≤ 3. Safe graph is

(b)
Σ zi

≤ 4. Safe graph is

complete.
1
i=1
complete.
3



2
4



(c)
Σ5
i=1
zi + 2z6 ≤ 5. Safe graph
(d)
Σ5
i=1
zi ≤ 4. Safe graph is

has two connected components.
3
complete.
3

6
2
5
2
4	6
7




(e) Σ
1

zi + 2z7 ≥ 2. Safe graph

(f)


Σ5
i=1

zi + 2z6 + 2z7 ≤ 7. Safe

i=1
has two connected components.
graph has two connected compo- nents.

Fig. 1. Facet defining structures according to Theorem 2.2. Solid segments represent the convex hull of their endpoints.



has a nonnegative optimal value, where M is a big positive number. This follows from the application of a classical result by Balas [2] to the mixed integer program- ming formulation for the 2-class classification problem considered in [5]. Since this model is a linear programming formulation, then it can be solved efficiently, hence such a feasibility check is of practical use.
Note that the feasibility of this linear programming model does not depend on the actual value of M , namely if M is small then some solutions are lost but the problem remains feasible. However, small values of M will lead to meaningless mathematical solutions. As observed in [1], setting M to a value a few orders of magnitude larger than the size of the box encapsulating the data points typically suffices to produce good quality solutions.

Separation procedures
The family of N -inequalities to consider has exponential size, hence separation procedures are needed for a practical implementation. We describe in this section an integer programming approach for performing such a separation. Although not guaranteed to run in polynomial time, the proposed approach turned out to be quite effective in practice.
Convex inclusion inequalities
Consider first the inequalities given by Theorem 2.1 when |T | = 1, called convex inclusion inequalities in [5] (see figures 1a and 1c for illustrations). Given a solution z¯ of the relaxed model, the separation problem for these inequalities consists in finding a point xj, j ∈ R, and a set S ⊆ B, such that xj ∈ conv(XS), and such that z¯j + i∈S z¯i > |S|. We call xj to be the center of the inequality. We restrict ourselves to a subset of the variables with fractional values, by considering the subsets BF = {i ∈ B | LB ≤ z¯i ≤ UB} and RF = {j ∈ R | LB ≤ z¯i ≤ UB}, where LB and UB are two parameters such that 0 ≤ LB < UB ≤ 1.
The separation can be accomplished with the following integer programming model. For each j ∈ R, we introduce the binary variable bj specifying whether xj is the center of the inequality or not. For each i ∈ B, we introduce the binary variable bi specifying whether i ∈ S. We also have a continuous variable λi ∈ [0, 1] for each i ∈ B, in sucha way that {λi}i∈B represent the multipliers associated with the points in XB showing that xj is a convex combination of the points selected to be included in the set S. In this setting, the separation problem can be formulated as follows.

max	Σ (z¯i − 1)bi + Σ z¯ibi
i∈BF	i∈RF
s.t.	Σ λixi = Σ bjxj	(3)
i∈BF	j∈RF
Σ λi = Σ bj =1	(4)
i∈BF	j∈RF
Σ bi = d +1	(5)
i∈BF
0 ≤ λi ≤ bi,	i ∈ BF	(6)
bi ∈ {0, 1},	i ∈ BF ∪ RF

The objective function asks to maximize the difference between the left-hand side and the right-hand-side of the inequality z¯j + Σi∈S z¯i ≤ |S|. Constraint (3) ensures that the selected point xj is indeed a convex combination of the points
selected to form S. Constraint (4) asserts that exactly one point in R is selected
(and this point will be xj in the inequality), and that the variables {λi}i∈B indeed represent a convex combination of the selected points from XB. Constraint (5) asks

to select exactly d + 1 points, which corresponds to the maximum number of points generating a minimal set S such that xj ∈ conv(XS). Finally, constraints (6) ensure that the convex combination in constraint (3) is taken among the selected points in S.


S, T-Inequalities
We can extend the idea discussed above in order to separate the S, T -inequalities (1). To this end, we again introduce a binary variable bi for each i ∈ B and a binary variable bj for each j ∈ R, representing whether the associated point is selected to belong to S and T , respectively. In this setting, we need conv(XS) ∩ conv(XB) /= ∅, and this is enforced with the introduction of a variable λi ∈ [0, 1] for each i ∈ B and a variable λj ∈ [0, 1] for each j ∈ R. The resulting model is as follows.


max	1 +	Σ
i∈BF ∪RF
(z¯i − 1)bi

s.t.	Σ λixi = Σ λjxj	(7)
i∈BF	j∈RF
Σ λi = Σ λj =1	(8)
i∈BF	j∈RF
Σ bj ≥ 2	(9)
i∈B
Σ bj ≥ 2	(10)
j∈RF
Σ bi + Σ bj ≤ d + 2	(11)
i∈BF	j∈RF
0 ≤ λt ≤ bt,	t ∈ BF ∪ RF	(12)
bt ∈ {0, 1},	t ∈ BF ∪ RF

Again, the objective function asks to maximize the difference between the left- hand-size and the right-hand-side of constraint (1) at the solution z¯. Constraint (7) asks for a nonempty intersection of conv(XS) and conv(XT ), by ensuring the ex- istence of coefficients {λi}i∈S and {λj}j∈T representing coincident convex combi- nations from each set. Constraint (8) asks these coefficients to indeed represent a convex combination. Constraints (9) and (10) ensure that |S| ≥ 2 and |T| ≥ 2, respectively, in order to avoid generating convex inclusion cuts. Constraint (11) asks to select at most d + 2 points, since this is the maximum value of |S| + |T | generating a minimal set of linearly inseparable points. Finally, constraints (12) ensure that the convex combination in constraint (3) is taken among the selected points in S and T .

Enforcing fractional variables
Contrary to the aim of the lazy constraints discussed in Section 3 (ensuring the feasibility of integral solutions), the purpose of the separation procedures described above is to cut fractional solutions. Since not all the constraints (1) are included in the model, a fractional solution can violate some of them –defined by subsets S and T corresponding to integral variables. Hence, in order to force fractional variables
in the generated cut, we add the constraint Σi∈BF fz¯i bi ≥ F , where fz¯i = 1 if
Dz¯i < LB +UB and fz¯i = 0 otherwise, for suitable values F, D ∈ R. The parameter D is set to a value such that fz¯i = 1 only if z¯i lies in the interval (LB, UB). The parameter F corresponds to a lower bound on the number of fractional variables in the generated cut.
Experiments
We have implemented a branch and cut procedure for the 2-class single-group clas- sification problem, based on the results and algorithms mentioned in the previous sections. In this section we provide some preliminary computational experiments with separation heuristics for some special cases of N -inequalities in order to explore such combinatorial methods as effective tools for solving classification problems. Our main goal with these experiments is not to provide a competitive algorithm for the 2-class single-group classification problem, since continuous optimization methods are much more effective than cutting-plane algorithms for this problem. Instead, we intend to assess whether combinatorial tools can potentially improve the overall efficiency when coupled to existing solution methods. To this end, we implemented a branch and bound algorithm to solve the basic formulation.
The initial model is composed by the z-variables with no constraints, and lazy constraints are dynamically added with the procedure mentioned in Section 3. This implementation was compared with the same algorithm when cuts are incorporated with the integer-programming-based separation procedures described in Section 4. The algorithm was coded in the Java programming language, using Cplex 12.8 as the linear programming solver (for the linear relaxations and checking for feasibility) and mixed integer programming solver (for the separation problems).
Table 1 summarizes the preliminary experiments with synthetic 2-class instances generated with the following random procedure. Initially, two points are defined in opposite sides and at distance 1 of a given hyperplane of dimension d − 1 to act as the centers of the two classes. Then, for each one of the centers, a cluster of points is created normally distributed about vertices of a d-dimensional hypercube with sides of length 2. Finally, a number of noise points are introduced in each class. For the results reported, the instances have 2500 random and 16 noise points and dimensions ranging from d =2 to d = 6. An illustration of the instance for d =2 is shown in Fig. 2.
For every instance, we report the number of nodes in the enumeration tree, the number of generated lazy constraints, the total running time in seconds, and the optimality gap (in %). The parameter M was set to 200 in all cases, which is two






Fig. 2. Instance for d = 2.
orders of magnitude larger than the coordinates of the instance points. The columns labeled “No cuts” correspond to the execution of the procedure with no additional cuts, besides the mandatory lazy constraints. The columns labeled “Inclusion cuts” correspond to the dynamical addition of the convex inclusion cuts, with the sepa- ration model presented in Section 4.1. The columns labeled “S, T -cuts” correspond to the dynamical addition of the S, T -cuts, with the separation model presented in Section 4.2. In both cases, the inequality found is added only if the objective value of the corresponding separation model is larger than a parameter V IOL. Finally, the results corresponding to the dynamical addition of S, T -cuts and, if it fails, followed by the dynamical addition of convex inclusion ones, appear in the columns labeled “Mixed”. Note that the parameters LB and D used in the separation procedures ensure that only fractional solutions are separated (such parameters for the convex inclusion and S, T -inequalities are identified with indices I and S, T , respectively). We conducted experiments with several combinations of values for LB and D. The results in Table 1 correspond to the best configuration for each case.
As Table 1 suggests, the separation procedures are able to generate a large number of cuts and provide upper bounds that are competitive with those of the pure branch and bound. In almost all cases (there is only one exception, with d = 2), the addition of cuts drastically reduces the addition of lazy constraints within the time limit of 1 hour. Another characteristic that can be observed is that the S, T -cuts are more effective than convex inclusion cuts.
Concluding remarks
We have presented in this work a first computational study of the effectiveness of the valid inequalities introduced in [5] for the 2-class classification problem, by


Table 1
Computational results for the procedure introduced in Section 5. We have used M = 200, F = 1,
V IOL = 0.2, and UB = 1.0 in these experiments. Column BEST indicates the value of the best solution found in all configurations.



resorting to the particular case of single groups for each class. The number of constraints in the initial model makes it necessary to resort to lazy constraints, which can be readily separated by a linear programming model. The separation of families of valid inequalities appears to be a tougher issue, and we resorted to mixed integer programming models for accomplishing this task. Our computational experience suggests that this strategy may be effective. As a future work, we intend to perform extensive computational experiments with the proposed cut generating procedure appended to other optimization methods for classification problems.


Acknowledgment
We are very grateful to the anonymous reviewers for their helpful remarks.

References
Amaldi, E., S. Coniglio and L. Taccari, Discrete optimization methods to fit piecewise affine models to data points, Computers & Operations Research 75 (2016), pp. 214–230.
URL http://www.sciencedirect.com/science/article/pii/S0305054816301022

Balas, E., Projection, lifting and extended formulation in integer and combinatorial optimization, Annals of Operations Research 140 (2005), pp. 125–161.
Bertsimas, D. and R. Shioda, Classification and regression via integer optimization, Operations Research 55 (2007), pp. 252–271.
Carrizosa, E. and D. R. Morales, A mixed integer optimisation model for data classification, Computers & Operations Research 40 (2013), pp. 150–165.
Corrˆea, R. C., D. Delle Donne and J. Marenco, On the combinatorics of the 2-class classification problem, Discrete Optimization (2018), pp. 1572–5286.
URL http://www.sciencedirect.com/science/article/pii/S1572528617302748

Freed, N. and F. Glover, Evaluating alternative linear programming models to solve the two group discriminant problem, Decision Sciences 17 (2007), pp. 151–162.
Maskooki, A., Improving the efficiency of a mixed integer linear programming based approach for multi- class classification problem, Comput. Ind. Eng. 66 (2013), pp. 383–388.
URL http://dx.doi.org/10.1016/j.cie.2013.07.005
Pardalos, P. M. and P. Hansen, 45, American Mathematical Society, Providence, RI, 2008.
Sun, M., A mixed integer programming model for multiple-class discriminant analysis, International Journal of Information Technology and Decision Making 10 (2011), pp. 589–612.
Uney, F. and M. Turkay, A mixed-integer programming approach to multi-class data classification problem, European Journal of Operational Research 173 (2006), pp. 910–920.
URL  https://EconPapers.repec.orgRePEc:eee:ejores:v:173:y:2006:i:3:p:910-920

Xu, G. and L. G. Papageorgiou, A mixed integer optimisation model for data classification, Comput. Ind. Eng. 56 (2009), pp. 1205–1215.
URL http://dx.doi.org/10.1016/j.cie.2008.07.012
