

Text segmentation in degraded historical document images

A.S. Kavitha a, P. Shivakumara b,*, G.H. Kumar a, Tong Lu c

a Department of Studies in Computer Science, University of Mysore, Karnataka, India
b Faculty of Computer Science and Information Technology, University Of Malaya, B-2-18, Malaysia
c National Key Lab for Novel Software Technology, Nanjing University, Nanjing, China

Received 2 March 2015; revised 1 October 2015; accepted 6 November 2015
Available online 2 January 2016

Abstract Text segmentation from degraded Historical Indus script images helps Optical Character Recognizer (OCR) to achieve good recognition rates for Hindus scripts; however, it is challenging due to complex background in such images. In this paper, we present a new method for segmenting text and non-text in Indus documents based on the fact that text components are less cursive com- pared to non-text ones. To achieve this, we propose a new combination of Sobel and Laplacian for enhancing degraded low contrast pixels. Then the proposed method generates skeletons for text components in enhanced images to reduce computational burdens, which in turn helps in studying component structures efficiently. We propose to study the cursiveness of components based on branch information to remove false text components. The proposed method introduces the nearest neighbor criterion for grouping components in the same line, which results in clusters. Furthermore, the proposed method classifies these clusters into text and non-text cluster based on characteristics of text components. We evaluate the proposed method on a large dataset containing varieties of images. The results are compared with the existing methods to show that the proposed method is effective in terms of recall and precision.
© 2015 Production and hosting by Elsevier B.V. on behalf of Faculty of Computers and Information,
Cairo University. This is an open access article under the CC BY-NC-ND license (http://creativecommons.
org/licenses/by-nc-nd/4.0/).





* Corresponding author.
E-mail addresses: kavitha_sanjay_as@yahoo.co.in (A.S. Kavitha), hudempsk@yahoo.com (P. Shivakumara), ghk.2007@yahoo.com (G.H. Kumar), lutong@nju.edu.cn (T. Lu).
Peer review under responsibility of Faculty of Computers and Information, Cairo University.
Introduction

India is a multilingual country, where all the states have provi- sion to specify their own official language, which results in many official languages and various documents in different languages. Though work on segmentation of text is improved significantly, the recognition of old scripts like Indus is still dif- ficult because of its complexity. Indus documents consist of symbols that look like ornamental in images [1]. Generally, these symbols are carved by hand on irregular surfaces such

http://dx.doi.org/10.1016/j.eij.2015.11.003
1110-8665 © 2015 Production and hosting by Elsevier B.V. on behalf of Faculty of Computers and Information, Cairo University. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).




190	A.S. Kavitha et al.


















Figure 1	Sample Indus document images.



Text





Non Text




Figure 2	Illustrating text and non-text components in Indus documents.



as stones during the period of 3000 BC–1500 BC. As a result, Indus script is found in seal form that was used by people for the purpose of communication in the past. Fig. 1 shows a few images of these documents, where texts are associated with animal-like pictures in various forms such as a single horn and two horns. This complexity makes the segmentation prob- lem more challenging and interesting. Due to the huge collec- tion of such documents and the lack of scholars in the field of epigraphy, it is difficult to interpret all the scripts manually as it consumes a large amount of time. In order to reduce manual efforts, there is a need for the digitization of the scripts to pre- serve vital information for future study. Developing an auto- matic algorithm for converting raw script data to digital data involves four steps, namely text line segmentation, word seg- mentation, character segmentation, and character recognition. Text line segmentation is an important step as it facilitates other steps to achieve good recognition rates. In addition, text line segmentation is hard for the document like Indus due to the irregular structures of text components and unpredictable background variations [2,3]. Therefore, in this work, we focus on text line segmentation from Indus scripts. We can see some of the efforts toward text line segmentation [18–21] in the liter- ature. Most of the methods are developed based on geometri- cal features such as aspect ratio and size for text line segmentation. Therefore, these methods may not be suitable
for text line segmentation from Indus document images, where one cannot expect uniform size and structure due to complex background. Hence, we can conclude that there is an immense scope for developing a new method for segmenting text lines from Indus document images.
The paper is structured as follows. In Section 2, we give a brief survey of related work. Section 3 discusses the proposed work in detail. Finally, Section 4 discusses experimental results for the proposed method and the comparisons with the exist- ing methods.
Previous work

There are several methods proposed for text extraction from scanned, handwritten, degraded and historical document images in the literature [4–10]. Most of the methods require plain and homogeneous background with a high contrast images for achieving good segmentation results. However, when we look at Indus documents as shown in Fig. 1, we can- not assume that such documents have plain backgrounds and structured text lines because these documents are handwritten with different tools on different surfaces. We consider Indus documents as a type of degraded historical document images, and text line segmentation from these documents still remains an unsolved problem. In this section, we will review the



Figure 3	Flow diagram of the proposed text line segmentation: BC1 and BC2 denote the number of branches in cluster-1 and cluster-2, respectively.


literature on text line segmentation from historical handwrit- ten degraded documents (i.e., Indus documents).
The survey on the contributions toward inscription can be found in Soumya and Kumar [11]. The authors proposed pre- processing techniques and segmentation methods of Kannada present handwritten texts based on connected component anal- ysis. However, none of the methods is tested on unstructured layout documents. Omar and Lu [4] proposed an algorithm to extract text lines from historical document images using Steerable Directional filters. An adaptive local connectivity map is generated based on paragraph map to extract para- graphs. The objective of this paper is to find the orientation for each paragraph. Patterns are validated using projection profiles. Text lines in each paragraph are extracted by finding
the central point of each connected component. However, the method can deal with the documents only containing text lines. Recently, Gatos et al. [5] proposed a work toward segment- ing historical handwritten document images into text lines and text zones. Text zones are extracted by finding vertical lines by rules. White run pixels are used for segmentation. Bounding box coordinates for each connected component are used to cal- culate the height of a character. However, the method requires a uniform height of characters with clear background. Kleber et al. [6] proposed a method for detecting the skewness of scanned documents, which is needed for image analysis. The method determines the skew of a document page by the Near- est Neighbor Clustering. Interested points are found using DOG to evaluate the skewness. However, the method can only













(a) Sobel Gradient Image	(b) Laplacian gradient Image












Intersection of two gradient Images	(d) Skeleton
Figure 4	Intermediate results of text enhancement method.





















Figure 5	Example for pruning components.


work for the characters on plain surfaces but not for ornamen- tal characters on irregular surfaces. Garz et al. [7] proposed binarization-free clustering to segment curved text lines in His- torical documents. Text lines are detected by representing word segments using graphs, in which an edge is a link between two segments. The method works well for the texts written in ink; however, it cannot work on unconnected characters. Rabaev et al. [8] detected characters in damaged documents and then grouped them to text lines by analyzing the evolution maps of connected components. A sweep line moved from left
to right is further used to check whether elements lie in the same line. However, the method can only detect lines of equal-size texts which are chosen in their dataset.
In Garzet al.’s method [9], parts of characters considered as interest points are extracted. Words are identified in high den- sity regions and characters are separated by ascenders and descenders. However, the method concentrates for median words but not the manuscripts containing variable heights. Method is robust to background noise such as stains but not to abrupt background. Messaoud et al. [10] introduced three



(a) Overlapping bounding boxes	(b) False segmentation
Figure 6	False components removal.

ization of Indus scripts using the probabilities of symbols sequences and the syntactic rules generated by the analyzed sequences or the correlations among symbols. Rajesh et al.
[16] proposed a probabilistic method to analyze the sequences of Indus scripts and predict missing letters.
Based on the above discussions, we can conclude that none of the existing methods can be tested on the documents like Indus for text line segmentation. Therefore, text detection from unstructured layout documents with low contrast and varied font sizes on irregular surfaces is still considered as an open challenge in the document analysis community.


Figure 7 Nearest neighbor criterion for text and non-text clusters.

steps to achieve multilevel text line segmentation by proposing a histogram approach, grouping connected components for text line estimation, using the nearest neighbor to overcome the overlapping problem. However, the approach is prone to errors from unstructured background.
The method in [12] segments text lines based on the dis- tances among the bounding boxes of components in an image, while the method in [13] segments a document that has text lines by drawing snakes (curves) over ridges (the central point of each line). The latter assumes a uniform height for text lines. However, it is not true for Indus documents. The advantage of the two methods is that they segment text lines irrespective of scripts and are said to be robust to non-structured layouts in Indus documents. Since these two existing methods are devel- oped for segmenting text lines from plain background images, they may give lower accuracies for Indus documents.
In summary, it is noted from the above discussions on text lines segmentation from historical document images such as handwritten and scanned document images that none of the existing methods gives a satisfied solution for unstructured documents and the documents containing irregular structures of characters. In addition, the existing methods require a high resolution and plain background for achieving good results.
We hardly found literature on epigraphical documents like Indus documents. Murthy et al. [14] proposed a method for the segmentation of touching lines and characters in Epigraphical documents. The method in [15] discussed about the character-
Proposed method

It is noted from the above discussions and Fig. 1 that an image can have any contrast and a text can have any character shape. In order to enhance low contrast texts, we propose to explore the combination of Laplacian and Sobel edge images as we are inspired by the work presented in [17] for video text detection, in which Laplacian and Sobel combination has been used for increasing low contrast texts in video. In this work, we perform intersection operation for Laplacian and Sobel images of the input image to obtain an enhanced image. Laplacian operation enhances both low and high contrast pixels at near edges, and at the same time it produces noise pixels due to background variations. Sobel operation only enhances high contrast pixels without producing noise pixels. Therefore, we perform inter- section operation to choose only the pixels which are signifi- cant for text line segmentation.
For the enhanced image, we further apply skeleton to reduce pixel widths of edge components. This operation pre- serves the structures of edge components in the enhanced image, and at the same time it saves the number of computa- tions. We observe that generally most Indus documents con- tain texts along with pictures like animals. Since a picture looks like animals with different shapes, when the branches of the picture look more cursive, the picture contains a larger number of branches. With this notion, we propose a method to eliminate the components which has more cursive branches in the skeleton image. This results in pruned text image components.
The above steps help in increasing the gap between text and non-text components spatially. To segment text lines, we



(e)
Figure 8	Illustrating grouping process.


propose clustering based on the nearest neighbor criterion to group the components that have closed proximity. The cluster- ing process continues until the method gets two clusters for the whole pruned image. This is because it is expected text compo- nents to be formed one cluster, and non-text components to be formed another cluster. This is valid because the space between text and non-text components is larger than the space between the respective text and non-text components. The proposed method studies the number of the branches in each cluster to classify text and non-text clusters. The cluster that contains less number of branches is considered as a text cluster because text components in this cluster are not cursive as another clus- ter containing animal-like pictures. This results in text line seg- mentation. One sample example is shown in Fig. 2, where we can see text lines and non-text lines are segmented by the pro- posed method. The block diagram of the proposed method is shown in Fig. 3.

Text enhancement

As discussed in the above discussions, we need to enhance low contrast text components. For this purpose, we consider Laplacian and Sobel operations on the input image as these
document images. To overcome this problem, we propose to use Laplacian operation, which enhances both low contrast and high contrast pixels because this operation involves the second order derivative. Besides, the Laplacian operation introduces noises for complex background information. To retain enhanced edges and suppress background noises, we propose to perform intersection operation of the Sobel and Laplacian operation outputs. For example, the results of Sobel and Laplacian operations on the input images are respectively shown in Fig. 4(a) and (b), where one can notice Sobel enhances high contrast information, while Laplacian enhances both low and high contrast information along with noises. To take the advantage of both Sobel and Laplacian, we perform an intersection operation as shown in Fig. 4(c), where it is noted that only significant information is highlighted. The pro- posed method applies skeleton to reduce pixel width to a single pixel to save the number of computations as shown in Fig. 4
(d). Let P1(i, j) and P2(i, j) be the pixel values at position (i, j) in A and B, respectively. The intersection of these gradient images is computed as true if P1(i, j) and P2(i, j) both have pos- itive gradient. The algorithmic steps of enhancement are repre- sented as follows.
The masks to compute Sobel gradient Image are given by,

are well known gradient operations to enhance the information
in the image. It is true that since Sobel operation is the first
2 —1  0  +1 3
2 —1 —2 —1 3

order derivative, it gives fine details for high contrast pixels. Therefore, it enhances only high contrast edges of text compo- nents but not the edges of low contrast components as in Indus
Gx = 6 —2    0    +2 7   And    Gy = 6
—1  0  +1
0	0	0  7
+1  +2  +1



(a) Text cluster	(b) Non-text cluster
Figure 9	Text and non-text cluster separation.



by,
The Sobel gradient of the image for array G[i, j] is obtained
K[I; J]= Kx + Ky	(6)
The intersection of gradient images is obtained by

Gx = ((2 * C(i + 2; j + 1)+ C(i + 2; j)+ C(i + 2; j + 2))
— (2 * C(i; j + 1)+ C(i; j)+ C(i; j + 2)))	(1)
Gy = ((2 * C(i + 1; j + 2)+ C(i; j + 2)+ C(i + 2; j + 2))
— (2 * C(i + 1; j)+ C(i; j)+ C(i + 2; j)))	(2)
The magnitude of pixel gradient is given by
G[i; j]= qGﬃﬃﬃﬃxﬃﬃﬃ2ﬃﬃﬃ+ﬃﬃﬃﬃGﬃﬃﬃﬃyﬃﬃ2ﬃﬃ	(3)
Laplacian Gradient for array C[i, j] is computed as
Kx = ((C(i + 2; j + 1)+ C(i; j + 1)— 2 * C(i; j)))	(4)
Ky = ((C(i + 1; j + 2)+ C(i + 1; j)— 2 * C(i; j)))	(5)
G[I; J]∩ K[I; J]	(7)
Pruning text components

Due to complex document images, the above enhancement step may enhance non-text components as shown in Fig. 4
(d). It is also true that a skeleton algorithm sometimes creates disconnections between the components. To avoid disconnec- tions, we perform smoothing using morphological operation. This results in a smoothed image, where we can see connected components without disconnections. Then the proposed method fixes the bounding box for each component in the smoothed image. If the bounding box of components overlaps with the bounding boxes of other components, it will be



(a) Input	(b) Bukhari et al.[13]	(c) Diemet al.[12]	(d) Proposed method
Figure 10	Text line segmentation by the existing and the proposed methods.

candidate components considered for merging. The distance between a candidate component and another component is cal- culated by finding the boundary values of the components. Cj is the set of all the other components excluding Ci. The dis- tance between the two components is considered for merging. Let (X1, Y1) and (X2, Y2) be the extreme coordinates of two components facing each other, and the distance between the two components is obtained by

Euclid distX1,X2 = q(ﬃﬃXﬃﬃﬃﬃ2ﬃﬃﬃ—ﬃﬃﬃﬃXﬃﬃﬃﬃ1ﬃﬃ)ﬃﬃ2ﬃﬃﬃ+ﬃﬃﬃﬃ(ﬃﬃYﬃﬃﬃﬃ2ﬃﬃ—ﬃﬃﬃﬃﬃYﬃﬃﬃﬃ1ﬃﬃ)ﬃ2ﬃﬃ
(8)


merged to make a single component. This connects sub- components, which have more than two pixel gaps. When we observe from the skeletons of an Indus document image, we are noted that the components that represent an animal-like picture have more cursive branches compared to the compo- nents that represent text as discussed. The proposed method then counts the number of branches for the results obtained by overlapping bounding boxes. If the number of a branch is larger than a certain threshold value, we discard it as a non- text component as shown in Fig. 5, where the marked compo- nents will be removed from the image. Fig. 6(a) shows the result after merging the nearest sub-components into a compo- nent using overlapping bounding boxes. Fig. 6(b) shows the result after discarding the components that have a large num- ber of branches.

Text line segmentation

It is noted from Fig. 6(b) that we can still see spaces between text and non-text regions due to the elimination of unwanted components. Next, we need to group text and non-text compo- nents separately to extract text lines from the image. Since the space between two regions generally looks larger than the space between two components, we propose the nearest neigh- bor clustering method for grouping the nearest components. For each component in the image, the method finds the nearest neighbor component using Euclidean distance as defined in Eq. (8). The component that gives the minimum distance is considered for grouping. This process continues until the method gets two clusters for the whole image. Since it is a two class problem (text and non-text) and it is known that the average space between two regions is larger than that between two components, the grouping process continues until it gets two clusters as shown in Fig. 7, where we can find the grouping results in two regions. If the distance between two regions does not satisfy a certain threshold, there are chances of getting more than two clusters. This is a rare case for Indus script because according to observation generally each image contains only one text lines with animal picture background. It can be illustrated mathematically as follows. Let C =
{C1, C2, C3, Cn} be the finite set of components. Let Ci be
The proximity of closeness defined by the minimum dis-
tance criteria is calculated by
Cn = Min d(a, b) : a s Ci, b s Cj=1,n — Ci}	(9)
We merge two nearest components by
Cnew = Rci ∪ Rcj ∪ Cn	(10)
The process of grouping is illustrated in Fig. 8, where (a)–
show the step by merging the nearest neighbor components and the final results. Since the grouping process involves unsu- pervised nearest neighbor clustering criterion, it results in clus- ters without identifying them. Therefore, we propose to extract features which represent text components, namely, the number of branches in text components in the cluster for classifying the cluster as a text one. The cluster that gives a less number of branches is considered as a text cluster because text compo- nents usually have fewer branches compared to non-texts like an animal picture.
Let NBc1 and NBc2 be the numbers of the branches in clus- ter1 and cluster2, respectively. If NBc1 < NBc2 then the con- tours of clusters c1 and c2 are located as text and non-text, respectively. If NBc2 < NBc1 then the contours of clusters c2 and c1 are located as text and non-text, respectively. The results can be seen in Fig. 9, where we can see text and non- text regions separately.

Experimental results

Since text line segmentation from Indus documents is a new problem as introduced, we create our own dataset consisting of 500 images from archeology survey of India, Mysore and magazines. This dataset includes varieties of text lines of differ- ent handwritings with different tools on different surfaces. As a result, this dataset is said to be complex compared to scanned document images. To measure the performance of the pro- posed method, we use classification rate with confusion matrix. To generate confusion matrix, we count the cluster that repre- sents text and the cluster that represents non-text for calculat- ing classification rate. The matching matrix of the proposed method is reported in Table 1, where it is noted that the pro- posed method gives a good classification rate for text and non-text classifications.
For evaluating text line segmentation, we use well-known measures such as recall and precision as in Eqs. (11) and
(12). The definitions for recall and precision are as follows. Let Gt be the total number of the text lines counted in 500 images, Tp be the number of the text lines segmented from the proposed method, Fn be the number of the lines that are



not segmented, and Fp be the number of non-texts that are classified as texts.
Tp
Recall = (Tp + Fn)	(11)
And
References

Mahadevan Iravatham. Dravidian proof of the Indus script via the rig Veda: a case study. Bull IRC 2014;4(1).
Kavitha AS, Shiva kumara P, Kumar GH. Skewness and nearest neighbour based approach for historical document classification. Proc CSNT 2013:602–6.
Kavitha AS, Shiva Kumara P, Kumar GH. An integrated method

Tp
Precision =
(Tp + Fp)
(12)
for classification of Indus and English document images. Proc ICERECT 2012:343–55.

To show the effectiveness of the proposed method, we
implement two recent methods on text line segmentation for comparative studies. The method in [12] segments text lines based on the distance between the bounding boxes of the com- ponents in an image. The method in [13] segments the docu- ments having text lines by drawing snakes (curves) over ridges (central points of each line). The latter method assumes a uniform height for all text lines. However, this is not true for Indus documents. The reason to choose these two methods is that they segment text lines irrespective of scripts and datasets and are said to be robust to non-structure layouts as in Indus documents. Since these two existing methods are developed for segmenting text lines from plain background images, the exist- ing methods report poor accuracies for our Indus documents. The qualitative results of the proposed and the existing meth- ods are shown in Fig. 10, where one can notice that the pro- posed method is able to segment text lines correctly for both the images, while both the existing methods fail to segment the first image in Fig. 10 due to the inherent limitations of the existing methods such as the requirements of both high res- olution and plain backgrounds. For the second image shown in Fig. 10, the existing methods segment text and non-text lines correctly since the image contains enough spaces between text and non-text lines. Since the existing methods aim at segment- ing text lines, they focus on the segmentation of text and non- text lines without separating text and non-text lines as shown in Fig. 10 on the second image. The quantitative results of the proposed and existing methods are reported in Table 2, where we can see that the proposed method is the best at recall and precision compared to the existing methods.

Conclusion and future work

We have proposed a new method for segmenting text lines from degraded historical document images like Indus. The proposed method introduces a new combination of Laplacian and Sobel operations for enhancing low contrast pixels in the images. The characteristics of the components in the image are studied to eliminate unwanted components, which results in text components pruning in the image. We have proposed a grouping process, which involves the nearest neighbor crite- rion for merging text components. The iterative clustering pro- cess is then proposed to separate text and non-text regions. Our future plan would be extending the same method for other Indian scripts to show its ability and generic properties. We also focus on character segmentation from segmented text lines and character recognition.
Omar A, Lu CC. Text line extraction for historical document
image using steerable directional filters. Proc ICALIP 2014:312–7.
Gatos B, Louloudis G, Stamatopoulos N. Segmentation of historical handwritten documents into text zones and text lines. Proc ICFHR 2014:464–9.
Kleber F, Diem M, Sablatnig R. Robust skew estimation of handwritten and printed documents based on gray value images. Proc ICPR 2014:3020–5.
Garz A, Fischer A, Bunke H, Ingold R. A binarization-free clustering approach to segment curved text lines in historical manuscripts. Proc ICDAR 2013:1290–4.
Rabaev I, Biller O, El-Sana J, Kedem K, Dinstein I. Text line detection in corrupted and damaged historical manuscripts. Proc ICDAR 2013:812–6.
Garz A, Fischer A, Sablatnig R, Bunke H. Binarization-free text line segmentation for historical documents based on interest point clustering. Proc DAS 2012:95–9.
Messaoud IB, Amiri H, Abed HE, Margner V. A multilevel text line segmentation framework for handwritten historical docu- ments. Proc ICFHR 2012:515–20.
Soumya A, Kumar GH. Preprocessing of camera captured inscriptions and segmentation of handwritten Kannada text. IJARCCE 2014;3(5):6794–803.
Diem M, Kleber F, Sablatnig R. Text line detection for heterogeneous documents. Proc ICDAR 2013:743–7.
Bukhari SS, Shafait F, Breuel TM. Script-independent handwrit- ten textlines segmentation using active contours. Proc ICDAR 2009:446–50.
Murthy KS, Kumar GH, Shivakumara P, Ranganath PR. Nearest neighbour clustering approach for line and character segmenta- tion in epigraphical scripts. Proc ICCS 2004.
Rajesh P, Rao PN, Yadav N, Vahia MN, Hrishikesh Joglekar, Adhikari R, Mahadevan I. Entropy, the Indus script, and language. Comput Linguist 2010:795–805.
Rajesh P, Rao PN. Probabilistic analysis of an ancient undeci- phered script. Proc Comput Soc 2010:76–80.
Shivakumara P, Sreedhar RP, Phan TQ, Shijian L, Tan CL. Multi-oriented video scene text detection through bayesian classification and boundary growing. IEEE Trans CSVT 2012:1227–35.
Zhu A, Wang G, Dong Y. Robust text segmentation in low quality images via adaptive stroke width estimation and stroke based superpixel grouping. Lect. Notes Comput. Sci. 2015:119–33.
Pintus R, Yang Y, Rushmeier H. Automatic text height extraction for the analysis of text lines in old handwritten manuscripts. ACM J Comput Cult Herit 2013:25.
Gaurav SM, Nandish C. A survey and analysis of segmenta- tion, feature extraction and classification in OCR system. IJAR 2015;5(1):24–6.
Thakur P, Azam A. Edge detection through integrated morphological gradient and fuzzy logic approach. IJSETR 2015;4(5):1613–6.
