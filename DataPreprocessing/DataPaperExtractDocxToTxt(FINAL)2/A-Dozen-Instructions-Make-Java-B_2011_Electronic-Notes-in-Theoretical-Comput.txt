

Electronic Notes in Theoretical Computer Science 264 (4) (2011) 19–34
www.elsevier.com/locate/entcs
A Dozen Instructions Make Java Bytecode 1
Jacek Chrząszcz2 Patryk Czarnik3 Aleksy Schubert4
Institute of Informatics University of Warsaw ul. Banacha 2
02–097 Warsaw Poland

Abstract
One of the biggest obstacles in the formalisation of the Java bytecode is that the language consists of
200 instructions. However, a rigorous handling of a programming language in the context of program verification and error detection requires a formalism which is compact in size. Therefore, the actual Java bytecode instruction set is never used in the context. Instead, the existing formalisations usually cover a ‘representative’ set of instructions. This paper describes how to reduce the number of instructions in a systematic and rigorous way into a manageable set of more general operations that cover the full functionality of the Java bytecode. The factorisation of the instruction set is based on the use of the runtime structures such as operand stack, heap etc. This is achieved by presentation of a formal semantics for the Java Virtual Machine.
Keywords: bytecode, semantics


Introduction
The transfer of programs from one party to the other raises the problem of security of its execution on the receiver’s side. Therefore it is desirable to provide means to guarantee certain computational properties of the code in the form it travels from the developer to the consumer. Java bytecode language (JVML in short) is one of the most popular formats for a code that travels in the Internet and the security of its execution has already caused practical problems (see [5,8]) which go beyond the abilities to control the execution by means of Java sandboxing. One of the possible ways to overcome the problems is to provide a precise mathematical model for the language, then prove properties of the programs using the model and supply

1 This work was partly supported by Polish government grant N N206 493138.
2 Email: chrzaszcz@mimuw.edu.pl
3 Email: czarnik@mimuw.edu.pl
4 Email: alx@mimuw.edu.pl

1571-0661 © 2011 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2011.02.003

the travelling program with additional information that will make it possible to reconstruct the proof efficiently on the code consumer’s side.
Several formal semantics were proposed for the JVML including the most notable ones: [1,7,11,13,14,15,16]. These formulations suffer from one of two problems — either they provide a formal semantics of (almost) all 200 bytecode instructions 5 or they choose a subset of the instructions that represents most of the interesting features. The drawback of the former option is that the formalisation in this case is very difficult to operate with as most of the proofs have to be done by induction on the structure of programs. Therefore the latter option is more often followed by researchers, but then the particular choice of instruction representatives is often not related to the actual instructions of the bytecode and is presented with very little discussion on the issue of the correspondence of the actual instructions to the ones in the model. The current paper provides the missing discussion and divides the instructions into groups that follow the same pattern of access to the JVM runtime structures (such as heap, operand stack etc.). For example, all load instructions are grouped together, all jumps, including the subroutine ones (jsr and ret), but also *aload, getfield, checkcast and instanceof form a single group as they all access the heap and (possibly) put something on the operand stack or raise an exception. In this way we obtain a factorisation of the whole set of the JVML instructions to 12 items. The actual lists of instructions can be found in [3].
We believe that it is crucial to come up with a formalisation that is based on a small number of instructions as then it is much easier to demonstrate the properties of the language itself — many proofs for such a language are done by induction on the structure of possible programs. If the number of instructions is limited then the number of cases to consider in such a proof is small. This is the main reason why ventures such as EML [10], where the number of semantical rules reaches several hundred, failed to develop metatheoretical properties, while such as Coq module system [2] succeeded with this regard. Moreover, it is a standard compiler design technique to establish a small language that makes easy design of optimisation techniques. Examples of such languages for Java and its bytecode include BAF, Jimple and Grimp [17] as well as BIR [6].
Moreover, our rigorous consideration gives the opportunity to present what are the instructions that really cover the whole spectrum of bytecode behaviours. We are aware that for certain properties of the JVML a slightly different set of instruc- tions would be more convenient (e.g. the proofs for interval static analysis require access to the actual arithmetic operations and then it is desirable to consider them explicitly). However, one still has a path to reach to all the operations in JVML as their particular behaviour in our semantics is available through access to appropri- ate tables associated with our generalised operations. We hope that this solution is useful in all meta-proofs for JVML as it allows to build a common framework for many analyses which is important when a verification platform is to be built for real JVML programs.
Naturally, this paper does not provide the full semantics for the JVML as it

5 The number is even greater when one considers wide instructions as separate.

is very complex. In fact, in a few places we make deliberate simplifications of the semantics in order to stay comprehensive in presentation.
Semantic domains and notation
We give here a small step semantics for the Java bytecode. The general form of a semantics step is:
P × h, ts → hj, tsj	(2.1)
where P is a program, h, hj are heaps and ts, tsj are states of the threads. The semantic domains of these values are defined in the following way. First, we provide the description of programs: Prog = [Cnames ~fin CDesc]. Programs are partial functions with finite domain that associate class descriptions from CDesc with class names from Cnames. The class names are just appropriately defined identifiers, the class descriptions are defined as CDesc = [Mnames ~fin MDesc] i.e. partial functions with finite domains that associate method descriptions MDesc with the method names. Again the method names are just appropriate identifiers while the method descriptions are somewhat more complicated and defined as
MDesc = [PC ~fin Instr] × ExTable ExTable = [PC × Cnames ~fin PC]
where Instr is the set of JVM instructions and ExTable is an exception table for the method. The intent is that a function in [PC ~fin Instr] provides a mapping from instruction labels to the instructions under the labels. The ExTable returns the handler address for a given exception origin address and class.
The set of heaps is defined to be the set of
Heap = [Loc × ThreadId ~fin (Cnames × Monitor × [Fnames ~fin Val])]
where Loc is the set of locations (e.g. natural numbers or pointers in the current architecture) with a distinguished location null (the set Loc\{null} will be denoted by Loc•), ThreadId is the set of the thread identifiers (e.g. natural numbers), Monitor is the set of monitors which will control the lock counter for the given object, this is defined precisely later. Fnames is the set of field names and Val is the set of expected field values i.e. Val = int ] long ]·· ·] Loc. The ThreadId is an argument of the heap, as each thread has its own view of the heap state. The exact way the different views are synchronised is described by the Java Memory Model [9, Section 17].
The set of thread states is defined as the set of all finite sets of thread descriptions, Pfin (Thread) × History combined with a state information History which contains an information needed for the thread scheduler to deterministically select a thread to execute. A thread description is
Thread = ThreadId × ThreadStatus × EvalState × FrameStack
where ThreadStatus represents the current status of the thread i.e. sleeping, blocked,

running, terminated etc. At last, the FrameStack = MethodFrame∗ contains a se- quence of the method frames of the form
MethodFrame = Cnames × Mnames × LVals × OpStack × PC
where LVals is the local variable table defined as [Vars ~fin Type × Val] with the set of local variable indices Vars = N, Type being the type of the value in the given entry and Val the value contained in the local variable table; OpStack is the operand stack defined as (StackKind × (Val ] PC))∗, where StackKind represents the type of the value in the current cell of the stack, note that we have to add PC type to make sure we can put labels of bytecode instructions used by subroutine commands; the same set PC is used as the final compound of MethodFrame and the value points to the currently executed bytecode instruction; EvalState is a set that represents the information on which exception has been thrown. We may assume that EvalState = Loc. The special location null is used to mark the situation that no exception has been thrown. We also assume that certain exceptions, such as NullPointerException, ClassCastException etc. are preallocated on the heap. This greatly simplifies the semantics as otherwise a number of semantic rules would be needed to allocate the exception on the stack and call its constructor before actially throwing it. And since the simplification does not concern used defined exceptions we decided not to complicate the semantics. 6
It is worth mentioning that the semantics we provide here is in the so called defensive style i.e. we provide the type identification along with the operand stack and local variables table entries to check if the values stored there have correct type. We can now define the set of monitors Monitor to be the product ThreadId × N.
A pair from the set represents the identifier of the thread that holds the lock and the number of the times the thread entered the monitor. We assume that the set ThreadId contains a distinguished constant none which is used to represent the
situation when no thread holds the monitor.
A natural operation on the operand stack o is pushing an element e. It is written as e·o. The examining the top of the stack is done by pattern matching and o = e·oj means that the stack o contains e at the top followed by the rest in oj.
The data structures which describe the state of the virtual machine are compli- cated. Therefore we need further notation to retrieve the information from them. First, we have to introduce the scheduler which chooses the particular thread to be executed: ÷ : Pfin (Thread) × History → Thread. We do not provide a particular definition for History as this is implementation dependent. We assume only that the scheduler returns any element from its first argument. To make the notation more succint we write ÷ts to denote ÷(ts). The components of the current thread are denoted as ÷ts = ⟨tidts, tstatusts, estts, tfsts⟩. As tfsts is also a composite value, we introduce further notation


tfsts = ⟨cnmts, mnmts, lvts, ostckts, pcts⟩· tfstail
(2.2)



6 In the Bicolano [13] JVM semantics the space on the heap is allocated but the constructor is not called.

where cnmts is the class name and mnmts is the method name of the currently executed method, lvts is the local variables table for the current method, ostckts is the current operand stack, pcts is the label of the currently executed instruction. The value tfstail denotes the (possibly empty) sequence of remaining method frames on the frame stack.

Modiﬁcation and lookup notation
We frequently modify slightly a given thread state to obtain a new one. The mod- ification is described using the notation changed item[replaced part → new part ]. These can be defined precisely as the construction of a new value where all compo- nents but replaced part are unchanged and the latter is replaced by new part . For example tfs[lv → lvj] is a thread state tfs modified so that its local variable table lvts in the topmost method frame is replaced with a new table lvj.
The lookup of a particular instruction is done using the notation P @pc.mnm.cnm where P ∈ Prog, pc ∈ PC, mnm ∈ Mnames, and cnm ∈ Cnames. This operation extracts from the program P the class declaration cnm and then it uses the Java method lookup scheme to retrieve the method of the name mnm (we assume the method name is such that it takes into account the signature of the method and therefore uniquely determines the method in the class). Then pc indicates which bytecode instruction from the code of the method should be retrieved.
Similarly, P @etable.mnm.cnm denotes the exception table for the method of the name mnm in the class cnm in P .
For h ∈ Heap, s ∈ Loc, and i ∈ ThreadId we write h(s, i) to denote the value at the location s visible in the heap h from the thread i. In most cases i is clear from the context so we omit it and write h(s). As h(s) is a compound value, we define
h(s)@cnm = π1(h(s))	h(s)@monitor = π2(h(s))	h(s)@obj = π3(h(s))
h(s)@tid = π1(π2(h(s)))	h(s)@lcount = π2(π2(h(s)))
In case s = null or s /∈ dom(h), the notations above have the value ⊥.
Auxiliary deﬁnitions
Throughout the following semantics description we use many minor notations. This section collects the description of their meaning.
The names such as int are used here in two meanings, as a name for the set of elements in the Java type of native integers and as a syntactical identifier which is used to refer to the set. The 64-bit values divide into two halves. The notation
long(m1, m2) (resp. double(m1, m2)) means the 64-bit value of type long (resp.
double) constructed from two 32-bit words m1 and m2. The type of a half with no distinction to which half and for which type (long or double) for a 64-bit value is denoted as half.
The Java Virtual Machine handles the 64-bit types in a special way. There- fore, the Java computational kinds are divided according to [12, Section 3.11.1] in

two categories: Cat1 = {int, float, ref, returnAddr} for 32-bit types and Cat2 =
{long, double} for 64-bit types.  We will also use the notation Cat1• to denote
Cat1 \ {returnAddr}.
As soon as a current thread is chosen we can conclusively determine the currently executed method. This method is denoted cmthd ∈ MDesc. We also use a function next : MDesc × PC → PC to obtain the label of the next instruction in the method using the order of the instruction occurrence there.


Additional remarks
The semantics we give below is in fact more in the flavour of the interleaving seman- tics than the actual Java Memory Model one. However, we provide here a way to handle the Java Memory Model as our heap is defined so that it can give a different view of the memory to each thread. Other features of the semantics such as class loading, class initialisation, finalisation, native and synchronized methods etc. are not handled as well. However, slight changes of the definitions above can give the rules below the meaning which can take them into account. Adding reflection would be more problematic as it would require us to change the form of semantic steps.


Semantics of instructions
The semantic rules present the evolution of runtime structures caused by the ex- ecution of instructions. Most of the rules are directly governed by the current instruction of the current method, but those dealing with exceptions are not.
In the course of the semantic transition the scheduler ÷ chooses a particular thread in ts to be executed. The notations we introduced in Section 2.1 all rely on the assumption that a thread is fixed. Therefore, we fix a single choice made by ÷ throughout each particular rule. However, the choice may change for different steps of our semantics. We also assume that the state of the heap can change after each rule so that the visibility of its content gets partially synchronised among threads. If we do full synchronisation with every step we obtain the interleaving semantics.


Instruction load
This instruction generalizes all JVM instructions that read local variables and push the value to the operand stack. Its parameters describe the type and source of the value to be written to the stack, the general form of the instruction is load (k, n) where k ∈ Cat1• ∪ Cat2 is a kind, and n is a local variable index.
In the simplest case, when k is a 32-bit kind, k ∈ Cat1•, the instruction reads a value from the local variable pointed by the index n and puts the value on the top

of the operand stack. It is required that the value is of kind k.


lvts(n)= (k, m)	ostckj = (k, m) · ostckts	pcj = next(cmthd, pcts)
P @pcts.mnmts.cnmts = load (k, n)	k ∈ Cat1•	estts = null
P × h, ts → h, ts[ostck → ostckj][pc → pcj]	ncat1-load
(3.1)
If k denotes a category-2 kind (long or double), the value to push on the stack is obtained from the values of two variables, indexed by n and n + 1. This is because category-2 values occupy two subsequent cells in the local variables array. We provide an artificial kind half for the second variable in such a pair of variables. Following the JVM description [12, Section 3.6.2] we use a single operand stack element for a category-2 value.


lvts(n)= (k, m1)	lvts(n + 1) = (half, m2)
ostckj = (k, k(m1, m2)) · ostckts	pcj = next(cmthd, pcts)
P @pcts.mnmts.cnmts = load (k, n)	k ∈ Cat2	estts = null
P × h, ts → h, ts[ostck → ostckj][pc → pcj]	ncat2-load	(3.2)



Instruction store
This instruction generalizes all JVM instructions that pop a value from the operand stack and put it in the local variable table. Its arguments are the kind and desti- nation of the popped value, the general form of the instruction is store(k, n) where k ∈ Cat1• ∪ Cat2 is a kind and n is a local variable index.
In case of a category-1 kind, the store instruction pops the topmost value from the operand stack and stores it in a local variable indexed by n.

lvj = lvts[n → (k, m)]
ostckts = (k, m) · ostckj	pcj = next(cmthd, pcts)
P @pcts.mnmts.cnmts = store(k, n)	k ∈ Cat1•	estts = null
P × h, ts → h, ts[ostck → ostckj][pc → pcj][lv → lvj]	ncat1-store	(3.3)

If k ∈ Cat2, two subsequent variables, n and n + 1, are modified. It is required that

the first variable is of kind k, and the second one is of kind half.

lvj = lvts[n → (k, m1)][n +1 → (half, m2)]
ostckj = (k, k(m1, m2)) · ostckts	pcj = next(cmthd, pcts)
P @pcts.mnmts.cnmts = store(k, n)	k ∈ Cat2	estts = null
P × h, ts → h, ts[ostck → ostckj][pc → pcj]	ncat2-store	(3.4)

Instruction stackop
Instruction stackop(op) generalizes all JVM instructions that use only the operand stack. It should be noted, that all such instructions operate on a fixed number of top elements, while the bottom part of the stack is neither read nor modified.
The parameter op denotes the stack operation to perform. The meaning of op is obtained through kindsstackop(op), which is a set of triples, each of them consisting of: a list of input kinds l, a function f , and a list of output kinds lj.
The list l defines the requirements of the operation with respect to the operand stack. The number of stack elements must not be less than the length of l, and for all i, the i-th element of the stack must be of kind li. This is denoted by check(s, l). The function f : OpStack → OpStack is the actual stack operation. |l| elements are popped from the stack and become the input of f , then the result of f is pushed
on the stack; lj describes guaranteed kinds of the result of f . In a sense f : l → lj.
(l, f, lj) ∈ kindsstackop(op)	ostckts = s · r check(s, l)	ostckj = f (s) · r	pcj = next(cmthd, pcts) P @pcts.mnmts.cnmts = stackop(op)	estts = null
P × h, ts → h, ts[ostck → ostckj][pc → pcj]	n-stackop	(3.5)
For example, the JVM instruction iadd is mapped to stackop(iadd), and
kindsstackop(iadd)= {([int, int], fiadd, [int])}
where fiadd performs addition of two 32-bit integers.
Polymorphic instructions, such as swap or dup, have more than one item in
kindsstackop, for instance kindsstackop(dup2) is equal to
{([k1, k2], fdup2, [k1, k2, k1, k2])}k1,k2∈Cat1  ∪  {([k], fdup, [k, k])}k∈Cat2
Instruction cond
This instruction generalizes all JVM instructions that may affect the program con- trol flow inside the current method, but do not modify the method frame stack, that is all unconditional and conditional jumps including tableswitch, lookupswitch,

jsr and ret. The instruction reads and modifies the operand stack and the program counter (PC). The general form of the instruction is cond (op, d) where op identifies the actual operation on runtime structures and d ∈ Dcond , Dcond = [N ~fin PC] rep- resents the static arguments of the instruction, which consist of an indexed table of addresses. The form and role of kindscond (op) is analogous to the role of kindsstackop. The difference here is the type of f : Dcond × OpStack × PC → OpStack × PC.
Arguments of f are the table of offsets, the relevant part of the operand stack, and the next PC. The function f returns the new value of the relevant part of the operand stack and the new value of PC. Only one JVM jump instruction, jsr, does put some value onto the operand stack: the current PC; ret is the only instruction that pops the new value of PC from the operand stack.
(l, f, lj)= kindscond (op)	ostckts = s · r
check(s, l)	(sj, pcj)= f (d, s, next(cmthd, pcts))	ostckj = sj · r P @pcts.mnmts.cnmts = cond (op, d)	estts = null
P × h, ts → h, ts[ostck → ostckj][pc → pcj]	n-cond	(3.6)
For example, the JVM instruction ifeq(o), performing a jump if the value on the top of the stack is the integer 0, is mapped to cond (ifeq, [0 '→ pc + o]), and kindscond (ifeq)= ([int], fifeq, [ ]) with fifeq(g, s, pc) returning ([ ], g(0)) if s = [(int, 0)] and ([ ], pc) otherwise. For lookupswitch, g is a function that maps key values to the corresponding addresses.

Instruction iinc
The opcode iinc is the only JVM instruction that uses solely the local variables array. The corresponding instruction in our formalisation is iinc(n, c), where n is a local variable index and c is an integer value.
If the local variable n is of kind int, its value is increased by c, according to the Java int arithmetic.
lvts(n)= (int, m)	lvj = lvts[n → (int,m +int c)]
pcj = next(cmthd, pcts)	P @pcts.mnmts.cnmts = iinc(n, c)	estts = null
P × h, ts → h, ts[lv → lvj][pc → pcj]	n-iinc
(3.7)

Instruction get
This instruction reads the heap and modifies the operand stack. The general form of the instruction is get (op, d), where op is the operator and d contains an optional static argument—a qualified field name.
As for the previous rules, kindsget (op, d) provides expected kinds of arguments on the stack, list of kinds of values to be put on the stack, and the function f of

type Dget × OpStack × Heap → OpStack ] Loc•. The function f attempts to read the indicated object field or array cell from the heap. If it exists, f returns the modified part of the stack, which is the value from the heap.

(l, f, lj)= kindsget (op, d)	ostckts = s · r	check(s, l) sj = f (d, s, h)	sj ∈ OpStack	ostckj = sj · r
pcj = next(cmthd, pcts)	P @pcts.mnmts.cnmts = get (op, d)	estts = null
P × h, ts → h, ts[ostck → ostckj][pc → pcj]	n-get
(3.8)
If it is impossible to obtain the requested value and an exception must be thrown (e.g. NullPointerException), f returns the location e of the exception in the heap and the resulting evaluation state is the exceptional state.


(l, f, lj)= kindsget (op, d)	ostckts = s · r	check(s, l)
e = f (d, s, h)	e ∈ Loc•	P @pcts.mnmts.cnmts = get (op, d)	estts = null
P × h, ts → h, ts[est → e]


exn-get
(3.9)



Instruction put
This instruction reads and modifies the operand stack and the heap without creating new locations. The general form of the instruction is put (op, d), where op is the operator and d contains an optional static argument—a qualified field name.
The role of kindsput (op, d) is similar to previous kinds with the function f of type Dput × OpStack × Heap → Heap ] Loc•. The function f attempts to modify the indicated field or array cell in the heap. If the indicated item exists and may be changed, f returns the modified heap.
Note that the value written by put does not have to be accessible by other threads immediately. In fact, any part of heap may be synchronized with the thread cache at any point of program execution, with Java Memory Model constraints preserved. In particular, the two halfs of a category-2 value may be synchronized independently.

(l, f, lj) ∈ kinds(op, d)	ostckts = s · r	check(s, l)	ostckj = r hj = f (d, s, h)	hj ∈ Heap	pcj = next(cmthd, pcts)
P @pcts.mnmts.cnmts = put (op, d)	estts = null
P × h, ts → hj, ts[ostck → ostckj][pc → pcj]	n-put	(3.10)

If the requested object does not exist, an exception is thrown.


(l, f, lj) ∈ kinds(op, d)	ostckts = s · r	check(s, l)	ostckj = r e = f (d, s, h)	e ∈ Loc•
P @pcts.mnmts.cnmts = put (op, d)	estts = null
P × h, ts → h, ts[est → e]




exn-put




(3.11)


Instruction new
This instruction modifies the operand stack and the heap by creating a new location. The general form of the instruction is new (op, d), where op is the operator and d is a list of its arguments (integers and class names).
The precise meaning of the instruction is given by the function f , obtained from kindsnew (op, d), together with expected kinds of arguments on the stack and the expected kinds of values to be stored on the operand stack, which is actually always one value of kind ref. The function f itself manipulates the heap, allocating the requested structure and returning the location of the allocated structure and the new heap in case of success, and the exception otherwise.
Note that this instruction and its rules are very similar to put . We preferred to keep the two separated as new adds new locations to the heap while put only modifies existing ones.

(l, f, lj)= kindsnew (op, d)	ostckts = s · r	check(s, l)	ostckj = sj · r
(sj, hj)= f (d, s, h)	sj ∈ OpStack	hj ∈ Heap
pcj = next(cmthd, pcts)	P @pcts.mnmts.cnmts = new (op, d)	estts = null
P × h, ts → hj, ts[ostck → ostckj][pc → pcj]	n-new
(3.12)


(l, f, lj)= kindsnew (op, d)
ostckts = s · r	check(s, l)	e = f (d, s, h)	e ∈ Loc• P @pcts.mnmts.cnmts = new (op, d)	estts = null P × h, ts → h, ts[est → e]




exn-new




(3.13)

Instruction monitor
This instruction can modify the state of threads by trying to acquire or release a monitor. The operation itself is done by modifying an object on the heap. The monitor instruction expects one location on the operand stack: the object with which the monitor in question is associated. The general form of the instruction is monitor (op), where op is either enter or exit .

Both variants of the instruction are handled by the same two rules — one for correct operation, one for raising an exception. The rules are governed by a partial function f : ThreadId × Loc × ThreadId × N ~ ThreadId × N ∪ Loc obtained from kindsmonitor (op). If op = enter, f (tidj, s, tid, c) is defined only if s = null or tid = none or tid = tidj. In the first case f returns a NullPointerException, in the second (tidj, 1), and in the third (tidj,c + 1). Since f is not defined when s /= null and tidj /= tid /= none, i.e. the monitor is owned by a different thread, the rule cannot be fired until the monitor is released.
If op = exit, f returns the exception IllegalMonitorStateException if tid /= tidj and otherwise either NullPointerException or (none, 0) or (tid,c− 1) depend- ing on the values of s and c.
For the lack of space we did not formalize other synchronization operations related to synchronized methods. Note however, that it is quite easy to syntactically transform a synchronized method into one having monitor (enter ) at the beginning and monitor (exit ) at every exit point.


f = kindsmonitor (op)	ostckts = s · r	s ∈ Loc
(tidj, lcountj)= f (tidts, s, h(s)@tid, h(s)@lcount)
tidj ∈ ThreadId	lcountj ∈ N	pcj = next(cmthd, pcts)	ostckj = r hj = h[s → h(s)[tid → tidj][lcount → lcountj]]
P @pcts.mnmts.cnmts = monitor (op)	estts = null
P × h, ts → hj, ts[pc → pcj][ostck → ostckj]	n-monitor
(3.14)

f = kindsmonitor (op)	ostckts = s · r	s ∈ Loc
e = f (tidts, s, h(s)@tid, h(s)@lcount)	e ∈ Loc
P @pcts.mnmts.cnmts = monitor (op)	estts = null
P × h, ts → h, ts[est → e]	exn-monitor	(3.15)

Instruction invoke
This instruction modifies the operand stack, the method frame stack and reads the heap. The general format of the instruction is invoke(mode, cnm, mnm), where mode is one of interface, special, static or virtual, and cnm and mnm are class and method name of the method that is supposed to be called.
The principal action of this instruction is to find the method code, prepare the new method frame and pass the execution to the new method instance. To do that the types l of expected values on the stack together with the expected types return by the method lj are read from kindsinvoke(mode, cnm, mnm), which

in turn reads them from the method signature. The list lj is of length at most 1. Next, the dispatch function is executed which checks that the method’s flags are not contradictory to the invoke mode, that the access rights are preserved (for private and protected methods) and selects the type of dispatch by returning either the class cnm for static dispatch or the class of the first location of s in h for dynamic dispatch. The dispatch function can also return an exception.
The rest of the n-invoke rule is devoted to the preparation of the new method frame: the function initlv places the arguments from the stack in the local variable table of the new frame after splitting values of type long and double and performing necessary floating-point value set conversions [12, Section 3.8.3]. Finally, the new method frame is put on the method frame stack with the empty initial operand stack and pc = 0.
Synchronized methods are not handled here, but please see the remark at the end of Section 3.9.
(l, lj)= kindsof invoke (mode, cnm, mnm)	 ostckts = s · r	check(s, l) cnmj = dispatch(mode, cnm, mnm, s, h)	tfsj = tfsts[ostck → r]
lvj = initlv (lvlength(P @mnm.cnm), s) tfsjj = ⟨cnmj, mnm, lvj, [ ], 0⟩· tfsj
P @pcts.mnmts.cnmts = invoke(mode, cnm, mnm)	estts = null
P × h, ts → h, ts[tfs → tfsjj]	n-invoke
(3.16)


(l, lj)= kindsof invoke (mode, cnm, mnm)	ostckts = s · r	check(s, l) e = dispatch(mode, cnm, mnm, s, h)	e ∈ Loc
P @pcts.mnmts.cnmts = invoke(mode, cnm, mnm)	estts = null
P × h, ts → h, ts[est → e]	exn-invoke
(3.17)

Instruction return
This instruction returns from the current method. It reads the operand stack and modifies the method frame stack by removing the current frame and updating the previous frame: moving the pc to the next instructions (usually over an invoke instruction) and updating the operand stack by pushing the return value, after the floating-point value set conversion [12, Section 3.8.3]. The general form of the instruction is return(l) where l is a list of kinds of length at most 1.
Even though [12] does not specify this explicitly, we decided to add the rule
n-term-return, to deal with the termination of the method corresponding to the

last frame on the frame stack.
These rules do not handle releasing of monitor when exiting a synchronized method. This can be simulated, however, by putting a monitor(exit) instruction before every return statement. Please see also the discussion in Section 3.9.

ostckts = s · r	check(s, l)
tfsts = f1 · ⟨cnmj, mnmj, lvj, ostckj, pcj⟩· tfstail	f1 ∈ MethodFrame tfsj = ⟨cnmj, mnmj, lvj, vsc(s) · ostckj, next(P @mnmj.cnmj, pcj)⟩· tfstail P @pcts.mnmts.cnmts = return(l)	estts = null
P × h, ts → h, ts[tfs → tfsj]	n-return
(3.18)


ostckts = s · r	check(s, l)	tfsts = [f ]	f ∈ MethodFrame
tfsj = []	tstatusj = TERMINATED
P @pcts.mnmts.cnmts = return(l)	estts = null
P × h, ts → h, ts[tfs → tfsj][tstatus → tstatusj]	n-term-return (3.19)


Instruction throw
This instruction takes no parameters, it reads and removes the location of the exception form the stack and changes the evaluation state of the current thread (the rule ex-throw ). The way the exceptions are handled in our semantics is the following. The evaluation state (est) component of each thread says if the execution is in the normal state, when est = null, or in exception handling state otherwise.
Note that the switch to the latter state can be done not only by executing the throw instruction but also by throwing an exception (e.g. NullPointerException) by other semantic rules. If est = e is a location of a valid exception, the remaining rules ex-in-handle, ex-out-handle or ex-term-handle can be fired, depending on the fact whether the exception is handled inside the current method or provokes its abrupt termination. In the latter case, the ex-term-handle rule handles the special case where the current method is the last on the method frame stack. This rule does not have a direct correspondence in [12], just like the rule n-term-return.
The feature which is not handled is the release of monitor when a synchronized method is abruptly terminated by an exception. Note however that this can be sim- ulated by adding a catch-all exception handler which would execute the instruction monitor(exit) and then rethrow the exception. See also the discussion at the end of Section 3.9.

ostckts = e · r	e ∈ Loc•
P @pcts.mnmts.cnmts = throw	estts = null
P × h, ts → h, ts[est → e]	ex-throw	(3.20)
ostckj = [e]	(pcts, h(e)@cnm) ∈ dom(P @etable.mnmts.cnmts) pcj = P @etable.mnmts.cnmts(pcts, h(e)@cnm)	estts = e ∈ Loc•
P × h, ts → h, ts[ostck → ostckj][pc → pcj][est → null]	ex-in-handle
(3.21)
(pcts, h(e)@cnm) /∈ dom(P @etable.mnmts.cnmts)
tfsts = f1 · f2 · tfstail	f1, f2 ∈ MethodFrame	estts = e ∈ Loc•

P × h, ts → h, ts[tfs → f2
· tfstail]	ex-out-handle

(3.22)
(pcts, h(e)@cnm) /∈ dom(P @etable.mnmts.cnmts) tfsts = [f ]	f ∈ MethodFrame	estts = e ∈ Loc•
P × h, ts → h, ts[tfs → [ ] ][tstatus → TERMINATED] ex-term-handle	(3.23)

Instructions without semantics
The functionality of a few instructions cannot be expressed by semantical transfor- mation of the runtime structures as their meaning is not described in JVM speci- fication [12]. These are breakpoint, impdep1, impdep2, and the instruction with the opcode 186. 7 Therefore, they are omitted from the paper. The opcode wide is taken into account along with the non-wide operations.
Conclusions
We have presented a concise formalisation of JVML which turns out to be factoris- able into 12 instruction mnemonics. This was possible because we separated generic operation of many instructions and tabularised particular behaviours of individual opcodes. In this way we rigorously reduced the overall complexity of the whole language without significantly sacrificing its features.

References
Atkey, R., CoqJVM: An executable specification of the Java Virtual Machine using dependent types, in: M. Miculan, I. Scagnetto and F. Honsell, editors, Types for Proofs and Programs, International Conference, TYPES 2007, Cividale des Friuli, Italy, May 2-5, 2007, Revised Selected Papers, Lecture Notes in Computer Science 4941 (2008), pp. 18–32.

7 JVM semantics says: ‘For historical reasons, opcode value 186 is not used.’


Chrząszcz, J., Modules in Coq are and will be correct, in: S. Berardi, M. Coppo and F. Damiani, editors, Types for Proofs and Programs, International Workshop, TYPES 2003, Torino, Italy, April 30 - May 4, 2003, Revised Selected Papers, Lecture Notes in Computer Science 3085, 2004, pp. 130–146.
Chrząszcz, J., P. Czarnik and A. Schubert, A dozen instructions make Java bytecode, available for download at http://www.mimuw.edu.pl/~chrzaszcz/papers/.

Consortium, M., Deliverable 3.1: Bytecode specification language and program logic (2006), available online from http://mobius.inria.fr.
Dean, D., E. Felten and D. Wallach, Java security: From HotJava to Netscape and beyond, Security and Privacy, IEEE Symposium on (1996), pp. 190–200.

Demange, D., T. Jensen and D. Pichardie, A provably correct stackless intermediate representation for Java bytecode, Technical Report Research Report 7021, INRIA (2009).
Freund, S. N., “Type systems for object-oriented intermediate languages,” Ph.D. thesis, Stanford University (2000).
Freund, S. N. and J. C. Mitchell, The type system for object initialization in the Java bytecode language, ACM Transaction on Programming Languages and Systems 21 (1999), pp. 1196–1250.

Gosling, J., B. Joy, G. Steele and G. Bracha, “The Java Language Specification, third edition,” The Java Series, Addison Wesley, 2005.
Kahrs, S., D. Sannella and A. Tarlecki, The definition of Extended ML: A gentle introduction, Theoretical Computer Science 173 (1997), pp. 445–484.
Klein, G. and T. Nipkow, A machine-checked model for a Java-like language, virtual machine, and compiler, ACM Transactions on Programming Languages and Systems 28 (2006), pp. 619–695.

Lindholm, T. and F. Yellin, “The Java (TM) Virtual Machine Specification (Second Edition),” Prentice Hall, 1999.
Pichardie, D., Bicolano – Byte Code Language in Coq (2006), http://mobius.inria.fr/bicolano. Summary appears in [4].
Pusch, C., Proving the soundness of a Java bytecode verifier specification in Isabelle/HOL, in:
R. Cleaveland, editor, Tools and Algorithms for Construction and Analysis of Systems, 5th International Conference, TACAS ’99, Amsterdam, The Netherlands, March 22-28, 1999, Proceedings, Lecture Notes in Computer Science 1579 (1999), pp. 89–103.

Qian, Z., A formal specification of Java Virtual Machine instructions for objects, methods and subrountines, in: Formal Syntax and Semantics of Java (1999), pp. 271–312.

St¨ark, R. F., J. Schmid and E. B¨orger, “Java and the Java Virtual Machine: Definition, Verification, Validation,” Springer, 2001.

Vall´ee-Rai, R., P. Co, E. Gagnon, L. Hendren, P. Lam and V. Sundaresan, Soot - a Java bytecode optimization framework, in: CASCON ’99: Proceedings of the 1999 conference of the Centre for Advanced Studies on Collaborative research (1999), p. 13.
