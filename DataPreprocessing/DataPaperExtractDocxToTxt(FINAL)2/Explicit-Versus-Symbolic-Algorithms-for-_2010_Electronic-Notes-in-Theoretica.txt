

Electronic Notes in Theoretical Computer Science 267 (2010) 15–28
www.elsevier.com/locate/entcs

Explicit Versus Symbolic Algorithms for Solving ALFP Constraints
Piotr Filipiuk Hanne Riis Nielson Flemming Nielson
DTU Informatics Technical University of Denmark
Kongens Lyngby, Denmark email: {pifi,riis,nielson}@imm.dtu.dk


Abstract
ALFP, Alternation-free Least Fixed Point logic, has successfully been used as an intermediate language in the implementation of static analysis and model checking problems. Clearly different analysis problems may give rise to ALFP clauses with different characteristics. There are also different approaches to solving ALFP clauses and some of those are better suited for certain kinds of clauses than others. The aim of this paper is to present two algorithms, one that is based on differential worklists and one based on BDD’s, and experiment with them.
Keywords: Static analysis, constraint solving, Alternation-free Least Fixed Point logic, binary decision diagrams, differential worklist algorithm.

Introduction
Static analysis can be seen as a two-phase process where we first transform the analysis problem into a set of constraints that, in the second phase, is solved to pro- duce the analysis result of interest. The constraints may be expressed in a language tailored to the problem at hand, or they may be expressed in a general purpose con- straint language; in this paper we follow the latter approach and consider ALFP, Alternation-free Least Fixed Point Logic, which is an extension of Datalog. ALFP has successfully been used as the constraint language for sophisticated analyses of a wide variety of programming paradigms including imperative, functional, concur- rent and mobile languages and more recently for model checking [4,12].
While a wide variety of analysis problems can be rephrased into the same con- straint language it is not necessarily the case that they all will benefit from the same solver techniques. We can for example imagine that certain solver techniques are better at handling certain types of input formulae, due to the use of specialized data structures. It is therefore desirable to be able to experiment with different data structures and algorithms for solving the constraints. Similar considerations

1571-0661 © 2010 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2010.09.015

can also be found in the area of model checking where the same tool may support different combinations of data structures and algorithms thereby allowing the user to choose the most appropriate combination for the problem at hand.
In this paper we report on two solver algorithms being developed for ALFP: one being a differential worklist algorithm, originally developed in [14], that is based on a representation of relations as prefix trees [14] and the other being a continuation passing style algorithm that is based on a BDD representation of relations [5]. BDD’s, originally designed for hardware verification, have already been used in a number of program analyses [19,3] and proven to be very efficient.
The rest of this paper is organized as follows. We first give the necessary back- ground information on Alternation-free Least Fixed Point Logic in Section 2. In Section 3 we describe the overall structure of the algorithm that is shared between the two solver algorithms. Sections 4 and 5 describe the data structures and the algorithms of the differential and the BDD based algorithms respectively. We con- tinue in Section 6 with experiments, employing model checking to verify a number of properties. We conclude in Section 7.
The logic ALFP
The alternation-free fragment of Least Fixed Point Logic (ALFP) [14] is an extension of Horn clauses allowing both existential and universal quantifications in precondi- tions, negative queries, disjunctions of preconditions, and conjunctions of conclu- sions. In order to deal with negative queries, we restrict ourselves to alternation-free formulae that are subject to a notion of stratiﬁcation defined below.
Definition 2.1 Given a fixed countable set X of variables, a non-empty and finite universe U and a finite alphabet R of predicate symbols, we define the set of ALFP formulae (or clause sequences), cls, together with clauses, cl, and preconditions, pre, by the grammar:

Here vi ∈ (X ∪ U ), x ∈ X , R ∈ R, k ≥ 0 and s ≥ 1.
Occurrences of R and ¬R in preconditions are called positive queries and negative queries, respectively, whereas the other occurrences of R are called assertions. We write 1 for the always true clause.
In order to ensure desirable theoretical and pragmatic properties in the presence of negation, we impose a notion of stratiﬁcation similar to the one in Datalog [1,6]. Intuitively, stratification ensures that a negative query is not performed until the predicate has been fully asserted. This is important for ensuring that once a pre- condition evaluates to true it will continue to be true even after further assertions

of predicates.
Definition 2.2 The formula cls = cl1, ··· , cls is stratified if there exists a function
rank : R→ {0, ··· , s} such that for all i = 1, ··· , s:
rank(R)= i for every assertion R in cli;
rank(R) ≤ i for every positive query R in cli; and
rank(R) < i for every negative query ¬R in cli.
To specify the semantics of ALFP we shall introduce the interpretations Q : R→ k Uk and ς : X → U for predicate symbols and variables, respectively. We shall write Q(R) for the set of k-tuples (a1,..., ak) from Uk associated with the k-ary predicate R and we write ς(x) for the atom of U bound to x. In the sequel we view the free variables occurring in a formula as constants from the finite universe U .
The satisfaction relations for preconditions pre, clauses cl and clause sequences cls
are specified by:
(Q, ς) |= pre,	(Q, ς) |= cl	and (Q, ς) |= cls
The formal definition is standard and is given in Appendix A.

Abstract algorithm
We shall present two algorithms for solving clause sequences; one being a differential worklist algorithm inspecting the tuples of the relations on an individual basis and another being a BDD based algorithm where the operations are performed at the level of relations. Although the underlying data structures of the two algorithms are very different they share the same overall structure and we shall present this in the present section and leave a more detailed discussion of the two algorithms to the next two sections.
Both algorithms operate with (intermediate) representations of the two interpre- tations ς and Q of the semantics; we shall call them env and result, respectively, in the following. In both algorithms result will be an imperative data structure that is updated as we progress. The data structure env is supplied as a parameter to the functions of the algorithms.
For both algorithms we have one function for each of the three syntactic cat- egories. The function solve takes a clause sequence as input and will call the function execute on each of the individual clauses. In the case of the differential worklist algorithm this takes the form

solve(cl1, ··· , cls) = execute(cl1)[ ]; ··· ; execute(cls)[ ]
where we write [] for the empty environment reflecting that we have no free variables in the clause sequences. In the case of the BDD based algorithm we shall use an explicit (imperative) stack keeping track of the clauses to be considered so here the

function takes the form
solve(cl1, ··· , cls) = let stack = [cl1, ··· , cls]
while stack /=[ ] do execute(pop stack)[ ]
where the function pop, as a side effect, pops the stack and returns its top element.
In both algorithms the function execute takes a clause cl as a parameter and a representation env of the interpretation of the variables. We have one case for each of the forms of cl:
execute(R(v1, ··· , vk))env = ··· 
execute(1)env = ()
execute(cl1 ∧ cl2)env = execute(cl1)env; execute(cl2)env execute(pre ⇒ cl)env = check(pre, execute(cl))env
execute(∀x : cl)env = let envj = ··· in execute(cl)envj
In the case of assertions the details depend on the actual algorithm and we shall return to those later. The case of conjunction is straightforward as we have to inspect both clauses. In the case of implication we make use of the function check that in addition to the precondition and the environment also takes the continuation execute(cl) as an argument. In the case of universal quantification we perform a recursive call using an updated environment; the details of which depend on the actual algorithm.
In both algorithms the function check takes a precondition, a continuation and an environment as parameters. The treatment of queries depends on the actual algorithm and so does the treatment of disjunction and universal quantification; except from the fact that the overall structure is:
check(R(v1, ··· , vk), next)env = ··· 
check(¬R(v1, ··· , vk), next)env = ··· 
check(pre1 ∧ pre2, next)env = check(pre1, check(pre2, next))env
check(pre1 ∨ pre2, next)env = ··· 
check(∃x : cl, next)env = let nextj = next ◦· · ·
let envj = ··· 
in check(cl, nextj)envj
check(∀x : cl, next)env = ··· 
For conjunction we exploit a continuation passing programming style and for ex- istential quantification we perform a recursive call using an updated environment

and an updated continuation; the details of which depend on the actual algorithm.
In the following two sections we give more details of the data structures used by the two algorithms and the missing cases in the above definitions.

Instantiation with differential worklist
In this section we present the main data structures and the details of the differential worklist algorithm [14,13]. The algorithm computes the relations in increasing or- der on their rank and therefore the negations present no obstacles. It combines the top-down solving approach of Le Charlier and van Hentenryck [7] with the propaga- tion of differences [8], an optimization technique for distributive frameworks which is also known in the area of deductive databases [2] or as reduction of strength transformations for program optimization [15]. As mentioned above the main data structures are env and result representing the (partial) interpretation of variables and predicates, respectively.
Here env is implemented as an array indexed by the variables and returning either None, which means that the variable is undefined or Some(a), which means that the variable is bound to a ∈ U . By using arrays we ensure that the values of variables can be accessed in constant time. The main operation on env is the function unify given by
⎧

unify(env, v, a)=	env[v '→ Some(a)] if v ∈X ∧ env[v]= None
⎪⎪⎩ fail	otherwise
It is extended to k-tuples in a straightforward way. The function unifiable will, when applied to env and a tuple (v1, ··· , vk), return the subset of Uk for which unify will succeed.
The interpretation of the predicate symbols Q is given by the global data struc- ture result, which is updated incrementally during computations. It is represented as a prefix tree that for each predicate R records the tuples currently known to be- long to R. The prefix trees themselves are implemented using a dynamic array that for each node n of the tree keeps a list of all currently available successor atoms, together with a hash table that maps pairs (n, a) of nodes n and atoms a to suc- cessor nodes. There are three main operations on the data structure result: the operation result.has checks whether a tuple of atoms from the universe is associ- ated with a given predicate, the operation result.sub returns a list of the tuples associated with a given predicate and the operation result.add adds a tuple to the interpretation of a given predicate.
Since Q is not completely determined from the beginning it may happen that a query R(v1, ··· , vk) inside a precondition fails to be satisfied at the given point in time, but may hold in the future when a new tuple (a1, ··· , ak) has been added to the interpretation of R. If we are not careful we will then lose the consequences that

adding (a1, ··· , ak) to R will have on the contents of other predicates. This gives rise to introducing yet another global data structure infl that records computations that have to be resumed for the new tuples; these future computations will be called consumers. The infl data structure is also represented as a prefix tree that for each predicate R records consumers that have to be resumed when the interpretation of R is updated. There are two main operations on the data structure infl: the operation infl.register that adds a new consumer for a given predicate and infl.consumers that activates all the consumers currently associated with a given predicate.
Let us now return to the description of the function execute for the cases that are specific for the differential algorithm, that is, the case of assertion and the case of universal quantification. In case of assertions the algorithm is as follows
execute(R(v1, ··· , vk))env =
let iterFun (a1, ··· , ak) = 
match result.has(R, (a1, ··· , ak)) with
| true → ()
| false →
result.add(R, (a1, ··· , ak))
iter (fun f → f (a1, ··· , ak)) (infl.consumers R)
in iter iterFun (unifiable(env,(v1, ··· , vk)))
The function uses the auxiliary function iter, which applies the function iter- Fun to each element of the list of k-tuples that can be unified with the argument (v1, ··· , vk). Given a tuple (a1, ··· , ak), the function iterFun adds the tuple to the interpretation of R stored in result if it is not already present. If the add operation succeeds, we first create a list of all the consumers currently registered for predicate R by calling the function infl.consumers. Thereafter, we resume the computations by iterating over the list of consumers and calling corresponding continuations.
In the case of universal quantification, we simply extend the environment to record that the value of the new variable is unknown and then we recurse:
execute(∀x : cl)env = execute(cl)((x, None) :: env)
Turning to the check function let us first consider the algorithm in the case of positive queries:
check(R(v1, ··· , vk), next)env =
let consumer (a1, ··· , ak) = 
match unify(env, (v1, ··· , vk), (a1, ··· , ak)) with
| fail → ()
| env’ → next env’
in infl.register(R,consumer); iter consumer (result.sub R)
We first ensure that the consumer is registered in infl, by calling function reg- ister, so that future tuples associated with R will be processed. Thereafter, the function inspects the data structure result to obtain the list of tuples associated with the predicate R. Then, the auxiliary function consumer unifies each tuple

with (v1, ··· , vk); and if the operation succeeds, the continuation next is invoked on the updated new environment.
In the case of negated query, the algorithm is of the form
check(¬R(v1, ··· , vk), next)env =
let iterFun (a1, ··· , ak) = 
match result.has(R, (a1, ··· , ak)) with
| true → ()
| false → next (unify(env, (v1, ··· , vk), (a1, ··· , ak)))
in iter iterFun (unifiable(env, (v1, ··· , vk)))
The function first computes the tuples unifiable with (v1, ··· , vk) in the environment env. Then, for each tuple it checks if the tuple is already in R and if not, the tuple is unified with (v1, ··· , vk) to produce new environment in which the continuation next is evaluated.
The check function for disjunction of preconditions is as follows
check(pre1 ∨ pre2, next)env =
check(pre1, next)env; check(pre2, next)env
The function simply checks preconditions pre1 and pre2 respectively in the current environment env. In order to be efficient we use memoization; this means that if both checks yield the same bindings of variables, the second check does not need to consider the continuation, as it has already been done.
The algorithm for existential quantification checks the precondition pre in the environment extended with the quantified variable. The continuation that is passed is a composition of functions next and tail, where the function tail removes quan- tified variable from the environment passed as a parameter. The algorithm is as follows:
check(∃x : pre, next)env =
check(pre, next ◦ tail)((x, None) :: env)
In the case of universal quantification the function check needs to inspect all atoms from the universe and find the extensions of env that are compatible with the pre- condition pre. In order to do that we iterate over the entire universe, successively binding the atoms to x and modifying the partial environments to be compatible with the precondition pre. We enumerate the universe using the auxiliary function loop, which is initially called with the complete list of atoms in the universe. The recursive structure of the function loop reflects the fact that universal quantifica- tion is a conjunction over the entire universe. The pseudo code for the case is as follows:
check(∀x : pre, next)env =
let loop Uj env’ =
match Uj with
| hd :: tl → check(pre, loop tl) ((x, Some(hd)) :: env’)
| [ ] → next env’
in loop U ((x, None) :: env)

Instantiation with BDD’s
We now turn our attention to the BDD based algorithm. This algorithm also makes use of the data structures env and result, but this time they are represented as bi- nary decision diagrams, or, to be more precise, by ordered binary decision diagrams (OBDD’s). The use of BDD’s allows us to operate on entire relations, rather than on individual tuples - as in the differential worklist algorithm. Furthermore, the cost of the BDD operations depends on the size of the BDD and not the number of tuples in the relation; hence dense relations can be computed efficiently as long as their encoded representations are compact.
Each BDD is defined over a finite sequence of distinct domain names. The main operations on BDD’s, to be used in the following, are given by means of operations on the relations they represent. Given two relations with the same domain names, the operations union, ∪, and proper subset testing, Ç, are defined as a corresponding operations on the set of their tuples. The projection operation, π, selects the subset of domains from the relation and removes all other domains. The select operation, σb, selects all tuples from the relation for which the given condition b holds. The complement operation, C, on the relation R returns a new
relation containing tuples that are not in R. Given two relations with pairwise
disjoint domain names, the product operation, ×, is defined as a Cartesian product of their tuples. The operation ∀di is the universal quantification of variables in domain di. It removes tuples from the relation by universal quantification over domain di.
The environment env and the interpretation of the predicates in result are represented as OBDD data structures. We need to keep track of the domain names of the BDD’s so the environments and predicates will be annotated with subscript [d1, ··· , dk] denoting a list of pairwise disjoint domain names. In the case of en-
vironments env[x1,··· ,xn] the domain names represent the variables currently in the scope.
Also in the BDD algorithm we shall use a data structure called infl, however, it is somewhat different from that of the differential algorithm. Given a relation R, infl[R] will determine the set of clauses that queries R; that is when R occurs in a precondition. Assuming that R has rank i and that cli = {cli1, ··· , clini } we define
infl (R)= {clij | R is a query in clij}
The data structure is implemented as a map. When new tuples are added to the interpretation of the predicate R, the clauses of infl[R] are pushed on the stack; hence they will be processed later with the updated interpretation of the predicate R.
We shall now present the parts of the algorithm that are specific for the BDD based algorithm. We begin with the case of assertion for the execute function, which is defined as follows:
execute(R[d1,··· ,dk ](v1, ··· , vk))env[x1,··· ,xn] =
for i =1 to k do
env[x1,··· ,xn,d1,··· ,di] → σvi=di (env[x1,··· ,xn,d1,··· ,di−1] × U[di])

oldR[d1,··· ,dk ] → result[R]
result[R] → oldR[d1,··· ,dk] ∪ π[d1,··· ,dk](env[x1,··· ,xn,d1,··· ,dk])
if oldR[d1,··· ,dk ] Ç result[R] then
stack.push(infl[R])
In the for loop the function incrementally builds a product of the current environ- ment and a relation representing the universe, and simultaneously selects the tuples compatible with the arguments (v1, ··· , vk). Then, the resulting relation is pro- jected to the domain names of R, and the content of R is updated with the newly derived tuples. Additionally, if the interpretation of predicate R has changed, the influence set infl of the predicate R is pushed on the stack.
The case of universal quantification is of the following form:
execute(∀x : cl)env[x1,··· ,xn] =
execute(cl)(env[x1,··· ,xn] × U[x])
The function extends the current environment with a domain for the quantified variable, and then executes the clause cl.
Turning to the check function, we first present the case for the query, which is as follows:
check(R[d1,··· ,dk ](v1, ··· , vk), next)env[x1,··· ,xn] = env’[x1,··· ,xn,d1,··· ,dk] → env[x1,··· ,xn] × result[R] for i =1 to k do
env’[x1,··· ,xn,d1,··· ,dk] → σvi=di (env’[x1,··· ,xn,d1,··· ,dk])
env’[x1,··· ,xn] → π[x1,··· ,xn](env’[x1,··· ,xn,d1,··· ,dk]) next(env’[x1,··· ,xn])
First, the function creates an auxiliary relation, which is a product of the relations representing the current environment and the predicate R. The for loop selects tuples that are compatible with the arguments (v1, ··· , vk) producing a new relation
that is then projected to the domain names of env[x1,··· ,xn]. The resulting relation is then applied to continuation next.
The case of negated query is similar, except that the predicate is complemented first. The algorithm for this case is of the following form:
check(¬R[d1,··· ,dk ](v1, ··· , vk), next)env[x1,··· ,xn] = env’[x1,··· ,xn,d1,··· ,dk] → env[x1,··· ,xn] × (C result[R]) for i =1 to k do
env’[x1,··· ,xn,d1,··· ,dk] → σvi=di (env’[x1,··· ,xn,d1,··· ,dk])
env’[x1,··· ,xn] → π[x1,··· ,xn](env’[x1,··· ,xn,d1,··· ,dk]) next(env’[x1,··· ,xn])
The check function for disjunction of preconditions is as follows:
check(pre1 ∨ pre2, next)env[x1,··· ,xn] =
check(pre1, λenv1	.
check(pre2, λenv2	.

[x1,··· ,xn]
next(env1	∪ env2
))env[x ,··· ,x ])env[x ,··· ,x ]

[x1,··· ,xn]
[x1,··· ,xn]
1	n	1	n

The function first checks both preconditions pre1 and pre2 in the current envi-

ronment env[x1,··· ,xn]. Unlike in the differential algorithm, the continuation next is

evaluated in the union of env1
1	n
2
[x1,··· ,xn]
, which were produced by calls

to the procedure check for preconditions pre1 and pre2 respectively.
In the case of existential quantification in precondition, the algorithm is as fol- lows:
check((∃x : pre, next)env[x1,··· ,xn] =
check(pre, next ◦ π[x1,··· ,xn])(env[x1,··· ,xn] × U[x])
The function first extends the current environment, in which the precondition is checked. Furthermore, before calling the continuation next, the domain for the quantified variable is projected out.
The universal quantification is dealt in the following way:
check(∀x : pre, next)env[x1,··· ,xn] =
check(pre, next ◦ (∀x))(env[x1,··· ,xn] × U[x])
The algorithm utilizes universal quantification of variables in a given domain, de- noted by ∀x, which is a standard BDD operation provided by the BDD package [10]. The operation removes tuples from the given relation by universal quantifi- cation over the given domain. Hence in the case of the BDD based algorithm it is enough to extend the current environment with a quantified variable, check the precondition in the extended environment and then perform universal quantification on the returned environment.

Experiments
The two algorithms have been implemented in F #, thereby allowing us to perform experiments for clauses with different characteristics. In this section we report on our experiments on problems arising from a modal logic representation of analysis problems. We make use of Action Computation Tree Logic (ACTL) [11] model checking to validate properties of programs written in a Pascal-like imperative lan- guage. A number of papers [18,17,16,9] have already noted the connection between iterative data-flow analysis and model checking. As an example the following ACTL formula expresses whether a variable x may have been last assigned at label l:
wasLastAssignedAt(x,l) = EF(a|a/=modx)(l ∧ EXmodx (true))
The formulation is based on abstractions of the actions that annotate the edges of a program model. Assignment statements, x := e, are abstracted to actions modx, whereas all other statements are abstracted to actions use. Intuitively, the formula verifies whether there exists a path, EF, not modifying variable x, leading to a state labeled l which has outgoing transition, EX, that modifies x. The ACTL formula is translated into the ALFP formula:

[∀s : [∃a : ∃sj : T (s, a, sj) ∧ ¬modx(a) ∧ R1(sj)] ⇒ R(s)]∧
[∀s : [∃a : ∃sj : T (s, a, sj) ∧ R(sj)] ⇒ R(s)]


2


1.5

1
1.5

1



0.5
0.5



0
0	50	100	150	200
number of states
formulaEX
0
0	50	100	150	200
number of states
formulaEU

Fig. 1. Running time for modalities EX and EU.






where R1 holds for all states satisfying (l ∧ EXmodx (true)) and T is a transition relation.
The scalability of the solver algorithms is assessed by measuring the amount of time required to verify different ACTL properties as a number of program states increases. In the experiments we consider formulae presented in Appendix B, which are then translated into ALFP as shown in [12].
Figures 1 and 2 show the growth in milliseconds of time consumption from these experiments. The solving time is depicted by a dashed line for the BDD based algorithm and a solid line for the differential one.
From the experiment results for modalities EX and EU we observed that both algorithms were slightly slower for the second case. This is caused by two fac- tors, greater length of the formula for modality EU and secondly the nesting of quantifiers, which in both cases is the same. Together, these factors determine the complexity of the algorithm [14]. What is more, the results show that the differen- tial algorithm outperformed BDD implementation by a factor of two in both cases. This is caused by the fact that when resuming computations the differential algo- rithm only propagates the differences, whereas in the current implementation of the BDD based algorithm entire clauses are recomputed.
Turning to results for modalities AX and AU there was a large difference in performance between the differential and BDD based algorithm. The reason for this is that the ALFP formulae expressing these modalities make use of universal quan- tification in precondition, for which the algorithms use different solving strategies. The differential algorithm inspects all atoms from the universe and finds the exten- sions of the current environment that are compatible with the given precondition. The BDD based algorithm, on the other hand, utilizes universal quantification on BDD’s that is computed in time O(n2), where n is the size of the BDD; hence it is much more efficient.


4	4

3	3

2	2

1	1


20	40	60	80	100	120
number of states
formulaAX
20	40	60	80	100	120
number of states
formulaAU

Conclusion
Fig. 2. Running time for modalities AX and AU.

This paper described two solver algorithms that use ALFP as the input language, one being a differential worklist algorithm based on a representation of relations as prefix trees and the other being a continuation passing style algorithm based on a BDD representation of relations. Currently no tuning of the clauses or variables is performed for any of the algorithms. Through the series of experiments we have shown how certain algorithms and data structures are better suited to certain kind of clauses than others. We have presented how, on the one hand, model checking problems benefit from the use of BDD’s, and on the other, how static analysis problems take advantage of the differential solving approach. We have commented on the experiments, thus, explaining the coherence between the techniques used and the actual solving times. In future work we plan to employ heuristics for clause tuning and variable ordering, in order to improve solving times. We also hope to identify other data structures and methods that can be efficiently employed in constraint solving.

References
Apt, K. R., H. A. Blair and A. Walker, Towards a theory of declarative knowledge, in: Foundations of Deductive Databases and Logic Programming., Morgan Kaufmann, 1988 pp. 89–148.
Balbin, I. and K. Ramamohanarao, A generalization of the differential approach to recursive query evaluation, Journal of Logic Programming 4 (1987), pp. 259–262.
Berndl, M., O. Lhot´ak, F. Qian, L. J. Hendren and N. Umanee, Points-to analysis using BDDs, in:
PLDI, 2003, pp. 103–114.
Bodei, C., M. Buchholtz, P. Degano, F. Nielson and H. R. Nielson, Static validation of security protocols, Journal of Computer Security 13 (2005), pp. 347–390.
Bryant, R. E., Symbolic boolean manipulation with ordered binary-decision diagrams, ACM Comput. Surv. 24 (1992), pp. 293–318.
Chandra, A. K. and D. Harel, Computable queries for relational data bases (preliminary report), in:
STOC, 1979, pp. 309–318.
Charlier, B. L. and P. V. Hentenryck, A universal top-down fixpoint algorithm, Technical report, CS- 92-25, Brown University (1992).

Fecht, C. and H. Seidl, Propagating differences: An efficient new fixpoint algorithm for distributive constraint systems, Nordic Journal of Computing 5 (1998), pp. 304–329.
Lamprecht, A.-L., T. Margaria and B. Steffen, Data-flow analysis as model checking within the jABC, in: CC, 2006, pp. 101–104.
Lind-Nielsen, J., Buddy, a binary decision diagram package .
URL http://sourceforge.net/projects/buddy/
Nicola, R. D. and F. W. Vaandrager, Action versus state based logics for transition systems, in:
Semantics of Systems of Concurrent Processes, 1990, pp. 407–419.
Nielson, F. and H. R. Nielson, Model checking is static analysis of modal logic, in: FOSSACS, 2010,
pp. 191–205.
Nielson, F., H. R. Nielson, H. Sun, M. Buchholtz, R. R. Hansen, H. Pilegaard and H. Seidl, The succinct solver suite, in: TACAS, 2004, pp. 251–265.
Nielson, F., H. Seidl and H. R. Nielson, A Succinct Solver for ALFP, Nord. J. Comput. 9 (2002),
pp. 335–372.
Paige, R., Symbolic finite differencing - part i, in: ESOP’90, LNCS 432 (1990), pp. 36–56.
Schmidt, D. A., Data flow analysis is model checking of abstract interpretations, in: POPL, 1998, pp. 38–48.
Schmidt, D. A. and B. Steffen, Program analysis as model checking of abstract interpretations, in: SAS, 1998, pp. 351–380.
Steffen, B., Data flow analysis as model checking, in: TACS, 1991, pp. 346–365.
Whaley, J. and M. S. Lam, Cloning-based context-sensitive pointer alias analysis using binary decision diagrams, in: PLDI, 2004, pp. 131–144.

Semantics of ALFP
We write ς[x '→ a] for the mapping that is as ς except that x is mapped to a. The semantics of preconditions, clauses and clause sequences is given by:
(Q, ς) |= R(v1,..., vk)	iff (ς(v1),...,ς(vk)) ∈ Q(R)
(Q, ς) |= ¬R(v1,..., vk) iff (ς(v1),...,ς(vk)) ∈/ Q(R)
(Q, ς) |= pre1 ∧ pre2	iff (Q, ς) |= pre1 and (Q, ς) |= pre2
(Q, ς) |= pre1 ∨ pre2	iff (Q, ς) |= pre1 or (Q, ς) |= pre2
(Q, ς) |= ∃x : pre	iff (Q, ς[x '→ a]) |= pre for some a ∈U 
(Q, ς) |= ∀x : pre	iff (Q, ς[x '→ a]) |= pre for all a ∈U 


(Q, ς) |= R(v1,..., vk)	iff (ς(v1),...,ς(vk)) ∈ Q(R) (Q, ς) |= 1	iff true
(Q, ς) |= cl1 ∧ cl2	iff (Q, ς) |= cl1 and (Q, ς) |= cl2
(Q, ς) |= pre ⇒ cl	iff (Q, ς) |= cl whenever (Q, ς) |= pre
(Q, ς) |= ∀x : cl	iff (Q, ς[x '→ a]) |= cl for all a ∈U 


(Q, ς) |= cl1, ··· , cls	iff (Q, ς) |= cli for all i, 1 ≤ i ≤ s

Expermiments input formulae
We present formulae used in experiments together with their translations to ALFP. For ease of presentation we introduce auxiliary formula φ = l∧ EXmodx (true), which is translated into following ALFP clauses defining relation R(lΛEXmodx (true)).
[∀s : Rtrue(s)]∧
[∀s : [∃a : ∃sj : T (s, a, sj) ∧ modx(a) ∧ Rtrue(sj)] ⇒ R(EX	(true))(s)]∧
[∀s : Rl(s) ∧ R(EXmodx (true))(s) ⇒ R(lΛEXmodx (true))(s)]∧

The relation is then used in the input clauses generated from ACTL formulae used in the experiments. The ACTL formulae along with corresponding ALFP clauses are given below.

formulaEX = EX(a|a/=modx)(l ∧ EXmodx (true))
[∀s : [∃a : ∃sj : T (s, a, sj) ∧ modx(a) ∧ R(lΛEX	(true))(sj)] ⇒ R(EX	(lΛEX	(true)))(s)]

formulaAX = AX(a|a/=modx)(l ∧ EXmodx (true))
[∀s : [∀a : ∀sj : ¬T (s, a, sj) ∨ (notmodx(a) ∧ Rtrue(sj))]∧
[∃a : ∃sj : T (s, a, sj)] ⇒ R(AX	(true))(s)]

formulaEU = E[true AU{a|a/=modx} (l ∧ EXmodx (true))]
[∀s : [∃a : ∃sj : T (s, a, sj) ∧ notmodx(a) ∧ R(lΛEX	(true))(sj)] ⇒
R(E[trueAUnotmodx (lΛEXmodx (true))])(s)]∧

[∀s : [∃a : ∃sj : T (s, a, sj) ∧ A(a) ∧ Rtrue(sj) ∧ R(E[true U

notmodx
(lΛEXmodx
(true))])(sj)] ⇒

R(E[trueAUnotmodx (lΛEXmodx (true))])(s)]


formulaAU = A[true AU{a|a/=modx} (l ∧ EXmodx (true))] [∀s : [[∃a : ∃sj : T (s, a, sj)]∧
[∀a : ∀sj : ¬T (s, a, sj) ∨ [notmodx(a) ∧ R(lΛEX	(true))(sj)]∨

[A(a) ∧ Rtrue(sj) ∧ R(A[true U

notmodx

(lΛEXmodx
(true))])(sj)]] ⇒

R(A[trueAUnotmodx (lΛEXmodx (true))])(s)]
