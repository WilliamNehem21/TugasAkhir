Available online at www.sciencedirect.com


Electronic Notes in Theoretical Computer Science 321 (2016) 67–88
www.elsevier.com/locate/entcs

A Model to Guide Dynamic Adaptation Planning in Self-Adaptive Systems
Andr´es Paz 1,2,3
Universit´e du Qu´ebec, E´cole de Technologie Sup´erieure, Montr´eal, Canada
Hugo Arboleda 1,2,4
Universidad Icesi, I2T Research Group, Cali, Colombia

Abstract
Self-adaptive enterprise applications have the ability to continuously reconfigure themselves according to changes in their execution contexts or user requirements. The infrastructure managing such systems is based on IBM’s MAPE-K reference model: a Monitor and an Analyzer to sense and interpret context data, a Planner and an Executor to create and apply structural adaptation plans, and a Knowledge manager to share relevant information. In this paper we present a formal model, built on the principles of constraint satisfaction, to address dynamic adaptation planning for self-adaptive enterprise applications. We formalize, modify and extend the approach presented in [1] for working with self-adaptation infrastructures in order to provide automated reasoning on the dynamic creation of structural adaptation plans. We use a running example to demonstrate the applicability of such model, even in situations where complex interactions arise between context elements and the target self-adaptive enterprise application.
Keywords: Self-Adaptive Enterprise Applications, Dynamic Adaptation Planning, Automated Reasoning.

Introduction
Currently many Enterprise Applications (EAs) live in dynamic execution contexts, interacting with other systems, and under the influence of stimuli from sources inside or outside the system scope. This may affect their behavior or the levels at which they satisfy agreed quality; however, regardless of these impacts, they still have to fulfill their service quality agreements. On the one hand, the fulfillment of quality agreements is completely and utterly dependent on system architectures,

1 This work has been partially supported by grant 0369-2013 from the Colombian Administrative Depart- ment of Science, Technology and Innovation (Colciencias) under project SHIFT 2117-569-33721.
2 We thank Miguel Jim´enez and Gabriel Tamura for their contributions on the project and the architecture of the SHIFT framework.
3 Email: afpaz@icesi.edu.co
4 Email: hfarboleda@icesi.edu.co

http://dx.doi.org/10.1016/j.entcs.2016.02.005
1571-0661/© 2016 The Authors. Published by Elsevier B.V.
This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).

which comprises software architecture, hardware and network infrastructure. On the other hand, in response to ever increasing needs for strengthened responsiveness and resiliency, quality agreements may evolve to reflect this business reality.
Autonomic computing deals with the management of independent components capable of handling both external resources and their internal behavior, which are constantly interacting in accordance with high-level policies. Its required infrastruc- ture usually integrates an autonomic manager, an implementation of the generic con- trol feedback loop from control theory, and managed components. Most autonomic managers are based on the MAPE-K reference model [2], allowing software systems to be adapted to context changes in order to ensure the satisfaction of agreed Service Level Agreements (SLAs). Five elements make up the reference model: Monitor, Analyzer, Planner, Executor and Knowledge Manager. The Monitor continuously senses context conditions and the Analyzer interprets and compares the sensed data with SLAs, the Planner synthesizes and creates adaptation plans when required, and the Executor alters the system’s behavior by modifying its structure in accor- dance with a given adaptation plan. All of them share information through the Knowledge Manager element.
In this paper we present a formal model, built on the principles of constraint satisfaction, to address the task of the Planner element, i.e. dynamic adaptation planning for self-adaptive enterprise applications. Our work in this paper is focused around changing quality agreements while EAs are already operational. This task, however, has a direct impact on system architecture. We consider in this work only the relationships of such quality agreements with software architecture in order to plan the necessary structural adaptations to meet the new quality specifications. We use a running example to demonstrate the applicability of such model, even in situations where complex interactions arise between context elements and the target self-adaptive enterprise application. In the context of product line engineering, decision and resolution models have been used for planning the composition of core assets according to variable configurations that include user requirements, e.g., [3,4]. All of such approaches, however, deal with problems related to product configuration without taking into account the problem of planning dynamic adaptation of systems. Some authors have explored different trends for generating reconfiguration plans.
For instance [5,6] use artificial intelligence based on hierarchical task networks and situation calculus, respectively, to plan new web service compositions in an attempt to overcome faults. [7] calculates fuzzy values of quality of service (QoS) levels for available service variants and selects the variants with the nearest QoS levels that fit the context and user requeriements. There are other approaches that implement dynamic adaptation of service compositions, e.g., [8,9,10]; however, they neither provide implementation details nor formal specifications of any formal model for planning activities.
In previous work [1], we presented an approach based on constraint satisfaction for product derivation planning in model-driven software product lines. There, we modeled the problem of planning the transformation workflow to derive products as a constraint satisfaction problem. In this paper, we base on such model and we fur-

ther formalize, modify and extend it for working with self-adaptation infrastructures in order to provide automated reasoning on the creation of structural adaptation plans.
The remainder of this paper is organized as follows. Section 2 introduces the background of this work. Section 3 presents our motivating case along with an illustrative example which we use as a running example throughout the following sections. Section 4 details our formal model, including the necessary definitions and specifications. Section 5 describes the automated reasoning that we currently provide. Section 6 discusses related work. Finally, Section 7 sets out conclusions and outlines future work.

Background
Autonomic Computing
In [11], IBM researchers Kephart and Chess introduced an architectural approach to realize autonomic computing based on independent elements capable of managing both external resources and their internal behavior. In light of this, autonomic systems are compositions of these autonomic elements, constantly interacting in accordance with high-level policies. Each autonomic element is composed of an autonomic manager, an implementation of the generic control feedback loop from control theory, and a managed element, a hardware or software resource, such as a server, a service or a set of interconnected software components.
The autonomic manager, based on the MAPE-K reference model [2], is the infrastructure that allows the software systems to be adapted to unforeseen con- text changes in order to ensure the satisfaction of agreed Service Level Agreements (SLAs). Comprising this infrastructure is (i) a Monitor element that continuously senses relevant context and system control data; (ii) an Analyzer element that in- terprets monitoring events reported by the Monitor to determine whether the SLAs are being fulfilled; (iii) a Planner element that creates a configuration from the variability model according to the context conditions delivered by the Analyzer to generate an adaptation plan, which defines the modification required by the de- ployed system structure and the required parameters to reach a desired system state; (iv) an Executor element that realizes adaptation plans, which alters the sys- tem’s behavior; and (v) a Knowledge Manager element sharing relevant information among the other elements.

Dynamic Software Product Line Engineering
Software Product Line Engineering (SPLE) is an expanding approach that aims at developing a set of software systems that share common features and satisfy the requirements of a specific domain [12]. While having much in common, product line members still differ in functional and quality requirements. Variability management is the key process in SPLE that is in charge of dealing with the analysis, model- ing, design and realization of variants while considering adequate decision making

support for building products by using reusable assets.
Variability Models. Variability in SPLE is captured in variability models, such as the Orthogonal Variability Model (OVM) [13,12]. An OVM is a variability model designed to only document variability; we use OVMs in this paper to doc- ument variability in our running example described in Section 3.2. In OVMs like the one presented in Figure 1, a variation point (p) represents a variable item in a system and is depicted as a triangle. A variant (v) represents a particular option to instance the variation point and is depicted as a rectangle linked to the varia- tion point by one of three types of relationships. Relationships between variants and variation points may be mandatory, optional or set. A mandatory relationship, depicted in Figure 1 as a solid line, states that if a variation point p is present its child variant v must be present too. An optional relationship, depicted as a dotted line, states that if a variation point p is present its child variant vp may or may not be present. A set of children variants {vi | i = 1,..., z} has a set relationship with their parent variation point p when an interval [x, y] of its children vi can be included {vi | x ≤ i ≤ y} if their parent is present. This type of relationship is illustrated as variants grouped by an angular solid line with a label describing the interval. Relationships can also exist between variants of different variation points. Such relationships are, namely, requires and excludes; they are drawn as single ar- row line and double arrow line respectively. A requires relationship is a cross variant constraint that states that if variant requires variant vb then if va is present, vb must be present too. An excludes relationship is a cross variant constraint that states that if variant va excludes variant vb then the variants cannot be present at the same time. We give a formal definition of each relationship when we present our proposed model in Section 4.








Fig. 1. Orthogonal Variability Model
Dynamic SPLE. Dynamic SPLE [14] extends current product line engineering approaches by moving their capabilities to runtime, helping to ensure that system adaptations lead to desirable properties. It is concerned about the management of reusable and dynamically reconfigurable core assets, facing the challenge of bind- ing variants to such assets, at runtime, when software is required to be adapted according to context changes.
Decision and Resolution Models. When variants are selected by architects at design time (in the context of SPLE), or defined by context conditions at runtime

(in the context of dynamic SPLE), concrete core assets must be selected as part of the (re)composition plan. In practice, there is a significant gap between vari- ability at a conceptual level (variation points and variants) and variability at the implementation level (concrete core assets to be deployed). With the objective of closing that gap, decision and resolution models are used [4,15]. A decision model relates open decisions and possible resolutions to define the necessary actions to derive product line members in accordance with configurations, which are sets of selected variants. A resolution model is the instance of a decision model, and it is used to create a product line member. In a resolution model all the decisions captured in a decision model are resolved, thus, it defines a product line member including a subset of chosen variants, the core assets required to derive the desired product, and the adaptation that must be performed on the core assets to obtain such product line member.
Variant Interactions. Decision models rapidly become very complex artifacts in the face of many variants and, specially, when variants interactions appear. When several variants are combined interactions between them may occur; this means, the presence of one variant affects the behaviour of another. Let suppose a variant vi is related to a software component ci, and a variant vj is related to a software component cj, an interaction exists when the presence of vi and vj in one configuration raises a problem when composing ci and cj. Some variant interactions may be benign, planned or desirable, but others, in turn, may have unwanted effects that may disrupt the user from obtaining the expected behavior. Since the variant interactions problem can be arbitrarily complex and computationally difficult to treat, a formal approach is an appropriate and flexible option.

Constraint Satisfaction
A great variety of combinatorial problems can be expressed as searching for one or several elements in a vast space of possibilities. In general, the search space is defined as all combinations of possible values for a predefined set of variables. Elements to be searched for are particular values of these variables. In most cases the desired values of the elements are implicitly specified by properties they should satisfy. These properties are known as constraints, which are usually expressed as predicates over some set of variables. Roughly speaking, a problem formulated in this frame is known as a Constraint Satisfaction Problem (CSP) [16].
Solving a CSP consists of two steps: modeling the problem (logical specification) and finding its solutions through a form of search (in this paper we perform a basic backtracking). Modeling involves basically the specification of the variables, their domains and the constraints among them. Solving the CSP through backtracking is an attempt at trying to incrementally build resolution candidates by assigning possible values to the variables. Partial candidates that cannot become a valid solution are discarded. If all variables are bound, a resolution candidate has been found. If, after exploring all possibilities no resolution candidate has been found, then the problem does not have a solution.





















Fig. 2. High-level architectural view of the SHIFT elements.
Motivating Case
The SHIFT Framework
Our research group has proposed independent approaches and implementations in the contexts of autonomic computing with the DYNAMICO reference model [17], quality of service (QoS) contract preservation under changing execution conditions with QoS-CARE [18], model-based product line engineering with the FieSta ap- proach [4,15], automated reasoning for derivation of product lines [1], and the recent (unpublished) contributions regarding quality variations in the automated deriva- tion process of product lines [19]. The required integration of all these efforts in a move to approach automation and quality awareness along the life cycle of enter- prise applications has motivated the creation of what we call the SHIFT Framework. Figure 2 presents a high-level architectural view of SHIFT’s constituting elements. The Automated Derivation region is concerned with providing support for functional and quality configuration and derivation of deployable enterprise ap- plications components and monitoring infrastructure. Generated components are stored in the Component Repository, which is managed by a Knowledge Manager element; they are an input for the adaptation planning process. The monitoring infrastructure is deployed as part of the Autonomic Infrastructure region, which implements the adaptation feedback loop of the DYNAMICO reference model [17].

As part of the Planner element, our focus in this paper, SHIFT considers the need for dynamically planning adaptations to application structure based upon quality configurations. Realizing the adaptation plans in the deployed and operat- ing managed Enterprise Application (EA) considers transporting components from their source repository to the corresponding computational resource, undeploying previous versions of them, deploying them into the middleware or application server, binding their dependencies and services, and executing them. In addition, if neces- sary, to recompile system source code to make measurement interfaces available to the monitoring infrastructure.
In order to obtain the best possible selection of composable components, or optimum resolution, when planning an adaptation, we propose in this paper ad- dressing dynamic adaptation planning through a model built on the principles of constraint satisfaction, which will help reasoning upon the set of constraints defined by reachable quality configurations and their relationships with the components in the component repository. Following Section 4 will refer to the relationships between components in the component repository and the reachable quality configurations as decision models, and all the possible adaptation plans that can be derived from a decision model given a specific quality configuration as resolution models.
Running Example
To illustrate the problem of adapting an EA, while at runtime, when the set of quality agreements (captured as quality scenarios as explained by Bass et al. in [20]) changes, we use the case of a large-scale e-commerce application. We use this case as a running example throughout the following sections. The following sections give the details regarding how the Planner element of the SHIFT Framework captures adaptation constraints and reasons upon them to determine possible adaptation plans to satisfy changing context conditions.
With our example e-commerce application there is the need to handle component compositions and adaptations driven by different system quality levels in accordance with varying shopping activities (e.g., special offers on certain products, shopping frenzies). This implies working with varying quality scenarios. Thus, we use the OVM in Figure 3 to capture the different quality scenarios that can be configured for the e-commerce EA. The quality attribute, environment and stimuli fields of a quality scenario represent a variation point. The response field represents a variant. Figure 3 illustrates 3 variation points with all of their variants linked with optional relationships.
Suppose the e-commerce application has been initially deployed fulfilling the re- quirement of purchase by credit card and the quality configuration corresponds to the selection of quality scenarios V2 and V4 detailed in Table 1. The time-behavior scenario determines an average latency of 6 seconds for purchases with credit card under a load of 1,000 purchases per minute, stochastically. The conﬁdentiality scenario specifies all available sensitive information is encrypted to prevent unau- thorized access.
A component diagram for the implementation of the purchase with credit card








	







Fig. 3. Variability Model

requirement is illustrated in Figure 4. This implementation comprises (i) a Purchase component that manages the workflow performed for any purchase, (ii) a Credit Card Authorization component in charge of performing the workflow to get ap- proval for the transaction with the issuing bank (or credit card association), (iii) a Risk Tool component responsible for validating credit card information provided by the customer and the responses sent from the issuing bank, (iv) a Credit Card Settlement component that requests the transfer of funds from the issuing bank into the merchant’s account, (v) a Cryptography Manager component that pro- cesses the encryption and decryption of information to and from the issuing bank, and (vi) a Payment Processor component managing all communications to the multiple issuing banks. The payment processing behavior exhibited by the previous implementation is specified step by step in Figure 5.
For a first adaptation setting suppose now that, while in operation, the appli- cation’s initial quality configuration has been changed due to an expected peak in system load caused by an upcoming Cyber Monday shopping season. Particularly quality scenario V2 has been replaced by quality scenario V3, presented in detail in Table 2. Quality scenario V4 remains selected. In turn, the application’s con- stituent components must be changed to new ones developed with the modified quality configuration in mind.

Table 1
Quality scenarios for the e-commerce application

Quality Attribute	Performance – Time behavior

Environment	The application provides a set of services available
to concurrent users over the Internet under normal operating conditions.

Stimuli	Users initiate 1,000 purchases with credit card as payment method per minute, stochastically.

Response	Every purchase is processed with an average la- tency of 6 seconds.


Quality Attribute	Security – Conﬁdentiality

Environment	The application provides a set of services that
makes sensitive information available to other ap- plications over the Internet.

Stimuli	Another application intercepts data by attacking the network infrastructure in order to obtain sen- sitive information.

Response	The architecture does not control the other ap- plication’s access, but information is encrypted in order to prevent access to sensitive information.



Fig. 4. Partial set of components for initial e-commerce application





authorize payment
validate credit card information
encrypt payment information
request reserve
decrypt response
validate response
settle payment
encrypt settlement information
request settlement
decrypt response

Fig. 5. Component collaboration for initial e-commerce application Table 2
Modified time-behavior scenario for the e-commerce application

Quality Attribute	Performance – Time behavior

Environment	The application provides a set of services available
to concurrent users over the Internet under normal operating conditions.

Stimuli	Users initiate 20,000 purchases with credit card as payment method per minute, stochastically.

Response	Every purchase with credit card as payment method is processed with an average latency of 2 seconds.

The adapted implementation for the purchase with credit card requirement is illustrated in Figure 6. This implementation comprises modified versions of the Purchase, Credit Card Authorization and Credit Card Settlement compo- nents. These modified components are marked with an asterisk symbol (*). A new component appears, the Order Manager component, which provides a consol- idated and automated processing of orders. The Payment Processor component remains unchanged. The behavior of this implementation is changed due to the structural adaptation performed that streamlined the workflow in comparison with

the initial deployment. Figure 7 shows the collaboration steps between the new set of components.


Fig. 6. Partial set of components for adapted e-commerce application



authorize payment
request reserve
store order
settle payment
request settlement



Fig. 7. Component collaboration for adapted e-commerce application
Suppose now, for a second adaptation setting, that to further strengthen the ap- plication to cope with the coming sales burst a new quality configuration has been specified selecting quality scenarios V3, V4 and V6. The new availability scenario V6 in Table 3 states that the system initializes and puts into operation spare com- ponents when part of the application becomes unavailable. The spare components are initialized from a persistent state before entering into operation. Thus, this

response requires the use of persistent storage (e.g., database) to maintain applica- tion state and be able to replace failed components. Let’s assume that the Payment Processor helps meet the time-behavior scenario in Table 2 due to its use of a cache to avoid requests to the database. A variant interaction arises when trying to fulfill both quality scenarios, as the availability scenario makes accessing the database mandatory and no caches are permitted. Hence, the availability scenario cannot be promoted with the planned adaptation shown in Figure 6. A new solution needs to be designed or the quality scenario needs to be either redefined or dropped.
Table 3
New quality scenario for the e-commerce application

Quality Attribute	Reliability – Availability

Environment	A subsystem of the application becomes unavail-
able.
Stimuli	Users initiate transactions to the affected subsys- tem.

Response	Spare components are initialized and placed into operation.


Self-Adaptation Planning
The previous e-commerce application provides an interesting example of the deci- sions that need to be taken when planning an adaptation to satisfy changing quality scenarios. Manually evaluating all component compositions, their relationships to quality scenarios and quality scenario interactions are costly, time consuming and error-prone; even more when the software system is already operational. In this section we propose an approach addressing dynamic adaptation planning built on the principles of constraint satisfaction.
Benavides et al. in [21] propose mapping variability models, particularly feature models, to an equivalent CSP representation in order to deal with the automated analysis of such models. To be able to analyze varying quality scenarios for the creation of adaptation plans we translate input OVMs holding the quality scenarios into a specific CSP representation. Definition 4.1 formally describes this CSP as a quality model. It is modified from the one presented for the translation of feature models into CSP in [21].
Definition 4.1 A quality model μ is a three-tuple of the form (Q, W, R); where Q is a finite set of l variables made up of h variation points p and i variants v; W is a finite set of domains made of the variants’ configuration states, with a state of 1, if the quality scenario is unselected, or 2, if the quality scenario is selected; and R is a finite set of constraints defined on Q.



Q = {{⟨pk⟩| k = 1,..., h}, {⟨vi⟩| i = 1,..., n}}


W = ((W
= [1..2] | ⎧⎪ 1 if pk is unselected ⎫⎪ ),

pk	⎪ 2 if p
(	⎪
is selected
⎫⎪⎭))	(1)

1 if vi is unselected
W	= [1..2] |
 

R = {rmandatory, roptional, rset, rrequires, rexcludes}	(2) The set R of Equation 2 contains the following relationship constraints:
Mandatory. A mandatory relationship states that if a variation point p is present its child variant v must be present too.
rmandatory = ⟨v ≥ 2 ⇔ p ≥ 2⟩
Optional. An optional relationship states that if a variation point p is present its child variant v may or may not be present.
roptional = ⟨p < 2 ⇒ v < 2⟩
Set. A set of children variants {vi | i = 1,..., z} has a set relationship with their parent variation point p when a number of them can be included if their parent is present.

z
rset = ⟨x ∈ [0..f ],y ∈ [1..g]((g ≤ z ∧ p ≥ 2) ⇒ ((x × 2) ≤ (	vi) ≤ (y × 2)))⟩
i=1
Requires. A requires relationship is a cross variant constraint that states that if variant va requires variant vb then if va is present, vb must be present too.
rrequires = ⟨a, b ∈ [1.. n]((a /= b) ∧ (va ⇒ vb))⟩
Excludes. An excludes relationship is a cross variant constraint that states that if variant va excludes variant vb then the variants cannot be present at the same time.
rexcludes = ⟨a, b ∈ [1.. n]((a /= b) ∧ ¬(va ∧ vb))⟩
In accordance to Definition 4.1, the OVM in Figure 3 can be translated to the quality model described in Equation 3.
μe−commerce = (Qe−commerce, W, R)	(3)

Where
Qe−commerce = {p1, p2, p3, v1, v2, v3, v4, v5, v6} W and R are as specified in Equations 1 and 2, respectively.
In order to plan an adaptation, values must be assigned to the variables in the Q set conforming to the selection and unselection of quality scenarios. We call this a quality conﬁguration. The quality configurations matching the initial scenario and the two adaptation settings for Cyber Monday in Section 3 are as specified in Equations 4, 5 and 6, respectively.


initial e−commerce
= {p1 = 2, p2 = 2, p3 = 1,
(4)

v1 = 1, v2 = 2, v3 = 1, v4 = 2, v5 = 1, v6 = 1}


Qtimebehavior = {p1 = 2, p2 = 2, p3 = 1,
v1 = 1, v2 = 1, v3 = 2, v4 = 2, v5 = 1, v6 = 1}
(5)



Qtimebehavior+availability = {p1 = 2, p2 = 2, p3 = 2,
v1 = 1, v2 = 1, v3 = 2, v4 = 2, v5 = 1, v6 = 2}
(6)

Promoting a quality scenario may often require several composed components, thus, in this paper we refer as a componentset (see Definition 4.2) to the composition of components promoting a quality scenario. We denote the composition operator as ⊕.
Definition 4.2 A componentset c is a composition of g components e.

g
c =	eu
u=1
For the example e-commerce application we have identified five componentsets: c1 (see Equation 7), c2 (see Equation 8), c3 (see Equation 9), c4 (see Equation 10) and c5 (see Equation 11).


c1 = Purchase ⊕ Credit Card Authorization⊕ Credit Card Settlement ⊕ Risk Tool
(7)


c2 = Cryptography Manager	(8)


c3 = Payment Processor	(9)



c4 = Purchase* ⊕ Credit Card Authorization*⊕
Credit Card Settlement*
(10)


c5 = Order Manager	(11)
Table 4 shows the relationships established between the quality scenarios (in the remainder of this paper we refer to every variant, i.e. response alternative, as one quality scenario) and the identified componentsets as presented in Section
3. A ✓ indicates the componentset requires the quality scenario to be selected in the configuration; on the contrary, an C indicates that the componentset requires the quality scenario to be unselected. A “-” indicates the componentset is not constrained by the presence of the quality scenario.
Table 4
Relationships between quality scenarios and components


One of the main elements of the proposed approach is the decision model. Deci- sion models in our approach relate componentsets stored in a component repository (see Figure 2) and quality scenarios to define the necessary actions to adapt an en- terprise application in accordance to a configuration of such quality scenarios.
Definition 4.3 A decision model D is a finite set of m×n decisions. Each decision
d relates one componentset cj with one quality scenario vi.



Where
D = {⟨di ⟩| j = 1,...,m ∧ i = 1,..., n}

⎧⎪⎪⎨ 0 if vi does not constrain the deployment of cj
	  

Table 4 maps to the decision model in Equation 12.

De−commerce = {dv1 = 2, dv2 = 2, dv3 = 1, dv4 = 0, dv5 = 1, dv6 = 1,

c1	c1
c1	c1
c1	c1

dv1 = 0, dv2 = 0, dv3 = 1, dv4 = 2, dv5 = 1, dv6 = 1,

c2	c2
c2	c2
c2	c2

dv1 = 2, dv2 = 2, dv3 = 2, dv4 = 0, dv5 = 1, dv6 = 1,
(12)

c3	c3
c3	c3
c3	c3

dv1 = 1, dv2 = 1, dv3 = 2, dv4 = 2, dv5 = 1, dv6 = 1,

c4	c4
c4	c4
c4	c4

dv1 = 1, dv2 = 1, dv3 = 2, dv4 = 0, dv5 = 1, dv6 = 1}

c5	c5
c5	c5
c5	c5

A resolution model is a decision model instance, which defines an adaptation plan.
Definition 4.4 A resolution model S is a finite set of s componentset deployments. The deployment sj is 0 if the componentset j should not be deployed, and 1 if the componentset j should be deployed.



Where
S = {⟨sj⟩| j = 1,..., m}
s = ⎧ 0 if cj should not be deployed
⎩ 1 if cj should be deployed

The resolution for the first adaptation setting in our e-commerce example is presented in Equation 13. The adaptation plan represented in this resolution model indicates that the componentsets c3, c4 and c5 should be the ones deployed in order to promote the configured quality scenarios (see Equation 5). According to the deci- sion model in Equation 12, with the available componentsets there is no adaptation that can meet the configured quality scenarios in Equation 6 corresponding to the second adaptation setting.

Se−commerce = {s1 = 0, s2 = 0, s3 = 1, s4 = 1, s5 = 1}	(13)
However, not every possible resolution model is a valid resolution model. A valid resolution model must satisfy the following constraints:
Definition 4.5 Deployment constraint. A componentset must be deployed satis- fying the respective deployment condition in the decision model.

∀j ∈ [1.. m]sj =1 ⇒ ∀i ∈ [1.. n](ci =0 ∨ (ci /=0 ∧ ci = vi))
j	j	j
Definition 4.6 Non-exclusion constraint. Two deployable componentsets must not exclude each other.


∀j1, j2 ∈ [1.. m](sj1
= sj2
=1 ∧ j1 /= j2) ⇒ ∀i ∈ [1.. n](ci
=0 ∨ ci
=0 ∨ ci	i

Definition 4.7 Completeness constraint. All deployable componentsets must take into account all the quality scenarios’ states in the quality configuration.

∀i ∈ [1.. n]∃j ∈ [1.. m](sj =1 ∧ ci /= 0))
Definition 4.8 A self-adaptation plan is a three-tuple of the form (L, T, P ); where L is a finite set of variables made up of the quality configuration Q (see Definition 4.1), the decision model D (see Definition 4.3) and the set of possible resolution models M (see Definition 4.4); T is a finite set of domains made up of the domains for the quality configuration (see Definition 4.1), decision model (see Definition 4.3) and resolution models (see Definition 4.4); and P is a finite set of constraints defined on L (see Definitions 4.1, 4.5, 4.6 and 4.7).

ωD = (L, T, P )
Definition 4.9 Let ωD be a self-adaptation plan of the form (L, T, P ), its solution space denoted as sol(ωD) is made up of all its possible solutions (possible resolution models M ). An adaptation is satisfiable if the solution space of ωD is not empty.

sol(ωD)= {⟨S⟩| ∀sj(sj ∈ S ⇒ P (sj)= true)}
Automated Reasoning
This section presents how automated reasoning is provided in the Planner element. Due to interactions between quality scenarios, and since different component com- positions may be available; conflicts between componentsets may arise. Automated reasoning seeks to cope with this issue by providing additional information to get the best possible selection of componentsets when determining an adaptation plan. The proposed approach is able to answer the following questions.
Application. Given a decision model, a quality configuration and a self- adaptation plan, there should be a way of verifying the resolution model’s applica- bility to adapt the specified enterprise application.
Definition 5.1 Let D be a decision model and Q a quality configuration, a resolu- tion model S is applicable if it is an element of the solutions of the equivalent CSP ωD.

applicable(S) ⇔ (S ∈ sol(ωD))	(14)
Possible resolutions. Once a quality configuration is defined, there should be a way to obtain the potential sets of componentsets that promote it.
Definition 5.2 Let D be a decision model and Q a quality configuration, the po- tential resolution models that promote Q from D are equal to the solutions of the equivalent CSP ωD.


resolutions(Q, D)= {⟨S⟩| S ∈ sol(ωD)}	(15)
Number of resolutions. A key question to be answered is how many potential resolution models a decision model contains to adapt an enterprise application. The higher the number of resolutions, the more flexible and complex becomes the decision model.
Definition 5.3 Let D be a decision model and Q a quality configuration, the num- ber of potential resolution models that promote Q from D, or cardinal, is equal to the solution number of its equivalent CSP ωD.

cardinal(Q, D) =| sol(ωD) |	(16)
Validation. A valid decision model is a model where at least one resolution model can be selected to adapt an enterprise application. That is, a model where ωD has at least one solution.
Definition 5.4 A decision model D is valid to adapt an enterprise application promoting quality configuration Q if its equivalent CSP is satisfiable.

valid(Q, D) ⇔ resolutions(Q, D) /= ∅	(17)
Flexible componentsets. A flexible componentset is a componentset that can be applied in self-adaptation plans for the same quality scenario with different combinations of other componentsets. Given a set of possible resolution models, there should be a way to find the componentsets appearing more than once in such set.
Definition 5.5 Let M be the set of possible resolution models, the set of flexible componentsets in M is equal to the componentsets selected to be applicable found in the intersection of M .

flexible(M )= {⟨s⟩| s =1 ∧ s ∈	M}	(18)
Inflexible componentsets. An inflexible componentset is a componentset that only makes part of one resolution model. Given a set of possible resolution models, there should be a way to find the inflexible componentsets in such set.
Definition 5.6 Let M be the set of possible resolution models, the set of inflexible componentsets in M is equal to the componentsets selected to be applicable not found in the intersection of M .

inflexible(M )= {⟨s⟩| s =1 ∧ s ∈/	M}	(19)
Optimum resolution. Finding out the best resolution model according to a criterion is an essential task for self-adaptation in the proposed approach. Given a set of possible resolution models, there should be a way to find the solution that

matches the criteria of an objective function. Two objective functions were taken into account. On the one hand, the function that outputs the resolution model with the greater number of applicable componentsets to self-adapt an enterprise application; namely max. On the other hand, the function that outputs the res- olution model with the least number of applicable componentsets to self-adapt an enterprise application; namely min.
Definition 5.7 Let M be the set of possible resolution models and O an objective function, the optimum solution (max or min) is equal to the optimum space of ωD.


max(M, O)= max(ωD, O)
min(M, O)= min(ωD, O)
(20)

Definition 5.8 Let ωD be a CSP, its optimum space, denoted as max/min(ωD, O),
Q	Q
is made up of all the solutions that maximize or minimize O, respectively.

max(ωD, O)= {⟨S⟩| ∀Sj((Sj ∈ sol(ωD) ∧ Sj /= S) ⇒ (O(S) ≥ O(Sj)))}
Q	Q	(21)
min(ωD, O)= {⟨S⟩| ∀Sj((Sj ∈ sol(ωD) ∧ Sj /= S) ⇒ (O(S) ≤ O(Sj)))}
Q	Q
Related Work
There are some approaches that have used CSPs for the manipulation of variability models in SPL Engineering. One of the most representative works on the subject was presented in [21], where the authors presented an algorithm to transform feature models into a CSP. The authors proposed to use CSPs to reason on feature models in such a way that they can answer questions such as number of products, filters based on user selections, valid configurations, among others. Several other contributions have been made since then, presenting CSPs as a good complement to SPLs (e.g., [22,23]). All of them, however, deal with problems related to product configuration without taking into account the problem of planning composition of products.
Some authors have explored different trends for generating reconfiguration plans. For instance, Moore et al. [5] use artificial intelligence (AI) based on hierarchical task networks; McIlraith et al. [6] propose an AI planner built by adapting and extending Golog [24], which is a logic programming language based on the situation calculus, built on top of Prolog. Other planners, like SHOP2 [25] are hierarchical task network planners, based on the situation calculus. When composing Web services, high level generic planning templates (subplans) and complex goals can be represented by Golog. These approaches, however, do not provide any support for self-adaptive infrastructures. On the other hand, Beggas et al. propose in [7] the use of fuzzy logic in adaptation planning. Adaptation controllers calculate fuzzy values for the QoS levels of available service variants, the current context state and user requirements. The variants with the nearest QoS levels that fit the current context state and user requirements will be selected for application.

There are approaches that implement dynamic adaptation of service composi- tions at the language level e.g., [26,27]; these can be complex and time-consuming, and with low-level implementation mechanisms for every element of the adapta- tion infrastructure. Our work is more closely related to approaches using models at runtime, e.g., [8,9,10], which implement, tacit or explicitly, the MAPE-K ref- erence model. The recent work of Alf´erez et al. [10] summarizes good practices implementing the MAPE-K reference model. They center their attention on ser- vice re-composition at runtime using dynamic product line engineering practices for assembling and re-deploying complete applications according to context- and system-sensed data. Application changes are reflected into the service composition by adding or removing fragments of Business Process Execution Language (WS- BPEL) code, which can be deployed at runtime. In order to reach adaptations, the authors argue that they use Constraint Programming for verifying at design time the variability model and its possible configurations; however, they neither provide implementation details nor formal specifications of any CSP model for planning activities.
Conclusions and Future Work
In this paper we presented a formal model based on the principles of constraint satisfaction for supporting the creation of Planner elements in self-adaptation in- frastructures. We use CSPs to reason on the set of constraints defined by reachable configurations and their relationships with the components stored in the compo- nent repository. We provided formal definitions of the concepts of quality model, decision model, resolution model, deployment constraint, non-exclusion constraint, completeness constraint, self-adaptation plan and solution space. Our formal model of the Planner allows us to answer the following questions: application, possible resolutions, number of resolutions, validation, flexible componentsets, inflexible com- ponentsets, and optimum resolution. We used a running example, in the context of enterprise applications and a self-adaptive framework, to demonstrate the appli- cability of the model, even in situations where complex interactions arise between context elements and the target self-adaptive enterprise application.
As future work, we will extend the model for reasoning on the process of bind- ing components while they are redeployed on system infrastructures. We will also implement a support tool for the model and integrate it into a self-adaptation in- frastructure. Other challenges to face in the near future are to perform a validations of our implementation with a case study.

References
H. Arboleda, J. F. D´ıaz, V. Vargas, and J.-C. Royer, “Automated reasoning for derivation of model- driven spls,” in SPLC’10 MAPLE’10, 2010, pp. 181–188.
IBM, “An architectural blueprint for autonomic computing,” IBM White Paper, 2006.
P. Tessier, S. G´erard, F. Terrier, and J. M. Geib, “Using Variation Propagation for Model-Driven Management of a System Family,” ser. LNCS 3714, 2005, pp. 222–233.


H. Arboleda, R. Casallas, and J.-C. Royer, “Dealing with Fine-Grained Configurations in Model-Driven SPLs,” in Proc. of the SPLC’09. San Francisco, CA, USA: Carnegie Mellon University, Aug. 2009,
pp. 1–10.
C. Moore, M. Xue Wang, and C. Pahl, “An architecture for autonomic web service process planning,” in Emerging Web Services Technology Volume III, ser. Whitestein Series in Software Agent Technologies and Autonomic Computing, W. Binder and S. Dustdar, Eds. Birkhaeuser Basel, 2010, pp. 117–130.
S. A. McIlraith and T. C. Son, “Adapting golog for composition of semantic web services,” in Proceedings of the Eighth International Conference on Principles and Knowledge Representation and Reasoning (KR-02), Toulouse, France, 2002, pp. 482–496.
M. Beggas, L. M´edini, F. Laforest, and M. T. Laskri, “Towards an ideal service qos in fuzzy logic-based adaptation planning middleware,” Journal of Systems and Software, vol. 92, pp. 71 – 81, 2014. [Online]. Available: http://www.sciencedirect.com/science/article/pii/S0164121213001738
R. Calinescu, L. Grunske, M. Kwiatkowska, R. Mirandola, and G. Tamburrelli, “Dynamic qos management and optimization in service-based systems,” IEEE Trans. on Software Engineering, vol. 37, no. 3, pp. 387–409, 2011.
D. Menasce, H. Gomaa, S. Malek, and J. P. Sousa, “Sassy: A framework for self-architecting service- oriented systems,” IEEE Software, vol. 28, no. 6, pp. 78–85, 2011.
G. H. Alf´erez, V. Pelechano, R. Mazo, C. Salinesi, and D. Diaz, “Dynamic adaptation of service compositions with variability models,” Systems and Software, vol. 91, no. 1, pp. 24–47, 2014. [Online].
Available: http://dx.doi.org/10.1016/j.jss.2013.06.034
J. O. Kephart and D. M. Chess, “The Vision of Autonomic Computing,” Computer, vol. 36, no. 1, pp. 41–50, Jan. 2003.
K. Pohl, G. B¨ockle, and F. J. v. d. Linden, Software Product Line Engineering: Foundations, Principles and Techniques. Secaucus, NJ, USA: Springer-Verlag New York, Inc., 2005.
F. Bachmann, M. Goedicke, J. Leite, R. Nord, K. Pohl, B. Ramesh, and A. Vilbig, “A Meta-model for Representing Variability in Product Family Development,” in Software Product-Family Engineering, 2004, pp. 66–80.
S. Hallsteinsen, M. Hinchey, S. Park, and K. Schmid, “Dynamic software product lines,” Computer, vol. 41, no. 4, pp. 93–95, April 2008.
H. Arboleda and J.-C. Royer, Model-Driven and Software Product Line Engineering, 1st ed. ISTE- Wiley, 2012.
E. Tsang, Foundations of Constraint Satisfaction. Academic Press, 1993.
N. M. Villegas, G. Tamura, H. A. Mu¨ller, L. Duchien, and R. Casallas, “DYNAMICO: A reference model for governing control objectives and context relevance in self-adaptive software systems,” LNCS, vol. 7475, pp. 265–293, 2013.
G. Tamura, R. Casallas, A. Cleve, and L. Duchien, “QoS contract preservation through dynamic reconfiguration: A formal semantics approach,” Science of Computer Programming, vol. 94, pp. 307– 332, 2014.
D. Dur´an and H. Arboleda, “Quality-driven software product lines,” Master’s thesis, Universidad Icesi, 2014. [Online]. Available: http://bibliotecadigital.icesi.edu.co/biblioteca{ }digital/handle/10906/77492
L. Bass, P. Clements, and R. Kazman, Software Architecture in Practice, 3rd ed. Boston, MA, USA: Addison-Wesley Longman Publishing Co., Inc., 2012.
D. Benavides, A. Ruiz-Cort´es, and P. Trinidad, “Automated reasoning on feature models,” LNCS, Advanced Information Systems Engineering: 17th International Conference, CAiSE 2005, vol. 3520,
pp. 491–503, 2005.
J. White, D. Benavides, B. Dougherty, and D. Schmidt, “Automated reasoning for multi-step software product line configuration problems,” in Proceedings of the 13th International Software Product Line Conference (SPLC’09), San Francisco, US, August 2009, pp. 1–10.
P. Trinidad, D. Benavides, A. Dur´an, A. Ruiz-Cort´es, and M. Toro, “Automated error analysis for the agilization of feature modeling,” J. Syst. Softw., vol. 81, no. 6, pp. 883–896, 2008.
H. J. Levesque, R. Reiter, Y. Lesp´erance, F. Lin, and R. B. Scherl, “GOLOG: A logic programming language for dynamic domains,” The Journal of Logic Programming, vol. 31, no. 1-3, pp. 59 – 83, 1997, reasoning about Action and Change.
U. Kuter, E. Sirin, B. Parsia, D. Nau, and J. Hendler, “Information gathering during planning for Web Service composition,” Web Semantics: Science, Services and Agents on the World Wide Web, vol. 3, no. 2-3, pp. 183 – 205, 2005.


L. Baresi and S. Guinea, “Self-supervising bpel processes,” IEEE Trans. on Software Engineering, vol. 37, no. 2, pp. 247–263, 2011.
N. C. Narendra, K. Ponnalagu, J. Krishnamurthy, and R. Ramkumar, Run-time adaptation of non- functional properties of composite web services using aspect-oriented programming. Springer, 2007.
