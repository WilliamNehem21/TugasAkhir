Electronic Notes in Theoretical Computer Science 124 (2005) 41–61  
www.elsevier.com/locate/entcs


A Rewriting-based Framework for Web Sites Verification 1
M. Alpuente
DSIC, Universidad Polit´ecnica de Valencia, Camino de Vera s/n, Apdo. 22012, 46071 Valencia, Spain. Email: alpuente@dsic.upv.es.

D. Ballis M. Falaschi
Dip. Matematica e Informatica, Via delle Scienze 206, 33100 Udine, Italy.
Email: {demis,falaschi}@dimi.uniud.it.


Abstract
In this paper, we develop a framework for the automated verification of Web sites which can be used to specify integrity conditions for a given Web site, and then automatically check whether these conditions are fulfilled. First, we provide a rewriting-based, formal specification language which allows us to define syntactic as well as semantic properties of the Web site. Then, we formalize a verification technique which obtains the requirements not fulfilled by the Web site, and helps to repair the errors by finding out incomplete information and/or missing pages. Our methodology is based on a novel rewriting-based technique, called partial rewriting, in which the traditional pattern matching mechanism is replaced by tree simulation, a suitable technique for recognizing patterns inside semistructured documents. The framework has been implemented in the prototype Web verification system Verdi which is publicly available.
Keywords: Formal Web site verification, specification languages, rewriting, simulation.


Introduction
The increasing complexity of Web sites has turned their design and construc- tion into a challenging problem. Systematic, formal approaches can bring

1 This work has been partially supported by MCYT under grants TIC2001-2705-C03- 01,HU2003-0003 and by Generalitat Valenciana under grant GR03/025, and by ICT for EU-India Cross Cultural Dissemination Project under grant ALA/95/23/2003/077-054.


1571-0661 © 2005 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2004.07.014


many benefits to quality Web site construction, giving support for automated Web site verification. This paper presents an approach to Web site specifi- cation and verification based on rewriting-like machinery. We use rewriting- based technology both to specify the integrity conditions and to formalize a verification technique which obtains the requirements not fulfilled by the Web site, and then is able to repair errors by finding out missing pages and/or incomplete information, such as the data or the links available in a particular page.
Although the management of Web sites has received significant attention in recent years [6,12,13], few works address the semantic verification of Web sites. [16] presents regular expression types, which are natural generalizations of DTDs describing structures in XML documents. In this framework, the problem of verifying the structure of an XML document boils down to a type- checking problem; that is, an XML document is well-structured, if it is well- typed. In [13], a declarative verification algorithm is proposed which checks a particular class of integrity constraints concerning the Web site’s structure, but not the contents of a given instance of the site. [12] proposes a methodology which consists of using inference rules and axioms to define some semantic constraints concerning the Web site contents. Then, a verification technique is proposed which is based on compiling the specification into Prolog code. Our idea in this paper is that term rewriting techniques can support in a natural way not only intuitive, high level Web site specification, but also efficient Web site verification and repairing techniques. As far as we know, rewriting-based techniques have not been explored in this context to date. We only know of two related approaches which focus on transformation rather than verification issues: a rewriting-based implementation is provided in [17] for (a fragment of) XSLT, the rule-based language designed by W3C for the transformation of XML documents, whereas rewrite rules are used in [3] to perform HTML transformations with the aim of improving Web applications by cleaning up syntax, reorganizing frames, or updating to new standards.
Our contribution. We first provide a rewriting-based, formal specifica- tion language which allows us to define conditions on both the structure and the contents of Web sites in a simple and concise way. For instance, it allows us to enforce that some information is available at a given Web page, some links between pages do exist or even the existence of the Web pages themselves. In our formalism, web pages (HTML/XML documents) are modeled as Her- brand terms, and, consequently, Web sites are finite sets of terms. Then, we formalize a verification technique in which a Web site is checked w.r.t. a given Web specification in order to detect incomplete and/or missing Web pages. Moreover, by analyzing the requirements not fulfilled by the Web site, we are


also able to find out the missing information which is needed to repair the Web site. Since reasoning on the Web calls for formal methods specifically fitting the Web context, we develop a novel, rewriting-based technique called partial rewriting, in which the traditional pattern matching mechanism is replaced with tree simulation [15] in order to provide a suitable mechanism for recog- nizing patterns inside semistructured documents. The notion of simulation has been already used before for dealing with semistructured data in a num- ber of query and transformation languages [6,8,14,10]. The reason is twofold: on the one hand, it provides a powerful method to extract information from semistructured data; on the other hand, efficient algorithms exist for comput- ing simulations [15]. To assess the feasibility and efficiency of our approach, we have implemented the prototype system Verdi (VErification and Rewriting for Debugging Internet sites), which is based on the verification methodology that we propose and is publicly available online.
Plan of the paper. Section 2 summarizes some preliminary definitions and notations. In Section 3, we formulate a simple method for translating HTML/XML documents into Herbrand terms. Section 4 is devoted to for- malize the specification language, whereas Section 5 formalizes the partial rewriting mechanism, which is based on page simulation. In Section 6, we introduce our verification technique, which is formalized as a fixpoint com- putation. First, the set of requirements to be fulfilled by the Web site W is computed as the fixpoint of a suitable operator associated with the Web site specification I. Then, by using simulations we select those requirements which are not satisfied by W and the corresponding incomplete/missing Web pages which are the source for the errors. The requirements which are not satisfied also allow us to ascertain the missing information which is needed to repair the Web site. Some notes regarding the implementation of the system Verdi are given in Section 7. Section 8 concludes. More details and missing proofs can be found in [2].

Preliminaries
We call alphabet a finite set of symbols. Given the alphabet A, A∗ denotes the set of all finite sequences of elements over A. Syntactic equality between objects is represented by ≡.
By V we denote a countably infinite set of variables and Σ denotes a set of function symbols, or signature. We consider varyadic signatures (i.e. signatures in which function symbols have an unbounded arity, that is, they may be followed by an arbitrary number of arguments) as in [11]. τ (Σ, V) and


τ (Σ) denote the non-ground term algebra and the term algebra built on Σ ∪V and Σ, respectively. τ (Σ) is usually called the Herbrand universe over Σ. A term t is linear, if no variable appears more than once in t.
Terms are viewed as labelled trees in the following way: a term in τ (Σ) is a tree (V, E, r, label ), where V is a set of vertices, E is a set of edges (i.e. pairs of vertices), r ∈ V is the root vertex and label is a labeling function such that label (v) ∈ (Σ ∪ V), for each v ∈ V . Let us see a small example.

Example 2.1 Consider the term t ≡ (f (g(a),X)) in τ ({f, g, a}, {X}). Term t can be represented by the structure (V, E, r, label ), where V = {v0, v1, v2, v3}, E = {(v0, v1), (v0, v2), (v1, v3)}, r ≡ v0, and function label is defined as follows: label (v0)= f , label (v1)= g, label (v2)= X, label (v3)= a.

Given two vertices v, v' ∈ V of a term t ≡ (V, E, r, label ), by v ≥ v' we mean that v is a descendant of v' in t. By t|v we mean the subterm rooted at vertex v of t. We denote the depth of a vertex v in a term t, that is the number of edges between r and v in t, as depth(t, v). A substitution σ ≡ {X1/t1, X2/t2,.. .} is a mapping from the set of variables V into the set of terms τ (Σ, V). By Var (t) we denote the set of variables occurring in term t.
In the following, we consider marked terms. Given Σ and V, we denote the marked version of Σ (V, respectively) as Σ (V, respectively). A syntactic object o ∈ Σ ∪ V  is called the marked version of o ∈ Σ ∪ V. Given a term t ≡ (V, E, r, label ) ∈ τ (Σ, V), a marking for t is a (boolean) function µ: V →
{yes, no}. The empty marking ε for t is a marking for t such that ε(v)= no, for each v ∈ V . We define the marked part of a term t as


mark (t, µ) ≡ ({v ∈ V | µ(v)= yes}, {(v1, v2) ∈ E | µ(v1)= µ(v2)= yes}, r, label ).


A valid marking µ for a term t ≡ (V, E, r, label ) is the empty marking for
t or a marking for t such that the two following conditions hold:
µ(r)= yes;
mark (t, µ) is a term in τ (Σ, V).
Given a term t ≡ (V, E, r, label ) and a valid marking µ for t, by slightly abusing

notation we recursively define a marked term µ(t) as follows:
⎧⎪ X	t ≡ ({v}, ∅, v, label ) ∧ label (v)= X ∈ V 
∧ µ(v)= yes
⎪
µ(t)= ⎪⎨ X	t ≡ ({v}, ∅, v, label ) ∧ label (v)= X ∈ V 
∧ µ(v)= no
⎪
f(µ(t1),..., µ(tn))	t ≡ (V, E, r, label ) ≡ f (t1,... , tn) ∧ µ(r)= yes
⎪⎩ f (µ(t1),..., µ(tn))	t ≡ (V, E, r, label ) ≡ f (t1,... , tn) ∧ µ(r)= no When no confusion can arise, we simply denote the marked term ε(t) by t.
Example 2.2 Consider again term t ≡ (f (g(a),X)) of Example 2.1. Let µ1
be a marking for t defined as µ1(v0) = µ1(v2) = µ1(v3) = yes, µ1(v1) = no. Additionally, let µ2 be a marking for t such that µ2(v0) = µ2(v1) = yes, µ2(v2) = µ2(v3) = no. Note that µ1 is not a valid marking for t as the marked part of t is not a term in τ ({f, g, a}, {X}), whereas µ2 is valid for t and µ2(t)= f(g(a),X) is a marked term.

Denotation of Web Sites
In this paper, a Web page is either an XML[20] or an HTML[19] document, and a Web site is a finite collection of Web pages. In the sequel, we provide a formalization of these concepts by means of semistructured expressions, which can be seen as an abstract syntax which generalizes the two markup languages XML and HTML. Then, we show how semistructured expressions can be translated into ordinary terms of a given term algebra in such a way that Web sites are represented as finite sets of (ground) terms.

Semistructured Expressions.
XML/HTML documents consist of nested structured data, which can be de- fined inductively. Abstracting from XML and HTML, we give a formal defi- nition of semistructured expressions which are suitable for representing struc- tured documents written in one of these two languages.
Let us consider two alphabets T and T ag . We denote the set T ∗ by T ext. An object t ∈ Tag is called tag element, while an element w ∈ Text is called text element. A semistructured expression e over T ext and T ag sets can be

specified by the following syntax 2

We denote the set of all the semistructured expressions over T ext and T ag by
S(T ext, T ag ). Note that T ext ⊆ S(T ext, T ag ).
Example 3.1 The following object is a semistructured expression.
<members>
<member>
<name> mario </name>
<surname> rossi </surname>
<status> professor </status>
</member>
<member>
<name> franca </name>
<surname> bianchi </surname>
<status> technician </status>
</member>
<member>
<name> giulio </name>
<surname> verdi </surname>
<status> student </status>
</member>
</members>


Roughly speaking, a semistructured expression is either a raw or a struc- tured piece of text, where the structure is provided by tags. Consequently, tags allow us to mark up some textual content, which may contain an arbitrary amount of further well-bracketed markup. Informally, the more tags we add, the more the text is structured, and in some sense its “formal organization” will also increase. Note that we have not explicitly dealt with XML/HTML attributes, as they can be seen as common tagged elements and thus modeled as semistructured expressions. On the other hand, without loss of generality, other XML/HTML features such as namespaces, DTDs and/or schemas, that are not relevant to this work are not conveyed by our notion of semistructured expression.
In the literature, slightly different formalisms have been introduced for modeling XML and HTML documents, e.g. in [1] semistructured expressions are directed graphs which can deal with crossing references. Nevertheless, we prefer the hierarchical representation which does not cause any serious restric- tion in many practical contexts while it greatly simplifies our methodology.


2 Note that symbol ϵ in the syntax given for semistructured expressions denotes the empty string and must not be confused with the empty marking ε.


Term representation.
Semistructured expressions are provided with a tree-like structure, therefore they can be conveniently translated into terms by applying the following straightforward transformation.
Definition 3.2 Let e be a semistructured expression over T ext and T ag . Then, e is represented by a term of the Herbrand universe τ (T ext ∪Tag ) by the translation
s to t : S(T ext, T ag ) → τ (T ext ∪ Tag ) defined as follows:
s to t (e)= ⎧⎨ w	if e ≡ w ∈ Text
⎩ t(s to t (e1),... , s to t (en))	if e ≡ <t> e1 ... en</t>
Example 3.3 Consider again semistructured expression of Example 3.1. Then, the term p computed by function s to t for that semistructured expression is
members(
member(name(mario),surname(rossi),status(professor)), member(name(franca),surname(bianchi),status(technician)), member(name(giulio),surname(verdi),status(Student))
)
To summarize, a Web page, which is coded as an HTML/XML document,
can be represented as a semistructured expression, which is then easily trans- lated into a corresponding term of a suitable term algebra. Therefore, in the remaining of this work, a Web page is modeled by a term in τ (T ext ∪ Tag ). Besides, a marked Web page is defined as µ(p), where p ∈ τ (T ext ∪ Tag ) and µ is a valid marking for p. A Web site is a finite collection of marked Web pages {ε(p1) ... ε(pn)}. In the following, we will also consider terms of the non-ground term algebra τ (T ext ∪ Tag, V), which may contain variables. An element s ∈ τ (T ext ∪ Tag, V) is called Web page template. µ(s) is a marked Web page template, when s ∈ τ (T ext ∪ Tag, V) and µ is a valid marking for
s. In our methodology, (marked) Web page templates are used for specifying properties on Web sites as described in the following section.
Web specification language
In the following, we present a term rewriting specification language, which is helpful to express properties about the content and the structure of a given Web site. Roughly speaking, a specification is a finite set of rules, where the terms in the left-hand side and in the right-hand side of each rule represent (eventually marked) Web page templates. The operational mechanism, for- malized in Section 5, is based on a novel rewriting-based mechanism, which is able to extract partial structure from a term, and then rewrite it.

Formally, Web site specifications are as follows.
Definition 4.1 A rule is a pair of terms l ~ µ(r) such that l, r ∈ τ (T ext ∪ T ag, V), l is linear, Var (r) ⊆ Var (l) and µ is a valid marking for r. A Web site speciﬁcation I is a finite set of rules {l1 ~ µ1(r1),... , ln ~ µn(rn)}.
Given a Web specification I, we denote the set of all left-hand sides (right- hand sides disregarding markings) of rules in I by LhsI (RhsI, respectively). In symbols, LhsI = {l | l ~ µ(r) ∈ I} and RhsI = {r | l ~ µ(r) ∈ I}.
The following example illustrates the definition of a Web specification. Marks are introduced by the user to help locating errors. We do not take care of marks for the time being but postpone the formal handling of marking information and the description of the verification framework to Section 6.
Example 4.2 Consider the following Web specification, which models some required properties of a research group Web site containing information about group members affiliation, scientific publications and personal data.
member(name(X), surname(Y)) ~ hpage(name(X), surname(Y), status)
hpage(status(professor)) ~ hpage(status(professor), teaching)
	
pubs(pub(name(X), surname(Y))) ~ member(name(X), surname(Y))

First rule formalizes the following property: if there is a Web page con- taining a member list, then for each member, a home page exists containing (at least) the name, the surname and the status of this member. Second rule states that whenever a home page of a professor is recognized, then that page must also include some teaching information. Finally, the third rule specifies that whenever there exists a Web page containing information about scientific publications, each author of a publication should be a member of the research group.
Informally, rules of a Web specification formalize conditions to be fulfilled by a given Web site. Intuitively, the interpretation of a rule l ~ µ(r) w.r.t. a Web site W is as follows: if (an instance of) l is recognized in W, also (an instance of) r must be recognized in a subset of W, which is determined by computing the sets of all Web pages which embed (an instance of) the marked part of r. This mechanism is formalized by partial rewriting.

Partial Rewriting
In order to mechanize the intended semantics of Web specification rules, we first devise a mechanism which is able to recognize the structure and the







 
Fig. 1. Page simulation between p1 and p2 .
labeling of a given Web page template inside a particular page of the Web site. This is provided by page simulation.
Page Simulations
The notion of page simulation for Web pages allows us to analyze and extract the partial structure of the Web site which is subject to verification.
Roughly speaking, a Web page p1 is simulated by a Web page p2, if the tree- structure of p1 is “embedded” into the tree-structure of p2. In other words, a simulation of a Web page (i.e. a labelled tree) p1 in a Web page p2 can be seen as a relation among the nodes of p1 and the nodes of p2 which preserves the edges and the labelings. Before formalizing the idea, we illustrate it by means of a rather intuitive example.
Example 5.1 Consider the following Web pages (called p1 and p2, respec- tively):
hpage(name,surname,status(professor),teaching) hpage(name(mario),surname(rossi),status(professor),
teaching(course(logic1),course(logic2)), hobbies(hobby(reading),hobby(gardening)))
Looking at Figure 1, we observe that the structure of p1 can be recognized inside the structure of p2 by considering the relation among nodes of p1 and nodes of p2 which is described by the dashed arrows in the figure. This relation essentially provides the so-called simulation of p1 in p2. Note that vice-versa does not hold: no relations can be found among nodes of p2 and nodes of p1, which “embed” the structure of p2 into p1. In other words, there does not exist a simulation of p2 in p1.

Simulations have been used in a number of works dealing with query- ing and transformation of semistructured data. For instance, [1,14] propose some techniques based on simulation for analyzing semistructured data w.r.t.


a given schema. The language Xcerpt [7,6] is a (logic) query language for XML and semistructured documents which implements a sort of unification by exploiting the notion of graph simulation. Other approaches involving sim- ulation, or closely related notions, have been employed to measure similarity among semistructured documents [4]. To keep our framework simple, we do not consider a semantic change/load for labels; this would require to introduce ontologies, which are outside the scope of the paper.
Basically, the reason why simulations are successfully employed in the im- plementation of these kinds of manipulation and querying methods is twofold. Firstly, it is a simple and powerful technique to extract and recognize the par- tial structure of a document; secondly, there are several efficient algorithms to compute (graph and tree) simulations (see [15]).
In the following, we provide our notion of simulation which is a slight adap- tation of the one given in [6] to consider Web page templates: we generalize the usual label relation to cope with the case when variables are used as labels, in the following definition.
Definition 5.2 Let s1 ≡ (V1, E1, r1, label1), s2 ≡ (V2, E2, r2, label2) be two Web page templates in τ (T ext ∪ Tag, V). The label relation ∼⊆ V1 × V2 is defined as follows:
v1 ∼ v2	iff	label1(v1)= label2(v2) or label1(v1) ∈ V.
Definition 5.3 Let s1 ≡ (r1, V1, E1, r1, label1), s2 ≡ (r2, V2, E2, r2, label2) be two Web page templates in τ (T ext ∪ Tag, V) and ∼⊆ V1 × V2 be the corre- sponding label relation. A page simulation of s1 in s2 w.r.t ∼ is a relation S ⊆ V1 × V2 such that, for each v1 ∈ V1, v2 ∈ V2
r1 S r2;
v1 S v2 ⇒ v1 ∼ v2;
v1 S v2 ∧ (v1, v' ) ∈ E1 ⇒∃ v' ∈ V2, v' S v' ∧ (v2, v' ) ∈ E2.
1	2	1	2	2
We define the projection of a simulation S of s1 in s2 w.r.t ∼ as π(S) = 
{v2 | (v1, v2) ∈ S}.
Roughly speaking, Definition 5.3 ensures two degrees of similarity between Web page templates, not only w.r.t. the labelings but also w.r.t. the struc- tures of the templates. On the one hand, Condition (2) of Definition 5.3 formalizes the similarity w.r.t labelings, that is, any pair of nodes (v, v') in a page simulation S of s1 in s2 have the same label, otherwise node v must be labelled by a variable, which somehow means that the label of v can be seen as a generalization of any concrete label of v'. Finally, Condition (1) and Condition (3) provide a relation between the tree structure of s1 and the tree


 


( a )


( b )


( c )




structure of s2.
Fig. 2. non-minimal and minimal simulations

Note that simulations are just relations among nodes of two given Web page templates. For our purposes, we are interested in simulations which are injective mappings from nodes of a given Web page template to nodes of another Web page template. As it will be apparent later, those simulations allow us to project the structure of a Web page template into another one, thus performing a sort of “partial” pattern matching between templates, which will be exploited to formulate our verification technique.
In the following, we define a subclass of simulations called minimal simu- lations.
Definition 5.4 Let s1 ≡ (V1, E1, r1, label1), s2 ≡ (V2, E2, r2, label2) be two Web page templates in τ (T ext ∪ Tag, V). A page simulation S of s1 in s2
w.r.t. ∼ is minimal if there are no page simulations S' of s1 in s2 w.r.t. ∼
such that S' ⊆ S.
Let us see an example which illustrates the notion of minimal simulation.
Example 5.5 Let us consider the following Web page templates s1 and s2: hobbies(hobby(X)), hobbies(hobby(reading),hobby(gardening)). In Fig- ure 2(a), the dashed arrows represent a non-minimal simulation of s1 in s2, while in Figures 2(b) and 2(c) two minimal simulations of s1 in s2 are depicted. Note that the last two simulations are mappings.
Lemma 5.6 Let s1 ≡ (V1, E1, r1, label1), s2 ≡ (V2, E2, r2, label2) be two Web page templates in τ (T ext ∪ Tag, V). A minimal page simulation S of s1 in s2
w.r.t. ∼ is a mapping S : V1 → V2 .
Minimal simulations do not guarantee that the tree structure of a given Web page template can be recognized inside another template. For this pur- pose, we need to furtherly restrict our class of simulations. Let us see an example.
Example 5.7 Consider Web page templates s1 ≡ f(X, Y) and s2 ≡ f(a). Note that there exists a minimal page simulation of s1 in s2 w.r.t. ∼ (see Figure 3), but the tree structure of s1 cannot be recognized as part of s2, e.g.



Fig. 3. minimal non-injective simulation
the vertex with label f in s1 has two outgoing edges, while the corresponding vertex in s2 has only one.
To solve the problem presented in Example 5.7, we simply restrict ourselves to consider minimal injective page simulations, which provide a one-to-one correspondence among edges of the two considered Web page templates.
It is not difficult to demonstrate that minimal injective simulations are particular instances of Kruskal’s embeddings [5] w.r.t. the relation ∼. In other words, a minimal injective page simulation of s1 in s2 w.r.t. ∼ exists iff s1 is embedded into s2 w.r.t. ∼, i.e., we are able to find out the structure and the labeling of s1 inside s2. Note that the minimal simulation of s1 in s2 depicted in Figure 3 is not injective and thus no embedding of s1 into s2 exists. Instead, Figures 2(b) and 2(c) illustrate two minimal injective simulations, that is, two embeddings between Web page templates.
Rewriting Web page templates
Definition 5.8 Let s1 ≡ (V1, E1, r1, label1), s2 ≡ (V2, E2, r2, label2) ∈ τ (T ext∪ T ag, V). We say that s2 partially matches s1 via substitution σ iff
there exists a minimal injective simulation S of s1 in s2 w.r.t. ∼;
for each (v, v') ∈ S such that label (v)= X ∈ V, σ(X)= (s2|v' ).
In Definition 5.8, we consider only minimal injective simulations between Web page templates s1 and s2, since this trivially ensures the existence of a substitution σ such that there exists a simulation of s1σ in s2 w.r.t. ∼; in other words, s1σ is embedded into s2.
Example 5.9 Consider again Example 5.5. We have that s2 partially matches
s1 via {X/reading} (see Figure 2(b)) and s2 partially matches s1 via
{X/gardening} (see Figure 2(c)). Note that performing partial matching by the non-minimal simulation of Figure 2(a) would produce σ ≡ {X/reading, X/gardening}, which is not a substitution.
Now we are ready to define a partial rewrite relation between marked Web page templates.
Definition 5.10 Let s ≡ (V, E, r, label ), t ∈ τ (T ext ∪ Tag, V). Let µ1 and
µ2 be two valid markings for s and t, respectively. Then, µ1(s) partially

rewrites to µ2(t) via rule r ≡ l ~ µ(r) and substitution σ (in symbols,
µ1(s) ~σ µ2(t)) iff there exists v ∈ V such that
s|v partially matches l via σ;
t = rσ.
Let r ≡ (Vr, Er, r, labelr) and rσ ≡ (Vrσ, Erσ, r, labelrσ). For each v ∈ Vrσ,
µ (v)= ⎧⎨µ(v)	if v ∈ (Vr ∩ Vrσ)
⎩µ(v')	if v ∈ (Vrσ \ Vr) ∧ (∃ v' ∈ Vr,v ≥ v', labelr(v') ∈ Var (r))
When rule r and substitution σ are understood, we simply write µ1(s) ~ µ2(t).
It is worth noting that we provide a notion of partial rewriting in which the context of the selected reducible expression s|v of the Web page template which is rewritten is disregarded after the rewrite step (see point (2) of Definition 5.10). Roughly speaking, given a Web specification rule l ~ µ(r), partial rewriting allows us to extract a subpart of a given Web page (template) s, which partially matches l, and to replace s by an instance of r; namely, rσ (see points (1) and (2) of Definition 5.10). Point (3) of Definition 5.10 establishes that rewritten templates inherit markings from the right-hand sides of the applied rules. More precisely,
each vertex of rσ, which is not affected by substitution σ, maintains the same marking of r;
each vertex, which belongs to a subterm of rσ replacing a variable X of r, is marked yes;
each vertex, which belongs to a subterm of rσ replacing a variable X of r, is marked no.
Example 5.11 Consider the Web page p of Example 3.3 and the first rule r1 of the Web specification of Example 4.2. Then, Web page template ε(p) partially rewrites to the following three Web pages by applying r1.
ε(p) ~r1 hpage(name(mario), surname(rossi), status) ε(p) ~r1 hpage(name(franca), surname(bianchi), status) ε(p) ~r1 hpage(name(giulio), surname(verdi), status)

Roughly speaking, markings in the right-hand sides of the rules allow us to find sets of Web pages, which might be incomplete or missing. Then, real buggy pages are detected inside these sets. We formalize the idea in the following section.

The verification framework
In the following, we show how simulation and partial rewriting can be applied to verify a given Web site W w.r.t. a Web specification I. Essentially, the main idea is to compute the set of all possible marked Web pages that can be derived from W via I by means of partial rewriting. These marked Web pages can be thought of as requirements to be fulfilled by W. Then, we check whether the computed requirements are satisfied by W by using simulation and marking information. In summary, the method works in two steps, which are repeatedly applied as described in the following.
Compute the set of requirements ReqI,W for W w.r.t. I
Check ReqI,W in W.
Computing the set of requirements
Let us introduce the following operator.
Definition 6.1 Let T be a set of marked Web page templates and I be a Web specification. Then,
RI(T)= T ∪ {µ2(s2) | ∃ µ1(s1) ∈ T,r ≡ l ~ µ(r) ∈ I s.t. µ1(s1) ~r µ2(s2)}

Roughly speaking, the operator in Definition 6.1 computes all marked tem- plates which result from partial rewriting the Web page templates of T by using the Web specification I, and returns the union of the resulting set and
T. By repeatedly applying this operator, it is possible to compute all marked Web pages that can be derived from an initial Web site after an arbitrary number of partially rewriting steps. For this purpose, we formalize the or- dinal powers of the operator RI w.r.t. a Web site W as follows: RI ↑W 0 = W, RI ↑W n = RI(RI ↑W (n − 1)), n > 0.
It is immediate to demonstrate that the operator RI is continuous on the lattice consisting of the powerset of the term algebra of the marked Web page templates ordered by set inclusion. This ensures that a least fixpoint of RI exists and can be reached after ω applications of RI, that is, RI ↑W ω where ω is the first infinite ordinal. Moreover, the least fixpoint of RI contains all the marked Web pages derivable from Web pages in W via I.
Now, recalling the interpretation of the rules of the Web site specification given in Section 4, Web pages derived by the application of a Web specification must be recognized as (part of) some Web page in the Web site. Therefore, those Web pages in the least fixpoint of RI which are not in W can be intended as requirements to be fulfilled by W. Thus, we define the set of requirements


for W w.r.t. I as ReqI,W = lfp(RI) \ W, where lfp(RI) is the least fixpoint of the operator RI.
Clearly, the fixpoint of RI (and hence ReqI,W) for an arbitrary Web specifi- cation might be infinite. Consider for instance the following example.
Example 6.2 Let W ≡ {h(g(0), f(0))} be a Web site and I ≡ {h(g(X)) ~
h(g(g(X)))} be a Web specification. Then,
ReqI,W = {h(g(g(0))), h(g(g(g(0)))), h(g(g(g(g(0))))),.. .}
is an infinite set of requirements which is infinite.
Fortunately, the computation of the set of requirements is finite for some interesting classes of Web specifications. Trivially, non-recursive specifica- tions allow to reach lfp(RI) after a finite number of applications of RI, i.e., lfp(RI) = RI ↑W k, k ∈ N. However, non-recursive definitions are not expres- sive enough for verification purposes, since some relevant conditions about Web sites cannot be formalized without resorting to recursion; e.g., some prop- erties stated in Example 4.2 cannot be formulated by using a non-recursive specification.
In the following, we define a class of recursive Web specifications for which the set of requirements is finite. Basically, the idea is to consider those spec- ifications for which the computation of the least fixpoint only generates Web pages whose size is bounded.
The following definition formalizes the considered class of Web site speci- fications.
Definition 6.3 A  Web  specification  I is  bounded  iff,  for  each l ≡ (V1, E1, r1, label1) ∈ LhsI, r ≡ (V2, E2, r2, label2) ∈ RhsI and each min- imal injective simulation S of l in r|v w.r.t. ∼, v ∈ V2, the following property holds
if v2 ∈ π(S) and label2(v2) ∈ Var (r|v), then for all v1 ∈ V1 s.t.
label1(v1) ∈ Var (l), depth(r|v, v2)= depth(l, v1).
Roughly speaking, Definition 6.3 states that, whenever a left-hand side l of a rule is simulated by (a subterm of) the right-hand side r of a (possibly different) rule, then no variables in the substructure of r which is recognized by simulation must be located at positions which are deeper than all the positions of the variables in l.
Example 6.4 Consider again the specification I in Example 6.2. The left- hand side of the rule h(g(X)) ~ h(g(g(X))) is simulated by its own right-hand


side. Moreover, variable X in the right-hand side is located at depth 3, while the unique variable in the left-hand side is at depth 2. Thus, I is not bounded.
Now, take into account specification
I' ≡ {m(n(X)) ~ h(n(X), s(s(X))), h(n(X)) ~ m(n(X), t)}.
Then, m(n(X)) is simulated by m(n(X), t) and h(n(X)) is simulated by h(n(X), s(s(X))). In both cases, variables occurring in the substructures of the right-hand sides which are recognized by simulation and variables of the respective left-hand sides are located at the same depth. Therefore, the Web specification I' is bounded.
For bounded Web specifications, the least fixpoint of the operator RI is finite as stated by the next proposition. This provides an effective method for computing the set of requirements ReqI,W.
Proposition 6.5 Let I be a bounded Web speciﬁcation and W be a Web site. Then, there exists k ∈ N such that lfp(RI)= RI ↑W k.
Example 6.6 Consider the bounded Web specification I of Example 4.2 and the following Web site W:
W = {members(member(name(mario),surname(rossi),status(professor)), member(name(franca),surname(bianchi),status(technician)), member(name(anna),surname(gialli),status(professor)), member(name(giulio),surname(verdi),status(student))),
hpage(name(mario),surname(rossi),phone(3333),status(professor), hobbies(hobby(reading),hobby(gardening))),
hpage(name(franca),surname(bianchi),status(technician),phone(5555)), hpage(name(anna),surname(gialli),status(professor),phone(4444),
teaching(course(algebra))), pubs(pub(name(mario),surname(rossi),title(blahblah1),year(2003)),
pub(name(anna),surname(gialli),title(blahblah2),year(2002)))}
Then, the set of computed requirements ReqI,W is
{ hpage(name(mario), surname(rossi), status), hpage(name(franca), surname(bianchi), status), hpage(name(anna), surname(gialli), status), hpage(name(giulio), surname(verdi), status),
hpage(status(professor), teaching), member(name(mario), surname(rossi)), member(name(anna), surname(gialli)) }
Checking requirements in Web sites
As we have seen in Section 5.1, simulation allows us to identify the structure of a given Web page (eventually, a template) into another. By taking advantage of this fact, we can develop a methodology, which is able to discover incom- pleteness errors in a given Web site w.r.t. a Web specification. Basically, the


idea is to verify the consistency of the Web site w.r.t. the set of requirements. To accomplish this task, we first use simulation for checking whether require- ments are embedded into some Web page of the considered Web site and then exploit marking information in order to diagnose incompleteness errors in the Web site.
More precisely, our analysis allows us to discover two kinds of incomplete- ness errors: (1) Web pages which are missing in a Web site w.r.t. a given Web specification, (2) Web pages which are incomplete w.r.t a given Web specification.
Let us first consider the former class of errors.
Definition 6.7 Let W be a Web site, I be a bounded Web specification and ReqI,W be the set of requirements for W w.r.t. I. Let µ(e) ∈ ReqI,W. The likely missed information set w.r.t. µ(e) is defined as
LMISµ(e) = {p ≡ (V, E, r, label ) ∈ W | there is a minimal injective simulation of
mark (e, µ) in p|v w.r.t. ∼, with v ∈ V }.
Roughly speaking, this definition allows us to compute a subset of the Web site containing all the web pages which are simulated by the marked part of a given requirement. These web pages could be potentially incomplete w.r.t. the web specification, since they might not satisfy the considered requirement. Let us see an example.
Example 6.8 Let us consider the rule r
hpage(status(professor)) ~ hpage(status(professor), teaching)
and the website W of Example 6.6. Rule r allows us to check whether web pages of professors contain some teaching information. Clearly, requirements computed by this rule should be only checked in such web pages. For this purpose, we use the marking information in the rhs of r in order to focus on the professor web pages. Let us consider the requirement
µ1 (e1 ) ≡ hpage(status(professor), teaching)
which can be derived from W by means of r. By applying Definition 6.7, we get
LMIS1 (e1 ) = {(1) hpage( name(mario), surname(rossi),
phone(3333), status(professor),
hobbies(hobby(reading), hobby(gardening))),
(2) hpage( name(anna), surname(gialli), status(professor), phone(4444), teaching(course(algebra))) }.
which contains only professor web pages to be checked for incompleteness errors.


From Definition 6.7, we can easily derive that, whenever the likely missing information set is empty for a given requirement µ(e), µ(e) is not recognized in any Web page of the Web site. In other words,that requirement identifies a missing element in the Web site.
Definition 6.9 Let W be a Web site, I be a bounded Web specification and ReqI,W be the set of requirements for W w.r.t. I. Let µ(e) ∈ ReqI,W. Then, µ(e) is missing in W w.r.t. I iff LMISµ(e) = ∅.
Let us see an example for clarifying our definitions.
Example 6.10 Consider again the set of requirements ReqI,W computed in Example 6.6. Then, µ(e) ≡ (hpage(name(giulio), surname(verdi), status)) is missing in W w.r.t. I, since LMISµ(e) = ∅. Indeed, the requirement µ(e) identifies a “group member” home page which does not appear in the Web site W.
Let us consider now incompleteness errors which refer to incomplete pages, that is, Web pages in which some piece of information is lacking (e.g. missing items).
Definition 6.11 Let W be a Web site, I be a bounded Web specification and ReqI,W be the set of requirements for W w.r.t. I. Let µ(e) ∈ ReqI,W and p ∈ W. Then, p ≡ (V, E, r, label ) is incomplete w.r.t. µ(e) iff
p ∈ LMISµ(e);
there is a minimal injective simulation of mark (e, µ) in p|v w.r.t. ∼, with
v ∈ V , s. t. there is no minimal injective simulation of e in p|v w.r.t. ∼.
In this case, we will call µ(e) incompleteness symptom for p.
Example 6.12 Recall the set of requirements ReqI,W computed in Example
6.6. Then, consider the requirement
µ1(e1 ) ≡ (hpage(status(professor), teaching)),
we have that
LMIS1 (e1 ) = {(1) hpage( name(mario), surname(rossi),
phone(3333), status(professor),
hobbies(hobby(reading), hobby(gardening))),
(2) hpage( name(anna), surname(gialli), status(professor), phone(4444), teaching(course(algebra))) }.
Now, by applying Definition 6.11, we detect that Web page (1) is incomplete
w.r.t. µ1(e1), which is therefore an incompleteness symptom for (1). In fact, Web page (1) lacks teaching information.
Finally, the remaining requirements do not give rise to further errors.


It is worth pointing out that our verification framework is able to detect both the erroneous Web pages and the cause of the detected errors (i.e., the so-called incompleteness symptoms). This allows us not only to locate bugs and inconsistencies w.r.t. a given specification, but also to easily repair them by comparing incomplete pages to incompleteness symptoms, since the latter provides the missing information which is needed to complete the erroneous Web pages.

Implementation
The basic methodology presented so far has been implemented in the prelimi- nary prototype system Verdi (VErification and Rewriting for Debugging Inter- net sites), which is written in DrScheme v205 [18] and is publicly available to- gether with a set of tests at http://www.dimi.uniud.it/∼demis/#software. The implementation consists of about 80 function definitions (approxi- mately 1000 lines of source code). Verdi includes a parser for semistructured expressions and Web specifications, and several modules implementing the user interface, the partial rewriting mechanism and the verification technique. The system allows the user to load a Web site consisting of a finite set of semistructured expressions together with a Web specification. Additionally, he/she can inspect the loaded data and finally check the Web pages w.r.t the Web site specification. The user interface is guided by textual menus, which
are (hopefully) self-explaining.
We tested the system on several Web site examples which can be found at the URL address mentioned above. In each considered test case, we were able to detect the errors (i.e. missing and incomplete Web pages) efficiently. For instance, it took less than one second the verification of the Web site of Example 6.6 w.r.t the Web specification of the Example 4.2, producing error messages when necessary.

Conclusions
Conceiving and maintaining Web sites is a difficult task. In this paper, we provide a rewriting-based, formal specification language which can be used to impose properties both on the structure (syntactic properties) and on the con- tents (semantic properties) of Web sites. The computation mechanism under- lying this language is based on a novel rewriting-like technique, called partial rewriting, in which the traditional pattern matching mechanism is replaced with tree simulation [15]. In our methodology, Web sites are automatically checked w.r.t. a given Web specification in order to detect incomplete and


missing Web pages. Moreover, by analyzing the requirements not fulfilled by the Web site, we are also able to find out the missing information needed to repair the Web site. Our methodology exploits some marking information on terms which represent the Web pages to better locate the errors, which is provided by the user in advance. We have also discussed some implementa- tion details of the preliminary system Verdi, a prototype implementation of the verification framework that we propose. Thus, we use the rewriting-based machinery as a common formalism for the specifications, for specifying our verification technique and for implementing the verification tool.
Finally, let us conclude by mentioning some directions for future work. We are currently extending our framework in order to provide a method for synthesizing the marking information semi-automatically. We also plan to extend the specification language in order to support the detection of regular expressions. This is useful to guarantee that proprietary or “forbidden” data are not displayed on the external version of the site (e.g. a number of credit card). On the practical side, we plan to supply a fully user-friendly system which can help Web administrators to design, check and maintain their Web sites. The system will be developed in Maude [9], which provides an efficient implementation of AC-rewriting, which can greatly simplify as well as improve the implementation of the partial-rewriting mechanism.

References
S. Abiteboul, P. Buneman, and D. Suciu. Data on the Web. From Relations to Semistructured Data and XML. Morgan Kaufmann, 2000.
M. Alpuente, D. Ballis, and M. Falaschi.  A Rewriting-based Framework for Web Sites Verification. Technical Report 4, DSIC, UPV, 2004. Available at URL: http://www.dsic.upv.es/users/elp/papers.html .
I. D. Baxter, F. Ricca, and P. Tonella. Web Application Transformations based on Rewrite Rules. Information and Software Technology, 44(13), 2002.
E. Bertino, M. Mesiti, and G. Guerrin. A Matching Algorithm for Measuring the Structural Similarity between an XML Document and a DTD and its Applications. Information Systems, 29(1):23–46, 2004.
M. Bezem. TeReSe, Term Rewriting Systems, chapter Mathematical background (Appendix A). Cambridge University Press, 2003.
F. Bry and S. Schaffert. Towards a Declarative Query and Transformation Language for XML and Semistructured Data: Simulation Unification. In Proc. of the Int’l Conference on Logic Programming (ICLP’02), volume 2401 of LNCS. Springer-Verlag, 2002.
F. Bry and S. Sebastian Schaffert. The XML Query Language Xcerpt: Design Principles, Examples, and Semantics. Technical report, 2002. Available at: http://www.xcerpt.org.
P. Buneman, S. B. Davidson, G. G. Hillebrand, and D. Suciu. A Query Language and Optimization Techniques for Unstructured Data. In Proc. of ACM SIGMOD Int’l Conference on Management of Data (ICMD’96), 1996.


M. Clavel, S. Eker, P. Lincoln, and J. Meseguer. Principles of Maude. In Proc. of 1st Int’l Workshop on Rewriting Logic and its Applications (RWLW’96), volume 15 of ENTCS, pages 65–89. Elsevier, 1996, http://www.elsevier.com/locate/entcs/volume15.html

A. Cortesi, A. Dovier, E. Quintarelli, and L. Tanca. Operational and abstract semantics of a graphical query language. Theoretical Computer Science, 275:521–560, 2002.
N. Dershowitz and D. Plaisted. Rewriting. Handbook of Automated Reasoning, 1:535–610, 2001.
T. Despeyroux and B. Trousse. Semantic Verification of Web Sites Using Natural Semantics. In Proc. of 6th Conference on Content-Based Multimedia Information Access (RIAO’00), 2000.
M. Fernandez, D. Florescu, A. Levy, and D. Suciu. Verifying Integrity Constraints on Web Site. In Proc. of Sixteenth International Joint Conference on Artiﬁcial Intelligence (IJCAI’99), volume 2, pages 614–619. Morgan Kaufmann, 1999.
M. F. Fernandez and D. Suciu. Optimizing regular path expressions using graph schemas. In
Proc. of Int’l Conference on Data Engineering (ICDE’98), pages 14–23, 1998.
M. R. Henzinger, T. A. Henzinger, and P. W. Kopke. Computing simulations on finite and infinite graphs. In IEEE Symposium on Foundations of Computer Science, pages 453–462, 1995.
H. Hosoya and B. C. Pierce. Regular Expression Pattern Matching for XML. In Proc. of 28th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages (POPL`ı01), volume 36(3) of ACM SIGPLAN Notices. ACM Press, 2001.
C. Kirchner, Z. Qian, P. K. Singh, and J. Stuber. Xemantics: a Rewriting Calculus-Based Semantics of XSLT. Rapport de recherche A01-R-386, LORIA, 2001.
PLT. DrScheme web site. Available at: http://www.drscheme.org.
World Wide Web Consortium (W3C). HyperText Markup Language (HTML) 4.01, 1997. Available at: http://www.w3.org.
World Wide Web Consortium (W3C). Extensible Markup Language (XML) 1.0, second edition, 1999. Available at: http://www.w3.org.
