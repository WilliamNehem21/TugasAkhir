EURO Journal on Computational Optimization 9 (2021) 100008

		




Pareto front approximation through a multi-objective augmented Lagrangian method
Guido Cocchi a, Matteo Lapucci b,∗, Pierluigi Mansuetob
a Intuendi Srl, Via Vittorio Emanuele II 165, Firenze 50139, Italy
b DINFO, Università di Firenze, Via di Santa Marta 3, Firenze 50139, Italy


a r t i c l e	i n f o	a b s t r a c t

	

2020 MSC:
90C29
90C30

Keywords:
Multi-objective optimization Augmented Lagrangian method Pareto front approximation Pareto stationarity
Global convergence
In this manuscript, we consider smooth multi-objective optimization problems with convex constraints. We pro- pose an extension of a multi-objective augmented Lagrangian Method from recent literature. The new algorithm is specifically designed to handle sets of points and produce good approximations of the whole Pareto front, as opposed to the original one which converges to a single solution. We prove properties of global convergence to Pareto stationarity for the sequences of points generated by our procedure. We then compare the performance of the proposed method with those of the main state-of-the-art algorithms available for the considered class of problems. The results of our experiments show the effectiveness and general superiority w.r.t. competitors of our proposed approach.





Introduction

Multi-objective optimization is a mathematical tool which proved to be particularly suited to model and tackle real-world problems where many contrasting goals have to be reached. Successful applications of multi-objective optimization can be found, for example, in statistics (Carrizosa and Frenk, 1998), design (Fu and Diwekar, 2004; Jüschke et al., 1997; Shan and Wang, 2005), engineering (Campana et al., 2018; Kasperska et al., 2004; Liuzzi et al., 2003; Pellegrini et al., 2014; Sun et al., 2016), environmental analysis (Fliege, 2001; Leschine et al., 1992), management science (Gravel et al., 1992; White, 1998) or space exploration (Palermo et al., 2003; Tavana, 2004).
Popular classes of algorithms to solve multi-objective problems are those of scalarization methods (Drummond et al., 2008; Eichfelder, 2009; Fliege, 2004; Gass and Saaty, 1955; Geoffrion, 1968; Pasco- letti and Serafini, 1984; Steuer and Choo, 1983; Zadeh, 1963) and of heuristic methods based on genetic and evolutionary strategies (Deb et al., 2002; Konak et al., 2006; Laumanns et al., 2002; Mostaghim et al., 2007). However, both these families of approaches come with shortcomings. Indeed, scalarization techniques require a detailed anal- ysis of the problem structure in order to identify the weights defin- ing a suitable scalarized objective. Moreover, an unfortunate choice of the weights may lead to unbounded scalar problems, even un- der strong regularity assumptions (Fliege et al., 2009, sec. 7). On the other hand, convergence properties cannot be stated for heuristic algorithms.
∗ Corresponding author.
E-mail address: matteo.lapucci@unifi.it (M. Lapucci).
In order to overcome these limitations, descent methods extend- ing classical scalar optimization techniques have been proposed to address constrained and unconstrained multi-objective problems (see, e.g., Drummond and Iusem, 2004; Fliege et al., 2009; Fliege and Svaiter, 2000). In this work we will bring particular attention to one of such algorithms, the extension of scalar augmented Lagrangian method (Birgin and Martinez, 2014) to the multi-objective case proposed by Cocchi and Lapucci (2020).
This group of algorithms typically produces, similarly to the scalar case, a sequence of points that is asymptotically driven to optimality. However, in the context of multi-objective applications, it is in practice crucial to generate a set of solutions constituting an approximation of the Pareto set, so that the user can choose, a posteriori, the solution providing the most appropriate trade-off among many.
Some recent works actually focused on strategies allowing to handle sequences of sets of points, instead of sequences of points, within multi- objective descent methods. This idea was first explored for derivative- free methods (Custódio et al., 2011; Liuzzi et al., 2016) and then consid- ered for derivative based methods, both in the constrained (Fliege and Vaz, 2016) and the unconstrained (Cocchi et al., 2020) case.
The contribution of this paper consists of the definition of
an extended version of the augmented Lagrangian algorithm for multi-objective optimization (ALAMO) proposed by Cocchi and La- pucci (2020), which deals with sets of points and effectively produces an
approximation of the Pareto front for constrained vector-valued prob- lems. The key elements that characterize the proposed algorithm are


https://doi.org/10.1016/j.ejco.2021.100008
Received 15 February 2021; Received in revised form 29 June 2021; Accepted 13 August 2021
2192-4406/© 2021 The Author(s). Published by Elsevier Ltd on behalf of Association of European Operational Research Societies (EURO). This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/)



the management of a set of points at each iteration, as proposed by Custódio et al. (2011), which are all mutually nondominated w.r.t. the current augmented Lagrangian;
the use of an Armijo-type line search, which possibly considers de- scent w.r.t. only a subset of objectives, in order to enrich the approx- imate front;
the use of a common penalty parameter and Lagrange multipliers for all points in the set of solutions;
the use of the multi-objective steepest descent algorithm from Fliege and Svaiter (2000) to make each point in the current set approximately Pareto-stationary w.r.t. the augmented Lagrangian, with increasing accuracy throughout the iterations.
For the proposed algorithm, we prove properties of convergence to Pareto-stationarity for the generated sequence of sets of points, with- out the need to recur to the concept of linked sequence introduced by Liuzzi et al. (2016). In fact, the convergence along linked sequences is implied by our result.
To the best of our knowledge, the SQP procedure by Fliege and
Vaz (2016) is the only other derivative based method for constructing an approximated Pareto front of constrained multi-objective problems
Definition 2.1. A point 𝑥̄ ∈ Ω is Pareto optimal for problem (1) if there does not exist 𝑦 ∈ Ω such that 𝐹 (𝑦) ≨ 𝐹 (𝑥̄). If there exists a neighborhood
 (𝑥̄) such that the previous property holds in Ω∩  (𝑥̄), then 𝑥̄ is locally
Pareto optimal.
Pareto optimality is a strong property which is hard to attain in prac- tice. A slightly weaker, but certainly more viable to obtain condition is weak Pareto optimality.
Definition 2.2. A point 𝑥̄ ∈ Ω is weakly Pareto optimal for problem (1) if there does not exist 𝑦 ∈ Ω such that 𝐹 (𝑦) < 𝐹 (𝑥̄). If there exists a neigh- borhood  (𝑥̄) such that the previous property holds in Ω∩  (𝑥̄), then
𝑥̄ is locally weakly Pareto optimal.
the problem. The image of the Pareto set through 𝐹 is referred to as the The set of all Pareto optimal solutions constitutes the Pareto set of
Pareto front. We can now turn to the first order necessary conditions for Pareto optimality.
Definition 2.3. A point 𝑥̄ ∈ Ω is Pareto-stationary for problem (1) if, for all feasible directions 𝑑 ∈ Q(𝑥̄) = {𝑣 ∈ ℝ𝑛 ∣ ∃𝑡̄ > 0 ∶ 𝑥̄ + 𝑡𝑣 ∈ Ω ∀ 𝑡 ∈ [0, 𝑡̄]}, it holds

that can be found in the literature. It is worth remarking that, in contrast with the SQP method, convergence of our algorithm does not depend
max
𝑗=1,…,𝑚
∇𝑓𝑗 (𝑥̄)𝑇 𝑑 ≥ 0.

on a final refinement step that follows a finite exploration phase. As also noted by its authors, SQP can indeed be seen as a single point pro- cedure run in a multi-start fashion. On the contrary, in our procedure
Under differentiability assumptions, Pareto-stationarity is a neces- sary condition for all kinds of Pareto optimality; note that the Pareto- stationarity condition can be compactly written as

convergence and exploration advance alongside, with both asymptoti-
min  max ∇𝑓 (𝑥)𝑇 𝑑 = 0.

introduce basic concepts and notation that will be used in the presen- tation of the proposed procedure; in Section 3 we describe in detail our approach; we then provide the convergence analysis in Section 4. In



Now, let us address well known results for unconstrained problems of the form
min 𝐹 (𝑥) = (𝑓1 (𝑥), … , 𝑓 (𝑥))𝑇 .	(2)

ing the good performance of the proposed procedure compared to a set of different state-of-the-art approaches. We finally give some concluding remarks in Section 6.

Preliminaries

In this paper, we consider optimization problems of the form
Pareto optimality notions match those of the constrained case. Even
such case Q(𝑥) = ℝ𝑛 for all 𝑥 ∈ ℝ𝑛.           Pareto-stationarity can be defined as in Definition 2.3, recalling that in
If a point 𝑥̄ is not a Pareto-stationary point for problem (2), then
there exists a direction which is a descent direction w.r.t. all objective
functions. Hence (according to Fliege and Svaiter, 2000, sec. 3.1) we can define the steepest common descent direction as the solution of problem

min
𝑥∈ℝ𝑛
𝐹 (𝑥) = (𝑓1 (𝑥), … , 𝑓 (𝑥))𝑇
(1)
min
max
∇𝑓𝑗 (𝑥̄)𝑇 𝑑,	(3)

s.t.	𝑔(𝑥) ≤ 0,
where 𝐹 ∶ ℝ𝑛 → ℝ𝑚 is a continuously differentiable function and 𝑔 ∶ ℝ𝑛 → ℝ𝑝 is a continuously differentiable, component-wise convex func- tion, so that the feasible set Ω = {𝑥 ∈ ℝ𝑛 ∣ 𝑔(𝑥) ≤ 0} is a closed convex set, which we assume to be nonempty. We denote by 𝐽𝐹 and 𝐽𝑔 the Ja- cobian matrices associated respectively with 𝐹 and 𝑔. In the following, we will also denote by 𝑒 the vector of all ones. Note that equality con-
straints can be equivalently expressed as couples of opposite inequality constraints, so this formulation is in fact general. Actually, specific man- agement of equality constraints can often be convenient from a compu- tational perspective; the following discussion could easily be extended to address the presence of explicit equality constraints, but we prefer not to take them into account for the sake of simplicity.
In the following we will make use of a partial ordering of points in
ℝ𝑚. Given two vectors 𝑢, 𝑣 ∈ ℝ𝑚, we have
𝑢 < 𝑣  ⇔  𝑢𝑖 < 𝑣𝑖  ∀ 𝑖 = 1, … , 𝑚,
𝑢 ≤ 𝑣  ⇔  𝑢𝑖 ≤ 𝑣𝑖  ∀ 𝑖 = 1, … , 𝑚.
We also say that 𝑢 dominates 𝑣, and denote it by 𝑢 ≨ 𝑣, if 𝑢 ≤ 𝑣 and 𝑢 ≠ 𝑣. Finally, we say that 𝑥 ∈ ℝ𝑛 dominates 𝑦 ∈ ℝ𝑛 w.r.t. 𝐹 if 𝐹 (𝑥) ≨ 𝐹 (𝑦).
the objectives 𝑓1, … , 𝑓𝑚 ; however, such a solution is very unlikely to Ideally, we would like to find a point simultaneously minimizing all
exist; instead, we rely on the concept of Pareto optimality.
𝑑∈ℝ 𝑗=1,…,𝑚
1
which, if 𝓁∞ norm is employed, can be reformulated as the LP problem
min	𝛽
𝛽∈ℝ, 𝑑∈ℝ𝑛
s.t.	−1 ≤ 𝑑𝑖 ≤ 1  ∀ 𝑖 = 1, … , 𝑛,
∇𝑓𝑗 (𝑥̄)𝑇 𝑑 ≤ 𝛽  ∀ 𝑗 = 1, … , 𝑚.
scent directions, based on an 𝓁2-regularized formulation of problem Note that a slightly different characterization of steepest common de-
(3) and again proposed by Fliege and Svaiter (2000), could be employed. Here we preferred to use formulation (3) because of the simplicity of the LP problem.
a real technical issue; we can define function 𝜃 ∶ ℝ𝑛 → ℝ such that 𝜃(𝑥̄) The solution of problem (3) may in fact be not unique, but this is not indicates the optimal value of problem (3) at 𝑥̄; function 𝜃 is continuous. We also denote by 𝑣(𝑥̄) the set of optimal solutions of (3), which is cer- tainly nonempty. As previously stated, if 𝑥̄ is Pareto-stationary, 𝜃(𝑥̄) = 0, if it is not, 𝜃(𝑥̄) < 0.
Now, based on the concept of steepest common descent, the stan- dard (single-point) multi-objective steepest descent (MOSD) algorithm
was proposed by Fliege and Svaiter (2000). We report the algorithm in Algorithm 1 .
The algorithm makes use of a backtracking Armijo-type line search, which is described in Algorithm 2. The idea of the latter procedure is




Algorithm 1: MultiObjectiveSteepestDescent.
1 Input: 𝐹 ∶ ℝ𝑛 → ℝ𝑚, 𝑥0 ∈ ℝ𝑛
2 𝑘 = 0
3 while 𝑥𝑘 is not Pareto stationary do
4	Compute
𝑑𝑘 ∈ arg min  max ∇𝑓𝑗 (𝑥𝑘)𝑇 𝑑
Finally, we recall, from Cocchi and Lapucci (2020), the definition of multi-objective augmented Lagrangian for problems with inequality constraints.

penalty parameter 𝜏 associated with problem (1) is given by Definition 2.5. The multi-objective augmented Lagrangian function of
(∑𝑝 (	{	𝜇 })2)
	 		

5	𝛼𝑘 = ArmijoTypeLineSearch(𝐹 (⋅), 𝑥𝑘, 𝑑𝑘)
6	𝑥𝑘+1 = 𝑥𝑘 + 𝛼𝑘 𝑑𝑘
7	𝑘 = 𝑘 + 1
8 return 𝑥𝑘
Algorithm 2: ArmijoTypeLineSearch.
1 Input: 𝐹 ∶ ℝ𝑛 → ℝ𝑚, 𝑥 ∈ ℝ𝑛, 𝑑 ∈ ℝ𝑛, 𝛼0 > 0, 𝛿 ∈ (0, 1), 𝛽 ∈ (0, 1)
2 𝛼 = 𝛼0
3 while 𝐹 (𝑥 + 𝛼𝑑) ≰ 𝐹 (𝑥) + 𝛽𝛼𝐽𝐹 (𝑥)𝑑 do
where 𝜇 ≥ 0 ∈ ℝ𝑝 is the vector of Lagrange multipliers.
The algorithm

In this section, we describe the multiple-points multi-objective
augmented Lagrangian method proposed in this paper, which we call FRONT-ALAMO, to solve problem (1). The algorithmic scheme is  reported in Algorithm  3. Note  that we have  de-
noted by MultiobjectiveSteepestDescent(⋅, ⋅, 𝜀𝑘 ) the procedure in Algorithm 1 run until the solution is 𝜀𝑘 -Pareto-stationary. We also de-
note by G𝐼 (𝑥, 𝜇) the components of G𝜏 (𝑥, 𝜇) indexed by 𝐼 , and by 𝜃𝑘 and

4	𝛼 = 𝛿𝛼	𝜏	𝑘

5 return 𝛼
𝑣𝑘 maps 𝜃 and 𝑣 associated with G𝜏 (𝑥, 𝜇 ).





that of reducing the step size as long as a suﬃcient decrease has not been reached for all the objective functions.
We now recall the main theoretical property characterizing the line


Algorithm 3: FRONT-ALAMO.

1 Input: 𝜇0 ∈ ℝ𝑝 , 𝜇̄ ≥ 0, 𝜌 > 1, 𝜎 ∈ (0, 1), 𝜏0 > 0, 𝑋0 a list of feasible non-dominated points for the original problem, {𝜀𝑘 } ⊂ ℝ a
decreasing sequence
2 for 𝑘 = 0, 1, … do

search (Fliege and Svaiter, 2000, Lemma 4).
Lemma 2.1. If 𝐹 is continuously diﬀerentiable and 𝐽𝐹 (𝑥)𝑑 < 0 (i.e., 𝜃(𝑥) <
3	Let G𝜏𝑘
as:
the current Augmented Lagrangian function defined

0), then there exists some 𝜀 > 0, which may depend on 𝑥, 𝑑 and 𝛽, such that
𝜏 ⎛∑𝑝 (	{	𝜇𝑘 })2⎞

𝐹 (𝑥 + 𝑡𝑑) < 𝐹 (𝑥) + 𝛽𝑡𝐽𝐹 (𝑥)𝑑

G𝜏 (𝑥, 𝜇𝑘) = 𝐹 (𝑥) +
𝑘
2  𝑖=1
max
0, 𝑔𝑖 (𝑥) +
𝑖
𝜏𝑘
⎟⎟𝑒

The above lemma guarantees finite termination of the line search procedure along a common descent direction. The following conver- gence properties (Fliege and Svaiter, 2000, Theorem 1 and Section 9.1)
hold instead for the MOSD procedure.
Lemma 2.2. Every accumulation point of the sequence {𝑥𝑘} produced by
5	set 𝑋tmp = 𝑋̂ 𝑘
6	for 𝑥𝑐 ∈ 𝑋̂ 𝑘 do
7	for 𝐼 ∈ 2{1,…,𝑚} do
8	if 𝜃𝐼 (𝑥𝑐 ) < 0 then
9	set 𝑑 ∈ 𝑣𝐼 (𝑥𝑐 )
𝑘	𝑘


𝐼	𝑘

10
Algorithm 1 is a Pareto stationary point. If the function 𝐹 has bounded level
sets, in the sense that {𝑥 ∈ ℝ𝑛 ∣ 𝐹 (𝑥) ≤ 𝐹 (𝑥0)} is bounded, then the sequence	11
{𝑥𝑘} stays bounded and has at least one accumulation point.
Now, we need to introduce relaxations to the concepts of Pareto-	12
set 𝛼 = ArmijoTypeLineSearch(G𝜏 (⋅, 𝜇 ), 𝑥𝑐 , 𝑑)
set 𝑧 =
MultiObjectiveSteepestDescent(G𝜏 (⋅, 𝜇𝑘), 𝑥𝑐 +
𝛼𝑑, 𝜀𝑘 )
if ∄ 𝑦 ∈ 𝑋tmp ∶ G𝜏 (𝑦, 𝜇𝑘) ≨ G𝜏 (𝑧, 𝜇𝑘) then

stationary and common descent directions. First, we recall the concept	13
set 𝑋tmp
(
= 𝑋
𝑘
tmp
⧵ {𝑥 ∈ 𝑋
𝑘
tmp |
G𝜏𝑘
(𝑧, 𝜇𝑘) ≨

of 𝜀-Pareto-stationarity introduced by Cocchi and Lapucci (2020).
Definition 2.4. Let 𝜀 ≥ 0. A point 𝑥̄ ∈ ℝ𝑛 is 𝜀-Pareto-stationary for prob-
lem (2) if
min  max ∇𝑓𝑗 (𝑥̄)𝑇 𝑑 ≥ −𝜀.

14
15



G𝜏𝑘
set 𝑋𝑘+1 = 𝑋tmp
for 𝑖 = 1, … , 𝑝 do

 

𝑥, 𝜇𝑘)} ∪ {𝑧}
{	𝜇𝑘 }


Next, inspired by Cocchi et al. (2020), we can introduce the concept
17
set 𝜇𝑘+1 = max {0, min{𝜇𝑘 + 𝜏
max {𝑔 (𝑥)}, 𝜇}}

{1, … , 𝑚}. Given problem
18	if (
𝑘+1
𝑘 ) or (∃ 𝑥𝑘+1 ∈ 𝑋𝑘+1 s.t. 𝑔 (𝑥𝑘+1) < 0 and

||𝑉	|| > 𝜎||𝑉 ||	𝑖

𝑑∈ℝ𝑛 𝑗∈𝐼	𝑗
1
𝑖
19	set 𝜏𝑘+1 = 𝜌𝜏𝑘

𝑑 ≤
we denote by 𝜃𝐼 (𝑥̄) its optimal value and by 𝑣𝐼 (𝑥̄) the set of optimal
solutions, which we refer to as steepest partial descent directions w.r.t.

20	else
21	set 𝜏𝑘+1 = 𝜏𝑘

𝐼 . Partial descent directions, if used appropriately, can be useful in al-		
gorithms to perform exploration steps to enrich the current Pareto set

2020, Proposition 3) that, if 𝑥̄ is not a Pareto-stationary point for (2), approximation. It is easy to see (by analogous reasonings as Cocchi et al., then 𝜃𝐼 (𝑥̄) < 0 for any 𝐼 ⊆ {1, … , 𝑚}.
points {𝑋𝑘}, which approximate the Pareto set of the original problem Through the iterations, the algorithm produces a sequence of sets of
with increasing accuracy. At each iteration, an augmented Lagrangian




eter 𝜏𝑘 and multipliers 𝜇𝑘. At the beginning of the generic iteration 𝑘, all function defined as in Definition 2.5 is considered, with penalty param-
Proposition 4.2. Let {𝑋𝑘+1} be the sequence of sets generated by Algorithm
Then, for each 𝑘 and for each 𝑥𝑘+1 ∈ 𝑋𝑘+1, we have:

points that are dominated w.r.t. G𝜏 (𝑥, 𝜇𝑘) are filtered out of the set; we
(a)
𝑥𝑘+1
is not dominated by any other point in 𝑋
𝑘+1
w.r.t. G𝜏 (𝑥, 𝜇𝑘), i.e.,

denote such filtered set by 𝑋̂ 𝑘 . Now, the following iterate is initialized
there does not exist
𝑘+1
𝑘
𝑘	𝑘

𝑘	𝑘
𝑦 ∈ 𝑋	such that G𝜏 (𝑦, 𝜇 ) ≨ G𝜏 (𝑥𝑘+1, 𝜇 );

as 𝑋̂ ; then, each point 𝑥𝑐 ∈ 𝑋̂  is used as a starting point for explo-
ration; in particular, for any possible subset 𝐼 ⊆ {1, … , 𝑚} the steepest
(b)
𝑥𝑘+1 is 𝜀𝑘
𝑘	𝑘
-Pareto-stationary w.r.t. G𝜏 (𝑥, 𝜇𝑘).

partial descent direction is explored by an ArmijoTypeLineSearch
restricted to the components of G𝐼 (𝑥, 𝜇𝑘), provided that a partial de-
Proof. We prove the two statements one at a time:
𝑘+1

𝜏𝑘
𝑋	is equal to 𝑋tmp at the end of the main loop of each iteration,

scent direction actually exists. After the line search step, the obtained
point is refined by steepest descent on all the objectives up to 𝜀𝑘 -Pareto-
at step 14. 𝑋
tmp
is initialized with 𝑋̂ 𝑘 , which contains mutually non-
𝑘

stationarity. If it is then not dominated w.r.t. G
𝜏𝑘
(𝑥, 𝜇𝑘) by any other
dominated points w.r.t. G𝜏 (𝑥, 𝜇 ) by its definition at line 4. Then,
𝑋tmp can be modified only at step 13, where a point is added only

point currently in the new iterate set, it is consequently added to such set, while all points that are dominated by it are removed.
Once all points in 𝑋̂ 𝑘 are tested, the constructed set will constitute
the next iterate 𝑋𝑘+1. The multipliers and the penalty parameter are
updated similarly as in the scalar ALM with multipliers safeguarding
(Kanzow and Steck, 2017), with one key adjustment: to evaluate how much a constraint is violated, the worst violation attained on that con-
straint by any point in 𝑋𝑘+1 is considered. In addition, the second clause
where a point which is strictly feasible w.r.t. some constraint 𝑔𝑖 is un- of the conditional statement at line 18 allows to avoid unfortunate cases
necessarily pushed to satisfy it with a larger margin.
if it is nondominated, from the condition at line 12, and all points dominated by it are removed.
We have two possible cases: 𝑥𝑘+1 ∈ 𝑋̂ 𝑘 or 𝑥𝑘+1 ∉ 𝑋̂ 𝑘 . In the latter
case, 𝑥𝑘+1 has necessarily been added to 𝑋tmp through instructions 9–13; in particular, 𝑥𝑘+1 was produced by instruction 11 and is thus
𝜀𝑘 -Pareto-stationary.
So, let us assume that 𝑥𝑘+1 ∈ 𝑋̂ 𝑘 and, by contradiction, that
𝜃𝑘 (𝑥𝑘+1) < −𝜀𝑘 . In this case, 𝑥𝑐 = 𝑥𝑘+1 would satisfy the conditions at step 8 for 𝐼 = {1, … , 𝑚}, as 𝜃𝐼 (𝑥𝑘+1) = 𝜃𝑘 (𝑥𝑘+1) < −𝜀𝑘 < 0. The line search hence is guaranteed, by Lemma 2.1, to find a step 𝛼 such that
G𝜏 (𝑥𝑐 + 𝛼𝑑, 𝜇𝑘) < G𝜏 (𝑥𝑐 , 𝜇𝑘), and by the properties of the MOSD pro-

𝑘	𝑘

Remark 3.1. At each iteration 𝑘, the set 𝑋𝑘+1 is a list of mutually non-
cedure we have G𝜏 (𝑧, 𝜇𝑘) ≤ G𝜏 (𝑥𝑐 + 𝛼𝑑, 𝜇𝑘). Hence, this new point 𝑧

𝑘	𝑘

dominated points w.r.t. G𝜏 (𝑥, 𝜇𝑘). As we will shortly see, maintaining a
set of mutually nondominated points with respect to the augmented La-
grangian does not provide theoretical asymptotic properties. However,
(strictly) dominates 𝑥𝑘+1 w.r.t. G𝜏 (𝑥, 𝜇𝑘). Now, from the instructions
of the algorithm, either 𝑧 belongs to 𝑋𝑘+1 or there exists 𝑦 ∈ 𝑋𝑘+1
such that G𝜏 (𝑦, 𝜇𝑘) ≨ G𝜏 (𝑧, 𝜇𝑘) < G𝜏 (𝑥𝑘+1, 𝜇𝑘). However, this is ab-

𝑘	𝑘	𝑘

this has a remarkable impact from a computational point of view: it al- lows, especially at late iterations, to remove solutions that are too far from feasibility or that have bad values for all the objectives; in addi- tion, in practice the algorithm will be run for a large enough number of iterations and then stopped; the solutions in the returned set are mu- tually nondominated w.r.t. the final augmented Lagrangian; because of this property, most of the points in the returned set that are “suﬃciently feasible” are nondominated also w.r.t. the original problem.
surd, since 𝑥𝑘+1 ∈ 𝑋𝑘+1 and from statement (a) 𝑋𝑘+1 contains mutu- ally nondominated points. Hence, 𝜃𝑘 (𝑥𝑘+1) ≥ −𝜀𝑘 .
□
Let {𝑋𝑘} be the sequence of (finite) sets produced by the algorithm.
we need to consider sequences of points {𝑥𝑘} such that 𝑥𝑘 ∈ 𝑋𝑘 for all In order to assess the asymptotic convergence properties of Algorithm 3,
𝑘.

In the next section, we will show in detail that Algorithm 3 is well defined and we will carefully address its convergence properties.

Convergence analysis

In this section, we provide a rigorous formal analysis of Algorithm 3 from a theoretical perspective. We first show that the pro- cedure is actually well defined and then we state its asymptotic con- vergence properties. Before proceeding, we need to make a reasonable assumption.
Assumption 4.1. The objective function 𝐹 has bounded level sets in the multi-objective sense, i.e., the set {𝑥 ∈ ℝ𝑛 ∣ 𝐹 (𝑥) ≤ 𝑧} is bounded for any 𝑧 ∈ ℝ𝑚.

Concerning algorithm well-definiteness, we begin by noting that the
We are now able to begin the convergence analysis with a technical Lemma.
Lemma 4.3. Let {𝑋𝑘} be the sequence of sets generated by Algorithm 3, and let {𝑥𝑘} be any sequence of points such that 𝑥𝑘 ∈ 𝑋𝑘 for all 𝑘. Let 𝑥̄ be a limit point of {𝑥𝑘}, i.e., there exists an infinite subset 𝐾 ⊆ {0, 1, …} such
that
lim 𝑥𝑘 = 𝑥̄,
𝑘→∞
𝑘∈𝐾
and suppose that 𝑔(𝑥̄) ≤ 0, i.e., 𝑥̄ ∈ Ω. Then, for all 𝑖 = 1, … , 𝑝 such that
𝑔𝑖 (𝑥̄) < 0 we have
max{0, 𝜇𝑘 + 𝜏𝑘 𝑔𝑖 (𝑥𝑘+1)} = 0
for all 𝑘 ∈ 𝐾 sufficiently large.
Proof. Let 𝑔𝑖 (𝑥̄) < 0 and 𝑘1 ∈ 𝐾 be such that 𝑔𝑖 (𝑥𝑘+1) < 𝑐 < 0 for all 𝑘 ≥
𝑘1, 𝑘 ∈ 𝐾. From the instructions of the algorithm we know that 𝜇𝑘 ≥ 0

line search procedure at line 10 of Algorithm 3 stops in a finite time, producing a valid stepsize. Indeed, this result holds straightforwardly from Lemma 2.1 and the fact that the procedure is performed consider-
ing G𝐼 (𝑥, 𝜇𝑘), starting at a point 𝑥𝑐 such that 𝜃𝐼 (𝑥𝑐 ) < 0.
for all 𝑘. There are two possible cases:
(a) 𝜏𝑘 → ∞
The sequence {𝜇𝑘} is bounded by definition, hence there exists 𝑘2 ≥
𝑘	𝑘+1

𝜏𝑘
𝑘	𝑘1 , 𝑘2 ∈ 𝐾, such that for all 𝑘 ∈ 𝐾, 𝑘 ≥ 𝑘2 we have 𝜇𝑖 + 𝜏𝑘 𝑔𝑖 (𝑥	) <

The other nontrivial instruction of the FRONT-ALAMO procedure is
0 and thus max{0, 𝜇𝑘 + 𝜏𝑘 𝑔𝑖 (𝑥𝑘+1)} = 0.

step 11, that we address in the following proposition.
(b) {
𝑖
𝜏𝑘 } is bounded.

Proposition 4.1. The MultiObjectiveSteepestDescent pro- cedure at line 11 of Algorithm 3 stops in a finite number of iterations.
Proof. Finite termination can be proved as in Proposition 4 from Cocchi and Lapucci (2020), recalling that Assumption 4.1 holds.	□

set                             𝑋𝑘. Now, we are able to characterize the points belonging to each iterate
From instruction 18 of the algorithm, there must exist 𝑘2 ≥ 𝑘1 such
that, for all 𝑘 ≥ 𝑘2, condition
∀ 𝑥 ∈ 𝑋𝑘+1  𝜇𝑘 + 𝜏𝑘 𝑔𝑗 (𝑥) ≤ 0  ∀𝑗 ∈ {1, … , 𝑝} s.t. 𝑔𝑗 (𝑥) < 0
holds. Hence, for 𝑘 ≥ 𝑘2 , 𝑘 ∈ 𝐾, we have 𝜇𝑘 + 𝜏𝑘 𝑔𝑖 (𝑥𝑘+1) ≤ 0. Thus, we have max{0, 𝜇𝑘 + 𝜏𝑘 𝑔𝑖 (𝑥𝑘+1)} = 0 for 𝑘 ∈ 𝐾 suﬃciently large.
□



quences   {𝑥𝑘}   produced   by   the   algorithm. Next, we prove feasibility of limit points of all possible points se-
Proposition 4.4. Let {𝑋𝑘} be the sequence of sets generated by Algorithm 3, with 𝜀𝑘 → 0, and let {𝑥𝑘} be any sequence of points such that 𝑥𝑘 ∈ 𝑋𝑘 for all 𝑘. Let 𝑥̄ be a limit point of {𝑥𝑘}. Then, 𝑥̄ is feasible for problem (1), i.e., 𝑔(𝑥̄) ≤ 0.
Proof. Let 𝐾 ⊆ {0, 1, …} be an infinite subset such that
lim 𝑥𝑘+1 = 𝑥̄.
𝑘→∞
𝑘∈𝐾
If the sequence {𝜏𝑘 } is bounded, from the instructions of the algorithm
Remark 4.1. Pareto-stationarity, which we are able to prove for limit points of FRONT-ALAMO, is the same property that holds for limit points of the sequence produced by the single point ALAMO and anal-
ogous, in the scalar context, to stationarity attained by limit points of scalar ALM. Therefore, it is reasonable to assume that stronger properties are unlikely to be obtained by an ALM-like algorithm.
Remark 4.2. In the literature of Pareto front constructing descent meth- ods (Cocchi et al., 2020; Liuzzi et al., 2016), convergence analysis is
based on the concept of linked sequence. A sequence {𝑥𝑘} is a linked
sequence if, for all 𝑘, 𝑥𝑘 ∈ 𝑋𝑘 and 𝑥𝑘 is generated at iteration 𝑘 − 1
starting the search procedure from 𝑥𝑘−1. It is easy to see that linked se-
quences are a particular instance of the sequences of points considered

there must exist 𝑘
such that, for all 𝑘 > 𝑘 , we have
𝑉 𝑘+1
≤ 𝜎 𝑉 𝑘 .

1
Since	1
1	‖	‖	‖	‖
in Propositions 4.4 and 4.5, hence the convergence result obtained for




lim
𝑉 𝑘
= 0,

𝑘→∞
i.e., for all 𝑖 ∈ {1, … , 𝑝},
lim 𝑉 𝑘+1 = lim min {



𝜇𝑘
min {−𝑔𝑖 (𝑥)}, 𝑖

= 0.
a limit point 𝑥̄. As commonly done in the literature of augmented La- Remark 4.3. In our theoretical analysis we assumed the existence of
grangian methods (Birgin and Martinez, 2014; Cocchi and Lapucci, 2020), we do not directly address properties of existence of limit points,

𝑘→∞ 𝑖
𝑘→∞
𝑥∈𝑋𝑘+1
𝜏𝑘
leaving it to boundedness arguments on the sequences, level sets, lower- level feasible sets or restart strategies.

Since by definition 𝜇𝑘 ≥ 0 for all 𝑖 and 𝑘, it has to be
lim min  −𝑔 (𝑥) ≥ 0.
𝑘→∞𝑥∈𝑋𝑘+1
But min𝑥∈𝑋𝑘+1 {−𝑔𝑖(𝑥)} ≤ −𝑔𝑖(𝑥𝑘+1). Hence
Remark 4.4. The SQP algorithm from Fliege and Vaz (2016) which is, to the best of our knowledge, the only other derivative-based method in the literature to generate an approximation of the Pareto front, has
similar convergence properties as Algorithm 3, in the sense that limit
points of sequences of solutions are Pareto-stationary. However, the set-

𝑔𝑖 (𝑥) = lim 𝑔𝑖 (𝑥𝑘+1) ≤ lim  max {−𝑔𝑖 (𝑥)} ≤ 0.
ting is basically different, as the exploration phase of the SQP method



Now, assume 𝜏𝑘 → ∞. From Proposition 4.2, we know that each point
𝑥 ∈ 𝑋𝑘+1 is 𝜀𝑘 -Pareto-stationary w.r.t. G𝜏 (𝑥, 𝜇𝑘). Hence
⎧⎪(	∑𝑝	{	𝜇𝑘 }	)𝑇 ⎫⎪
dently driven to Pareto-stationarity by an iterative method. Conver- gence hence follows from a single-point mechanism. On the other hand, in Algorithm 3 exploration and convergence are performed somewhat
in parallel, in an effectively multiple-points fashion.

max
𝑗=1,…,𝑚
⎩
∇𝑓𝑗 (𝑥𝑘+1 ) + 𝜏𝑘
𝑖=1
max
0, 𝑔𝑖 (𝑥𝑘+1 ) +
𝑖
𝜏𝑘
∇𝑔𝑖 (𝑥𝑘+1 )
𝑑  ≥ −𝜀𝑘
⎪⎭
∀ 𝑑 ∈ ℝ𝑛 ∶ 𝑑
≤ 1.
Computational experiments

Dividing both sides of the inequality by 𝜏𝑘 and taking the limits for
𝑘 → ∞, 𝑘 ∈ 𝐾, recalling the continuity of 𝐽𝐹 and 𝐽𝑔 , the boundedness of 𝑑 and {𝜇𝑘} and that 𝜏𝑘 → ∞, we get

In this Section, we show the results of thorough computational ex- periments, focusing on the comparisons between FRONT-ALAMO and
some state-of-the-art methods in the multi-objective constrained opti-

max
⎧⎪(∑𝑝
max{0, 𝑔 (𝑥̄)}∇𝑔 (𝑥̄)
)𝑇
𝑑⎫⎪
≥ 0  ∀ 𝑑 ∈ ℝ𝑛 ∶ 𝑑
≤ 1,
mization context. All the tests were run on a computer with the follow-

𝑗=1,…,𝑚 ⎨⎪
𝑖=1
𝑖	𝑖
⎪⎬⎭
ing characteristics: Intel Xeon Processor E5-2430 v2 6 cores 2.50 GHz, 16 GB RAM. The code for all the algorithms considered in the experi- ments was written in Python3.

of       𝑗,       is       equal       to which, since the arguments of the outer max operator are independent
1 ∇  max{0  ( )} 2 𝑇	0  ∀  ∈  𝑛 ∶	1
2
where the max operator is intended component-wise. Thus, 𝑥̄ is a critical
point for problem

Experiment Settings

Before commenting the results, we list the state-of-the-art methods used in the comparisons with FRONT-ALAMO. In addition, we describe the tested problems and the metrics used in the comparisons.

min 1
𝑥∈ℝ 2
max{0, 𝑔(𝑥)} 2 .
Metrics
In order to evaluate the performance of the algorithms, we employed

Since Ω ≠ 0 and the above problem is convex, 𝑥̄ is a global minimum point with max{0, 𝑔(𝑥̄)} = 0, i.e., 𝑔(𝑥̄) ≤ 0.	□
Finally, we show that limit points are Pareto-stationary for the orig- inal problem.
Proposition 4.5. Let {𝑋𝑘} be the sequence of sets generated by Algorithm 3, with 𝜀𝑘 → 0, and let {𝑥𝑘} be any sequence of points such that 𝑥𝑘 ∈ 𝑋𝑘 for all 𝑘. Let 𝑥̄ be a limit point of {𝑥𝑘}. Then, 𝑥̄ is Pareto-stationary for problem
(1).
Proof. Recalling that, from Proposition 4.2, 𝑥𝑘+1 is 𝜀𝑘 -Pareto-stationary for G𝜏 (𝑥, 𝜇𝑘), the result follows as in Proposition 6 from Cocchi and
Lapucci (2020), where Lemma 4.3 can be used in place of Lemma 9 from the referenced paper.	□
the three metrics defined by Custódio et al. (2011), which are very pop- ular and used by the multi-objective optimization community: purity,
Γ–spread and Δ–spread. We recall that the purity metric measures the
quality of the generated front, that is, how good the non-dominated
points computed by a solver are with respect to those obtained by the other ones. Clearly, a higher value is associated with a better perfor- mance. In order to calculate this metric, we need a reference front to which compare the generated front of an algorithm. In our experiments, the reference front was the one obtained by combining the fronts of all the considered algorithms and by discarding the dominated points. The spread metrics are equally essential because they measure the uniformity
of the generated front in the objectives space. In particular, the Γ–spread
is defined as the maximum 𝓁∞ distance in the objectives space between adjacent points of the Pareto front, and the Δ–spread is quite similar



to the standard deviation of the 𝓁∞ distances between adjacent Pareto front points. In these metrics, good performance is associated with a low
value.
In addition to the three previous metrics, we evaluated the number of non-dominated points obtained by a method with respect to the ref- erence front (ND–points). We supposed that this metric was as important as the purity one. Indeed, ND–points metric allowed us to see how many non-dominated points an algorithm was capable to obtain with respect to the whole reference front.
Lastly, we employed the popular performance profiles introduced by Dolan and Moré (2002), that are an useful tool to better appreciate the relative performance and robustness of the algorithms. The performance profile for a solver is the (cumulative) distribution function for the ratio of the value of the performance measure obtained by the solver to the best one of all of the solvers. In particular, it is the probability for solver
𝑠 that one of its performance measure values achieved in a problem is
within a factor 𝜏 ∈ ℝ of the best possible value obtained by all of the
solvers in that problem. For a more detailed explanation about perfor-
mance profiles, we refer to Dolan and Moré (2002). Note that perfor- mance profiles w.r.t. purity and ND–points were generated considering the inverse of the obtained values, since the metrics have increasing values for better solutions.

Algorithms and hyper-parameters
The choices about the FRONT-ALAMO hyper-parameters values
were made based on some preliminary results on a subset of the tested problems, which we do not report here for the sake of brevity. The val- ues are the following:
𝜏0 = 1;
if the problem only has bound constraints 𝜌 = 10, otherwise 𝜌 = 2;
𝜎 = 0.9;
𝜇 = 104;
𝜇0 = 0 ∈ ℝ𝑝;
in the ArmijoTypeLineSearch 𝛽 = 10−4 and 𝛿 = 0.5.
The first algorithm we chose to use in the comparison with FRONT-ALAMO is MOSQP (Fliege and Vaz, 2016), which is a gradient- based method for constrained and unconstrained nonlinear multi- objective optimization problems that implements an SQP–type ap- proach. Since it is the only gradient-based algorithm from the literature
designed to produce Pareto front approximations, we consider it our most important competitor. The chosen hyper-parameters for MOSQP
approximations, we used 𝐻𝑖 = 𝐼𝑚 (𝐼𝑚 being the identity matrix) in the were the best ones according to Fliege and Vaz (2016). For the quadratic second stage and 𝐻𝑖 = ∇2𝑓𝑖(𝑥𝑘) + 𝐸𝑖 (𝐸𝑖 being obtained by a modified
Cholesky algorithm) in the third stage, as Fliege and Vaz (2016) state that it is the most robust and eﬃcient way to use MOSQP. For a more de- tailed explanation about the various MOSQP stages and versions, we re- fer to Fliege and Vaz (2016). Lastly, we used the Ipopt software pack-
age (Wächter and Biegler, 2006) (https://github.com/coin-or/Ipopt) in order to solve the SQP problems.
DMS (Custódio et al., 2011) is the second algorithm used in
the comparisons. It is a multi-objective derivative-free methodology, which is inspired by the search/poll paradigm of direct-search meth- ods of directional type and uses the concept of Pareto dominance to maintain a list of non-dominated points, from which the new iter-
ates or poll centers are chosen. The hyper-parameters for DMS were
set according to Custódio et al. (2011) and to the authors code (http://www.mat.uc.pt/dms).
The third and last algorithm is NSGA-II (Deb et al., 2002), which is
a non-dominated sorting-based multi-objective evolutionary algorithm. In particular, NSGA-II is a genetic algorithm that is mainly composed
by a fast non-dominated sorting approach and a selection operator that creates a mating pool by combining the parent and offspring populations
and selecting the best 𝑁 solutions. In contrast to the other algorithms,
NSGA-II considers a fixed number of solutions in the pool, which was
Table 1
Problems used in the computational experiments. #L.C. indicates the num-
ber of linear constraints (in this column the boundary constraints are not con- sidered). #N.L.C. indicates the number of non linear constraints. B.C. indicates the type(s) of the boundary conditions.



set to 100 in our experiments. The hyper-parameters of the algorithm were the ones chosen by Deb et al. (2002).
For each algorithm and problem, we decided to execute the test for up to 2 min. A termination criterion based on a time limit is the fairest way to evaluate the behavior of such diverse algorithms on the tested problems. Clearly, specific stopping criteria indicating that a certain al- gorithm cannot improve the solutions anymore were also taken into ac-
count. Since NSGA-II is the only non-deterministic algorithm used in
the computational experiments, we decided to run it with 10 different seeds for the pseudo-random number generator. Every execution had the same time limit used for the other algorithms (2 min). After the ex- ecution of the 10 runs, we compared the fronts based on the purity met- ric and we chose the best one among them. In this case, the reference front for the comparison was obtained by combining the fronts of the
10 executions. We considered the resulting best front as NSGA-II out- put. Executing 10 runs lets NSGA-II reduce its sensibility with respect
to the seed used for its random operations. Note however that, since we consider a best case scenario for NSGA-II, the overall comparison should be considered at least partially biased in favor of this algorithm. The other methods (FRONT-ALAMO, DMS, MOSQP) are deterministic. Therefore, they were executed once.

Problems
The tested problems are described in Table 1. In this benchmark, we considered problems whose objective functions are at least continuously differentiable almost everywhere. Since some problems present singu- larities, we counted them as Pareto-stationary points. All the constraints are defined by continuously differentiable convex functions.
We included in our benchmark the slightly modified versions of the BNH problems and the LAP problems from Cocchi and Lapucci (2020). We also included a modification of the OSY problem (Osyczka and Kundu, 1995). The modified form of this problem can be found in Appendix A.
Furthermore, we included into the test set problems characterized only by boundary constraints: the CEC problems (Zhang et al., 2008), the ZDT problems (Zitzler et al., 2000) and the MOP problems (Huband et al., 2006). It is worth remarking that the CEC and ZDT problems have particularly diﬃcult objective functions, so they are interesting to study the effectiveness of the algorithms when solving hard problems.
For each problem with general constraints, we started the algorithms from one feasible point (Table 2). In this way, we intended to study the exploration capabilities of the algorithms. Indeed, algorithms with great exploration abilities should create a spread and solid Pareto front on these problems. For the bound constrained problems (MOP1 is the only

ering the M-BNH problems (For interpretation of the references to color in text, the reader is referred to the web version of the article).














Table 2
Initial points for the tested problems.

PROBLEM(S)	INITIAL POINT(S)
M-BNH1, LAP1,	0 ∈ ℝ𝑛
LAP2, MOP1
M-BNH2	[8, −3]
M-OSY	[2, 0, 1, 0, 1, 8]
CEC, ZDT,	Points from the MOP2, MOP3	hyper-diagonal





exception since it is too small in terms of number of dimensions), the ini- tial points were uniformly selected from the hyper-diagonal defined by the lower and upper bounds, as done by Custódio et al. (2011). In these cases, the number of initial points is equal to the number of dimensions of the considered problem.
M-BNH, LAP1 and M-OSY problems

We begin by studying the performance of the considered algorithms on the M-BNH1, M-BNH2, LAP1 and M-OSY problems.
The results on the M-BNH problems (Fig. 1) show the great perfor- mance of FRONT-ALAMO with respect to the competitors: indeed, our method obtained the best purity value in the M-BNH1 problem and a
purity value very close to the best one in the M-BNH2. In this latter problem, the differences with respect to our gradient-based competitor
and DMS are even clearer, as FRONT-ALAMO obtained a purity value
very close to 1. Here, the MOSQP method did not manage to obtain a single non-dominated point w.r.t. the competitors. Considering the Δ–
spread, FRONT-ALAMO was the second best method in both problems. As for the Γ–spread, FRONT-ALAMO appears to have a decent behavior,
being the second best algorithm in the M-BNH1 problem and outper- forming all the competitors in the M-BNH2 problem. This behavior can

ering the LAP1 and M-OSY problems (For interpretation of the ref- erences to color in text, the reader is referred to the web version of the article).















also be observed on the LAP1 and M-OSY problems (Fig. 2). The worst algorithm turned out to be MOSQP, which seems to lack of search ca- pabilities in the objectives space on the M-BNH problems. This fact can also be noted for the DMS and NSGA-II algorithms on the M-BNH2
problem, which turned out to be diﬃcult to solve. DMS outperformed the NSGA-II method on the M-BNH1 problem in terms of ND–points
ing the spread metrics, DMS performed better in terms of Γ–spread, while and purity, while on the M-BNH2 one it is the opposite. Lastly, consider- NSGA-II outperformed DMS on the Δ–spread.
Considering the LAP1 problem (Fig. 2), FRONT-ALAMO performed very well and its scores are close to those of DMS, which was the over- all best algorithm on this problem. This fact can be also seen in the
front plots: the Pareto fronts obtained by the two algorithms are very similar, while the other two methods (NSGA-II and MOSQP) did not
have the same performance. Among these two latter algorithms, the
MOSQP method managed to outperform FRONT-ALAMO on one met-
ric, that is the purity, while the NSGA-II algorithm performed bet- ter on the Δ–spread. In the M-OSY problem (Fig. 2) NSGA-II was the
most effective obtaining an uniform and spread Pareto front. In this case, FRONT-ALAMO achieved some interesting results. First of all, it outper- formed the DMS algorithm: this achievement is remarkable since DMS is
gradient-free and can escape non optimal Pareto-stationary points, while our method is gradient-based. In addition, our algorithm obtained more
non-dominated points and a better Γ–spread than its gradient-based com-
petitor (MOSQP).
The last FRONT-ALAMO peculiarity that we can see from these plots is the number of non-dominated points it achieved. Only the DMS algo- rithm managed to obtain a much greater value of ND–points in some


Fig. 3. Performance profiles for the four algorithms on the LAP2 problems. Each sub-figure represents the performance profiles con- sidering as a performance measure one of the metrics explained in Section 5.1.1 (For interpretation of the references to color in text, the reader is referred to the web version of the article).










Fig. 4. Pareto front approximation for the four algorithms consider- ing LAP2 problems at different dimensionalities (For interpretation of the references to color in text, the reader is referred to the web version of the article).









problems. However, in these problems FRONT-ALAMO was equally competitive in terms of this metric and the purity one.

LAP2 problems

The LAP2 problems represent another useful class of problems: in- deed, they allow to discuss about the sensibility of the algorithms with
regard to 𝑛, that is, how well they scale. Indeed, many algorithms have
great performance considering small values of 𝑛. However, when a prob-
lem size grows, they lose their abilities to retrieve good Pareto front ap-
proximations. Before seeing some plots and metric values, we show the performance profiles considering all the LAP2 problems (Fig. 3).
The performance profiles highlight that FRONT-ALAMO strongly outperformed the other competitors with respect to ND–points, pu-
rity and Γ–spread. The second most robust algorithm is the DMS
one. As for the Δ–spread, the methods performed similarly: here, it
is very diﬃcult to indicate the best algorithm. This fact can be a
On the contrary, in terms of the Γ–spread there is a clear winner: proof that no algorithm suffered from a non-uniformity in their fronts.
FRONT-ALAMO.
The motivation of these different results on the two spread metrics can be explained through the Fig. 4, where we show the Pareto fronts in four different LAP2 problems. Here, we show the fronts all together in order to provide a more direct impression of the results. Indeed, in


Table 3
Metrics values obtained by the four algorithms in the LAP2 problems with 𝑛 = 2, 10, 50, 100. The values marked
in bold are the best values (each of which is related to a specific score) obtained in a specific problem.



Fig. 5. Performance profiles for the four algorithms on the CEC, ZDT and MOP problems. Each sub-figure represents the perfor- mance profiles considering as a performance measure one of the metrics explained in Section 5.1.1 (For interpretation of the refer- ences to color in text, the reader is referred to the web version of the article).









the LAP2 problems, FRONT-ALAMO results show the superiority of our
form Pareto front. The competitors obtained large Γ–spread values with method at exploring the objectives space and creating a spread and uni-
respect to those of FRONT-ALAMO, since they struggle to explore the
extreme regions of the front.
When 𝑛 = 2, all the methods managed to obtain the same Pareto front. However, increasing 𝑛, the differences between them become
more and more clear. For instance, NSGA-II performance got worse with 𝑛 ≥ 10. It seems to be unable to spread the search in the objectives
space and, also, to create a good, although small, Pareto front. The other gradient-free method (DMS) performed better but still it hardly reached the extremes of the objectives space. MOSQP seems not to have this last
negative feature but it generally retrieved very few points and, in ad-
dition, most of them are dominated. However, the MOSQP performance was good with 𝑛 ≤ 10.
The above comments on the algorithm behaviors on the LAP2 prob- lems are also supported by the numbers in Table 3. Observe that

FRONT-ALAMO, whose performance was quite good on problems with small dimension, outperformed the competitors as the value of 𝑛 in-
creased. The superiority of our method when the dimension of a prob- lem is high is very remarkable, especially considering ND–points (we obtained the best value, by far, for this metric in all the four problems),
purity and Γ–spread. As we just highlighted commenting the performance
profiles, all the algorithms performed well regarding the Δ–spread met-
ric.

CEC, ZDT and MOP problems

In this last section of computational experiments, we comment the results on the problems characterized only by boundary constraints. Some of these are very diﬃcult to solve and, in detail, the hardest ones are the CEC and ZDT problems. The CEC problems have non- continuously differentiable objective functions. The same feature is present in the ZDT problems, where the objective functions are also



composite. For the sake of brevity, we preferred to show the perfor- mance profiles related to all these problems. The performance profiles are shown in Fig. 5.
Regarding the ND–points metric, FRONT-ALAMO managed to out-
perform the competitors once again. Indeed, we can conclude that this is one of the most important peculiarities of our method: its capabilities
Appendix A. Modified form of the OSY problem

In this Appendix, we introduce the modified version of the OSY prob- lem (Osyczka and Kundu, 1995) used in the computational experiments. The modification is carried out in order to make the feasible set and the objective functions convex.

allow it to expand the search towards a great portion of the objectives
space and to retrieve many Pareto points. Considering this metric, the other two best competitors were NSGA-II and DMS: because of their
min
𝑥∈ℝ6
𝑓1 (𝑥) = 25(𝑥1 − 2)2 + (𝑥2 − 2)2 + (𝑥3 − 1)2 + (𝑥4 − 4)2 + (𝑥5 − 1)2
𝑓2 (𝑥) = ∑6	2

gradient-free nature, allowing them to potentially escape from non opti- mal Pareto-stationary points, they managed to obtain good results in the
most complex functions. On the contrary, the performance difference be- tween FRONT-ALAMO and the other gradient-based method (MOSQP) is very sharp.
The performance profiles on the purity metric highlight the effec- tiveness of our method: it was not obvious, a priori, to obtain such great results with such complex functions, especially when some of our com- petitors are derivative-free.
with respect to the other competitors. In particular, in the Γ–spread Lastly, considering the spread metrics, our results are competitive
performance profiles FRONT-ALAMO was the third best algorithm, while the gradient-free methods (NSGA-II and DMS) managed to have
slightly better performance. Regarding the Δ–spread, NSGA-II turned
out to be the most robust algorithm. However, the performance profiles
on this metric are another proof of the effectiveness of the four algo- rithms to retrieve an uniform Pareto front.

Conclusions

In this paper, we considered smooth multi-objective optimization problems subject to convex constraints. We focused on the task of gener- ating good Pareto front approximations for this class of problems. After a brief review of the existing literature, we proposed an Augmented La- grangian Method specifically designed for this task.
The method represents an extension of the ALAMO procedure from
Cocchi and Lapucci (2020), which is designed to produce a single Pareto- stationary solution. The proposed algorithm handles, at each iteration, a list of points that are mutually non-dominated and Pareto-stationary with respect to the current multi-objective augmented Lagrangian. Line searches along steepest common and partial descent directions are em- ployed to carry out an exploration of the objectives space. The penalty parameter and the Lagrange multipliers are updated taking into account constraints violations committed by all the points in the current list.
For this algorithm, we proved global convergence to Pareto- stationarity of the sequences of points in the iterates lists. This type of convergence is more general than that based on linked sequences.
With respect to the only other derivative-based method for this kind of problems, the SQP from (Fliege and Vaz, 2016), we obtain similar asymptotic properties for the limit points, but our method does not stop
the exploration phase after a finite number of iterations.
Moreover, thorough computational experiments show that our method outperforms the SQP algorithm in terms of popular metrics for multi-objective optimization. We also compared the proposed procedure with the state-of-the-art derivative-free (DMS) and genetic (NSGA-II) approaches. Our procedure proved to obtain better results even w.r.t.
the two mentioned ones.

Declaration of Competing Interest

The authors declare that they have no conflict of interest.

Acknowledgment

The authors would like to thank professor Marco Sciandrone for the precious discussions.
s.t.	𝑥1 + 𝑥2 − 2 ≥ 0, 6 − 𝑥1 − 𝑥2 ≥ 0,
2 − 𝑥2 + 𝑥1 ≥ 0,
2 − 𝑥1 + 3𝑥2 ≥ 0,
4 − (𝑥3 − 3)2 − 𝑥4 ≥ 0,
−(𝑥5 − 3)2 + 𝑥6 − 4 ≥ 0,
0 ≤ 𝑥1 , 𝑥2 , 𝑥6 ≤ 10,
1 ≤ 𝑥3, 𝑥5 ≤ 5,
0 ≤ 𝑥4 ≤ 6.
References

Birgin, E.G., Martinez, J.M., 2014. Practical Augmented Lagrangian Methods for Con- strained Optimization, 10. SIAM.
Campana, E.F., Diez, M., Liuzzi, G., Lucidi, S., Pellegrini, R., Piccialli, V., Rinaldi, F., Serani, A., 2018. A multi-objective DIRECT algorithm for ship hull optimization. Com- put. Optim. Appl. 71 (1), 53–72.
Carrizosa, E., Frenk, J.B.G., 1998. Dominating sets for convex functions with some appli- cations. J. Optim. Theory Appl. 96 (2), 281–295.
Cocchi, G., Lapucci, M., 2020. An augmented Lagrangian algorithm for multi-objective optimization. Comput. Optim. Appl. 77 (1), 29–56.
Cocchi, G., Liuzzi, G., Lucidi, S., Sciandrone, M., 2020. On the convergence of steepest descent methods for multiobjective optimization. Comput. Optim. Appl. 1–27.
Custódio, A.L., Madeira, J.F.A., Vaz, A.I.F., Vicente, L.N., 2011. Direct multisearch for multiobjective optimization. SIAM J. Optim. 21 (3), 1109–1140.
Deb, K., Pratap, A., Agarwal, S., Meyarivan, T., 2002. A fast and elitist multiobjective genetic algorithm: NSGA-II. IEEE Trans. Evol. Comput. 6 (2), 182–197.
Dolan, E.D., Moré, J.J., 2002. Benchmarking optimization software with performance pro- files. Math. Program. 91 (2), 201–213.
Drummond, L.M.G., Iusem, A.N., 2004. A projected gradient method for vector optimiza- tion problems. Comput. Optim. Appl. 28 (1), 5–29.
Drummond, L.M.G., Maculan, N., Svaiter, B.F., 2008. On the choice of parameters for the weighting method in vector optimization. Math. Program. 111 (1-2), 201–216.
Eichfelder, G., 2009. An adaptive scalarization method in multiobjective optimization.
SIAM J. Optim. 19 (4), 1694–1718.
Fliege, J., 2001. OLAF—A general modeling system to evaluate and optimize the location of an air polluting facility. OR-Spektrum 23 (1), 117–136.
Fliege, J., 2004. Gap-free computation of Pareto-points by quadratic scalarizations. Math.
Methods Oper. Res. 59 (1), 69–89.
Fliege, J., Drummond, L.M.G., Svaiter, B.F., 2009. Newton’s method for multiobjective optimization. SIAM J. Optim. 20 (2), 602–626.
Fliege, J., Svaiter, B.F., 2000. Steepest descent methods for multicriteria optimization.
Math. Methods Oper. Res. 51 (3), 479–494.
Fliege, J., Vaz, A.I.F., 2016. A method for constrained multiobjective optimization based on SQP techniques. SIAM J. Optim. 26 (4), 2091–2119.
Fu, Y., Diwekar, U.M., 2004. An eﬃcient sampling approach to multiobjective optimiza- tion. Ann. Oper. Res. 132 (1-4), 109–134.
Gass, S., Saaty, T., 1955. The computational algorithm for the parametric objective func- tion. Naval Res. Logist. Q. 2 (1-2), 39–45.
Geoffrion, A.M., 1968. Proper eﬃciency and the theory of vector maximization. J. Math.
Anal. Appl. 22 (3), 618–630.
Gravel, M., Martel, J.M., Nadeau, R., Price, W., Tremblay, R., 1992. A multicriterion view of optimal resource allocation in job-shop production. Eur. J. Oper. Res. 61 (1-2), 230–244.
Huband, S., Hingston, P., Barone, L., While, L., 2006. A review of multiobjective test problems and a scalable test problem toolkit. IEEE Trans. Evol. Comput. 10 (5), 477–
506. doi:10.1109/TEVC.2005.861417.
Jüschke, A., Jahn, J., Kirsch, A., 1997. A bicriterial optimization problem of antenna de- sign. Comput. Optim. Appl. 7 (3), 261–276.
Kanzow, C., Steck, D., 2017. An example comparing the standard and safeguarded aug- mented Lagrangian methods. Oper. Res. Lett. 45 (6), 598–603.
Kasperska, R., Ostwald, M., Rodak, M., 2004. Bi-criteria optimization of open cross sec- tion of the thin-walled beams with flat flanges. In: PAMM: Proceedings in Applied Mathematics and Mechanics, 4. Wiley Online Library, pp. 614–615.
Konak, A., Coit, D.W., Smith, A.E., 2006. Multi-objective optimization using genetic algo- rithms: a tutorial. Reliab. Eng. Syst. Saf. 91 (9), 992–1007.
Laumanns, M., Thiele, L., Deb, K., Zitzler, E., 2002. Combining convergence and diversity in evolutionary multiobjective optimization. Evol. Comput. 10 (3), 263–282.
Leschine, T.M., Wallenius, H., Verdini, W.A., 1992. Interactive multiobjective analysis and assimilative capacity-based ocean disposal decisions. Eur. J. Oper. Res. 56 (2), 278–289.



Liuzzi, G., Lucidi, S., Parasiliti, F., Villani, M., 2003. Multiobjective optimization tech- niques for the design of induction motors. IEEE Trans. Magn. 39 (3), 1261– 1264.
Liuzzi, G., Lucidi, S., Rinaldi, F., 2016. A derivative-free approach to constrained multi- objective nonsmooth optimization. SIAM J. Optim. 26 (4), 2744–2774.
Mostaghim, S., Branke, J., Schmeck, H., 2007. Multi-objective particle swarm optimization on computer grids. In: Proceedings of the 9th Annual Conference on Genetic and Evolutionary Computation. ACM, pp. 869–875.
Osyczka, A., Kundu, S., 1995. A new method to solve generalized multicriteria opti- mization problems using the simple genetic algorithm. Struct. Optim. 10 (2), 94–99. doi:10.1007/BF01743536.
Palermo, G., Silvano, C., Valsecchi, S., Zaccaria, V., 2003. A system-level methodology for fast multi-objective design space exploration. In: Proceedings of the 13th ACM Great Lakes Symposium on VLSI. ACM, pp. 92–95.
Pascoletti, A., Serafini, P., 1984. Scalarizing vector optimization problems. J. Optim. The- ory Appl. 42 (4), 499–524.
Pellegrini, R., Campana, E.F., Diez, M., Serani, A., Rinaldi, F., Fasano, G., Iemma, U., Li- uzzi, G., Lucidi, S., Stern, F., et al., 2014. Application of derivative-free multi-objective algorithms to reliability-based robust design optimization of a high-speed catamaran in real ocean environment1. In: Engineering Optimization IV-Rodrigues et al.(Eds.),
p. 15.
Shan, S., Wang, G.G., 2005. An eﬃcient Pareto set identification approach for multiobjec- tive optimization on black-box functions. J. Mech. Des. 127 (5), 866–874.
Steuer, R.E., Choo, E.-U., 1983. An interactive weighted Tchebycheff procedure for mul- tiple objective programming. Math. Program. 26 (3), 326–344.
Sun, Y., Ng, D.W.K., Zhu, J., Schober, R., 2016. Multi-objective optimization for robust power eﬃcient and secure full-duplex wireless communication systems. IEEE Trans. Wirel. Commun. 15 (8), 5511–5526.
Tavana, M., 2004. A subjective assessment of alternative mission architectures for the human exploration of Mars at NASA using multicriteria decision making. Comput. Oper. Res. 31 (7), 1147–1164.
Wächter, A., Biegler, L.T., 2006. On the implementation of an interior-point filter line-search algorithm for large-scale nonlinear programming. Math. Program. 106 (1), 25–57.
White, D.J., 1998. Epsilon-dominating solutions in mean-variance portfolio analysis. Eur.
J. Oper. Res. 105 (3), 457–466.
Zadeh, L., 1963. Optimality and non-scalar-valued performance criteria. IEEE Trans. Au- tom. Control 8 (1), 59–60.
Zhang, Q., Zhou, A., Zhao, S., Suganthan, P.N., Liu, W., Tiwari, S., 2008. Multiobjective optimization test instances for the CEC 2009 special session and competition. Univer- sity of Essex, Colchester, UK and Nanyang technological University, Singapore, special session on performance assessment of multi-objective optimization algorithms, tech- nical report 264, 1–30.
Zitzler, E., Deb, K., Thiele, L., 2000. Comparison of multiobjective evo- lutionary algorithms: empirical results. Evol. Comput. 8 (2), 173–195. doi:10.1162/106365600568202.
