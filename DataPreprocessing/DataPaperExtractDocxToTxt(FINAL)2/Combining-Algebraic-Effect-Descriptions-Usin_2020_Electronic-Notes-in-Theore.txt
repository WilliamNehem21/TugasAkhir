Available online at www.sciencedirect.com


Electronic Notes in Theoretical Computer Science 352 (2020) 257–281
www.elsevier.com/locate/entcs

Combining Algebraic Effect Descriptions Using the Tensor of Complete Lattices
Niels Voorneveld1,2
Department of Software Science Tallinn University of Technology Tallinn, Estonia

Abstract
Algebras can be used to interpret the behaviour of effectful programs. In particular, we use Eilenberg-Moore algebras given over a complete lattices of truth values, which specify answers to queries about programs. The algebras can be used to formulate a quantitative logic of behavioural properties, specifying a congruent notion of program equivalence coinciding with a notion of applicative bisimilarity. Many combinations of effects can be interpreted using these algebras. In this paper, we specify a method of generically combining effects and the algebras used to interpret them. At the core of this method is the tensor of complete lattices, which combines the carrier sets of the algebras. We show that this tensor preserves complete distributivity of complete lattices. Moreover, the universal properties of this tensor can then be used to properly combine the Eilenberg-Moore algebras. We will apply this method to combine the effects of probability, global store, cost, nondeterminism, and error effects. We will then compare this method of combining effects with the more traditional method of combining equational theories using interaction laws.
Keywords: Algebraic effects, Eilenberg-Moore algebra, Tree monad, Complete lattice, Tensor product, Program equivalence, Quantitative logic, Applicative bisimilarity, Probability, Nondeterminism, Global store.


Introduction
Effects can alter the behaviour of functional programs in many ways. In order to interpret the behaviour of effectful programs, we choose a set of answers called a quantitative truth space, and a set of questions (theoretical tests on programs) given by algebras. In [29], such truth spaces and algebras are used to formulate a logic of quantitative behavioural properties, which induces a notion of program equivalence. This is a generalisation of earlier work based on modalities (Boolean algebras) [27].
We study algebraic effects in the sense of [24]. Such algebraic effects are given by a signature of effect operations. For each effect we choose a truth space A of answers

1 This research was supported by the ESF funded Estonian IT Academy research measure (project 2014- 2020.4.05.19-0001).
2 Email: niels.voorneveld@taltech.ee

https://doi.org/10.1016/j.entcs.2020.09.013
1571-0661/© 2020 The Author(s). Published by Elsevier B.V.
This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).

given by a complete lattice, and one or more algebras. Such algebras can be specified by local functions over the effect operations (forming an observation algebra). If such functions preserve non-empty suprema, they induce an ω-continuous Eilenberg- Moore algebra. Many examples of algebraic effects can be expressed using such algebras, including probability, global store, nondeterminism, error, and cost.
An ω-continuous Eilenberg-Moore algebra specifies a notion of program equiv- alence on functional languages with effects and general recursion. This program equivalence can be formulated as applicative bisimilarity [1,5,6], and as logical equiv- alence via a quantitative logic [29,30]. Moreover, the algebra induces a compositional equational theory, which for the various examples coincide with the usual equational theories for algebraic effects formulated in the literature (see e.g. [23,25,26] for such equational theories).
The main contribution of this paper is the development of a generic method for combining effects described by algebras constructed using local functions over effect operations. This method uses the tensor product on complete lattices, featured e.g. in [9,16,28,32]. This operation is a symmetric monoidal product which naturally combines the different notions of truth for the different effects. We show that the tensor product preserves complete distributivity of complete lattices. Complete distributivity is useful for characterising the structure of the tensor of complete lattices.
We combine algebras by combining their local functions, following an elegant definition in terms of the universal property of the tensor product. Given that the complete lattices we use are completely distributive, this combination of local functions preserves the supremum preservation property mentioned before. As such, the induced algebras are suitable for specifying notions of program equivalence.
We compare this method of combining effects with the more traditional way of combining equational theories, which is done by specifying interaction laws such a commutativity [14,15]. We see that our method of combining effects does not uniformly coincide with either the sum or the tensor of equational theories. Instead, it “chooses” interaction laws appropriate to each combination of effects.
In Section 2, we start with some preliminaries on algebraic effects and complete lattices. In Section 3, we formulate how to interpret effects using effect descriptions, which allow us to construct algebras. In Section 4 we develop a general theory for combining quantitative truth spaces, given by completely distributive lattices, using the tensor product. Then in Section 5, we use universal properties of the tensor product to combine functions on complete lattices. In Section 6, we formulate how to combine effect descriptions and their algebras, and apply this method to study several combinations of effects. Lastly, in Section 7, we compare this method with methods for combining equational theories.

Preliminaries
We represent effects using algebraic effect operations following [24]. Each operation
op has an arity ar(op) ∈ N, which tells how many arguments the operation has. For

example, we can consider the operation of nondeterministic choice nor, which has arity 2 and chooses nondeterministically between two possible continuations given by its two arguments.
For each effect, or combination of effects, we specify an effect signature Σ given by a set of effect operations.


Definition 2.1 A Σ-effect tree (henceforth tree) overa set X is a possibly infinite tree whose nodes are:
leaf nodes labelled ⟨x⟩ for x ∈ X,
leaf nodes labelled ⊥, describing divergence,
and internal nodes op for op ∈ Σ, which has ar(op) many children.

We write op⟨t1,..., tar(op)⟩ for the tree whose root has node op, and whose children are given by t1,..., tar(op). If a tree only has finitely many nodes, we call it ﬁnite. We write Tν(X) for the set of trees over X, and Tμ(X) for the subset of Tν(X)
Σ	Σ	Σ
containing the finite trees over X.
Given an order on X, we can inductively define an order on Tμ(X) according
to the following rules:
For any x, y ∈ X, x ≤X y ⇒ ⟨x⟩ ≤T μ(X) ⟨y⟩.
For any t ∈ Tμ(X), ⊥≤ μ	t.
Σ	TΣ (X)
For any op ∈ Σ, and l1,..., lar(op), r1,..., rar(op) ∈ Tμ(X),
(∀1 ≤ i ≤ ar(op). li ≤T μ(X) ri) ⇒ op⟨l1,..., lar(op)⟩ ≤T μ(X) op⟨r1,..., rar(op)⟩.
Σ	Σ
The above definition can be adapted to give a coinductive formulation of an order on Tν(X). If X is an ω-cpo (meaning it contains limits of increasing sequences), then Tν(X) is an ω-cpo as well. Moreover, each tree is the limit of a sequence of finite trees.
The operations Tμ(−) and Tν(−) give endofunctors in the category of posets.
Σ	Σ
Taking some order preserving map f : X → Y , we can lift it to an order preserving
map on trees Tμ(f ): Tμ(X) → Tμ(Y ), where Tμ(f )(t) is the result of replacing in
Σ	Σ	Σ	Σ
t each leaf ⟨x⟩ with ⟨f (x)⟩, leaving the rest of the tree unchanged. We define the
function Tν(f ): Tν(X) → Tν(Y ) in the same way.
Σ	Σ	Σ
There is an alternative formulation of these functors. First, we have the partial-
ity functor (−)⊥ on posets which adds a minimal element ⊥ to its argument. Given an effect signature Σ, we define the signature functor FΣ as FΣ(X)=  op∈Σ Xar(op). Then we define the functors using smallest and largest fixpoint constructions:
Tμ(X)= μY.(X + FΣY )⊥,	Tν(X)= νY.(X + FΣY )⊥ .
Σ	Σ
Both Tμ(−) and Tν(−) form monads in the category of posets, where the unit η is
Σ	Σ
given by ηX (x)= ⟨x⟩, and the monad multiplication μ is given by locally replacing
each leaf η(t) by the subtree t (we “flatten” the input).

Motivation
In this subsection we discuss how algebras as defined in this paper can be used. A computation is program that needs to be evaluated, or reduced, in order to produce a result. In general, we consider a computation to either return a value or diverge, potentially encountering effects along the way. As such, we interpret the operational semantics of a programming language as giving a function: |−| : Computations → Tν(Values). In the absence of recursion, this function could be
Σ	μ
given by |−| : Computations → TΣ (Values).
When we test a property of a program, we often start with a property on the values this program can return. For instance, a property of natural numbers can be “Evenness”. A property on values is in general given by a quantitative predicate P : Values → A. This uses a truth space A, like the Booleans, or the real number interval [0, 1] of probabilities. To translate this predicate on values to a predicate on programs which return such values, we want to lift the predicate P to a quantitative predicate Pj : Computations → A. For this purpose, we specify an algebra α : Tν(A) → A in order to perform the following composition: (α ◦ Tν(P ) ◦|− |) : 
Σ	Σ
Computations → A.
This composition implements the following intuition. We have a program which, after invoking some effects, produces a value according to the operational semantics
|− |. We have determined a degree of truth for each potential value the program may return, using a quantitative predicate P . Lastly, we use an algebra α, which interprets how effects encountered during the execution of the program combines the degrees of truths of all possible return values, and the effectful ways we could get to those values, into a singular degree of truth.
Take for instance a program which tosses a coin, and on heads will return an 3, and on tails a 6. We want to determine to what degree this program produces an even number. So we take a predicate P which associates to 3 a 0 probability of being even, and to6a1 probability of being even. Then our algebra combines these two results, with the knowledge that the coin is fair. This allows it to determine that the program is expected to produce an even number half of the time.
In the above example, we use as truth space A = [0, 1], the real number interval representing probabilities that certain properties (like “evenness”) are held. How- ever, depending on the effect in question, we may need other notions of truth. For instance, for computations using a global store, truth is conditional on the state of this global store upon initiation of evaluation. In that case, we can use the powerset of states as truth space. In the next subsection we study which properties A, the truth space for our quantitative predicates, needs to satisfy to be useful, keeping it general enough to accommodate a plethora of examples.

Complete lattices
To interpret effectful behaviour, we use a poset of truth values, potential answers to questions asked of (or tests performed on) programs. Intuitively, if a < b, then b represents a truth which holds in “more” evaluations of a program than the truth

of a. The notion of “more” depends on the effect in question. It may mean: more likely, or for more initial states.
In order for this space of truth values to be suitable for specifying a congruent notion of program equivalence, it needs to be a complete lattice. This has two theoretical reasons:
In order to construct enough quantitative predicates for distinguishing between behaviourally different programs, we need to close our collection of predicates under arbitrary suprema and infima.
To formulate applicative bisimilarity, a relation lifting device called a relator is defined using our algebras. To facilitate this process, suprema are used to prove that such relators preserve composition of relations.
We will not go further into these two points in this paper. See [29,30] for more details.
Given a poset A and a subset X ⊆ A, we write	X for the supremum of X: the unique smallest element of A greater than or equal to any element in X. Let X be the infimum of X: the unique largest element of A less than or equal to any element in X. These elements may not exist. We distinguish between two notions
of completeness.
Definition 2.2 A poset A is a complete lattice if for any X ⊆ A,	X exists.
A poset A is an inhabitant complete lattice (or icomplete lattice) 3 if for any non- empty X ⊆ A,	X exists.
If A is a complete lattice, the infimum	X always exists, and is equal to	{x ∈
A | ∀y ∈ X, x ≤ y}.
Note that a complete lattice is also icomplete. The difference between the two notions of completeness is wh ether o r not the element  ∅, the smallest element of
denote FA for the smallest element of A, and TA for the biggest element of A.
We expand the intuition of the complete lattice as a truth space. The complete lattices contains degrees of truth, which are possible answers to tests on programs. For instance, we make ask ourselves whether: “this program returns an even num- ber”. The element TA denotes the fact that the property is always observed, regard- less of effects that may occur in the evaluation of the program. This happens for instance if the program terminates with a desirable result, without any interference of effects. The element FA denotes the fact the property is never observed. This can for instance happen if the program diverges, or produces an undesirable result, without any interference of effects. Even when effects occur, TA and FA may be attained. For instance, a randomized algorithm may produce different results but still have a 100% probability of producing an even number.
Examples of complete lattices, used as truth spaces for effects, include:
The Booleans B containing only true and false.

3 This terminology does not appear in the literature. It is used here to distinguish it from (total) com- pleteness. The same holds for the term ‘ilinear’ later in the paper.

The real number interval [0, 1] describing probabilities that a statement is true.
The powerset P(S) of states S describing initial states of a global store.
The natural numbers N∞ with limit element ∞, describing costs.
There is a functor !(−) from the category of icomplete lattices Icom to the category of complete lattices Com, which adds a smallest element to its input. This functor is left adjoint to the forgetful functor U : Com → Icom (which forgets that its input has a smallest element). Note that both U◦ ! and ! ◦U give an endofunctor akin to the partiality functor (−)⊥ on categories Icom and Com respectively.
Importantly, Tμ(−) and Tν(−) are not functors in these categories, since Tμ(X)
Σ	Σ	Σ
and Tν(X) do not tend to have top elements. For instance, two different effect
operators do not have a common upper bound. This is why we will remain firmly inside the category of posets when discussing algebras.
We write Πi∈IAi for the I-indexed product of sets Ai. An element of this space is given in lambda notation, λi.ai, which represents an I-indexed family where for each i ∈ I, ai ∈ Ai.
Definition 2.3 A function f : Πi∈IAi → B from a product of icomplete lattices to an icomplete lattice is ilinear if for any family of nonempty subsets {Si ⊆ Ai}i∈I , f (λi.  Si)= {f (λi.xi) | ∀i.xi ∈ Si}.
A function f : Πi∈IAi → B from a product of complete lattices to a complete lattice is linear if for any family of subsets {Si ⊆ Ai}i∈I , f (λi.  Si)=  {f (λi.xi) |
∀i ∈ I. xi ∈ Si}.
If a function is linear, then it is ilinear. Conversely, an ilinear function f : Πi∈IAi → B on complete lattices is linear if and only if for any family of elements {xi ∈ Ai}i∈I such that ∃i ∈ I.xi = FAi , then f (λi.xi)= FB.
The reason why we distinguish between linearity and ilinearity is because of a disconnect between the demands on the truth space A, and the demands on how to answer questions using an algebra. Linearity is the inherent property of morphisms in Com which contains our truth spaces, whereas the local functions which will make up our algebras are ilinear, but not linear in general (see the forthcoming examples in Subsection 3.2).
A complete lattice is completely distributive if the infima distributes over the suprema operation. See for instance [7] for an overview of properties of complete lattices. There is an equivalent definition to complete distributivity using linearity:

Definition 2.4 A complete lattice A is completely distributive if for any set I, the infima operation  I Πi∈IA → A, sending λi.xi to  i∈I xi, is linear.
Observe that it is sufficient to require the infima operations I to be ilinear, since they automatically satisfy the extra property of bottom preservation discussed below Definition 2.3. Assuming that our truth spaces are completely distributive will be necessary later on for establishing some properties. Note however, that it is always possible to freely generate a completely distributive lattice from any complete

lattice. So in theory, this restriction to complete distributivity is not restrictive in terms of applications to describing effects.

Effect Descriptions
For each effect, or combination of effects, we choose a completely distributive lattice A of truth values, or space of observables. To interpret the behaviour of effects, we specify an algebra α : Tμ(A) → A in the category of posets. This algebra is constructed using the following recipe.
For each op ∈ Σ, we specify a function αop : Aar(op) → A. We call such functions the local functions of α. We combine all these local functions to create a function αΣ : (A + FΣ(A))⊥ → A with the following definition:
αΣ(⊥) := FA =	∅,	αΣ(inleft(a)) = a, αΣ(inright(op(a1,..., aar(op))) = αop(a1,..., aar(op)).
This function inductively induces an algebra α : Tμ(A) → A on Tμ(−)= μY.((−)+ 
Σ	Σ
FΣ(Y ))⊥.
If an algebra is constructed using the above recipe, we call it a locally constructed
algebra.
Definition 3.1 Given a monad (M, η, μ), an algebra a : MA → A is an Eilenberg- Moore algebra (henceforth EM-algebra) if the following two diagrams commute:

A   ηA /M¸A 
MMA  Ma /M¸A  

a	μA	a
z	 
A	MA	a	/A¸
By a simple induction on Tμ(A), we get the following result.
Lemma 3.2 Any locally constructed algebra α forms an Eilenberg-Moore algebra.
As discussed before, we can use the algebra to interpret the behaviour of effectful computations, by lifting predicates on values to predicates on computations. Given an algebra a : MA → A, we can lift a quantitative predicate P : X → A to a quantitative predicate a(P ) := (a ◦ M (P )) : MX → A.
Definition 3.3 An algebra a : MA → A on an icomplete lattice A is leaf-ilinear if for any set X, element t ∈ Tμ(X) and function f : X → P/=$(A) associating to each x ∈ X a non-empty subset of A,
a(  ◦f )(t)	=	  {a(P )(t) | P : X → A, ∀x ∈ X.P (x) ∈ f (x)} .

The concept of leaf-ilinearity implements the notion of ilinearity of algebras α :
Tμ(A) → A to the extend that it is possible, given that Tμ(A) is not necessarily an
Σ	μ	Σ
icomplete lattice. The leaves of TΣ (A) are taken from the icomplete lattice A, and
as such are closed under non-empty suprema. Leaf-ilinearity asserts that the algebra

preserves such suprema within the leaves. One consequence of this property is that, as a predicate lifting device, a leaf-ilinear algebra preserves non-empty suprema.
By induction on the structure of Tμ(A), we have the following result.
Lemma 3.4 If the algebra α is locally constructed by ilinear local functions, then
α is leaf-ilinear.
Inﬁnitary trees
We use leaf-ilinearity to extend the algebra α : Tμ(A) → A to an algebra α :
ν	Σ	^
TΣ(A) → A capable of interpreting infinite trees. Firstly, note that any ilinear
function is monotone. As such, we can establish the following result by induction:
Lemma 3.5 Suppose a is a leaf-ilinear EM-algebra such that α(⊥)= FA.
For any two trees t, tj ∈ Tμ(A) such that t ≤ μ	tj, α(t) ≤ α(tj).
Σ	TΣ (A)
Consider a tree t ∈ Tν(A), then there is an ascending sequence of trees t0 ≤
μ	Σ
sequence t0, t1,... approximates t. We define α(t) as	n α(tn). This is well-defined, since for any two sequences t0, t1,... and tj , tj ,... approximating t, there is an
0  1

m for any n such that tn ≤ tj and hence by Lemma 3.5, α(tn) ≤ α(tj
). Hence

n α(tn) ≤  n α(tj ) and vice versa,  n α(tn) ≥  n α(tj ).
Last but not least, we have the following result, for which we give a brief sketch
of a proof.
Lemma 3.6 Suppose α is a locally constructed leaf-ilinear algebra.	Then α :
Tν(A) → A is an EM-algebra.
Proof. Any ilinear function f : An → A is ω-continuous: Given a series of ascend- ing sequences {a1}i∈N, {a2}i∈N,..., {an}i∈N in A, then, by ilinearity and monotonic-
i	i	i
ity: f (  a1,...,  an) =  {f (ai ,..., ai ) | i1,..., in ∈ N} =   f (a1,..., an).
Using this, we can by induction establish that, for any ascending sequence of trees
t0 ≤T μ(A) t1 ≤T μ(A) ... , α^( i∈N ti)=	i∈N α^(ti).

Σ	Σ	Σ	Σ
proximating d. Then {Tν(α)(d )}	is an increasing sequence of elements of Tν(A).

Σ ^	i

	
i∈N	Σ
μ	μ
 	 				

i α(μdi)= α^( i μdi)= α^(μ( i di)) = α^(μd).
We may sometimes simply write α instead of α, as the latter is an extension of the former.
Another way trees could be infinite, is by having effect operations with infinite width. It is not difficult to extend the above theory to include effectful operations with countable arities. To deal with this, we specify an ilinear local function f : Aω → A. To inductively define an algebra, we use fj : Aω → A constructed as:


fj(λn.an
)= 
m∈N
f	λn.	an	if n < m	.	(1)
F	if n ≥ m

If f is ilinear, then fj is ω-continuous, hence the induced algebras on Tμ(A) and
Tν(A) are both ω-continuous EM-algebras.
Lemma 3.7 If f : Aω → A is ilinear, then fj : Aω → A as deﬁned in (1) is
ω-continuous.
Proof. For m ∈ N, let fm : Am → A be the ilinear function fm(a0, a1,..., am—1) :=

f (a0, a1,..., am—1, FA, FA,... ).  Since fj
has finite arity and is ilinear, it is ω-

continuous (see proof of Lemma 3.6). So, the function fj : Aω → A defined by
fj (λn.an) = fm(a0, a1,..., am—1) is ω-continuous too. We conclude that fj =
m  j is ω-continuous.	2
Moreover, if f already is ω-continuous, then fj = f . The notion of ﬁniteness can be adapted to infinite-width trees by saying that a tree is finite if there are only finitely many non-⊥ leaves. Using fj in our inductive definition of an algebra effectively formalises the idea that any result of the algebra can be approximated by finite trees.
In the rest of this paper, we will concern ourselves mostly with ilinear local functions over effect operations with finite arity. We specify the following structure for interpreting effects.
Definition 3.8 An effect description (Σ, A, α) consists of an effect signature Σ, a completely distributive lattice A, and an interpretation α given by an ilinear function αop : Aar(op) → A for each op ∈ Σ.
Examples
We look at some examples of effects and their effect descriptions.
Example 3.9 [Probability] We consider the effect signature Σprob = {por} with a single effect operation por for binary probabilistic choice. The operation has arity 2, and chooses fairly between two continuations. We give this the effect description (Σprob, [0, 1], Exp), with as complete lattice of truth values the real number interval [0, 1]. We give probabilistic computations the expectation interpretation Exp, given by the local function Exppor : [0, 1]2 → [0, 1] which calculates the average between its two arguments Exppor(a, b)= (a + b)/2. The constructed algebra Exp : Tν([0, 1]) → [0, 1] will calculate the expected value of a leaf a ∈ [0, 1], assuming each choice in a tree t ∈ Tν([0, 1]) is resolved fairly.
Example 3.10 [Global Store] We consider a set of global store locations
Loc for storing Boolean values.  We consider the effect signature Σglobal :=
{lookupl, updatel(T), updatel(F) | l ∈ Loc} which for each global store location l has a lookup operation lookupl of arity 2 and two update operations updatel(T), updatel(F) of arity 1. The update operations save a Boolean value to a global store, whereas the lookup operations look up a Boolean value from a global store location, and uses it to choose one of its two continuations: The left continuation if the value is T and the right continuation if the value is F. We write S := BLoc for the set of global states, and we call elements of P(S)  (S → B) assertions on the global state.

We give this effect the description (Σglobal, P(S), Wp) with the weakest precondition
interpretation Wp, where:
Wplookupl (a, b) := {s ∈ a | s(l)= T}∪ {s ∈ b | s(l)= F}.
Wpupdatel(v)(a) := {s[l := v] | s ∈ a},   where s[l := v](l) = v and s[l :=
v](lj)= s(lj) for any lj /= l.
Wp : Tν(P(S)) → P(S) will calculate the set of correct starting states for which, when the computation is evaluated with that state, it terminates in some leaf ⟨R⟩ with a final state satisfying assertion R ∈ P(S).
Alternatively, we could also have a global store used for storing natural numbers. In such a case, the lookup operation will have a countably infinite arity, and the set of states is given by S = NLoc. This works out the same way as Boolean store. In the rest of the paper we will, for the sake of clarity, only look at Boolean store.
Example 3.11 [Cost] We consider the effect signature Σcost := {costq | q ∈ Q>0}, where for each positive rational number q we have an effect operation costq with arity 1, which requires a cost q to be spend before continuing evaluation. For example, a sleep operation which delays computation for some time, or a save operation which requires a certain amount of memory to be reserved. We see the nonnegative reals [0, ∞] with reverse order as the space of total costs (which contain all limits of rational costs). We give the effect the description (Σcost, [0, ∞], Tal) with the tally interpretation Tal summing all costs together, where
Talcostq (a)= a + q.
Example 3.12 [Nondeterminism] We consider the effect signature Σnon = {nor} with one effect operation nor with arity 2 for binary nondeterministic choice. We give this the effect description (Σnon, A, Pos), with as truth space the three element chain A := {F, , T} containing the three degrees of possibility (this is e.g. used in [13] for describing nondeterminism). The smallest element F represents impossibility, the middle element represents possibility, and the largest element T represents inevitability. We give the effect the interpretation Pos which issues the degree of possibility and follows the algebraic structure established in [4,3]:
Posnor(a, a)= a,   Posnor(a, b)=   if a /= b.
The constructed algebra Pos : Tν(A) → A will produce T if any resolution of choice leads to a leaf labelled T. It will produce  if it is possible to get to a leaf labelled T or  , but not all resolutions yield T.
Example 3.13 [Error] We consider the effect signature Σerror := {raise} with a single effect operation raise of arity 0, which aborts evaluation displaying an error message. We use the effect description (Σerror, A, Err) where A is as given in the previous example. We give this the interpretation Err where Errraisee () = . This effect may be combined with itself using the forthcoming method for combining ef- fects, in order to get an interpretation of multiple errors. For simplicity, we consider only one error at this time.
Example 3.14 [Pure computation] Last but not least, we consider the situation in which there is no effectful behaviour at all (except for divergence). This has the

effect description (∅, B, ↓) with an empty signature, the Booleans as truth space, and the termination interpretation, which has no local functions since the signature is empty. The constructed algebra is ↓: Tν(B) → B, where Tν(B)= (B)⊥, sends ⊥
Σ	Σ
to F and v ∈ B to v.
We end this section with a short motivational discussion on how these algebras can give rise to notions of program equivalence.
As noted before, an algebra α : Tν(A) → A can be used to lift a predicate on values to a predicate on computations. This can be used to generate a logic of quantitative formulas, as done in [29]: For each type in the language, we have a collection of formulas. A program of a type functions as a model for such formulas, satisfying each formula to a certain degree a ∈ A. We say that two programs of the same type are behaviourally equivalent if they satisfy each formula to the same degree.
It is also possible to define a notion of applicative bisimilarity, in the sense of [1,6]. We define a relator using our algebra, which lifts a relation on values to a relation on computations. This relator specifies a notion of applicative bisimulation, a relation which is closed under certain operations (like application). Two programs are applicatively bisimular if there is an applicative bisimulation which relates the two. Given that our algebra is an ω-continues EM-algebra, this notion of applicative bisimilarity coincides with the notion of behavioural equivalence (see [29]).
Last but not least, we can define the notion of contextual equivalence. We specify a basic relation on computations of base type: Two programs of base type are equivalent if they satisfy each predicate, lifted by the algebra, to the same degree. The contextual equivalence is then the largest compatible (or congruent ) relation which, on base types, coincide with the basic relation. The preorder A need not be a complete lattice for the definition of contextual equivalence to work, and this notion of program equivalence does not always coincide with the above two notions (in particular in the presence of nondeterminism). However, compared to the other notions of program equivalence, it is in general more difficult to show that two programs are contextually equivalent given the above formulation.

Tensor of Complete Lattices
We have defined effect descriptions to interpret the behaviour of algebraic effects. We will now start building the foundation for combining effects and their descrip- tions. In particular, given two effect descriptions (Σ1, A1, α1) and (Σ2, A2, α2), we want to find an effect description (Σ12, A12, α12) for the combination of effects.
Firstly, the combined signature Σ12 is given by the sum or disjoint union of the original two signatures Σ12 := Σ1 + Σ2. Combining truth spaces and local functions is more involved. In this section, we study the theory for combining these things, starting with the tensor operation on complete lattices. This tensor, and its two representations, are featured in [9,16,28,32].
Definition 4.1 The tensor product of two complete lattices A and B is a complete

lattice A ⊗ B such that there is a universal linear function uA,B : A × B → A ⊗ B with the property that: Any linear function f : A × B → C into a complete lattice C is the composition of uA,B with some linear function f⊗ : (A ⊗ B) → C.
In particular, this factorisation gives us a natural bijection between linear func- tions f : (A) × (B) → C with two arguments and linear functions g : (A ⊗ B) → C with one argument. This can be generalised to a bijection between linear functions f : Πi∈I (Ai × Bi) → C and linear functions g : Πi∈I (Ai ⊗ Bi) → C.
We look at different representations of the tensor A⊗B of two complete lattices (featured in the aforementioned literature), respectively the powerset representation and the function representation:
(A ⊗ B)r := {S ⊆ A × B | ∀x ⊆ A, y ⊆ B, x × y ⊆ S ⇔ ( x,  y) ∈ S}, with inclusion order.
For any a ∈ A, b ∈ B, ur  (a, b) := {(aj, bj) ∈ A×B | aj = FA ∨bj = FB ∨ (aj ≤
a ∧ bj ≤ b)}.
A linear function f : A × B → C factors through g : (A ⊗ B)r → C given by

g(S) :=	{f (a, b) | (a, b) ∈ S}.
(A ⊗ B)→ := {f : A → B | ∀x ⊆ A. f ( pointwise (extensional) order.

x) = 

 {f (a) | a ∈ x}}, with

A linear function f : A × B → C factors through g : (A ⊗ B)→ → C given by
g(h) :=	{f (a, h(a)) | a ∈ A}.
Depending on which two complete lattices we combine, we may choose an ap- propriate representation of the tensor. In the general theory, we will mainly stick to the powerset representation. Since (A ⊗ B)r and (A ⊗ B)→ both represent the same complete lattice, there is an isomorphism between the two, given by:
R : (A ⊗ B)r → (A ⊗ B)→, R(S)= λa.	{b ∈ B | (a, b) ∈ S}.
L : (A ⊗ B)→ → (A ⊗ B)r , L(h)= {(a, b) ∈ A × B | b ≤ h(a)}.
We give a concrete definition to the aforementioned bijection between linear functions f : Πi∈I (Ai × Bi) → C and linear functions g : Πi∈I (Ai ⊗ Bi) → C with respect to the powerset representation of the tensor product.
F : (Πi∈I (Ai × Bi) → C) → (Πi∈I (Ai ⊗ Bi)r → C),
by	F (f )(λi.Si) :=	{f (λi.(ai, bi)) | ∀i ∈ I. (ai, bi) ∈ Si}.	(2) We look at some known properties of the tensor product, using the two repre-
sentations interchangeably.
Lemma 4.2 The tensor product B ⊗ A, of the Booleans and a complete lattice A, is isomorphic to A.
Proof. We use the function representation. Elements of (B ⊗ A)→ are given by supremum reversing functions f : B → A. These are precisely the functions f : B → A such that f (F)= TA, hence they are in one-to-one correspondence with elements of A (values given by f (T)).	2

Proposition 4.3 The tensor product gives a symmetric monoidal product in the category of complete lattices Com, with the unit given by the Booleans B.
Proof. First note that the powerset representation immediately gives us symme- try. Using the function representation, it can be shown that (A ⊗ (B ⊗ C)→)→ is isomorphic to (B ⊗ (A ⊗ C)→)→. Using these isomorphisms:
(A ⊗ (B ⊗ C))   (A ⊗ (C ⊗ B))   (A ⊗ (C ⊗ B)→)→   (C ⊗ (A ⊗ B)→)→ 
(C ⊗ (A ⊗ B))  ((A ⊗ B) ⊗ C).
Lastly, Lemma 4.2 shows the Booleans are a unit for the tensor product.	2
We look at one more example of a tensor product relevant to combining effects (Example 1.2.9 from [8]).
Lemma 4.4 The tensor product (P(S) ⊗ A), of the powerset lattice P(S) and a complete lattice A, is isomorphic to the complete lattice (S → A), of functions from S to A, with pointwise order.
Proof. We use the function representation. Take f ∈ (P(S) ⊗ A)→, which is a supremum reversing function f : P(S) → A. Then for any set K ⊆ S, f (K) = f ( s∈K{s}) =	 s∈K f ({s}). Hence f is completely determined by the function fj : S → A given by λs.f ({s}). Vice versa, each function g : S → A determines an f sending K to	s∈K g(s). Hence (P(S) ⊗ A)→ is isomorphic to the function space S → A.		2

The supremum operation for tensor products
We have a closer look at the powerset representation of the tensor of two complete lattices. It is easy to establish that the infimum operation on (A ⊗ B)r is given by the intersection on sets. The supremum operation on (A⊗B)r is more complicated. Luckily, if the tensor is taken over completely distributive lattices, this supremum can be given a clear and useful characterisation.
Firstly, we investigate the following closure operation.
Definition 4.5 Given two complete lattices A and B, and a subset S ⊆ A × B, let
S ⊆ A × B be the set {(	x,	y) | x ⊆ A, y ⊆ B, x × y ⊆ S}.
Note that if S ∈ (A ⊗ B), then S = S. Moreover, for S ⊆ Sj ⊆ A × B, S ⊆ Sj, hence S is always included in the smallest element of (A ⊗ B) containing S. With the following lemma, we can prove that under certain conditions, S is the smallest
We call a subset S ⊆ A × B down-closed if for any (a, b) ∈ S, aj ≤ a, and bj ≤ b, we have (aj, bj) ∈ S.
Lemma 4.6 Suppose that both A and B are completely distributive lattices, then for any down-closed S ⊆ A × B, S ∈ (A ⊗ B).

closure of S, ({a∧aj | aj ∈ xj}×{b∧bj | bj ∈ yj}) ⊆ S, hence ( {a∧aj | aj ∈ xj}, {b∧


and similarly	{b ∧ bj | bj ∈ yj} = b. Hence (a, b) ∈ S^.

		
{zi}i∈I of a complete lattice, we denote xi∈Izi for the set { i∈I ci | ∀i ∈ I. ci ∈ zi}.

hence for any a ∈ x, ((xb∈yxb ) × ( 

b∈y
yb )) ⊆ S (where  is union). Repeating

this process, we can derive that (( a∈x
(xb∈yxb )) × (xa∈x( 

b∈y
yb ))) ⊆ S, hence

( ( 

a∈x
(xb∈yxb )),  (xa∈x( 

b∈y
yb ))) ∈ S^. Now, by distributivity,

 ( 

a∈x
(xb∈yxb )) = 

a∈x
(  (xb∈yxb )) = 

a∈x
( b∈y
(  xb )) = 

a∈x
( b∈y
a) = 


  	    					 
a∈x(	y)=	y.
We conclude that (	x,	y) ∈ S.	2
Corollary 4.7 For A and B two completely distributive lattices, then for any X ⊆
(A ⊗ B),	X =	X.
Proof. Since all members of X, as elements of (A ⊗ B), are down-closed, we know
be equal to  X.	2
An example: uA,B(a, b) ∨ uA,B(aj, bj)= uA,B(a, b) ∪ uA,B(aj, bj) ∪ uA,B(a ∨ aj,b ∧ bj) ∪ uA,B(a ∧ aj,b ∨ bj).

Combining functions
The tensor product gives us a clear way of combining two linear functions f : Πi∈IA → A and g : Πi∈IB → B into a single linear function (f ⊗g): Πi∈I (A⊗B) → (A ⊗ B). This is done in the following way:
Compose f and g with uA,B into a single linear function uA,B ◦ (f × g) : Πi∈IA × Πi∈IB → (A ⊗ B).
Permute the arguments of the function to get a linear function from Πi∈I (A×B) to (A ⊗ B).
Apply F from (2) to the result to get a linear function (f ⊗g): Πi∈I (A⊗B) →
(A ⊗ B).
To get a clearer picture of what is going on, we can apply this construction directly to the powerset representation (A⊗B)r of the tensor product. This gives us a concrete definition of the combination of functions (f ⊗ g)r : Πi∈I (A ⊗ B)r → (A ⊗ B)r , which is as follows:
(f ⊗ g)r (λi.Si)	:=	 {uA,B(f (λi.ai), g(λi.bi)) | ∀i ∈ I. (ai, bi) ∈ Si}.

Using the powerset representation, we can make the following observation.

Proposition 5.1 If both A and B are completely distributive lattices, then A ⊗ B
is completely distributive.

Proof. We use the alternative definition for complete distributivity given in Defi- nition 2.4.
Take some set I, and consider the infimum functions  A and  B on A and B
respectively. Since A and B are completely distributive, both infimum functions are linear. Hence their combination ( A ⊗	B) is linear too. Consider some family
( A ⊗  B )r (λi.Si)	=	 {uA,B ◦ ( A,  B )(λi.ai, λi.bi) | ∀i ∈ I. (ai, bi) ∈ Si}
=	 {uA,B( i∈I ai, i∈I bi) | ∀i ∈ I. (ai, bi) ∈ Si}
=	 {uA,B(a, b) | (a, b) ∈  i∈I Si}
=	 {u A,B(a, b) | (a, b) ∈  i∈IS i} =  i∈IS i .
{uA,B(a, b) | (a, b) ∈ S} = S.
Hence, ( A ⊗  B ) is the infimum function on (A⊗ B), which we know is linear.
This holds for all indexing sets I, so we conclude by Definition 2.4 that (A ⊗ B) is completely distributive.	2



Combining ilinear functions
As can be seen in the examples of Subsection 3.2, local functions are not linear in general, they are ilinear. For example, Exppor(F[0,1], T[0,1])= (0 + 1)/2 /=0= F[0,1]. So we need a method of combining ilinear functions. Luckily, if all the complete lattices concerned are completely distributive, the bijection F given in (2) preserves ilinearity. This allows us to use the same construction to combine ilinear functions.

Lemma 5.2 Suppose that A and B are completely distributive lattices, then for any ilinear function f : Πi∈I (A× B) → C, F (f ), the function F (f ): Πi∈I (A⊗ B) → C is ilinear.

Proof. Take for any i ∈ I an arbitrary set Xi ⊆ (A ⊗ B). By Corollary 4.7,
∀i ∈ I.  Xi = ^Xi. Since for any a ∈ A and b ∈ B,  Xi contains (a, FB)
and (FA, b), it already contains (	x,	y) for either x or y empty, hence we have
 Xi = ^Xi = {(  x,  y) | x ⊆ A, y ⊆ B, both non-empty and x × y ⊆  Xi}.

F (f )(λi.  Xi)  =   {f (λi.(ai, bi)) | ∀i ∈ I. (ai, bi) ∈  Xi}
=	{f (λi.(	xi,	yi)) | ∀i ∈ I. xi ⊆ A, yi ⊆ B,
both non-empty s.t. xi × yi ⊆	Xi}
(by ilinearity )	=	{f (λi.(ai, bi)) | ∀i ∈ I. ai ∈ xi ⊆ A, bi ∈ yi ⊆ B, xi × yi ⊆	Xi}
=	{f (λi.(ai, bi)) | ∀i ∈ I. (ai, bi) ∈	Xi}
=	{f (λi.(ai, bi)) | ∀i ∈ I. ∃Si ∈ Xi. (ai, bi) ∈ Si}
=	{ {f (λi.(ai, bi)) | ∀i ∈ I. (ai, bi) ∈ Si}| ∀j ∈ I. Sj ∈ Xj}
=	{F (f )(λi.Si) | ∀i ∈ I. Si ∈ Xi} .
We conclude that F (f ): Πi∈I (A ⊗ B) → C is ilinear.	2
We finish this section with this final important result, showing that we can safely combine ilinear functions.
Proposition 5.3 Suppose A and B are two completely distributive lattices, and consider two ilinear functions f : (Πi∈IA) → A and g : (Πi∈IB) → B. Then (f ⊗ g): (Πi∈I (A ⊗ B)) → (A ⊗ B) given by F (uA,B ◦ (f × g)) is ilinear.
Proof. Note that uA,B is linear, hence ilinear. So (uA,B) ◦ (f × g) is ilinear as well. Hence we get the result by a simple application of Lemma 5.2.	2
There is an alternative, but equivalent, formulation for the above combination of ilinear functions. We define the tensor ⊗i of icomplete lattices, the itensor, using Definition 4.1 but replacing linearity with ilinearity. This gives us a bijective function Fi : Πi∈I (A × B) → (A ⊗i B) between spaces of ilinear function. Using the adjunction U ▶ ! , we can find an ilinear function (UA ⊗i UB) → U (A ⊗ B) over complete lattices A and B. We compose Fi with that function to retrieve our function F . Proving that these functions coincide however, requires some effort. As such, the approach in this paper uses the more direct, and theoretically less cumbersome, approach. Further comparison between the two tensors could be an interesting research topic for the future.
Combining effect descriptions
We combine two effect descriptions (Σ1, A1, α1) and (Σ2, A2, α2) into an effect de- scription (Σ12, A12, α12), where Σ12 := Σ1 +Σ2, A12 := (A1 ⊗A2), and α12 is defined by the following ilinear local functions:
For op ∈ Σ1, let α12,inleft(op) : (A ⊗ B)ar(op) → (A ⊗ B) be (α1,op ⊗	). For op ∈ Σ2, let α12,inright(op) : (A ⊗ B)ar(op) → (A ⊗ B) be (  ar(op) ⊗ α2,op).
The combined effect interpretation is defined by combining the relevant interpreta- tion of an effect operation from its source with the infimum function. Hence, since A1 and B1 are completely distributive, α12 is made up of ilinear local functions.

For ease of notation, we will write α1 ∗ α2 for α12 when looking at examples.
Lemma 6.1 Given some ilinear function f : AI → A and inﬁmum/conjunction
: BI → B on the Booleans. Then (f ⊗	) is under the isomorphism (A ⊗ B)  A
from Lemma 4.2 equal to f.
Proof. (f ⊗  )(λi.Si)=  {uA,B(f (λi.ai),  i∈I bi) | ∀i ∈ I. (ai, bi) ∈ Si}. Since for any S ∈ (A ⊗ B) and all a ∈ S, (a, F) ∈ S, we need only concern ourselves with the case where  i∈I bi /= F, or equivalently, when ∀i ∈ I. bi = T. So (f ⊗  )(λi.Si)= 
{uA,B(f (λi.ai), T) | ∀i ∈ I.(ai, T) ∈ Si}. Using the isomorphism (A ⊗ B)  A we
can transport (f ⊗	) to a function from AI to A, which is given by sending λi.ai
to:
 {a | (a, T) ∈  {uA,B(f (λi.aj), T) | ∀i ∈ I. (aj, T) ∈ uA,B(ai, T)}} = f (λi.ai).2
In general, for op ∈ Σ1, α12,op(λi.Si)	=	{uA,B(α1,op(λi.ai), b) | b ∈ B, ∀i ∈
I. (ai, b) ∈ Si}.
Proposition 6.2 The method of combining effects gives a symmetric and associa- tive operation on effect descriptions, with a unit given by pure computations (∅, B, ↓).
Proof. The sum on signatures Σ is a symmetric and associative operation, with a unit given by the empty set ∅. By Proposition 4.3, we know the tensor to be a symmetric and associative operation on complete lattices, with a unit given by B. Lastly, the tensor combination of ilinear functions is symmetric, associative 4 , and has a unit given by an infimum function over B (see Lemma 6.1).	2

Examples of combining effects
To illustrate how the above method yields valid interpretations of combinations of effects, we look at a handful of examples. In each case, we add a specific effect to an arbitrary effect description. In Subsection 7.1, we will look at some more specific combinations of effects.
Example 6.3 [Adding nondeterminism] Take some effect description (Σ, A, α). To this, we add nondeterminism from Example 3.12, which has choice operator nor : α2 → α, truth space A and interpretation Pos. The combined truth space (A ⊗ A) is given by the space of pairs {(a, b) ∈ A2 | a ≤ b}. Such a pair (a, b) represents a worst-case value a denoting the minimum degree of truth that is always reached, and a best case value b denoting the maximum degree of truth that could be reached. These correspond respectively to demonic and angelic nondeterminism.
Let β be the combined interpretation given by α ∗ Pos. Our method yields the following local functions:
∀op ∈ Σ. βinleft(op)(λi.(ai, bi)) = (αop(λi.ai), αop(λi.bi)).
βinright(nor)((a1, b1), (a2, b2)) = (a1 ∧ a2, b1 ∨ b2).

4 This fact is not completely trivial, but is straightforward to prove.

We can give β an alternative description. The algebra β will resolve nondetermin- istic choices of an input tree both in the worst possible way and in the best possible way. It will then apply α to the resulting two trees, and return two values of A respectively.
Example 6.4 [Adding Global Store] Take some effect description (Σ, A, α). To this we add Boolean Global Store from Example 3.10, which has effect signature Σglobal = {lookupl, updatel(T), updatel(F) | l ∈ Loc}, assertions P(S) and weakest precondition interpretation Wp. As shown in Lemma 4.4, the tensor of the two complete lattices is given by the function space S → A. We can see this as the space of valuations or quantitative A-valued assertions on global states S. Let β be the combination of interpretations (α ∗ Wp), then we get:
∀op ∈ Σ. βinleft(op)(λi.fi)= λs ∈ S.αop(λi.fi(s)).
β	(f ,f ) = λs ∈ S.  f1(s)	if s(l) = T,
βinright(updatel(v))(f ) = λs ∈ S.f (s[l := v]).
We can give β an alternative description. The algebra β will resolve, for each starting state s, the global store operations of its input tree appropriately, and give its leaves (which are functions from S to A) the final state as argument. To each resulting tree, it will apply α to compute the appropriate value in A.
Example 6.5 [Adding Cost] Take some effect description (Σ, A, α). To this, we add the cost effect from Example 3.11, which has effect signature Σcost := {costq | q ∈ Q>0}, truth space [0, ∞] with reverse order, and the tally interpretation Tal. The tensor of the truth spaces is given by functions R≥0 → A which are infimum preserving with respect to the standard ordering of the real numbers. Technically, it is functions from [0, ∞], but ∞ is always sent to TA, so we can remove it from the definition without loss of generality.
Let β = (α ∗ Tal) be the combination of interpretations. Then:
For op ∈ Σ, βinleft(op)(λi.fi) = λr ∈ R≥0. αop(λi.fi(r)).
βinright(costq )(f ) = λr ∈ R≥0. f (r + q).
We can give β an alternative description. The algebra β will, given a certain al- lowance r ∈ R≥0 to spend, go through the tree spending the allowance on resolving any cost operations. Once it encounters a cost operation it cannot pay for, it puts a ⊥ leaf at that location. If it encounters another leaf, which contains a function from R≥0 to A, it feeds this function the remaining allowance as an argument and puts the result as the new value of the leaf. It then applies α to the resulting tree to compute the appropriate value of A.
Equations and interaction laws
Given some countable set of variables V, we see an element of Tν(V) as an algebraic expression. A pair of algebraic expressions (e1, e2) ∈ Tν(V) × Tν(V) expresses an
Σ	Σ

equation (e1 = e2) or inequation (e1 ≤ e2), denoting whether they are related in some way. A set of such (in)equations form a relation on algebraic expressions R ⊆ (T ν(V))2, which can be specified by choosing a set of axioms A ⊆ (Tν(V))2
Σ	Σ
appropriate to the effect, and closing this set under a couple of proof rules, e.g.
compositionality :
∀(e1, e2) ∈ R, ∀f, g : V → Tν(V).	(∀x ∈ V. (f (x), g(x)) ∈ R) =⇒ (Tν(f )(e1),Tν(g)(e2)) ∈R .
Σ	Σ
An axiom we tend to assume for each effect example is the inequation (⊥ ≤ x) where x ∈ V. This reflects the fact that a diverging computation does not produce anything observable.
An EM-algebra α : Tν(A) → A on some preorder specifies a relation Rα ⊆
(Tν(V))2 as follows:
∀e1, e2 ∈ Tν(V),	(e1, e2) ∈ Rα	⇐⇒	∀f : V → A. α(Tν(f )(e1)) ≤
Σ	Σ
α(Tν(f )(e2)) .
If α is an EM-algebra, then Rα is compositional. More on this comparison can be found in [31].
We say that an algebra α complements a set of axioms A if they generate the same algebraic relation. The word ‘complement’ expresses their opposing nature: whereas equations state equality between programs, algebras are used to find dis- tinctions between programs (see Examples 7.2 and 7.6 for such a distinctions). An equation (e1, e2) holds for α if (e1, e2) ∈ Rα. This direct correspondence allows us to compare the method of combining effects defined in this paper with traditional methods for combining equational theories of effects [14,15].
Firstly, we observe that equations which holds for the individual effects still holds for the combination of effects. Note that for two effect signatures Σ ⊆ Σj, Tν(V) ⊆ Tν′ (V). For simplicity, we consider Σ1 + Σ2 = Σ1 ∪ Σ2, hence it contains
Σ	Σ
both Σ1 and Σ2.

Proposition 7.1 Given two effect descriptions (Σ1, A1, α1) and (Σ2, A2, α2), let

(Σ12, A12, α12) be their combination. Then both Rα1
⊆ Tν (V) and Rα
⊆ Tν (V)
1

are contained in Rα12
⊆ Tν
12
(V).


Proof. Consider t ∈ Tν ((A ⊗ B)r ), hence t only has internal nodes from Σ1. For

ˆ12	A,B ^1	Σ1	b

{uA,B(α1(Tμ (fb)(t)), b) | b ∈ B}.
If t = ⟨S⟩, then α12(t) = S =  {uA,B(a, b) | (a, b) ∈ S} =  {uA,B(fb(S), b) |
	



α12(t)=	α12,op(α12(t1),...,  α12(tn))
=	α12,op(W{uA,B(α1(T μ (fb)(t1)), b) | b ∈ B},..., W{uA,B(α1(T μ (fb)(tn)), b) | b ∈ B})
W	Σ1	Σ1
=	{α12,op(uA,B(α1(T μ (fb )(t1)), b1),..., uA,B(α1(T μ (fb )(tn)), bn)) | b1,..., bn ∈ B}

W	Σ1	V
Σ1	n
μ

=	{uA,B(α1,op(a1,..., an),  i b′ ) | ∀i ∈ I. bi ∈ B, (ai, b′ ) ∈ uA,B(α1(T  (fb )(ti)), bi)}
Σ1	i
μ
=	{uA,B(α1,op(a1,..., an), b) | ∀i, bi ∈ B, b ∈ B, (ai, b) ∈ uA,B(α1(TΣ1 (fbi )(ti)), bi)}
=	W{uA,B(α1,op(a1,..., an), b) | ∀i, ai ∈ A, b ∈ B, ai ≤ α1(T μ (fb)(ti))}
Σ1
μ	μ
=	{uA,B(α1,op(α1(TΣ1 (fb)(t1)),..., α1(TΣ1 (fb)(tn))), b) | b ∈ B}
=	W{uA,B(α1(T μ (fb)(t1)), b) | b ∈ B}  .
Which is what we wanted to prove. For an infinite tree t approximated by finite trees t1, t2, t3,... :
αˆ12(t) = αˆ12(  ti) =  α12(ti) =   {uA,B(α1(Tμ (fb)(ti)), b) | b ∈ B}
i	i	i	Σ1
Consider an equation (e1, e2) ∈ (Tν (V)) which holds for α1. Then, given f :
V → (A⊗B), we know by the above result that α (Tν (f )(e )) = α  (Tν (f )(e )),
ˆ12	Σ1	1	ˆ12	Σ1	2
hence the equation holds for α12.	2
In particular, if α1 complements a set of axioms A, then all equations from A still hold for α12. We conclude that equations are preserved by our method of combining effect descriptions.
Comparing methods of combining effects
Given two sets of axioms A1 ⊆ (Tν (V))2 and A2 ⊆ (Tν (V))2, then we define the
Σ1	Σ2
axioms of the equational sum [14,15] of effects to be A1 ∪ A2. In some cases, the
interpretation of a combination of effects defined in this paper corresponds to the equational sum:
Example 7.2 [Cost with Error] We combine the effects of cost in Example 3.11, and error in Example 3.13, using Example 6.5. The resulting combination of effects coincides with the sum of equational theories. We can see that for any q ∈ Q>0, the effect operation costq does not distribute over raise. This is because costq(raise()) and raise() are distinguished by the combined algebra (Tal ∗ Err):
(Tal ∗ Err)(raise())(0)	=		/=	F =	(Tal ∗ Err)(costq(raise()))(0) .
Informally, if we have no resources (the 0 argument), then raise() will yield an error (the ), whilst costq(raise()) will stall (the ⊥) as it requests a resource we do not have. We can use this as a basis to prove that our combined algebra complements the sum of equational theories..
In other cases, extra axioms are needed to describe the interaction between the effects we want to combine. Such axioms, which contain effect operations from both theories, are called interaction laws. The most common interaction law is a commutativity law [14,15].
Definition 7.3 Given two effect operations op1 and op2 of arity n and m respec- tively, the commutativity law between op1 and op2 is given by:
op1(λi. op2(λj. vi,j)) = op2(λj. op1(λi. vi,j)) ,

where we use a distinct variable vi,j ∈ V for each 1 ≤ i ≤ n and 1 ≤ j ≤ m. 5

Let commut(Σ1, Σ2) ⊆ Tν
(V) be the set containing the commutativity law

for each pair op1 ∈ Σ1 and op2 ∈ Σ2. Given two sets of axioms A1 ⊆ (Tν (V))2 and A2 ⊆ (Tν (V))2, then we define the axioms of the equational tensor [15] of effects to be A1 ∪ A2 ∪ commut(Σ1, Σ2). Note that these will still be closed under operations like compositionality, when used to generate an algebraic relation.
In some cases, the description of a combination of effects as defined in this paper corresponds to the equational tensor:
Example 7.4 [Probability with Global store] We combine the effects of probability in Example 3.9, and global store in Example 3.10, using Example 6.4. We will show that the relation Rα induced by the combined algebra α = Exp ∗ Wp contains all the commutativity laws. From Example 6.4, we know that the combined truth space is given by A = (S → [0, 1]). Now, por commutes with lookupl since, given a, b, c, d ∈ A:
α(por(lookupl(a, b), lookupl(c, d))) =  λs.(α(lookupl(a, b))(s)+ α(lookupl(c, d))(s))/2
=	λs.	(a(s)+ c(s))/2	if s(l)= T
(b(s)+ d(s))/2	if s(l)= F
=	α(lookupl(por(a, c), por(b, d)))  .
The operation por commutes with updatel,T since, given a, b ∈ A:
α(por(updatel,T(a), updatel,T(b))) =  λs.(α(updatel,T(a))(s)+ α(updatel,T(b))(s))/2
=	λs.(a(s[l := T]) + b(s[l := T]))/2
=	λs.α(por(a, b))(s[l := T])
=	α(updatel,T(por(a, b)))  .
Similarly, the operation por commutes with updatel,F. Hence, Rα contains commut(Σprob, Σglobal), the commutativity laws. We conclude that α complements the tensor of equational theories.
In some famous cases, the equational sum coincides with the equational tensor. This is because the commutativity laws are already present in the original sets of axioms.
Example 7.5 [Nondeterminism with Error] We combine the effects of nondeter- minism in Example 3.12, and error in Example 3.13. As seen in Proposition 7.1, the relation Rα induced by the combined interpretation α = (Pos∗Err) contains the orig- inal axioms of the theory. One such axiom is that of idempotency, that nor(x, x)= x. The commutativity law between nor and raise is given by nor(raise, raise) = raise, which can be proven using idempotency, substituting raise for x. Hence the combi- nation of effects complements both the sum and the tensor of equational theories

5 The choice of variables is unimportant, since the resulting (induced) relation on T ν (V) will be closed under substitution. Note also that the definition of commutativity law can be easily adapted to talk about operations with countable arity.

(since they are identical).
Lastly, there is an instance in which the method of combining effects neither corresponds to the equational sum, nor with the equational tensor:
Example 7.6 [Probability with Nondeterminism] We combine the effects of prob- ability in Example 3.9, and nondeterminism in Example 3.10, using Example 6.3. The combined truth space A is given by ordered pairs (a, aj) of elements a, aj ∈ [0, 1]. Let α = (Exp ∗ Pos). We first show that this algebra does not comple- ment the sum of equational theories, since the interaction law por(x, nor(y, z)) = nor(por(x, y), por(x, z)) holds for α. Take (a, aj), (b, bj), (c, cj) ∈ A:
α(por((a, aj), nor((b, bj), (c, cj)))) = ((a + (b ∧ c))/2, (aj + (bj ∨ cj)/2))
= ((a + b)/2 ∧ (a + c)/2, (aj + bj)/2 ∨ (aj + cj)/2)
= α(nor(por((a, aj), (b, bj)), por((a, aj), (b, bj)))) . However, the commutativity law por(nor(x, y), nor(z, w)) = nor(por(x, z), por(y, w)) does not holds for α, since for x = (0, 0), y = w = (1/4, 1/4), and z = (1, 1):
α(por(nor(x, y), nor(z, w)))	= (((0 ∧ 1/4) + (1 ∧ 1/4))/2, ((0 ∨ 1/4) + (1 ∨ 1/4))/2)
= (1/8, 5/8) /= (1/4, 1/2)
= ((0 + 1)/2 ∧ (1/4+ 1/4)/2, (0 + 1)/2 ∨ (1/4+ 1/4)/2)
= α(nor(por(x, z), por(y, w))) .
Hence, the combined interpretation α neither complements the sum, nor comple- ments the tensor of equational theories. Instead, it complements a natural theory for this combination of effects, as e.g. described in [18,19].
Conclusions and related work
In this paper, we looked at Eilenberg-Moore algebras over the tree monad, whose carrier sets are given by complete lattices. These are used in [29,30] to formu- late behavioural equivalence, in particular to define quantitative modalities: lifting quantitative predicates on values to quantitative predicates on computations. These quantitative modalities are a generalisation of Boolean modalities, given by subsets of Tν({∗}), and used in [27,22] to specify program equivalence. In turn, those modalities are based on the notion of observation from [17].
Eilenberg-Moore algebras describing weakest preconditions, as done in our ex- ample for global store, are commonly used for describing effectful programs, see
e.g. [12]. In [2,20], weakest precondition semantics are given in terms of Dijkstra monads. It would be interesting to see whether the theory developed here has practical applications to the formalism developed in those papers.
This paper only features a selection of examples, though a lot more effects, like Input/Output, can be given an effect description. It is also possible to implement the jump effect, which is given an algebraic description in [10]. Moreover, though we only looked at a couple of combinations of effects, we can use our method for

combining effect descriptions to give a description of any combination of the effects featured in this paper. This includes combining effects with themselves, e.g. nonde- terminism with nondeterminism would create a description of a game between two nondeterministic schedulers.
One interesting combination we did not look at specifically is the combination of global store and error. It turns out, that this combination coincides with the tensor of equational theories. Informally, this describes the situation in which the global store is inaccessible after an error has been raised. It is also possible to define an algebra complementing the sum of equational theories, as defined in [29,30]. We can tweak interpretations of combinations of effects in other ways too. E.g., when combining probability with cost, we can associate a cost to each probabilistic choice. This would induce a logic capable of testing the average time till convergence.
We focussed on effect operation with finite arity in this paper. As mentioned before, it is also possible to extend the results to include operations with infinite arity. This for instance allows us to describe global store for storing natural numbers. However, not all examples with infinite arity can be incorporated. Take for instance countable nondeterminism. It is not possible to inductively check must-termination over countable choice. So, though it is possible to define local ilinear functions to describe this (e. g.j  ), the induced algebra cannot appropriately detect must-
when looking at local functions with infinite arity, one needs to be careful to check if they are ω-continuous.
Lastly, the algebras used in this paper seem suitable for defining quantitative relations, e.g. metrics [11,21], on functional programming languages with effects. For metrics, quantales tend to be used as space of distances. Since completely distributive lattices form quantales, there is a possible link between such metrics and the algebras used in this paper. It could be possible to develop a formalism for using algebras for defining quantitative relations, and use the method for combining effects to combine such quantitative relations. This would be an interesting avenue for future research.

Acknowledgements:
I would like to thank both Alex Simpson and Danel Ahman for the helpful tips and discussions, and the anonymous reviewers for their insightful feedback and suggestions.

References
Abramsky, S., The lazy λ-calculus, Research Topics in Functional Programming (1990), pp. 65–117.
Ahman, D., C. Hritcu, K. Maillard, G. Mart´ınez, G. Plotkin, J. Protzenko, A. Rastogi and N. Swamy, Dijkstra monads for free, in: 44th ACM SIGPLAN Symposium on Principles of Programming Languages (POPL), 2017, pp. 515–529.
Battenfeld, I., K. Keimel and T. Streicher, Observationally-induced algebras in domain theory, Logical Methods in Computer Science 10(3:18) (2014), pp. 1–26.

Battenfeld, I. and M. Schr¨oder, Observationally-induced effect monads: Upper and lower powerspace constructions, Electron. Notes Theor. Comput. Sci. 276 (2011), p. 105–119.
Crubill´e, R. and U. Dal Lago, On probabilistic applicative bisimulation and call-by-value λ-calculi, Lecture Notes in Computer Science 8410 (2014).
Dal Lago, U., F. Gavazzo and P. B. Levy, Effectful applicative bisimilarity: Monads, relators, and the Howe’s method, Logic in Computer Science (2017), pp. 1–12.
Davey, B. A. and H. A. Priestley, “Introduction to Lattices and Order,” Cambridge University Press, 2002, 2nd edition.
Eklund, P., J. Guti´errez Garc´ıa, U. Ho¨hle and J. Kortelainen, “Semigroups in Complete Lattices: Quantales, Modules and Related Topics,” 2018.
Ern´e, M. and J. Picado, Tensor products and relation quantales, Algebra Univers. 78 (2017), p. 461–487.
Fiore, M. and S. Staton, Substitution, jumps, and algebraic effects, in: Proceedings of the Twenty- Third EACSL Annual Conference on Computer Science Logic (CSL) and the Twenty-Ninth Annual ACM/IEEE Symposium on Logic in Computer Science (LICS), CSL-LICS ’14, 2014, pp. 41:1–41:10.
Gavazzo, F., Quantitative behavioural reasoning for higher-order effectful programs: Applicative distances, in: Proceedings of the 33rd Annual ACM/IEEE Symposium on Logic in Computer Science, LICS 2018, 2018, pp. 452–461.
Hasuo, I., Generic weakest precondition semantics from monads enriched with order, Theoretical Computer Science 604 (2015), pp. 2–29.
Heckmann, R., Abstract valuations: A novel representation of plotkin power domain and vietoris hyperspace, Electr. Notes Theor. Comput. Sci. 6 (1997), pp. 160–173.
Hyland, M., G. Plotkin and J. Power, “Combining Computational Effects: Commutativity and Sum,” Springer US, Boston, MA, 2002 pp. 474–484.
Hyland, M., G. Plotkin and J. Power, Combining effects: Sum and tensor, Theoretical Computer Science
357 (2006), pp. 70 – 99.
Jacobs, B., Semantics of weakening and contraction, Annals of Pure and Applied Logic 69 (1994),
pp. 73 – 106.
Johann, P., A. Simpson and J. Voigtl¨ander, A generic operational metatheory for algebraic effects, in:
Proceedings of Logic in Computer Science (LICS’10), 2010, pp. 209–218.
Keimel, K. and G. D. Plotkin, Mixed powerdomains for probability and nondeterminism, Logical Methods in Computer Science 13 (2017).
Lopez, A. and A. Simpson, Basic operational preorders for algebraic effects in general, and for combined probability and nondeterminism in particular, in: 27th EACSL Annual Conference on Computer Science Logic, CSL 2018, 2018, pp. 29:1–29:17.
Maillard, K., D. Ahman, R. Atkey, G. Mart´ınez, C. Hritcu, E. Rivas and E. Tanter, Dijkstra monads for all, in: 24th ACM SIGPLAN International Conference on Functional Programming (ICFP), 2019.
Mardare, R., P. Panangaden and G. D. Plotkin, Quantitative algebraic reasoning, in: Proceedings of the 31st Annual ACM/IEEE Symposium on Logic in Computer Science, LICS ’16, 2016, pp. 700–709.
Matache, C. and S. Staton, A sound and complete logic for algebraic effects, in: Lecture Notes in Computer Science, Springer International Publishing, 2019 pp. 382–399.
Plotkin, G. D., Domains (1983), course notes.
Plotkin, G. D. and J. Power, Adequacy for algebraic effects, Foundations of Software Science and Computation Structures (2001), pp. 1–24.
Plotkin, G. D. and J. Power, Notions of computation determine monads, in: Proceedings of the 5th International Conference on Foundations of Software Science and Computation Structures, 2002, pp. 342–356.
Sigmon, K., Cancellative medial means are arithmetic, Duke Math. J. 37 (1970), pp. 439–445.
Simpson, A. and N. Voorneveld, Behavioural equivalence via modalities for algebraic effects, ACM Trans. Program. Lang. Syst. 42 (2020), 45 pages. Journal version of ESOP 2018 conference paper.


Su¨nderhauf, P., Tensor products and powerspaces in quantitative domain theory, Electronic Notes in Theoretical Computer Science 6 (1997), pp. 327 – 347, MFPS XIII, Mathematical Foundations of Progamming Semantics, Thirteenth Annual Conference.
Voorneveld, N., Quantitative logics for equivalence of effectful programs, Electronic Notes in Theoretical Computer Science 347 (2019), pp. 281 – 301, proceedings of the Thirty-Fifth Conference on the Mathematical Foundations of Programming Semantics.
Voorneveld, N., “Equality between programs with effects,” Ph.D. thesis, University of Ljubljana (2020).
Voorneveld, N., From equations to distinctions: Two interpretations of effectful computations, in: Proceedings Eighth Workshop on Mathematically Structured Functional Programming, Electronic Proceedings in Theoretical Computer Science 317 (2020), pp. 1–17.
Wille, R., Tensorial decomposition of concept lattices, Order 2 (1985), p. 81–95.
