

Electronic Notes in Theoretical Computer Science 253 (2009) 87–99
www.elsevier.com/locate/entcs

Computing Optimal Tests for Non-deterministic Systems Using DNNF Graphs
Anika Schumann1	Martin Sachenbacher2
Institut fu¨r Informatik Technische Universita¨t Mu¨nchen 85748 Garching, Germany
Jinbo Huang3
National ICT Australia and The Australian National University
Canberra, ACT 0200 Australia

Abstract
The goal of testing is to distinguish between a number of hypotheses about a system—for example, dif- ferent diagnoses of faults—by applying input patterns and verifying or falsifying the hypotheses from the observed outputs. Optimal distinguishing tests (ODTs) are those input patterns that are most likely to distinguish between hypotheses about non-deterministic systems. Finding ODTs is practically important, but it amounts in general to determining a ratio of model counts and is therefore computationally very expensive.
In this paper, we present a novel approach to this problem, which uses structural properties of the system to limit the complexity of computing ODTs. We first construct a compact graphical representation of the testing problem via compilation into decomposable negation normal form. Based on this compiled representation, we show how one can evaluate distinguishing tests in linear time, which allows us to efficiently determine an ODT. Experimental results from a real-world application show that our method can compute ODTs for instances that were intractable for previous approaches.
Keywords: testing, DNNF graphs, model counting.


Introduction
Testing asks whether a system can be stimulated with input patterns such that different hypotheses about the system can be verified or falsified from the observed

1 Email: anika.schumann@in.tum.de
2 Email: sachenba@in.tum.de
3 Email: jinbo.huang@nicta.com.au

1571-0661© 2009 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2009.09.053

output patterns. Applications include model-based fault analysis of technical sys- tems, autonomous control (acquiring sensor inputs to discriminate among competing state estimates), and bioinformatics (designing experiments that help distinguish between different possible explanations of biological phenomena).
In many real-world applications of testing, the underlying models are non- deterministic; applying an input can lead to several possible outputs. Different notions of testing with such non-deterministic models have been introduced. In the area of diagnosis, [11] introduced deﬁnitely and possibly discriminating tests (DDTs and PDTs) for systems modeled as constraints. For a DDT, the sets of pos- sible outputs are disjoint and thus it will necessarily distinguish among hypotheses, whereas for a PDT, the sets partially overlap and thus it may or may not distinguish among hypotheses. In automata theory, [1] studied the analogous problem of gen- erating strong and weak distinguishing sequences for non-deterministic finite state machines; for sequences of length at most k ∈ N, this can be reduced to the problem of finding DDTs and PDTs [6]. [7] introduced optimal distinguishing tests (ODTs), which generalize DDTs and PDTs by maximizing the ratio of distinguishing over non-distinguishing possible outcomes. Finding ODTs is important as it reduces the number of tests to be executed and the overall costs of the testing process. [7] pro- posed and analyzed a simple greedy-type algorithm to approximate ODTs, which in some real-world applications produces test inputs whose distinguishing ratios are close to those of ODTs.
In this paper, we present a novel search algorithm to compute ODTs (and thus DDTs and PDTs), which exploits structural properties of the model to limit the complexity of optimal test generation. Its main feature is a carefully constructed graph—through manipulation of logical theories and compilation into decomposable negation normal form (DNNF) [5]—that allows efficient computation of good upper bounds on ratios of model counts. These upper bounds are used to prune the search in a way motivated by a recent planning algorithm [8]. We show that our method can compute ODTs for instances that were intractable for previous approaches.

Background
Following the framework in [7,10,11], we assume that the system can be modeled as a constraint satisfaction problem (CSP), which is a triple M = (V, D, C), where D = D(v1) × ... × D(vn) are the finite domains of finitely many variables vj ∈ V, j = 1,... , n, and C = {C1,... , Cm} is a finite set of constraints with Ci ⊆ D, i = 1,... , m. We denote by X the set of all solutions, that is, assignments x ∈ D to the variables such that all constraints are satisfied. That is, X = {x | x ∈ D, C(x)}, where C(x) denotes x ∈ Ci for all i = 1,... , m.
In addition, the system under investigation defines a set of controllable (input) variables I and a set of observable (output) variables O. Formally, a hypothesis M for a system is then a CSP whose variables are partitioned into V = I ∪ O ∪ L, such that I and O are the input and output variables of the system, and for all assignments to I, the CSP is satisfiable. The remaining variables L = V \ (I ∪ O)

are called internal state variables. We denote by D(I) and D(O) the cross product of the domains of the input and output variables, respectively: D(I)= ×v∈7 D(v) and D(O)= ×v∈O D(v).
The goal of testing is then to find assignments of the input variables I that will cause different assignments of output variables O for different hypotheses. In the general case of non-deterministic systems, an input assignment can yield more than one possible output assignments. This case is frequent in practice; one reason is that in order to reduce the size of a model, it is common to aggregate the domains of system variables into small sets of values such as ‘low’, ‘med’, and ‘high’; a side- effect of this abstraction is that the resulting models can no longer be assumed to be deterministic functions, even if the underlying system behavior was deterministic. Another reason is the test situation itself: even in a rigid environment such as an automotive test-bed, there are inevitably variables or parameters that cannot be completely controlled while testing the device.
In order to capture sets of outputs, for a given hypothesis M and an assign- ment t ∈ D(I) to the input variables, we define the output function X : D(I) → 2Ð(O) with t '→ {y | y ∈ D(O), ∃ x ∈ X : x[I]= t ∧ x[O] = y}, where 2Ð(O) de- notes the power set of D(O), and x[I], x[O] denote the restriction of the vector x to the input variables I and the output variables O, respectively. Note that since M will always yield an output, X (t) is non-empty.


Distinguishing tests
Non-deterministic models have given rise to the introduction of so-called possibly and deﬁnitely distinguishing tests, for short PDT and DDT, respectively [11]. The first type of test (PDT) might distinguish between hypotheses, as the sets of possible outputs partially overlap, whereas the second type (DDT) will necessarily do so, as the sets of possible outputs are disjunct:

Definition 2.1 (Distinguishing Tests) Consider k ∈ N hypotheses M1,... , Mk with input variables I and output variables O. Let Xi be the output func- tion of hypothesis Mi with i ∈ {1,... , k}. An assignment t ∈ D(I) to I is a possibly distinguishing test (PDT), if there exists an i ∈ {1,... , k} such that X (t) \	X (t) /= ∅. An assignment t ∈ D(I) is a deﬁnitely distinguishing test (DDT), if for all i ∈ {1,... , k} it holds that Xi(t) \ j/=i Xj(t)= Xi(t).

For testing with non-deterministic automata models instead of logical theories or CSPs, there exists the analogous notion of so-called weak and strong distinguish- ing sequences [1,3]. Finding such sequences with a length bounded by some k ∈ N can be reduced to the problem of finding PDTs and DDTs, by unrolling automata into a constraint network using k copies of the automata’s transition and observa- tion relation [6]. Therefore, in this paper we restrict ourselves to models given as networks of finite-domain constraints.

A2H :	i1	i2	o1	A'  :	i1	i2	o1
2H 	
L	L	L	L	L	L
L	H	L	L	H	L
L	H	H	H	L	H
H	 L	H	H	H	H H	H	H
not:	i1	u	AUL:	u	o1	o2	A'  :	u	o1	o2
UL 	
	
L	H	L	L	L	L	L	L
H	L	L	H	L	L	H	L
H	L	L	H	L	L
H	L	H	H	H	L H	H	H
Fig. 1. Circuit with two possibly faulty adders: A'	and A'  .

Optimal Distinguishing Tests
2H	UL 

Due to limited observability or a high degree of non-determinism, it is not un- common that a DDT for the hypotheses does not exist, and one can instead only find PDTs. This motivates a quantitative measure for tests that refines and gener- alizes the previous notions of PDTs and DDTs. The intuition is that if we assume the possible outcomes (feasible assignments to the output variables) to be (roughly) equally likely, a PDT will be more likely to distinguish among two given hypotheses compared to another PDT, if the ratio of possible outcomes that are unique to a hy- pothesis versus all possible outcomes is higher. The notion of optimal distinguishing tests introduced in [7] formalizes this goal of finding tests that discriminate among two hypotheses as good as possible:
Definition 2.2 (Distinguishing Ratio) Given a test input t ∈ D(I) for two hypotheses M1, M2 with input variables I and output variables O, we define Γ(t) to be the ratio of feasible outputs that distinguish among the hypotheses versus all feasible outputs:
Γ(t) := |X1(t) ∪ X2(t)|− |X1(t) ∩ X2(t)|
|X1(t) ∪ X2(t)|
Γ is a measure for test quality that refines the notion of PDTs and DDTs: if Γ is 0, then the test does not distinguish at all, as both hypotheses lead to the same observations (output patterns). If the value is 1, then the test is a DDT, since the hypotheses always lead to different observations. If the value is between 0 and 1, then the test is a PDT (there is some non-overlap in the possible observations). Note that Γ is well-defined since for any chosen t ∈ D(I), the sets X1(t) and X2(t) are non-empty.
An optimal distinguishing test (ODT) is one that has the maximal distinguish- ing ratio. Figure 1 shows an example consisting of three components: one not component and the two adders: A2H and AUL. The former is high dominant upon receiving input i2 = H and the latter is low dominant upon receiving input u = L. Here we consider the hypotheses that either both adders function normally, i.e.
M1 = {not, A2H , AUL} or that both adders are faulty, i.e. M2 = {not, A'  , A'	}.
2H	UL 
This example has the two PDTs: [−i1, i2] and [−i1, −i2] which have the following

distinguishing ratios:
Γ([−i1, i2]) = 	|{o1,o2},{o1,−o2},{−o1,o2}|	 = 3 and
|{o1,o2},{o1,−o2},{−o1,o2},{−o1,−o2}|	4
Γ([−i1, −i2]) = 	|{−o1 ,o2}|	 = 1 .
|{−o1,o2},{−o1,−o2}|	2
Therefore, the input [−i1, i2] is an ODT for this example.
Deterministic DNNF
We briefly review graph-based representations of propositional theories. A proposi- tional theory f is in negation normal form (NNF) [5] if it only uses conjunction (and,
∧), disjunction (or, ∨), and negation (not, ¬), and negation only appears next to variables. An NNF is decomposable (DNNF) if conjuncts of every conjunction share no variables. A DNNF is deterministic (d-DNNF) if disjuncts of every disjunction are pairwise logically inconsistent. A d-DNNF is smooth if disjuncts of every OR node mention the same set of variables. In the rest of the paper we also assume that every variable of the logical theory appears in a smooth d-DNNF graph (this can always be ensured in polynomial time [5]). Figure 2 illustrates a smooth d-DNNF graph representing the set of PDTs for the example shown in Figure 1.
d-DNNF graphs can be generated for propositional theories in conjunctive nor- mal form (CNF) using the publicly available C2D compiler [4]. The complexity of this operation is polynomial in the number of variables and exponential only in the treewidth of the system in the worst case. Furthermore, given a DNNF graph G one can compute its projection ΠΣ(G) on variable set Σ in linear time. Without impact on the computation time we therefore assume that M1 and M2 are defined over input and output variables only.
Based on a smooth d-DNNF graph G the number of models consistent with a partial assignment X to the d-DNNF variables can be computed in linear time. This follows from the fact that each model in G is represented by a subgraph Gs that satisfies the properties: (i) every OR node in Gs has exactly one child, (ii) every AN D node in Gs has the same children as it has in G, and (iii) Gs has the same root as G.

Fig. 2. Smooth d-DNNF graph representing ¬i1 ∧ (i2 ∨ ¬i2). “A” and “O” indicate an And and an Or node, respectively. Numbers in non-leaf nodes are their identifiers.

For instance, for the graph in Figure 2 the model [−i1, −i2] is represented by the subgraph with nodes A1, O2, −i1, −i2. Henceforth we will denote subgraphs with these properties as m-subgraphs. Those that satisfy only the first two properies we will denote as s-subgraphs. Further we say that a subgraph Gs is labeled by a literal l if Gs has a leaf node l.
Model counting with respect to X then consists of computing the number of



Algorithm 1 Model counting with respect to instantiation X
8 1	if N is a leaf node consistent with X
Λ(N )= >< 0	if N is a leaf node inconsistent with X
: Qi Λ(Ni) if N = Vi Ni

m-subgraphs that are labeled by the literals in X. This is done by a bottom-up traversal of the graph as shown in Algorithm 1. The Λ(N ) value of each node N represents the number of s-subgraphs rooted in N whose labels are consistent with
X. Hence, the Λ(N ) value of the root of the graph denotes the total number of consistent models.

ODT Computation Using DNNF
In this section we show how we can represent the ODT problem as a single DNNF graph and thus obtain a representation that directly exploits the system structure to achieve compactness. Furthermore we describe how we can modify the model counting algorithm described in Section 2.3 to determine the precise distinguishing ratio for any complete instantiation of a test vector (CITV) and an upper bound for any partial instantiation of a test vector (PITV), both in linear time. The latter allows an efficient search for an ODT without computing the Γ value for all test vectors. For some cases, depending on the structure of the DNNF graph, an ODT can be determined directly without a search.
Encoding the ODT problem as single DNNF
We now describe how we can represent the ODT problem as a single d-DNNF graph G'. Since the size of that graph impacts the efficiency of the ODT computation we will also show how we can reduce the size of G' by taking into account that we are only interested in the model counts for the test vectors, not in the actual observations. We will show that G' can be projected on its input variables only, if we compute the number of models before they get lost through the projection.
A graph on whose basis one can compute the distinguishing ratio Γ needs to represent both hypotheses M1 and M2. These two hypotheses could be encoded by a graph of the form M1 ∨ M2. However, in addition we need to distinguish the models that belong to the numerator of Γ, i.e., that are consistent with f PDT O¯ = (M1 ∨ M2) ∧ ¬(M1 ∧ M2), and those that do not. We do this by introducing an additional variable d and by labelling every m-subgraph representing a model consistent with the numerator with the literal −d and by adding the literal d to the remaining m-subgraphs. Thus G' is defined as follows:
G' = (f PDT O¯ ∧ ¬d) ∨ (M1 ∧ M2 ∧ d)
As stated in Subsection 2.3 this d-DNNF graph can be generated based on the CNF representations of M1 and M2 using the available C2D compiler. Figure 3 depicts

this graph G' for our example based on which we can compute the distinguishing ratio for any CITV. For instance, to compute Γ([−i1, −i2]) we count the number of m-subgraphs labeled by −i1, −i2 and −d to obtain the numerator of Γ. In this example there is only one such m-subgraph that consists of the additional nodes: A1, O2, A4, O6, A8, −o1, and o2. To obtain the denominator of Γ we need to count the number of models consistent with M1 ∨ M2 (see Definition 2.2), that is, the number of models consistent with f PDT O¯ ∨ (M1 ∧ M2). Hence we add the number of m-subgraphs labeled by −i1, −i2 and −d and the number of those labeled by
−i1, −i2 and d. For our example there is only one subgraph labeled by the latter, namely the one consisting of the additional nodes: A1, O2, A4, O6, A9, −o1, and
−o2. Hence we obtain Γ([−i1, −i2]) = 1 , as given in Subsection 2.2. Note that, since the definition of graph G’ ensures that each of its m-subgraphs is labeled by either d or −d, we can also determine the denominator of Γ by counting the number of m-subgraphs labeled by −i1 and −i2.
Formally Γ(t) based on G’ is defined as follows:


|G'(t ∧ ¬d)|
Γ(t) := |G'(t ∧ ¬d)| + |G'(t ∧ d)| =
|G'(t ∧ ¬d)|


|G'(t)|

where |G'(X)| denotes the model count under the instantiation X. Hence we can compute the distinguishing ratio for any CITV using Algorithm 1.
G1
G'










G2


Fig. 3. Graph G’ for the example shown in Figure 1. The bottom label of a node N refers to its local counts: αN /βN . In graph G1 the bottom label denotes the test assessment values computed by Algorithm 2 when running it with t = [−i1, −i2] and in G2 these values present the results of running Algorithm 3 with respect to instantiation true.

We now describe how we abstract the non-input variables from G' without losing information relevant to the ODT problem. This is done by first computing the nodes

NI of the resulting graph G = Π7 (G') and then by counting the s-subgraphs that are in G' but not in G. The node set NI is composed of those nodes that have an input variable as descendant. For the graph G’ in Figure 3 these nodes are the “white” ones. Formally, a node N ∈ N is in NI iff:
N is a leaf labeled by an input variable or
N has a child in NI .
In order to count the s-subgraphs that are in G' but not in G we partition the set of children for each OR and AN D node in G' into those that belong to NI, i.e., NJ = {Ni | Ni ∈ NI } and those that do not, i.e., NH = {Ni | Ni ∈/ NI }. For these nodes the counting procedure of Algorithm 1 can be refined as follows:
,	h Λ(Nh)+	j Λ(Nj ) if N =	i Ni
Λ(N )= 
,, h Λ(Nh) ·  j Λ(Nj)	if N =  i Ni
where for y = {h, j} and NY = ∅ we define  y Λ(Ny) = 1.
The point is that the local count value γN =  h Λ(Nh) (resp. γN =  h Λ(Nh)) does not change when computing the model count for a different t. This results from the fact that the s-subgraph rooted in Nh is not labeled by any input variables and hence is consistent with any test vector. Thus it is sufficient to compute these values for each node only once. More precisely we label each non-leaf node N by αN (resp. βN ) representing the local count value of the numerator (resp. denominator) of Γ(N ). αN is obtained by running the refined version of Algorithm 1 with respect to instantiation ¬d and for βN we count the models with respect to instantiation true, i.e., Λ(N ) = 1 for all leaves. Graph G’ in Figure 3 shows this labelling for our example.

Computation of Γ(t) based on DNNF graph G
For computing the distinguishing ratio we use the fact that the αN and βN values of OR nodes in G are necessarily 0. This follows from G' and hence G being smooth, which means that all s-subgraphs rooted in N are labeled with the same variables. Therefore, either one of these variables is an input variable in which case the local counts are 0 for all children of N or none of these variables is an input variable in which case the OR node itself is not in G. Therefore the distinguishing ratio can be computed as presented in Algorithm 2. It is obtained from the value of the root as stated formally in Theorem 3.1. The bottom label of G1 of Figure 3 shows the Λα and Λβ values for t = [−i1, −i2].
Theorem 3.1 (Test Assessment) Let G be the root node of the smooth DNNF graph G. Then Γ(t)= Γ(G, t) for any complete instantiation t of input variables.



Algorithm 2 Test assessment with respect to instantiation t
For a leaf N consistent with t we set

and for a leaf N inconsistent with t we set
Λα(N )= Λβ(N )= 1

Λα(N )= Λβ(N )= 0.


For remaining nodes we compute:



8> (Pi Λα(Ni),

(αN ·  i Λα(Ni),
>:	Q	V

Then we compute the distinguishing ratio for each node:
Γ(N, t)= ( 0	if Λβ(N )= 0

Λα(N)
Λβ (N)
otherwise



Upper bounds for partial test vectors
While the computation of the distinguishing ratio could have also been done based on two separate DNNF graphs, we now show how this single graph is essential to our new method for computing upper bounds on the distinguishing ratio based on a PITV tp. We start by pointing out that Algorithm 2 also retrieves exactly the subgraph of G that is consistent with t. 4 The Γ(t) value can therefore also be seen as the Γ value of that subgraph. We will now show how we can compute a subgraph for a PITV tp whose Γ value will necessarily be an upper bound on that of every completion of tp.
This subgraph GS is composed of a set of s-subgraphs and the question of which of those should be included in GS translates into the question of which children of an OR node should be included. The distinguishing ratio for such a node N with children N1,... Nj is defined as:
Γ(N, t )= Λα(N1)+ Λα(N2) ·· · + Λα(Nj) .
p	Λβ(N1)+ Λβ(N2) ··· + Λβ(Nj)
Therefore, Γ(N, tp) cannot be larger than the Γ value of its “best” child, i.e., the child with the highest distinguishing ratio.  This results from the fact that for

x = a1+b1
and a1 ≤ b1 and therefore a1 ≤ a2·b1
we have

a2+b2
a2	b2

a2·b1 + b1
b2

a2 · b1 + b1 · b2

b1 · (a2 + b2)	b1

x ≤  b2	 =
a2 + b2
b2 · (a2 + b2)
=	= .
b2 · (a2 + b2)	b2

Since this reasoning also holds if the numerator and denominator of x have more

4 This graph is composed of the root and of all nodes N for which Λβ(N ) > 0 and for which at least one parent Np satisfies Λβ (Np) > 0.

than two summands, we have
Γ(N, t ) ≤ max Λα(Ni) .
i	Λβ(Ni)
Hence, we can obtain an upper bound for Γ(N, tp) by setting the values of each OR node to the values of its “best” child and by computing the values for the other nodes as in Algorithm 2.
Naturally, the search for an ODT will be the more efficient the tighter the upper bounds. To that end we include in the subgraph only the “best” child for those OR nodes that have a leaf as descendant which is not set by tp; see Algorithm 3. Formally, a node N is set by tp, i.e., set(N, tp)= 1, iff
N is a leaf node whose variable is set by tp or
N is an AN D or OR node such that for all children Ni we have set(Ni, tp)= 1.
For instance for node O2 of graph G1 shown in Figure 3 we have set(O2, [−i2]) = 1 and set(O2, [−i1]) = 0. Every child of an OR node set by tp is necessarily either consistent or inconsistent with a complete instantiation of tp regardless of how tp is completed. Therefore we can compute the distinguishing ratio for these OR nodes as in Algorithm 2 and are still guaranteed that Γ(N, tp) is an upper bound for every node N .
Note that resulting from G being smooth all consistent children of an OR node have necessarily the same set value and thus their Λα and Λβ values are either all the result of a maximization or all the result of a summation.

Algorithm 3 Upper bound with respect to instantiation tp
For an OR node N = Wi Ni we compute:
8> (Pi Λα(Ni),

(Λα(Nm), if set(N, tp)= 0 and
: Λβ (Nm)) Γ(Nm, tp)= maxi Γ(Ni, tp)
For remaining nodes the computation is same as in Algorithm 2. The distinguishing ratio Γ(N, tp) is also computed as in Algorithm 2.
Note further that we are using the same name for the value function as in Algorithm 2. The reason is that Algorithm 2 can now be regarded as a special case of Algorithm 3 where t is a complete instantiation of a test vector, and hence for all OR nodes the set function returns true. It is precisely in this case that the computed value is guaranteed to be exact as formally stated in the following theorem:
Theorem 3.2 (Upper Bound) Let tp be a PITV and G the root node of the smooth DNNF graph G. Then Γ(t) ≤ Γ(G, tp) for any complete instantiation t of the free variables in tp.

ODT computation
With the DNNF graph G and the linear time algorithms to compute the precise distinguishing ratio for a CITV and an upper bound for a PITV we have obtained the basis for our ODT search method. This consists of a branch-and-bound search over the input variables. Iteratively we set the input variables until either all variables are set and the precise distinguishing ratio is obtained or until the upper bound of the PITV is lower than the Γ value for a previously computed CITV.
Interestingly, if G has a certain structure we can obtain an ODT without a search by making use of the facts (i) that we can compute an upper bound ΓUB for the distinguishing ratio of the ODT by running Algorithm 3 with respect to instantiation true, and (ii) that there is exactly one test vector t that is consistent with the resulting subgraph GS. The latter results from graph G being decomposable. Now, since we can compute Γ(t) using Algorithm 2 we could be able to determine an ODT in linear time as stated in the following theorem:
Theorem 3.3 Let t be a test vector consistent with the subgraph GS that is obtained from computing the distinguishing ratio with respect to instantiation true. t is an ODT that can be computed in linear time if Γ(t)= Γ(GS).
For our example the condition of this theorem holds and hence we could obtain the ODT t = [−i1, i2] without a search (see G2 of Figure 3). Note that the condition of this Theorem always holds if G is deterministic. Unfortunately only graph G’ is guaranteed to be deterministic and the projection operation applied to G’ to obtain G, i.e., the abstraction from the observable variables, does not preserve determinism. To ensure determinism we would need to recompile G, but this might alter its structure completely. This would result in the loss of local count values and hence our ability to compute the distinguishing ratio from that graph.

Experimental Evaluation
We evaluated our DNNF-based testing method on a model of an automotive engine test-bed [9], which consists of three major components: engine, pipe, and throttle. The goal is to find leaks in the pipe by assigning three to four controllable variables, and observing three to four measurable variables. The problem has been turned into sets of discrete instances of varying sizes by applying different abstractions to the original mixed discrete-continuous model, and using a direct encoding from CSP to SAT [12].
Table 1 shows the experimental results for computing ODTs and DDTs. For each instance, we report the size (number of nodes) of the DNNF graph computed, and the computation time in seconds on a Linux Dual-Core PC with 1GB of RAM. For instances that have DDTs, we compared our method with the most recent specialized DDT approach [10] based on quantified Boolean formulas and the QBF solver sKizzo [2]. That approach was able to solve instances 1b–3b and ran out of memory for the rest. In contrast, our ODT approach could also solve instances 4b–6b.


	
Table 1
Results of ODT (left) and DDT (right) computation.

Our method is the first that computes exact ODTs; hence we cannot compare it directly with previous approaches. However, we used the greedy algorithm of [7] to compute approximate solutions for the same problem instances. This algorithm was only able to solve instances 1a–7a; that is, for instances 8a–10a we were able to compute an optimal solution where the previous approach could not even compute a suboptimal one.

Conclusion and Future Work
Optimal distinguishing tests generalize and refine the notion of possibly and defi- nitely distinguishing and strong and weak tests for non-deterministic systems. Since computing ODTs can be computationally very expensive, previous work has focused on approximate solutions. We presented a new method to compute exact ODTs based on innovative ways of compiling the ODT problem into DNNF and comput- ing upper bounds to prune a systematic search. Experimental results show that the method is able to compute both ODTs and DDTs for instances that were too large for previous methods. Future work may include extensions of this method to finding tests with minimal costs, or to situations where possible output patterns cannot be assumed to be equally likely.

References
R. Alur, C. Courcoubetis, and M. Yannakakis.	Distinguishing tests for nondeterministic and probabilistic machines. In Proc. ACM Symposium on Theory of Computing, pages 363–372, 1995.
M. Benedetti. skizzo: A suite to evaluate and certify QBFs. In Proc. CADE-05, 2005.


S. Boroday, A. Petrenko, and R. Groz. Can a model checker generate tests for non-deterministic systems? Elec. Notes Theor. Comp. Sci., 190:3–19, 2007.
A. Darwiche. The c2d compiler user manual. Technical report, Comp. Sci. UCLA, 2005.
A. Darwiche and P. Marquis. A knowledge compilation map. Journal of Artificial Intelligence Research, 17:229–264, 2002.
M. Esser and P. Struss. Fault-model-based test generation for embedded software. In Proc. IJCAI-07, pages 342–347, 2007.
S. Heinz and M. Sachenbacher. Using model counting to find optimal distinguishing tests. ZIB Report 08-32, Zuse Institute Berlin, 2008.
J. Huang. Combining knowledge compilation and search for conformant probabilistic planning. In
Proc. ICAPS-06, pages 253–262, 2006.
J. Luo, K. Pattipati, L. Qiao, and S. Chigusa. An integrated diagnostic development process for automotive engine control systems. IEEE Trans. on Systems, Man, and Cybernetics, 37(6):1163–1173, 2007.
M. Sachenbacher and S. Schwoon. Model-based testing using quantified CSPs. In ECAI-08 Workshop on Model-based Systems, 2008.
P. Struss. Testing physical systems. In Proc. AAAI-94, pages 251–256, 1994.
T. Walsh. SAT vs. CSP. In Proc. of CP-00, pages 441–456, 2000.
