Electronic Notes in Theoretical Computer Science 123 (2005) 35–74  
www.elsevier.com/locate/entcs


Differential Interaction Nets
Ehrhard Thomas 1 ,2
Institut de math´ematiques de Luminy
CNRS and Universit´e de la M´editerran´ee, UMR 6206 F´ed´eration de recherche des unit´es de math´ematiques de Marseille, FR 2291
Marseille, France
Laurent Regnier3
Institut de math´ematiques de Luminy
CNRS and Universit´e de la M´editerran´ee, UMR 6206 F´ed´eration de recherche des unit´es de math´ematiques de Marseille, FR 2291
Marseille, France

Abstract
We introduce interaction nets for the differential lambda-calculus and exhibit in this framework a new symmetry between the of course and the why not modalities of linear logic, completely similar to the symmetry between the tensor and par connectives of linear logic.
Keywords: lambda-calculus, linear logic, proof nets, interaction nets, differential calculus


Introduction
In previous semantical investigations [7,6], the first author observed that it can perfectly make sense to extend linear logic and the lambda-calculus with
differential constructions. From these observations, he derived with the sec- ond author in [8] a differential lambda-calculus, which is a lambda-calculus equipped with a notion of formal differentiation (and new term constructions

1 This work has been supported by the ACI project GEOCAL
2 Email: ehrhard@iml.univ-mrs.fr
3 Email: regnier@iml.univ-mrs.fr



1571-0661 © 2005 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2004.06.060


corresponding to differentials). In the same paper, it is moreover advocated that derivation is a very natural operation from an operational viewpoint: it corresponds to the possibility of feeding a term (of type A → B for instance)
with exactly one copy of its argument. In other words, taking the derivative of
a term means extracting the linear part of the term, where “linear” takes here its logical (or computer science) meaning of “using ones argument exactly once”.  One of the main ideas developed in [8] is precisely that this logical
notion of linearity coincides with the mathematical meaning (remember that the derivative, in mathematics, is the best linear approximation of a func- tion). This idea is further reinforced by a result relating the Taylor formula to the linear head reduction strategy of the lambda-calculus (the reduction implemented by Krivine’s machine for instance).

Exponentials and differentiation.
In the present paper, our goal is to give a linear logic account of this extension of functional languages with differential constructs. More precisely, motivated by the structures of the models mentioned above, we want to express the differential operations developed in the differential lambda-calculus as new
operations on the exponential “!” of linear logic. Remember that, in linear
logic, the structural operations of weakening and contraction obtain a logical status thanks to the introduction of the two exponential modalities “?” and “!”, which are De Morgan dual of each other (through linear negation, which is involutive). So exponentials are responsible for the possibility of erasing and copying data, which is of course essential during computations. In linear logic without exponentials, a proof uses linearly its hypotheses.
In K¨othe spaces [7] as well as finiteness spaces [6], formulae are interpreted as topological vector spaces, and proofs of linear logic as linear continuous maps between these spaces. Then exponentials appear as “symmetric tensor algebra” constructions [3]. In linear logic, an intuitionistic implication A ⇒ B is translated as !A B (where this symbol corresponds to linear implica- tion). In the models considered here, linear maps from !X to Y can be seen as “analytic functions” (that is, functions definable by a power series) from the vector space X to the vector space Y . For each space X, the space !X is equipped with the following structure, which is standard from the viewpoint of linear logic:
There is a map !X → X (dereliction) and a map !X → !!X (digging) which are natural and turn “!” (which must be a functor) into a comonad. The basic use of dereliction (which also explains its name) is that, by compo- sition on the left, it allows to turn a linear function from X to Y into an analytic function from X to Y (it is a forgetful operation: linear functions


are particular analytic functions).
There is a map !X → 1 (where 1 is the unit of the tensor product) and a map
!X → !X ⊗!X which correspond respectively to weakening and contraction. These maps turn !X into a ⊗-comonoid (co-algebra). Contraction allows to turn a two-parameter analytic function f into a one-parameter g defined by g(x) = f (x, x). Similarly, given a vector y of Y , seen as a linear function from 1 to Y (1 is the field and this map is just the linear function t '→ ty), by composing on the left with weakening, we define the constant analytic function X → Y , with value y.
In these models, as we have said, the morphisms of the (cartesian closed) Kleisli category of the comonad “!” can naturally be seen as analytic functions, and therefore can be differentiated. Classically, the derivative of a function f : X → Y is a function f ' : X → (X   Y ) such that for each x ∈ X, the linear function f '(x) (the derivative of f at point x) is the “best linear approximation” of the function X → Y which maps u ∈ X to f (x + u) ∈ Y (the general definition is local). Of course, if the function f is “very regular” (for instance, smooth or even analytic) then the derivative f ' will have the same degree of regularity. In the analytic case, differentiation turns a linear function f : !X → Y into a linear function f ' : !X → (X  Y ), that is, f ' : (!X ⊗ X)  Y . It turns out that, just like for the structural logical operations above, f ' can be obtained from f by composing it (as a linear function from
!X to Y ) on the left with a particular linear morphism (!X ⊗ X) → !X. This morphism itself can be defined in terms of more primitive operation on
!X which appear somehow as symmetrical to the above mentioned structural morphisms.
There is a linear map X → !X (co-dereliction) which corresponds to a particular case of differentiation: given an analytic function f : X → Y seen as a linear function !X → Y , by composing f with co-dereliction, we obtain a linear map X → Y which is the derivative of f at point 0. Unlike the transformation of a linear function into an analytic function using dereliction, the transformation of an analytic function into a linear function using co-dereliction is very destructive, since all the non-linear part of the function is forgotten (think of the case where the analytic function is constant).
There is a linear map !X ⊗!X → !X (co-contraction) which has the following effect. Given an analytic function f : X → Y seen as a linear function
!X → Y , by composing f with co-contraction, we obtain a linear map
!X ⊗ !X → Y , that is an analytic function g with two parameters of type
X, which is the function defined by g(x, y) = f (x + y). Similarly, there


is a particular vector in !X (categorically, a linear map 1 → !X), called co-weakening, and whose effect by left-composition on an analytic f seen as a linear map !X → Y is to produce the value f (0). These maps turn !X into a ⊗-monoid (or algebra).
Of course, there is a number of commutations satisfied by these morphisms and the morphisms associated to the “?” modality. One can see the present formalism of differential nets as a graphical presentation of these commuta- tions.


Differential nets.
The exponential fragment of linear logic contains constructions for the weakening, contraction and dereliction operations of “?”; they can be equiv- alently presented in sequent calculus or proof nets formalisms [9]. In proof nets, unary, ternary and binary links (respectively) are associated with these three operations. On the other hand, linear logic has only one rule for “!”,
an introduction rule called promotion. It is certainly the most complicated
rule of linear logic: in sequent calculus, its application requires the context to have a certain shape — all formulae being ?-formulae — and in proof nets, it requires the introduction of boxes, whose main operational effect is to delimit sub-nets to be erased or duplicated as a whole by weakening or contraction
links during cut elimination.
Here we have more rules associated with “!”: co-weakening, co-contraction and co-dereliction, as we have seen. Moreover, among these rules, co-weakening and co-dereliction appear as new introduction rules, exactly as weakening and dereliction are introduction rules for “?”. We can hope that it will make sense to extend proof nets with three new kinds of links associated to these rules,
and even that such a system could exist without promotion, since we have
other ways of introducing “!”-formulae. We develop here such a promotion- free formalism, using Lafont’s notion of interaction nets [11] rather than proof nets 4 .
In interaction nets, logical rules are represented by cells connected with each others by wires through their ports. Each cell has a unique principal port
and reduction occurs between cells connected by their principal ports: this means that the cuts of proof nets are replaced in interaction nets by wires between principal ports (see [12]).

4 This is basically an aesthetic choice: in proof nets, one of our reduction rules, the contraction/co-contraction reduction, would require the introduction of new axiom links in the reduced net, whereas axiom links are kept “implicit” in interaction nets as wires between auxiliary ports of cells.


As we have seen, there is a complete symmetry between ?-cells and !- cells (weakening/co-weakening, contraction/co-contraction and dereliction/- co-dereliction). Strikingly, this symmetry extends to the reduction rules we have deduced from our models: if a redex consisting of two exponential cells connected by their principal ports (a “?”-cell, for instance a dereliction, and a “!”-cell, for instance a co-contraction) reduces to a net π, then the dual redex obtained by swapping “?” and “!” reduces to π where “?” and “!” are swapped.
One fundamental point which departs this syntax from standard interac- tion nets or proof nets is that, just like in [8], we are obliged to consider sums of nets, due to the fact that our reduction is “non-deterministic” (this point is extensively discussed and illustrated in [8]). These sums are created by the dereliction/co-contraction and co-dereliction/contraction reduction rules (the 0-ary versions of these rules, dereliction/co-weakening and co-dereliction/- weakening yield zero nets, where 0 is the neutral element of the sum). In spite of this non-determinism, the calculus enjoys the Church-Rosser conflu- ence property, as soon as reduction is properly extended to sums. The same phenomenon was already observed in [8]).

Correctness.
Not all nets obtained by connecting together tensor, par, weakening, con- traction, dereliction, co-weakening, co-contraction and co-dereliction cells are correct differential interaction nets. Obviously, it does not make sense to con- nect two tensor cells through their principal ports for instance. We avoid such ill-formed nets by introducing a typing system allowing recursive types and we prove that this notion of typeability is preserved under reduction. But being typeable in such a system is not enough for a differential net to be accept- able 5 : just as in multiplicative proof nets, a correctness criterion is needed. In ordinary linear logic, a proof net satisfying the Girard, or Danos-Regnier [5] criterion (for instance, but others have been designed) has the fundamental property of being sequentializable [9], which means that it comes from a proof in the sequent calculus of linear logic. Here we do not propose any sequent calculus corresponding to our interaction nets (though such a calculus exists, and sequentialization certainly holds), but we nevertheless define a correct- ness criterion, obviously inspired by the Danos-Regnier criterion: contraction is handled like a par and co-contraction like a tensor. What we prove is that this criterion is preserved under reduction, which guarantees that the normal forms of correct nets (typeable nets satisfying the criterion) do not contain

5 At least from a logical viewpoint. Such “incorrect” nets might be interesting from a purely computational viewpoint.


cycles (deadlocks). We also sketch a proof that all nets satisfying this criterion are strongly normalizable.
Observe that this criterion is the only feature of the presented formalism which breaks the symmetry between its positive (⊗, !) and negative ( , ?) connectives.

Resource lambda-calculus.
Finally, we try to illustrate the connection between these nets and lambda- calculus. Of course, since we have decided to exclude promotion from this pre- sentation, it is impossible to translate the (differential) lambda-calculus in dif-
ferential interaction nets 6 . But fortunately, lambda-calculi with a linear no-
tion of application have been designed and studied by various authors [2,1,10], and it is possible to extract from such formalisms promotion-free fragments, what we do here, defining a resource lambda-calculus where the basic operation
of substitution is a partial derivation operation. We translate this calculus in differential interaction nets. We shortly discuss the issue of adding promotion (and hence ordinary application) to this calculus.
Our differential nets can really be seen as a non-deterministic extension of multiplicative proof nets of linear logic, with exponential operations of contraction and co-contraction considered as multiplexing operators allowing several agents to communicate in a common “broadcast area”, and dereliction and co-dereliction transforming agents into communicating agents. This view- point strongly suggests to address the possible connections between differential nets and process calculi.

Syntax and reduction rules
General interaction nets.
We assume to be given a collection of symbols. Each of these symbols is given together with a nonnegative integer, its arity.
An interaction net consists of the following data:
a finite set P of free ports;
a finite set C of cells, each cell c being given with a symbol l(c) (and the pairs (c, i) where i is a nonnegative integer at most equal to the arity of c are called connected ports);
a set W of wires together with a function ∂ mapping each wire to a set of 0 or 2 (free or connected) ports, and such that the collection of these sets

6 This is actually not quite true: lambda-terms can be interpreted as generally infinite sums of differential nets, by Taylor expanding all applications.


be a partition of the set of all ports.
Each cell c ∈ C has a particular port (c, 0) which is called its principal port, the others being called auxiliary ports.
A cell of symbol α of arity n is usually pictured as follows:

the singled out port on the right being the principal port, and the other ports on the left being the auxiliary ports. Interaction always occurs between two cells connected by their principal ports (such an interaction net is called a
redex ), and consists in replacing this redex by a given interaction net (de-
pending only on the redex) having the same “free ports”. To be more precise, a redex is a net

p1 	
.
pl 	
	 q1
.
	 qr

reducing to a net with the same ports p1,..., pl, q1,... , qr, and which only depends on α and β:

p1 		q1
.	.
pl 		qr

This means that if the redex occurs within an interaction net π as follows

then this interaction net reduces to



An oriented wire is a wire w ∈ W such that ∂w has two elements, together with an ordering of these elements (that is, an ordered pair (p1, p2) with ∂w =
{p1, p2}). Such an oriented wire w will be naturally pictured as an arrow, and can obviously be reversed into a wire w∗. Typing 7 a net will consist in associating to each of its oriented wires a formula of linear logic, with the constraint that the formula associated to w∗ must be the linear negation of the formula associated to w.
When dealing with interaction nets, we shall not use this completely formal presentation which would lead to very boring developments. We shall stay at a more informal level, but all of our reasonings can be formalized.

Differential interaction nets.
We consider the following symbols. First, we have two multiplicative cells of arity 3: the tensor cell and the par cell, depicted as follows, together with their typing rules:
A	A

B	B
For each of the two exponentials, we have 3 cells of respective arities 1, 2 and 3. We give them together with their typing rule.
Weakening and co-weakening (or application to 0):

Dereliction and co-dereliction (or derivation at 0):

Contraction and co-contraction (or convolution product 8 ):
	
?A	!A
The interaction nets built with these cells will be called simple nets, and general nets will be linear combinations of simple nets. We shall see that reducing simple nets gives rise in general to non trivial linear combinations. These linearly combined simple nets must have the same free ports, which will

7 We shall give later a more precise definition of net typing.
8 This terminology comes from an analogy with distributions, see the end of [7].


be considered as the free ports of the linear combination itself. This allows to connect together general nets and not only simple nets, through their free ports. To turn such a connection of linear combinations of simple nets into a general net, we simply apply multi-linearity. In this way, we are reduced to
considering only simple nets and linear combinations thereof. More precisely, if
we have two nets π and ρ, both of which are sums of simple nets (π = Σl	πi

and ρ = Σr	ρ
i=1

common free ports p1,... , pn (of course, π and ρ can have other free ports), then the result of this operation is the sum of the l × r simple nets obtained by connecting 9 πi with ρj through the ports p1,... , pn for all i, j.


Reduction rules.
The first reduction rule concerns the multiplicative cells and it is com- pletely standard.

Tensor/Par.
A⊥	A
~

B⊥	B
One has to be careful about the fact that the ports of a cell have indexes and reduction respects these indexes. We have written here these indexes (0, 1 and 2) explicitly for both cells. This is also essential for typing: if the port 1 of a ⊗ cell is connected to an incoming wire of type A and the port 2 to an incoming wire of type B, then any outcoming wire connected to its principal port 0 will
carry type A ⊗ B (and not B ⊗ A!). Similarly for  cells, of course. A priori,
one has also to take this into account for contraction and co-contraction cells. But we shall see in the reduction rules that they are actually commutative (this point will be made more explicit in future work).
Next come the rules concerning the exponential cells. As we shall see, they are completely symmetrical.

Co-weakening/weakening.
This yields nothing (or more precisely, a multiplicative nothing), as follows:

9 This operation should be defined precisely and the correct definition would be rather long because each of the two connected nets can contain wires w with ∂w consisting of two elements belonging to {p1,..., pn}; such wires can be connected in the resulting net
just like electric extensions, and these composed wires must be reduced to standard ones, producing possibly loops in the resulting net (wires w with ∂w = ∅). But there is of course no conceptual difficulty here.



		~

This means that if a simple net contains the weakening/co-weakening redex, it reduces to the same net, but without this redex.
We justify this rule as follows. Imagine that we have a (simple) net π with conclusion B, and that we build a constant function f : A → B of value π as the following net

Applying this function to the value 0 amounts to building the net, whose only pending wire is of type B:

Obviously, the value of this expression is π, which justifies the reduction rule.

Co-weakening/dereliction and co-dereliction/weakening.
These rules cancel completely simple nets. Let us start with the dereliction/co- weakening which has a ludics flavor (if we identify co-weakening with daimon):


~


... 

where the box on the right-hand side denotes the 0 net, with the same free ports as the left-hand net.
As an intuitive justification, consider the following situation, where π can be considered as a linear function from A to B.



The complete net above, with conclusions ?A⊥ and B has therefore to be considered as an “analytic” function from A to B which happens to be linear: this is precisely the purpose of the dereliction cell. Plugging a co-weakening as follows
amounts to applying this linear function to 0, and we obtain the value 0 of type B, as prescribed by our reduction rule. In this reduction, the whole simple net π disappears (whether connected or not) and our initial configuration is replaced by a 0-net of type B.
The co-dereliction/weakening interaction is completely symmetrical.


~


... 

Again, let us give an intuitive justification. Using a weakening cell, we can build a constant “analytic” function f form A to B, which always take the value corresponding to π:

The following net represents then the derivative of f at point 0


	
which indeed must be a linear function from A to B. This function must be null since f is constant. This is exactly what our reduction rules prescribes.

Co-weakening/contraction and weakening/co-contraction.
Both rules are duplications. The first rule is as follows.

!A
~
!A

As a justification, consider the following net, where π represents an analytic function f (y, z) with two parameters (named here y and z for notational con- venience, and that we indicate in the picture below) of type A and value of type B

This net represents the analytic function g from A to B such that g(x) = 
f (x, x). Building the net

amounts to apply the function g to 0, which clearly produces the same result as the following net (which corresponds to f (0, 0)).



The second reduction rule is symmetrical to that one.

?A
~
?A

Consider indeed the following net, which represents a constant function f
(with value b of type B, represented by π), and with one parameter of type A

Then we build the following two parameter function g by plugging a co- contraction cell
 
This function is defined by g(y, z) = f (y + z) = b and is just a two parameter constant function, in accordance with our reduction rule which produces the following net

?

?A⊥


Co-dereliction/dereliction.
This is a simplification without much surprises.
A
~	

Consider again the following net

which represents an analytic function f from A to B which happens to be the linear function h represented by the net π. Then the following net

represent the linear function f '(0), the derivative of f at point 0; it is well known that this function must be h, in accordance with our reduction rule.

Co-contraction/dereliction and contraction/co-dereliction.
Both situations lead to sums as follows. The first rule is
!A


!A

!A
~	+



Consider once more the net



which represents an analytic function f from A to B which happens to be the linear function h represented by the net π. Then the following net

y z



represent the two parameters analytic function g given by g(y, z) = f (y + z). By linearity of f , we have g(y, z) = f (y)+ f (z). But this latter expression is represented by the following sum of simple nets


y
y	+	z
z


In the first summand, the variable z is not used, whence the weakening cell, and symmetrically for the second summand. This is exactly the equation implemented by the reduction rule under consideration (taking into account our conventions on distributivity).
Strikingly enough, the contraction/co-dereliction configuration leads to a completely symmetrical pattern, but for rather different mathematical reasons.
?A


?A
?A
~	+
?A


Consider indeed the following net, where π represents an analytic function f (y, z) with two parameters (named here y and z for notational convenience, and that we indicate in the picture below) of type A and value of type B

This net represents the analytic function g from A to B such that g(x) = f (x, x). Then the following net represents the linear function g'(0), from A to B

Given a vector u of type A, we know (by the usual laws of calculus) that
g'(0) · u = f ' (0, 0) · u + f ' (0, 0) · u (f ' (0, 0) and f ' (0, 0) are the two partial
y	z	y	z
derivatives, computed at point (0, 0), which are linear functions from A to B).
This latter expression corresponds to the following sum of nets



+



which is the net obtained by applying the co-dereliction/contraction reduction above, as well as our convention on distributivity.

Co-contraction/contraction.
This is just the standard rule of bi-algebras.


!A	?A⊥


~
!A	!A


We have typed the wires of the right-hand net in various different ways for illustrating our conventions. Consider again the following net, where π repre- sents an analytic function f (y, z) with two parameters of type A and value of type B

This net represents the analytic function g from A to B such that g(x) = 
f (x, x). Plugging a co-contraction, we get the net


y′ z′





which represents the two parameters function h given by h(y', z') = f (y' + z', y' + z'). Now it is clear that the following net represents exactly the same function. Here, the variables y' and z' are duplicated before being added, whereas in the net above, duplication was performed after addition; the result is obviously the same, in accordance with our reduction rule.
!A	?A⊥
y′





z′


What we have defined so far.
To be precise, we have defined a relation ~, which is a relation from simple nets to nets (actually, sums of 0, 1 or 2 simple nets only). This relation will be called simple one step reduction and will be generalized later, when we shall be concerned with the confluence issue.


Example of reduction.
Consider the following simple net (the reader can check that it is typeable).

We suggest the reader to try the following game: on the right side of this configuration, connect a simple net π representing a bilinear function f (y, z), taking two parameters of type A, and yielding values of type B, as follows:

Using the above explanation about the cells as operating on analytic func- tions, try to figure out what should be the function corresponding to this configuration, and compare your computation with the following reduction.
There is only one redex, and the reduction yields

a simple net with 4 redexes. Each of these redexes leads to a sum of two simple nets. So we obtain a sum of 16 simple nets, 14 of which will disappear reducing to 0 as we shall see. After reducing the upper-left redex, we get a sum of two similar simple nets π1 and π2:

+


We consider only the first of these nets. If now we reduce the upper-right redex, we get




+


In the right-hand term of this sum, we have a co-dereliction/weakening redex which annihilates completely this simple net, and the sum reduces to its first member. Reducing the lower-left redex in this net, we get

+


The right-hand member of this sum contains a co-dereliction/weakening re- dex and therefore reduces to 0. In the left-hand member, we can fire the weakening/co-weakening redex, which vanishes, and the co-contraction/dere- liction redex, leading to

+


The right-hand term of this sum reduces again to 0 (it contains a dereliction/- co-weakening and a co-dereliction/weakening redex), whereas the first net, after having fired the weakening/co-weakening and the two dereliction/co- dereliction redexes, leads simply to



Performing the same computation on π2, we obtain

Finally, the normal form of our simple net is the sum of these two wirings:

+


Weak typing
The nets defined in the previous section can contain pathological patterns con- sisting of two cells connected by their principal ports and for which we have given no reduction rules — for instance two tensor cells connected by their principal ports — or can reduce to nets containing such pathological pat-


terns. We therefore introduce a very weak typing system which will have the following two key features:
a weakly typeable net contains no pathological pattern (weak correctness), and
if π is weakly typeable and π reduces to π', then π' is also weakly typeable (subject reduction).
Let us assume to be given a denumerable set A of type variables. Types are defined by the following syntax.
If α is a type variable, then α and α¯ are (atomic) types. The atomic type
α¯ corresponds to the linear negation of α and is called a “negated type
variable”.
If A and B are types, then A ⊗ B and A	B are types.
If A is a type then !A and ?A are types.
If A is a type, then A⊥ is defined by induction using the De Morgan laws

of linear logic (with of course α⊥ = α¯
and (α¯)⊥ = α). An important op-

eration is substitution of a formula for a type variable within another for- mula; this is defined as usual, and requires (for the negated occurrences of the substituted variable) computing linear negations “on the fly”. For instance,
(α ⊗ α¯) [!β/α] = !β ⊗ ?β¯


Typing a net.
Let π be a simple net. To the cells c of π, we associate pairwise disjoint sets of type variables Sc and we assign types to all ports of all cells (considered conventionally, for each cell, as oriented toward the outside) as follows. We also assign to each free port of π a type variables, these variables being distinct
from each other and distinct from the variables assigned to connected ports. This assignment of types to ports will sometimes be called the primitive type assignment of π.
If c is a tensor or a par cell, then Sc must have two elements α1 and α2, and the types associated to the ports are

α¯1 α¯2
α1 ⊗ α2
α¯1 α¯2

α1	α2

If c is an exponential cell, then Sc must have one element α, and the associated types are

!α	?α



α¯	!α

?α¯ 
!α
?α¯ 
α¯	?α

!α¯ 
?α
!α¯ 

Warning: for a technical reason related to the dereliction/co-contraction and co-dereliction/contraction reduction rules, in the case where c is a weakening or co-weakening cell, and only in these cases, we allow also the unique element of Sc to be a negated type variable.
In this way, each port of π receives a type. We define now a set Eπ of equations between types: it is the set of all the equations A  B⊥ where A and B are types associated to ports related by a wire in π. Up to renaming of type variables, this set of equations is uniquely defined and depends only on π.
A set E of equations between types is called a simultaneous recursion (fol- lowing [4]) if E = {α1  A1,... , αn  An} (we use the symbol “ ” rather than “=” for denoting these formal equations) where the αi’s are pairise distinct
type variables and the Ai are types which are not of the shape β¯ (negated atom) 10 .
Let π be a simple net, and let p1,... , pk a repetition-free list of its free ports. We say that the simple net π is weakly typeable of type A1,... , Ak if there is a simultaneous recursion E such that E ▶eq Eπ where ▶eq stands for standard equational reasoning (with the multiplicative and exponential
connectives of linear logic as function symbols, and substitution defined as explained above) and E ▶eq ϕi = Ai⊥ for i = 1,...,k (where ϕi are the type variables associated to the free ports pi by the primitive type assignment of π). In this situation, we write

E ▶ π | p1 : A1,... , pk : Ak


Subject reduction.
The first property of this notion of typing is subject reduction.  If π is a simple net, if E ▶ π | p1 : A1,... , pk : Ak and if π reduces to a sum
of simple nets Σn	πn, then there is a simultaneous recursion E' such that
E' ▶ πj | p1 : A1,... , pk : Ak for each j.
This is proved by simply examining each reduction. We just consider the two most complicated cases. Assume that π is of the shape

10 The purpose of this restriction is to avoid the dramatic cyclic definition α α¯; we have no trouble with equations between positive atoms, we shall see that they are necessary.



Then we know that E ▶eq G1  !α, E ▶eq G2  !α, E ▶eq !α  !β¯, E ▶eq G3  β and E ▶eq ϕj  Aj⊥ for j = 1,... , k. According to the co-contraction/- dereliction reduction rule, this net reduces to a sum of two simple nets π1 + π2; we consider only π1, the other one being similar:

We have kept the same primitive assignment for the subnet ρ, and we have introduced fresh type variables γ and δ for the cells obtained by reducing the redex under consideration (warning : for the new weakening cell c, we have taken Sc = {γ¯}). Of course, this primitive assignment induces the same types as above for the free ports of ρ (namely, ϕ1,... ,ϕk, G1, G2 and G3).
Let E' = E ∪ {γ α, δ β}. Then E' is a simultaneous recursion. By hypothesis, and since E' ⊇ E, we know that E' ▶eq Eρ and E' ▶eq ϕj  Aj⊥ for j = 1,... , k. Moreover, E' ▶eq G1  !α, hence E' ▶eq G1  !γ since E' ▶eq γ  α. Similarly E' ▶eq G3  δ. Last, by hypothesis we have E' ▶eq G2  !α,
and also E' ▶eq !α   !β¯. But ▶eq δ   β, hence E' ▶eq !α   !δ¯. Therefore
E' ▶eq G2  !δ¯, and finally E' ▶ π1 | p1 : A1,..., pk : Ak. One checks easily
that, with a similar extension of E' as a simultaneous recursion E '', one has E '' ▶ π2 | p1 : A1,... , pk : Ak (and of course E '' ▶ π1 | p1 : A1,... , pk : Ak remains valid).
The case of a co-dereliction/contraction reduction is completely similar.
Last, let us consider the co-contraction/contraction reduction. So we start with a simple net of the shape



We know as above that E ▶eq G1   !α, E ▶eq G2   !α, E ▶eq !α   !β¯, E ▶eq G3  ?β, E ▶eq G4  ?β and E ▶eq ϕj  Aj⊥ for j = 1,... , k. Firing this redex, we obtain the following simple net π'.
Again, we assume that the type variables αi and βi are fresh.  Let E' = E ∪{αi  α, βi  β | i = 1, 2} which is a simultaneous recursion. Then we have E' ▶eq G1  !α and E' ▶eq !α  !β¯ by hypothesis, hence E' ▶eq G1  !β¯1; the
equations concerning G2, G3 and G4 are dealt with similarly. The “internal” equations such as E' ▶eq !β¯1 = !α2 result from E ▶eq !α  !β¯ and from the four equations we have added to E.
The other reduction rules are similarly simple to deal with.
Observe that this general notion of typing subsumes the simple typing outlined at the beginning of the paper: a net π with ports p1,... , pn is simply typeable with type Ai for port pi iff E ▶ π | p1 : A1,..., pn : An with a recursion E = {αj  Bj | i = 1,..., m} such that, for each j and each l ≤ j, the variable αj does not appear in the type Bl (such a recursion will be called loop-free).

Weak correctness of weakly typed nets.
Let us say that a net is weakly correct if it contains no pathological pattern. It is very easy to prove that a weakly typed net is weakly correct. It suffices to consider the set T of infinite types built with the connectives “⊗”, “ ”, “!” and “?”. A valuation I : A → T can be extended to all finite types in the


obvious way. Given a set E of equations, let us write I |= E if I(A) = I(B) for all equation A  B belonging to E. Equational reasoning on types is sound with respect to this semantics: if E ▶eq E' and I |= E, then I |= E'. Now we conclude observing first that, if E is a simultaneous recursion, there exists a valuation I : A → T such that I |= E (this is fundamentally due to our restriction that simultaneous recursions cannot contain equations of the shape α = β¯ where α and β are type variables, and to the fact that, in a
simultaneous recursion, a type variable cannot occur twice as left member of an equation), and second that if for some valuation I, one has I |= Eπ, then the simple net π is weakly correct.

Confluence
One of the nice features of Lafont’s interaction nets is that they enjoy the Church-Rosser property in the strongest sense: the diamond property holds for the one-step reduction. This will also be the case here, but we have to be careful when extending the one-step reduction ~ to arbitrary nets (that is, to sums of simple nets).
An adequate definition of this concept is the following. Let π be a net
which is a sum π = Σn	πi of simple nets, and let π' be another net. We

say that π


i=1

π' if π' = Σn
π' where for each i, π' = π

Observe that when π is simple, then the original notion of simple one-step
reduction coincides with this new notion, so it makes sense to keep the same notation for both. Observe also that if π1 and π2 are nets and if πi ~ π' for i = 1, 2, then π1 + π2 ~ π' + π' . This may seem weird for a notion of
1	2
one-step reduction, but one must keep in mind that the sum represents a kind
of non-deterministic superimposition of simple nets.
Now the following statement is easy to check. Let π, π1 and π2 be nets. If π ~ πi for i = 1, 2, then π1 = π2 or there exists a net π' such that πi ~ π' for i = 1, 2. From our definition of one-step reductions for general nets, we can restrict our attention to the case where π is simple. For producing π1 and π2, we choose two redexes in π, that we can of course assume to be distinct. If none of these redexes is a co-dereliction/contraction or dereliction/co-contraction redex, then we conclude as in standard interaction nets, using the fact that reduction is purely local (there is of course the case where one of the redexes
is a co-dereliction/weakening or co-weakening/dereliction, but in that case we can converge to the 0 net).
Assume for instance that one of the redexes is a co-dereliction/contraction redex and that the other one is a co-contraction/dereliction redex, so that our


net π has the following shape:

Reducing the left redex, we obtain in one step the following sum


+


Now reducing the right redex in both terms of this sum, we obtain in one step again the following sum, which we also obtain from the original net by reducing first the right redex, and then the left redexes (up to associativity
and commutativity of addition, of course):


+




+	+



Acyclicity criterion
We extend the Danos-Regnier criterion for multiplicative proof nets to the present setting. We shall not prove a sequentialization theorem, simply be- cause we do not present here any sequent calculus corresponding to these nets. The criterion is nevertheless essential because it will prevent the appearance of cyclic structures during reduction, and thereby insure strong normalization. Let π be a simple net. A switching is a map S from the set of par and contraction cells of π to the set {1, 2} (the names of the auxiliary ports of the cell). Given such a switching S, we define a non-oriented graph G(π, S). The nodes of this graph are the ports of π. Let p and q be two ports of π, there is
an edge between p and q in G(π, S) if
there is a wire between p and q in π, or
p and q are the two ports of a dereliction or co-dereliction cell, or
p and q are the principal port and one of the auxiliary ports of a tensor or of a co-contraction cell, or


p and q are the principal port and the port i (i = 1 or i = 2) of a par or of a contraction cell c such that S(c) = i.
We say that π is acyclic if G(π, S) is an acyclic graph (a forest) for each switch- ing S of π. We cannot require connexity as one usually does in multiplicative linear logic because this property is not preserved by the co-contraction/- dereliction reduction (the redex itself is a simple net without par or contrac- tion cells and which gives rise to a connected graph, whereas each summand of the result of the reduction gives rise to is a disconnected graph; this problem might be solved by introducing an edge between the weakening cell and the dereliction cell, but we do not care so much about connexity anyway here).



Preservation under reduction.
The main property is again that this acyclicity property is preserved under
reduction: if an acyclic simple net π reduces to a sum Σn	πi of simple nets,
then each of the πi’s is acyclic. The proof is a simple checking of all the possible reductions, as we did in the previous section for subject reduction. Let us concentrate on the tensor/par and on the contraction/co-contraction reductions, the other ones obviously reducing the connectivity of the net.
Consider first the case where π has the following structure 11 (we have given names to the ports involved in the reduction):

Due to the acyclicity of π, we must have p /= q, p /= q', p' /= q and p' /= q'. To be more precise, what we have pictured here is not a simple net, but two simple nets, namely ρ and the considered redex consisting of c and d, these two simple nets being connected by identifying the free ports p and r, p' and r' etc. As far as acyclicity is concerned, this is harmless.
The reduced net π' is


11 This case is well known by the way, since it corresponds to the standard correctness criterion of MLL proof nets. We give the proof here for self-containedness, and because it corresponds to a sub-case of the other case.



Let S be a switching of π', that is, a switching of the subnet ρ. Assume toward a contradiction that the graph G(π', S) has a cycle C = (p1,... , pn) (so pi are pairwise distinct ports of π', such that pi and pi+1 as well as pn and p1 are connected in G(π', S), and moreover n ≥ 3). Then C must contain both wires w and w'. Indeed, if it contains none, then C is a cycle in G(ρ, S) which is impossible since G(ρ, S) is acyclic because ρ is a subnet of π which is acyclic. If C passes only through w, then extend S to the switching S1 of π which maps the par cell d to 1; it is clear that C is a cycle in the graph G(π, S1), contradiction.
So we can assume without loss of generality that p1 = p and p2 = q, and that there exists i < n such that
i > 2, pi = p' and pi+1 = q', or
i > 2, pi = q' and pi+1 = p'.
In the first case, consider the switching S1 of π obtained by extending S with
c '→ 1. The corresponding graph is

In this graph, (q, p3,... , pi−1, p', r', r'', s'', s) is a cycle which contradicts the acyclicity of π. In the second case, both switching S1 and S2 (where d '→ 2) provide the cycle (p, r, r'', r', p', pi+2,... , pn).
Consider now the co-contraction/contraction situation, in a simple net π:



By reducing this redex, we obtain the following simple net π':

and we must show that G(π', S') is acyclic, whatever be the switching S' of π' that we consider. Such a switching is obtained by extending a switching S of ρ by giving values 1 or 2 to the two contraction cells d1 and d2. Up to symmetries, there are only two such extensions: S' which maps d1 to 1 and d2 to 2, and S' which maps d1 and d2 to 1. The first switching produces a graph G(π', S' ) whose acyclicity is obtained exactly as in the tensor/par situation above. The second switching produces the following graph G(π', S' ):

whose acyclicity results from the acyclicity of G(π, S1) where S1 is is the switch- ing of π which is equal to S on ρ and maps d to 1.
We shall say that a net is correct if it is weakly typeable and acyclic. As we have seen, if π is correct and reduces to π', then π' is also correct. A simple net, even if it is simply typeable, can have infinite reductions, as shown by the following example.



The trouble with this net is of course that it contains a cycle (put the con- traction switch on the lower position). The main property of correct nets is that they enjoy strong normalization.





Co-contraction and contraction trees.
We call contraction trees the simple nets generated by the following in- ductive definition (we define in the same induction the principal port and the auxiliary ports of a contraction tree).
A weakening cell is a contraction tree, whose principal port is the principal port of the cell and which has no auxiliary ports.
If τ1 and τ2 are contraction trees with disjoint sets of ports, and with prin- cipal ports p1 and p2 respectively, then the net obtained by plugging p1 and p2 to the auxiliary ports of a contraction cell c is a contraction tree, whose principal port is the principal port of c, and whose auxiliary ports are those of τ1 and τ2.
In a completely similar way, one defines the notion of co-contraction tree.
A contraction tree τ with auxiliary ports p1,... , pn will typically be pic- tured as follows.
p1


We adopt similar conventions for co-contraction trees.





Generalized reduction.
Observe that the reduction rules involving a contraction cell or a co- contraction cell generalize in the obvious way (but now with several steps of reductions of course). For instance






p1	q1
~∗




where σ1,... , σn are n disjoint copies of σ, and similarly for the τj’s. As another examples, we have the following reduction, which generalizes both co-dereliction/contraction (m = 2) and co-dereliction/weakening (m = 0) reductions.
q1
!
q1	.
p	qi
~∗	i=1	!
.


We define a new relation from simple nets to nets ~g as the reduction which takes these as elementary steps (plus the tensor/par reduction, still considered as an elementary step). We extend this relation to general nets as we did for
~. This new reduction relation is clearly included in ~∗.




Weak normalization (sketch).
We outline a proof that ~ is a (weakly) normalizing reduction; strong normalization follows, by the diamond property of ~, established in section 4.
If π is a simple net, its pure size |π|P is the number of tensor, par, dere- liction and co-dereliction cells in π. Its structural size |π|S is the number of contraction and co-contraction cells (we do not count weakening and co-
weakening cells as one might have expected here).
In the present context, let us call structural redex a co-weakening/weaken- ing, co-weakening/contraction, weakening/co-contraction or co-contraction/- contraction redex. By examining the auxiliary ports of the two cells involved in such a redex R (whose principal ports will be denoted l and r) within a simple net π, we observe that such a redex is uniquely embedded into a subnet of π which has the following structure



p1	q1


where
τ is a co-contraction tree and σ is a contraction tree;
no port pi is the principal port of a co-contraction tree of π and
no port qj is the principal port of a contraction tree of π.
This structure will be called the generalized structural redex associated to R. Observe moreover that if π is correct, by acyclicity, one has pi /= qj for each i = 1,... , n. Therefore, when reducing this generalized structural redex, no new structural redex is created: this is the key observation in our proof sketch.
Let S(π) be the number of structural redexes in π.
If π is a correct simple net, we define its measure M(π), a triple of non- negative integers, by setting M(π) = (|π|P, S(π), |π|S) if π is not normal, and M(π) = (0, 0, 0) if π is normal. We extend this notion of measure to arbitrary
correct nets π = Σn	πi (where the πi’s are simple and correct) by setting
M(π) = maxn	M(πi), triples of integers being ordered under the lexicographic
order.
We define now a particular reduction (a non-deterministic reduction strat- egy) first as a relation from correct simple nets to correct nets as follows. Let π be a correct simple net and let π' be a net, we say that π ~w π' if
π contains a dereliction/co-weakening or a co-dereliction/weakening re- dex and π' = 0, and else if
π contains a tensor/par or a dereliction/co-dereliction redex and π' is obtained from π by reducing this redex, and else if
π contains a structural redex and π' is obtained from π by reducing the associated generalized structural redex (in the sense of the generalized reduction defined above), and else if
π contains a dereliction/co-contraction or a co-dereliction/contraction re- dex and π' is obtained from π by reducing this redex.
Observe then that π ~∗ π' (and hence π' is correct) and that M(π') < M(π) (for the lexicographic order on triples of integers). Observe also that if π is
a correct simple net which is not normal, then π ~w π' for some net π' since one of the four cases enumerated above must occur. We extend this reduction
relation to arbitrary correct nets as follows: if π is a sum Σn	πi of simple

'	'	Σn	'

i=1
'


and π ~w π' for this extended notion of reduction, then π ~∗ π' (and hence
π' is correct) and M(π') < M(π). This proves that our reduction ~ is weakly
normalizing, as announced.

Interpreting the resource lambda-calculus in differ- ential nets
The resource lambda-calculus (or lambda-calculus with multiplicities) has been invented by Boudol [2] and further studied also by Curien and Lavatelli [1]. The work of Kfoury [10] develops the same line of ideas consisting in intro-
ducing, within an ordinary lambda-calculus, the idea of linear application, a 
new kind of application where the argument is provided exactly once to the function. The motivations of these authors were quite different, but their basic idea of linear application can be recast in our setting as differential application.
Let us consider a version of the resource lambda-calculus where application is really linear (not affine). The syntax we define has two sorts (simple 12 terms and simple poly-terms) which are defined by mutual induction as follows. As usual, we are given a denumerable supply of variables.
If x is a variable, then x is a simple resource term.
If x is a variable and s is a simple resource term, then λx s is a simple resource term.
If s is a simple resource term and S is a simple poly-term (sometimes called a bunch in the literature), then ⟨s⟩ S is a simple resource term.
If s1,... , sn are simple resource terms, then [s1,... , sn] (the multi-set con- sisting of these terms, repetitions being taken into account) is a simple poly-term.
In the present setting, we find convenient to use the following more alge- braic notations for multi-sets representing simple poly-terms: 1 represents the empty simple poly-term, if t is a simple resource term, t also denotes the simple poly-term [t], and if S and T are simple poly-terms, then ST is the sum (the concatenation) of the multi-sets S and T . From now on we drop the adjective “resource” everywhere and say “term” instead of “resource term”. Let ∆ be the set of all simple terms and ∆! be the set of all simple poly-terms Let R be a ring 13 . If U is a set, we denote by R⟨U ⟩ the free R-module

12 As before, “simple” means here not being a linear combination.
13 We can use arbitrary coefficients as long as normalization issues are not concerned, for
our resource terms as well as for differential nets: this point is discussed in [8]. As set R of coefficients, we can also take a semi-ring, which is like a ring apart from the fact that the additive monoid is not supposed to be a group; the set N of natural numbers is a typical


built on U , that is the set of all finite formal linear combinations of elements of U with coefficients in R. The elements of R⟨∆⟩ are called terms, and the elements of R⟨∆!⟩ are called poly-terms. All syntactic constructions on simple terms and poly-terms are extended to arbitrary terms and poly-terms
by linearity (when they are unary constructions) or bilinearity (when they are
binary constructions). For instance, if s = Σn	aisi is a term which is a linear
combination of the pairwise distinct simple terms si, then





and if S = Σn
n
λx s =	aiλx si
i=1

aiSi is a poly-term which is a linear combination of the
m

which is a linear combination of the pairwise distinct simple poly-terms Tj, then


ST =
n,m


i=1,j=1
aibjSiTj .





Substitution and partial derivation.
Substitution of a term t for a variable x in a simple term or poly-term σ (we use this kind of Greek letter for denoting a term or poly-term, when we do not want to make a distinction between these two sorts) is defined as usual
by induction on σ (warning: t is not assumed to be simple, so the result is not
simple in general, and one uses the generalized syntactic constructions defined above by multilinearity). This operation is then extended to arbitrary σ by linearity; it is linear in σ but not in t. A particularly important case is when t = 0: if σ contains at least one free occurrence of x, then σ [0/x] = 0, and otherwise σ [0/x] = σ.
More important is the operation of partial derivation of terms and poly- terms, in the direction of a given term. Given a variable x and a term u, by induction on the simple term or poly-term σ, we define ∂σ · u (linear in σ and
in u) as follows.



semi-ring.


∂y · u =  u	if y = x
∂λy t · u = λy   ∂t · u	where we assume of course that y /= x
∂⟨s⟩ S · u =  ∂s · u  S + ⟨s⟩  ∂S · u 
∂x	∂x	∂x
n

∂[s1,... , sn] · u = Σ[s ,... ,s	, ∂si · u, s

,... ,s ]

Observe that with our notations for poly-terms, ∂1 · u = 0 and ∂ST · u =

 ∂S · u T + S  ∂T · u 
∂x	∂x
∂σ · u



∂σ · (Σ u ) = Σ ∂σ · u
∂x
∂σ · u is then extended by linear-

ity to arbitrary terms and poly-terms σ.  The basic commutation property
of this operation is the following equation, which is a syntactic version of Schwarz Lemma:
 ∂   ∂t · u  · v =  ∂   ∂t · v  · u +  ∂t ·  ∂u · v 

where we assume that x does not occur free in v. In particular, if we assume moreover that y does not occur free in u, then the two partial derivatives commute (whence the name we gave to this property).

Reduction.
A redex is a simple term s of the shape s = ⟨λx t⟩ T (so t and T are simple). A redex reduces to a term which is not simple in general. If T = 1, then s reduces to t [0/x], and if T = uU , then s reduces to λx  ∂t · u  U (of course, T can be written as a product uU in various different ways in general and thus this redex can reduce to various different terms in general). This notion of reduction is then defined for arbitrary simple terms and poly-terms (and not simply redexes) by extension to contexts. We denote by ~ the corresponding reduction relation, which is thus included in (∆ × R⟨∆⟩) ∪ (∆! × R⟨∆!⟩) (and more precisely in (∆ × N⟨∆⟩) ∪ (∆! × N⟨∆!⟩). This relation can be extended to arbitrary terms and poly-terms (with coefficients in R) as we did in [8]. But here, when we are concerned with reduction, we assume for simplicity that R = N, and we extend ~ to arbitrary linear combinations as we did for differential nets.
This notion of reduction enjoys confluence as well as strong normalization. Confluence results from the syntactic version of Schwarz Lemma we mentioned


above. Strong normalization is essentially trivial, as reducing a simple term or poly-terms, one obtains a sum of terms or poly-terms whose all elements have less symbols than the original term.




Translation.
We define a translation of simple terms and poly-terms to correct simple nets which are typeable in a simultaneous recursion E which is a loop-free recursion to which we add the two following equations involving two distinct type variables ι and o:

ι = !o ⊗ ι	and	o  ?ι	o

Such a net will be said to be DR-typeable (in reference to the pure proof nets of Danos and Regnier, which have the same kind of typing, see [13]).
Let l be a list ((x1, p1),... , (xn, pn)) where the xi’s are pairwise distinct variables and the pi’s are pairwise distinct free ports (in other words, l is a finite partial injection from variables to free ports). Given a simple term or poly-term σ whose all free variables are contained in the domain {x1,..., xn} of l, and given a free port p not belonging to the image {p1,... , pn} of l, we
define a simple differential net σ∗ whose free ports are p1,... , pn and p. This
net will be typeable as follows

p1	pn  p
where α = o when σ is a simple term, and α = !o when σ is a simple poly-term. The definition is by induction on σ. If σ is a variable, and hence σ = xi
for a uniquely determined i ∈ {1,..., n}, then σ∗ is







If σ = λx t, then σ∗ is
?	?
?ι	?ι
... 
p1	pi	pn	p






?	o
p1	pn



p
where q, p' are distinct free ports, distinct from p and from the pi’s. If σ =
⟨s⟩ S, then σ∗ is
p′′
!o


!o	o
?ι	?ι	o
′ ...	′	′	⊗
1	n



?ι	... ?ι
′′	′′
1	n



?	?

?ι	?ι	o
... 
p1	pn	p
where l' = ((x1, p' ),... , (xn, p' )) and l'' = ((x1, p''),... , (xn, p'')) are finite
1	n	1	n
injections such that l, l' and l'' have disjoint images, and p, p' and p'' are distinct free ports, not belonging to the union of these images.
Let us turn now to the interpretation of poly-terms. If σ = 1, then σ∗ is



... 
p1

pn	p

If σ = [t] where t is a simple term, then σ∗ is



p
Last, if σ = ST , then (with the same notational conventions as in the case of
an application) σ∗  is



?ι
′
1 ... 
?ι  !o
′
n
?ι
′′
1 ... 
?ι  !o
′′
n

p′′


?	?
!

?ι	?ι
...	!o
p1	pn
p
Due to this last case, the translation is not exactly deterministic, because there are many ways of decomposing a poly-term as products. But the various nets obtained are equivalent (in a sense to be defined in future work) simply because all co-contraction trees having the same arity are equivalent, and similarly for contraction trees.
A straightforward induction shows that the simple differential nets ob- tained in that way are DR-typeable as well as acyclic, and thus correct. More-
over, it can be checked that if t ~∗ t', then t∗ ~∗ t'∗ . The main ingredient
in the proof of this property is the following Substitution Lemma. Let σ be a simple term or poly-term, u be a simple term, l, l' and l'' be finite injections from variables to free ports whose common domain V contains all free vari- ables of u, and which have disjoint images, and let p, p' and p'' be distinct free ports, not occurring in the images of l, l' and l''. Let x be a variable which does not belong to V and let q be a free port different from all those introduced so far. Then the differential interaction net



	


?ι	... ?ι  ?ι
′	′
1	n
α	o	?ι
!
... ?ι
′	′
1	n





?	?


?ι	?ι
... 
p1	pn	p
reduces to  ∂σ · u ∗ ; this is proved by induction on σ, of course.





A few words about promotion.
This resource calculus is essentially finitary, in the sense that it lacks the usual application operation of lambda-calculus which allows for arbitrary du- plications. Observe that duplication is present here (we have a contraction cell in our differential nets), but is not a real duplication in the sense of lambda- calculus: here, when a poly-term (multiset of simple terms) is “duplicated” by a contraction cell, it is cut into two disjoint pieces which are communicated to the two auxiliary ports of this cell; this is done in all possible ways, whence the sums which appear during the reduction.
The finitary nature of this calculus is revealed by its strong normalization property which holds even in the untyped case. For obtaining the full power of lambda-calculus (and in particular the possibility of representing all partial
recursive functions), one has to introduce a promotion operation (in the sense
of promotion in linear logic, which turns a proof of !A   B into a proof of !A   !B). In the present resource calculus, promotion is represented by a new way of constructing poly-terms, similar to the t '→ t∞ construction of Boudol’s resource lambda-calculus, or π-calculus [14], and which plays exactly the same role of providing a potentially infinite supply of t.
So given a simple term t, we introduce a new simple poly-term exp0(t), which corresponds to the promotion of t. The intention behind this construc- tion is that exp0(t) is equal to the an infinite “exponential” sum, where the


exponents have to be understood in the sense of the product of poly-terms:

∞	n

exp0
t =		t  n!
n=0

assuming of course that this makes sense with our choice of R (take for instance
R to be a field).
The reason for the index 0 in exp0 t is that if we want to keep our calculus finite (no infinite terms appearing during computations), then we have to equip our promotion with a rule similar to the “t∞ = (t|t∞)” rule of the π- calculus. One way to proceed is to say that exp0 t = 1 + t exp1 t, exp1 t =
1+ t exp2 t,... ,expn t = 1 +  t  expn+1 t, and so our extension of the syntax
2	n+1
consists in introducing, for each simple term t and nonnegative integer n, a new
poly-term exp t corresponding to the series Σ∞  n!  tk. We can consider
the equation expn t = 1 +  t  expn+1 t as part of the reduction, saying that expn t ~ 1 +  t  expn+1 t but this of course has the serious drawback of preventing strong normalization to hold, even in the simply typed case. It is
certainly wiser to implement this equation by saying that


⟨λx s⟩ exp
t ~ s [0/x]+   1  λx  ∂s · t   exp	t. 


Of course, to complete this extension of the resource lambda-calculus, one has to say what ∂expn s ·t should be in general. Fortunately, this does not require the introduction of new term constructions, but surprisingly introduces negative coefficients. The reader will check easily that the following equation holds, when one expands the expn’s into power series:

∂expn s · t =	exp
∂x	n
  n 
s −	exp
n +1 


n+1
s	∂s · t
∂x

where, again, the product has to be taken in the sense of poly-terms mul- tiplication (for n = 0, this is just the fact that the exponential is its own derivative).

References
G´erard Boudol, Pierre-Louis Curien, and Carolina Lavatelli. A semantics for lambda calculi with resource. Mathematical Structures in Computer Science, 9(4):437–482, 1999.
G´erard Boudol. The lambda calculus with multiplicities. Technical Report 2025, INRIA Sophia-Antipolis, 1993.


Richard Blute, Prakash Panangaden, and Robert Seely. Fock space: a model of linear exponential types. In Proceedings of the Ninth Conference on Mathematical Foundations of Programming Semantics, number 802 in Lecture Notes in Computer Science. Springer-Verlag, 1993.
Felice Cardone and Mario Coppo. Decidability properties of recursive types. In Carlo Blundo and Cosimo Laneve, editors, ICTCS, volume 2841 of Lecture Notes in Computer Science, pages 242–255. Springer-Verlag, 2003.
Vincent Danos and Laurent Regnier. The structure of multiplicatives. Archives for Mathematical Logic, 28, 1989.
Thomas Ehrhard. Finiteness spaces. Mathematical Structures in Computer Science, 2000. To appear.
Thomas Ehrhard. On Ko¨the sequence spaces and linear logic. Mathematical Structures in Computer Science, 12:579–623, 2002.
Thomas Ehrhard and Laurent Regnier. The differential lambda-calculus. Theoretical Computer Science, 309(1-3):1–41, 2003.
Jean-Yves Girard. Linear logic. Theoretical Computer Science, 50:1–102, 1987.
Assaf J. Kfoury. A linearization of the lambda-calculus. Journal of Logic and Computation, 10(3):411–436, 2000.
Yves Lafont. Interaction nets. In Seventeenth Annual Symposium on Principles of Programming Languages, pages 95–108, San Francisco, California, 1990. ACM Press.
Yves Lafont.	From proof nets to interaction nets.	In J.-Y. Girard, Y. Lafont, and
L. Regnier, editors, Advances in Linear Logic, pages 225–247. Cambridge University Press, 1995. Proceedings of the Workshop on Linear Logic, Ithaca, New York, June 1993.
Laurent Regnier. Lambda-Calcul et R´eseaux. Th`ese de doctorat, Universit´e Paris 7, January 1992.
Davide Sangiorgi and David Walker. The pi-calculus: a Theory of Mobile Processes. Cambridge University Press, 2001.
