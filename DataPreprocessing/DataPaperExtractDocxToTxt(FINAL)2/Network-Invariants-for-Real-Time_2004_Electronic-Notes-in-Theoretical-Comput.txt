	Electronic Notes in Theoretical Computer Science 98 (2004) 57–74	
www.elsevier.com/locate/entcs




Network Invariants for Real-Time Systems

Olga Grinchtein1	Martin Leucker2
IT Department Uppsala University Uppsala, Sweden

Abstract
We extend the approach of model checking parameterized networks of processes by means of network invariants to the setting of real-time systems. We introduce timed transition structures (which are similar in spirit to timed automata) and define a notion of abstraction which is safe with respect to linear temporal properties. We strengthen the notion of abstraction to allow a finite system, then called network invariant, to be an abstraction of networks of real-time systems. In general the problem of checking abstraction of real-time systems is undecidable. Hence, we provide sufficient criteria, which can be checked automatically, to conclude that one system is an abstraction of a concrete one. Our method is based on timed superposition and discretization of timed systems. We exemplify our approach by proving mutual exclusion of a simple protocol inspired by Fischer’s protocol, using Weizmann’s model checker TLV.
Keywords: model checking, network invariants, parameterized systems, superposition


Introduction
Model-checking is a method for verifying concurrent systems in which the computations of a high-level description of a system are compared to those formulated by a logical requirement specification to establish that they are compatible. Checking linear temporal logic (LTL) specifications of finite-state systems is well understood. Faced with concurrent systems consisting of an arbitrary number of processes working in parallel, however, model checking is more challenging, since we have to deal with unboundedly many states. A

1 Email: Olga.Grinchtein@it.uu.se
2 Email: Martin.Leucker@it.uu.se This author is supported by the European Research Training Network “Games”.

1571-0661 © 2004 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2003.10.006

fruitful approach for checking these parameterized systems, as they are often called, is by use of abstraction and network invariants.
The idea of abstraction is to check a smaller finite-state system instead of the original one. If the smaller system provides more computations, compris- ing those of the original one, every linear temporal logic property it satisfies, also holds for the original system. For branching-time logics, similar ideas work if we restrict the logic to a universal fragment [6]. Abstractions of original sys- tems may either be found manually or using ideas of abstract interpretation. In the first case, one has to prove that the abstract system indeed comprises all computations of the original one. Basic principles underlying the construction of abstract models are understood from e.g., [8,7,9].
Verification by means of network invariants was introduced in [19] and turned into a working method in [14]. In a nutshell, the idea can be sketched as follows. Suppose we have a finite-state process Φ, e.g., repeatedly requesting and releasing some resource. We want to reason about a setting in which an arbitrary number of instances of Φ work in parallel. In other words, we study the system Φ1  ···  Φn, where the number n of instances of Φ is not known in advance. While for every n, we deal with a finite system, it is clearly not possible to check the system iteratively for all n.
Using the idea of abstraction, it suffices to find a finite-state system ΦA which satisfies our requirement specification and which abstracts Φ1  ···  Φn for arbitrary n. Similar to induction over natural numbers, the latter is implied—with some further constraints—if ΦA is an invariant, i.e., ΦA is an abstraction of Φ as well as of ΦA  ΦA. The first item shows that Φ  ···  Φ can be abstracted by ΦA  ···  ΦA, which can further be abstracted by ΦA, using the second requirement.
In this way, checking a parameterized system is reduced to finding a pos- sible network invariant that satisfies the requirement imposed on the param- eterized system and proving that it is indeed a network invariant. Finding a possible invariant is usually carried out manually, and checking whether it satisfies the requirement specification can be done automatically using model checking. Proving that a system is a network invariant can be reduced to checking abstraction, which can be done automatically for finite-state sys- tems. This approach is elaborated for checking linear-time specifications of fair discrete systems in [13] where also techniques for finding invariants are discussed.
Traditional techniques for model checking do not admit explicit model- ing of time, and are thus unsuitable for analysis of real-time systems. Alur and Dill introduced timed automata to model behaviour of real-time systems. Furthermore, model-checking techniques were developed [4].

In this paper we study the problem of reasoning about parameterized timed systems. To the best of our knowledge, this is the first approach for studying network invariants in the sense of [19] for networks of timed systems.
We follow the outline of [13], in which parallel systems of fair discrete systems were examined, but enrich the underlying systems with clocks to model timed behaviour. We extend the notion of abstraction and network
invariant to the timed setting. A main contribution of the paper is a procedure
for checking whether a given timed transition structure is an abstraction of another one.
We introduce timed transition structures which are similar to timed au- tomata.  The main differences are that we distinguish private and global
variables and that communication is by shared variables instead of message passing. Thus, our communication model is closer to Java-like concurrent programming languages.
We say that ΦA is an abstraction of Φ if ΦA comprises at least the computa- tions of Φ. The idea is used, e.g. in [1]. We show that our notion of abstraction
is safe with respect to linear temporal logic, i.e., linear-time properties of an abstract system also hold for a concrete one. Provided further environmental
behaviour is taken into account, we show that checking whether a system is a network invariant can be reduced to proving abstraction.
Note that although clocks can be understood as real valued variables, they are different from ordinary data variables since time progresses for all clocks synchronously. If time δ passes for clock x, then it also passes for clock y. Treating clocks just as real valued variables would disregard this “hidden” correlation of clocks and lead to wrong conclusions. This implicit dependency of clocks is one of the obstacles to overcome when extending the approach of networks invariants to the setting of real-time systems.
We provide sufficient criteria, which can be checked automatically, to con- clude that a system is an abstraction of a concrete one. Our method is based on timed superposition [12]. The superposition of Φ and ΦA is a structure similar to a timed transition structure, whose computations can be projected to computations of Φ and ΦA, where as best as possible, ΦA tries to follow the
moves of Φ. We show that if the superposition satisfies certain LTL properties, ΦA is indeed an abstraction of Φ.
To check whether a superposition satisfies LTL properties, we use the no- tion of discretization of timed transition structures, developed by [10] and [5], which have an infinite state space, to obtain finite-state systems, maintaining
satisfaction of LTL properties. This allows us to use standard verification tools, like TLV [16].
As a by-product, our work also clarifies so-called module checking in the

setting of real-time systems.
Our approach is exemplified by proving mutual exclusion of a simple pro- tocol inspired by Fischer’s protocol, using Weizmann’s model checker TLV [16].
We restrict ourselves to finite domains of data variables. Using predicate abstraction (see [11], [13]), it should be possible to extend our results to sys- tems with variables ranging over infinite domains.
Systems similar to our timed transition structures have been studied in [15]. The approach is based on automatic abstraction, but is limited to checking safety properties of timed systems with integer time domain. A different approach for studying parameterized systems is presented in [2] and [3]. It is based on finite symbolic representation of infinite sets of states and computing pre-images and convergence. It was shown that reachability for such systems is decidable if each process has a single clock. Our method is also applicable for verifying liveness properties of systems with an arbitrary number of clocks.
Since we develop our theory in the setting of LTL, our notion of abstraction is based on set inclusion of computations. When considering branching-time logics, simulation becomes natural for defining abstraction. This approach was studied for timed systems [18] and it was shown that simulation is decidable.
The question of network invariants, however, was not addressed. Note that simulation is a stronger relation than language inclusion, i.e., it might be easier to find a network invariant when abstraction is based on language inclusion rather than on simulation.
In the next section we define timed transition structures. Section 3 recalls
the syntax and semantics of LTL (in the timed setting). In Section 4 we develop the verification scheme using network invariants, we define discretiza- tion of timed transition systems and prove that our discretization is correct with respect to LTL properties. We illustrate our approach in Section 5. We conclude the paper by summing-up our results.

Timed Transition Structures
A time domain I is a totally ordered monoid with a least element equal to the neutral element. Usually, we consider I = R+, the set of nonnegative reals, and I = IN, the set of natural numbers (including 0).
A clock, denoted by x, x1,... , is a variable which is interpreted over a time domain. Given a finite set of clocks C = {x1,... , xn}, a clock valuation is a function v : C → I that assigns to every clock x ∈ C a time. If I = R+, we denote by [v(x)♩ (respectively Tv(x)²) the integer (fractional) part of x
with respect to a given clock valuation v. Let v + t and v ↓reset for t ∈ I 

and reset ⊆ C denote the clock valuations that satisfy (v + t)(x) = v(x) + t for all clocks x ∈ C and, respectively, (v ↓ reset )(x) = 0 for x ∈ reset and (v↓reset )(x) = v(x) for x ∈/ reset .
If C is a set of clocks, the set XC of clock constraints is the set of Boolean combinations of atomic formulas of the form x ∼ c, where ∼∈ {<, ≤, >, ≥} and c ∈ IN.
Definition 2.1 A tuple Φ = (D, C, W, O, Θ, λ, Π) is a timed transition struc- ture (TTS) where
D = {d1,... , dr} is a finite set of discrete variables ranging over finite domains. Let D be the set of (data) valuations where a (data) valuation maps the variables in D to their domain.
C = {x1,... , xn} is a finite set of clocks, each ranging over R+. Clocks cannot be data variables.
Additional to the clocks in C, a TTS has a master clock, denoted by now , which is not modified by any transition. We denote by C¯ the union of C with now .
We call V = D  C¯ 3 the set of system variables and S = D × RC¯ the set of states of Φ. Thus, a state is of the form (κ, v) where κ is a valuation and v is a clock valuation, which assigns to every clock in C¯ a time. We denote
s(d) and s(c) the value of variable d and value of clock c in state s.
W ⊆ V is a finite set of owned variables, which cannot be modified by the environment.
O ⊆ V is a finite set of variables which the environment can observe. We require V = W ∪ O. We require now to be observable, i.e., now ∈ O.
Θ is the initial condition, which is a set of assertions (first-order formula) over states characterizing the initial states. It is required that at initial states all clocks are equal to 0.
λ ⊆ D ×D × XC × 2C is the transition table. An entry (κ, κ', g, reset) ∈ λ should be read as: move from state with valuation κ to a state with valuation κ' if the guard g is satisfied, and reset the clocks listed in reset .
Π = ∨κ∈Dϕκ → pκ is the time-progress condition, where φκ is an assertion, which holds at the state with valuation κ and pκ ∈ XC for κ ∈ D.
We call variables in O also global variables, the ones in O − W shared, and the elements of W − O local variables. Global, shared, and local clock and data variables are defined in the expected manner.

3 X  Y denotes the disjoint union of X and Y .




[x≥1]
[x ≤ 2]





Fig. 1. Example

Example 2.2 A simple example of a TTS is shown in Figure 1. We have (data) variables d and s. d indicates that a resource is busy and might also be changed by other processes running in parallel while s just identifies whether the system is in the initial phase or has started. We set d as observable while s is assumed to be local. We have a single clock x. From the initial state where s and d equal 0, the system can proceed to the next state, if at least one time unit has elapsed. Sometimes, we add a label like s := 1 to an edge to stress that exactly the variable s has changed when taking this transition. In the second state, the system can remain until time reaches 2, or, it moves to the third state where the value of d is flipped.
Let us fix a TTS Φ = (D, C, W, O, Θ, λ, Π) (with |C¯| = n) for the rest of this section. For a TTS, we distinguish two types of transitions, −→RT and

tick
λ	'	'	'

−→RT , both subsets of S × S. We write s = (κ, v)−→RT s = (κ ,v ) iff there
exists (κ, κ', g, reset ) ∈ λ such that v |= g, v' |= pκ' , and v' = v ↓ reset . In
other words, we move from s to s' if the time progress condition of κ' and the transition’s guard is satisfied and reset the clocks listed in reset . In this

case, we call s' a λ-successor of s. We write s = (κ, v) tick
s' = (κ', v') iff the

transition is only caused by some time delay δ, that is, if κ' = κ and there is a δ > 0, such that v' = v + δ and ∀0 ≤ t ≤ δ : v + t |= pκ. In this case, we call s' a tick-successor of s. Thus, a timed transition structure Φ induces an
infinite-state transition system, denoted by [Φ]RT = (S, −→RT ) with states S

and transition relation −→RT
= −λ→
tick
RT ∪ −→RT .

A run of Φ is a finite or infinite sequence of states π = s0, s1,... such
that s0 ▶ Θ (initiality) and for each j ≥ 0 sj−→RT sj+1 (consecution). If furthermore the value of now grows beyond any bound (time divergence), we
call π a computation of Φ. Formally, we require that for every c ∈ R+ there is a j ∈ IN such that sj(now ) > c. When comparing computations of two timed transition structures, we are usually only interested in observable variables. Let ocomp(Φ) = {π|O | π is a computation of Φ} where for a computation π = s0, s1,... we denote by π|O the sequence s0|O, s1|O,... 
If a TTS is running in parallel with an environment (for example other instances of the same process), the environment might change shared data variables or reset shared clocks. We therefore study also the computations of a

TTS when put into an arbitrary environment. Let λenv = {(κ, κ', true, reset ) |
κ(d) = κ'(d) if d ∈ W and reset ∩ W = ∅} denote possible changes of an
environment respecting owned variables. We write s = (κ, v)−λe→nv RT s' = (κ', v') iff there exists (κ, κ', true, reset) ∈ λenv with v' = v↓reset .
A modular run of Φ is a finite or infinite sequence π = (s0, λ)(s1, m1) ... 
of states and markers in {λ, env, tick } such that s0 ▶ Θ (initiality) and

for each j ≥ 0 s −λ→RT
sj+1
and mj+1
= λ, s −λe→nv
RT s
j+1
and mj+1
= env

and not s −λ→RT
sj+1
, or s
tick
j −→RT
sj+1
and mj+1
= tick . π is called a mod-

ular computation, if time diverges.  We denote by mocomp(Φ) = {π|O |
π is a modular computation of Φ} the set of modular computations restricted to observable variables. For a modular computation π = (s0, m0)(s1, m1) ... we denote by π|O the sequence (s0|O, m0)(s1|O, m1) ... 
Let Φ1 = (D1, C1, W1, O1, Θ1, λ1, Π1) and Φ2 = (D2, C2, W2, O2, Θ2, λ2, Π2)
be two TTSs with D1 ∩ C2 = D2 ∩ C1 = ∅. We say that Φ1 and Φ2 are composable if W1 ∩ W2 = ∅, W1 ∩ O2 = ∅ and W2 ∩ O1 = ∅. In other words, Φ1 and Φ2 own different variables and have only observable variables in common. The parallel composition of Φ1 and Φ2, denoted by Φ1  Φ2, is defined if Φ1 and Φ2 are composable and is the TTS Φ = (D, C, W, O, Θ, λ, Π), where
D = D1 ∪ D2, C = C1 ∪ C2, W = W1 ∪ W2, O = O1 ∪ O2 Π = Π1 ∧ Π2,
Θ = Θ1 ∧ Θ2, and λ is the largest relation in D× D × XC × 2C that projected onto the variables of Φi conforms with λi for i ∈ {1, 2}. Note that the parallel composition is commutative, i.e., Φ1  Φ2 = Φ2  Φ1.
To simplify our presentation, we silently assume that whenever we build the parallel composition of two TTSs, they are composable.


Linear Temporal Logic
As a requirement specification language we use a stutter-invariant version of linear temporal logic (LTL). A model for a temporal formula p is an infinite sequence of states π = s0, s1,... , where each state s provides an interpretation for the variables in p. A state formula is constructed out of propositions stating properties of observable data variables and time variables, where the latter are restricted to clock constraints, and the Boolean operators ¬ and ∨. A temporal formula is constructed out of state formulas to which we apply the Boolean
operators and the temporal operator U (until ). As opposed to general LTL,
we do not consider a next-state operator, since the notion of next state is not clear in the setting of (dense) timed systems.
Given a model π, we present an inductive definition for the notion of a temporal formula p holding at a position j ≥ 0 in π, denoted by (π, j) |= p.

For a state formula p, (π, j) |= p ⇔ sj |= p,
(π, j) |= ¬p ⇔ (π, j) |= p,
(π, j) |= p ∨ q ⇔ (π, j) |= p or (π, j) |= q,
(π, j) |= p U q ⇔ ∃k ≥ j(π, k) |= q and for every i such that j ≤ i < k, (π, i) |= p.
As usual, additional temporal operators can be defined, such as  p =
true U p and  p = ¬ ¬p.
If (π, 0) |= p, we say that π satisﬁes p and write π |= p. A formula p is called valid, if p holds on all models.
Given a TTS Φ and a temporal formula p, we say that p is Φ-valid denoted by Φ |= p if p holds on all models that are computations of Φ. The notion extends to modular validity by considering modular computations instead.

Verification by Network Invariants
In this section, we define the concept of network invariants for parameterized systems built-up from timed transition structures. We reduce the problem to model checking certain formulas of the superposition of two timed transition structures. For the latter, we show how to construct discretized systems that can be checked using a standard LTL model checker.

Network Invariants and Continuous Time
Given two TTSs Φ and Φ', we say that they are comparable, if O = O', O ∩ W = O' ∩ W ', that is, they have the “same” observable variables. To simplify our presentation, let us fix two comparable TTSs Φ and ΦA for this section. We start by defining the notion of abstraction for timed transition structures.
Definition 4.1 We say that ΦA is an abstraction of Φ, denoted by Φ ±RT ΦA, iff ocomp(Φ) ⊆ ocomp(ΦA) and call Φ the concrete system and ΦA the abstract system.
Thus, ΦA is an abstraction of Φ, if for every computation of the concrete system projected to observable variables, there is a computation of the abstract system with the same projection. It is easy to see that the abstraction relation is transitive.
Example 4.2 The TTS shown in Figure 2 is an abstraction of the one ex- plained in Example 2.2. We recall that d was the only observable vari- able in the previous example and that the only observable computation is







d := 0


Fig. 2. Example
(d = 0)(d = 0)(d = 1)(d = 0)(d = 1) .. .. This is obviously contained in the observable computation of the TTS shown in Figure 2.
The abstraction relation is safe in the following sense:
Theorem 4.3 Let p be an LTL formula. If ΦA |= p and Φ ±RT ΦA then
Φ |= p.
Note that the other direction is not true in general, i.e., if ΦA does not satisfy a property p, Φ still might do so.
The basic idea of network invariants is captured by the following theorem:
Theorem 4.4 If Φ and ΦA satisfy
(I1)  Φ ±RT ΦA,
(I2)  for all TTSs Ψ we have Φ  Ψ ±RT ΦA  Ψ,
(I3)  ΦA  ΦA ±RT ΦA, and
(I4) for all TTSs Ψ we have (ΦA  ΦA)  Ψ ±RT ΦA  Ψ, then Φ  ···  Φ ±RT ΦA.
Proof. Φ  ···  Φ can be abstracted by ΦA  Φ  ···  Φ due to (I2). Because of commutativity this is equal to Φ  ΦA  Φ  ···  Φ. This can, again because of (I2), be abstracted by ΦA  ΦA  Φ  ···  Φ. Iterating this argument and using transitivity of the abstraction relation, we get that Φ  ···  Φ ±RT ΦA  ···  ΦA. Note that we silently assumed to have more than one copy of Φ. For a single copy (I1) gives the same argument. Using (I3) and (I4), it can be easily seen that ΦA  ···  ΦA ±RT ΦA. Altogether, this means Φ  ···  Φ ±RT ΦA.	 
Note that the previous theorem can be simplified in the following way: Take Ψ to be a copy of Φ but removing unobservable variables, then Φ  Ψ equals Φ. Thus (I2) implies (I1) and (I4) implies (I3). 4
Theorem 4.4 suggests the following strategy to verify properties of a net- work: Find an abstraction ΦA, check whether it satisfies the properties in question and prove (I1)–(I4). However, (I2) and (I4) are not constructive in

4 Taking Ψ to be an “empty” TTS will serve the same duty.



[x > 1]
[x = 1]
[x > 1]


		
Fig. 3. Example
the sense that it requires to check for all TTSs Ψ. Therefore, we are after a stronger abstraction relation making the approach effective.
Definition 4.5 We say that ΦA is a modular abstraction of Φ, denoted by Φ ±M ΦA, iff mocomp(Φ) ⊆ mocomp(ΦA).
Modular abstraction is what we are looking for:
Theorem 4.6 If Φ ±M ΦA then for all TTSs Ψ we have
Φ  Ψ ±RT ΦA  Ψ

Proof. We give a sketch of the proof. Given a computation of Φ  Ψ for an arbitrary system Ψ, we can construct a modular sequence by marking transitions of Ψ as environmental moves. Modular abstraction states that, when restricting this sequences to observable variables of Φ, it is also one of ΦA restricted to observable variables. A careful study now shows that with transitions of Ψ this sequence can be concretized to a computation of ΦA  Ψ. 
The previous theorem yields (I2) and, taking Φ = ΦA  ΦA also (I4). Although it seems straightforward, it only holds because we required clock now to be observable:
Example 4.7 Consider the TTSs Φ, ΦA, and Ψ shown in Figure 3 without the implicit observable clock now . In all modular computations of Φ and ΦA restricted to observable variables we observe that 0 is assigned to d. We would conclude that Φ ±M ΦA. However, one computation of Φ  Ψ is d = 1; d = 0,
which is not possible in ΦA  Ψ. Requiring now to be observable reveals that
Φ /±M ΦA.
How to show that Φ ±M ΦA? Using results from timed automata, it is easy to see that this question is undecidable, unlike in the case for discrete systems. We therefore concentrate on sufficient conditions. We use the idea of superposition (extended to the timed setting), followed by discretization of time.
The superposition of two TTSs Φ and ΦA is a TTS assuring that ΦA tries best in simulating Φ. Furthermore, we allow extra determinization conditions to be provided by the user. We add a Boolean data variable mis, which is

true iff it was not possible for ΦA to follow Φ or the user’s determinization condition is too limiting.
Definition 4.8 For two composable and comparable timed transition struc- tures Φ = (D, C, W, O, Θ, λ, Π) and ΦA = (DA, CA, WA, OA, ΘA, λA, ΠA) we
define their superposition sp(Φ, ΦA, Θd, λd) to be the timed transition struc-
ture ΦS = (DS, CS, WS, OS, ΘS, λS, ΠS) where
DS = D ∪ DA  {mis}, CS = C ∪ CA,
WS = W ∪ WA ∪ {mis}, OS = O ∪ {mis} = OA ∪ {mis},
ΘS = (Θ ∧ ΘA ∧ Θd ∧ (mis = false)) ∨ (Θ ∧ ¬(ΘA ∧ Θd) ∧ (mis = true)), ΠS = Π ∧ ΠA,
Θd is an assertion over DS, such that Θ → Θd|D,
CS	'
λd ⊆ DS × DS × XCS × 2	, such that (κ, κ , g, reset ) ∈ λ implies that there
is (κˆ, κˆ', gˆ, r^eset ) ∈ λd with κˆ|D = κ, κˆ'|D = κ', g → gˆ, and r^eset |D = reset ,
λS = λˆS ∩ λd where λˆS ⊆ DS × DS × XC × 2CS with (κ, κ', g, reset) ∈ λˆS if one of the following holds:
if κ(mis) = f alse no mismatch has occurred yet. We distinguish:
· if there is a g' such that (κ|D, κ'|D, g', reset |C) ∈ λ, let gΦ be the dis-
junction of all such g'. Let gΦ	be the disjunction of all g' such that

(κ|DA
, κ'|D
, g', reset |C
) ∈ λA, where the empty disjunction is false.

'
Then we require g = gΦ ∧ gΦA and κ (mis) = false, stating that both
guards of the systems are satisfied and no mismatch is found, or, g = gΦ ∧ ¬gΦ and κ'(mis) = true describing the case that Φ could move but not ΦA, so that a mismatch is found
· or, taking an environmental transition, we require g = true, κ(d) = κ'(d) if d ∈ W , reset ∩ W = ∅, and κ'(mis) = false
if κ(mis) = true then we require g = true, κ = κ', and reset = ∅
In simple words, the superposition unites the variables of both structures, combines the initial and progression condition in a conjunctive way and allows
steps in both systems to be taken synchronously (item i). If one step is possible in Φ but not in ΦA, we move to a state in which mis = true (item ii) and stay there.
Theorem 4.9 Let Φ and ΦA be two comparable timed transition structures. Let λd and Θd be user-deﬁned determinization conditions. If sp(Φ', ΦA, Θd, λd) satisﬁes

then Φ ±M ΦA.
ΦS |=  ((¬Π ∨ ΠA) ∧ mis = false)	(1)

In (1) we also check the progress condition to guarantee that ΦA can cope

with all tick -transitions of Φ
It now remains to check ΦS |= ((¬Π ∨ ΠA) ∧ mis = false). To be able to use a standard LTL model checker, we employ discretizations of TTSs.

Discretization of Timed Transition Structures
In this subsection we associate to a timed transition structure a finite state transition system satisfying the same linear-time properties. This allows us to use LTL model checkers for finite-state machines for analyzing timed tran- sition structures. We use the discretization given in [10] and [5], though our presentation is different.
First, we define the standard region equivalence relation [4] on clock valuations as follows: Let K denote the greatest constant appearing in guards and invariant conditions of timed transition structure. We let v  v' iff for all x, y ∈ C,
v(x) > K iff v'(x) > K,
if v(x) ≤ K, then [(v(x))♩ = [v'(x)♩ and Tv(x)² = 0 iff Tv'(x)² = 0, and,
if v(x) ≤ K and v(y) ≤ K, Tv(x)² ≤ Tv(y)² iff Tv'(x)² ≤ Tv'(y)².
The equivalence class of a valuation v with respect to  is called a clock region and is denoted by [v].
By definition, every clock region can uniquely be identified by the integer values of the clocks together with an ordering of their fractional parts.  In
other words, for valuations v and v' and sequences 0 ∼1 Tv(xi )² ∼2 ··· ∼n

Tv(xi
)² < 1 and 0 ∼' Tv'(xi )² ∼' ··· ∼' Tv'(xi
)² < 1 we have v   v' iff

n	1	1	2	n	n
[v(xi)♩ = [v'(xi)♩ and ∼i=∼', where ∼i, ∼' ∈ {<, =} for i ∈ {1,... , n}.
i	i
The order of fractional values of clocks can be stored in an array of slots
containing clocks (see Figure 4(a)). The first slot contains all clocks x with
Tv(x)² = 0 and the remaining slots are filled according to the order of the fractional values. 5 While in general n + 1 slots would suffice, we take, for sim-
plicity, 2n slots. We distinguish even and odd slots and follow the convention that whenever one of the fractional values is 0, we only use even slots, while we use odd slots if all fractional values are greater than 0, and draw the array in a two dimensional fashion (Figure 4(b)). It is now obvious that all region equivalence classes can be represented using K-times 2n slots plus one slot for clocks with value K and one for clocks with value greater than K. Figure 4(c) shows the setup for K = 2 and n = 3.
It is now straightforward to define a discretized semantics of a timed tran- sition structure. Let ∆ =  1  be the discretization step. The discretized time

5 Of course, this representation is not unique without imposing further restrictions.

0 <	<	<  < 1


even odd
0


... 
0	1	K


(a) slots
(1b) 2n slo2tns − 1
(c) time domain > K 

Fig. 4. Slots and discrete time domain

domain I∆ is defined as I∆ = {s∆ | s ∈ IN, 0 ≤ s ≤ 2nK +1} (see Figure 4(c). For j ∈ {0,... 2n − 1} we say that clock x occupies slot j if Tv(x)² = j∆ and
call the value of x even (odd) iff j is 0 or even (odd, respectively).
The discretized transition system of Φ, denoted by [Φ]DT , is a finite state transition system (SDT , ΘDT , −→DT ) where the set of states is SDT = D × IC¯, the initial state condition ΘDT agrees with Θ, and −→DT , the transition
λ	tick

relation, is defined as −→DT =
defined as
−→DT ∪ −→DT .  The latter relations are

tick
s = (κ, v)−→DT
s' = (κ, v') iff s tick
(κ, v + ∆) and v' = v+˙ ∆, where

Δ
= min
{x + y, K + ∆} extends to valuations as expected.

s = (κ, v)−λ→DT s' = (κ', v') iff (κ, v)−λ→RT (κ', v'') and,
if there are clocks x with v(x) = 0 and y with odd value then even and odd slots are used and we adjust the fractional part to use only even slots: Let j ∈ {0,... , 2n − 1} be an odd slot which is not occupied by any clock. For v''(x) < K, we set v'(x) = v''(x)+ ∆ if x occupies a slot in {1,... ,j − 1}, v'(x) = v''(x) − ∆ if the occupied slot of x is greater than j. If x occupies slot 0 or v(x) > K, we let v'(x) = v''(x).
else only even slots and slot 0 are used or all slots are odd, and we let
v' = v''.
A run of [Φ]DT is any infinite path of it starting in an initial state. A computation of [Φ]DT is a run in which infinitely many tick -transitions are taken.
Let us check that Φ and [Φ]DT can be identiﬁed with respect to com- putations.  Let (κ, v) ≡ (κ', v') iff κ = κ' and v   v'.  For a computation π : s0, s1,... of Φ, let π¯ be the sequence π¯ : s¯0, s¯1,... which is a subsequence of π in which subsequent states of π are compressed to a single state when they are equivalent with respect to ≡. That is, π¯ : si0 , si1 ,... and satisfies

0 = i0 < i1 < ... , for k, k' ∈ {ij,..., ij+1−1} we have sk ≡ sk' , si
/≡ sij+1
, and

for all j, s¯j ≡ si . We call two computations π, π' of Φ stuttering-equivalent,
denoted by π ≡ π', iff for π¯1 = s¯0, s¯1,... and π¯2 = s¯' , s¯' ,... and all i ≥ 0
0	1
we have s¯i ≡ s¯'. Note that π¯ is stuttering equivalent to π and that π¯ can be considered as a minimal element of all sequences stuttering equivalent to π.

The notion of stutter equivalence carries over to computations of discretized timed transition systems in the expected manner. We now easily see ([10], [5])
Lemma 4.10 [Φ]DT preserves qualitative behaviour of Φ, that is, for each computation π1 of Φ, there exists a computation π2 of [Φ]DT such that π¯1 ≡ π¯2, and vice versa.
Given a TTS Φ and a temporal formula p, we say that p is Φ-valid ([Φ]DT - valid) denoted by Φ |= p ([Φ]DT |= p), if p holds on all models which are computations of Φ ([Φ]DT , respectively).
It is obvious that stutter equivalent computations satisfy the same LTL formulas. Together with Lemma 4.10 this implies:
Theorem 4.11 For every TTS Φ and LTL formula p we have Φ |= p iff
[Φ]DT |= p.
Note that there are different versions for discretizing a timed-transition structure. We found this one, however, easy to realize in verification tools like TLV. Given a timed transition structure, one can define tick -transitions con- sisting of adding time with possible adjustment in a straightforward manner.
To cope with our adjusted notion of computation, we added a binary data vari- able dt to the underlying system, which is swapped whenever a tick -transition is taken. Adding as fairness-constraint that infinitely often dt must be 0 as well as 1, the notion of a fair run coincides with our notion of computation.

The Final Approach
We sum-up our approach in Table 1. Steps i, ii, and v have to be carried out manually, while the remaining items can be done automatically.

Example
We construct a network invariant for a simple protocol in the spirit of Fischer’s protocol [17] but modified to show certain particularities in finding invariants. Fischer’s protocol is used to guarantee mutual exclusion in a concurrent sys- tem consisting of an arbitrary number of processes using clocks and a shared variable.
Our protocol consists of an arbitrary number of instances of the process shown in Figure 5. α ≤ β are two arbitrary integer values. Processes Φ1 and Φ2 can be distinguished from Φ := Φ3 and we study the network N = Φ1  Φ2  Φ  ···  Φ. Each process has a local clock xi and an owned variable
loci ∈ {1,..., 7} indicating the current control location loci = 5 is the initial
state. The processes communicate via a shared variable d. Furthermore, every



Table 1
Verifying network of processes

process has a variable i acting as a process identifier. Control states 1–4 are patterned after Fischer’s protocol, while 5–7 are added to show the need for adding further clocks in invariants, as we will point out below.
When a process is in state 1, it may proceed to state 2, when d equals 0, indicating that no process requested to enter the critical section (state 4). If so, it resets its clock xi. It may remain in state 2 at most α time units. Processes Φ1 and Φ2 (identified by i = 1 and i = 2, respectively) proceed to state 3 requesting the critical section by setting d to i. The other processes just set d to 3 instead of i as in Fischer’s protocol. We have to make this modification to get equal processes Φ3, Φ4,... If a process can enter the critical section after a given time bound β, it moves to state 4, otherwise it proceeds in state 3 or move to state 1. Leaving the critical section, the process moves back to state 1 resetting d.
States 5, 6, and 7 are added to show an example of the hidden dependencies between clocks. State 7 is only reachable if another process in parallel sets d = 4 (by moving from 5 to 6), enabling the guard of the current process to move from 5 to 7). However, since clocks increment simultaneously, this cannot happen, as we will prove.

[d = 0]
xi := 0
5	1


2	xi ≤ α



[xi


≤ β ∧ d = 4]


[xi > β]d := 4




[φ]d := 0



[¬φ]
[d < 4 ∧ i ≤ 2]
xi := 0,d := i
[d < 4 ∧ i > 3] xi := 0,d := 3

7	6	4	3
[φ ∧ xi > β]

φ = ((i ≤ 2 ∧ d = i) ∨ (i > 3 ∧ d = 3))
Fig. 5. An adaption of Fischer’s protocol
We would like to show that neither process Φ1 nor Φ2 can reach state 7 and that never both of them are in state 4, a standard mutual-exclusion property.
It can be formalized by
p =  (loc1 ≤ 6 ∧ ¬(loc1 = 4 ∧ loc2 = 4))
Our goal is to construct a network invariant ΦA satisfying Φ  ···  Φ ±M
ΦA and Φ1  Φ2  ΦA ▶ p.

A natural possible network invariant, denoted by Φc
, is shown in Fig-

ure 6(a). Its state space consists of all possible values of d and the transitions set d according to the destination state. Since ΦA should abstract Φ3, states 1 and 2 (which are shown as a single state to simplify the presentation) are

only reachable by environmental moves. We add to Φc
a clock x to follow the

timing constraints imposed by Φ when moving to states 0 or 4. To preserve
p, we must reset clock x, when 3 is assigned to d.
We can check automatically that Φ ±M Φc . However, if we try to show

that Φc  
c  ±M Φc
we obtain a counterexample: Consider the run of

Φc [1]  Φc [2] given by 6
A	A

(d = 0, x[1] = 0, x[2] = 0) → ··· → (d = 0, x[1] > β, x[2] > β)
→ (d = 3, x[1] = 0, x[2] > β) → (d = 4, x[1] = 0, x[2] > β)

There is a run s0,..., si,... of Φc [3] such that si(d) = 0 and si+1(d) = 3.

Then, since every transition in Φc
which modifies value d to 3 resets x, it

is not possible to take a transition from si+1 to si+2 such that si+2(d) = 4.

Therefore Φc
is not network invariant.

We obtain a network invariant ΦA for example by adding a clock y to Φc

which is never reset and modified by Φc
such that transitions, which set d = 4 

depend only on the new clock. This invariant is shown in Figure 6(b). We can

6 We use the postscript [i] to distinguish local variables of instances of Φ.



x := 0
x := 0
x := 0
x := 0

	

dab:=st4raction
netdw:o=rk4 invariant
Fig. 6. (Possible) network invariants

check successfully that Φ ±M ΦA and ΦA  ΦA ±M ΦA, using the approach developed in the previous section.
Note that in all cases, we did not have to give determinization conditions when constructing superpositions.

Conclusion
In this paper, we presented a method for checking linear temporal logic prop- erties of networks of timed systems. Our approach is based on network in- variants, previously studied for untimed systems. The main ingredients are discretization of superposition to check that a network of processes can be
abstracted by a single timed system.
Acknowledgement: We thank B. Jonsson, Y. Kesten, A. Pnueli, and E. Shahar for pointing out this problem, for fruitful discussions, and for hints on using TLV.

References
Abadi, M. and L. Lamport, The existence of refinement mappings, Theoretical Computer Science 82 (1991), pp. 253–284.
Abdulla, P. A. and B. Jonsson, On the existence of network invariants for verifying parameterized systems, in: Correct system design-recent insights and advances, Springer, 1999
.
Abdulla, P. A. and B. Jonsson, Model checking of systems with many identical timed processes, Theoretical Computer Science 290 (2002), pp. 241–264.
Alur, R., Timed automata, in: Proc. 11th International Computer Aided Verification Conference, Lecture Notes in Computer Science 1633 (1999), pp. 8–22.


Asarin, E., M. Bozga, A. Kerbrat, O. Maler, M. Pnueli and A. Rasse, Data structures for the verification of timed automata, in: O. Maler, editor, Hybrid and Real-Time Systems (1997), pp. 346–360.
Clarke, E., O. Grumberg and D. Long, Model Checking and Abstraction, in: Proceedings of the 19th Annual ACM Symposium on Principles of Programming Languages, ACM, New York, 1992, pp. 342–354.
Clarke, E. M., O. Grumberg and D. Long, Model checking and abstraction, in: POPL92, 1992.
Cousot, P. and R. Cousot, Abstract interpretation: A unified model for static analysis of programs by construction or approximation of fixpoints, in: POPL77, 1977, pp. 238–252.
Dams, D., O. Grumberg and R. Gerth, Abstract interpretation of reactive systems: Abstractions preserving ∀CTL∗, ∃CTL∗ and CTL∗, in: Proc. IFIP working conference on Programming Concepts, Methods and Calculi (PROCOMET’94), 1994.
Gollu, A., A. Puri and P. Varaiya, Discretization of timed automata, in: Proceedings of the 33rd IEEE conferene on decision and control, 1994, pp. 957–958.
Graf, S. and H. Saidi, Construction of abstract state graphs with PVS, , 1254 (1997).
Jonsson, B., Compositional specification and verification of distributed systems, ACM Transactions on Programming Languages and Systems 16 (1994), pp. 259–303.
Kesten, Y. and A. Pnueli, Control and data abstraction: The cornerstones of practical formal verification, Software Tools for Technology Transfer 2 (2000), pp. 328–342.
Kurshan, R. P. and K. L. McMillan, A structural induction theorem for processes, Information and Computation 117 (1995), pp. 1–11.
Lesens, D. and H. Sa¨ıdi, Abstraction of parameterized networks, in: F. Moller, editor, Infinity’97, Second International Workshop on Verification of Infinite State System, Electronic Notes in Theoretical Computer Science 9 (2000).
Pnueli, A. and E. Shahar, A platform combining deductive with algorithmic verification, in: Rajeev Alur and Thomas A. Henzinger, editors, Proceedings of the Eighth International Conference on Computer Aided Verification CAV, Lecture Notes in Computer Science 1102 (1996), pp. 184–195.
Schneider, F. B., B. Bloom and K. Marzullo, Putting time into proof outlines, in: de Bakker, Huizing, de Roever and Rozenberg, editors, Real-Time: Theory in Practice, LNCS 600, 1992.
Ta¸sıran, S., R. Alur, R. P. Kurshan and R. K. Brayton, Verifying abstractions of timed systems, in: U. Montanari and V. Sassone, editors, CONCUR ’96: Concurrency Theory, 7th International Conference, Lecture Notes in Computer Science 1119 (1996), pp. 546–562.
Wolper, P. and V. Lovinfosse, Verifying properties of large sets of processes with network invariants, in: Proceedings of the International Workshop on Automatic Verification Methods for Finite State Systems, Lecture Notes in Computer Science 407 (1989), pp. 68–80.
