

Electronic Notes in Theoretical Computer Science 269 (2011) 71–82
www.elsevier.com/locate/entcs

The Descriptive Complexity of the Deterministic Exponential Time Hierarchy
Cibele Matos Freire1,3 Ana Teresa Martins2,4
Departamento de Computa¸c˜ao Universidade Federal do Cear´a Fortaleza, Brasil

Abstract
In Descriptive Complexity, we investigate the use of logics to characterize computational complexity classes. Since 1974, when Fagin proved that the class NP is captured by existential second-order logic, considered the first result in this area, other relations between logics and complexity classes have been established. Well-known results usually involve first-order logic and its extensions, and complexity classes in polynomial time or space. Some examples are that the first-order logic extended by the least fixed-point operator captures the class P and the second-order logic extended by the transitive closure operator captures
the class PSPACE. In this paper, we will analyze the combined use of higher-order logics of order i, HOi, for i ≥ 2, extended by the least fixed-point operator, and we will prove that each level of this hierarchy captures each level of the deterministic exponential time hierarchy. As a corollary, we will prove that the
hierarchy of HOi(LFP), for i ≥ 2, does not collapse, that is, HOi(LFP) ⊂ HOi+1(LFP).
Keywords: Descriptive Complexity, Higher-Order Logics, Deterministic Exponential Time Hierarchy, Fixed-Point Operator.


Introduction
In Computational Complexity, the measure of the efficiency of an algorithm is usu- ally based on the amount of time and space consumed in its execution. The investi- gation about the efficiency of an algorithm allows us to define a hierarchy of classes of problems. When this hierarchy is based on time and space, we identify important classes as the class P that contains all problems which have a polynomial determin- istic Turing machine that solves them, and the class NP that contains all problems which have a polynomial nondeterministic Turing machine that solves them.

1 This research is partially supported by CNPq (Master’s degree scholarship)
2 This research is partially supported by CNPq (PQ, Universal 2008, “Casadinho” 2008) and CAPES(PROCAD)
3 Email:cibelemf@lia.ufc.br
4 Email:ana@lia.ufc.br

1571-0661 © 2011 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2011.03.006

The measures of time and space in Computational Complexity, although natural from the point of view of engineering since they reflect physical resources necessary for computing, are not intuitive from the mathematical perspective.
In 1974, Fagin showed that the complexity class NP is exactly the one where problems in it can be described by the existential fragment of second-order logic (∃SO), that is, NP=∃SO [1]. This result is very important since it indicates that the complexity of a problem can be characterized independently of the machine, through the expressiveness of a logical language used to specify all and only the problems of a class.
After Fagin’s initial result, many others were obtained leading us to believe that all complexity classes can be precisely captured by a logical language. This area is known as Descriptive Complexity [6].
In the definition of a complexity class, decision problems play an essential role and, in the area of Descriptive Complexity, we refer to them as boolean queries. We can describe a boolean query using a formula ϕ and we say that a boolean query is computable if there is a Turing machine M that computes it, i.e., A |= ϕ iff M accepts A, for all finite relational structures A.
An example of an important boolean query is REACHABILITY, or simply REACH, thus defined: Let G be a graph and s and t be two vertices in G. Is there a path between s and t in G? If we want to express this query in first-order logic (FO), we will see that it is not possible due to its limited expressive power. Indeed, we know that FO=LH, i.e., FO captures the logarithmic time hierarchy and, as REACH is in P−LH, FO cannot express it [6].
By the fact that FO=LH, we can notice that the expressive power of FO is too weak. There are several ways to extend FO in order to get stronger logics. For instance, we can increase the order of the variables of the logic obtaining higher- order logics, we can add operators not expressible in FO as the transitive closure and the fixed-point ones, and we can allow formulas of infinite size obtaining infinitary logics.
In this paper, we are interested in investigating the combined use of the least fixed-point operator with higher-order logics. In section 2, we will present the definition of higher-order logics and some expressiveness results already established in the literature. In section 3, we will introduce the least fixed-point operator and we will show how it increases the expressive power of FO. In section 4, we will prove our main result: the characterization of the complexity classes captured by each higher-order logic extended with the least fixed-point operator. Some corollaries about the expressive power of these logics are also presented. We will end with the Conclusion section. Throughout the text, the basics of Computational Complexity are from [12].

Higher-Order Logics
As said in the Introduction, there are several ways to increase the expressive power of FO. In this section, we will introduce the higher-order logics, HO, whose language

extend that of FO with relation variables of any order. At the end of this section, we will see how big is their expressive power when compared to the one of FO already mentioned.
We begin with the definition of formulas in higher-order logics based on a vocab- ulary σ, a finite set of constant, function and relation symbols. For our purposes, we will only consider relational vocabularies, the ones which just contain relation sym- bols. For every i ≥ 2, the alphabet of a higher-order logic of order i, HOi, contains the usual logical and punctuation symbols, the symbols in σ, a countable infinite set of individual variables x1, x2, x3,... and, for every r ≥ 1 and 2 ≤ j ≤ i, a countable infinite set of r-ary relation variables X1, X2, X3,... of order j. Henceforth, we will often use x and y for individual variables, X and Y for relation variables and R for relation symbols, with or without indexes.
Definition 2.1 Let σ be a relational vocabulary. The set of σ-formulas of HOi is inductively defined as follows:
If x and y are individual variables, then x = y is a σ-formula.
If R is an r-ary relation symbol in σ, r ≥ 1, and x1,..., xr are individual variables, then R(x1,..., xr) is a σ-formula.
If X is an r-ary relation variable of order 2, r ≥ 1, and x1,..., xr are individual variables, then X(x1,..., xr) is a σ-formula.
If X is an r-ary relation variable of order j, r ≥ 1 and 3 ≤ j ≤ i, and Y1,..., Yr
are r-ary relation variables of order j − 1, then X(Y1,..., Yr) is a σ-formula.
If X and Y are relation variables of the same order and of the same arity, then
X = Y is a σ-formula.
If ϕ and ψ are σ-formulas, then (¬ϕ), (ϕ ∧ ψ), (ϕ ∨ ψ) are σ-formulas.
If ϕ is a σ-formula and x is an individual variable, then ∃xϕ and ∀xϕ are
σ-formulas.
If ϕ is a σ-formula and X is a relation variable, then ∃Xϕ and ∀Xϕ are σ- formulas.
Whenever the reference to σ is either clear or unimportant, we will just speak of formulas, instead of σ-formulas. The atomic formulas are the ones introduced above by items (i) to (v).
The interpretation of a formula is based on the following definitions. A relational
σ-structure A is a tuple (A, RA, .. ., RA), where A is a nonempty finite set, the
1	n
domain of A, and RA, 1 ≤ i ≤ n, is an r-ary relation on A that interprets each
r-ary relation symbol Ri ∈ σ. A valuation v on a σ-structure A is a function which assigns to each individual variable x an element of A, and to each r-ary relation variable X of order j, r ≥ 1 and 2 ≤ j ≤ i, an r-ary relation of order j on A. The notion of relation of order j can be defined as: Let R be a relation of order j and arity r. If j = 2 then R is a relation on Ar, i.e., R ∈ A2, where A2 = P(Ar) and P(Ar) is the powerset of Ar. If j = i then R is a relation on the set of relations of

order i − 1, i.e., R ∈ Ai, where Ai = P(Ar
). Let v0 and v1 be two valuations on

a σ-structure A, and let V be a variable of whichever kind, we say that v0 and v1
are V -equivalent if they coincide in every variable of whichever kind, but on V .
Definition 2.2 Let A be a σ-structure and let v be a valuation on A. The notion of satisfaction on HOi is inductively defined as follows:
A,v |= (x = y) :iff v(x)= v(y), where x and y are individual variables.
A,v |= R(x1,..., xr) :iff (v(x1),..., v(xr)) ∈ RA, where R is an r-ary relation symbol in σ, r ≥ 1, and x1,..., xr are individual variables.
A,v |= X(x1,..., xr) :iff (v(x1),..., v(xr)) ∈ v(X), where X is an r-ary rela- tion variable of order 2, r ≥ 1, and x1,..., xr are individual variables.
A,v |= X(Y1,..., Yr) :iff (v(Y1),..., v(Yr)) ∈ v(X), where X is an r-ary rela- tion variable of order j, r ≥ 1 and 3 ≤ j ≤ i, and Y1,..., Yr are r-ary relation variables of order j − 1.
A,v |= (X = Y ) :iff v(X) = v(Y ), where X and Y are relation variables of order j, for some 2 ≤ j ≤ i, and of arity r, for some r ≥ 1.
A,v |= (¬ϕ) :iff A,v |= ϕ, where ϕ is a formula.
A,v |= (ϕ ∧ ψ) :iff A,v |= ϕ and A,v |= ψ, where ϕ and ψ are formulas.
A,v |= (ϕ ∨ ψ) :iff A,v |= ϕ or A,v |= ψ, where ϕ and ψ are formulas.
A,v |= ∃xϕ :iff there is a valuation vj that is x-equivalent to v and A, vj |= ϕ, where x is an individual variable and ϕ is a formula.
A,v |= ∀xϕ :iff for every valuation vj that is x-equivalent to v we have that
A, vj |= ϕ, where x is an individual variable and ϕ is a formula.
A,v |= ∃Xϕ :iff there is a valuation vj that is X-equivalent to v and A, vj |= ϕ, where X is a relation variable and ϕ is a formula.
A,v |= ∀Xϕ :iff for every valuation vj that is X-equivalent to v we have that
A, vj |= ϕ, where X is a relation variable and ϕ is a formula.
As for FO, we can define the class Σi , i, j ≥ 1, of formulas ϕ ∈ HOi+1 of the
i
form ∃X11 ... ∃X1s1 ∀X21 ... ∀X2s2 ... QXj1 ... QXjs ψ, where ψ ∈ HO , and Q is
either ∃ or ∀ depending on whether j is odd or even, respectively. That is, Σi is the
class of HOi+1 formulas with j − 1 alternations of quantifiers block of variables of

order i + 1, starting with an existential quantifier. The class Πi
is dually defined.

We say that a formula ϕ is in Generalized Skolem Normal Form, GSNF, if it belongs
to either Σi or Πi , for some i, j ≥ 1. The following well known lemma is true.
j	j
Lemma 2.3 [3] For all i ≥ 2, and for every formula ϕ ∈ HOi, there is a formula
ϕˆ ∈ HOi which is in GSNF and equivalent to ϕ.
Some results concerning the descriptive complexity of HO over finite structures were already established in [14], [4], [8], [10] and [9]. The following one gives a well-known correspondence between SO and the polynomial-time hierarchy.
Theorem 2.4 [14] SO = PH, where PH is the polynomial-time hierarchy deﬁned

as: PH = S ΣiP, Σ0P = P and Σi+1P = NPΣiP , for every i.
i≥0
The following theorems give results for all levels of HO. The first theorem shows that each level of HO is more expressive than the level before, and the second shows that the same is true when we consider the existential and universal fragments.
Theorem 2.5 [4] For all i ≥ 2, HOi ⊂ HOi+1.
Theorem 2.6 [8] For all i ≥ 2,
∃HOi ⊂ ∃HOi+1.
∀HOi ⊂ ∀HOi+1.
In [9] and [10] a characterization of HO is presented. Some criticisms about this characterization are presented in [3]. We follow the late characterization. Be- fore presenting this result, we need the definition of the function exp and of the nondeterministic exponential time hierarchy, NEXPH.
Definition 2.7 Let f (n) be a function on natural numbers.  We define
exp(0,f (n)) = f (n) and, for i ≥ 1, exp(i, f (n)) = 2exp(i−1,f(n)).
Definition 2.8 For i ≥ 0 and j ≥ 1, we define the Nondeterministic Exponential Time Hierarchy as:
NEXPH0 = S NTIME(exp(i, nc))
c∈N
NEXPHj = NEXPH0Σj−1P , where Σj−1P is defined as in the polynomial-time
i	i
hierarchy.
The following theorem establishes that each fragment of HO in the prenex normal
form, i.e. Σi and Πi , captures a level in the Nondeterministic Exponential Time
Hierarchy. The Theorem 2.4 is a straightforward corollary of Theorem 2.9.
Theorem 2.9 [2] [3] For i, j ≥ 1:
Σi = NEXPHj−1.
j	i−1
Πi = coNEXPHj−1.
j	i−1
By Lemma 2.3 and Theorem 2.9, we get as a corollary the characterization of the higher-order logics.

Corollary 2.10 [2] [3] For every i ≥ 2, HOi= S (NEXPHj
∪ coNEXPHj	).

j≥0
The Least Fixed-Point Logic
In the first section, we said that FO is not powerful enough to express the boolean query REACH, although it can express the following one: “Let G be a finite graph with two vertices, s and t, in it. Is there a path from s to t in G with length n?” How can we explain this fact? From a computational point of view, we may say

that FO can express loops with a precise number of iterations (for-loops), but not the ones where you do not know in advance the number of steps needed to finish them (while-loops). From a mathematical point of view, we may say that many inductively defined relations are not FO expressible.
Another possibility of extending FO and increasing its expressive power is with an operator. In this section, we will add the least fixed-point operator to FO which allows one to define new relations by induction. This is the Least Fixed-Point logic, FO(LFP). We will close this section by also analysing its expressive power.
Let A be a finite set, P(A) be its powerset, F : P(A) → P(A) be an operator on A. We say that F is monotone if X ⊆ Y then F (X) ⊆ F (Y ), for X, Y ⊆ A. A set X ⊆ A is a fixed-point of F if F (X)= X. A set X ⊆ A is the least fixed-point of F , lfp(F ), if it is a fixed-point and, for every other fixed-point Y of F , we have
X ⊆ Y . F gives rise to a sequence of sets ∅,F (∅),F (F (∅)),.. .. Let us call its members by F0, F1, F2,.. ., i.e., F0 = ∅ and Fn+1 = F (Fn). Fn will denote the n-th stage of F . Suppose that there is an n0 such that F (Fn0 )= Fn0 . By the definition of this sequence, Fm = Fn0 , for all m ≥ n0 and, by the definition of fixed-point, Fn0 is a fixed-point of F . We will denote Fn0 by F∞. We can not garantee that the fixed-point F∞ exists, however, in some cases, we can say that it exists and is the least fixed-point of F .
Lemma 3.1 [7][15] If F is monotone, then F∞ is the least ﬁxed-point of F.
Besides the fact that F∞ is the least fixed-point when F is monotone, its clear that the fixed-point is achieved at most in the n-th stage, where |A| = n.
Let σ be a relation vocabulary, R a k-ary relation symbol not in σ and ϕ(R, x1,..., xk) a σ ∪ {R}-formula. For each finite σ-structure A, ϕ(R, x1,..., xk) induces the operator Fϕ : P(Ak) → P(Ak) defined as
Fϕ(X)= {(a1,..., ak) |A |= ϕ(X/R, a1,..., ak)},
where ϕ(X/R, a1,..., ak) means that R is interpreted as X in ϕ.
FO(LFP) is defined as an extension of FO with formulas for computing the least fixed-point of operators Fϕ. By Lemma 3.1, if Fϕ is monotone then lfp(Fϕ)= Fϕ and the least fixed-point is achieved no later than the nk-th stage of Fϕ. In order to assure this property to Fϕ, we have to impose some syntactic restriction to ϕ. Let ϕ be a formula that may contain an occurrence of a relation R. We say that an occurence of R is positive in ϕ if it is under the scope of an even number of negations. Otherwise, it is negative. A formula ϕ is positive in R if all occurrences of R are positive, or there are none at all.
Lemma 3.2 Let σ be a relational vocabulary, R a k-ary relation symbol not in σ
and ϕ(R, x1,..., xk) a σ∪ {R}-formula. If ϕ is positive in R, then Fϕ is monotone.
The proof of this lemma is by induction on formulas. The intuitive idea of this lemma is as follows: We want to prove that if X ⊆ Y ⊆ Ak then Fϕ(X) ⊆ Fϕ(Y ). However, for it to be false there would be a tuple (a1,..., ak) in Fϕ(X) that was not in Fϕ(Y ). However, this is not possible. Since X ⊆ Y , the only possibility for

(a1,..., ak) /∈ Fϕ(Y ) would be if an occurrence of R were negative in ϕ, which is not the case.
Definition 3.3 Let σ be a relational vocabulary, R a k-ary relation symbol not in σ, ϕ(R, x1,..., xk) a σ ∪ {R}-formula and A a finite σ-structure. The language of FO(LFP) extends that of FO with the following formation rule:
if ϕ(R, x1,..., xk) is positive in R and (t1,..., tk) is a tuple of terms, then [lfpR,x1,...,xk ϕ(R, x1,..., xk)](t1,..., tk) is a formula whose free variables are those of (t1,..., tk).
The satisﬁability relation of FO(LFP) extends that of FO with the following defi- nition:
A |= [lfpR,x ,...,x ϕ(R, x1,..., xk)](a1,..., ak) iff (a1,..., ak) ∈ lfp(Fϕ).
As an example, let σ = {E}, E and R binary relations, A a finite σ-structure, and ϕt(R, x1, x2)= E(x1, x2) ∨ ∃z(E(x1, z) ∧ R(z, x2)). Note that ϕt is positive in
R. Now consider [lfpR,x1,x2 ϕt(R, x1, x2)]. What does this formula define? By the above definition, the answer is lfp(Fϕt ). But what is Fϕt in this case? For a set X ⊆ A2, Fϕt (X)= E ∪ (E ◦ X), where E ◦ X = {(a, b) | (a, c) ∈ R, (c, b) ∈ R, for some c ∈ A}. Hence, [lfpR,x1,x2 ϕt(R, x1, x2)] defines the transitive closure of E.
Now, we can define the query REACH in FO(LFP) as follows:
REACH = [lfpR,x1,x2 ϕt(R, x1, x2)](s, t).
As mentioned in the Introduction, FO = LH, the logarithmic-time hierarchy. We saw above that the addition of the least fixed-point operator to FO really increases its expressivity. The next theorem measures how much is this gain.
Theorem 3.4 [5][16][11] Over ﬁnite and ordered structures, FO(LFP) captures P, the class of problems decidable in deterministc polynomial time, that is, FO(LFP)
= P.
The proof of this theorem is based on the fact that FO=LH and REACHa is complete for P via first-order reductions. REACHa is a variation of REACH where the path between s and t must be alternating. We can express REACHa in FO(LFP) as follows: REACHa = [lfpR,x1,x2 ϕa(R, x1, x2)](s, t), where ϕa(R, x, y) ≡ (x = y)∨(∃z(E(x, z)∧R(z, y))∧(A(x) → ∀z(E(x, z) → R(z, y)))) (see [6] for further details). In order to prove that FO(LFP) ⊆ P, we must construct a polynomial time Turing machine M that computes the query defined by a FO(LFP) sentence ϕ. The
proof is by induction on the structure of ϕ. The difficult case is when ϕ is of the form [lfpR,x1,...,xk ϕ(R, x1,..., xk)]. In this case, the machine will calculate the new relation defined by the least fixed point operator. In each stage of Fϕ, the machine will verify if ϕ is satisfied. As the fixed-point is achieved no later than the nk-th stage, where n is the size of the structure and k the arity of the new relation, and
the first-order sentence ϕ can be evaluated in logarithmic time, the new relation is computed in polynomial time, so M is in P. For the other direction, since REACHa is complete for P, all problems in this class can be reduced to it. Moreover, since

REACHa is definable in FO(LFP), it is easy to see that all problems in P are definable in FO(LFP) too.

Higher-Order Logics with the Least Fixed-Point Op- erator
As mentioned in the previous sections, one can increase the expressive power of logics in several ways. Here, we will investigate if the addition of the least fixed- point operator to higher-order logics increases their expressive power and we will identify which are the complexity classes captured by such logics. This is theorem
4.4 and it is the main result of this paper.
There are other fixed-points as the inflationary (IFP) and partial (PFP) ones. In [13], the authors added inflationary and partial fixed-points to higher-order logics and they showed that, for every order, it is sufficient to increase the order of the given logic by one to capture inflationary fixed-points, and by two to capture partial fixed-points. We get similar results as straightforward corollaries of Theorem 4.4, although a similar result to Theorem 4.4 is not proved in [13].
Definition 4.1 Let σ be a relational vocabulary, R a k-ary relation variable of order i + 1, ϕ(R, X1,..., Xk) a formula of HOi(LFP), where X1,..., Xk are k-ary relation variables of order i, and A a finite σ-structure. The language of HOi(LFP) extends that of HOi with the following formation rule:
if ϕ(R, X1,..., Xk) is positive in R and (V1,..., Vk) is a tuple of relations of order i, then [lfpR,X1,...,Xk ϕ(R, X1,..., Xk)](V1,..., Vk) is a formula whose free variables are those of (V1,..., Vk).
The satisﬁability relation of HOi(LFP) extends that of HOi with the following definition:
A |= [lfpR,X ,...,X ϕ(R, X1,..., Xk)](R1,..., Rk) iff (R1,..., Rk) ∈ lfp(Fϕ).
The following theorem shows which complexity class the first level of HOi(LFP) captures. Although this fact is cited in the literature, we did not find any proof or reference for this proof.
Theorem 4.2 Over ﬁnite and ordered structures, SO(LFP) captures EXP, the class of problems decidable in exponential time, that is, SO(LFP) = EXP.
In attempt to prove the theorem above, we analyze a more general result. Instead of investigating only the first level of the hierarchy of higher-order logics with the least fixed-point, we obtained a proof that deals with all the hierarchy. In fact, we prove that each level of this hierarchy is captured by a level of the deterministic exponential time hierarchy, as we will see below.
Definition 4.3 Let i-EXP = TIME(exp(i, nk)), for all k. The Deterministic Ex-
ponential Time Hierarchy is defined as: EXPH = S i-EXP.
i≥1

Theorem 4.4 For all i ≥ 2, HOi(LFP) captures (i−1)-EXP over ﬁnite and ordered structures.

Proof.
HOi(LFP) ⊆ (i − 1)-EXP.
By induction on formulas ϕ. Every atomic formula of HOi(LFP) is a formula without the operator lfp, thus it is a formula of HOi. By Corollary 2.10 and by

the fact that S
j≥0
(NEXPHj
∪ coNEXHj
) ⊆ (i − 1)-EXP [12], we can say that

atomic formulas can be evaluated with an (i − 1)-EXP machine.
ϕ = ¬ψ. By inductive hypothesis, there is a machine Mψ ∈ (i − 1)-EXP that evaluates ψ. The machine Mϕ uses Mψ to verify if A satisfies ψ. If Mψ accepts, then Mϕ rejects and vice-versa.
ϕ = ψ1 ∧ ψ2. Let Mψ1 and Mψ2 be the machines that evaluate ψ1 and ψ2. Therefore, Mϕ uses these machines and, if both accept, Mϕ accepts. Otherwise, it rejects.
ϕ = ψ1 ∨ ψ2. Similar to the previous case.
ϕ = ∃xψ. By inductive hypothesis, there is a machine Mψ ∈ (i − 1)-EXP that evaluates ψ. Note that ψ has one free variable x. Then, the machine Mϕ writes on a work tape the binary encoding of j = 0,...,n − 1 and, using Mψ, it verifies if A |= ψ(j/x). If Mψ accepts, for some j, then Mϕ accepts. Otherwise, Mϕ rejects. As the size of domain is n, this will be done at most n times and, therefore, Mϕ ∈ (i − 1)-EXP.
ϕ = ∀xψ. Similar to the previous case.
ϕ = ∃Xψ. X is a relational variable of order j, 2 ≤ j ≤ i, and arity k. By induction hypothesis, there is a machine Mψ ∈ (i − 1)-EXP. Note that ψ has a free variable X. Mϕ uses a work tape to code relations of order j and arity k. This tape uses exp(i − 2, nk) cells and it can encode exp(i − 1, nk) different relations. To each relation R described in the tape, Mψ is used to verify if A |= ψ(R). If Mψ accepts for some R, then Mϕ accepts. Otherwise, Mϕ rejects. As at most exp(i− 1, nk) calls to Mψ will be done, then Mϕ will execute in time exp(i− 1, nk).exp(i− 1, O(nc)) = exp(i − 1, O(nc)). Thus, Mϕ ∈ (i − 1)-EXP.
ϕ = ∀Xψ. Similar to the previous case.
ϕ = [lfpR,X1,...,Xk ψ(R, X1,..., Xk)](R1,..., Rk). By inductive hypothesis, there is Mψ ∈ (i − 1)-EXP. The machine Mϕ uses two work tapes to write a encoding of relations of order i + 1 that will be assigned to the relational variable R. As these relations are of order i + 1, their maximum size is the number of different tuples that can be formed with relations of order i. If the relation is of order 2
and arity r, then the maximum size is given by |Ar| = exp(0, nr). If the order is 3, the maximum size is |Ar| = exp(1, nr) and, in the general case, if order is i,
then the maximum size is |Ar	| = exp(i − 2, nr). Thus, we need exp(i − 1, nk)
cells to encode a relation of order i + 1. In the first step, R = ∅ is the relation encoded on tape 1. Using the machine Mψ, Mϕ computes the following relation: Rj = {(V1,..., Vk) | A |= ψ(R, V1,..., Vk)}. If R = Rj then the fixed-point is achieved and it is sufficient to test whether (X1,..., Xk) ∈ R. Otherwise, it copies

the contents of tape 1 into tape 2, it erases the contents of tape 1, and it computes Rj again. As ψ is positive in R, with an argument like in Lemma 3.2 and by the Lemma 3.1, we know that the fixed-point of Fψ will be achieved in at most exp(i− 1, nk) steps. So, Mψ will be called at most exp(i− 1, nk) times and Mϕ will execute in time exp(i − 1, nk).exp(i − 1, O(nc)) = exp(i − 1, O(nc)). Therefore, Mϕ
∈ (i − 1)-EXP.
(i − 1)-EXP ⊆ HOi(LFP).
Let M ∈ (i − 1)-EXP be a Turing machine that executes in time exp(i − 1, nk), for some k. As a consequence, we can conclude that it uses at most exp(i − 1, nk) cells in its work tapes. We want to define a formula ϕ such that M accepts A iff A |= ϕ. Our formula describes the computation of the machine and, as the computation of a machine is described as a sequence of configurations, we will use a relation C to encode such sequence of configurations. A machine configuration is defined by the current state, the current position of the head of each tape and the current content of each work tape. We can encode this data with a relation C of order i + 1 and arity 3, as we can see next. We use the first component of C as a time stamp to indicate which is the position of the configuration in the sequence, i.e., in which moment of the computation the configuration described by that tuple was reached. As the machine executes in time exp(i − 1, nk), we can encode this with relations of order i. The second component indicates what kind of data is encoded in the third component of C. The data can be the current state, the current head position of tape m or the current content of tape m. As the number of states and tapes of the machine is finite, this can be encoded using individual variables, easily with a relation of order i. The third component encodes the data itself. In this case, when we indicate the position of the head or the contents of work tape, we need to encode an exponential number of positions, because, as we previously mentioned, the machine uses at most exp(i − 1, nk) cells for each tape. Therefore, we can use relations of order i again. Now, we can see that each tuple of C encodes a part of the configuration of machine M and, in fact, if we want to know what is the configutation of M in time t, we have to look for all tuples whose the first component is “t”. As the tuples of the relation C are formed by relations of order i, C is a relation of order i + 1. As we cannot quantify relations of order i + 1, we need to use the least fixed-point operator to define the relation C. To do this, we define a formula ψ such that C = [lfpR,X1,X2,X3 ψ(R, X1, X2, X3)]. The formula
ψ is built based on the instructions of the machine in a way that in the t-th step
of the least fixed-point operator the tuples added to the relation are the ones that encode the configuration of M in the instant t. In the end, it is enough to verify if there isa tuple in C in which the first component indicates the time exp(i − 1, nk), the second component indicates that the data is the current state, and the third component indicates the accepting state.	2
Theorem 4.2 is a straightforward corollary of Theorem 4.4. The last one follows the same argument of well known results as, for example, FO=LH, FO(LFP)=P and SO=PH, although they differ in technical details. The interesting fact is the close

relation between the addition of the least fixed-point operator and the exponential gain in time. For example, FO captures the logarithmic hierarchy and, when we add the operator to obtain FO(LFP), the new logic captures the class P, i.e., an exponential gain in time with respect to LH. This gain also occurs when we add the least fixed-point operator to higher-order logics. Below, see some reasonable corollaries that follow from our main result.
Corollary 4.5 HOi(LFP) ⊂ HOi+1(LFP), for all i ≥ 2.
Corollary 4.6 HOi(LFP) ⊆ HOi+1, for all i ≥ 2.
Corollary 4.7 S HOi(LFP) = S HOi.
i≥2	i≥2
In the Corollary 4.5 we see that the hierarchy of higher-order logics with the least fixed-point does not collapse. In fact, the proof of this corollary is a consequence of Theorem 4.4 and of the Time Hierarchy Theorem [12] which has as a corollary the fact that (i − 1)-EXP ⊂ i-EXP. Corollary 4.6 is similar to the theorem proved in [13] to HOi(IFP), and Corollary 4.7 states that there is no gain in expressivity when we consider the union of all levels of the hierarchy.
5	Conclusions
In Descriptive Complexity, we are interested in characterizing complexity classes using logics. Most results were obtained involving FO, and its extensions, and polynomial complexity classes. In this paper, we investigated the addition of the least fixed-point operator to higher-order logics.
Our central result is that HOi(LFP) captures the (i − 1)-EXP complexity class, for i ≥ 2. Hence, we characterized all levels of the Deterministic Exponential Time Hierarchy. From this, we obtained interesting corollaries. The first one states that it is sufficient to increase the order of the given higher-order logic by one to capture the least fixed-point operator, that is, HOi(LFP) ⊆ HOi+1, for all i ≥ 2. We also proved that the HOi(LFP) hierarchy does not collapse since each level is more expressive than the previous one, that is, HOi(LFP) ⊂ HOi+1(LFP), for all i ≥ 2. Finally, despite of the gain of expressivity in each level of the HOi(LFP) hierarchy, there is no gain in expressivity when we consider the union of all levels, that is,

i≥2
HOi(LFP) = S
HOi.

The idea of adding some fixed-point operators to higher-order logics was first
formulated by [13], but for inflationary and partial fixed-points. They get similar results to our corollaries, although not for theorem 4.4.

References
Fagin, R., Generalized first-order spectra and polynomial-time recognizable sets, , 7, AMS Bookstore, 1974 pp. 43–73.
Hella, L. and J. M. Turull Torres, Expressibility of higher order logics, Eletronic Notes in Theoretical Computer Science 84 (2003), pp. 129–140.

Hella, L. and J. M. Turull Torres, Computing queries with higher order logics, Theoretical Computer Science (2006), pp. 197–214.
Hull, R. and J. Su, On the expressive power of database queries with intermediate types, Journal of Computer and System Sciences 43 (1991), pp. 219–267.
Immerman, N., Relational queries computable in polynomial time (extended abstract), in: STOC ’82: Proceedings of the fourteenth annual ACM symposium on Theory of computing (1982), pp. 147–152.
Immerman, N., “Descriptive Complexity,” Springer, 1999.
Knaster, B., Un th´eor´eme sur les fonctions d’ensembles., Annales de la Soci´et´e Polonaise de Math´ematique. 6 (1928), pp. 133–134.
Kuper, G. M. and M. Y. Vardi, On the complexity of queries in the logical data model, Lecture Notes in Computer Science (1988), pp. 267–280.
Leivant, D., Characterization of complexity classes in higher-order logic, in: Proceedings of the 2nd. Annual Conference Structure in Complexity Theory, (1987), pp. 203–217.
Leivant, D., Descriptive characterizations of computational complexity, Journal of Computer and System Sciences 39 (1989), pp. 51–83.
Livchak, A. B., Languages for polynomial-time queries, Computer-Based Modeling and Optimization of Heat-Power and Electrochemical (1982), p. 41.
Papadimitriou, C. H., “Computational Complexity,” Addison Wesley Logman, 1994.
Schewe, K.-D. and J. M. T. Torres, Fixed-point quantifiers in higher order logics, in: Proceeding of the 2006 conference on Information Modelling and Knowledge Bases XVII (2006), pp. 237–244.
Stockmeyer, L. J., The polynomial-time hierarchy, Theoretical Computer Science 3 (1977), pp. 1–22.
Tarski, A., A lattice-theoretical fixpoint theorem and its applications., Pacific Journal oh Mathematics
5 (1955), pp. 285–309.
Vardi, M. Y., The complexity of relational query languages (extended abstract), in: STOC ’82: Proceedings of the fourteenth annual ACM symposium on Theory of computing (1982), pp. 137–146.
