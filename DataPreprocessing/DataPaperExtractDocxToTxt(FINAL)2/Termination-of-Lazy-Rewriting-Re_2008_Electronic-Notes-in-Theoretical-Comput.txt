Electronic Notes in Theoretical Computer Science 204 (2008) 35–51	
www.elsevier.com/locate/entcs
Termination of Lazy Rewriting Revisited
Felix Schernhammer and Bernhard Gramlich1
Theory and Logic Group Institute of Computer Languages TU Wien, Austria

Abstract
Lazy rewriting is a proper restriction of term rewriting that dynamically restricts the reduction of certain arguments of functions in order to obtain termination. In contrast to context-sensitive rewriting, reductions at such argument positions are not completely forbidden but delayed. Based on the observation that the only existing (non-trivial) approach to prove termination of such lazy rewrite systems is flawed, we develop a modified approach for transforming lazy rewrite systems into context-sensitive ones that is sound and complete with respect to termination. First experimental results with this transformation based technique are encouraging.
Keywords: term rewriting, lazy rewriting, termination, context-sensitive system


Introduction
In functional programming languages, evaluations are often carried out in a lazy fashion. This means that in the evaluation of an expression, the result of certain subexpressions is not computed until it is known that the particular result is actually needed. A very similar idea is used in lazy rewriting ([3]) where the reduction of certain subterms is delayed as long as possible (cf. also [1], [8], and [10]).
Termination analysis of functional programs has recently become a major subject of research in the rewriting community. Due to the similarity of lazy rewriting and the lazy evaluation strategy of functional programs, the use of lazy rewriting seems promising to find new methods for proving termination of functional programs. In particular lazy rewriting and lazy evaluation in functional programming share the idea of postponing certain evaluation steps. More precisely, arguments of functions are only evaluated if their final result is needed to compute the function.
Example 1.1 Consider the following functional program given in term rewriting system (TRS) syntax.

1 Email: {felixs,gramlich}@logic.at

1571-0661 © 2008 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2008.03.052

from(x) → x : from(s(x))	take(0, xs) → []
take(x, []) → []	take(s(x),y : ys) → y : take(x, ys)
Without an evaluation strategy the input term take(s(0),from(0)) is non-termi- nating. Yet, when using a lazy evaluation strategy it is terminating and the result is 0. The crucial difference is that in a term of the shape take( , : from( )) the from subterm may not be evaluated under lazy evaluation, because its result is not needed to evaluate any more outer function.
However, a reduction of the problem of proving termination of functional pro- grams to the problem of proving termination of lazy TRSs is non-trivial. The reason is that functional programming languages typically allow for features such as higher- order functions, typing and strategies other than lazy evaluation; e.g., in Haskell always the “first” defining equation is applied to an object term when several equa- tions are applicable (at the same position) (this has already been pointed out in [6]).
Therefore, lazy rewriting can only approximate lazy (Haskell) evaluations but clearly not simulate them in a one-to-one fashion. Yet, the described features of functional programs can be encoded or approximated through standard transfor- mations such that finally lazy rewriting can be used for a termination analysis (cf. e.g. [7]).
In this work we present a transformation from lazy TRSs into context-sensitive ones that is sound and complete w.r.t. termination and thus allows us to reduce the problem of deciding whether a lazy TRS is terminating or not to the same problem for context-sensitive TRSs, which has already been studied to some extent (cf. eg. [12] ). As this is the first sound and complete transformation for lazy TRSs, it enables us for the first time to investigate the use of lazy rewriting in the area of termination analysis of functional programs.
Lazy rewriting was initially introduced by [3] in a graph rewriting setting (al- though the basic underlying idea is much older, cf. e.g. [4], [15], [14]). However, for the termination analysis of functional programs it makes sense to consider term rewriting instead of graph rewriting, for the following reasons. First of all, using term rewriting instead of graph rewriting is more general and does not prohibit cer- tain evaluations a priori. Moreover, the theory of ordinary term rewriting is much further developed as compared to graph rewriting. In particular, existing methods for the termination analysis of ordinary as well as context-sensitive rewrite systems can be applied where possible. Hence, in this work we will use the notion of lazy term rewriting introduced in [11].
In [11] a transformation from lazy rewrite systems into context-sensitive ones was proposed, which was supposed to preserve non-termination and conjectured to be complete w.r.t. termination. Unfortunately, a counterexample (see Example 3.4 below) proves that this transformation is unsound w.r.t. termination. In this paper we repair the transformation and prove both soundness and completeness of the new transformation w.r.t. termination.

In Section 2 of this paper we will present basic definitions and notations of lazy rewriting. In Section 3 we introduce the transformation of [11] and give a counterexample to its soundness w.r.t. termination. We then propose a modified version of the transformation which is proved to be sound and complete w.r.t. termination. Section 4 contains a discussion of the presented approach and of some experimental results. 2
Preliminaries
We assume familiarity with the basic concepts and notations in term rewriting as well as context-sensitive term rewriting as provided for instance in [2,9].
As in [3] and [11] we are concerned with left-linear lazy rewrite systems in this work.
General assumption: Throughout the paper we assume that all lazy rewrite systems are left-linear 3 and ﬁnite.
Lazy rewriting operates on labelled terms. Each function and variable symbol of a term has either an eager label e or a lazy label l which we will write as superscripts. So, given a signature Σ = {f1, ..., fn}, we consider a new signature Σ' = {fe,fl , ..., fe,fl }. We denote by V ' the set of labelled variables, so T (Σ',V ')
1	1	n	n
is the set of labelled terms of a labelled signature Σ'. The notation te (resp. tl) for a
labelled term t indicates that t has an eager (resp. lazy) root label. Following [11] we use a replacement map μ to specify for each function f ∈ Σ which arguments should be evaluated eagerly. Given a replacement map μ we define the canonical labelling of terms as a mapping labelμ : T (Σ,V ) →T (Σ',V '), where Σ' is the labelled signature and V ' are the labelled variables [11]:
labelμ(t)= labele (t)
labelα(x)= xα (α ∈ {e, l})
labelα(f (t1, ..., tn)) = fα(labelα1 (t1), ..., labelαn (tn))
μ	μ	μ
where αi = e if i ∈ μ(f ), l otherwise, and α ∈ {e, l}
Given a labelled term t, the unlabeled term erase(t) is constructed from t by omit- ting all labels. A position p of a term t is said to be eager (resp. lazy ), if the symbol at the root of the subterm starting at position p of t has an eager (resp. lazy ) la- bel. Note that the lazy positions of a term are not the same as the non-replacing positions in context-sensitive rewriting. The reason is that in lazy rewriting ea- ger positions may occur below lazy ones whereas in context-sensitive rewriting all positions which are below a non-replacing position are non-replacing.
However, rewrite steps may only be performed at so-called active positions. A position p is called active if all positions on the path from the root to p are eager. Note that, given an unlabeled term t and a replacement map μ, the active positions of labelμ(t) are exactly the replacing positions w.r.t. context-sensitive rewriting.

2 Due to lack of space, the proofs of some results (e.g., of Lemmata 3.13, 3.18 and 3.19) have been omitted here. They can be found in the technical report version of this paper [17].
3 Nevertheless, for clarity we will mention this assumption in the main results.

Definition 2.1 ([11], [3]) The active positions of a labelled term t (denoted Act(t)) are recursively deﬁned as follows.
The root position ϵ of t is active.
If p is an active position and position p.i is eager, then position p.i is active.
Example 2.2 Consider a labelled term fe(al, ge(hl(ae))). Positions ϵ, 2 and 2.1.1
are eager. Positions 1 and 2.1 are lazy and positions ϵ and 2 are active.
Definition 2.3 ([11], [3]) Let l ∈ T (Σ,V ) be linear, t ∈ T (Σ',V ') be a labelled term and let p be an active position of t. Then l matches t|p modulo laziness if either
l ∈ V or
if l = f (l1, ..., ln) and t|p = fe(tα, ..., tα) (α ∈ {e, l}), then for all eager subterms
1	n
te, li matches modulo laziness te.
i	i
If tl at position p.i is a lazy subterm and li /∈ V , then position p.i is called essential.
Informally, a matching modulo laziness is a partial matching ignoring (possible) clashes at lazy positions. Positions where such clashes occur may be activated (i.e., their label may be changed from lazy to eager).
Definition 2.4 ([11]) Let R = (Σ, R) be a (left-linear) TRS. Let t be a labelled term and let l be the left-hand side of a rule of R. If l matches modulo laziness t|p, and this matching gives rise to an essential position p.i (t|p.i = fl(t1, ..., tn)), then
t →A t[fe(t1, ..., tn)]p.i. The relation →A R is called activation relation.
Example 2.5 Let l = f (a, b) be a linear unlabeled left-hand side of a rule, and
t = fe(ae, cl). Then l matches t modulo laziness giving rise to the essential position

and we have fe(ae, cl) →A
fe(ae, ce). The left-hand side l does not match the

labelled term fe(ae, ce) modulo laziness.
Definition 2.6 ([11]) Let l be the (linear) left-hand side of a rewrite rule and let t be a labelled term. If l matches erase(t), then the mapping σl,t : V ar(l) →T (Σ',V ') is deﬁned as follows. For all x ∈ V , with l|q = x : σl,t(x) = t|q.
Informally, σl,t is the matcher when matching l against erase(t), where one adds the appropriate labels of t.
This substitution is modified to operate on labelled terms in the following way, yielding the mapping σs,t : V ' →T (Σ',V ') [11]:

ye
σs,t(xe) = 
⎩ fe(t1, ..., tn)
y
σs,t(xl) = 
⎩ fl(t1, ..., tn)
if σs,t(x) = yα ∈ V '
if σs,t(x) = fα(t1, ..., tn) if σs,t(x) = yα ∈ V '
if σs,t(x) = fα(t1, ..., tn)

σ is homeomorphically extended to a mapping T (Σ',V ') →T (Σ',V ') as usual.
Definition 2.7 ([11]) Let R = (Σ, R) be a (left-linear) TRS with replacement map

μ. The active rewrite relation →R μ: T (Σ',V ') ×T (Σ',V ') is deﬁned as follows: Let t be a labelled term such that the left-hand side of a rewrite rule l → r matches erase(t|p) with σ   and let p ∈ Act(t). Then t →R μ t[σ  (labelμ(r))]p.
Informally, the active rewrite relation →R μ performs rewrite steps according to rewrite rules as usual, but only at active positions, and taking labels into account when constructing the contractum.
Example 2.8 Let l = f (x, b) → g(x) be a rewrite rule and t = fe(he(al), be) be a labelled term. Furthermore, consider a replacement map μ(f ) = μ(h) = {1}, μ(g) = 
∅. Then σl,t(x) = he(al) and σl,t(xl) as appearing in the labelled right-hand side of
the rule is hl(al). Thus we have fe(he(al), be) →R μ ge(hl(al)).
The lazy rewrite relation L→Rμ is the union of the activation relation and the active rewrite relation.
Definition 2.9 ([11]) Let R be a (left-linear) TRS and let μ be a replacement map for R. The lazy rewrite relation L→Rμ induced by (R, μ) is the union of the two
relations →A and →R μ (L→Rμ=→A R ∪ →R μ).
Example 2.10 Consider the functional program of Example 1.1.
from(x) → x : from(s(x))	take(0, xs) → []
take(x, []) → []	take(s(x),y : ys) → y : take(x, ys)
Now we interpret it as lazy term rewriting system with a replacement map μ given by μ(f ) = ∅ for all functions f. When evaluating the canonically labelled term takee(sl(0l),froml(0l)) it is obvious that the subterm froml(0l) must be activated and evaluated before take can be computed. According to the lazy rewrite relation we have: takee(sl(0l),froml(0l)) L→Rμ takee(sl(0l),frome(0l)) L→Rμ takee(sl(0l), 0l : froml(sl(0l))) L→Rμ 0l : takee(0l,frome(sl(0l))) L→Rμ 0l .
Definition 2.11 Let R be a TRS with a replacement map μ. Then R is LR(μ)- terminating if there is no inﬁnite L→Rμ-sequence starting from a term t, whose la- belling is canonical or more liberal (i.e., whenever labelμ(erase(t))|p is eager, then t|p is eager as well).
Informally, we call a labelled term t more liberal than its canonically labelled ver- sion labelμ(erase(t)) if it has strictly more eager labels. The reason for considering terms with canonical or more liberal labelling in the definition of LR(μ)-termination is that only such terms appear in lazy reduction sequences starting from canonically labelled terms, in which we are actually interested.
Example 2.12 Consider a lazy TRS consisting of one rule f (a) → b with a re- placement map μ(f ) = ∅. Now, when considering the canonically labelled term fe(al) we can reduce it to fe(ae) according to the lazy rewrite relation. The latter term is more liberally labelled than its canonically labelled version.

Note that LR(μ)-termination and well-foundedness of →LR do not coincide in general. The reason is that LR(μ)-termination concerns the non-existence of lazy reduction sequences starting from canonically (or more liberally) labelled terms, while there may still be infinite reduction sequences starting from other terms. Example 2.13 shows that the two notions are indeed different.
Example 2.13 Consider the TRS {g(f (a), c) → a, h(x, f (b)) → g(x, h(x, x))} with a replacement map μ(f ) = μ(g) = {1} and μ(h) = {1, 2}. This system is LR(μ)- terminating. This can be shown with the transformation of Deﬁnition 3.8 and
Theorem 3.20. However, →LR is not well-founded: ge(fe(bl), hl(fe(bl),fe(bl))) →LR
μ			μ

ge(fe(bl), he(fe(bl),fe(bl))) →LR  ge(fe(bl), ge(fe(bl), hl(fe(bl),fe(bl)))) →LR
... Note

μ			μ
that the term bl at position 1.1 of the starting term is lazy while it would have been eager in the canonically labelled version of the starting term. This being more lazy is the key for the existence of the inﬁnite reduction sequence.

Transforming Lazy Rewrite Systems
Lucas’ Transformation
We start with the definition of the transformation of [11], because it provides the basic ideas for our new one. The main idea of the transformation is to explicitly mimic activation steps of lazy rewriting through special activation rules in the trans- formed system which basically exchange function symbols to make them more eager (this goes back to [13]). Activations in lazy rewriting are possible at positions which correspond to a non-variable position of the left-hand side of some rule in a partial matching. This is why in the transformation we are concerned with non-variable lazy positions of left-hand sides of rules.
The transformation is iterative. In each iteration new rules are created until a fixed point is reached. The following definition identifies for a rule l → r and a position p the positions p.i which are lazy in labelμ(l). These positions are dealt with in parallel in one step of the transformation.
Definition 3.1 ([11]) Let l → r be a rewrite rule and p a non-variable position of
l, then
I(l, p) = {i ∈ {1, ..., ar(root(l|p))}| i /∈ μ(root(l|p)) ∧ p.i ∈ PosΣ(l)}.
Example 3.2 Consider a rewrite rule l = f (a, b, x) → r and a replacement map
μ(f ) = {1}. Then I(l, ϵ) = {2}.
Definition 3.3 ([11]) Let R = (Σ, R) be a TRS with replacement map μ and let I(l, p) = {i1,..., in} /= ∅ for some rule l → r ∈ R and p ∈ PosΣ(l) where root(l|p) = f. The transformed system Ro = (Σo, Ro) and μo are deﬁned as follows:
Σo = Σ ∪ {fj | 1 ≤ j ≤ n} where fj are new function symbols of arity ar(fj) = 
ar(f )
μo(fj) = μ(f ) ∪ {ij} for all 1 ≤ j ≤ n and μo(g) = μ(g) for all g ∈ Σ

Ro = R − {l → r}∪ {l' → r | 1 ≤ j ≤ n}∪ {l[x]p.i  → l' [x]p.i
| 1 ≤ j ≤ n}

ij	j	j	j
where l' = l[fj(l|p.1, ..., l|p.m)]p if ar(f ) = m, and x is a fresh variable.
The transformation of Definition 3.3 is iterated until arriving at a system Rq = (Σq, Rq) and μq such that I(l, p) = ∅ for every rule l → r ∈ Rq and every position p ∈ PosΣ(l). For further motivation and examples concerning Definition 3.3 we refer to [11].
In [11] it remains unspecified how the pair l, p is selected in one step of the transformation. However, it turns out that the order in which those pairs are considered can be essential.
Example 3.4 Consider the TRS {f (g(a), a) → a, b → f (g(c), b)} with a replace- ment map μ(f ) = {1} and μ(g) = ∅. This system is not LR(μ)-terminating:
be L→Rμ fe(ge(cL), bL) L→Rμ fe(ge(cL), be) L→Rμ fe(ge(cL),fe(ge(cL), bL)) L→Rμ ... 
However, if we start the transformation with the ﬁrst rule and position p = ϵ, and consider position 1 of the ﬁrst rule in the second step of the transformation, then we arrive at the context-sensitive system
f2(g1(a), a) → a	f (g' (a), x) → f2(g(a), x)
f2(g(x), a) → f2(g1(x), a)	f (g(x), y) → f (g' (x), y)
b → f (g(c), b)
with μ(f ) = μ(g1) = μ(g' ) = {1} and μ(f2) = {1, 2}. 4 This system is μ-terminating (proved with AProVE [5]). The lazy reduction sequence starting from b cannot be mimicked anymore, because due to the two transformation steps ﬁrst the argument of g has to be activated which prevents the activation of the b in the second argument of f.

The New Transformation
Deﬁnition
In Lucas’ transformation, positions that are dealt with last during the transforma- tion must be activated first in rewrite sequences of the transformed system. This can be seen in Example 3.4 where I(f (g(a), a), ϵ) is considered in the first step of the transformation but position 2 must be activated after position 1.1 (whose activation is enabled by a later transformation step considering I(f (g(a), x), 1)).
Thus, the order in which lazy positions of rules are dealt with during the trans- formation is the reverse order in which they may be activated in the resulting transformed system. Since we want to simulate lazy rewriting, and in lazy rewrit- ing only outermost lazy positions may be activated in a labelled term, we consider more inner lazy positions first in our new transformation. Therefore, with the re- sulting context-sensitive system more outer positions may be activated only before

4 Here and subsequently the subscripts of function symbols indicate additional replacing positions. So the replacement map of a symbol fi differs from that of f in that i is replacing in fi.

more inner ones.
Despite considering more inner positions first in the transformation, we do not want to prioritize any (orthogonal) lazy positions. Thus, we define I(l) which identifies the innermost lazy positions in a term with respect to a given replacement map μ.
Definition 3.5
I(l) = {p ∈ PosΣ(l) | p is lazy in labelμ(l) ∧
∧ (∄q ∈ PosΣ(l) : q lazy in labelμ(l) ∧ q > p)} .
Before presenting the formal definition of our new transformation (see Definition 3.8 below), which crucially relies on Definition 3.5, we want give an informal expla- nation and illustration of its essential features. In our transformation we distinguish two kinds of rules that are generated. On the one hand we have activation rules which are characterized by the fact that in these rules the left- and right-hand side differ only at exactly one position, where in the right-hand side a different function symbol as in the left-hand side is used. While having the same arity, the different function symbol in the right-hand side has exactly one more replacing position and the argument at that position is a variable (in both sides). All other rules are active rewrite rules.
The actual transformation proceeds in 3 stages. First, a set of initial activation rules is created. These rules enable the activation of one innermost position of a left-hand side of the original rules of the lazy TRS. As already indicated, by a rule activating position p.i we mean a rule l → r where l and r differ only in the function symbol at position p and p.i is replacing in r but non-replacing in l.
In the second stage one rule l → r (activating a position p) created in stage 1 (or stage 2) is replaced by a set of activation rules. This set contains two activation rules for each innermost lazy non-variable position of l. Let q be such a position (note that q is either above or orthogonal to p). Then the first of these two rules is a rule which activates q. Apart from that, both sides of this rule are identical to l (i.e. position p is still inactive). The second rule activates position p. However, in this rule position q is already active. So the second rule differs from the initial rule l → r only in that position q is replacing in both sides (cf. Example 3.6).
Example 3.6 Assume an activation rule l = f (g(x), a) → f (g1(x), a) was gener- ated in step 1 of the transformation where μ(g) = μ(f ) = ∅ and μ(g1) = {1}. The rule activates position p = 1.1. The left-hand side of this rule (if canonically labelled) has two innermost non-variable lazy positions I(l) = {1, 2}. Thus, it will be replaced by a set of new rules. We ﬁrst consider the innermost lazy position q = 1. So ﬁrst, a rule is created which activates q where p is non-replacing (in this special case po- sition p does not even occur in the rule). This rule is f (y, a) → f1(y, a). Second, we create a rule which activates p while q already is active: f1(g(x), a) → f1(g1(x), a). These two rules illustrate that in a system obtained by this kind of transformation more outer positions (like position 1) may be activated only before more inner ones (like 1.1). For the second innermost lazy position of the original rule we also obtain two rules:

f (g(x), z) → f2(g(x), z)	f2(g(x), a) → f2(g1(x), a)
We have μ(f1) = {1} and μ(f2) = {2}. Note that all of the generated rules still have non-replacing non-variable positions in their left-hand sides. Hence, each of them must be transformed (and replaced) further in the same way as the original rule of this example was processed.
This construction ensures that with the obtained rules in every derivation q (which was considered after p in the transformation) is activated before p, which is sound as p is a more inner (or parallel) position compared to q (since it was considered first).
The latter construction is repeated until the rules obtained do not have any lazy (non-variable) positions. We would like to point out once again that, as we consider innermost positions of terms in stage one and one iteration of stage two in our transformation, the outermost lazy positions of the initial rules of the lazy system are dealt with last. Hence, these are the positions which may be activated first in reduction sequences of the transformed system.
In the third stage of the transformation for each rule of the original lazy system one active rewrite rule is created. This rule differs from the original rule from which it was created only in the fact that the left-hand side is fully activated, i.e. it contains no lazy non-variable position. The reason is that whenever an active reduction step is performed on a lazy sequence it can be simulated by first fully activating the redex with the generated activation rules and afterwards performing the actual active step. This is done in derivations of our transformed system.
Since all new function symbols which are introduced by the transformation are substituted for function symbols of the original signature, we define the mapping orig from the signature of the transformed system into the original signature which identifies for each new function symbol the original one for which it was substituted.
Definition 3.7 Let R = (Σ, R) be a TRS with replacement map μ. If in one step of the transformation f ∈ Σ is replaced by a new function symbol f', then orig(f') = f. Furthermore, if f' is substituted for a function symbol g /∈ Σ, then orig(f') = orig(g). For function symbols h ∈ Σ, we set orig(h) = h and for variables we have orig(x) = x.
Definition 3.8 Let R = (Σ, R) be a TRS with replacement map μ. The trans- formed system R = (Σ, R) with μ is constructed in the following three stages.
Generation of Initial Activation Rules. The transformed signature Σ ⊇ Σ
and the set A(l) for every rule l → r ∈ R are deﬁned as the least sets satisfying
l[x]p.i → l'[x]p.i ∈ A(l) if p.i ∈ I(l) and l' = l[fi(l|p.1, ..., l|p.n)]p	(1)
∧ fi ∈ Σ
∧ orig(g) = orig(h) ∧ μ(g) = μ(h) ⇒ g = h for all g, h ∈ Σ
where μ is deﬁned by μ(f ) = μ(f ) for all f ∈ Σ and μ(f ) = μ(orig(f )) ∪ {i}
if fi was introduced in (1). Then we have R :=  L→r∈R A(l).
Saturation of Activation Rules.

Processing one Activation Rule Let R = A(l1) ∪ ... ∪ A(lm) and let l → r ∈ A(lj) for some j ∈ {1, ..., m} such that I(l) is not empty. Then we modify the set A(lj) in the following way:
A(lj) = A(lj) − {l → r}∪ {l[x]p.i → l'[x]p.i}∪ {l' → r'}
for all p.i ∈ I(l) where l' = l[fi(l|p.1, ..., l|p.n)]p and r' = r[f'(r|p.1, ..., r|p.n)]p. If there is no g ∈ Σ˜ with orig(g) = orig(fi) and μ(g) = μ(root(l|p)) ∪ {i}, then Σ˜ = Σ˜ ∪ {fi} and μ(fi) = μ(root(l|p)) ∪ {i}, otherwise fi = g. Analogously, if there is no g ∈ Σ˜ with orig(g) = orig(f') and μ(g) = μ(root(r|p)) ∪ {i}, then

i	i

R :=	 
L→r∈R
i

A(l)

Iteration Step 2.a is iterated until for all rules l → r of R we have that
I(l) = ∅.
Generation of Active Rewrite Rules. For each rule l → r ∈ R we add one active rewrite rule to R. For every position p ∈ PosΣ(l), we consider the set
Symb(p, l) = {root(r'|p) | l' → r' ∈ A(l) ∧ p ∈ PosΣ(r')}.
The function symbol which is least restrictive in this set (i.e., the maximal element of μ(f ) w.r.t. the subset relation of all f ∈ Symb(p, l)) is unique and denoted by maxSymb(p, l). We set

R := R ∪ 
L→r∈R

l'' → r

where l'' is given by Pos(l) = Pos(l''), root(l''|p) = maxSymb(p, l) for all p ∈ PosΣ(l) and root(l''|p) = root(l|p) for all p ∈ PosV (l). The signature of the transformed system is not altered in this stage.
The transformation is terminating and produces a finite context-sensitive rewrite system (CSRS) provided that the input is finite. Furthermore, the function symbol maxSymb(p, l) is unique for every rule l → r ∈ R and every p ∈ PosΣ(l) (cf. [17] for further details).
Example 3.9 Consider the TRS from Example 3.4 {l1 = f (g(a), a) → a, l2 = b → f (g(c), b)} with a replacement map μ s.t. μ(f ) = {1} and μ(g) = ∅. In the ﬁrst stage of the transformation we have I(l1) = {1.1, 2} and the following two initial activation rules are added (i.e. A(l1)). {f (g(x), a) → f (g1(x), a),f (g(a), x) →
f2(g(a), x)} with μ(g1) = {1} and μ(f2) = {1, 2}. A(l2) = ∅, because l2 does not contain any lazy non-variable positions. In step 2.a, the ﬁrst rule of A(l1) is re- placed by {f (g(x), y) → f2(g(x), y), f2(g(x), a) → f2(g1(x), a)} where the position
p.i that was used is 2 (i.e., ϵ.2) and thus the new function symbol introduced is f2. In the second iteration, the second rule of A(l1) is replaced by {f (g(x), y) → f (g1(x), y),f (g1(a), x) → f2(g1(a), x)}. Here, the position p.i that was used is

1.1 and thus the new function symbol is g1. Finally, the following active rewrite rules are added: {f2(g1(a), a) → a, b → f (g(c), b)}. For l1 we have Symb(ϵ, l1) = 
{f, f2}, Symb(1, l1) = {g, g1} and Symb(1.1, l1) = Symb(2, l1) = {a}. There- fore, maxSymb(ϵ, l1) = f2, maxSymb(1, l1) = g1, maxSymb(1.1, l1) = a and maxSymb(2, l1) = a. For l2 we trivially have maxSymb(ϵ, l2) = b. Hence, the system R˜ consists of
f (g(x), y) → f2(g(x), y)	f2(g(x), a) → f2(g1(x), a)
f (g(x), y) → f (g1(x), y)	f (g1(a), x) → f2(g1(a), x) f2(g1(a), a) → a		b → f (g(c), b)
with μ(f ) = μ(g1) = {1}, μ(f2) = {1, 2} and μ(g) = ∅. R is not μ-terminating:
b →μe f (g(c), b) →μe f2(g(c), b) →μe f2(g(c),f (g(c), b)) →μe ... 
Remark 3.10 Note that the above system could not have been derived with Lucas’ transformation regardless of the order in which the positions are processed there. The reason is that when applied to this example, Lucas’ transformation always enforces some order of activation of the two orthogonal lazy positions, whereas the new transformation does not.
The rest of the paper is concerned with the proof of soundness and completeness of the transformation of Definition 3.8 w.r.t. termination. First, we will deal with the simpler case of completeness.

Soundness and Completeness
Theorem 3.11 Let R = (Σ, R) be a left-linear TRS with replacement map μ, and let R = (Σ, R), μ be the transformed system (resp. replacement map) according to Deﬁnition 3.8. If R is LR(μ)-terminating, then R is μ-terminating.
In order to prove the soundness of our transformation, we are going to show the existence of an infinite reduction sequence in the transformed system, whenever there is an infinite lazy reduction sequence in the original system. So assume there is an infinite lazy reduction sequence in a TRS R with replacement map μ. The first observation is that every lazy reduction sequence naturally corresponds to a context-free (i.e. ordinary) →R-sequence, which performs the active rewrite steps of the lazy reduction sequence. We will construct a →μe-reduction sequence in the transformed system R that corresponds to a context-free →R-sequence, cf. Figure 1. Terms in the context-free →R-sequence and terms in the corresponding μ-sequence are in a special relationship.
Definition 3.12 Let R = (Σ, R) be a TRS, μ a replacement map and let s, t ∈ T (Σ,V ) be two terms. Abusing notation we write s →∗c t if and only if
for all positions p ∈ Posμ(t) we have root(t|p) = root(s|p), and
for all minimal positions q ∈ Pos(t)\Posμ(t) we have s|q →∗ s' and s' →∗c t|q.
μ	μ
The idea behind →∗c is that context-free reduction steps which occur at positions



t1
verase
 LR)
μ
t2
verase
 LR)
μ
t3
verase
 LR)
μ
t4
verase
 LR)
μ
... 

erase(t1)  )=erase(t2)  )=erase(t3)   )=erase(t4)   )=
... 

∗ ˆμec	∗ ˆμec
∗ ˆμec
∗ ˆμec

'	 )∗	'
1	μe	2
  )∗	'
μe	3
  )∗	'
μe	4
  )∗
μe
... 


Fig. 1. Relation between the various rewrite sequences occurring in the soundness proof.


that are in the replacing part of the simulating term should be simulated, thus the replacing parts of two terms s and t with s →∗c t must be entirely equal. On the other hand, context-free steps that occur at positions which are forbidden in the simulating term are ignored. Yet, if the forbidden subterm in which they occur eventually gets activated, then these steps may still be simulated.
As minimal non-replacing positions in a term are always strictly below the root, the recursive description of →∗c in Definition 3.12 is well-defined.
We have s = t ⇒ s →∗c t. Figure 1 illustrates the correspondence between a lazy reduction sequence, the corresponding context-free one, and the →μe-sequence. Note that if the lazy reduction sequence is infinite, then there are infinitely many non- empty steps in the context-free reduction sequence, as every labelled term admits only finitely many activation steps.
In the first part of the soundness proof we show the existence of a →μe-sequence of the shape as in Figure 1.
The next lemma establishes the relationship between a context-free reduction sequence and a corresponding →μe reduction of Figure 1.
Lemma 3.13 Let (R = (Σ, R), μ) be a TRS with replacement map and let (R = (Σ˜, R˜), μ˜) be the system obtained by the transformation of Deﬁnition 3.8. Let s and
t be terms from T (Σ,V ), such that s →∗c t. If t → t∗ (with a rule l → r) and

p ∈ Posμe(s), then s →+ s∗ and s∗ →∗
t∗. Otherwise, if t p
t∗ and p /∈ Posμe(s),

μe
then s →∗ s∗ and s∗ →∗c t∗.
μec	→

μe	μe
Unfortunately, the last lemma and the correspondence of lazy, context-free and
→μe-reduction sequences of Figure 1 are not sufficient to prove the existence of an in- finite →μe-sequence in the presence of an infinite lazy reduction sequence, since there may be only finitely many non-empty →μe-reductions in the simulating sequence.
Example 3.14 Consider a TRS R consisting of the rules {a → f (a),f (b) → b}. This system is not LRμ-terminating when considering a replacement μ with μ(f ) = 
∅. Consider the inﬁnite lazy reduction sequence
ae L→Rμ fe(aL) L→Rμ fe(ae) L→Rμ ... 
The transformed system is {a → f (a),f (x) → f1(x), f1(b) → b} with μ(f ) = ∅ and μ(f1) = {1}. We can simulate the inﬁnite lazy reduction sequence by a →μe f (a) →μe f1(a) →μe ... Note that in this simulating derivation function symbols of

the extended signature are introduced which are not immediately “consumed” by a more outer active rewrite step. Example 3.15 shows that this can lead to problems.
Example 3.15 Consider a non-terminating TRS R = {f (g(x)) → f (g(x)), g(a) →
g(b),a → c} with a replacement map μ given by μ(f ) = {1} and μ(g) = ∅. The
transformed system R˜ is {f (g(x)) → f (g(x)), g(x) → g1(x), g1(a) → g(b),a → c}
with μ(f ) = μ(g1) = {1} and μ(g) = ∅. Consider the context-free reduction sequence
f (g(a)) → f (g(c)) → f (g(c)) → ... . If we activate position 1.1 in f (g(a)) in

the simulating →μe-sequence, we cannot further extend f (g(a)) →μe
f (g1(c)), because the term f (g1(c)) is a →μe-normal form.
f (g1(a)) →μe

The crucial difference why the activation of a subterm is essential in Example
3.14 and unnecessary in Example 3.15 is that in the former example the activated subterm itself initiates an infinite lazy reduction sequence. This observation will be used in the second part of the soundness proof (cf. Theorem 3.20).
When constructing an infinite reduction sequence in the transformed system corresponding to an infinite lazy sequence in the soundness proof, we will identify those activations that activate a non-terminating subterms sinf and simulate them
by activating the corresponding subterm s'	in the simulating sequence. After-
wards, we will focus only on an infinite lazy reduction sequence initiated by sinf . This way the simulated activation, i.e., the introduction of a function symbol of the new signature, is of no relevance for the further simulation as it happened outside
'
inf
With the following definition we intend to identify labelled terms in an infinite lazy reduction sequence with non-terminating proper subterms that have possibly been activated. For such terms t, the predicate mininf (t) does not hold.
Definition 3.16 Let Σ be a signature and μ be a replacement map for Σ. A la- belled term t is said to be minimal non-terminating if it admits an inﬁnite lazy reduction sequence and for each eager labelled proper subterm t|p of t, either t|p does not initiate an inﬁnite lazy rewrite sequence, or position p is eager in the term labelμ(erase(t)). We write mininf (t) if t has this property.
Definition 3.17 Let R = (Σ, R) be a TRS with replacement map μ. Let t be a labelled term t and t L→Rμ s be an activation step. This activation step is called inf-activating (thus it is an inf-activation step) if and only if mininf (t) but not mininf (s).
It is easy to see that whenever mininf (t) holds for a labelled term t, there is no active position p ∈ Act(t) which is non-active in labelμ(erase(t)), such that t|p initiates an infinite lazy reduction sequence.
In the second part of the soundness proof we will show that each infinite lazy reduction sequence contains either an inf-activation step or an active rewrite step s L→Rμ t at position p such that p is μ-replacing in erase(s). Furthermore, such steps result in non-empty simulations by the →μe-sequence.
Lemma 3.18 Let R = (Σ, R) be a TRS with replacement map μ. Let t be a labelled term satisfying mininf (t). Then we have:

If t L→Rμ s with an inf-activation step at position q1 activating position q2 and q1 < p ≤ q2 is the maximal (w.r.t. ≤) eager position in s which does initiate an inﬁnite reduction sequence s.t. t|p does not, then we have mininf (s|p).
If t L→Rμ s with any other step than in (i) (i.e., activation steps which are not inf-activating, or active rewrite steps), then mininf (s).
The next lemma characterizes infinite lazy reduction sequences starting from minimal non-terminating labelled terms. It states that in such an infinite lazy reduction sequence after finitely many steps there is either an active rewrite step si L→Rμ si+1 at some position p which is active in labelμ(erase(si)) or there is an inf-activation step. We already know from Lemma 3.13 that active rewrite steps at such positions can be simulated by a non-empty sequence in the transformed system (remember that the active rewrite steps of a lazy reduction sequence correspond to a context-free derivation). In Theorem 3.20 we will prove that the same is true for inf-activation steps.
Lemma 3.19 Let R = (Σ, R) be a TRS with a replacement map μ. Let t0 be a labelled term with the property mininf (t0). Let P : t0 L→Rμ t1 L→Rμ ... L→Rμ tn L→Rμ ... be an inﬁnite lazy reduction sequence starting from t0. Then, either there is an active rewrite step ti L→Rμ ti+1 at position p, where p is active in labelμ(erase(ti)), or there is an inf-activation step in P.
Theorem 3.20 Let (R = (Σ, R), μ) be a left-linear TRS with replacement map and let (R = (Σ, R), μ) be the system obtained by the transformation of Deﬁnition 3.8. If R˜ is μ-terminating, then R is LR(μ)-terminating.
Proof. (Sketch) 5 We will show that the existence of an infinite lazy reduction sequence P : t0 L→Rμ t1 L→Rμ ... (where t0 is canonically or more liberally labelled) implies the existence of an infinite reduction sequence in the transformed system.
The following invariant will be maintained for every labelled term ti of an infinite reduction sequence P . Let s0 →μe s1 →μe ... be the simulating reduction sequence we are going to construct:
There is a sj and a position o such that
sj|o →∗c erase(ti|o) ∧ mininf (ti|o)
and position o is μ-replacing in sj and active in ti. Furthermore, ti|o is at least as eager as its canonically labelled version (i.e., whenever labelμ(erase(ti|o)) has an eager label at some position q, then the label of ti|o is eager at that position, too). Note that the latter condition is trivially fulfilled by all terms ti in P , and thus by all subterms, since no “deactivations” are possible in lazy rewriting and active rewrite steps only introduce canonically labelled terms.
We show that a finite initial subsequence of P implies the existence of a non- empty reduction sequence in the transformed system which preserves the invariant. As each term ti|o itself initiates an infinite lazy reduction sequence, this suffices to

5 For a more detailed version of the proof we refer to [17]

show that there is an infinite reduction sequence in the transformed system.
In order to apply Lemma 3.19, we assume mininf (t0). This minimality con- straint can be satisfied, as w.l.o.g. we can find a t0 such that each proper subterm of t0 with an eager label does not initiate an infinite lazy reduction sequence.
The infinite reduction sequence we are going to construct in the transformed system starts with the term s0 = erase(t0). We have s0 →∗c erase(t0).
Lemma 3.19 states that in the lazy reduction sequence starting from t0 there is either an active rewrite step ti L→Rμ ti+1 at position p such that p is active in labelμ(erase(ti)), or there is an inf-activation step. Let tj L→Rμ tj+1 be the first such step.

The goal is to show that the reduction sequence t0 L→R∗
tj+1 can be simulated

by a sequence s0 →+ si such that si|o →∗c erase(tj+1|o) and mininf (tj+1|o) holds
μe	μe
for some position o which is active in tj+1 and replacing in si. We make a case
distinction on whether the step tj L→Rμ tj+1 is an active rewrite step or an inf- activation step.
Assume the step tj L→Rμ tj+1 is an active rewrite step at position p such that p is active in labelμ(erase(tj)). Then, by using Lemmata 3.13 and 3.18 we

can derive that there exists a reduction sequence s0 →∗
si →+
si+1 such that

si+1 →∗c erase(tj+1) and mininf (tj+1).
Assume the step tj L→Rμ tj+1 is an inf-activation step. This implies that a sub- term tj+1|p is activated, which is non-LR(μ)-terminating (furthermore, mininf (tj+1|p) holds according to Lemma 3.18). Then we can construct a sim-
ulating sequence s0 →∗ si →+ s∗ where in the non-empty subsequence si →+ s∗
μe	μe	i	μe	i
position p is activated and the subterm at position p is reduced in order to obtain
s∗|p →∗c erase(tj+1|p) (cf. Definition 3.12).
i	μe

Now given an infinite lazy reduction sequence P starting from a labelled term
t0 and a term s0 with s0 →∗c erase(t0), we have shown that a ﬁnite subse- quence t0 L→R+ ti of a special shape implies the existence of a non-empty sequence
s0 →+ sj such that sj|p →∗c erase(ti|p), where p is active in ti and replacing in
μe	μe
sj, mininf (ti|p) holds and ti|p initiates an infinite lazy reduction sequence. Thus, again the infinite lazy sequence starting at ti|p has a finite subsequence, that can be simulated by a non-empty reduction sequence in the transformed system. By
repeating this construction, we get an infinite reduction sequence in the transformed system starting at s0.	 

Experiments and Discussion
In the proof of Theorem 3.20 we saw that the context-sensitive rewrite system (CSRS) obtained by our transformation cannot simulate lazy reduction sequences in a one-to-one fashion. When simulating infinite lazy reduction sequences, after every inf-activation step in the lazy reduction an entirely new infinite lazy sequence was considered, namely the one initiated by the activated subterm. Thus, the ques-

tion arises whether we can define a transformation from lazy rewrite systems into context-sensitive ones, such that the transformed system is able to fully simulate the lazy reduction system. We conjecture that this is indeed possible ([16]), but would render termination proofs more difficult. The reason is that such a transformation would need to introduce even more rules that alter the status (i.e., lazy or eager) of positions in lazy terms (to be more precise, more activation rules would be needed). Regarding the size of the transformed system, the number of rules created by our transformation is in general exponentially higher than the number of lazy non- variable subterms in left-hand sides of rules of the lazy system. However, we found that in our test series that was taken from the termination problem database ([18]) this number was not too high in most of the systems. This leads to the ques- tion whether our transformation is practically feasible in proofs of termination of real-world lazy TRSs. A series of tests were performed to answer this question, cf. [17]. As this is the first experimental termination analysis of lazy TRSs, nei- ther lazy test TRSs nor benchmarks of other methods for proving lazy termination were readily available. Thus, we used the context-sensitive TRSs from the [18] and interpreted these systems as lazy ones.  Out of 53 lazy systems that were tested, lazy termination of 35 could be shown.  The tests were performed using
AProVE ([5]) for proving context-sensitive termination of the CSRSs obtained by
our transformation (with a time limit of 10 seconds). When interpreting these results one has to keep in mind that the example TRSs considered were actually supposed to be considered context-sensitive by their authors. Thus, in many cases the changes made by our transformation were only minimal. There were only 3 sys- tems (namely Ex1 Zan97.trs, Ex9 Luc06 and Ex14 AEGL02) for which termination could be proved in the context-sensitive case but not in the lazy case. However, all these systems actually become non-terminating when considered to be lazy instead of context-sensitive. This indicates that in many practical cases the analysis of lazy termination with our approach may well be feasible and a priori not too hard. Furthermore, lazy termination analysis can greatly benefit from ongoing research in the field of context-sensitive termination.

Acknowledgement
We would like to thank the anonymous reviewers of the previous workshop submis- sion for numerous useful hints and criticisms.

References
M. Alpuente, S. Escobar, B. Gramlich, and S. Lucas. On-demand strategy annotations revisited. Technical Report DSIC–II/18/03, UPV, Valencia, Spain, 2003.

F. Baader and T. Nipkow. Term rewriting and all that. Cambridge University Press, New York, NY, USA, 1998.
W. Fokkink, J. Kamperman, and P. Walters. Lazy rewriting on eager machinery. ACM Transactions on Programming Languages and Systems, 22(1):45–86, 2000.


D. P. Friedman and D. S. Wise. CONS should not evaluate its arguments. In S. Michaelson and R. Milner, eds., Proc. 3rd ICALP, pp. 257–284. Edinburgh University Press, 1976.
J. Giesl, R. Thiemann, and P. Schneider-Kamp. AProVE 1.2: Automatic termination proofs in the dependency pair framework. In Ulrich Furbach and Natarajan Shankar eds., Proc. IJCAR’06, LNCS 4130, pp. 281–286, 2006.
J. Giesl, S. Swiderski, R. Thiemann, and P. Schneider-Kamp. Automated Termination Analysis for Haskell: From Term Rewriting to Programming Languages In F. Pfenning, ed., Proc. RTA’06, LNCS 4098, pp. 297–312. Springer, 2006.
J. Giesl, R. Thiemann, and P. Schneider-Kamp. Proving and Disproving Termination of Higher-Order Functions In B. Gramlich, ed., Proc. FROCOS’05, LNAI 3717, pp. 216–231. Springer, 2005.
P. Henderson and J. H. Morris Jr. A lazy evaluator. In Conference Record of the Third ACM Symp. on Principles of Programming Languages, Atlanta, Georgia, Jan. 1976, pp. 95–103, 1976.
S. Lucas. Context-sensitive computations in functional and functional logic programs. Journal of Functional and Logic Programming, 1998(1), 1998.
S. Lucas. Termination of on-demand rewriting and termination of OBJ programs. In H. Sondergaard, ed., Proc. PPDP’01, pp. 82–93, 2001. ACM Press, New York.
S. Lucas. Lazy rewriting and context-sensitive rewriting. In M. Hanus, ed., Proc. WFLP’01, ENTCS 64, Elsevier, 2002.
S. Lucas. Proving termination of context-sensitive rewriting by transformation. Information and Computation, 204(1):1782–1846, 2006.
Q. H. Nguyen. Compact normalisation trace via lazy rewriting. In B. Gramlich and S. Lucas, eds.,
Proc. WRS’01, ENTCS 57, 2001.
M. J. Plasmeijer and M. C. J. D. van Eekelen. Functional programming and parallel graph rewriting. Addison-Wesley, 1993.
R. Strandh. Classes of equational programs that compile into efficient machine code. In N. Dershowitz, ed., Proc. RTA’89, LNCS 355, pp. 449–461. Springer, 1989.
F. Schernhammer. On context-sensitive term rewriting. Master’s thesis, TU Wien, February 2007. 2007.
F. Schernhammer and B. Gramlich. Termination of lazy rewriting revisited. Technical Report E1852- 2007-01 (available at http://www.logic.at/people/schernhammer/papers/), TU Wien, 2007.
Termination Problem Database. Available at http://www.lri.fr/~marche/tpdb.
