Electronic Notes in Theoretical Computer Science 46 (2001)
URL: http://www.elsevier.nl/locate/entcs/volume46.html 10 pages


Reconstruction of hv-convex Binary Matrices from Their Absorbed Projections

Attila Kuba 1,2 and Antal Nagy 3
Department of Applied Informatics University of Szeged
Szeged, Hungary



Abstract
The reconstruction of hv-convex binary matrices from their absorbed projections is considered. Although this problem is NP-complete if the non-absorbed row and column sums are available, it is proved that such a reconstruction problem can be solved in polynomial time from absorbed projections when the absorption is
represented by β = (1+√5)/2. Also a reconstruction algorithm is given to determine
the whole structure of hv-convex binary matrices from such projections.

Introduction
The reconstruction of binary matrices from their row and column sums is a basic problem in discrete tomography (DT). There are several theories, al- gorithms, and applications connected with this problem. As a collection of related papers see [1]. One of the most intensively studied classes of DT is the class of hv-convex binary matrices, in which there is no 0 between two 1s in their rows and columns (in other words, the rows and columns have consecutive-1 property). This problem was posed and a reconstruction al- gorithm was given by Kuba [2]. As it was proved later by Woeginger the complexity of this reconstruction problem is NP-complete [7].
Recently a new kind of discrete tomography problems have been intro- duced [3]. These new type of problems can be considered as the topics of the emission discrete tomography, shortly EDT, connected to a kind of emission model: The function to be reconstructed represents a radioactive object emit- ting activity into the surrounding space, where the space is filled with some

1 This work was supported by the grants FKFP 0908/1997 and OTKA 032241
2 Email: kuba@inf.u-szeged.hu
3 Email: nagya@inf.u-szeged.hu
◯c 2001 Published by Elsevier Science B. V. Open access under CC BY-NC-ND license.


absorbing material. Accordingly, the measurements in EDT are so-called ab- sorbed projections depending on not the emitting object only but also on the absorption itself. It is known that the problem of uniqueness in EDT (in the case of certain absorption) is more complicated [3] than the same problem with non-absorbed projections.
In this paper we are going to show that there is at least one problem which is easier in the case of absorbed projections, where the absorption is represented with a special value of β. This is the problem of reconstructing hv-convex binary matrices from their absorbed row and column sums. We are going to show that this problem can be solved in polynomial time and a reconstruction algorithm is also given.
The organisation of this paper as follows. First the necessary defini- tions and notation are introduced. Section 3 contains the concept of β- representation which can be used very well in the case of absorbed row and column sums. It turns out that there is a very limited way to create binary rows and columns having the consecutive-1 property with given absorbed row and column sums. From this limitation it follows in Section 4 that many 0s and 1s of the binary matrix can be recognised simply from the row or column sums. Finally, in Section 5 we give an algorithm with polynomial time com- plexity, which is able to reconstruct all hv-convex binary matrices. The whole theory to be presented in this paper can be extended in higher dimensions as well.

Definitions and Notation
Let A = (aij)m×n be a (0,1)-matrix (in another words: binary matrix) with size m × n, i.e., aij ∈ {0, 1} for i = 1,..., m, j = 1,..., n. The pair (i, j) will be called position. The row and column sum vectors of A, R(A)= (r1,..., rm) and S(A)= (s1,..., sn), respectively, are defined as
ri = Σ aij,	i = 1,...,m ,
j=1
sj = Σ aij,	j = 1,...,n .
i=1
Then the reconstruction problem for binary matrices can be defined as follows.
Problem 2.1 Reconstruction M
Given: m, n ∈ N and R ∈ Nm, S ∈ Nn (N0 denotes the set of nonnegative
0	0
integers).
Task: Construct a binary matrix A with size m × n such that
R(A) = R	and	S(A) = S . 


This problem was studied, for example, by Ryser [6], who gave also a reconstruction algorithm with time complexity O(mn).
The reconstruction problem M is too general for many applications because of the high number of solutions. It is interesting to study similar reconstruction problems in different classes of binary matrices, where binary matrices with some special properties are to be reconstructed. Such a property can be the consecutive-1 property.
Definition 2.2 Let a1 ··· ak be a word of 0s and 1s, i.e., ai ∈ {0, 1} for i = 1,..., k. We say that a1  ak has the consecutive-1 property if there is no 0 between two 1s in it. Accordingly, the consecutive-1 property can be defined for the words constructed from the rows and columns of binary matrices (it is called horizontal and vertical convexity, or shortly, h- and v-convexity). If all rows and columns of a binary matrix have this property then we say that the binary matrix is hv-convex.
Problem 2.3 Reconstruction hvM
Given: m, n ∈ N and R ∈ Nm, S ∈ Nn.
Task: Construct an hv-convex binary matrix A with size m × n such that
R(A) = R	and	S(A) = S . 
This problem was posed and a reconstruction algorithm was given by Kuba [2]. As it turned out later the complexity of this reconstruction problem is NP-complete [7].
We are going to study a similar reconstruction problem in the case of absorbed projections (see [3]). The absorbed projections are defined here in a special case when the absorption is characterised by the constant
1+ √5
β =	.
2
It is easy to see that constant β has the following property.

(1)
β−1 = β−2 + β−3 .
Then the absorbed projections can be defined as follows.

Definition 2.4 Let A be a binary matrix with size m × n. Its absorbed row and column sum vectors, Rβ(A) = (r1,..., rm) and Sβ(A) = (s1,..., sn), respectively, are defined as
ri = Σ aijβ−j,	i = 1,...,m ,
j=1 m

(2)
sj = Σ aijβ−i,	j = 1,...,n .
i=1
Then consider the following reconstruction problem for hv-convex binary

matrices from their absorbed row and column sums.

Problem 2.5 Reconstruction hvMA
Given: m, n ∈ N and R ∈ Rm, S ∈ Rn (R0 denotes the set of non-negative
0	0
real numbers).
Task: Construct an hv-convex binary matrix A with size m × n such that
Rβ(A) = R	and	Sβ(A) = S . 

β-representations
Let R and S be the absorbed row and column sums of the binary matrix A = (aij)m×n. Then, using the terminology of numeration system [5], we can say on the base of (2) that ai1 ··· aim is a (ﬁnite) representation in base β of ri or it is a (ﬁnite) β-representation of ri for i = 1,... m. Similarly, a1j ··· amj is a β-representation of sj for j = 1,..., n. It is quite easy to see that in general the β-representation is not unique. As an example, consider the following two finite β-representations of the number 1/β:
(3)	100 = 011 ,
because 1 · β−1 +0 · β−2 +0 · β−3 = 0 · β−1 +1 · β−2 +1 · β−3 on the base of (1). Even more, if there is one of the sub-words 011 and 100 in a β0-represen- tation then it can be replaced by the other one without changing the value of the representation. This operation is called 1D elementary switching. For example, consider the word 01000 having length 5. A 1D elementary switching can be done in the positions 2, 3, and 4 getting the word 00110 still represent- ing the same number. The words 011 and 100 are called 0-type and 1-type 1D elementary switching words, respectively, also the switching pair expression can be used. In [4] it is proved that the β-representations of the same number
can be got from each other by such switchings.
Generally, the following Lemma is true, see Section 2.1 in [3].
Lemma 3.1 Let a1 ··· ak and b1 ··· bk be different, k-digit-length β0-represen- tations of the same number. Then b1 bk can be get from a1 ak by a ﬁnite number of 1D switchings having the form
01x21x41 ··· x2l11 ←→ 10x20x40 ··· x2l00	(l ≥ 0) ,
where x2, x4,..., x2l denotes positions in the corresponding sub-words where the two representations have the same binary digit.
A simple consequence of this lemma is that if A and A' are different binary matrices with the same absorbed row and column sums then the elements where the matrices are different constitute subsequences 01x21x41 ··· x2l11 and 10x20x40 ··· x2l00 (l ≥ 0) in the rows and columns of the matrices.
Let r	and take the greatest β-representation of r with respect to the lexicographic order, it is called the β-expansion and it is denoted by
⟨r⟩. Furthermore, let the class of k-digit-length β-representations with the

consecutive-1 property be denoted by r(c).	For example, if r = 1/β then
r(c) = {10000, 01100} and ⟨r⟩ = 10000.
Let Ck denote the set of non-negative real numbers having a k-digit-length β-representation with consecutive-1 property, formally
(c)
Ck = {r | r	/= ∅} .
Lemma 3.2 For any real number r	Ck (k	N) there are at most two
k-digit-length β-representations with the consecutive-1 property.
Proof. Let r /= 0. r ∈ Ck if and only if r has the form
r = 00 ··· 0011 ··· 1100 ··· 00 ,
where the sub-sequence of 1s starts in position j1 and ends in position j2 (1 ≤ j1  j2  k). According to Lemma 3.1 if there is a different β-representation of r then it can be generated from (6) by switchings
01x21x41 ··· x2l11 ←→ 10x20x40 ··· x2l00	(l ≥ 0) .
It is easy to check that only the switching

011 ←→ 100
is possible between two β-representations in r(c)

and this switching can be

done if and only if

or (10)
giving
1 ≤ j1 = j2,	j2 +2 ≤ k

1 < j1,	j1 +1 = j2 ≤ k

(11)
(c)
k
= {00 ··· 010000 ··· 0, 00 ··· 001100 ··· 0} .

In every other cases r(c) contains only one representation (6).	✷
Let r ∈ Ck. The positions of r(c) can be classified as variant and invariant
positions as follows.
Definition 3.3 The position i (1 ≤ i ≤ k) is variant in the class r(c) if there are two β-representations in r(c) such that they have different (binary) digits in position i. The position i is invariant 0 if all of the β-representations in r(c) has digit 0 in position i. Finally, the position i is invariant 1 in the class
r(c) if all of the β-representations in r(c) has digit 1 in position i.
k	k
For example, let r = 1/β again and consider the class r(c) = {10000,
01100}. Then the positions 1,2, and 3 are variant, and positions 4 and 5 are
invariant 0 in r(c).
From the viewpoint of variant and invariant positions Lemma 3.2 has the following consequence.

Corollary 3.4 Let r ∈ Ck (r /= 0 and k ∈ N). There are at most three variant positions in the class r(c) as it can be seen from the following cases.
Case 1. If there is exactly one 1 in r , say in position j, and j < k  1 then the positions j, j + 1, and j +2 are variant, and every other position in r(c) are invariant 0.

Case 2. Otherwise r(c)
has only one β-representation, and so all 0s in

this representation indicate invariant-0 positions and all its 1s indicate invariant-1 positions in r(c).

Variant and Invariant Positions of hv-convex Binary Matrices
Let R ∈ Cm and S ∈ Cn . Let A(hv) = A(hv)(R, S) denote the class of hv-
convex binary matrices having absorbed projections R and S.
Definition 4.1 The position (i, j) (1 ≤ i ≤ m, 1 ≤ j ≤ n) is variant in the class A(hv) if there are A, A' ∈ A(hv) such that aij /= a' . The position (i, j) is invariant 0 in the class A(hv) if aij = 0 for all A ∈ A(hv). Finally, the position (i, j) is invariant 1 in the class A(hv) if aij = 1 for all A ∈ A(hv) .
It is easy to see that if A(hv)(R, S) /= ∅ then we have the following relation between the variant and invariant positions in (r )(c)/(s )(c) and A(hv)(R, S).
If j is an invariant position in (r )(c) then (i, j) is the same type invariant
i n
position in A(hv)(R, S). Similarly, if i is an invariant position in (s )(c) then
j m
(i, j) is the same type invariant position in A(hv)(R, S).
As a consequence we get
Corollary 4.2 There are at most three variant positions in each row and column in A(hv).
Definition 4.3 A binary matrix is unique among the hv-convex binary ma- trices with respect to its absorbed row and column sums if there is no other hv-convex binary matrix with the same absorbed row and column sums. Oth- erwise the matrix is called non-unique.
As the simplest examples of non-unique hv-convex binary matrices consider


(12)


E(0)  =
 0 1 1 
 1 0 0 




and	E(1) =
 1 0 0 
 0 1 1 



On the base of (3) it is easy to check that E(0) and E(1) have the same ab- sorbed row and column sums, therefore they are non-unique hv-convex binary matrices. These matrices play important role also in the theory of (not nec-

essarily hv-convex) unique binary matrices (see [3]), E(0) and E(1) are called the 0-type and 1-type 2D elementary switching patterns, respectively.
The 2D elementary switching patterns play important role also in the class of hv-convex binary matrices as it can be seen from the following theorem. Let

(0)
(i,j)
(1)
(i,j)
denote the corresponding elementary switching patterns if they

are 3 × 3 sub-matrices located in the position {i, i + 1,i + 2}× {j, j + 1,j + 2}
for some i ∈ {1,...,m − 2} and j ∈ {1,...,n − 2}.
Theorem 4.4 A binary matrix is non-unique among the hv-convex binary matrices with respect to its absorbed row and column sums if and only if it con-

tains an elementary switching pattern E(0)
(1)
(i,j)
for some i ∈ {1,...,m −

2	and j	1,...,n	2	such that every other matrix element in rows
i, i + 1,i +2 and columns j, j + 1,j +2 are 0.
Proof. One direction is trivial: If there is an elementary switching pattern as a sub-matrix of the hv-convex binary matrix A then by changing it to the other type of 2D elementary switching pattern we get a new A' hv-convex binary matrix with the same absorbed row and column sums, i.e., A is non-unique.
In order to prove the other direction let us suppose that there are two hv-convex binary matrices, A and A'(/= A), with the same absorbed row and column sums. Let i be the first row where A is different from A' (1 ≤ i ≤ m) and let j be the first column (1 ≤ j ≤ n) in this row where A is dif- ferent from A', that is aij /= a' .  Without the lack of generality we can
suppose that aij = 0 and a'  = 1. Then according to Lemma 3.1 aij and
ij are the first elements of the “difference” subsequences 01x21x41 ··· x2k11
and 10x20x40  x2k00 (k   0) in row i and column j (x2, x4,... x2k de- notes the positions where both subsequences has the same elements). Be- cause of hv-convexity, k = 0 in this case for any such subsequence. That is,

aijai,j+1ai,j+2 = 011 and a' a'	a'
= 100. Applying the same idea to the

ij i,j+1 i,j+2

columns, we get that ai+1,jai+1,j+1ai+1,j+2 = 100 and a'
'
i+1,j+1
i+1,j+2 =

011, and ai+2,jai+2,j+1ai+2,j+2 = 100 and a'
'
i+2,j+1
'
i+2,j+2
= 011. That

is, there is a 0-type/1-type 2D elementary switching pattern in A/A', respec-
tively, in the positions i, i+1, i+2  j, j +1,j +2 . Because of hv-convexity, there is no other 1 in these rows and columns of A and A'.	✷

An Algorithm to Determine Variant and Invariant Positions
Instead of reconstructing an hv-convex binary matrix A from their absorbed row and column sums R and S directly, we determine the variant and invariant positions of the class (hv)(R, S), called the structure of (hv)(R, S). As we know from Theorem 4.4, the knowledge of the variant and invariant positions is equivalent to the knowledge of the positions of the (eventual) 2D elementary switching patterns in any element of A(hv)(R, S).

This algorithm starts to fill a matrix X with the initial values free, in- dicating that the variability of none of the positions is decided yet. Then, on the base of Corollary 3.4, we write 1s and 0s in the rows and columns of X indicating the invariant 0s and 1s, respectively. At most 3 free positions remain in each row and column after this step. The remaining free positions that are in a 3 3 free sub-matrix are variant positions of the class, the others can be determined from the 0s and 1s in their 3 3 neighbourhood. Formally, the algorithm is as follows.
Algorithm 1 for determining the variant and invariant positions of the class of hv-convex binary matrices from absorbed row and column sums
Input: m, n ∈ N, R ∈ Cm, S ∈ Cn .
Output: A matrix Xm×n indicating the variant and invariant positions or the algorithm terminates with contradiction.
Step 1: X := (free)m×n

Step 2: If (i, j) is an invariant position of (r )(c) then let x
= 0/1 accordingly

i n	ij
for i = 1,...,m (see Corollary 3.4).

Step 3: If (i, j) is an invariant position of (sj)(c) then let xij
= 0/1 accordingly

for j = 1,...,n (see Corollary 3.4). If a position gets different values in Steps 2 and 3 then it is a contradiction and the algorithm terminates without giving any indication of variant/invariant positions.
Step 4: For each free position (i, j) if it is not in a free 3 × 3 sub-matrix then set (i, j) to 0 or 1 depending on its 3 × 3 neighbourhood.

As an example of using Algorithm 1 see Fig. 1. Consider the following reconstruction problem: R = (r1, ..., r9) and S = (s1, ..., s10) where ⟨r1⟩ =
⟨r9⟩ = 0000001000, ⟨r2⟩ = 0000000100, ⟨r3⟩ = ⟨r4⟩ = ⟨r5⟩ = 1000000000,
⟨r6⟩ = ⟨r7⟩ = ⟨r8⟩ = 0001000000, ⟨s1⟩ = ⟨s2⟩ = ⟨s3⟩ = 001000000, ⟨s4⟩ =
⟨s5⟩ = ⟨s6⟩ = 000001000, ⟨s7⟩ = 000000001, ⟨s8⟩ = 110000000, ⟨s9⟩ =
100000000, s10 = 000000000. In Fig. 1 the Steps of Algorithm 1 can be followed.The solutions of this reconstruction problem are in Fig. 2.

Theorem 5.1 Algorithm 1 determines the variant and invariant positions of any class A(hv)(R, S) /= ∅ in O(mn) steps.


It is easy to see that if	(hv)(R, S) =	then any element of this class can be generated from the output of Algorithm 1 by replacing the 3	3 free sub-matrices with a suitable 2D elementary switching pattern (E(0) or E(1)). As a final remark we can say that the same method can be used to prove corresponding theorems and algorithms for reconstructing binary matrices in n-dimension from their n (n		2) orthogonal absorbed projections when the
absorption is characterised by the constant β.




0 0 0 0 0 0 . . . 0
a)
0 0 0 0 0 0 1 0 0 0 
b)

0 0 0 0 0 0 0 1 1 0 
0 0 0 0 0 0 0 1 0 0 
. . . 0 0 0 0 0 0 0 
. . . 0 0 0 0 0 0 0 
. . . 0 0 0 0 0 0 0 0 0 0 . . . 0 0 0 0 
0 0 0 . . . 0 0 0 0 
0 0 0 . . . 0 0 0 0 
0 0 0 0 0 0 1 0 0 0 
c)
Fig. 1. Determination of variant and invariant positions by Algorithm 1. a) Result of Step 2. b) Result of Step 3. c) Result of Step 4. (Positions indicated by “.” are free.)
References
Herman, G. T., and A. Kuba, “Discrete Tomography. Foundations, Algorithms, and Applications,” Birkha¨user, Boston, 1999.
Kuba, A., Reconstruction of two-directionally connected binary patterns from their two orthogonal projections, Comp. Vision Graph. and Image Proc. 27 (1984), 249–265.
Kuba, A., and M. Nivat, Reconstruction of discrete sets with absorption, Lecture Notes in Computer Sciences, vol. 1953, Springer-Verlag, Berlin (2000), pp. 137–




Fig. 2. The four solutions of the given reconstruction problem.
148.
Kuba, A., and M. Nivat, A sufficient condition for non-uniqueness in binary tomography with absorption, submitted for publication (2001).
Lothaire, M., “Combinatorics on Words,” Cambridge University Press, Cambridge, 1997.
Ryser, H. J., Combinatorial properties of matrices of zeros and ones, Canad. J. Math. 9 (1957), 371–377.
Woeginger, G. W., The reconstruction of polyominoes from their orthogonal projections, Inform. Proc. Letters 77 (2001), 225–229.
