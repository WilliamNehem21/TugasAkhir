Electronic Notes in Theoretical Computer Science 196 (2008) 37–51	
www.elsevier.com/locate/entcs

Induction on Concurrent Terms
Anders Schack-Nielsen1
Programming, Logics and Semantics IT University of Copenhagen Denmark

Abstract
This paper considers MiniML equipped with a standard big-step semantics and a destination-passing se- mantics both represented in concurrent LF (CLF) and prove the two semantics equivalent. The proof is then examined yielding insights into the issues concerning induction on concurrent terms. We conclude by outlining some of the difficulties that one will need to address when designing a meta-logic for CLF.
Keywords: CLF, logical frameworks, induction, destination-passing style.


Introduction
CLF [1] is a logical framework with several interesting applications including ade- quate representations of the π-calculus, protocols and programming languages em- ploying state, concurrency, lazy computations and more. Furthermore, a large sub- set of these semantic specifications can currently be run with LolliMon [3] which implements parts of CLF. However, CLF currently has no notion of meta-logic and it is therefore not possible to reason about CLF representations within CLF. In this paper we will consider an initial case study in order to shed light on some of the difficulties that one will need to address when designing a meta-logic for CLF.
CLF is a dependently typed lambda calculus extended by linear types and monadic types inhabited by concurrent terms, which makes it a conservative exten- sion of the dependently typed logical framework LF. Therefore CLF supports the same “judgments as types, derivations as terms” methodology as LF. The Twelf system [5] implements LF and provides a meta-logic for reasoning about LF repre- sentations. Twelf is well-suited for formalizing functional programming languages, their operational semantics and type systems, as well as classical and intuitionistic

1 Email: anderssn@itu.dk

1571-0661 © 2008 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2007.09.016

logics. However, imperative and concurrent language features are hard to imple- ment and reason about using Twelf since e.g. state has to be modelled and reasoned about explicitly.
The presence of concurrent terms in CLF allows for a new representation methodology compared to the way e.g. operational semantics has been represented in Twelf. In Twelf the methodology is a goal-oriented approach focusing on proof- search via backward chaining bearing much resemblance to logic programming, whereas in CLF the canonical representation methodology is context-oriented, em- ploying forward chaining inside the monad. As CLF is a conservative extension to LF it allows both styles of representation to coexist.
The Twelf methodology provides means to represent meta-theory and its proofs as higher-level judgments describing relations between derivations, and these proofs can then be mechanically checked by checking the totality of the relation.
So the important question is whether the methodology of meta-theory represen- tation and proof representation known from Twelf can be conservatively extended to deal with the new CLF representations and how. The CLF extensions over LF are linear and concurrent terms, so a conservative meta-logic for CLF would need to extend Twelf with induction on linear and concurrent terms. The importance of this question is emphasized by the fact that it is a main part of the uncharted CLF-territory and contains valuable insight on the directions in which CLF could be further developed.
The case study that we will consider in this paper is the equivalence proof of two semantics for MiniML. On the one hand we can represent a big-step semantics com- pletely within the LF fragment of CLF, and on the other hand we can also represent the semantics in destination-passing style employing the distinct features of CLF. This style of representation is based on multiset rewriting with names (destinations) representing the holes in evaluation contexts. Furthermore, destination-passing style is a natural way to represent semantics in CLF and it allows for easy extension of the MiniML semantics to include lazy evaluation, futures, mutable references and concurrency [2]. Given these two styles of semantics, the equivalence proof will bridge the two different representation methodologies, and we will use the proof to outline some of the difficulties that one will need to address when designing a meta-logic for CLF.

CLF
Syntax
In the CLF type theory we have objects, types and kinds. In order to simplify the meta-theory all terms are required to be in canonical form (i.e. completely beta- reduced and completely eta-expanded), and this invariant can be maintained by a suitable definition of substitution which performes the necessary reduction steps (hereditary substitution).
The CLF types are the ones known from LF (with A → B as syntactic sugar for Πx : A. B as usual) and the linear connectives from LLF, i.e. linear implication

Kinds
K ::= type | Πx : A. K	Kinds
Types
A, B ::= A   B | Πx : A. B | A & B |T| {S}| P	Asynchronous types
P ::= a | P N	Atomic type constructors
S ::= S1 ⊗ S2 | 1 | ∃x : A. S | A	Synchronous types
Objects
N ::= λ^x. N | λx. N | ⟨N1, N2⟩| ⟨⟩ | {E}| R	 Normal objects R ::= c | x | R ^N | R N | π1 R | π2 R	Atomic objects E ::= let {p} = R in E | M	 Expressions
M ::= M1 ⊗ M2 | 1 | [N, M ] | N	Monadic objects
p ::= p1 ⊗ p2 | 1 | [x, p] | x	Patterns
Contexts
Γ ::= ·| Γ,x : A	Unrestricted contexts
Δ ::= ·| Δ,x ^: A	Linear contexts
Signatures
Σ ::= ·| Σ,a : K | Σ,c : A	Signatures
Fig. 1. CLF syntax

(  ), additive product (&) and top (T). Then there is multiplicative product (⊗), the multiplicative unit (1) and dependent pair (∃) all of which are wrapped in a monadic type constructor {S}. The complete syntax is given in figure 1. The destinction between normal and atomic objects is simply there to enforce canonical forms.
Constructing objects inside the monad (i.e. expressions inside curly braces) is supposed to model concurrent computation, and any given term consisting of a sequence of let expressions denotes a trace of that computation. In order to facilitate this interpretation two terms will be considered equivalent if they only differ in the ordering of their let expressions. The equivalence ≡ is defined as the smallest congruence relation satisfying
let {p1} = R1 in let {p2} = R2 in E ≡ let {p2} = R2 in let {p1} = R1 in E

where the bindings are independent: p1 and p2 must bind disjoint sets of variables, no variable bound by p1 can appear free in R2 and vice versa.

Computational interpretation of CLF
The representation of meta-theory in Twelf is based on a computational interpreta- tion of LF signatures as logic programs. With this in place a meta-logic can then be used to state the totality of certain relations, which thereby represent constructive proofs.
The basis of computation is constructing a term of a given type, by the means of proof search. This consists of applying right-rules in the corresponding logic until the goal is reduced to an atomic type, at which point the different constructors of the type is tried one by one by backtracking from unsatisfiable subgoals.
The semantics of CLF is similar (it is implemented as the language LolliMon 2 and described in detail in [3]) except when encountering the monad type. At this point the computation goes from being goal-directed to being context-directed. The context-directed computation consists of a sequence of steps, each of which is a nondeterministic choice between either ending the context-directed mode and con- structing the monadic object M directly or nondeterministically choosing a term in the context (or signature) and reduce it to its monadic head with left-rules at which point the context gets augmented with the newly constructed types using a let-binding: let {p} = R in E, where R is the computation step that was just taken, p is the binding of the newly constructed types and E is the rest of the computation. These steps are considered atomic and are not undone, backtracking is only applied during the construction of the individual steps to make sure that the step
can actually be completed before committing to the nondeterministic choice.

CLF meta-theory
In Twelf, proofs are by structural induction since whatever is represented in Twelf is represented as an inductively defined LF-term. Furthermore the proof objects themselves are inductively defined LF-terms. We expect this meta-level representa- tional methodology to extend to CLF as well, since it is a conservative extension at both the object level and the semantic level. There are however several challenges, and the one we will focus on is how to extend the structural induction known from Twelf to one working with terms with implicit concurrency. 3

MiniML
The primary object of study in this paper will be the semantics of MiniML re- presented in two different ways. The first representation is a big-step semantics represented entirely in the LF fragment of CLF as it would be done in Twelf. The second representation is done in destination-passing style employing the monad and

2 LolliMon is not exactly CLF since for the monadic and linear types it only includes the corresponding logic and not the terms. But currently LolliMon is as close as one gets to an implementation of CLF and it is sufficient for execution of programs in the destination-passing semantics given in this paper.
3 As a side note, notice that the monadic terms potentially allows for a “concurrent” proof built in a more algorithmic manner instead of the usual induction proofs. What this means is however still unclear.

the linear features of CLF (see [2]). The meta-theorem that we will be examining is the equivalence proof of these semantics.
Note that the destination-passing semantics does everything sequentially, but since it is within the monad the potential for concurrency is still enough to generate intersting observations as we will see below. Furthermore the destination-passing semantics can easily be extended with e.g. concurrency, mutable references, lazy evaluation, etc. (as shown in [2]). In section 5 we will discuss some of the compli- cations of the proof in the context of concurrency.
Syntax
The fragment of MiniML that we will be considering include abstractions, applica- tions, fixpoints and natural numbers with zero, successor and case.
e ::= x | z | s e | (case e1 of z ⇒ e2 | s x ⇒ e3) | λx.e | e1 e2 | fix x.e
The MiniML syntax is represented in CLF (and LF) as shown in figure 2.
exp : type.
z : exp.
s : exp → exp.
case : exp → exp → (exp → exp) → exp. lam : (exp → exp) → exp.
app : exp → exp → exp. fix : (exp → exp) → exp.
Fig. 2. MiniML syntax in CLF


Big-step semantics
The first semantics for MiniML is a standard call-by-value big-step semantics (fig- ure 3) and has the standard representation where the type family ev E V is inha- bited if and only if E evaluates to V . 4
The given representation is not strictly a CLF signature as defined in [1] since it is not in canonical form. It can however easily be transformed into the equiva- lent canonical form by eta expansion. In the following I will freely use any form eta equivalent to a canonical form, since the more verbose canonical form can be obtained by mechanical eta expansions.
Destination-passing semantics
The second semantics for MiniML is a destination-passing semantics. Destination- passing style is based on multi-set rewriting and handles evaluation contexts (a.k.a.

4 Note that this semantics as it is given is not suitable for Twelf execution, since Twelf solves subgoals “inside out”. If the semantics should be executed in Twelf, one would therefore have to do a simple rewriting, reversing the order of the arguments of ev case z, ev case s and ev app.

ev : exp → exp → type.
ev_z	: ev z z.
ev_s	: ΠE:exp. ΠV:exp. ev E V → ev (s E) (s V). ev_case_z : ΠE1:exp. ΠE2:exp. ΠE3:exp → exp. ΠV:exp.
ev E1 z → ev E2 V → ev (case E1 E2 E3) V. ev_case_s : ΠE1:exp. ΠE2:exp. ΠE3:exp → exp. ΠV:exp. ΠV’:exp.
ev E1 (s V’) → ev (E3 V’) V → ev (case E1 E2 E3) V. ev_lam	: ΠE:exp → exp. ev (lam E) (lam E).
ev_app	: ΠE1:exp. ΠE2:exp. ΠE1’:exp → exp. ΠV:exp. ΠV2:exp. ev E1 (lam E1’) → ev E2 V2 → ev (E1’ V2) V
→ ev (app E1 E2) V.
ev_fix	: ΠE:exp → exp. ΠV:exp. ev (E (fix E)) V → ev (fix E) V.
Fig. 3. Big-step semantics in CLF


continuations) implicitly by naming the context holes. The names of the holes in the evaluation contexts are called destinations [6]. With the logic programming semantics of CLF outlined above in mind, the destination-passing semantics of MiniML is defined as follows. We introduce a type of destinations dest 5 , a type family eval E D representing the instruction to evaluate E and return the result in destination D and a type family return V D representing the returned value V in destination D. Now the type Πd : dest. eval E d  {return V d} is inhabited if and only if E evaluates to V .
The signature is given in figure 4. Notice how each constructor consumes an eval E D to produce either a return V D representing the result, or a new eval E' d' corresponding to the subexpression to be evaluated next along with a con- tinuation in the form ΠV : exp. return V d' {... }. Take for instance eval_case. Assuming that we have an eval E D in the context with E = case E1 E2 E3 and we aim to construct a return V D in the monad. Then eval_case can be ap- plied to yield a fresh destination d', an eval E1 d' and a continuation which can only be applied when the result of evaluating E1 has finished. The continuation is an additive product which means that we can only ever use one of the branches. The eval E1 d' will trigger further rules and end up with a result in the form of return V1 d' (assuming termination). If V1 is z we can apply the first projection of the continuation and if V1 is s V ' we can apply the second projection. In both cases we end up with a new eval E' D designating the expression to be evaluated and this will in turn trigger further rules and if this terminates we will end up with the result in the form of a return V D.



5 Notice how the type dest is empty since we initially have no evaluation context and thus no holes to name, i.e. all we will ever see are variables of type dest.

dest	: type.
return : exp → dest → type. eval	: exp → dest → type.
eval_z	: ΠD:dest. eval z D  {return z D}. eval_s	: ΠE:exp. ΠD:dest.
eval (s E) D   {∃d’:dest. eval E d’ ⊗
ΠV:exp. return V d’  {return (s V) D}}. eval_case : ΠE1:exp. ΠE2:exp. ΠE3:exp → exp. ΠD:dest.
eval (case E1 E2 (λx. E3 x)) D 
{∃d’:dest. eval E1 d’ ⊗
( (return z d’   {eval E2 D}) &
(ΠV’:exp. return (s V’) d’   {eval (E3 V’) D})
) }.
eval_lam : ΠE:exp → exp. ΠD:dest.
eval (lam (λx. E x)) D   {return (lam (λx. E x)) D}. eval_app : ΠE1:exp. ΠE2:exp. ΠD:dest.
eval (app E1 E2) D 
{∃d’:dest. eval E1 d’ ⊗
(ΠE1’:exp → exp. return (lam (λx. E1’ x)) d’ 
{∃d’’:dest. eval E2 d’’ ⊗
(ΠV2:exp. return V2 d’’   {eval (E1’ V2) D})
}
)
}.
eval_fix : ΠE:exp → exp. ΠD:dest.
eval (fix (λx. E x)) D   {eval (E (fix (λx. E x))) D}.
Fig. 4. Destination-passing semantics
Equivalence of semantics
We would like to prove the equivalence of the two semantics presented above. More formally, we will prove the following theorem:
Theorem 4.1 For all closed terms E and V of type exp, the type ev E V is inhabited if and only if the type Πd : dest. eval E d  {return V d} is inhabited.
The proof consists of two parts, each being a translation from one semantics to the other. We will start with the easy one: translating big-step into destination- passing style.
Translation from big-step to destination-passing style
The paper proof
Lemma 4.2 Let E and V be closed terms of type exp and let P be a closed term of type ev E V . Then there exists a closed term C of type Πd : dest. eval E d 

{return V d}.
Proof. The proof is a simple structural induction on P .
Case: P = ev_z
We take C = eval_z.
Case: P = ev_s E' V ' P '
In this case E = s E', V = s V ' and P ' is of type ev E' V '. We can therefore apply the induction hypothesis to P ' to get a C'. Now let
C = λd.λ^u : eval (s E') d. {let {[d', (p : eval E' d')
⊗ (f : ΠV.return V d'   {return (s V ) d})]}
= eval s E' d ^u in
let {r' : return V ' d'} = C' d' ^p in let {r : return (s V ') d} = f V ' ^r' in r}.

Case: P = ev_case_z E1 E2 E3 V P1 P2
In this case P1 is of type ev E1 z and P2 is of type ev E2 V . We apply the induction hypothesis to P1 and P2 yielding C1 and C2. Now let


'
C = λd.λu.{let {[d , (p
: eval E
'
d ) ⊗ f ]} = eval case E E
E d ^u in

1	1	1	1	2	3

'	'
let {r : return z d } = C1
d' ^p in

let {p2
: eval E2
d} = (π1
f ) ^r' in

let {r : return V d} = C2 d ^p2 in
r}.

The remaining cases are similar. The induction hypothesis is applied to all subterms representing subevaluations (i.e. subterms of type eval E V for some E and V ), after which C is easily constructed.	 

Representation of the proof in CLF
Since the above proof only relies on straigtforward induction on LF-terms it should be easy to represent in CLF for any conservative extension of the Twelf meta-theory to CLF. This is however still very speculative. More on this below in section 4.2.2.

Translation from destination-passing style to big-step
This part of the proof is a lot trickier. We cannot simply deconstruct a term of type eval E D  {return V D} into a constructor and subterms of the same type schema, since this among other things relies on the implicit ordering of the consumption of linear variables.

The paper proof
In order to complete the proof we will need to come up with a much stronger induction hypothesis. We will need to reason about the continuations that can occur in the linear context, and in order to make this precise, we will start with a definition of normal linear contexts to be the relevant linear implications from return ... into a monadic type:
Definition 4.3 A linear context Δ is called normal if it only consists of variables with the following types:
Πv : exp. return v D'   {return (s v) D}
(return z D'  {eval E2 D})
& (Πv' : exp. return (s v') D'   {eval (E3 v') D})

Πe' : exp → exp. return (lam (λx. e'
) D'  {∃d'' : dest. eval E2 d'' ⊗

1	''	1

(Πv2 : exp. return v2 d
  {eval (e'
1
v2) D})}

Πv2 : exp. return v2 D''  {eval (E' v2) D}
for any instantiations of the free variables (written with capital letters).
Notice that these types correspond exactly to the continuations put in the con- text by eval_s, eval_case and eval_app. The latter is represented with two possible types, since the application of the continuation result in yet another con- tinuation.
Now we can state the lemma:
Lemma 4.4 Let Γ be a context of destinations, Γ = d1 : dest,... , dn : dest, and let Δ be a normal linear context. Let E and V ' be closed terms of type exp. Let d and d' be two (not necessarily distinct) destinations in Γ. And let C be a term with a typing Γ; Δ ▶ C : eval E d  {return V ' d'}. Then there exists a closed term V of type exp,a closed term P of type ev E V ,a context Γ' of destinations with Γ ⊆ Γ' and a subterm R of C with a typing Γ';Δ ▶ R : return V d  {return V ' d'}.
Proof. The proof is by induction on C.	First of all C must have the form λ^u : eval E d.{.. .}. Secondly, since there is no way to construct a term of type return ... directly in the current context and signature, we know that C must consist of at least one computation step (let-term). This first step must be an ap- plication of one of the eval_?’s from the signature, since everything in the context constructing something monadic requires a term of type return ... to be present.
Now we can consider the different possibilities. The cases are very similar so we will only present the zero, successor and the application cases in detail.
Case: C = λ^u : eval z d.{let {r} = eval_z d ^u in R'}
In this case we can take V = z, P = ev_z and R = λ^r.{R'}.
Case: C = λ^u : eval (s E1) d.{let {[d0,p ⊗ f ]} = eval_s E1 d ^u in C'}
We apply the induction hypothesis to Γ0; Δ0 ▶ λ^p.{C'} : eval E1 d0 
{return V ' d'} where Γ0 = Γ, d0 : dest and Δ0 = Δ,f ^: Πv.return v d0 
{return (s v) d} to get V1 : exp, P1 : ev E1 V1 and Γ'; Δ0 ▶ R' :

return V1 d0  {return V ' d'}. Now since d0 /= d' then R' has to be of the form λ^r'.{let {r} = f V1 ^r' in R''}. Then we can take V = s V1, P = ev_s P1 and R = λ^r.{R''}.
Case: C = λ^u : eval (case E1 E2 E3) d.{let {[d0,p ⊗ f ]} =
eval_case E1 E2 E3 d ^u in C'}
This is similar to the successor case above except that there is now two possible
forms for R', each of which yields subcomputations with eval’s in the context; i.e.
R' can be λ^r'.{let {p'} = (π1 f ) ^r' in C' } or λ^r'.{let {p'} = (π2 f ) V '' ^r' in C' }.
2	'	'	3
The induction hypothesis can then be applied again on C2 and C3 yielding
ev E2 V and ev (E3 V '') V respectively. Together with the big-step term from the first application of the induction hypothesis we can now create a term of type ev (case E1 E2 E3) V with either ev_case_z or ev_case_s.
Case: C = λ^u : eval (lam E') d.{let {r} = eval_lam E' d ^u in R'}
This case is similar to the zero case; i.e. we take V = lam E', P = ev_lam E’
and R = λ^r.{R'}.
Case: C = λ^u : eval (app E1 E2) d.{let {[d0, p1 ⊗ f1]} =
eval_app E1 E2 d ^u in C1}
We apply the induction hypothesis to Γ1; Δ1 ▶ λ^p1.{C1} : eval E1 d0 
{return V ' d'}. This gives us P1 : ev E1 V1 and Γ' ; Δ1 ▶ R1 : return V1 d0 
'	'	1	^	'
{return V	d }.	Now R1 has to be on the form λr.{let {[d0, p2 ⊗ f2]} =
f1 E' ^r in C2}. This implies that V1 = lam E' . Since C2 is a subterm of
1	1	^	'
C we can apply the induction hypothesis on Γ2; Δ2 ▶ λp2.{C2} : eval E2 d0 
{return V ' d'}. This gives ▶ P2 : ev E2 V2 and Γ' ; Δ2 ▶ R2 : return V2 d'
'  '	^ 2	0

{return V
d }. Now R2 has to be on the form λr.{let {p3} = f2 V2 ^r in C3}.

Since C3 is a subterm of C2 which is a subterm of C we can apply the induction
hypothesis on Γ3;Δ ▶ λ^p3.{C3} : eval (E' V2) d  {return V ' d'}. This gives
'	'	1	'  '
▶ P3 : ev (E1 V2) V3 and Γ ;Δ ▶ R3 : return V3 d   {return V  d }. Now we
can set V = V3, construct P from P1, P2 and P3 using ev_app and set R = R3.
Case: C = λ^u : eval (fix E') d.{let {p} = eval_fix E' d ^u in C'}
This case follows directly from one application of the induction hypothesis.
 
Now we can apply the lemma to d : dest; · ▶ C : eval E d  {return V ' d}. This gives Γ'; · ▶ R : return V d   {return V ' d}, but since Δ is empty and d = d', R has to be equal to λ^r.{r}. This in turn implies V ' = V which gives us the sought ▶ P : ev E V ' completing the translation from destination-passing style to big-step semantics.
Representation of the proof in CLF
Currently CLF does not have a meta-theory to support the representation of proofs. So even though it is very speculative, it is still interesting to consider the represen- tation of the above proof in CLF, as we will gain insight in some of the unresolved issues regarding the design of a meta-theory for CLF.
One of the main issues is how to adequately state the lemma (or theorems in

general). Some of the problems that are related to linearity arise already in the context of linear LF (LLF) and are discussed in [7].
A natural first approach would be: 6
lemma : ΠE:exp. ΠD1:dest. ΠD2:dest. ΠV2:exp. ΠV1:exp. (eval E D1   {return V2 D2})
→ ev E V1
→ (return V1 D1   {return V2 D2}) → type.
%mode lemma +E +D1 +D2 +V2 -V1 +C -P -R.
The line %mode . . . is the Twelf way of specifying which arguments should be regarded as input (+) and which should be regarded as output (-). The type should thus be read as “Given E, D1, D2, V2 and C where C has type eval E D1 
{return V2 D2}, there exists V1, P and R such that P has type ev E V1 and R has type return V1 D1  {return V2 D2}.
The zero case can be encoded without problems:
lemma_z : lemma z D1 D2 V2 z
(λ^u:eval z D1.{let {r’} = eval_z ^u in let {r} = R^r’ in r}) ev_z R.
But we get in trouble with the successor case:
lemma_s : lemma (s E) D1 D2 V2 (s V)
(λ^u:eval (s E) D1.
{let {[d’,p⊗f]} = eval_s ^u in let {r} = C d’ ^f ^p in r})
(ev_s P) R
← Πd’. Πf. lemma E d’ D2 V2 V (λ^p. C d’ ^f ^p) P
(λ^r’.{let {r’’} = f V ^r’ in let {r} = R ^r’’ in r}).
There are two problems. The first is with f. One could imagine that a hypo- thetical CLF coverage checker doing output coverage 7 would not be able to see that f cannot occur in R. This is because the definition of the type family gives no indication of the relationship between the linear contexts of the given computation trace and the returned continuation, as opposed to the paper formulation in which we are able to state that they should be equal.
The second problem is the newly created destinations. Every time a new des- tination is created it stays in scope for the entire rest of the computation. This is handled in the paper proof above by stating that the continuation is typed in Γ', even though Γ' \ Γ essentially is superfluous. But we cannot have a type family in which the different arguments are typed in different contexts; and realizing when the different destinations are no longer needed is not trivial by local observations. This
problem manifests itself in the same way as the first, namely that a hypothetical coverage checker would not be able rule out the possibility of d’ occurring in R.

6 We will disregard the problem with the continuation being a subcomputation of the input, since that is already studied in the context of Twelf and can be solved.
7 Output coverage checking is essentially checking the validity of inversion.

Another central issue is that of (input) coverage checking. Once we have all of the cases from the proof, a hypothetical coverage checker would need to figure out that all cases are indeed covered. This implies analyzing the possibilities of pattern matching monadic objects. If we disregard reordering of let-terms then coverage checking should not be much harder than for LF. But this is a very conservative solution and probably not what we want (see section 5 below).
As a side note, notice that the specification of normal contexts resembles the world declarations of Twelf.

Handling interleavings of let-bindings
The considered semantics are both sequential. Let us see what happens if we use the features of CLF to make the destination-passing style concurrent. Consider the following alternative, concurrent version of eval_app:
eval_app’ : ΠE1:exp. ΠE2:exp. ΠD:dest.
eval (app E1 E2) D 
{∃d1:dest. ∃d2:dest. eval E1 d1 ⊗ eval E2 d2 ⊗
(ΠE1’:exp → exp. ΠV2:exp. return (lam (λx. E1’ x)) d1 
return V2 d2   {eval (E1’ V2) D}
)
}.
This version differs from the previous by adding both eval E1 d1 and eval E2 d2 to the context at the same time. This means that the subsequent evaluations of E1 and E2 can happen in any order and the individual steps can be arbitrarily interleaved. However, since these two computations are essentially independent, the different traces representing different interleavings must all be equivalent modulo let-floating; but since this fact is not immediate the proof gets more complicated.
Let us see how a proof translating this concurrent version into big-step looks like. First of all, since there can now be multiple eval’s in the context we will have to modify the definition of normal contexts to accomodate this, i.e. allow variables with types eval E D and return V D to occur in a normal context. With this new definition lemma 4.4 can be reused in its exact same formulation. Notice that this singles out a particular eval E d to be the focus of the lemma.
Now in order to start the proof and split by cases like we did above we will need to argue that C does indeed begin with the consumption of the eval E D that the lemma focusses on. This is, however, no longer immediate. The computation trace C can just as well begin with the consumption of any of the other eval’s in the context or by the application of a Π ... return ...  {.. .} to a corresponding return. Therefore we will need a let-floating-lemma to state that any C with the type given is equivalent to a trace in which the particular eval E d is consumed first:
Lemma 5.1 (let-floating for eval’s) Let Γ be a context of destinations, Γ= d1 :

dest,... , dn : dest, and let Δ be a normal linear context. Let E and V ' be closed terms of type exp. Let d and d' be two (not necessarily distinct) destinations in Γ. And let C be a term with a typing Γ; Δ ▶ C : eval E d {return V ' d'}. Then there exists a term C' ≡ C, such that C' = λ^u.{let {.. .} = ... ^u in C''}.
The dots in the form for C' covers all the different cases that the main proof subsequently splits into.
The proof of this let-floating-lemma relies on the fact that there can never be introduced anything in the (linear or unrestricted) contexts, which would allow the linear ressource eval E d to be consumed in any different way.
With this in place we can reuse the cases of the proof for zero, lambda and fix- point without changes. The other cases will however require their own let-floating- lemmas. Consider for instance the successor case; after the application of the in-
duction hypothesis, we want to apply inversion to conclude that R' begins with the application of f , but this requires a specific let-floating-lemma stating that any R' of the corresponding type is equivalent to a term beginning with the application of
f . Similarly for the other cases; each time inversion is used on the R resulting from the induction hypothesis we will need a specific let-floating-lemma.
Here are two of them:
Lemma 5.2 (let-floating for the successor case) Let Γ be a context of desti- nations, Γ = d1 : dest,... , dn : dest, and let Δ be a normal linear context. Let V and V ' be closed terms of type exp. Let d and d' be two (not neces- sarily distinct) destinations in Γ and let d'' be a destination in Γ distinct from the other two. And let R be a term with typing Γ; Δ,f ^: Πv. return v d'' 
{return (s v) d}, r' ^: return V d ▶ R : {return V ' d'}. Then there exists a term
R' ≡ R, such that R' = {let {r} = f V ^r' in R''}.
Lemma 5.3 (let-floating for the concurrent app case) Let Γ be a context of destinations, Γ = d1 : dest,... , dn : dest, and let Δ be a normal linear context.  Let V1, V2 and V ' be closed terms of type exp.  Let d and d' be two (not necessarily distinct) destinations in Γ and let d1 and d2 be two dis-
tinct destinations in Γ distinct from the other two. And let R be a term with typing Γ; Δ,f ^: Πe.Πv. return (lam (λx. e x)) d1   return v d2 
{eval (e v) d}, r1 ^: return V1 d1, r2 ^: return V2 d2 ▶ R : {return V ' d'}. Then V1 is equal to lam E for some E and there exists a term R' ≡ R, such that R' = {let {p} = f E V2 ^r1 ^r2 in R''}.
If let-floating has to be reasoned about explicitly in CLF then we could probably just as well have represented the concurrent features explicitly as it would be done in Twelf. To get actual benefit from CLF it therefore seems likely that we would have to come up with a let-floating aware coverage-checker, such that the let-floating would be handled behind the scenes, much like substitution is handled behind the scenes in Twelf. More specifically, in a trace where A and B can occur in either order, we want to be able to implicitly assume that for instance A occurred first.

CLF signatures
All the proofs so far are working with a fixed signature and of course cannot be expected to work with arbitrary extensions to the signature. Extending MiniML in any way will naturally require extensions to the proofs as well. This is all good and reasonable. If we however extend the signature with something completely different
i.e. new types and type families, we would expect the proofs to work without any changes. So far these are just the natural expectations coming from the way Twelf works.
In Twelf we know this is how things work, since execution is goal-oriented and adding a new type family does not add any new constructors to the old type fam- ilies. In CLF execution works differently. When inside the monad, the execution semantics will simply nondeterministically perform any action possible given the current signature and context. And since the proofs at some point have to conclude that there can be no more computation, any signature allowing monadic objects — and thereby computation steps — to be constructed directly will disrupt the proofs. Therefore I propose a simple restriction on CLF signatures which will hopefully simplify meta-theory representations a bit. Consider the number of terms N of type ·; · ▶ N : {1} in some signature. Of course we can have N = {1}. But if there are any other terms N : {1} then any computation trace constructing any monadic type can have interjections of completely irrelevant, superfluous steps. The proposed restriction is therefore that there can be only one term N of type {1} in
the empty context. Adding stuff like
junk : type. junk_intro : junk.
junk_elim : junk   {1}.
would therefore be considered an illegal signature.
A conservative approximation of this restriction which is easy to compute, is to simply start the proof search semantics looking for a term of type {1}. The first step after entering the monad is a nondeterministic choice depending on the signature. Now if the only option for this nondeterministic choice is to terminate the forward-directed mode and construct 1 directly then we are certain that the signature is legal, otherwise we reject the signature.

Conclusion and future work
We have proven a traditional big-step semantics equivalent to a destination-passing semantics by induction on terms with an equivalence relation capable of modelling concurrency. Examination of this proof has identified several problems regarding meta-theory representations in CLF.
First, there is the problem of scoping; during the course of a computation in the monad, every intuitionistically introduced term stays in the context. This means that subcomputations cannot easily be split, since the different parts are typed in increasingly larger contexts. One solution could perhaps be to represent proofs in

a forward-directed manner in the monad, since this would allow ∃-introductions of variables instead of Π-introductions. In the case of the destinations they did not actually occur; if this is the common case, another solution might be to infer this by an automated analysis.
Second, there is the problem of linear contexts; this could though perhaps be solved at the CLF meta-level with some sort of extended world-declaration stating which terms should be linear in which arguments. Alternatively, the work on hybrid metalogical frameworks [7] might be applicable.
Third, there is the problem regarding coverage in the context of let-floating. There is a lot to be gained if a coverage checker could be devised in such a way that the overhead of let-floating-lemmas described in section 5 could be moved to the correctness proof of the coverage checker.
Furthermore it has been argued that restricting the CLF signatures in some way is necessary for a CLF implementation. Specifically it seems like a good idea to require that the type {1} is only inhabited by a single term.

Acknowledgement
I thank Andrzej Filinski and my advisor Carsten Schu¨rmann for helpful discussions.

References
Iliano Cervesato, Frank Pfenning, David Walker, and Kevin Watkins. “A concurrent logical framework I: Judgments and properties”. Technical Report CMU-CS-02-101, Department of Computer Science, Carnegie Mellon University, 2002.
Iliano Cervesato, Frank Pfenning, David Walker, and Kevin Watkins. “A concurrent logical framework II: Examples and applications”. Technical Report CMU-CS-02-102, Department of Computer Science, Carnegie Mellon University, 2002.
Pablo Lo´pez, Frank Pfenning, Jeff Polakow, and Kevin Watkins. 2005. “Monadic concurrent linear logic programming”. In Proceedings of the 7th ACM SIGPLAN international Conference on Principles and Practice of Declarative Programming (Lisbon, Portugal, July 11–13, 2005). PPDP ’05. ACM Press, New York, NY, 35–46.
Andrew McCreight and Carsten Schu¨rmann. “A Meta-Linear Logical Framework”. Proceedings of Logical Frameworks and Meta Languages, July 2004.
Frank Pfenning and Carsten Schu¨rmann. “System description: Twelf — a meta-logical framework for deductive systems”. In Proceedings of the 16th International Conference on Automated Deduction (CADE-16), Trento, Italy, June 1999. H. Ganzinger, Ed. Lecture Notes In Computer Science, vol. 1632. Springer-Verlag, London, 202-206.
Frank Pfenning. “Substructural operational semantics and linear destination-passing style”. In W.-
N. Chin, editor, Proceedings of the 2nd Asian Symposium on Programming Languages and Systems (APLAS’04), page 196, Taipei, Taiwan, Nov. 2004. Springer-Verlag LNCS 3302.
Jason Reed. “A Hybrid Metalogical Framework”. Thesis Proposal Working Draft. Jan. 2007.
http://www.cs.cmu.edu/∼jcreed/papers/thesprop.pdf
