Electronic Notes in Theoretical Computer Science 174 (2007) 63–84	
www.elsevier.com/locate/entcs

What is Itanium Memory Consistency from the Programmer’s Point of View?
Lisa Higham1
Department of Computer Science The University of Calgary Calgary, Canada

LillAnne Jackson2
Department of Computer Science The University of Victoria Victoria, Canada

Jalal Kawash3
Department of Computer Science American Univ. of Sharjah Sharjah, UAE


Abstract
A programmer-centric model describes the memory consistency rules of amultiprocessor as a collection, one for each processor, of ‘views’ of instructions and some agreements between these views. It also requires the natural notion of validity: the value read from a shared memory location is the one that was most recently stored, according to a given view. This allows reasoning about programs at a non-operational level in the natural way, not obscured by the implementation details of the underlying architecture. In this paper, we formulate a programmer-centric description of the memory consistency model provided by the Itanium architecture. However, our definition is not tight. We provide two very similar definitions and show that the specification of the Itanium memory model lies between the two. These two definitions are motivated by slightly different implementations of load-acquire instructions. A further entertainment of a handful of other load-acquire rules leads us to question whether the specification of the Itanium memory order [9] is indeed faithful to the Itanium architecture intentions.

Keywords: Programmer-centric memory consistency, itanium multiprocessor.



1 Email: higham@cpsc.ucalgary.ca
2 Email: lillanne@cs.uvic.ca
3 Email: jkawash@aus.edu

1571-0661 © 2007 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2007.04.007

Introduction

Modern multiprocessor systems include a variety of hardware components such as write-buffers, caches, distributed memory and multiple buses all intricately inter- connected. As a consequence, the way that information flows in these various ar- chitectures differs widely. To program such systems correctly while exploiting the potential efficiencies available because of these components, it is crucial to have a thorough understanding of this information flow. The rules that describe this flow of data for a particular architecture is called the memory consistency model of that architecture. These rules are presented in the system architecture manuals (and other sources) using many different descriptive (in)formalisms. This motivates us to respecify memory consistency models using a common framework. Such a frame- work helps us compare different systems, port code between systems, and transfer our expertise in one system to facility in another. One framework often used to specify a memory consistency model for an architecture A is to describe each in- struction by a program of lower level operations acting on the components of A. An execution is a sequence of all the operations of all the instructions executed by each processor. Then,
rules are added that restrict the order in which these lower level operations can occur in any execution, and
a notion of validity is defined, which constrains what values can legitimately be
associated with each operation.
An execution must satisfy all the ordering rules and the validity condition in order to be a possible execution on A.
For example, this style has been used to describe the memory semantics of Sparc machines [12]. To illustrate, in this style, a ldp(x) (load x by p instruction) could be specified to be the program of operations that first checks the local write buffer of p for a value for x; if it is there it returns the most recently stored such value, otherwise it returns the value of x from main memory. Rules would include one that required that this program of operations must be executed in order, but that the read operation of main memory could be delayed while other operations intervened. The validity condition would require that ldp(x) could return without consulting main memory, if and only if there was a value for x in p’s write-buffer just before this load was invoked. The Intel Itanium architecture is similarly specified [9,10] but in this case the specification does not prescribe any particular implementing architecture.
We contend, however, that for programming purposes, a memory consistency model should be specified as a set of (ordering) rules on the instructions used by the programmer, rather than on a lower level collection of operations. Furthermore, the validity condition should be the natural notion of validity of sequences of these instructions acting on the objects of the system. For example, in a valid sequence of loads and stores, the value returned by each load instruction should be the value written by the most recent preceding instruction in the sequence that stored a value to the same memory location. Such a description is useful to a programmer

of the system since she can reason about her code directly, and therefore we call it programmer-centric. Descriptions in terms of lower level operations specify an implementation (in hardware or on a virtual platform) and are useful for an archi- tect who is building the system, but should not be confused with its specification. In this case these lower level implementations should be proved equivalent to the specification. A further advantage of our approach is that constructions can be composed. A high level specification of an object oriented system can be imple- mented by a succession of constructions, such that an implementation at one level is the specification for a still lower level, and each level of implementation is proved to correctly implement its specification. This, of course, is the familiar notion of abstraction; we simply extend it to weak models of memory consistency.
In previous work [7,6] we have established a framework for specifying programmer-centric memory consistency models and for proving such equivalences between specifications and implementations. We have applied this framework and the proof techniques to an extensive example involving write buffer architecture [6]. This paper applies these ideas to the Intel Itanium architecture. That is, we aim for a programmer-centric specification of the memory consistency of the Itanium multiprocessor. As will be seen, we failed to realize this goal. Instead, we define two very similar programmer-centric memory consistency models, Itaniumw and Itaniums, and show that “official” Itanium memory consistency [9], henceforth re- ferred to as Itanium (with no subscript), lies strictly between these two (Section 4). Itaniumw and Itaniums differ only slightly in the ordering constraints involving Itanium load-acquire instructions, and each is motivated by a plausible hardware implementation. We show that several other plausible definitions also fail to exactly capture the Itanium memory consistency specification (Section 5). Furthermore, we know of no lower level description that has a plausible hardware implementation and is equivalent to Itanium. For example, we have been able to use our techniques to show that the machine proposed by Chatterjee and Gopalakrishnan [3] does not exactly implement Itanium (Section 6). We are even led to speculate whether the specification of the Itanium memory consistency [9] is really what the Itanium architects intended!
Section 2 highlights the architectural features of Itanium. Before we present our main results, we briefly describe the model in Subsection 3.1. Subsection 3.2 defines Itaniumw and Itaniums. In Section 4 we argue that the Itanium specification [9] is weaker than Itaniums and stronger than Itaniumw. The formal proofs are elsewhere [8]. In Section 5, we consider several other potential programmer-centric definitions, and show each of them also fails to exactly capture Itanium consistency. The rest of this paper requires familiarity with the Itanium memory consistency model [9]. Those definitions that are essential for this work are reproduced in Subsection 3.3.
Several other frameworks for describing memory consistency have been proposed but are not central to this paper. The framework of Adir, Attiya and Shurek [1] is very similar to ours and precedes ours. Arvind and Maessem [2] provide a framework for serializable memory models. We are unaware, however, of how to use these

frameworks to prove equivalence between systems. Yang et. al. [13,14,4] present a non-operational approach to specifying and analyzing shared memory consistency models and use it to provide a translation of the rules of Itanium specification. The TLA work of Joshi et. al. [11] is a precise specification of Itanium and is the basis of the official specification [9].

Itanium Architecture Highlights
The Itanium specifications [9] are independent of specific machine implementations. While we do not know of a concrete machine implementation that exactly captures the Itanium specifications, this section gives an overview of the architectural features of such a machine.
Itanium provides a distributed-shared memory (DSM) architecture where each processor maintains a replicated copy of the shared address space. For this paper the shared memory consists of only shared variables. That is, instructions either load or store a shared variable. Loads are satisfied by returning the value in the local replica, without any communication with the other processors. However, stores are performed by updating the local replica and broadcasting the update to every other processor to apply it in their replicas. Stores by a processor are visible to that processor before they can be visible to other processors. The channels between processors are not necessarily FIFO when two instructions are applied to different variables. The rules that govern processor execution and inter-processor interaction are complicated and give rise to complex behaviors.
Itanium also supports write-buffers with read by-passing. A store is buffered before it is committed to the replicas in order to hide store latencies. A load by a processor checks if the local write-buffer contains a store that can satisfy the load (both the load and the store are on the same variable). If this is the case, the value of the most recent such store is returned, without the need to check the local replica. In the case of a buffer miss, the load bypasses the pending stores in the buffer and loads the value from the local replica. Write-buffering further complicates the behavior of Itanium. Bypassing loads can complete before earlier buffered stores and give rise to an out-of-order execution. From the programmer’s point of view, a foreign load returns a value from the local replica, rather than from the local buffer. This is guaranteed, for instance, when a processor loads a variable that it never stores, such as a a single-writer variable owned by a different processor. The write buffers in Itanium are guaranteed to be FIFO only per variable. Hence, two store instructions to different variables can be applied to a replica in the opposite order in which they occur in a processor’s program.
In order to restrict out-of-order execution, Itanium supports the extensions of “acquire” and “release” to load and store instructions, respectively. A load-acquire instruction is required to be always performed before any subsequent instruction in the program. A store-release is required to be always performed after every preceding instruction in the program. Typically a program with a critical section performs an acquire before entering the critical section, ensuring that the critical

section is delayed until the proper lock is obtained. Also, it performs a release after exiting the critical section ensuring that the lock is not released earlier than the actual exit from the critical section. Itanium also provides fence instructions and semaphore read-modify-write instructions which combine both acquire and release requirements.
Acquires and releases restrict the write buffer’s behavior. For instance, when a release is buffered it forces all previously buffered stores to be removed from the buffer and applied to the local replicas before the release itself. Depending on the implementation, a load-acquire can force the buffer to be flushed, but this is not necessary in general. They also restrict the inter-processor interaction behavior. Incoming store-releases restrict how processors apply the other incoming stores. Typically, just as a release forces a preceeding store to be removed from the buffer earlier, these stores have to be applied remotely earlier than the release.
From the programmer’s point of view, an Itanium execution is a collection of “views”, one for each processor. Due to DSM nature, a processor’s view consists of its own loads and all processors’ stores. The view allows out-of-order execution and there has to be a minimum level of agreement between these views. The Itanium specifications [9] are summarized at the end next of section, in which we formulate these Itanium views.

Multiprocesses, Computations and Memory Consis- tency
Instructions, multiprocessors and computations
As each process in a multiprocess system executes, it issues a sequence of instruction invocations on shared memory objects. 4 For this paper the shared memory consists of only shared variables, and each instruction invocation is Itanium-based. That is, each instruction invocation is of the form stp(x, v) or st.relp(x, v) meaning that process p writes a value v to the shared variable x, or ldp(x) or ld.acqp(x) meaning that process p reads a value from shared variable x or of fencep meaning that process p invoked a memory fence instruction. Instruction invocations st and st.rel are referred to collectively as store instructions and have store semantics; ld and ld.acq are called load instruction invocations and have load semantics. It suffices (for this paper) to model each individual process p as a sequence of these instruction invocations and call such a sequence an individual (Itanium-based) program. 5 An (Itanium-based) multiprogram is a finite set of these individual programs.
An instruction is an instruction invocation completed with a response. In our setting the response of a store instruction invocation or a fence instruction invoca- tion is an acknowledgment and is ignored. The response of a load invocation is the value returned by the invocation. A (multiprocess) computation of an Itanium-based

4 Parts of this section were first used in previous work (Section 2.2 of [5]); they are re-used in this work in a modified form.
5 We have made common some simplifying assumptions such as memory locations do not overlap, memory is cacheable (i.e., WB) and semaphores are omitted.

multiprogram, P is created from P by changing each load instruction invocation, ldp(x) (respectively, ld.acqp(x)) to ν ←ldp(x) (respectively, ν ←ld.acqp(x)) where ν is either the initial value of x or some value stored to x by some store to x in the multiprogram.
Notice that the definition of a computation permits the value returned by each ld(x) or ld.acq(x) instruction invocation to be arbitrarily chosen from the set of values stored to x by the multiprogram. In an Itanium machine (or any other multiprocessor), the values that might actually be returned are substantially further constrained by its architecture, which determines the way in which the processes communicate and that shared memory is implemented. A memory consistency model captures these constraints by specifying a set of additional requirements that computations must satisfy. Typically, these require the existence of a set of sequences of instructions that satisfy certain properties. A collection of such sequences that meet all the requirements is called a set of verifying sequences. We use C(P, MC) to denote the set of all computations of multiprogram P that satisfy the memory consistency model MC. Memory consistency model MC is stronger than MC’ if, for every Itanium-based Multiprogram P , C(P, MC) ⊆ C(P, MC'). MC is strictly stronger than MC’ if for every Itanium-based Multiprogram P , C(P, MC) Ç C(P, MC') The terms weaker and strictly weaker are defined similarly.
The description of a memory consistency model is simplified by assuming that each store instruction invocation has a distinct value. Although it is technically straightforward to remove this assumption, without it, the description of the mem- ory model is messy and its properties are consequently obscured.
For an Itanium-based computation C, I(C) denotes all the instructions in C. I(C)|p is the subset of I(C) in processor p’s program sequence; I(C)|x is the subset of I(C) applied to variable x; I(C)|r is the subset containing only the load in- structions; I(C)|w is the subset containing only the store instructions; Let I(C)|acq denote the subset containing all ld.acq instructions plus the memory fence instruc- tions; let I(C)|rel denote the subset containing all st.rel instructions plus the mem-
prog
ory fence instructions. The relation (I(C), −→ ), called program order, is the set of
all pairs (i, j) of instructions that are in the same individual computation of C and
y
such that i precedes j in that sequence. For any partial order relation (I(C), −→ ),
y	y
the notation i −→ j is used to mean of (i, j) ∈ (I(C), −→ ).
A load instruction is domestic if the value it returns was stored into shared memory location x by a store instruction by the same processor; memory fence instructions and load instructions that are not domestic are foreign. If an instruc- tion, i, with load semantics returns the value stored by an instruction, j, with store semantics then i and j are causally related.

Weak and strong Itanium memory consistency
This section formulates two programmer-centric definitions of Itanium consistency. They differ only in the way a ld.acq is implemented.
Define the following partial orders:

wordp	wordp
Weak Orderable Order: (I(C)|p ∪ I(C)|w, −→ ) for each p ∈ P : i −→ j if
prog
i, j ∈ I(C)|p ∪ I(C)|w and i −→ j and one of the following:
Weak Acquire: i ∈ I(C)|acq and is foreign, or
Release: j ∈ I(C)|rel, or
Same Memory: i, j ∈ I(C)|x and [(i ∈ I(C)|w or j ∈ I(C)|w) or (i ∈
I(C)|acq)]
sordp	sordp
Strong Orderable Order: (I(C)|p ∪ I(C)|w, −→ ) for each p ∈ P : i −→ j if
prog
i, j ∈ I(C)|p ∪ I(C)|w and i −→ j and one of the following:
Strong Acquire: i ∈ I(C)|acq, or
Release: j ∈ I(C)|rel, or
Same Memory (Simpler): i, j ∈ I(C)|x and [i ∈ I(C)|w or j ∈ I(C)|w ]
The Strong Orderable Order requires a “text-book” or conservative implementa- tion of ld.acq instructions. That is, it requires the ld.acq to precede any instruction that follows it in the program. In the presence of buffers, certain architectural de- cisions can sacrifice this “text-book” behavior. For instance Weak Orderable Order captures the situation when a ld.acq can be satisfied from the buffer (a domestic ld.acq). A following (in program order) ld can by-pass the buffer. Or, a following st to a different variable can be committed to the local replica earlier than the buffered st that is used to satisfy the ld.acq. In this case, the order between ld.acq and the subsequent ld or st can no longer be guaranteed. There is one occurrence of each st in a processor’s view, and these views are constructed based on the order in which stores occur in the local replicas. To maintain the intuitive notion of validity, the ld.acq must be delayed in the view until its causally-related st occurs in the local replica. Hence, a domestic ld.acq may occur in a view after a ld or a st that follows it in program order. Weak Orderable Order allows this behavior, but prohibits it when the ld.acq is foreign (necessarily satisfied from the local replica rather than the buffer). The Same Memory condition prohibits this behavior when ld.acq and the ld are applied to the same variable: if the ld.acq is satisfied from the buffer, then either the ld is also satisfied from the buffer or if not the st under consideration must have been applied to the local replica.
One mechanism to prohibit a domestic ld.acq to occur in a processor’s view later than it should be is to flush the buffer before the ld.acq is completed, ensuring that the ld.acq is always satisfied from the local replica. Such an architecture could achieve views satisfying Strong Orderable Order.
The Release condition is simply what a programmer expects: any instruction preceding a st.rel must maintain this order in the processors’ views. The following defines these views.

Definition 3.1 A computation C satisfies Weak Itanium consistency, denoted Itaniumw, if for each p ∈ P there is a sequence Sp of the instructions I(C)|p∪I(C)|w that is valid for p, such that:
wordp	Sp
If i, j ∈ I(C)|p ∪ I(C)|w and i −→ j then i −→ j, (Orderable requirement) and

Sp	Sq
If i, j ∈ I(C)|x|w and i −→ j then i −→ j, ∀q ∈ P , (Same Memory agreement)
and
Sp	Sq
If i, j ∈ I(C)|rel and i −→ j then i −→ j, ∀q ∈ P , (Release agreement) and
Sp	Sq
If i ∈ I(C)|rel and j ∈ I(C)|st|p and i −→ j then i −→ j, ∀q ∈ P , (Release to
Store agreement) and
There does not exist a cycle of i1, i2 ... ik ∈ I(C)|w where ij ∈ I(C)|pj, ∀j ∈
S1	S2	S3
{1, 2,... k} and k ≤ n such that: ik −→ i1, and i1 −→ i2, and i2 −→ i3 ... and
i	Sk
k−1 −→ ik (Cycle Free agreement)
Definition 3.2 A computation satisfies Strong Itanium consistency, denoted Itaniums, if it satisfies all the conditions of Itaniumw, but with Weak Orderable order replaced by Strong Orderable order(in item 1. of Definition 3.1 above).
Hence, a view of a processor consists of its own instructions in addition to the store instructions of all other processors. Each view maintains the required Orderable Order (item 1). The remaining items are “agreement” requirements, establishing required relationships between the different views. Since channels be- tween processors are FIFO for each variable, the communicated store instructions to the same variable must appear in every view in the same order (item 2). A st.rel instruction occurs in all replicas atomically. Hence item 3 requires the st.rel instructions to be seen in the same order by all processors and item 4 enforces that for any st seen by its processor after a st.rel, that st must be seen in the same way by all processors. Item 5 is a technical condition arising from timing considerations. Consider a store sp by p and a store sq by q. Since a store is visible to the storing processor before it is visible to others, it is not possible for p see sq before sp, and yet for q see sp before sq. Item 5 generalizes this to any number of processors.
Itanium memory consistency according to the Itanium manual
The proofs that Itaniumw and Itaniums bound the definition of Itanium are else- where [8] and they make extensive reference to the Intel manual [9]. We still refer- ence the specifications of the Intel manual in this paper, particularly when we argue if a given computation satisfies Itanium or otherwise. Recall that Itanium (without a subscript) refers to the system specified in this manual [9]. For completeness, the definitions that we require are paraphrased from this manual next. When the same things are named differently in the manual [9] and in our framework (Section 3), we maintain our terminology and notation. For example, what we call a computation is exactly what the manual calls an execution, and we denote program order by
prog
−→ whereas the manual uses  . We also define a few additional terms to simplify
notation. The symbol st[.rel] represents a store instruction (i.e. either st or st.rel), ld[.acq] represents a load instruction (i.e. either ld or ld.acq), and i represents any Itanium-based instruction.
Each Itanium-based instruction is decomposed into operations that either read values from or write values to memory locations. An instruction’s operations corre-

spond to different aspects of the visibility of the instruction for different processors. Specifically, ld[.acq] is “decomposed” into a single read operation R(ld[.acq]). st[.rel] by processor p is decomposed into n + 1 write operations for an n-processor multi- processor: a local write operation visible only to p denoted LV(st[.rel]) and a remote write operation for each processor q in the system denoted RVq(st[.rel]). fence is “de- composed” into just one operation, F(fence). The operations of an instruction and the instruction itself correspond. For example, each of the operations LV(stp(x, v)), RVp(stp(x, v)) and RVq(stp(x, v)) for every processor q /= p corresponds to the store instruction stp(x, v). The operation O is a read operation (respectively, write oper- ation) if O corresponds to load (respectively, store) instruction.
We assume that memory locations with distinct names do not overlap. Let WR be a (write) operation corresponding to instruction st[.rel] and RD be a (read) opera- tion corresponding to instruction ld[.acq]. The value stored by st[.rel] (respectively, written by WR) is denoted WrVal(st[.rel]) (respectively, WrVal(WR)). Similarly, the value loaded by ld[.acq] (respectively, read by RD) is denoted RdVal(ld[.acq]) (re- spectively, RdVal(RD)). Every location b in memory has an initial value, denoted by InitVal(b), that will be returned to read operations when they occur before there are any write operations to that location.
Any computation of the basic Itanium processor family memory ordering model must have an associated visibility order which linearly orders all the operations that correspond to all the instructions of the computation and satisfies the Itanium rules below. (If there is no visibility order for a computation that satisfies all of these rules, the computation is not permitted by the architecture.)
If an instruction i is by a processor p, we write p = Proc(i). For any two operations O and U, O −V→ U means that O precedes U in the visibility order V. If there is a store instruction stp(x, ·) and a load instruction ldp(x) such that LV(stp(x, ·))

V
−→ R(ldp(x))
V
−→ RVp(stp(x, ·)) then the operation R(ldp(x)) is a local read in V

and ldp(x) is a local load in V (or simply a local load or local read when V is clear).

Itanium rules
Write Operation Order
(WO): No store can become visible remotely before it becomes visible locally.
For every store st[.rel] where p=proc(st[.rel]),
VLV(st[.rel])	RVp(st[.rel]) and
VRVp(st[.rel])	RVq(st[.rel]) for q /=Proc(st[.rel]).
Program Order
(ACQ): No instruction can become visible before a preceding ld.acq.

prog
If ld.acq −→
i, A is a read operation corresponding to ld.acq, and O is an operation

corresponding to i, then A −V→ O.
(REL): No st.rel can become visible before a preceding instruction.

prog
If i −→
st.rel, and i is not a store instruction, and O is an operation correspond-

ing to i, then
O −V→ LV(st.rel).

If
prog
st[.rel] −→ st.rel	where	st[.rel]	is	a	store	instruction,	then
V

LV(st[.rel]) −→ LV(st.rel) and
RVp(st[.rel]) −V→ RVp(st.rel) for each processor p.
(FEN): 6 Instructions become visible in order with respect to fence instructions.

prog
If fence −→
i and O is an operation corresponding to i, then F(fence) −V→ O.

If i −pr→og fence and O is an operation corresponding to i, then O −V→ F(fence).
Memory-Data Dependence
(MD:RAW): No load may become visible before an earlier store to a common location.

If st[.rel] and ld[.acq] access the same memory location and st[.rel] then
prog
−→ ld[.acq],

V
LV(st[.rel]) −→ R(ld[.acq]).
(MD:WAR): No store may become visible locally before an earlier load to a com- mon location.
prog
If ld[.acq] and st[.rel] access the same memory location and ld[.acq] −→ st[.rel],
then

R(ld[.acq])
V
−→ LV(st[.rel]).

(MD:WAW): Stores by a processor to a common location become visible to that processor in program order.
prog
If st[.rel]1 and st[.rel]2 access the same memory location and st[.rel]1 −→ st[.rel]2,
then

LV(st[.rel]1)
V
−→ LV(st[.rel]2).

Coherence
(COH): Stores to the same location become remotely visible in the same order for every processor.
If	st[.rel]1	and	st[.rel]2	are	stores	to	the	same	location	and Proc(st[.rel]1)=Proc(st[.rel]2) and
V
LV(st[.rel]1) −→ LV(st[.rel]2) then
V
RVp(st[.rel]1) −→ RVp(st[.rel]2).
If	st[.rel]1	and	st[.rel]2	are	stores	to	the	same	location

V
and	RVp(st[.rel]1) −→ RVp
(st[.rel]2)
for	any	processor	p,	then

RVq(st[.rel] ) −V→ RV (st[.rel] ) for all processors q.
Store-release
(WBR): Store-release instructions become remotely visible atomically.

If RVp(st.rel)
−V→ O −V→ RVq(st.rel) then

O=RVr(st.rel) for some processor r.

Read Value
(RV1): Let ld[.acq] be a local load of location x and st[.rel] be a store to x, such
V
that Proc(st[.rel]) = Proc(ld[.acq]). Suppose that LV(st[.rel]) −→ R(ld[.acq]) and
there is no other store,st[.rel]’ to x with Proc(st[.rel]’)= Proc(ld[.acq]) where

V
LV(st[.rel]) −→ LV(st[.rel]’)
V
−→ R(ld[.acq]). Then

RdVal(ld[.acq]) = WrVal(st[.rel]).
(RV2): Let ld[.acq] be a non-local load of location x and p = Proc(ld[.acq]). Sup- pose there is a store st[.rel] to x such that RVp(st[.rel]) −V→ R(ld[.acq]), and there is no other store st[.rel]’ to x with

V
RVp(st[.rel]) −→ RVp(st[.rel]’)
Val(st[.rel]).
V
−→ R(ld[.acq]).	Then RdVal(ld[.acq]) = Wr-

(RV3): Let  ld[.acq]  be  a  non-local  load  instruction  of  location  x  and
p	= Proc(ld[.acq]).	Suppose there is no store st[.rel] to x  such that
V
RVp(st[.rel]) −→ R(ld[.acq]). Then RdVal(ld[.acq]) = InitVal(x).

Itanium is strictly between Itaniumw and Itaniums
The proofs of our two major theorems, Theorems 4.1 and 4.2 are elsewhere [8].
Theorem 4.1 Itanium memory consistency is strictly stronger than Itaniumw
memory consistency.
Theorem 4.2 Itaniums memory consistency is strictly stronger than Itanium
memory consistency.
Here we focus on a compuation that captures the essential difference between
Itaniumw and Itanium.
Comp 1	p :3 ←ld(x) st(x, 2) 2 ←ld.acq(x) st(y, 4)
q :4 ←ld.acq(y) st(x, 3)
In Computation 1, the 2 ←ld.acqp(x) instruction is domestic while the 4 ←ld.acqq(y) instruction is foreign. 4 ←ld.acqq(y) must be satisfied from the local replica and not the write-buffer, but it is possible for 2 ←ld.acqp(x) to be satis- fied from p’s write-buffer while stp(x, 2) is pending, waiting to be applied to p’s local replica. Since the write-buffers are only FIFO per variable, it is possible for stp(y, 4) to be applied to p’s replica before stp(x, 2). Hence, in p’s view it is possible for 2 ←ld.acqp(x) to occur after stp(y, 4), a violation of the “text-book” implemen- tation of ld.acq. Itaniumw allows this behavior, which is captured by the following verifying sequences:
Sp : stp(y, 4) stq(x, 3) 3 ←ldp(x) stp(x, 2) 2 ←ld.acqp(x)
Sq : stp(y, 4) 4 ←ld.acqq(y) stq(x, 3) stp(x, 2)
Computation 1 does not satisfy Itanium because to the following cycle of oper- ations:

R(3 ←ld (x)) MD:W AR
(MD:RAW )

p	−→	LV(stp(x, 2))
(ACQ)
−→
(WO)

(WO)

R(2 ←ld.acqp(x))	−→	LV(stp(y, 4))
(RV 2)	(ACQ)
−→	RVp(stp(y, 4))
−→	RVq(stp(y, 4))

−→ R(4 ←ld.acqq(y)) −→
(WO)
(WO)
(RV 2)

LV(stq(x, 3)) −→ RVq(stq(x, 3))
−→ RVp(stq(x, 3))
−→ R(3 ←ldp(x)).

Any verifying visibility sequence is a total order, so no such sequence could extend
the orders of this cycle.
Also, Computation 1 does not satisfy Itaniums, which requires 2 ←ld.acqp(x) to precede stp(y, 4) in p’s view. However, this is not possible because Sp must extend:

st (x, 3)	valid
same memory
same memory

q	−→	3 ←ldp(x)
−→	stp(x, 2)
−→	2 ←ld.acqp(x)

strong acquire
−→	stp(y, 4).
Sq
The Cycle Free agreement requirement needs stq(x, 3) −→ stp(y, 4) because oth-

erwise stq(x, 3)
Sp
−→ stp(y, 4)
Sq
−→ stq(x, 3) which is not allowed. Thus, Sq contains

cycle free
the following cycle: st (x, 3)
valid
strong acquire

stq(x, 3) .
q	−→	stp(y, 4)
−→ 4 ←ld.acqq(y)	−→

While the “liberal” behavior of the ld.acq instructions in Itaniumw allows com- putations that are otherwise prohibited under Itanium, the conservative “text- book” behavior of the ld.acq instructions in Itaniums is too prohibitive.
Computation 2 satisfies Itanium consistency but not Itaniums consistency.


Comp 2
q : st(x, 3) 3 ←ld.acq(x) st(y, 4)
⎩	2 ←ld.acq(z) 3 ←ld(x)

Processor q can place stq(x, 3) in its write-buffer, satisfy 3 ←ld.acq(x) from the buffer, and then buffer stq(y, 4). Since the write-buffers are only FIFO per variable it is possible for stq(y, 4) to be applied to both replicas while stq(x, 3) is still pending in the buffer. Processor p can perform 4 ←ld.acqp(y) and then apply stp(x, 5) to q’a replica while stq(x, 3) is still in q’s buffer.
Formally, a sequence V that satisfies Itanium is: LV(stq(x, 3)), Rq(3 ←ld.acqq(x)), LV(stq(y, 4)),
RVq(stq(y, 4)), RVp(stq(y, 4)), Rp(4 ←ld.acqp(y)),
LV(stp(x, 5)), LV(st.relp(z, 2)), RVp(stp(x, 5)), RVq(stp(x, 5)), RVp(st.relp(z, 2)), RVq(st.relp(z, 2)), Rq(2 ←ld.acqq(z)),
Rq(3 ←ldq(x)), RVq(stq(x, 3)), RVp(stq(x, 3)).
Itaniums does not allow Computation 2 since Itaniums requires all ld.acq in- structions to be satisfied from the local replica rather than the buffer. Hence, stq(x, 3) is guaranteed to be applied to q’s replica before even stq(y, 4) is buffered. p must see stq(y, 4) before it buffers stp(x, 5) because it sees the value in y through a ld.acq instruction. When p sees stq(y, 4), the value of x in q’s replica must be
3. p’s st.relp(z, 2) forces stp(x, 5) to be applied everywhere before the st.rel itself. When q sees st.relp(z, 2), it must also have seen stp(x, 5). So the value of x in q’s replica must be 5, overwriting the earlier value of 3. 3 ←ldq(x) must take place

after 2 ←ld.acqq(z), since Itaniums requires the ld.acq to precede any following instruction. However, we have already argued that the value of x according to q cannot be 3.
Formally, the Itaniums sequence, Sp, must extend:

stq(y, 4)
valid
−→ 4 ←ld.acqp(y)
strong acquire
−→	stp(x, 5)
Sq
release
−→	st.relp(z, 2).	The Cy-

cle Free agreement requirement needs stq(y, 4) −→ stp(x, 5) because otherwise

stq(y, 4)
Sp
−→ stp(x, 5)
Sq
−→ stq(y, 4) which is not allowed.	Thus, Sq must ex-

tend: stq(x, 3)
same memory
−→	3 ←ld.acqq(x)
strong acquire
−→	stq(y, 4)
cycle free
−→	stp(x, 5)

release
−→  st.relp(z, 2)
3 ←ldq(x) invalid.
valid
−→ 2 ←ld.acqq(z)
strong acquire
−→	3 ←ldq(x). This makes the final

Comparing Alternative Acquire Orders
Itaniumw and Itaniums bound Itanium and the only difference between them is slight changes in the Acquire Order. So a natural question is: “Is there a definition of an Acquire Order that yields a programmer-centric memory consistency spec- ification that is equivalent to Itanium?” This section examines several plausible Acquire Order definitions and compares their relative strengths. One interesting result is another memory consistency model that is weaker that Itaniums yet still strictly stronger than Itanium.


Acquire order deﬁnitions


Acq


prog

Define the following Acquire orders: i1 −→ i2 if i1, i2 ∈ I(C)|p ∪ I(C)|w and i1 −→ i2
and:
Acquire A or Strong Acquire i1 ∈ I(C)|acq
Acquire B or Weak Acquire i1 ∈ I(C)|acq and is foreign
Acquire C i1 ∈ I(C)|acq and i2 is not a domestic load.
prog	prog
Acquire D i1 ∈ I(C)|w and ∃i3 such that i1 −→ i3 −→ i2 and i3 ∈ I(C)|acq and
i1 is causally related to i3.
Acquire A and B were defined and motivated in Subsection 3.2. Acquire C models a possible implementation where two load instructions, i1 = ld.acq program ordered before i2 = ld or ld.acq, i1 checks the write-buffer and misses it, bypasses any pending stores, and returns its value from the local replica. Meanwhile i2 hits the buffer and returns. The effect is that i2 bypasses i1 because when constructing the processor’s view i2 will be delayed until its causally-related buffered write is committed to the local replica. Acquire D restricts this behavior in which any instruction can similarly bypass an earlier (in program order) domestic ld.acq. The bypassing instruction cannot be moved too early in the processor’s view. It must follow the st that is causally related to the bypassed ld.acq.
If Acquire A is used in the Itanium memory consistency defined in Subsection 3.2 the Itaniums memory consistency model is defined. If, instead, Acquire B is used

in the Itanium system defined in Subsection 3.2 the Itaniumw memory consistency model is defined. ItaniumC is defined similarly by using the Acquire C order and ItaniumD is defined by using the Acquire D order.
Other Itanium consistency models are defined by the intersection between pairs of these consistency models. For example: Computations satisfying ItaniumC∩D must satisfy both ItaniumC and ItaniumD. The verifying sequences that show that a computation satisfies both consistency models may differ (the verifying sequences for ItaniumC and those for ItaniumD may be different sequences).
The final type of Itanium-based memory consistency models that we consider are defined by the conjunction of pairs of consistency models. It requires that there is one set of verifying sequences, which satisfy both models simultaneously. For example an ItaniumC∧D computation requires one set of sequences that simul- taneously meets the properties of both models ItaniumC and ItaniumD. Clearly, ItaniumC∧D is strictly stronger than ItaniumC∩D, ItaniumC∧B is strictly stronger than ItaniumC∩B and ItaniumD∧B is strictly stronger than ItaniumD∩B. Also, observe that Itaniums is stronger than Itaniumw and ItaniumC and ItaniumD. Any of the systems ItaniumC∧B, ItaniumC∧D and ItaniumD∧B is also weaker than Itaniums.





Strong  Weak
	 Incomparable







Fig. 1. Relative Strength of Various Systems


Incomparable consistency models
Figure 1 shows the relative strength of each system. The next two subsections present computations and proofs that establish the relationships in Figure 1. We
validabbreviate our notation as follows: a	b means that validity requires that a pre- cedes b in the sequence being discussed; a Same Mem b means that the Same Memory

Order requires that a precedes b in the sequence being discussed; a
Same Mem Agree
−→	b

means that the Same Memory Agreement requires that a precedes b in the sequence
being discussed; and hence forth.
Computation 1 of Section 4 was shown to satisfy Itaniumw but not Itanium (consequently, it does not satisfy Itaniums). Computation 1 does not satisfy ItaniumC (consequently, it does not satisfy any of ItaniumC∩B, ItaniumC∧B, ItaniumC∩D, or ItaniumC∧D); Acquire C prohibits a ld.acq to be bypassed by

any following instruction in program order, unless it is a domestic ld. In Compu- tation 1, both ld.acq instructions are followed by a single st instruction. Acquire C requires both ld.acq instructions to maintain their program order with the following st instructions. Hence in Computation 1 Acquire A and Acquire C are equivalent.
Formally, the sequence Sq must extend:
st (y, 4) v−a→lid 4 ←ld.acq (4) Acquire C st (x, 3).
p	q	−→	q
Sq
Since stp(y, 4) −→ stq(x, 3) the Cycle Free Agreement requires that stp(y, 4)
Sp
−→ stq(x, 3). Thus the sequence Sp does not exist because of the cycle: stp(y, 4)

Cycle Free
−→	stq(x, 3)
v−a→lid 3 ←ldp(x)
Same Mem
−→	stp(	2)
Same Mem
−→

2 ←ld.acqp(x)
Acquire C
−→	stp(y, 4).

Computation 1 satisfies ItaniumD. Since 4 ←ld.acqq(y) is foreign, Acquire D does not require program order to be maintained between 4 ←ld.acqq(y) and the following stq(x, 3). The following verifying sequences show that Computation 1 satisfies ItaniumD.
Sp : stq(x, 3) 3 ←ldp(x) stp(x, 2) 2 ←ld.acqp(x)
stp(y, 4)
Sq : stq(x, 3) stp(x, 2) stp(y, 4) 4 ←ld.acqq(y)
Since Computation 1 satisfies both Itaniumw and ItaniumD, it also satisfies ItaniumD∩B. However, it does not satisfy ItaniumD∧B. The sequence Sq must extend:

valid
stp(y, 4) −→ 4 ←ld.acqq(y)
Sq
Acquire B
−→	stq(x, 3).

Since	stp(y, 4) −→ stq(x, 3)	the	Cycle	Free	Agreement	requires	that
Sp
stp(y, 4) −→ stq(x, 3).	Thus the sequence Sp does not exist because of the

Cycle Free
cycle: st (y, 4)
valid
Same Mem
Acquire D

p
stp(y, 4).
−→	stq(x, 3)
−→ 3 ←ldp(x)
−→	stp(x, 2)	−→

Computation 3 is an example of a foreign ld.acq followed by a domestic ld.
Comp 3   p : st(x, 1) 2 ←ld.acq(y) 1 ←ld(x)
q :1 ←ld(x) st(x, 3) st.rel(y, 2)
Computation 3 is not possible under Itanium. For q to see 1 in x, stp(x, 1) must have been applied to both replicas. When p sees 2 in y, stq(x, 3) must have been also propagated to p’s replica, overwriting stp(x, 1), because the 2 is propagated via a following st.rel. There is no way by which p can see 1 in x, when performing
1 ←ldp(x) unless it is performed before 2 ←ld.acqp(y); however, Itanium requires
2 ←ld.acqp(y) to precede 1 ←ldp(x).
Formally, Computation 3 does not satisfy Itanium (consequently, it does not satisfy Itaniums) because the visibility order V must extend:

LV(stp(x, 1))
(WO)
−→ RVp(stp(x, 1))
(WO)
(WO)
−→ RVq(stp(x, 1))
(WO)
(RV 2)
−→ R(1 ←ldq(x))
(REL)
(W AR)
−→

LV(stq(x, 3))
(RV 2)
−→
−→	RVq(stq(x, 3))
−→	RVp(stq(x, 3))
−→	RVp(st.relq(y, 2))

R(2 ←ld.acqp(y))
(ACQ)
−→  R(1 ←ldp(x)).

This, however, ensures that the R(1 ←ldp(x)) does not satisfy any of (RV1), (RV2),
or (RV3).
Computation 3 is not possible with Itaniumw. Note that 2 ←ld.acqp(y) is for- eign and Acquire A and Acquire B are equivalent in this computation. In other words, Itaniumw requires the buffer to be flushed before the foreign 2 ←ld.acqp(y) is performed. Hence, 1 ←ldp(x) is not possible using an argument similar to the argument given for Itanium.
Formally, Computation 3 does not satisfy Itaniumw (consequently, it does not satisfy any of ItaniumC∧B,  ItaniumD∧B,  ItaniumC∩B,  or ItaniumD∩B)

: the sequence Sq must maintain stp(x, 1)
valid
−→ 1 ←ldq(x)
Same Mem
−→	stq(x, 3)

Release
−→	st.relq(	2).  Since stp(	1)
Sp
Sq
−→ stq(x, 3), by the Same Memory Agree-

ment we must have stp(x, 1) −→  stq(x, 3).	So, sequence Sp must maintain

Same Mem Agree
st (x, 1)
Release
valid
Acquire B

p	−→	stq(x, 3)
−→	st.relq(y, 2)
−→ 2 ←ld.acqq(y)	−→

1 ←ldp(x), yielding an invalid 1 ←ldp(x).
Both Acquire C and Acquire D allow 1 ←ldp(x) to appear as if it completed earlier than 2 ←ld.acqp(y). Hence Computation 3 is ItaniumC and ItaniumD as formally confirmed by the following sequences:
Sp : stp(x, 1) 1 ←ldp(x) stq(x, 3) st.relq(y, 2)
2 ←ld.acqp(y)
Sq : stp(x, 1) 1 ←ldq(x) stq(x, 3) st.relq(y, 2)
Note that these sequences simultaneously satisfy ItaniumD and ItaniumC. So, Computation 3 also satisfies ItaniumC∧D and ItaniumC∩D.
Computation 4 has a domestic ld.acq followed in program order by a domestic ld. ItaniumC does not constrain the ordering of this ld, while ItaniumD requires that 2 ←ldp(y) follows st.relp(x, 1) because it is causally related to 1 ←ld.acqp(x), which precedes 2 ←ldp(y).


Comp 4
1 ←ld.acq(x) 2 ←ld(y)
⎩ q :2 ←ld(y) st(y, 4) st.rel(x, 5)

Computation 4 is not Itanium. For q to see 2 in y, it must have been the case that stp(y, 2) removed from p’s buffer and applied to both replicas. So, when p sees 5 in x, it must also have received stq(y, 4) because the 5 is being propagate by a st.rel. Itanium requires 5 ←ldp(x) to precede st.relp(x, 1) and 2 ←ldp(y) to follow 1 ←ld.acqq(x). Also st.relp(x, 1) must precede 1 ←ld.acqp(x) because both are on
x. Hence, 2 ←ldp(y) must be performed after 5 ←ldp(x). However, we argued that on and after 5 ←ldp(x), the value of y in p’s replica must be 4, not 2.
Formally, Computation 4 does not satisfy Itanium nor Itaniums.  Had

it been the case, V must extend:	LV(stp(y, 2))
(WO)
−→	RVp(stp(y, 2))
(WO)
−→

RVq(stp(y, 2))
(RV 2)
−→ R(2 ←ldq(y))
(RAW )
−→	LV(stq(y, 4))
(WO)
−→ RVq(stq(y, 4))
(WO)
−→

RVp(stq(y, 4))
(RV 1 or 2)
(REL)
−→ RVp(st.relq(x, 5))
(ACQ)
(RV 2)
−→ R(5 ←ldp(x))
(REL)
−→ LV(st.relq(x, 1))

−→	R(1 ←ld.acqp(x)) −→  R(2 ←ldp(y)). However this means that the final
R(2 ←ldp(y)) does not satisfy any of (RV1), (RV2), or (RV3).
Computation 4 satisfies ItaniumC∧B (consequently, ItaniumC, Itaniumw, and ItaniumC∩B). 1 ←ld.acqp(x) is domestic and under these models, it can be sat- isfied from the buffer. These models allow 2 ←ldp(y) to complete (or appear to complete) before all of the preceding operations: 1 ←ld.acqp(x) because it is do- mestic, st.relp(x, 1) because it is on x, and 5 ←ldp(x) also because it is on a different variable. This is shown formally by the following sequences:
Sp : stp(y, 2) 2 ←ldp(y) stq(y, 4) st.relq(x, 5) 5 ←ldp(x)
st.relp(x, 1) 1 ←ld.acqp(x)
Sq : stp(y, 2) 2 ←ldq(y) stq(y, 4) st.relq(x, 5) st.relp(x, 1)
Computation 4 does not satisfy ItaniumD (and hence it does not satisfy any of ItaniumC∧D, ItaniumD∧B, ItaniumD∩B, or ItaniumC∩D).  Acquire D prohibits 2 ←ldp(y) to be moved forward in p’s view past st.relp(x, 1) because it is causally related to 1 ←ld.acqp(x) which precedes 2 ←ldp(y). So, a similar argument given for Itanium applies here.
Formally, the sequence Sq must extend:

stp(y, 2)
valid
−→ 2 ←ldq(y)
Sp
Same Mem
−→	stq(y, 4). Thus, the Same Memory Agreement

requires that stp(y, 2) −→ stq(y, 4). Therefore, Sp must extend:

Same Mem Agree
st (y, 2)
Release
valid
Release

p	−→	stq(y, 4)	−→	st.relq(x, 5)	−→	5 ←ldp(x)	−→
Acquire D
st.relp(x, 1)	−→	2 ←ldp(y). This ensures that the final 2 ←ldp(y) is invalid.
In Computation 5, 1 ←ld.acqp(x) is domestic and is followed by a st. only Acquire B among all other acquire orders allows stp(y, 2) to occur earlier than 1 ←ldp(x) in p’s view.


Comp 5
q :2 ←ld(y) st(y, 3) st.rel(x, 4)
⎩ t :4 ←ld.acq(x) 1 ←ld(x)

Computation 5 satisfies Itanium (Consequently, Itaniumw) as shown by the following visibility order V:
LV(stp(x, 1))	R(1 ←ld.acqp(x))	LV(stp(y, 2))	RVp(stp(y, 2))	RVq(stp(y, 2)) RVt(stp(y, 2)) R(2 ←ldq(y)) LV(stq(y, 3))
RVq(stq(y, 3))	RVp(stq(y, 3))	RVt(stq(y, 3))	LV(st.relq(x, 4))	RVq(st.relq(x, 4))
RVp(st.relq(x, 4)) RVt(st.relq(x, 4))
R(4 ←ld.acqt(x)) RVp(stp(x, 1)) RVt(stp(x, 1)) R(1 ←ldt(x)) RVq(stp(x, 1)).
Computation 5 is Itaniumw as shown by the following sequences:
Sp : stp(y, 2) stq(y, 3) st.relq(x, 4) stp(x, 1) 1 ←ld.acqp(x)
Sq : stp(y, 2) 2 ←ldq(y) stq(y, 3) st.relq(x, 4) stp(x, 1)
⎪⎪⎩  t	p	q	q

quence Sq must extend stp(y, 2)
valid
−→ 2 ←ldq(y)
Same Mem
−→	stq(y, 3). Thus, the

Same Memory Agreement requires that stp(y, 2) −→ stq(y, 3) in all sequences. So,

the sequence S
must extend st (x, 1) Same Mem
Acquire C
1 ←ld.acq (x)
st (y, 2)

p Same Mem Agree
p	−→
Release
p	−→	p

−→	stq(y, 3)
Acquire D
st (x, 1)
−→	st.relq(x, 4) or
Same Mem Agree

Release

p	−→	stp(y, 2)
−→	stq(y, 3)
−→	st.relq(x, 4) . Thus, the

Same Memory Agreement requires that stp(x, 1) −→ st.relq(x, 4) in all sequences.
Observe that the final part of Same Memory Order requires that sequence St main- tains 4 ←ld.acq(x) before 1 ←ld(x) and thus it cannot be valid.
Consequently, Computation 5 does not satisfy any of the models: ItaniumC∧D,
ItaniumC∧B, ItaniumD∧B, ItaniumD∩B, ItaniumC∩D, or ItaniumC∩B.
Theorem 5.1 Itanium is incomparable to
ItaniumC,
ItaniumD,
ItaniumC∧D,
ItaniumC∧B,
ItaniumD∩B,
ItaniumC∩B,
ItaniumC∩D
Proof.
Computation 3 is not Itanium but is ItaniumC .	Computation 5 is not
ItaniumC but is Itanium.
Computation 1 is not Itanium but is ItaniumD.	Computation 5 is not
ItaniumD but is Itanium.
Computation 3 is not Itanium but is ItaniumC∧D.  Computation 5 is not
ItaniumC∧D but is Itanium.
Computation 4 is not Itanium but is ItaniumC∧B.  Computation 5 is not
ItaniumC∧B but is Itanium.
Computation 1 is not Itanium but is ItaniumD∩B.  Computation 5 is not
ItaniumD∩B but is Itanium.
Computation 4 is not Itanium but is ItaniumC∩B.  Computation 5 is not
ItaniumC∩B but is Itanium.
Computation 3 is not Itanium but is ItaniumC∩D.  Computation 5 is not
ItaniumC∩D but is Itanium.

Theorem 5.2 Itaniumw is incomparable to
ItaniumC, and
ItaniumD.

Proof.
Computation 3 is not Itaniumw but is ItaniumC.	Computation 1 is not
ItaniumC but is Itaniumw.
Computation 3 is not Itaniumw but is ItaniumD.  Computation 5 is not
ItaniumD but is Itaniumw.

Theorem 5.3 ItaniumC is incomparable to ItaniumD.
Proof. Computation 4 is not ItaniumD but is ItaniumC. Computation 1 is not
ItaniumC but is ItaniumD.	 
Theorem 5.4 ItaniumC∧D is incomparable to ItaniumC∧B.
Proof. Computation 3 is not ItaniumC∧B but is ItaniumC∧D. Computation 4 is not ItaniumC∧D but is ItaniumC∧B.	 

A consistency model strictly weaker than Itaniums and stronger than Itanium
It can be established that ItaniumD∧B is strictly stronger than Itanium [8].
Theorem 5.5 ItaniumD∧B memory consistency is strictly stronger than Itanium
memory consistency.
So, ItaniumD∧B is weaker than Itaniums but still stronger than Itanium. At present a programmer-centric consistency model that is equivalent to Itanium has not been identified. However, there is promise in this technique of strengthening the Acquire B order.

An Itanium Operational Model
One possible Itanium machine has been defined by Chatterjee and Gopalkrishnan [3]. They provide an operational model that is defined in terms of buffers and memories and uses non-deterministic ordering rules. Figure 2 is a drawing of their machine. The local replica of processor p is denoted Mp. Each processor has three buffers: Write Output Buffer (WOB), Write Input Buffer (WIB), and a Read Buffer (RD). These abbreviations are subscripted by the owner’s id when required. For example, WOBp is the WOB of p.
We provide an informal description of the associated transition system. A ld.acq by p atomically checks p’s WOB for pending stores to the same memory location and either returns that value or, if none exist, returns the value of that location from Mp. A ld by p checks p’s WOB for pending stores to the same memory location and either returns that value or issues the ld to p’s RB, denoted Issue(ld to RBp). A st.rel by p issues the st.rel to p’s WOB, Issue(st.rel to WOBp). A st by p issues the st to p’s WOB, Issue(st to WOBp). A fence by p flushes the buffers, Flush(p). A memory write event at p checks to see if it is allowed, then updates memory p from the WIB for p and deletes the instruction, i from the WIB for p. We will denote





st.rel
























Fig. 2. Chatterjee and Gopalkrishnan Operational Model
these operations as Update(i into Mp) and Delete(i from WIBp) respectively. A memory read event at p returns the specified value from memory and deletes the load from the RB for p. We use the completed ld instruction to indicate the return of the read value and denote the delete as Delete(i from RBp). This short summary is missing many details about when transitions can occur. See [3] for that information. Computation 4, which was previously shown to be not possible on Itanium as specified by the architectural definition [9], is possible on this machine. The ld.acq in p of that computation is domestic it completes before the 5 ←ldp(x) instruction
which was issued to RBp. The following sequence shows the transitions:
Issue(stp(y, 2) to WOBp) −→ Issue(ldp(x) to RBp) −→ Issue(st.relp(x, 1) to WOBp) −→
←ld.acqp(x) 7 −→
←ldp(y) 8 −→
[ Delete(stp(y, 2) from WOBp) Issue(stp(y, 2) to WIBp)
Issue(stp(y, 2) to WIBq) ] −→ [ Delete(stp(y, 2) from WIBq)
Update(st(y)2 into Mq)] −→
[ Delete(stp(y, 2) from WIBp) Update(st(y)2 into Mp) ] −→
Issue( ldq(y) to RBq) −→

7 Completes using a value in WOBp
8 Completes using a value in WOBp

[ Delete(ldq (y) from RBq) 2 ←ldq(y)] −→
Issue(stq(y, 4) to WOBq) −→
[ Delete( stq(y, 4) from WOBq) Issue(stq(y, 4) to WIBp)
Issue(stq(y, 4) to WIBq)] −→
[ Delete(stq (y, 4) from WIBp)
Update(stq(y, 4) into Mp)] −→
[ Delete(stq (y, 4) from WIBq) Update(stq(y, 4) into Mq) ] −→
Issue(st.relp(x, 5) to WOBq) −→
[ Delete(st.relp(x, 5) from WOBq) Issue(st.relp(x, 5) to WIBp)
Issue(st.relp(x, 5) to WIBq) ] −→ [ Delete(st.relp(x, 5) from WIBp)
Update(st.relp(x, 5) into Mp) ] −→ [ Delete(st.relp(x, 5) from WIBq)
Update(st.relp(x, 5) into Mq) ] −→
[ Delete(ldp(x) from RBp)5 ←ldp(x)] −→
[ Delete(st.relp(x, 1) from WOBp) Issue(st.relp(x, 1) to WIBp)
Issue(st.relp(x, 1) to WIBq) ] −→ [ Delete(st.relp(x, 1) from WIBp)
Update(st.relp(x, 1) into Mp) ] −→ [ Delete(st.relp(x, 1) from WIBq)
Update(st.relp(x, 1) into Mq) ] .
It remains to determine the relationship between this machine and Itaniumw. The problem of finding an operational model that exactly captures Itanium also remains open.

Concluding Remarks
The Itanium memory consistency model is specified at the architectural level, with- out a reference architecture implementation. Such a low-level specification can be very useful to chip verification. However, they are not convenient to programmers and algorithm designers, who normally reason about their programs at a higher level. This work attempts but fails to formulate a programmer-centric description of the Itanium memory consistency model. Instead, it provides two very similar definitions (stronger and weaker than Itanium) that bound the official lower-level specifications. These two definitions differ in the way the load-acquires are imple- mented in the presence of write-buffers, such as if and when a load-acquire causes the buffer to be flushed.
This lead us to investigate different possible acquire orders and consequently different possible implementations for load-acquires. The result is an array of dif- ferent programmer-centric models largely incomparable to each other, but none of them tightly captures the official Itanium memory model.
We have also looked at an earlier attempt to provide an operational model for Itanium. We showed that this implementation admits behaviors that are prohibited

under Itanium.
Though these definitions do not tightly capture Itanium, they are still very useful to programmers. For instance to prove that a problem cannot be solved with Itanium, it suffices to show it is not solvable using Strong Itanium. To prove the correctness of an algorithm for Itanium, it suffices to show correctness under Weak Itanium. This however does not replace a single programmer-centric definition that is tightly captures the Itanium behavior. This work shows that this goal is a real challenge. We hope that the techniques demonstrated in this paper allow us to achieve this goal.

References
A. Adir, H. Attiya, and G. Shurek. Information-flow models for shared memory with an application to the PowerPC architecture. IEEE Trans. on Parallel and Distributed Systems, 14(5):502–515, 2003.
Arvind and J. W. Maessem. Memory model = instruction reordering + store atomicity. In Proceedings of ISCA 2006.
P. Chatterjee and G. Gopalakrishnan. Towards a formal model of shared memory consistency for intel itaniumtm. In Proc. 2001 IEEE International Conference on Computer Design (ICCD), pages 515–518, Sept 2001.
G. Gopalakrishnan, Y. Yang and H. Sivaraj. QB or not QB: An efficient execution verification tool for memory orderings. In Proc. 16th International Conference on Computer Aided Verification (CAV04), 2004.
L. Higham and L. Jackson. Porting between itanium and sparc multiprocessing systems. In Accepted to: 18th ACM Symposium on Parallelism in Algorithms and Architectures (SPAA ’06), to appear 2006.
L. Higham, L. Jackson, and J. Kawash. Specifying memory consistency of write buffer multiprocessors.
ACM Trans. on Computer Systems. To appear.
L. Higham, L. Jackson, and J. Kawash. Capturing register and control dependence in memory consistency models with applications to the itanium architecture, May 2006. Submitted to: DISC 2006.
L. Higham, L. Jackson, and J. Kawash. Programmer-centric conditions for itanium memory consistency. Technical Report Technical Report 2006-838-31, Department of Computer Science, The University of Calgary, July 2006.
Intel Corporation. A formal specification of the intel itanium processor family memory ordering.
http://www.intel.com/ , Oct 2002.
Intel Corporation. Intel itanium architecture software developer’s manual, volume 2: System architecture. http://www.intel.com/, Oct 2002.
R. Joshi, L. Lamport, J. Matthews, S. Tasiran, M. Tuttle, and Y. Yu. Checking cache-coherence protocols with tla, 2003.
SPARC Int’l, Inc. The SPARC Architecture Manual version 8. Prentice-Hall, 1992.
Y. Yang, G. Gopalakrishnan and K. Slind. Analyzing the intel itanium memory ordering rules using logic programming and sat. In Proc. 12th Advanced Research Working Conference on Correct Hardware Design and Verification Methods (CHARME03), pages 81–95, 2003.
Y. Yang, G. Gopalakrishnan and K. Slind. Nemos: A framework for axiomatic and executable specifications of memory consistency models. In Proc. 18th International Parallel and Distributed Processing Symposium (IPDPS04), 2004.
