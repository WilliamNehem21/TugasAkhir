 Electronic Notes in Theoretical Computer Science 93 (2004) 102–117 
www.elsevier.com/locate/entcs




Faithfully Reflecting the Structure of Informal Mathematical Proofs into Formal Type Theories

G.I. Jojgov, R.P. Nederpelt, M. Scheffer1
Eindhoven University of Technology The Netherlands

Abstract
Mathematical proofs, as written in every-day Common Mathematical Language (CML), are in- formal and many details are left implicit. To check such proofs with a proof assistant they need to be formalized and elaborated to full detail. In order to reduce the possibility of formalization errors and therefore increase the reliability of the translation of CML texts into type theories, we use a version of Nederpelt’s formal language WTT extended with logical notation that encodes the natural deduction proof steps. By using this intermediate version, the subsequent translation into a full-fledged type theory can be made such that the proof clearly reflects the structure of the original CML proof. This makes it easier to ensure that the formalization of the CML text is done correctly, and offers additional advantages over usual representations of proof terms in type theory.
Keywords: weak type theory, type theory, proof representation, formalization


Introduction
Proof assistants are interactive computer programs that are used to cre- ate, check and store formal theories in fields that may range from strictly theoretical as foundations of mathematics, to practical applications as prov- ing correctness of software or hardware systems. Given a text in its formal language, the proof assistant is capable of checking its correctness with re- spect to a set of rules. The role of the human in this process is to provide the

1 Email: G.I.Jojgov@tue.nl R.P.Nederpelt@tue.nl M.Scheffer@tue.nl


1571-0661 © 2004 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2003.12.030


formalization and to guide the proof assistant during the proof construction process.
One can ask how reliable such a method is for doing mathematics with a proof assistant. To answer this question we need to look at the two main phases in the translation of an informal proof (in the mind of a mathematician) to its fully formalized and computer-checked version (see Figure 1). At the first stage we have to phrase the informal proof/theory in the language of the prover. Then at the second stage, using the prover we create and/or check the formal proof.
The famous de Bruijn criterion states that in order to have a maximum
reliability in the second phase, we need to have a small, manually-verifiable proof-checker to control the proofs. The proof-checker is independent of the possibly very complex machinery that actually constructs those proofs. There- fore, by using a proof assistant that conforms to the criterion of de Bruijn we can achieve a fairly high degree of reliability.

Fig. 1. The two stages of the formalization process. The initial formalization translates the informal theory (1) written in CML (e.g. an article in LATEX) into a formulation in a formal system
(2) (e.g. a WTT text) without checking logical consistency. At the second stage the proofs are
created or refined if necessary. The result is a formally verified theory (3) (e.g. in the Calculus of Constructions)
As shown by practical experiences with proof assistants, the reliability of the initial formalization of the informal theory is at least as important. The problem in this case is however that there is no way to check that a formal statement correctly reflects the informal ideas that the author of the text had. In [8] the following approach to this problem is proposed: In order to increase the reliability of the initial translation of informal ideas into a formal system, introduce a new formal system that is as close as possible to the informal common mathematical language (CML). By providing a low-threshold initial formalization, we shorten the distance between the informal and the formal versions of a theory and therefore reduce the risk of making ‘undetectable’ formalization errors. The formal system proposed in [8] (and first introduced in [5]) is called Weak Type Theory (WTT). It imposes very little constraints (hence ‘weak’) on the formal text and mainly focuses on ensuring linguistic coherence.


On the other hand, proofs encoded in Type Theory are subject to tight typing rules and a well-typed term inhabiting a propositional type is an en- coding of a fully formalized proof of that proposition. Since many interactive theorem provers (like Coq [9]) use the procedurally-oriented tactics-based ap- proach, the proof terms constructed by these systems are often unreadable and the structure of the original proof is not visible.
The aim of this paper is to show by means of a tiny case study that the possibility to reflect the logical reasoning (expressed by natural deduction steps) and the possibility to reflect the informal discourse of a CML proof are actually orthogonal. We show how a mathematical proof written in CML can be presented formally in a version of WTT, extended with notation for natural deduction steps and subsequently translated into a full-fledged type
theory. We will show that both versions of the proof reflect the structure of the
original CML proof and remain very close to it. This means that it is easier for the author to make sure that his informal ideas are correctly represented in
the formal version. We use a fairly standard extension of type theory (namely adding global deﬁnitions) to encode the formal WTT proof in type theory.
In comparison with the ‘standard’ approach of encoding proofs as single λ-terms we see significant gains in e.g. the readability of the proof, the pos- sibilities for its maintenance (i.e. dealing with changes in the original proof) and therefore the overall reliability of the formalization.
The contribution of this paper should be seen not in the introduction of new systems but rather in the way we can use existing ones (WTT, type- theory) to address the problems of reliability of formalization in type-theory based theorem provers. In particular, we show how the structure of informal proofs written in a WTT version extended with notation for natural deduction (ND) steps can be maintained in existing type systems.
In the next section we first give a short introduction to WTT and a version of WTT extended with logical notation (called WTTL). In Section 3 we introduce the extensions that we make to the Calculus of Constructions (λC) in order to maintain the structure of the WTTL proofs. Subsequently in Section 4 we give a sample translation of a CML proof into type theory via WTTL and compare it with the traditional encoding in type theory. We end with a brief discussion of related work in Section 5 and conclusions in Section 6.

WTT and a logical extension to WTT
It is beyond the scope of this article to fully introduce Weak Type Theory, a language to express mathematical texts; here we limit ourselves to giving a first impression of the language. WTT was first introduced in [5] and is a


refinement of de Bruijn’s Mathematical Vernacular [1] (MV).
WTT is faithful to the mathematician’s language yet is formal and avoids ambiguities.
WTT is close to the usual way in which mathematicians express themselves in writing.
WTT has a syntax based on linguistic categories instead of set/type theo- retic constructs.
More so than MV however, WTT has a precise abstract syntax whose derivation rules resemble those of modern type theory, enabling important desirable properties of the WTT language such as strong normalisation, de- cidability of type checking and subject reduction (with respect to δ-reduction). The derivation system allows one to establish that a book written in WTT is well-formed following the syntax of WTT, and has great resemblance with ordinary mathematics books.
WTT (like MV) is weak as regards correctness: the rules of WTT only concern linguistic correctness, its types are purely linguistic so that the formal translation into WTT is satisfactory as a readable, well-organized text. In WTT, logico-mathematical aspects of truth are disregarded. This separates concerns and means that WTT:
can be easily understood by either a mathematician, a logician or a computer scientist.
acts as an intermediary between the language of mathematicians and that of logicians.
is independent of any underlying formalism, such as type theory, set theory or category theory.
The syntax of WTT is based on linguistic categories, that form the (weak) types of the WTT terms. We mention the linguistic categories of WTT with- out going into details:
on the atomic level: variables, constants and binders
on the phrase level: terms, sets, nouns and adjectives
on the sentence level: statements and definitions
on the discourse level: contexts, lines and books
A WTT book represents a mathematical proof and consists of a sequence of lines, each being either a statement or a definition (in a certain context). The context ‘sets the stage’ for a statement/definition and is itself a list of statements (being either assumptions or typing statements, also known as dec- larations). On its turn, statements and definitions are build up from smaller


linguistic categories at the phrase and atomic level, among which terms, sets, nouns, binders, etc.

Fig. 2. Exam√ple of a definition line and a statement line of a WTT book. The binder ι in the
definition of	x is Russel’s definite descriptor. The expression ιy:R(ϕ(y)) should be read as ‘the
real number y for which ϕ(y) holds.

Figure 2 shows an example of a definition line and a statement line in WTT. The contexts consist of a declaration of a variable x and assumption it
and is separated from the actual statement of the line by a symbol ‘D’. The statement of the line is on its turn build up from constants like √, = and +,
variables x and n, and from the binder ∃.
The abstract syntax of WTT, which we do not give here, establishes the well-formedness conditions for these linguistic categories. All constructs ob- tained with the derivation system have a weak type, which corresponds to a linguistic category. The derivation rules, for which we also refer to [5], only give a subset of the well-formed constructs obtained with the abstract syn- tax, since the rules enforce that those constructs obey certain (weak) typing requirements.
The derivation system is syntax-driven, in the sense that for each sub(goal) in a derivation, only one rule is applicable. A book constructed with our derivation system is transparently structured and in general less ambiguous than CML texts. The derivation rules for example enforce that all parameters of a constant that is used are spelled out and that there are no free variables in a book.
WTT can be used as a starting point in the translation of mathematical texts into type theory. We show how the use of a WTT version extended with logic (i.e. WTTL) can be used to obtain a type theoretical translation of CML texts that clearly preserve the structure. Thereto we have to add definitions for all logical operators and rules to the context of the judgement in type theory.
Examples
We consider an example translation into WTT of a proof from mathe- matical analysis. It contains the definitions of ‘difference quotient’ and of ‘differentiable’ and a statement using the latter definition:
For convenience we first abbreviate the following contexts by Γ1 and Γ2:



Fig. 3. A CML text from analysis.

Γ1 ≡ A ⊆ R,f : A → R,a : A, h : R,h /= 0,a + h ∈ A
Γ2 ≡ A ⊆ R,f : A → R,a : A
The WTT book corresponding to the text in Figure 3 is presented on Figure 4.

Fig. 4. The analysis text of Figure 3 in WTT.

To illustrate how WTT can be extended with logical notation, let us look at another example. We translate the following CML proof of one of the rules of de Morgan, that says (a b)  ( a  b), into WTT. Figure 5 shows the proof of the rule in CML.

Fig. 5. CML version of de Morgan’s proof
The constants and binders used in a WTT book are listed in the so-called preface of that WTT book, which lists the weak types of the constants/binders and their arguments.

Preface:
Constants	Arguments	Type

,  ,	(stat, stat)	stat
(stat)	stat
f alse	()	stat
We first abbreviate the following contexts: Γ1 ≡  a : stat,b : stat
Γ2 ≡ Γ1, ¬(a ∧ b) Γ3 ≡ Γ2, ¬(¬(a)) Γ4 ≡ Γ3,b 
Given the preface and the contexts Γ1 ... Γ4 as above, the informal proof of Figure 5 can be encoded by the WTT text on Figure 6. Notice that the

Fig. 6. The proof of de Morgan’s law translated into a WTT book

version of Figure 6 is a faithful representation of the CML version; therefore it also contains line 5, although this is not strictly necessary to derive de Morgan’s rule. The WTT text does not include the logic reasoning behind the statements. In the corresponding extended version of WTT, we include the logical reasoning (based on rules of classical natural deduction) in the rightmost column. An impression of the WTTL version can be found on the Figure 7, for a detailed introduction to the extended version of WTT see [6]. Although this could be done, the so-called logical comments of WTTL version are not checked for correctness: the final check for correctness is done on the level of type theory, not here. We could also decide to translate this
extended WTT version to other formalisms than type theory.
Next, we show how we can adapt the calculus of constructions so that we can translate the proof of Figure 7 into type theory in such a way that the structure of the proof is maintained.



Fig. 7. The proof of de Morgan’s law translated into WTTL – an extension of WTT with ND logical comments.
Extending λC with Global Parametric Definitions and Constants
To add global parametric definitions and parametric constants in the style of [11,15] to the Calculus of Constructions λC [10], we extend the set of pseudo- terms by allowing constant instances c(t1,... , tn). This means that the set of the pseudoterms T is given by
T := V | C(T ... T ) | (T T ) | (λV : T . T ) | (ΠV : T . T )

The pseudo-contexts are also extended by allowing the declaration and definition of global constants (respectively denoted as Γ1, c(→x : A→): B, Γ2 and Γ1, c(→x : A→) := T : B, Γ2). The abbreviation →x : A→ stands for a list of declarations x1 : A1,... , xn : An.
The definitions can be subject to unfolding, which is usually referred to as
δ-reduction:
Γ1, c(→x : A→) := T : B, Γ2 ▶ c(→t) →δ T [→x := →t]
where T [→x := →t] abbreviates T [x1 := t1] ... [xn := tn].
In addition to the standard typing rules of λC, we have three extra rules for dealing with primitive parametric constants and parametric constant defini- tions. The first two rules are weakening rules that are needed to add primitive constants and definitions to the context. The third rule is needed for the use (i.e. instantiation) of these constants.
In addition, in the conversion rule of λC the β-equality is replaced by βδ- equality. The resulting system will be referred to as λCD. It is contained in the systems described in [11,15], but here we do not use the additional possibility


to introduce local definitions.

Formalizing a CML proof
Let us start with a mathematical proof as it can be found in mathematics books. To clearly illustrate the technique we take a simple example and use a naive formulation of set t√heory here; a more elaborate example translation
(of Pythagoras’ proof that	2 is irrational) can be found in [6].
Consider the CML proof on Figure 8 of the statement A	B	A B = in set theory. Mathematicians have no problem reading this text and following

Fig. 8. A proposition and its CML proof.
the idea of the proof although quite a few details are left implicit. One such detail is the set-theoretic foundation on which the proof is based, another is the precise logical reasoning justifying the steps of the proof and yet a third

Fig. 9. The proof in WTTL . Each line has a number, optional label, a context, the statement that is claimed or a definition of a constant, and finally a logical comment (not checked for consistency)
one is the ambiguity of natural language.


Compare the CML proof with the text in Figure 9 where the gray text represents items in the informal text that are (for the main part) implicit. In the right column we add the logical reasoning behind the statements. These so-called logical comments are built up according to rules, specific to the chosen logic (ND for classical first order logic in this case). The contexts Γi abbreviate the following:
Γ1	≡	X, Y : SET
Γ2	≡	A, B : SET
Γ3	≡	A, B : SET, A ⊆ B
Γ4	≡	A, B : SET, A ⊆ B, x : U, x ∈ A \ B
Although this text contains much more detail than the original CML proof we can still read it and follow the proof step by step. Those steps are not the steps that we make in some proof system, but the statements that the author
used or meant in his/her proof. In that sense the formal version reflects the
structure of the original proof.
The proof of Figure 9 is written in a formal language and is verifiably in accordance with its syntax and rules, but its logical correctness has not been verified. To do that we need to fully formalize the logical comments (in gray) that it contains. This can be done by translating this text into type theory.
One way to do that is to formulate the theorem in the language of a proof assistant and use its facilities (tactics) to prove it. But then of course we are creating a different proof whose structure is dictated by the proof assistant. Eventually, when we finish the proof, we have a proof term and a proof script that generated it, but their relation to the original proof is not clear.
Suppose that the type theory we want to translate our proof into is the Calculus of Constructions (λC) [10]. Using the formulas-as-types embedding of logic into λC, we can encode proofs into lambda terms. One such term 2 is presented in Figure 10. We can check that it really encodes a proof of the statement that we wanted to prove, but it does not reflect the proof that we started with and it can barely be called human-readable.
We will show that this does not necessarily have to be the case. We need a more declarative approach than using pure λ-terms. One possibility is to represent the proof not as one single λ-term but as a sequence of terms representing each step of the original proof. This sequence can naturally be expressed by a series of definitions in a context of a typing judgement in the following way: Suppose Γ0 is a context describing all elements of the language that we work with and the global assumptions for the proof. Then each informal step of the proof (i.e. each line in its formulation in WTT)

2 This is the β-normal form of the term presented in Appendix A, here given in the usual
λ-calculus syntax.



Fig. 10. A λ-term encoding a proof of A  B  A B = . H1 and H2 encode the two lemmata used implicitly in the informal proof.
is added as a parameterized definition in the context, Γ0, l1(∆1) := M1 : A1,... , ln(∆n) := Mn : An. Each definition li(∆i):Ai represents the encoding Ai of the statement of line i and Mi encodes the reasoning steps to conclude Ai from the previous lines (see the box below). Note that each definition has a number of parameters ∆i describing local variables and assumptions.

Fig. 11. Encoding a line as a definition.
Extending λC with definitions in the context (global definitions) is not difficult (see Section 3) and one can show that the obtained λCD enjoys the usual properties of the Calculus of Constructions (Severi [11], Bloo et al. [15,13], Kamareddine [12]).
Normally, proof-checking is translated into type-checking of the term that encodes the proof. In our case the checking of a proof becomes checking the validity of the context that encodes it. To illustrate how this works we present the sample proof as a typing context in Figure 12. There we see how each of the nine lines is encoded as a definition. Let Γ be the context of Figure 12 prefixed by context Γ0 containing declarations for the elements of the language and the logic that we formalize the proof in. If in λCD we manage to prove Γ ▶ ∗ :  then we can be sure that the proof is correct.
Compare the representation of the proof by a context with the λ-term in Appendix A that corresponds to it. We obtained it by translating the proof in Figure 12 to the proof assistant Coq [9] and unfolding all definitions. Although both the context of Figure 12 and the term in Appendix A represent the same proof, the version using definitions in the context is more comprehensible.


Note that each of the steps of the original proof is still clearly present in the context presentation. This provides greater reliability because we can trace back the definitions to the steps of the informal proof.
Ideally the translation from the presentation on Figure 9 to the context on Figure 12 would be done automatically. The translation from the extended WTT version to λCD can, at least for a large part, be automated. We briefly describe the procedure below.
Each book, as in Figure 9, becomes a judgement of the form Γ ▶ ∗ :  in type theory. The constants and binders of the preface of the WTT book are included in the context of the judgement in λCD. Each line of the WTT text then becomes a constant definition in the context of the λCD translation. Each element of the WTT context becomes a parameter of the defined constant in λCD. The logical comments correspond to ND rules and using the Curry- Howard embedding can be encoded as λ-terms that form the body of the definition in the typing context that codifies a WTTL line with a statement. Since the WTTL text may represent logically incorrect proofs, this trans- lation can produce an invalid context, but even then we get a reference to the original text where the error originated from, by locating the definition in the context that did not typecheck. However, the experience in [6] shows that there are problems for fully automatic translation that require further
investigation.

Related Work
In [11] Severi and Poll describe how to introduce definitions in a Pure Type System. Their work is extended by Bloo et al. [15,13], Kamareddine [12] by considering also parametric definitions. The rules presented in Section 3 are derivable from those works. Most of the current theorem proving systems support definitions of some sort. One of the well-known application of defini- tions there is to simulate a form of forward reasoning. It is interesting in our case that we only need to introduce global definitions in order to reflect the declarative aspects of proof-representation.
The need for a mathematician-friendly interface to proof assistants is also the motivation behind the mathematical proof language proposed by Baren- dregt [7]. It is inspired by the declarative approach taken by the system Mizar
[14] where one writes his/her proof statement by statement and the computer tries to infer the reasoning steps between the statements. In [16] Wiedijk pro- poses formal proof sketches for the language of Mizar which are also close to CML presentations of proofs.
We thank the anonymous referee of the paper for pointing out the work of


Lemma1(X : ∗s,Y : ∗s,a : U, p : a ∈ X \ Y ) : a ∈ X ∧ ¬(a ∈ Y ), Lemma2(X : ∗s) : ∀x∈X(f alse) ⇒ X =2s ∅,
⊆(X : ∗s,Y : ∗s) := ∀(X, λx : X.x ∈ Y ),


l1(A : ∗s,B : ∗s,p : A ⊆ B, x : U, q : x ∈ A \ B) :=
Lemma1(A, B, x, q) : x ∈ A ∧ ¬(x ∈ B),
l2(A : ∗s,B : ∗s,p : A ⊆ B, x : U, q : x ∈ A \ B) :=
∧-elimleft(x ∈ A, ¬(x ∈ B), l1(A, B, p, x, q)) : x ∈ A,
l3(A : ∗s,B : ∗s,p : A ⊆ B, x : U, q : x ∈ A \ B) :=
p : ∀y:A(y ∈ B),
l4(A : ∗s,B : ∗s,p : A ⊆ B, x : U, q : x ∈ A \ B) :=

∀-elim(A, λx
: A.x'
∈ B, l3(A, B, p, x, q), l2(A, B, p, x, q)) : x ∈ B,

l5(A : ∗s,B : ∗s,p : A ⊆ B, x : U, q : x ∈ A \ B) :=
∧-elimright(x ∈ A, ¬(x ∈ B), l1(A, B, p, x, q)) : ¬(x ∈ B),
l6(A : ∗s,B : ∗s,p : A ⊆ B, x : U, q : x ∈ A \ B) :=
¬-elim(x ∈ B, l5(A, B, p, x, q), l4(A, B, p, x, q)) : f alse, l7(A : ∗s,B : ∗s,p : A ⊆ B) :=
∀-intro(U, λx : U.x ∈ A \ B ⇒ f alse, λx : U.λy : x ∈ A \ B.l6(A, B, p, x, y))
: ∀x∈A\B(f alse),
l8(A : ∗s,B : ∗s,p : A ⊆ B) :=
⇒-elim(∀x∈A\B(f alse),A \ B = ∅, Lemma2(A \ B), l7(A, B, p))
: A \ B = ∅,
l9(A : ∗s,B : ∗s,p : A ⊆ B) :=
⇒-intro(A ⊆ B, A \ B = ∅, λx : A ⊆ B.l8(A, B, x)) : A ⊆ B ⇒ A \ B = ∅,


∗ : 

Fig. 12. The λCD context captures the structure of the CML proof

Huang [4] where Gentzen’s natural deduction [3,2] proofs are presented at the assertion level. This is achieved by identifying domain-specific derivable rules that are used to abbreviate tedious parts of the proof. On the logical level this allows the representation of the same reasoning steps as in our presentation. However since we use WTT as a basis, the texts written in WTTL can be seen as natural deduction proofs provided that they are correct. Since we strive for a low threshold formalism we impose weak (i.e. linguistic) constraints and therefore allow more texts including logically incorrect ones.

Conclusions
In our tiny case study we have shown that within currently available systems it is possible to choose an alternative representation of proofs that faithfully represents the structure of the informal arguments formalized in the proof. This gives us an increased level of confidence that the formal proof is the one the author meant. It also allows tracing back which parts of the formal proof correspond to which part of the informal one and therefore increases the maintainability of the proof. By starting the formalization as close as possible to the informal representation, we reduce the chance of formalization errors.
In recent years, we have seen a successful implementation of several differ- ent proof checking systems (e.g. COQ, Mizar, PVS, Lego, Nuprl, Agda, HOL, Isabelle, etc.). Although many of them have evolved to mature systems, wide acceptance of proof assistants by mathematicians outside the theorem proving community is still to come.
Now that their foundations have been sufficiently developed, the time has come for the proof assistants to become an accepted research tool for mathe- maticians. To achieve this goal we need to lower the threshold for using them. Therefore the formalization process needs to be made easier so that also ma- thematicians who are not type theory experts can use a proof assistant. We hope that with this paper we have shown how some of these goals could be achieved within the existing systems.

References
Bruijn, N.G. de. The Mathematical Vernacular, a Language for Mathematics with Typed Sets,
Proceedings of the Workshop on Programming Languages, Marstrand, Sweden, 1987, p. 865-936
Andrews, P.B. An Introduction to Mathematical Logic and Type Theory: To Thruth through Proof, Academic Press, Inc., 1986
Pravitz, D. Natural Deduction: A Proof Theoretic Study, Almquist & Wiksel, 1965
Huang, X. Reconstructing Proofs at the Assertion Level, 12th International Conference on Automated Deduction, 1994


Nederpelt, Rob. Weak Type Theory: A formal language for mathematics, May, 2002, CSR-02-05,
Technische Universiteit Eindhoven
Scheffer, Mark. Formalizing Mathematics Using Weak Type Theory, 2003, M.Sc. Thesis,
Technische Universiteit Eindhoven, Available via http://zax.mine.nu
Barendregt, Henk. Towards an Interactive Mathematical Proof Language, Thirty Five Years of Automath, F. Kamareddine ed., Kluwer, 2003
Kamareddine, Fairouz and Nederpelt, Rob. A derivation system for a formal language of mathematics, July, 2001, Submitted for publication
The Coq Development Team. The Coq Proof Assistant Reference Manual – Version V7.4, Feb 2003, http://coq.inria.fr

Coquand, Thierry and Huet, G´erard. The Calculus of Constructions, Information and Computation, p. 95-120, 1988, number 76(2/3)
Severi, P. and Poll, E. Pure Type Systems with Definitions, 1994, Proc. of LFCS’94,
St. Petersburg, Russia, p. 316–328, LNCS series, number 813, Springer Verlag, Berlin
Kamareddine, F. and Nederpelt, R. Refining the Barendregt Cube using Parameters,
Proceedings of FLOPS 2001, p. 375–389, LNCS 2024, Springer Verlag, 2001
Bloo, R. and Kamareddine, F. and Nederpelt, R. The Barendregt Cube with Definitions and Generalized Reduction, Information and Computation, 126(2), pp. 123–143, 1996
Mizar. The System Mizar, http://www.mizar.org
Bloo,R. and Kamareddine, Fairouz and Laan, Twan and Nederpelt, Rob. Parameters in Pure Type Systems, Proceedings of LATIN’02, 2002, Springer, volume LNCS 2286,
Wiedijk, Freek. Formal proof sketches, Fokkink, Wan and Pol, Jaco van de, 7th Dutch Proof Tools Day, CWI, 2003

A	Proof Term
The term below (in Coq syntax) is obtained by unfolding all definitions from Figure 12. λ-abstraction is incoded in Coq by square brackets and Π-abstraction by round brackets.
[A, B:∗s; p:(A ⊆ B)]
([A0, B0:∗s; p0 :(A0 ⊆ B0 )] (H2 (A0 \ B0 )
([A1, B1 :∗s; p1:(A1 ⊆ B1 )]
([A2:∗s; P :(U → ∗p); p2 :((x:U )(x ∈ A2) → (P x)); x:U ](p2 x)
(A1 \ B1 ) [ :U ]False [x:U ; g:(x ∈ (A1 \ B1 ))]
([A2, B2 :∗s; p2:(A2 ⊆ B2 ); x0:U ; q:(x0 ∈ (A2 \ B2 ))]
([A3:∗p; p3:([A:∗p ]A → False A3); q0:A3 ](p3 q0) (x0 ∈ B2)
([A3, B3 :∗s; p3:(A3 ⊆ B3 ); x1:U ; q0:(x1 ∈ (A3 \ B3 ))] ([A4, B4 :∗p;
p4:([A, B:∗p](γ:∗p )(A → B → γ) → γ A4 B4)]
(p4 B4 [ :A4; l:B4 ]l) (x1 ∈ A3) (x1 ∈ B3 ) → False
([A4, B4:∗s;  :(A4 ⊆ B4 ); x2:U ;
q1:(x2 ∈ (A4 \ B4 ))](H1 A4 B4 x2 q1) A3 B3 p3
x1 q0)) A2 B2 p2 x0 q) ([A3, B3 :∗s; p3:(A3 ⊆ B3 ); x1:U ; q0:(x1 ∈ (A3 \ B3 ))]
([A4:∗s; P :(U → ∗p );
f0:([A:∗s; P :(U → ∗p)](x:U )(x ∈ A) → (P x) A4 P );
t:U ; q1 :(t ∈ A4 )](f0 t q1) A3 [y:U ](y ∈ B3 )
([A4, B4:∗s; p4:(A4 ⊆ B4 ); x2 :U ;
:(x2 ∈ (A4 \ B4 ))]p4 A3 B3 p3 x1 q0) x1
([A4, B4:∗s; p4:(A4 ⊆ B4 ); x2 :U ; q1:(x2 ∈ (A4 \ B4 ))]
([A5, B5:∗p; p5:([A, B:∗p](γ:∗p )(A → B → γ) → γ A5 B5 )] (p5 A5 [k:A5 ; :B5 ]k) (x2 ∈ A4 )
(x2 ∈ B4 ) → False
([A5, B5:∗s;  :(A5 ⊆ B5 ); x3:U ;
q2:(x3 ∈ (A5 \ B5 ))](H1 A5 B5 x3 q2) A4
B4 p4 x2 q1)) A3 B3 p3 x1 q0)) A2 B2 p2 x0 q)) A1 B1 p1 x g)) A0 B0 p0 )) A B p)
: (A, B:∗s)(A ⊆ B) → ((A \ B)= ∅)
