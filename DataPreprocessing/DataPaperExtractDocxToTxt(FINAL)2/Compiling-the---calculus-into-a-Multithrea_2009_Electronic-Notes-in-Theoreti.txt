

Electronic Notes in Theoretical Computer Science 241 (2009) 57–84
www.elsevier.com/locate/entcs

Compiling the π-calculus into a Multithreaded Typed Assembly Language
Tiago Cogumbreiro, Francisco Martins, Vasco T. Vasconcelos
Department of Informatics, Faculty of Sciences, University of Lisbon, Portugal

Abstract
We extend a previous work on a multithreaded typed assembly language (MIL) targeted at shared memory multiprocessors, and describe the design of a type-preserving compiler from the π-calculus into MIL. The language enforces a policy on lock usage through a typing system that also ensures race-freedom for typable programs, while allowing for typing various important concurrency patterns. Our translation to MIL gener- ates code that is then linked to a library supporting a generic unbounded buffer monitor, variant of Hoare’s bounded buffer monitor, entirely written in MIL. Such a monitor shields client code (the π-calculus compiler
in particular) from the hazardous task of direct lock manipulation, while allowing for the representation of π-calculus channels. The compiler produces type correct MIL programs from type correct source code, generating low-contention cooperative multithreaded programs.
Keywords: Pi-calculus, multithreaded assembly language, typed assembly language

Introduction
Current trends in hardware made available multi-core CPU systems to ordinary users, challenging researchers to devise new techniques to bring software into the multi-core world. However, shaping software for multi-cores is more evolving than simply balancing workload among cores. In a near future (in less than a decade) Intel prepares to manufacture and ship 80-core processors [13]; programmers must perform a paradigm shift from sequential to concurrent programming and produce, from scratch, software adapted for multi-core platforms.
High-level programming languages must as well undergo substantial transforma- tions in order to make available concurrency primitives at an adequate level of ab- straction, balancing the added power of concurrent programming with the increase of complexity in applications. Important operational properties of high-level lan- guages, and therefore of programs written in those languages, are captured via types and enforced using type systems. Ultimately, such properties should be present in the running application, since they contribute to certify its correct execution. One approach to express and verify operational properties of actual running code is to

1571-0661 © 2009 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2009.06.004

equip assembly languages with types, and take advantage of type safety properties enforced by type systems. Building compilers that preserve typings while translat- ing a high-level typed language into a typed assembly language helps in securing properties of the source language. Our contribution towards this end starts not from an high-level programming language, but from the π-calculus, a concise language from channel-based concurrent computations, and arrive at a multithreaded typed intermediate language (MIL), while preserving typability.
The type system we propose for MIL closely follows the tradition of typed as- sembly languages [20,21,22], extended with support for threads and locks, following Flanagan and Abadi [8]. With respect to this last work, however, our work is posi- tioned at a much lower abstraction level, and faces different challenges inherent to non-lexically scoped languages. Lock primitives have been discussed in the context of concurrent object calculi [7], JVM [9,10,16,17], C [12], C-- [27], but not in the context of typed assembly (or intermediate) languages. In a typed setting, where programs are guaranteed not to suffer from race conditions, we
Syntactically decouple the lock and unlock operations from what one usually finds unified in a single syntactic construct in high-level languages: Birrel’s lock-do-end construct [2], used under different names (sync, synchronized-in, lock-in) in a number of other works, including the Java programming language [4,5,7,8,9,10,12];
Allow for lock acquisition/release in schemes other than the nested discipline imposed by the lock-do-end construct;
Allow forking threads that hold locks.
We previously introduced a multithreaded typed assembly language (MIL) and its operational semantics, together with a type system that ensures that well-typed programs are free from race conditions [30]. The present paper presents a version of the language that includes:
Read-only tuples. We adhere to the continuation-passing [1] style when writing MIL code, since for simplicity MIL does not provide for stack manipulation. It turns out that in many situations closures are immutable. In particular, closures obtained by translating π-calculus programs are constant. In order to help coding this common pattern we introduce read-only tuples that need not be protected by locks, since they introduce no potential races.
Tuple creation in registers. In order to initialize read-only tuples, these are created directly in registers. As long as the tuple remains local to the (single threaded) processor there is no need to protected it with a lock nor to gain permission to manipulate it. If the tuple is to be shared, the share instruction allocates memory in the heap, copies the tuple in the register to the heap, while protecting it with a lock or marking as read-only.
Polymorphic types. We discussed how to introduce universal and existential types in [30]. Here we incorporate both kinds of polymorphism, in particular existential types over locks. Universal and existential types over locks allow a lock variable to escape the static scope where it was declared.

Compilers for several concurrent programming languages based on process cal- culi have been proposed, including for the TyCO language [18], the Join calcu- lus [11], Pict [26], and HACL [23]. These works, however, target sequential archi- tectures and are not proved to be type-preserving. A proposal for compiling TyCO, concurrent object-based language, into a multithreaded run-time system [24] was conducted in a untyped setting.
Type-preserving compilation, on the other hand, maintains type information throughout each compilation stage. The work from Morrisett et al. [22] presents
a five stage type-preserving compilation, from System F into a (sequential) typed assembly language.
This paper proposes a type-preserving translation from the π-calculus into MIL, a multithreaded typed assembly language for multi-core/multi-processor architec- tures. We start from a simple asynchronous typed version of the π-calculus [3,15] and translate it into MIL code. The translation is proved to preserve typability. A by-product of this work is an unbounded buffer monitor, variant of Hoare’s bounded buffer monitor [14], entirely written in MIL. The monitor provides, in addition to creation, procedures to append elements to the buffer and to remove elements from the buffer, shielding client code (the π-calculus compiler in particular) from the haz- ardous task of direct lock manipulation. A type-checker and an interpreter for MIL, as well as the code for the unbounded buffer monitor and the π-to-MIL compiler are available on-line [19].
The outline of the paper is as follows. Sections 2 and 4 describe the target language (MIL) and the source language (π-calculus), respectively. The section on MIL also shows the main result for the language, in the form of the lock discipline imposed by the type system, and race freedom for typable processes. Section 3 introduces the code for the monitor, showing MIL in action. Section 5 defines the translation function itself, together with the result on type preservation. In the closing section we summarise our results and outline directions for further investi- gation.

Target Language: A Multithreaded Intermediate Lan- guage
MIL is an assembly language targeted at an abstract multi-processor equipped with a shared main memory. Each processor consists of a series of registers and of a local memory for instructions. Registers may directly contain tuples, representing data local to the processor. In order to use MIL a real system must implement some scheme of local memory. The main memory is divided into a heap and a run pool. The heap stores data and code blocks. A code block declares the registers types it expects, the required locks, and an instruction sequence. The run pool contains suspended threads waiting for a free processor. Figure 1 summarises the MIL architecture.
This section introduces the lock discipline, syntax and operational and static semantics for MIL, and concludes with the main result of the language.




Fig. 1. The MIL architecture.

λ/∈Λ



Lock discipline
Fig. 2. The lock discipline.

We provide two distinct access privileges to shared tuples: read-only and read- write, the latter mediated by locks. A standard test and set lock instruction is used to obtain a lock, thus allowing a thread to enter a critical region. Threads read and write from the shared heap via conventional load and store instructions. The policy for the usage of locks (enforced by the type system) is depicted in Figure 2 (cf. Theorem 2.1), where λ denotes a singleton lock type and Λ the set of locks held by the thread (the thread’s permission). Specifically, the lock discipline enforces that:
before lock creation, λ is not a known lock;
before test and set lock, the thread does not hold the lock;
before accessing the heap, the thread holds the lock (the thread has entered a critical region);
unlocking can happen only when the lock is held;
thread termination only without held locks.




permissions	Λ ::= λ1,..., λn
access mode	π ::= λ | ro
register ﬁles	 R ::= {r1 : v1,..., rR : vR} processor		p ::= ⟨R; Λ; I⟩ processors array	P ::= {1: p1,..., N: pN}
thread pool	T  ::=  {⟨l1, R1⟩,..., ⟨ln, Rn⟩}
heap values	h ::= ⟨v1 ... vn⟩π  | τ{I}
heaps	H ::= {l1 : h1,..., ln : hn}
states	S ::= ⟨H; T ; P⟩ | halt

Fig. 4. Abstract machine.

Syntax
The syntax of our language is generated by the grammar in Figures 3, 4, and 9. We rely on a set of heap labels ranged over by l, a set of type variables ranged over by α and β, and a disjoint set of singleton lock types ranged over by λ.
Most of the machine instructions, presented in Figure 3, are standard in assembly languages. Instructions are organised in sequences, ending in jump or in done. Instruction done frees the processor to execute another thread waiting in the thread pool. Our threads are cooperative, meaning that each thread must explicitly release the processor (using the done instruction).
Memory tuples are created locally, directly at processor’s registers using the new



∀i.P (i) = ⟨ ;  ; done⟩
⟨ ; ∅; P⟩→ halt
P (i) = ⟨ ;  ; done⟩	H(l) = ∀[ ].(  requires Λ){I}


⟨H; T  {⟨l, R⟩}; P⟩→ ⟨H; T ; P{i : ⟨R; Λ; I⟩}⟩
(R-halt) (R-schedule)

P (i) = ⟨R;Λ  Λ'; (fork v; I)⟩
Rˆ(v) = l	H(l) = ∀[ ].( requires Λ){ }



⟨H; T ; P⟩→ ⟨H; T ∪ {⟨l, R⟩}; P{i : ⟨R; Λ'; I⟩}⟩
(R-fork)


Fig. 5. Operational semantics (thread pool).
instruction. To share memory, tuples are transferred to the heap using the share instruction, according to a chosen access policy: read-only or read-write (in which case it must be guarded by a lock).
The abstract machine, generated by the grammar in Figure 4, is parametric on the number of available processors, N, and on the number of registers per proces- sor, R. An abstract machine can be in two possible states: halted or running. A running machine comprises a heap, a thread pool, and an array of processors of fixed length N. Heaps are maps from labels into heap values that may be tuples or code blocks. Tuples are vectors of mutable values protected by some lock λ, or else of constant values (identified by tag ro). Code blocks comprise a signature and a body. The signature of a code block describes the type of the registers and the locks that must be held by the thread when jumping to the code block. The body is a sequence of instructions to be executed by a processor.
A thread pool is a multiset of pairs, each of which contains the address (i.e., a label) of a code block and a register file. A processor array contains N processors, each of which is composed of a register file, a set of locks (the locks held by the thread running at the processor), and a sequence of instructions (the instructions that remain to execute).

Operational Semantics
The operational semantics is presented in Figures 5 to 8. The run pool is man- aged by the rules in Figure 5. Rule R-halt stops the machine when it finds an empty thread pool and all processors idle, changing the machine state to halt. Oth- erwise, if there is an idle processor and a thread waiting in the pool, then rule R-schedule assigns the thread to the idle processor. Rule R-fork places a new thread in the pool; the permissions of the thread are split in two—those required by the forked code, and the remaining ones—the thread keeps the latter set.
Operational semantics concerning locks are depicted in Figure 6. The instruction newLock creates a new lock ρ ready to be acquired, whose scope is the rest of the code block. A tuple ⟨0⟩ρ, representing the value of the lock, is allocated in the heap and register r is made to point it. The lock value is within a uni-dimensional tuple because the machine provides for tuple allocation only; lock ρ is used for type safety purposes (just like all other singleton types).  The test and set lock



P (i) = ⟨R; Λ; (λ, r := newLock; I)⟩	l /∈ dom(H)	ρ fresh


⟨H; T ; P⟩→ ⟨H{l : ⟨0⟩ρ}; T ; P{i : ⟨R{r : l}; Λ; I[ρ/λ]⟩}⟩
(R-newLock)

P (i) = ⟨R; Λ; (r := testSetLock v; I)⟩	Rˆ(v) = l	H(l) = ⟨0⟩λ	(	0)

⟨H; T ; P⟩→ ⟨H{l : ⟨-1⟩λ}; T ; P{i : ⟨R{r : 0};Λ  {λ}; I⟩}⟩
P (i) = ⟨R; Λ; (r := testSetLock v; I)⟩	H(Rˆ(v)) = ⟨-1⟩λ


⟨H; T ; P⟩→ ⟨H; T ; P{i : ⟨R{r : -1}; Λ; I⟩}⟩
R-tsl

(R-tsl -1)

P (i) = ⟨R;Λ  {λ}; (unlock v; I)⟩	Rˆ(v) = l	H(l) = ⟨ ⟩λ	(	)


⟨H; T ; P⟩→ ⟨H{l : ⟨0⟩λ}; T ; P{i : ⟨R; Λ; I⟩}⟩
R-unlock


Fig. 6. Operational semantics (locks).



P (i) = ⟨R; Λ; (r := new n; I)⟩	|→0| = n


⟨H; T ; P⟩→ ⟨H; T ; P{i : ⟨R{r : ⟨→0⟩}; Λ; I⟩}⟩
P (i) = ⟨R; Λ; (share r a; I)⟩	R(r) = ⟨→v⟩
l /∈ dom(H)	π is λ when a = guarded by λ else ro

⟨H; T ; P⟩→ ⟨H{l : ⟨→v⟩π}; T ; P{i : ⟨R{r : l}; Λ; I⟩}⟩
(R-new)



(R-share)

P (i) = ⟨R; Λ; (r := v[n]; I)⟩	H(Rˆ(v)) = ⟨v1..vn..vn+m⟩π	π ∈ {ro}∪ Λ
⟨H; T ; P⟩→ ⟨H; T ; P{i : ⟨R{r : vn}; Λ; I⟩}⟩
(R-loadH)

P (i) = ⟨R; Λ; (r := r'[n]; I)⟩	R(r') = ⟨v1..vn..vn+m⟩


⟨H; T ; P⟩→ ⟨H; T ; P{i : ⟨R{r : vn}; Λ; I⟩}⟩
(R-loadL)

P (i) = ⟨R; Λ; (r[n] := v; I)⟩
Rˆ(v) /= ⟨ ⟩ R(r) = l  H(l) = ⟨v1..vn..vn+m⟩λ λ ∈ Λ



⟨H; T ; P⟩→ ⟨H{l : ⟨v1.. Rˆ(v)..vn+m⟩λ}; T ; P{i : ⟨R; Λ; I⟩}⟩
(R-storeH)
P (i) = ⟨R; Λ; (r[n] := r'; I)⟩	R(r') /= ⟨ ⟩	R(r) = ⟨v1..vn..vn+m⟩
⟨H; T ; P⟩→ ⟨H; T ; P{i : ⟨R{r : ⟨v1..R(r')..vn+m⟩}; Λ; I⟩}⟩
(R-storeL)


Fig. 7. Operational semantics (memory).


instruction, present in many machines designed for multi-threading, is an atomic operation that loads the contents of a word into a register and then stores another value in that word. When a testSetLock is applied to an unlocked state, the type variable λ is added to the permissions of the processor and its value becomes ⟨-1⟩λ. Locks are waved using instruction unlock, as long as the thread holds the lock.
Rules related to memory manipulation are described in Figure 7. They rely on the evaluation function Rˆ that looks for values in registers, in the pack constructor, and in the application of universal types.




P (i) = ⟨R; Λ; jump v⟩	H(Rˆ(v)) = {I}


⟨H; T ; P⟩→ ⟨H; T ; P{i : ⟨R; Λ; I⟩}⟩

(R-jump)

P (i) = ⟨R; Λ; (r := v; I)⟩	Rˆ(v) /= ⟨ ⟩
(R-move)



⟨H; T ; P⟩→ ⟨H; T ; P{i : ⟨R{r : Rˆ(v)}; Λ; I⟩}⟩
P (i) = ⟨R; Λ; (r := r' + v; I)⟩


⟨H; T ; P⟩→ ⟨H; T ; P{i : ⟨R{r : R(r')+ Rˆ(v)}; Λ; I⟩}⟩
P (i) = ⟨R; Λ; (if r = v jump v'; )⟩	R(r) = v	H(Rˆ(v')) = {I}	(

(R-arith)

)


⟨H; T ; P⟩→ ⟨H; T ; P{i : ⟨R; Λ; I⟩}⟩
P (i) = ⟨R; Λ; (if r = v jump ; I)⟩	R(r) /= v


⟨H; T ; P⟩→ ⟨H; T ; {i : ⟨R; Λ; I⟩}⟩
R-branchT
(R-branchF)

P (i) = ⟨R; Λ; (ω, r := unpack v; I)⟩	Rˆ(v) = pack τ, v' as	(	)


⟨H; T ; P⟩→ ⟨H; T ; P{i : ⟨R{r : v'}; Λ; I[τ/ω]⟩}⟩
R-unpack






Rˆ(v
Fig. 8. Operational semantics (control flow).


R(v)	if v is a register
pack τ, R(v') as τ'	if v is pack τ, v' as τ'
Rˆ(v')[τ ]	if v is v'[τ ]
⎪⎩v	otherwise

Rule R-new creates a new tuple in register r, local to some processor, of a given length n; its values are all initialised to zero. Sharing a tuple means transferring it from the processor’s local memory into the heap. After sharing the tuple, reg- ister r records the fresh location l where the tuple is stored. Depending on the access method, the tuple may be protected by a lock λ, or tagged as read-only (rule R-share). Values may be loaded from a tuple if the tuple is local, if the tuple is shared as a constant, or if the lock guarding the shared tuple is held by the processor. Values can be stored in a tuple when the tuple is held in a register, or the tuple is in shared memory and the lock that guards the tuple is among the processor’s permissions.
The transition rules for control flow, illustrated in Figure 8, are straightfor- ward [25].

Type Discipline
The syntax of types is depicted in Figure 9. A type of the form ⟨→τ ⟩π describes a heap allocated tuple: shared and protected by a lock λ if π is λ, or shared and read-only if π is ro (cf. Figure 4). A type ⟨→τ ⟩ describes a tuple directly created in a register. A type of the form ∀[ω→ ].(Γ requires Λ) describes a code block: a
thread jumping into such a block must instantiate all the universal variables ω→
(type variables α or singleton lock types λ), it must also hold a register file type Γ,


types	τ ::= int | ⟨→τ ⟩π | ⟨→τ ⟩ | ∀[ω→ ].(Γ requires Λ) |
∃ω.τ | μα.τ | λ | α
type variable or lock	ω ::= α | λ
register ﬁle types	Γ ::= r1 : τ1,..., rn : τn
typing environment	Ψ ::= ∅ | Ψ,l : τ | Ψ,λ :: Lock | Ψ,α :: TyVar

Fig. 9. Types.
as well as the locks in Λ. The singleton lock type λ is used to represent the type of a lock value in the heap.
Types ∃α.τ are conventional existential types. With type ∃λ.τ we are able to existentially quantify over lock types, following [8]. The scope of a lock extends until the end of the code block that creates it. However, there are situations in which we need to use a lock outside its scope. For instance, in Section 3 we present a MIL implementation of Hoare-like monitors, associating a lock with each monitor. The implementation we present allocates tuples that must be protected by the monitor’s lock, which is out of scope. (The scope of the lock is the code block that creates the monitor.) In fact, for sharing a tuple protected by the monitor’s lock, it is sufficient to know that such a lock exists. Our implementation stores the lock in an existential lock value and uses the abstracted singleton lock type when protecting tuples, after unpacking.
As usual, the recursive type is defined by μα.τ . We take an equi-recursive view of types, not distinguishing between a type μα.τ and its unfolding τ [μα.τ/λ]. Recursive, universal, and existential type constructors introduce bindings on type variables and singleton lock variables as usual. ftv(τ ) denotes the set of free type variables in τ , and flt(τ ) the set of free singleton lock types in τ .
The type system is presented in Figures 10 to 13. Instructions are checked against a typing environment Ψ (mapping heap labels to types, type variables to kind TyVar, and singleton lock types to kind Lock), a register file type Γ holding the current types of the registers, and a set Λ of lock variables: the permission of the code block.
Typing rules for values are illustrated in Figure 10. Heap values are distinguished from operands (that include registers as well) by the form of the sequent. A formula Γ <: Γ' allows forgetting registers in the register file type, and is particularly useful in jump instructions where we want the type of the target code block to be more general (ask for less registers) than those active in the current code [22]. Rule T-type makes sure types are well-formed, that is do not include type variables or singleton lock types not in scope. The rules for value application and for pack values, T-valApp and T-pack, work both with type variables α and singleton lock types λ, taking advantage of the fact that substitution τ'[τ/ω] is defined only when τ is not a singleton lock type and ω is a type variable, or when both τ and ω are singleton lock types. In either case, type τ must be well-formed.
Rule T-done in Figure 11 requires that locks must have been released prior to



	∅▶ τi	
▶ r1 : τ1,..., rn+m : τn+m <: r1 : τ1,..., rn : τn
▶ Γ <: Γ'
(S-regFile)

▶ τ <: τ
▶ ∀[ω→ ].(Γ requires Λ) <: ∀[ω→ ].(Γ' requires Λ)	(S-reflex,S-code)

α ∈ ftv(τ ) ⇒ α :: TyVar ∈ Ψ	λ ∈ flt(τ ) ⇒ α :: Lock ∈ Ψ


Ψ ▶ τ
(T-type)

▶ τ' <: τ	Ψ	:	Ψ	:
(	,	,	)



Ψ,l : τ' ▶ l : τ
▶ n int
▶ b λ
T-label T-int T-lock

Ψ ▶ τ	Ψ ▶ v : τ'[τ/ω]	ω ∈/ τ, Ψ	τ' /= ⟨ ⟩
Ψ ▶ pack τ, v as ∃ω.τ' : ∃ω.τ'
(T-pack)

Ψ ▶ τ	Ψ; Γ ▶ v : ∀[νω→ ].(Γ' requires Λ)
Ψ; Γ ▶ v[τ ]: ∀[ω→ ].(Γ'[τ/ν] requires Λ[τ/ν])
Ψ ▶ v : τ


Ψ; Γ ▶ v : τ
Ψ; Γ
▶ r : Γ(r)

(T-valApp,T-val,T-reg)


Fig. 10. Typing rules for values	and for operands	.


Ψ; Γ; ∅▶ done	(T-done)

∀i.Γ(ri) /= ⟨ ⟩	Ψ; Γ ▶ v : ∀[].(Γ requires Λ)	Ψ; Γ; Λ' ▶ I
Ψ; Γ; Λ  Λ' ▶ fork v; I
Ψ,λ :: Lock; Γ{r : ⟨λ⟩λ};Λ ▶ I[λ/ρ]	λ /∈ Ψ, Γ, Λ,I	(
(T-fork)

)

Ψ; Γ; Λ ▶ ρ, r := newLock; I
T-newLock

Ψ; Γ ▶ v : ⟨λ⟩λ	Ψ; Γ{r : λ};Λ ▶ I	λ /∈ Λ Ψ; Γ; Λ ▶ r := testSetLock v; I
Ψ; Γ ▶ v : ⟨λ⟩λ	Ψ; Γ; Λ ▶ I
(T-tsl)

(	)



Ψ; Γ; Λ  {λ}▶ unlock v; I
Ψ; Γ ▶ r : λ	Ψ; Γ ▶ v : ∀[].(Γ requires (Λ  {λ}))	Ψ; Γ; Λ ▶ I
Ψ; Γ; Λ ▶ if r = 0 jump v; I
T-unlock
(T-critical)



Fig. 11. Typing rules for instructions (thread pool and locks)	.

terminating the thread. Rule T-fork splits permissions into sets Λ and Λ': the former is transferred to the forked thread according to the permissions required by the target code block, the latter remains with the current thread.
Rule T-newLock assigns a lock type ⟨λ⟩λ to the register. The new singleton
lock type is recorded in Ψ, so that it may be used in the rest of the instructions I. Rules T-tsl requires that the value under test holds a lock, disallowing testing a lock already held by the thread. Rule T-unlock makes sure that only held locks are unlocked. Finally, rule T-critical ensures that the current thread holds the
exact number of locks required by the target code block and adds the lock under test to the set of locks of the thread.  A thread is guaranteed to hold the lock



Ψ; Γ{r : ⟨i→nt⟩};Λ ▶ I	|i→nt| = n
Ψ; Γ; Λ ▶ r := new n; I
(T-new)

Ψ ▶ λ	Ψ; Γ ▶ r : ⟨→τ ⟩	Ψ; Γ{r : ⟨→τ ⟩λ};Λ ▶ I	π is λ when a = guarded by λ else ro
Ψ; Γ; Λ ▶ share r a; I
(T-share)

Ψ; Γ ▶ v : ⟨τ1..τn+m⟩π	Ψ; Γ{r : τn};Λ ▶ I	τn /= λ	π ∈ Λ ∪ {ro}


Ψ; Γ; Λ ▶ r := v[n]; I
(T-loadH)

Ψ; Γ ▶ v : ⟨τ1..τn+m⟩	Ψ; Γ{r : τn}; Λ ▶ I	τn /= λ
Ψ; Γ; Λ ▶ r := v[n]; I
(T-loadL)

Ψ; Γ ▶ v : τn Ψ; Γ ▶ r : ⟨τ1..τn+m⟩λ Ψ; Γ{r : ⟨τ1..τn+m⟩};Λ ▶ I  τn /= λ, ⟨ ⟩ λ ∈ Λ Ψ; Γ; Λ ▶ r[n] := v; I
(T-storeH)
Ψ; Γ ▶ v : τ	Ψ; Γ ▶ r : ⟨τ1..τn..τn+m⟩	Ψ; Γ{r : ⟨τ1..τ..τn+m⟩};Λ ▶ I	τ /= λ, ⟨ ⟩
Ψ; Γ; Λ ▶ r[n] := v; I


Ψ; Γ ▶ v : τ	Ψ; Γ{r : τ};Λ ▶ I	τ /= ⟨ ⟩


Ψ; Γ; Λ ▶ r := v; I
(T-storeL)
(T-move)

Ψ; Γ ▶ r' : int	Ψ; Γ ▶ v : int	Ψ; Γ{r : int};Λ ▶ I


Ψ; Γ; Λ ▶ r := r' + v; I
(T-arith)

Ψ; Γ ▶ v : ∃ω.τ	Ψ,ω : : kind(ω); Γ{r : τ};Λ ▶ I	ω /∈ Ψ, Γ, Λ Ψ; Γ; Λ ▶ ω, r := unpack v; I
Ψ; Γ ▶ r : int	Ψ; Γ ▶ v : ∀[].(Γ requires Λ)	Ψ; Γ; Λ ▶ I
Ψ; Γ; Λ ▶ if r = 0 jump v; I
Ψ; Γ ▶ v : ∀[].(Γ requires Λ) Ψ; Γ; Λ ▶ jump v
(T-unpack) (T-branch) (T-jump)



Fig. 12. Typing rules for instructions (memory and control flow)	.


only after (conditionally) jumping to a critical region. A previous test and set lock instructions may have obtained the lock, but as far as the type system goes, the thread holds the lock only after the conditional jump.
The typing rules for memory and control flow are depicted in Figure 12. The rule for sharing a mutable tuple under lock λ makes sure that the lock is in lexical scope (Ψ ▶ λ). Operations for loading from and for storing into tuples require that the processor hold the right permissions (the locks for the tuples it reads from or writes to). Local tuples require no permission for its manipulation, however, special care is taken to disallow its duplications or aliasing, via the various τ /= ⟨ ⟩ in the
rules. Rule T-unpack unpacks either a conventional or a lock existential type.
A new entry α :: TyVar or ω :: Lock is added to Ψ, according to the nature of ω. The new type variable or singleton lock type may then be used in the rest of the instructions I.



∀i.Ψ ▶ Γ(ri)	Ψ ▶ R(ri): Γ(ri) Ψ ▶ R : Γ 

(reg file,	)

∀i.Ψ ▶ P (i)	Ψ ▶ R : Γ	Ψ; Γ; Λ ▶ I

	
Ψ ▶ P	Ψ ▶ ⟨R; Λ; I⟩
(processors,	)

∀i.Ψ ▶ li : ∀[ ].(Γi requires )	Ψ ▶ Ri : Γi
Ψ ▶ {⟨l1, R1⟩,..., ⟨ln, Rn⟩}
(thread pool,	)

Ψ, ω→ : : kind(ω→ ); Γ; Λ ▶ I
Ψ ▶ ∀[ω→ ].(Γ requires Λ): τ
∀i.Ψ ▶ vi : τi	Ψ ▶ ⟨→τ ⟩π


Ψ ▶ ⟨→v⟩π : ⟨→τ ⟩π
(heap value,	)



▶ halt
∀l.Ψ ▶ H(l): Ψ(l)


Ψ ▶ H
Ψ ▶ H	Ψ ▶ T	Ψ ▶ P
▶ ⟨H; T ; P⟩
(heap,	)

(state,	)


Fig. 13. Typing rules for machine states.



The rules for typing machine states are illustrated in Figure 13. The rules for code blocks in the heap records in Ψ the type variables and the singleton lock types present in the abstraction, so that they may be used in the rest of the instructions I. For an extended example of MIL in action, refer to Section 3 and to refer-
ences [19,30].






Types against races
We split the results in three categories: the standard “well-typed machines do not get stuck” (which we omit altogether), the lock discipline, and races. The lock discipline is embodied in the following theorem (cf. Figure 2).
Theorem 2.1 (Lock discipline) Let Ψ ▶ H and Ψ ▶ ⟨R; Λ; (ι; )⟩.
If ι is λ,  := newLock, then λ /∈ dom(Ψ).
If ι is := testSetLock v and H(Rˆ(v)) = ⟨ ⟩λ, then λ /∈ Λ.
If ι is v[ ] :=  or := v[ ], and H(Rˆ(v)) = ⟨ ⟩λ, then λ ∈ Λ.
If ι is unlock v and H(Rˆ(v)) = ⟨ ⟩λ, then λ ∈ Λ.
If ι is done, then Λ = ∅.
For races we follow Flanagan and Abadi [8]. We start by defining the set of permissions of a machine state, by gathering the permissions of the running threads with those in the run pool, and with the set of unlocked locks in the heap. Remember that a permission is a set of locks, denoted by Λ.

Definition 2.2 [State permissions.]
LP = {Λ | i ∈ [1..R] and P (i) = ⟨ ; Λ; ⟩}
LT = {Λ | ⟨l, ⟩∈ T and H(l) = ∀[ ].( requires Λ){ }} LH = {{λ | l ∈ dom(H) and H(l) = ⟨0⟩λ}}
L⟨H;T ;P⟩ = LP ∪ LT ∪ LH
2L
halt

We are interested only in mutual exclusive states, that is, states whose permis- sions do not “overlap.” Also, we say that a state has a race condition if it contains two processors trying to access the heap at the same shared location.
Definition 2.3 Mutual exclusive states. halt is mutual exclusive; S /= halt is
mutual exclusive when i /= j implies Λi ∩ Λj = ∅, for all Λi, Λj ∈ LS.
Accessing the shared heap. A processor of the form ⟨R; ; (ι; )⟩ accesses the shared heap H at location l, if ι is of the form v[ ] :=  or of the form  := v[ ], l = Rˆ(v), and H(l) = ⟨ ⟩λ, for some λ.
Race condition. A state S has a race condition if S = ⟨H; ; P⟩ and there exist i and j distinct such that P (i) and P (j) both access the shared heap H at some location l.

Notice that the definition above allows two threads to access the heap at the same read-only location, since λ in ⟨ ⟩λ denotes a lock (and not ro). We can show that typable mutual exclusive states do not have races.
Theorem 2.4 If S is a mutual exclusive typable state, then S does not have a race condition.
Also, typability and mutual exclusion are two properties of states preserved by reduction.
Theorem 2.5 Let S → S'. Then,
If ▶ S, then ▶ S';
If S is mutual exclusive, then so is S'.
The proof of each result is by a conventional case analysis on the reduction rules. For the second, we note that the rules that manipulate locks (R-fork, R-newLock, R-tsl 0, and R-unlock) all preserve the disjointedness of state permissions.
Corollary 2.6 (Types against races) If S is a mutual exclusive typable state and S →∗ S', then S' does not have a race condition.

An Unbounded Buffer Monitor in MIL


unbounded buffer: monitor begin
buffer : Queue {of Element} nonEmpty: condition procedure append(m: Element) begin
buffer . enqueue(m) nonEmpty.signal
end append
procedure remove(c: Continuation)
begin
if buffer . isEmpty() then nonEmpty.wait
fork c( buffer . dequeue())
end remove
buffer = createQueue()
end unbounded buffer

Fig. 14. An Hoare-style unbounded buffer monitor.
This section describes an Hoare-style implementation of an unbounded buffer mon- itor. The buffer is accessible to programs running in parallel: producers update the buffer by appending a new element at the end; consumers update the buffer by removing the first element. Figure 14 describes the monitor we are interested in.
Whenever the buffer is empty, as in the initial state of the monitor, the operation that removes the first element from the queue is undefined. We make sure that the consumer waits until the producer has made the queue nonempty. The queue is assumed to be infinitely large, thus there is always room in the queue for producers to append new elements. For this reason, and contrasting with removing from the buffer, appending does not block.
Our monitor exports three operations—create, append, and remove—as MIL code, with the following signatures,
createMonitor ∀[Element] (r1 : CreateContinuation(Element)) append ∀[Element] (r1: Monitor(Element), r2 : Element)
remove ∀[Element] (r1 : Monitor(Element), r2 : RemoveContinuation(Element))
where Element is a given type, the type of the elements in the monitor, and Monitor is an abstract type. By using continuation-passing style [1], operations createMonitor and remove also receive a closure containing the continuation. In either closure, the continuation code expects an environment of type α in r1. The continuation of the create procedure, however, expects in r2 the newly created monitor, whereas that for the remove procedure expects an element of the buffer.
def CreateContinuation(Element) = ∃α.⟨(r1 : α, r2 : Monitor(Element)), α⟩ro
def RemoveContinuation(Element) = ∃α.⟨(r1: α, r2 : Element), α⟩ro
We illustrate the usage of monitors with a traditional producer/consumer ex- ample. Code block main creates a monitor for a buffer of integers and starts three threads (code block producerConsumer): a producer (code block producer) that appends integers to the buffer, and two identical consumers defined by code block consumer. The element removed from the buffer is delivered at code block consumeNext that “consumes” the element and asks for another one by jumping back to the consumer code block.
main() {


−− create the base (empty) environment
r2 := new 0
share r2 read-only −− ⟨⟩ro
−− create the closure
r1 := new 2
r1 [1] := producerConsumer −− set the continuation
r1 [2] := r2	−− set the environment
share r1 read-only −− ⟨(r1:⟨⟩ro , r2 :Monitor(int )), ⟨⟩ro ⟩
r1 := pack ⟨⟩ro , r1 as CreateContinuation( int )
jump createMonitor[ int ]
}
producerConsumer(r1:⟨⟩ro ,  r2 :Monitor(int ))  {
−− the environment is the monitor
r1 := r2
fork producer fork consumer fork consumer done
}
consumer(r1:Monitor(int)) {
−− create the closure
r2 := new 2
r2 [1] := consumeNext −− set the continuation
r2 [2] := r1	−− the environment is the monitor
share r2 read-only	−− ⟨(r1:Monitor(int), r2 : int ), Monitor(int)⟩
r2 := pack Monitor(int ), r2 as RemoveContinuation(int)
fork remove[int ]
done
}
consumeNext(r1:Monitor(int), r2 : int ) {
−− process the element in r2
jump consumer
}
producer(r1 :Monitor(int )) {
−− set the element
r2 := 2
−− produce the element
fork append[int ]
jump producer
}

The three monitor operations described above is all we need in order to compile
the π-calculus in Section 5. The rest of this section is organised in three parts. The first introduces the three monitor operations. The second presents the wait and signal operations, and the last the queues of generic elements, used to implement both the buffer and the monitor’s condition.



The monitor
When implementing monitors in MIL, we associate a lock with each monitor to ensure mutual exclusion for the monitor’s operations. Each operation needs to acquire the monitor’s lock before executing its body and release the lock upon exit. Monitor’s data is stored in a tuple containing the references for both the buffer queue and the nonEmpty condition.
def Monitor(Element) = ∃λ.UnpackedMonitor(λ,Element)
def UnpackedMonitor(λ,Element) = ⟨Queue(λ,Element),Condition(λ),⟨λ⟩λ⟩ro
def Condition(λ) = Queue(λ,WaitContinuation(λ))

For creating the monitor we generate a lock, a buffer queue, and a condition queue. After that we assemble a tuple with the monitor’s local data and pack it together with the monitor’s lock. The resulting value is a monitor of type Monitor(Element), with Element being the type of the elements to store in the monitor’s buffer.
Code block createMonitor is the entry point for the creation of a monitor, expecting a continuation in register r1 of type CreateContinuation(Element), defined above. Operation
createMonitor is divided into three code blocks, since we adhere to the CPS style. The first code block creates the monitor’s lock, allocates an environment for storing intermediate data, recording the operation continuation closure and the monitor’s lock, and finally issues the creation of the buffer queue.
createMonitor ∀[Element] (r1 :CreateContinuation(Element)) {
λ, r3 := newLock −− create the lock of the monitor
−− create the environment for createQueue
r2 := new 3 −− ⟨CreateContinuation(Element),⟨λ⟩λ,Queue(λ,Element)⟩
r2 [1] := r1 −− store the continuation closure
r2 [2] := r3 −− store the monitor’s lock
r3 := createMonitorCondition[ λ,Element] −− set the continuation of createQueue
jump createQueue[λ,Element,MonitorEnv(λ,Element)]
}
def MonitorEnv(λ,Element) = ⟨CreateContinuation(Element),⟨λ⟩λ,Queue(λ,Element)⟩

The second code block (createMonitorCondition) stores the buffer queue (just created and passed in r1) in the intermediate environment, jumping to the creation of the queue supporting the non empty condition.
createMonitorCondition ∀[λ,Element] (r1 :Queue(λ,Element), r2:MonitorEnv(λ,Element)) {
r2 [3] := r1	−− store the buffer in the internal environment
r3 := initMonitor [ λ,Element] −− set the continuation of createCondition
jump createQueue[λ,WaitContinuation(λ),MonitorEnv2(λ,Element)]
}
def MonitorEnv2(λ,Element) = ⟨CreateContinuation(Element),⟨λ⟩λ,Queue(λ,Element)⟩

Code block initMonitor implements the third and final stage of the monitor con- struction by allocating and initialising the monitor’s data: the buffer queue, the condition, and the monitor’s lock. Then the thread processing this code block un- packs the closure and passes the new monitor (in register r1) to the continuation.
initMonitor ∀[λ,Element] (r1 :Condition(λ),r2 :MonitorEnv2(λ,Element)) {
−− allocate the monitor
r3 := new 3
r3 [2] := r1	−− store the condition variable
r1 := r2 [3]	−− load the buffer from the internal environment
r3 [1] := r1	−− store the buffer in the monitor
r1 := r2 [2]	−− load the lock of the monitor
r3 [3] := r1	−− store the lock
share r3 read-only −− ⟨Queue(λ,Element),Condition(λ),⟨λ⟩λ⟩
r4 := r2 [1]	−− load the closure
α,r4 := unpack r4  −− unpack the closure
r1 := r4 [2]	−− load the environment
r4 := r4 [1]	−− load the continuation
r2 := pack λ, r3 as Monitor(Element) −− abstract the monitor’s lock
jump r4	−− execute the continuation
}

The monitor operation append places one element in the buffer and signals the non empty condition variable. The operation accepts elements of type Element in register r2, and a monitor of type Monitor(Element) in register r1. The operation starts by unpacking the monitor for accessing the monitor’s lock. Code block appendAcquire then spin-locks to acquire exclusive access to the lock, jumping to code block appendEnqueue on success. This pattern is repeated for all monitor procedures.
append ∀[Element] (r1:Monitor(Element), r2 :Element) {
λ,r1 := unpack r1	−− unpack the monitor’s lock
r3 := r1 [3]	−− load the lock
jump appendAcquire[λ,Element]	−− try to acquire exclusive access
}
appendAcquire ∀[λ,Element] (r1 :UnpackedMonitor(λ,Element),r2:Element,r3:⟨λ⟩λ) {
r4 := testSetLock r3	−− try to acquire the lock if r4 = 0 jump appendEnqueue[λ,Element] −− lock acquired, continue jump appendAcquire[λ,Element]	−− otherwise, repeat
}
The two following code blocks implement the body of the append procedure (vide
Figure 14) by enqueuing the element in the buffer (code block appendAcquire), and by signalling the non empty condition (code block appendSignal), possibly awakening a pending consumer.
appendEnqueue ∀[λ,Element] (r1:UnpackedMonitor(λ,Element),r2:Element) requires (λ) {
r3 := new 2
r3 [1] := appendSignal[λ,Element] −− set the continuation to the signal operation
r3 [2] := r1	−− store the environment
share r3 read-only  −− ⟨(r1:UnpackedMonitor(λ,Element)) requires (λ),UnpackedMonitor(λ,Element)⟩
r3 := pack UnpackedMonitor(λ,Element),r3 as EnqueueContinuation(λ)
r1 := r1 [1]	−− load the buffer
jump enqueue[λ,Element]
}
appendSignal ∀[λ,Element] (r1 :UnpackedMonitor(λ,Element)) requires (λ) {
r2 := r1 [2] −− load the condition variable r1 := r1 [3] −− load the monitor’s lock jump signal [ λ]
}
Operation remove takes an element from the buffer of a monitor (in register r1)
and transfers it to a closure of type RemoveContinuation(Element) expected in register r2.
We list the code blocks embodying method remove. Likewise operation append, the first code block unpacks the monitor’s lock, and jumps to removeAcquire. The second code block performs a spin-lock to acquire exclusive access to the monitor’s lock, continuing to code block testCondition on success.
remove ∀[Element] (r1 :Monitor(Element),r2:RemoveContinuation(Element)) {
λ, r1 := unpack r1 −− unpack the monitor’s lock
r3 := r1 [3]	−− load the lock
jump removeAcquire[λ,Element] −− acquire the monitor’s lock
}
removeAcquire ∀[λ,Element] (r1 :UnpackedMonitor(λ,Element),r2:RemoveContinuation(Element),r3:⟨λ⟩λ) {
r4 := testSetLock r3
if r4 = 0 jump testCondition[λ,Element]
jump removeAcquire[λ,Element]
}
The implementation of the procedure body (vide Figure 14): checks for available elements in the buffer (code block testCondition ); if the buffer is empty, it suspends itself and waits for a non empty buffer ( if r5 = 0 jump wait[λ]); otherwise, it dequeues

the element (code block exec) and applies the continuation to the dequeued element (code block execRelease). Notice that execRelease frees the monitor’s lock before entering the consumer’s continuation.
testCondition ∀[λ,Element] (r1 :UnpackedMonitor(λ,Element),r2:RemoveContinuation(Element),
r3 : ⟨λ⟩λ) requires (λ) {
−− create an environment for the continuation
r4 := new 2
r4 [1] := r2 −− store the closure of operation ’ remove’
r4 [2] := r1 −− store the unpacked monitor
share r4 read-only −− ⟨RemoveContinuation(Element),UnpackedMonitor(λ,Element)⟩
r2 := r1 [2]  −− load the condition
r5 := r1 [1]  −− load the buffer
r5 := r5 [2]  −− load the buffer ’ s size
r1 := r3	−− set the lock of the monitor for the wait operation
−− create the closure for wait
r3 := new 2
r3 [1] := exec[λ,Element] −− set the continuation of wait
r3 [2] := r4	−− store the environment
share r3 read-only −− ⟨(r1:RemvEnv(λ,Element)) requires (λ),RemvEnv(λ,Element)⟩
r3 := pack RemvEnv(λ,Element),r3 as WaitContinuation(λ) if r5 = 0 jump wait[λ]	−− wait until an element arrives r1 := r4	 −− restore the environment jump exec[λ,Element]	 −− otherwise dequeue and exec
}

The environment storing remove internal data is of type
def RemvEnv(λ,Element) = ⟨RemoveContinuation(Element),UnpackedMonitor(λ,Element)⟩ro
The following code blocks dequeue an element from the buffer and deliver it to
the consumer.
exec ∀[λ,Element] (r1 :RemvEnv(λ,Element)) requires (λ) {
r2 := new 2
r2 [1] := execRelease[ λ,Element] r2 [2] := r1
share r2 read−only −− ⟨(r1:RemvEnv(λ,Element),r2:Element) requires(λ),RemvEnv(λ,Element)⟩
r2 := pack RemvEnv(λ,Element),r2 as DequeueContinuation(λ,Element)
r1 := r1 [2] −− load the monitor r1 := r1 [1] −− load the buffer jump dequeue[λ,Element]
}
execRelease ∀[λ,Element] (r1 :RemvEnv(λ,Element), r2:Element) requires (λ) {
r4 := r1 [2]  −− load the monitor
r4 := r4 [3] −− load the monitor’s lock unlock r4	−− unlock the monitor’s lock r3 := r1 [1] −− load the continuation α,r3 := unpack r3 −− unpack the closure r1 := r3 [2] −− load the environment
r3 := r3 [1]  −− load the continuation
jump r3	−− jump to the continuation
}


Wait and Signal
We represent a condition variable in MIL as a (initially empty) queue of closures that are currently waiting on that condition. Manipulating the condition’s queue is through the usual operations wait and signal . A wait operation is issued from inside a monitor and causes the calling thread to suspend itself until a signal operation occurs. Waiting on a condition (in register r2) amounts to enqueuing the continua- tion of the wait operation (in register r3) in the condition’s queue. Notice that the

lock (in register r1) protecting the queue is the same lock used to enforce mutual exclusion access to the monitor operations. Also notice that the lock is released after enqueuing the continuation, allowing other threads to use the monitor, and that the thread terminates (vide code block release ).
def WaitContinuation(λ) = ∃α.⟨(r1 :α) requires (λ),α⟩ro

wait ∀[λ] (r1 : ⟨λ⟩λ,r2 :Condition(λ),r3 :WaitContinuation(λ)) requires (λ) {
−− closure for the release code block ( continuation after enqueue)
r4 := new 2
r4 [1] := release [ λ] r4 [2] := r1
share r4 read-only −− ⟨(r1:⟨λ⟩λ) requires (λ),⟨λ⟩λ⟩
r4 := pack ⟨λ⟩λ,r4 as WaitContinuation(λ)
r1 := r2 −− set the queue
r2 := r3 −− set the element to enqueue
r3 := r4 −− set the continuation
jump enqueue[λ,WaitContinuation(λ)]
}
release ∀[λ] (r1 : ⟨λ⟩λ) requires (λ) { unlock r1 −− release the monitor’ s lock done	−− terminate the thread
}
Code block signal , also issued from inside a monitor, causes exactly one of the
delayed threads to resume immediately. A signal operation must be followed directly by resumption of a delayed thread, without possibility of an intervening procedure call from a third thread. There is an implicit notion of an uninterrupted transfer of ownership that goes from the signalling thread that finishes to the delayed thread that resumes execution, which fits nicely in MIL’s lock discipline. The transmission of lock permission is carried out by jumping to the continuation closure without releasing the monitor’s lock. We implement O-J. Dahl’s variant [6] of the signal operation that should be used as the last operation of a monitor procedure.
The signal code block first checks if there are no delayed threads to signal, in which case it terminates. Otherwise, the thread dequeues a closure and proceeds to execute code block signalDequeue that continues the execution of the suspended thread.
signal ∀[λ] (r1 : ⟨λ⟩λ, r2 :Condition(λ)) requires (λ) {
r3 := r2 [2]	−− load the length of the queue if r3 = 0 jump release[ λ] −− no closures to signal , finish r1 := r2	−− set the queue of closure
r2 := new 2
r2 [1] := signalDequeue[α]
r2 [2] := 0	−− an empty environment
share r2 read-only	−− ⟨(r1:int,r2 :WaitContinuation(λ)) requires (λ), int ⟩
r2 := pack int , r2 as DequeueContinuation(λ,WaitContinuation(λ))
jump dequeue[λ,WaitContinuation(λ)]
}
signalDequeue ∀[λ] (r1 : int , r2 :WaitContinuation(λ)) requires (λ) {
α,r2 := unpack r2	−− unpack the suspended thread continuation and go
r3 := r2 [1]	−− the continuation
r1 := r2 [2]	−− the environment
jump r3
}



An implementation of queues



Fig. 15. Syntax of the π-calculus.

The buffer and the condition variable are implemented as queues. A queue of type
def Queue(λ,α)=⟨QueueImpl(λ,α),int⟩λ

describes unbounded queues of elements of type α, protected by lock λ. Queues are implemented as tuples protected by a lock λ that hold the implementation of type QueueImpl(λ,α) and an integer representing the length of the queue. The description of type QueueImpl(λ,α) as well as the code for operations on queues can be found in [19]. There are three operations on queues—creation, enqueuing, and dequeuing—with the following signatures:
createQueue ∀[λ,α,β] (r2 :α, r3 :( r1 :Queue(λ,α), r2:β))
enqueue ∀[λ,α](r1 :Queue(λ,α),r2:α,r3:EnqueueContinuation(λ)) requires (λ) dequeue ∀[λ,α] (r1 :Queue(λ,α), r2:DequeueContinuation(λ,α)) requires (λ)
For creating queues we provide operation createQueue that expects in register r2 the environment of any type α, and in register r3 a code block for passing the new queue (in register r1). Operation enqueue places the element present in register r2 at the end of the queue given in register r1. Afterwards, the thread executing this code block continues by unpacking and processing the closure in register r3 of type
def EnqueueContinuation(λ)=∃ α.⟨(r1:α) requires (λ),α⟩ro
Removing an element from the head of the queue (operation dequeue) that targets a queue in register r1 and delivers the removed element to the continuation present in register r2 of type
def DequeueContinuation(λ,α)=∃ β.⟨(r1:β,r2:α) requires (λ),β⟩ro
Both enqueue and dequeue operations as well as their continuations require exclusive access to the lock of the queue.

Source language: the π-calculus
Our starting point is the simple typed asynchronous π-calculus [3,15,28], equipped with integer values, generated by the syntax in Figure 15.
The syntax is divided into three categories: processes, values, and types. Values v
are either names or integer values. Names are ranged over by lower case Roman letters and are taken from a denumerable set. The vector notation is used to denote


Γ ▶ n: int	Γ ▶ x : T	Γ ▶ 0	(T-Int,T-Name,T-Nil)

Γ ▶ x(→y).P
Γ ▶!x(→y).P
Γ ▶ x : [T0 ... Ti]	Γ, y0 : T0,..., yi : Ti ▶ P
Γ ▶ x(→y).P
Γ ▶ x : [T→ ]	Γ ▶ vi : Ti	∀i ∈ I
Γ ▶ x⟨→v⟩
(T-Rep,T-In)

(T-Out)

Γ ▶ P	Γ ▶ P'
Γ,x : [T→ ] ▶ P
(	,	)

Γ ▶ P | P'
Γ ▶ (ν x : [T→ ]) P
T-Par T-Res


Fig. 16. Typing rules for the π-calculus.

a possibly empty sequence of symbols; for example →x stands for the sequence of names x1 ... xn with n ≥ 0.
Processes P comprise the inactive process 0; the output process x⟨→v⟩ that sends a sequence of values →v on channel x; the input process x(→y).P that receives a value via channel x and proceeds as P , after substituting →v for →y. The parallel composition process running concurrently P | Q; the restriction process (ν x : T ) P that creates a new channel definition local to process P ; and, finally, the replicated input process
!x(→y).P that represents an infinite number of active input processes x(→y).P running in parallel.
For types T , we have int representing integer values, and [T→ ] denoting a channel that can carry a sequence of values of types T→ . The operational semantics for the π-calculus is the standard and can be easily found in, e.g., [28].
Figure 16 presents a standard type system for the π-calculus. A typing Γ is a partial function of finite domain from names to types. We write dom(Γ) for the domain of Γ. When x /∈ dom(Γ) we write Γ,x : T for the typing Γ' such that dom(Γ') = dom(Γ) ∪ {x}, Γ'(x) = T , and Γ'(y) = Γ(y) for y /= x. Type judgements are of two forms: (a) Γ ▶ v : T means that value v has type T under the assumptions in typing Γ; and (b) Γ ▶ P asserts that process P is well typed regarding typing Γ. The typing rules are straightforward. Rule T-Int states that primitive values
are typed under the int type. The type of name is taken from the type environment
(Rule T-Name). The inactive process 0 is always well typed (Rule T-Nil). A repli- cated input process !x(→y).P is well typed if its non-replicated from is (Rule T-Rep). T-In says that the input process x(→y).P is well typed if the input channel x is a channel type and if continuation process P is also well typed in an environment ex- tended with the types for the parameters. The output process x⟨→v⟩ is well typed if x is a channel if its arguments are correctly typed, rule T-Out. The parallel process is well typed if each of its parts are, rule T-Par. Finally, the process (ν x : [T→ ]) P is well typed if, by adding the association between name x and type [T→ ] to Γ, the contained process P is well typed, rule T-Res.

Compiling π into MIL

This section presents a translation of the simply typed pi-calculus with integer values (described in Section 4) into the multithreaded intermediate language (described in Section 2). The translation is extremely simplified by using the unbounded buffer monitor (described in Section 3) to manage message queues. We first present the translation, then the main result of the translation—type preservation—, and finally discuss choices we made.




The translation function
The translation from the π-calculus into MIL comprises the translation T [[·]] of types, V→x[[· ] of values, and P[[· ] of programs (closed π-processes).
Types of the π-calculus have a direct representation in the supporting library, thus the translation is straightforward.


T [[int]] d=ef int
T [[[T→ ]]] d=ef Monitor(T	[[T→ ]])
Tseq[[T1 ... Tn]] = ⟨T [[T1]],..., T [[Tn
]]⟩ro


The integer type of the π-calculus is translated in the corresponding type of MIL. A π-channel is translated into an unbounded buffer monitor whose elements are read-only tuples of values: integer values or monitors for other channels.
The translation V→x[[· ] of values loads into register r3 a value from the environ- ment →x (addressed by register r1), or moves into the same register an integer literal.

V→x[[v]] d=ef	r3 := r1[i]	if v = xi
r3 := v	if v is an integer literal

The translation of a program P yields a heap, containing several code blocks, among which we find main.

P[[P ]] d=ef main(){E Γ(∅, ∅); I} H
where ⟨H, I⟩ = P$,$[[P ]]

Block main prepares an empty environment, E Γ(∅, ∅), for the top level process, which is then translated by P$,$[[P ]]. In all cases register r1 contains the current environment, the address of a read-only tuple containing the free names in the process.
Function E Γ(→x, →y) generates an instruction sequence that creates a new environ- ment as a copy of the current environment →x (in register r1 of type Tseq[[T→ ] where T→ are the types of →x) extended with environment →y in register r2 (of type Tseq[[T→ ']]),

leaving the newly created environment in register r1.

E Γ(→x, →y) d=ef (r := new |→x→y|
∀ 1 ≤ i ≤ |→x|	r4 := r1[i]
r3[i] := r4
∀ 1 ≤ j ≤ |→y|	r4 := r2[j]
r3[j + |→x|] := r4
share r3 read-only	−−Tseq[[Γ(→x→y)]]
r1 := r3)

First, a new environment is allocated, as a local tuple, and filled with the elements from environments →x and →y. Next, the tuple is made shared for reading, allowing multiple threads to access the environment without contention. Lastly, the ad- dress of the newly created environment is copied to register r1, as required by the continuation code.
A process P is translated by function P→x,Γ[[P ]], parametric on a sequence of names →x and on a π-calculus typing environment Γ, where Γ ▶ P and fn(P ) ⊆ {→x}. The result of the translation is a pair composed of a heap H and a sequence of instructions I. This function is defined by cases. The translation of the inactive, of the parallel composition, and of the output processes are as follows.


P→x,Γ
[[0]]
d=ef ⟨∅, done⟩
P→x,Γ[[x ⟨→v⟩]] d=ef ⟨∅,I⟩ where


P→x,Γ[[P | Q]] d=ef ⟨H  H
where

  HQ

,I⟩
I = (r2 := new |→v|

∀ 1 ≤ j ≤ |→v|

V→x[[vj]]
r [j] := r

⟨HP , IP ⟩ = P→x,Γ[[P ]]
share r2
2
read-only
3
−−Tseq[[Γ(→v)]]

⟨HQ, IQ⟩ = P→x,Γ[[Q]]
H = lQ (r1 : Tseq[[Γ(→x)]]){IQ}
I = (fork lQ; IP )
r1 := r1[i]
jump append[Tseq[[Γ(→v)]]])


The translation of the inactive process is direct: the thread is terminated and an empty heap produced. The parallel process P | Q is translated by forking the execution of Q and continuing with the execution of P in the current thread, whilst (read-only) environment →x is shared by both processes. For the output process, the registers are laid out as expected by code block append in the monitor of Section 3: register r1 contains the (address of) channel xi (that is, the monitor), and register r2 contains (the address of) the tuple with values →v (that is, the element to append to the buffer in the monitor). The control is then transferred to code block append. By Γ(v) we mean T where Γ ▶ v : T (cf. Figure 16); in other words, T when v : T ∈ Γ, or int if v is an integer literal.

The translation of an input process is as follows.


P→x,Γ[[x (→y).P ]] d=ef ⟨H  H', jump l⟩ where
[T→ ] = Γ(xi) Γ' = Γ, →y : T→
⟨H',I'⟩ = P→x→y,Γ' [[P ]]
contType = (r1 : Tseq[[Γ(→x)]], r2 : Tseq[[T→ ]])





H = l' contType {E Γ' (→x, →y); I'}
l (r1 : Tseq[[Γ(→x)]]) { r2 := new 2 r2[1] := l'
r2[2] := r1
share r2 read-only	−− ⟨contType, Tseq[[Γ(→x)]]⟩ro
r2 := pack Tseq[[Γ(→x)]], r2 as RemoveContinuation(Tseq[[T→ ]])
r1 := r1[i]
jump remove[Tseq[[T→ ]]]}


The resulting instruction jump l executes code block l in heap H, which prepares registers r1 and r2 and then transfers control to the monitor’s code block remove. Channel xi (that is, the monitor) is loaded in register r1; the closure for continua- tion P is loaded at register r2, as witnessed by type Tseq[[Γ(→x)]]. The code for remove transfers the control back to l' (in heap H), where the current environment is again in register r1, and the values that replace →y (that is, the element removed from the monitor’s buffer) is in register r2. The current environment →x is then extended with →y and process P is executed.
The translation of the replicated input process is identical, except for the code block

l' contType {fork l; E Γ' (→x, →y); I'}


that starts the continuation of the removed element by forking a copy of the trans- lation of the input process at code block l.
In the translation of scope restriction, a new monitor is created for channel y

and added to the current environment.
P→x,Γ[[(νy : T ) P ]] d=ef ⟨H H',I⟩ where
T = [T→ ]
Γ' = Γ,y : T
⟨H',I'⟩ = P→xy,Γ' [[P ]]
contType = (r1 : Tseq[[Γ(→x)]], r2 : T [[T ]])
H = l contType {
r3 := new 1
r3[1] := r2
share r3 read-only	−−⟨T [[T ]]⟩ro
r2 := r3 E Γ' (→x, y) I'}


I = (r2 := new 2
r2[1] := l
r2[2] := r1
share r2 read-only	−−⟨contType, Tseq[[Γ(→x)]]⟩ro
r1 := pack Tseq[[Γ(→x)]], r2 as CreateContinuation(Tseq[[T→ ]])
jump createMonitor[Tseq[[T→ ]]])
In instruction sequence I, register r1 is loaded with the continuation, and control transferred to operation createMonitor. The code for createMonitor transfers the control back to l, where the current environment is again in register r1 and the newly created monitor is register r2. Before proceeding with the code for P , this channel (monitor) must be appended to the current environment: in register r2 we create a one-place environment containing the channel, which is then concatenated to the current environment via instructions E Γ' (→x, y).
Applying the translation function to process (ν x : int) (x(y).0 | x⟨2⟩)) yields the code shown in Figure 17.

Results
The main result of our compiler states that the translation produces type correct MIL programs from type correct π-programs (closed processes).
Theorem 5.1 If ∅▶ P, then Ψ ▶ P[[P ]] for some Ψ.
The proof builds a typing derivation for the MIL program P[[P ]], using the follow- ing lemma to construct the derivations for the heap H and the instruction sequence I generated by the translation P$,$[[P ] of process P , where Ψ0 is the environment that



main () {
−− [[(new x:⟨int⟩)(x(y).0 | x⟨2⟩ )]]
−− E(0,0)
r3 := new 0
share r3 read-only	−− ⟨⟩ro
r1 := r3
−− (new x:⟨int⟩ )[[( x(y).0 | x⟨2⟩ )]]
r2 := new 2
r2 [1] := l1
r2 [2] := r1
share r2 read-only
−− ⟨(r1:⟨⟩ro , r2 :Monitor(⟨ int ⟩ro )), ⟨⟩ro ⟩
r1 := pack ⟨⟩ro , r2 as CreateContinuation(⟨ int ⟩ro )
jump createMonitor[⟨ int ⟩ro ]
}
l1 (r1 : ⟨⟩ro , r2 :Monitor(⟨ int ⟩ro )) {
r3 := new 1
r3 [1] := r2
share r3 read-only	−− ⟨Monitor(⟨int⟩ro) ⟩ro
r2 := r3
−− E(0,x)
r3 := new 1
r4 := r2 [1]
r3 [1] := r4
share r3 read-only	−− ⟨Monitor(⟨int⟩ro)⟩
r1 := r3
−− [[x(y ).0]] | [[ x⟨2⟩ ]]
fork l4
−− x(y ).[[0]]
jump l2
l3 (r1 : ⟨Monitor(⟨ int ⟩ro ) ⟩ro , r2 : ⟨ int ⟩ro ) {
−− E(x,y)
r3 := new 2
r4 := r1 [1]
r3 [1] := r4
r4 := r2 [1]
r3 [2] := r4
share r3 read-only −− ⟨Monitor(⟨int⟩ro ), int ⟩
r1 := r3
−− 0
done
}
−− x⟨2⟩
l4 (r1 : ⟨Monitor(⟨ int ⟩ro ) ⟩ro ) {
r2 := new 1
r3 := 2
r2 [1] := r3
share r2 read-only −− ⟨int⟩ro
r1 := r1 [1]
jump append[⟨int ⟩ro ]
}

}
l2 (r1 : ⟨Monitor(⟨ int ⟩ro ) ⟩ro ) {
r2 := new 2
r2 [1] := l3
r2 [2] := r1
share r2 read-only
−− ⟨(r1:⟨Monitor(⟨int⟩ro ) ⟩ro , r2 :⟨ int ⟩ro ), ⟨Monitor(⟨ int ⟩ro ) ⟩ro ⟩
r2 := pack ⟨Monitor(⟨int ⟩ro ) ⟩ro , r2 as RemoveContinuation(⟨int⟩ro )
r1 := r1 [1]
jump remove[⟨int ⟩ro ]
}

Fig. 17. The translation of process (ν x : int) (x(y).0 | x⟨2⟩)) into a MIL program.

types the whole library, and includes entries for code blocks createMonitor, append, and remove with the corresponding types described in Section 3.
Lemma 5.2 If P→x,Γ[[P ]] = ⟨H, I⟩ with Γ ▶ P and fn(P ) ⊆ →x, then ∃Ψ ⊇ Ψ0 such that Ψ ▶ H and Ψ; (r2 : Tseq[[Γ(→x)]]); ∅▶ I.
The proof for this lemma is by induction on the structure of the π-process P , simplified by the fact that each process constructor generates quite a concise code thanks to the library discussed in Section 3. The target code produced by P[[P ] must be linked to the library H0. We have not attempted to hand-check the typability of the 250-plus lines of H0; instead we have run it through the MIL type checker [19], which has been used to type check various non-trivial programs.

Discussion
Turner uses a single queue to hold both the messages and the input processes waiting for messages, taking advantage of an invariant by which queues never con-

tain both messages and input processes simultaneously [29]. Our implementation uses two queues, one to hold the messages in the monitor’s buffer, the other to imple- ment the condition variable, which, remarkably are instances of the same abstract data type: Queue(λ,Element) and Queue(λ,WaitContinuation(λ)). We tried a Turner-like imple- mentation where the data structure implementing π-channels contained addresses of two different queues, given that, for typing reasons, we cannot have a same queue containing messages and objects, even if at different times. The monitor-based implementation we propose uses the same amount of memory, yet less lines of code.
Conclusions and Further Work
The contributions of this work are twofold: a) the extension of MIL with memory local to a processor, heap allocated read-only tuples that may be shared without con- tention, polymorphic and lock-existential types, and the corresponding type sound- ness result, and b) a type-preserving compilation algorithm from the π-calculus into MIL, witnessing the flexibility of the language in a typed (hence race-free) sce- nario. As a by-product of the translation we showed how to implement a generic unbounded buffer monitor in MIL.
We are currently developing on a version of MIL equipped with a compare- and-swap primitive rather than locks, allowing in particular to obtain a wait-free implementation of queues, hence of the π-calculus and related languages. Future work includes the static detection of deadlocks and developing a model that adheres more closely to multi-core processors as we know them, in particular foregoing the direct allocation of arbitrary-length tuples directly on registers.

References
Appel, A. W., “Compiling with Continuations,” Cambridge University Press, 1991.
Birrell, A., An introduction to programming with threads, Technical Report 35, Digital Systems Research Center, Palo Alto, California (1989).
Boudol, G., Asynchrony and the π-calculus (note), Rapport de Recherche 1702, INRIA Sophia-Antipolis (1992).
Boyapati, C., R. Lee and M. Rinard, Ownership types for safe programming: preventing data races and deadlocks, in: Proceedings of OOPSLA ’02 (2002), pp. 211–230.
Boyapati, C. and M. Rinard, A parameterized type system for race-free Java programs, in: Proceedings of OOPSLA ’01 (2001), pp. 56–69.
Dahl, O. J. and C. A. R. Hoare, “Hierarchical program structures,” Academic Press, 1972 pp. 175–220.
Flanagan, C. and M. Abadi, Object types against races, in: J. C. M. Baeten and S. Mauw, editors,
Proceedings of CONCUR ’99, LNCS 1664 (1999), pp. 288–303.
Flanagan, C. and M. Abadi, Types for safe locking, in: S. D. Swierstra, editor, Proceedings of ESOP ’99, LNCS 1576 (1999), pp. 91–108.
Flanagan, C. and S. N. Freund, Type-based race detection for Java, ACM SIGPLAN Notices 35 (2000),
pp. 219–232.
Flanagan, C. and S. N. Freund, Type inference against races, in: R. Giacobazzi, editor, Proceedings of SAS ’04, LNCS 3148 (2004), pp. 116–132.

Fournet, C. and G. Gonthier, The reflexive chemical abstract machine and the join-calculus, in:
Proceedings of POPL ’96, ACM Press, 1996, pp. 372–385.
Grossman, D., Type-safe multithreading in Cyclone, in: Z. Shao and P. Lee, editors, Proceedings of TLDI ’03, SIGPLAN Notices 38(3) (2003), pp. 13–25.
Held, J., J. Bautista and S. Koehl, From a few cores to many: A tera-scale computing research overview
(2006), white paper.
Hoare, C. A. R., Monitors: an operating system structuring concept, Communications of the ACM 17
(1974), pp. 549–557.
Honda, K. and M. Tokoro, An Object Calculus for Asynchronous Communication, in: P. America, editor, Proceedings of ECOOP ’91, LNCS 512 (1991), pp. 133–147.
Iwama, F. and N. Kobayashi, A new type system for JVM lock primitives, in: Proceedings of ASIA- PEPM ’02 (2002), pp. 71–82.
Laneve, C., A type system for JVM threads, Journal of Theoretical Computer Science 290 (2003),
pp. 741–778.
Lopes, L., F. Silva and V. T. Vasconcelos, A Virtual Machine for the TyCO Process Calculus, in:
G. Nadathur, editor, Proceedings of PPDP ’99, LNCS 1702 (1999), pp. 244–260.
MIL website.
URL http://gloss.di.fc.ul.pt/mil/

Morrisett, G., Typed assembly language, in: B. C. Pierce, editor, Advanced Topics in Types and Programming Languages, MIT Press, 2002 pp. 137–176.
Morrisett, G., K. Crary, N. Glew, D. Grossman, R. Samuels, F. Smith, D. Walker, S. Weirich and
S. Zdancewic, Talx86: A realistic typed assembly language, in: Proceedings of WCSSS ’99, 1999, pp. 25–35.
Morrisett, G., D. Walker, K. Crary and N. Glew, From System F to Typed Assembly Language, ACM Transactions on Programing Language and Systems 21 (1999), pp. 527–568.
Oyama, Y., K. Taura and A. Yonezawa, An Efficient Compilation Framework for Languages Based on a Concurrent Process Calculus, in: C. Lengauer, M. Griebl and S. Gorlatch, editors, Proceedings of Euro-Par ’97, LNCS 1300 (1997), pp. 546–553.
Paulino, H., P. Marques, L. Lopes, V. T. Vasconcelos and F. Silva, A multi-threaded asynchronous language, in: V. Malyshkin, editor, Proceedings of PaCT ’03, LNCS 2763 (2003), pp. 316–323.
Pierce, B. C., “Advanced Topics In Types And Programming Languages,” MIT Press, 2002.
Pierce, B. C. and D. N. Turner, Pict: A Programming Language Based on the Pi-Calculus, in:
G. Plotkin, C. Stirling and M. Tofte, editors, Proof, Language and Interaction: Essays in Honour of Robin Milner, Foundations of Computing (2000), pp. 455–494.
Ramsey, N. and S. P. Jones, Featherweight concurrency in a portable assembly language (2001).
Sangiorgi, D. and D. Walker, “The π-calculus: a Theory of Mobile Processes,” Cambridge University Press, 2001.
Turner, D. N., “The Polymorphic Pi-Calculus: Theory and Implementation,” Ph.D. thesis, LFCS, University of Edinburgh (1996).
Vasconcelos, V. T. and F. Martins, A multithreaded typed assembly language, in: G. Gopalakrishnan and J. O’Leary, editors, Proceedings of TV ’06, 2006, pp. 133–141.
