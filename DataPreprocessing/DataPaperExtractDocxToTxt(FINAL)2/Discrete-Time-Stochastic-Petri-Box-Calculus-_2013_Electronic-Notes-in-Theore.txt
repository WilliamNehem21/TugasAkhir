Available online at www.sciencedirect.com


Electronic Notes in Theoretical Computer Science 296 (2013) 229–252
www.elsevier.com/locate/entcs

Discrete Time Stochastic Petri Box Calculus with Immediate Multiactions dtsiPBC
Igor V. Tarasyuka,1,3, Hermenegilda Macia`b,2,4 and Valent´ın Valerob,2,5
a A.P. Ershov Institute of Informatics Systems SB RAS, Novosibirsk, Russian Federation
b High School of Computer Science Engineering, UCLM, Albacete, Spain

Abstract
We propose discrete time stochastic Petri box calculus extended with immediate multiactions, called dt- siPBC. The step operational semantics is constructed via labeled probabilistic transition systems. The denotational semantics is defined via labeled discrete time stochastic Petri nets with immediate transitions (LDTSIPNs). A consistency of both semantics is demonstrated. In order to evaluate performance, the cor- responding semi-Markov chains are analyzed. In a case study, performance of the shared memory system is evaluated.
Keywords: Stochastic process algebra, Petri box calculus, discrete time, immediate multiaction, probabilistic transition system, LDTSIPN, performance evaluation, shared memory system.


Introduction
Algebraic process calculi are a recognized formal model for specification of com- puting systems and analysis of their behaviour. Petri Box Calculus (PBC) [2] is a flexible and expressive process algebra developed as a tool for specification of Petri nets structure and their interrelations. Its goal was also to propose a compositional semantics for high level constructs of concurrent programming languages in terms of elementary Petri nets. PBC has a step operational semantics in terms of labeled transition systems. Its denotational semantics was proposed in terms of a subclass

1 Supported by Deutsche Forschungsgemeinschaft (DFG), 436 RUS 113/1002/01.
2 Supported by Spanish government (co-financed by FEDER founds), the project “Modeling and analyzing composite Web services using formal methods”, TIN2009-14312-C02-02.
3 Email:itar@iis.nsk.su
4 Email:Hermenegilda.Macia@uclm.es
5 Email:Valentin.Valero@uclm.es

1571-0661 © 2013 Elsevier B.V. Open access under CC BY-NC-ND license.
http://dx.doi.org/10.1016/j.entcs.2013.07.015

of Petri nets (PNs) equipped with interface and considered up to isomorphism called Petri boxes.
There are timed extensions of PBC considering a deterministic or a nondeter- ministic time model: time Petri box calculus (tPBC) [7], in which an interleaving semantics is considered and actions have a time interval associated; timed Petri box calculus (TPBC) [11], where a step semantics is considered and multiactions have time durations associated, and arc time Petri box calculus (atPBC) [16], in which a step semantics is also considered and time intervals for the multiaction delays. There are also stochastic extensions of PBC: stochastic Petri box calculus (sPBC) [8, 9], with a continuous time model and multiaction delays that follow a negative exponential distribution. A discrete time stochastic extension of finite PBC was presented in [17], dtsPBC, providing a step operational semantics and a deno- tational semantics based on dts-boxes, a subclass of labeled discrete time stochastic PNs (LDTSPNs).
In this paper, dtsPBC is extended with the iteration operator and immediate multiactions. This new language, discrete time stochastic and immediate Petri box calculus (dtsiPBC), is a discrete time analog of sPBC. Immediate multiactions in- crease the specification capability: they can model instant probabilistic choices and activities with negligible durations. They are also used to specify urgent activities and the ones, which not relevant for performance evaluation. In many cases, they result in a more clear system representation. We define a step operational semantics by using labeled probabilistic transition systems, and a corresponding denotational semantics in terms of a subclass of LDTSPNs with immediate transitions (LDT- SIPNs), called dtsi-boxes. Consistency of both semantics is then demonstrated. The corresponding stochastic process, semi-Markov chain (SMC), is constructed and in- vestigated, with the purpose of performance evaluation. At last, a case study of a system with two processors and a common shared memory explains how to model and analyze performance of concurrent systems with dtsiPBC.
There are many well-known works related to stochastic extensions of process algebras (SPAs). Due to the lack of space we can only mention a few of them, as MTIPP [4], PEPA [5] and EMPA [1]. The first difference between dtsiPBC and these classical SPAs comes from PBC, since dtsiPBC is based on that calculus: all operations and a notion of multiaction are inherited from PBC. The second difference is discrete conditional probabilities of activities in dtsiPBC due to its discrete time semantics, whereas the action rates are used in the standard SPAs with continuous time semantics. Discrete time operational semantics of dtsiPBC allows for concurrent execution of activities in steps. In continuous time semantics, concurrency is simulated by interleaving, since simultaneous occurrence of any two events has zero probability according to the properties of continuous probability distributions. The third difference are immediate multiactions in dtsiPBC which have the same priority while immediate actions in EMPA can have different prior- ities. There exist no immediate actions in MTIPP and PEPA. There is a recent work by Markovski and de Vink [10], where a SPA with discrete time is defined, providing for it an interleaving semantics, but in this work immediate actions are

not considered.
The paper is organized as follows. In Section 2, the syntax of the extended calculus dtsiPBC is presented. In Section 3, we construct the operational semantics of the algebra in terms of labeled probabilistic transition systems. In Section 4, we propose the denotational semantics based on a subclass of LDTSIPNs. In Section 5, the corresponding stochastic process is defined and analyzed. In Section 6, an illustrative example of the shared memory system is presented and investigated as a case study. Section 7 summarizes the results obtained and outlines research perspectives.


Syntax
We denote the set of all ﬁnite multisets over a set X by NX


and the set of all

subsets of X by 2X . Let Act = {a, b, .. .} be the set of elementary actions. Then Act = {aˆ, ˆb, . . .} is the set of conjugated actions (conjugates) s.t. a /=a aˆnd aˆ = a. Let A = Act ∪Act be the set of all actions, and L = NA be the set of all multiactions.
Note that ∅∈ L, this corresponds to the execution of a multiaction that contains no visible action names. The alphabet of α ∈L is defined as A(α)= {x ∈A| α(x) > 0}.
A stochastic multiaction is a pair (α, ρ), where α ∈ L and ρ ∈ (0; 1) is the conditional probability of the multiaction α. These probabilities are used to calculate the probabilities of state changes (steps) at discrete time moments. The probabilities of stochastic multiactions are required not to be equal to 1, since this value is left for immediate multiactions. On the other hand, notice that zero probabilities are not allowed for multiactions, since they would never be performed in this case. Let SL be the set of all stochastic multiactions.
An immediate multiaction is a pair (α, l), where α ∈L and l ∈ N \ {0} is the non-zero weight of the multiaction α. These are clearly identifiable from stochastic multiactions, because of the natural number instead of a real number in the interval (0; 1). Stochastic and immediate multiactions cannot be executed together in some concurrent step, i.e. the steps can only consist either of stochastic or immediate multiactions, the latter having a priority over stochastic ones. Thus, in a state where both kinds of multiactions can occur, immediate multiactions always occur before stochastic ones. Let IL be the set of all immediate multiactions.
Notice that the same multiaction α ∈ L may have different probabilities and weights in the same specification. An activity is a stochastic or an immediate multiaction. Let SIL = SL ∪ IL be the set of all activities. The alphabet of (α, κ) ∈ SIL is defined as A(α, κ) = A(α). The alphabet of Υ ∈ NSIL is defined as A(Υ) = ∪(α,κ)∈ΥA(α). For (α, κ) ∈ SIL, we define its multiaction part as L(α, κ)= α and its probability or weight part as Ω(α, κ)= κ.
Activities are combined into formulas by the following operations: sequential ex- ecution ;, choice [], parallelism , relabeling [f ] of actions, restriction rs over a single action, synchronization sy on an action and its conjugate, and iteration [ ∗∗ ] with three arguments: initialization, iteration body and termination. Sequential execu-

tion and choice have the standard interpretation like in other process algebras, but parallelism does not include synchronization unlike the corresponding operation in the standard process calculi. Relabeling functions f : A→A are bijections preserv- ing conjugates, i.e. ∀x ∈ A, f (Σxˆ) = fˆ(x). Relabeling is extended to multiactions:
activities: for Υ ∈ NSIL, we define f (Υ) =	(α,κ)∈Υ(f (α), κ). Restriction over an action a ∈ Act means that any process behaviour containing a or aˆ is not allowed.
Synchronization of multiactions is defined for multiactions belonging to the same class (stochastic or immediate). Taking into account this requirement, let α, β ∈ L, and a ∈ Act s.t. a ∈ α and aˆ ∈ β or aˆ ∈ α and a ∈ β. Synchronization of α and β by a is defined as α ⊕a β = γ, where
γ(x)=  α(x)+ β(x) − 1,  if x = a or x = aˆ;
α(x)+ β(x),	otherwise.
As in PBC, static expressions specify the structure of processes and correspond to unmarked LDTSIPNs. A restriction must be introduced to avoid inconsistency of the iteration operator. We do not allow any concurrency at the highest level of the second argument of iteration. This is not a severe restriction, since we can prefix parallel expressions by an activity with the empty multiaction. The mentioned inconsistency can result in non-safe nets [3].
Definition 2.1 Let (α, κ) ∈ SIL, and a ∈ Act . A regular static expression of dtsiPBC is defined by the following syntax:

E ::= (α, κ) | E; E | E[]E | E  E | E[f ] | E rs a | E sy a | [E ∗ D ∗ E],
where D ::= (α, κ) | D; E | D[]D | D[f ] | D rs a | D sy a | [D ∗ D ∗ E].

RegStatExpr will denote the set of all regular static expressions of dtsiPBC. Dy- namic expressions specify process states, and correspond to LDTSIPNs (marked by definition). Dynamic expressions are obtained from static ones which are annotated with upper or lower bars and specify active components of the system at the current instant. E denotes the initial, E denotes the ﬁnal state of the process specified by a static expression E. The underlying static expression of a dynamic one is obtained by removing all the bars from it.
Definition 2.2 Let E ∈ StatExpr, a ∈ Act . We define dynamic expressions:

G ::= E | E | G; E | E; G | G[]E | E[]G | G  G | G[f ] | G rs a | G sy a |
[G ∗ E ∗ E] | [E ∗ G ∗ E] | [E ∗ E ∗ G].

DynExpr will denote the set of all dynamic expressions of dtsiPBC. If the underly- ing static expression of a dynamic one is not regular, the corresponding LDTSIPN can be non-safe (but it is 2-bounded in the worst case [3]). A dynamic expression is regular if its underlying static expression is regular. RegDynExpr denotes the set of all regular dynamic expressions of dtsiPBC.

Operational semantics
Inaction Rules. These describe structural transformations for dynamic expres- sions, but not changing the states of the specified processes. The goal of these syn- tactic transformations is to obtain the well-structured terminal expressions called operative ones to which no inaction rules can be further applied. These transfor- mations do not take any time, and their application to a dynamic expression will not modify the corresponding marking in the associated LDTSIPN. No transitions are therefore fired in relation with these transformations. In Table 1, we define the inaction rules for the regular dynamic expressions in the form of overlined and underlined static ones, where E, F, K ∈ RegStatExpr and a ∈ Act . Inac- tion rules for arbitrary regular dynamic expressions are defined in Table 2, where E, F ∈ RegStatExpr, a ∈ Act and G, H, G, H ∈ RegDynExpr .
Table 1
Inaction rules for overlined and underlined regular static expressions


Table 2
Inaction rules for arbitrary regular dynamic expressions

A regular dynamic expression G is operative if no inaction rule can be applied to it. OpRegDynExpr denotes the set of all operative regular dynamic expressions of dtsiPBC. Note that any dynamic expression can be always transformed into a (not necessarily unique) operative one by using the inaction rules. We shall consider regular expressions only and omit the word “regular”.
Definition 3.1 Let ≈ = (⇒ ∪ ⇐)∗ be the structural equivalence of dynamic ex- pressions in dtsiPBC. Thus, two dynamic expressions G and Gj are structurally equivalent, denoted by G ≈ Gj, if they can be reached from each other by applying the inaction rules in forward or backward direction.
Action and empty loop rules. With action rules the execution of activities is captured. The prioritization of immediate multiactions w.r.t. stochastic ones is also captured by these action rules. We also have the empty loop rule, which is used to capture a delay of one time unit at any state when no immediate multiactions are

executable. In this case, the empty multiset of activities is considered to be executed. Action rules with stochastic multiactions define dynamic expression transformations due to the execution of non-empty multisets of stochastic multiactions, and are time consuming, they take one time unit, whereas action rules with immediate multiactions define instantaneous dynamic expression transformations due to the execution of non-empty multisets of immediate multiactions. Action rules with either stochastic or immediate multiactions respectively correspond to stochastic or immediate transition firings in the corresponding LDTSIPN. The firing of a set of stochastic transitions is time consuming, one time unit elapses with their firing, whereas immediate transitions take no time in their firing.

With the empty loop rule G →∅
G (rule El in Table 3) we capture the possibility

to stay at a tangible state (only stochastic movements are possible) without firing any activities. This is defined as an empty movement that takes one time unit. This rule reflects a non-zero probability to stay at the current state at the next time moment, which is an essential feature of discrete time stochastic processes. This is a new rule that has no prototype among inaction rules of PBC, since it represents

a time delay. The PBC rule G →∅
G from [3] in our setting would correspond to a

rule G ⇒ G, but notice that our model is strongly based on the transformation of dynamic expressions into operative ones by the bars movements, hence, we do not introduce it in dtsiPBC.
Thus, an application of every action rule with stochastic multiactions or the empty loop rule requires one time unit delay, i.e. the execution of a (possibly empty) multiset of stochastic multiactions leading to the dynamic expression transformation described by the rule is accomplished instantaneously after one time unit. An application of every action rule with immediate multiactions does not take any time, i.e. the execution of a (non-empty) multiset of immediate multiactions is accomplished instantaneously at the current instant.
Expressions of dtsiPBC can contain identical activities. Thus, to avoid technical difficulties, such as the proper calculation of the state change probabilities for mul- tiple transitions, we can always enumerate coinciding activities from left to right in the syntax of expressions. The new activities obtained from synchronization will be annotated with concatenation of numberings of the activities they come from, hence, the numbering we use has a tree structure to reflect the effect of multiple synchronizations. But notice that the new activities resulting from synchronizations in different orders should be considered up to permutation of their numbering. In this way, we can recognize different instances of the same activity.
Due to the lack of space we omit a formalization of the numbering mechanism, which is straightforward. From now onwards, we will assume that the identical activities are enumerated when needed to avoid ambiguity. This enumeration is considered to be implicit.
Let E ⊆ X2 be an equivalence relation on a set X. The equivalence class (w.r.t. E ) of x ∈ X is [x]E = {y ∈ X | (x, y) ∈ E}. The equivalence E partitions X into the set of equivalence classes X/E = {[x]E | x ∈ X}.
Let G be a dynamic expression. Then [G]≈ = {H | G ≈ H} is the equivalence

class of G w.r.t. the structural equivalence. G is an initial dynamic expression, de- noted by init (G), if ∃E ∈ RegStatExpr, G ∈ [E]≈. G is a ﬁnal dynamic expression, denoted by ﬁnal (G), if ∃E ∈ RegStatExpr, G ∈ [E]≈.
Definition 3.2 Let G ∈ OpRegDynExpr . We now define the set of all sets of activ- ities which can be executed from G, denoted by Can(G). Let (α, κ) ∈ SIL, E, F ∈ RegStatExpr, G, H ∈ OpRegDynExpr and a ∈ Act .
If ﬁnal (G) then Can(G)= ∅.

If G = (α, κ) then Can(G)= {{(α, κ)}}.
If Υ ∈ Can(G) then Υ ∈ Can(G ◦ E), Υ ∈ Can(E ◦ G) (◦∈ {; , []}),
Υ ∈ Can(G  H), Υ ∈ Can(H  G), f (Υ) ∈ Can(G[f ]), Υ ∈ Can(G rs a)
(when a, aˆ /∈(AΥ)), Υ ∈ Can(G sy a), Υ ∈ Can([G ∗ E ∗ F ]),
Υ ∈ Can([E ∗ G ∗ F ]), Υ ∈ Can([E ∗ F ∗ G]).
If Υ ∈ Can(G) and Ξ ∈ Can(H) then Υ+Ξ ∈ Can(G  H).
If Υ ∈ Can(G sy a) and (α, κ), (β, λ) ∈ Υ are different, a ∈ α, aˆ ∈ β then
(Υ + {(α ⊕a β, κ · λ)}) \ {(α, κ), (β, λ)}∈ Can(G sy a), if κ, λ ∈ (0; 1);
(Υ + {(α ⊕a β, κ + λ)}) \ {(α, κ), (β, λ)}∈ Can(G sy a), if κ, λ ∈ N \ {0}. When we synchronize the same set of activities in different orders, we ob- tain several activities with the same multiaction and probability or weight parts, but with different numberings having the same content. Then we only consider a single one of the resulting activities to avoid introducing
redundant ones.
By definition of Can(G), Υ ∈ Can(G) implies ∀Ξ ⊆ Υ, Ξ /=∅, Ξ ∈ Can(G). The expression G ∈ OpRegDynExpr is tangible, denoted by tang (G), if Can(G) contains only sets of stochastic multiactions (possibly including the empty set), i.e.
∀Υ ∈ Can(G), Υ ∈ NEL. Otherwise, G is vanishing, denoted by vanish(G), meaning that there are immediate multiactions in the sets from Can(G), hence, according to the note above, there are non-empty sets of immediate multiactions in Can(G), i.e.
∃Υ ∈ Can(G), Υ ∈ N£L \ {∅}. Clearly, immediate multiactions are only executable from vanishing operative dynamic expressions. Stochastic multiactions are only executable from tangible ones, since no stochastic multiactions can be executed from a vanishing operative dynamic expression G, even if Can(G) contains sets of stochastic multiactions. The reason is that immediate multiactions have a priority over stochastic ones, and must be executed first.
In Table 3, we define the action and empty loop rules, where (α, ρ), (β, χ) ∈ SL, (α, l), (β, m) ∈ IL, (α, κ) ∈ SIL.  Further, E, F ∈ RegStatExpr, G,H ∈
OpRegDynExpr, G˜, H˜ ∈ RegDynExpr, a ∈ Act . Moreover, Γ, Δ ∈ NEL \ {∅},
Γj ∈ NEL, I, J ∈ N£L \{∅}, Ij ∈ N£L and Υ ∈ NE£L \{∅}. The names of the action
f	f	f	f
rules with immediate multiactions have suffix ‘i’.
Rule Sy2 establishes that the synchronization of two stochastic multiactions is made by taking the product of their probabilities, since we are considering that both must occur for the synchronization to happen, so this corresponds to the probability of the event intersection. In rule Sy2i, we sum the weights of two

Table 3
Action and empty loop rules

synchronized immediate multiactions, since the weights can be interpreted as the rewards, thus, we collect the rewards. Moreover, we express that the synchronized execution of immediate multiactions has more importance than that of every single one. Since execution of immediate multiactions takes no time, we prefer to execute in a step as many synchronized immediate multiactions as possible to get more progress in behaviour, this aspect will be used later, while evaluating performance on the basis of the embedded discrete time Markov chains. We do not have self- synchronization, i.e. the synchronization of an activity with itself, since all the (enumerated) activities executed together are considered to be different. This allows us to avoid many technical difficulties [3].
Transition systems. Now we construct labeled probabilistic transition systems of dynamic expressions to define later the operational semantics.
Definition 3.3 The derivation set DR(G) of a dynamic expression G is the minimal set s.t. [G]≈ ∈ DR(G) or, if [H]≈ ∈ DR(G) and ∃Γ, H → H, then [H]≈ ∈ DR(G).
Let G be a dynamic expression and s, s˜ ∈ DR(G). The set of all the sets of
Υ
activities executable in s is defined as Exec(s) = {Υ | ∃H ∈ s, ∃H˜, H → H˜}.
Note that if Υ ∈ Exec(s), then ∃H ∈ s, Υ ∈ Can(H). The state s is tangible, if
Exec(s) ⊆ NEL. For tangible states we may have Exec(s)= ∅. Otherwise, the state
s is vanishing, and in this case Exec(s) ⊆ N£L \ {∅}. The set of all tangible states from DR(G) is denoted by DRT (G), and the set of all vanishing states from DR(G) is denoted by DRV (G). Clearly, DR(G) = DRT (G) DRV (G), where denotes disjoint union.

Let Υ ∈ Exec(s) \ {∅}. The probability of the set of stochastic multiactions or the weight of the set of immediate multiactions which is ready for execution in s is
  (α,ρ)∈Υ ρ ·  {{(β,χ)}∈Exec(s)|(β,χ)/∈Υ}(1 − χ), s ∈ DRT (G);
 

For Υ = ∅ and s ∈ DRT
(G), let PF (∅, s)=	  {(β,χ)}∈Exec(s)(1 − χ), Exec(s) /= ∅;
1,	Exec(s)= ∅.

Thus, if s ∈ DRT (G) and Exec(s) /=∅, then PF (Υ, s) could be interpreted as a joint probability of independent events. Each such an event is interpreted as readiness or not readiness for execution of a particular stochastic multiaction from Υ. The multiplication in the definition is used because it reflects the probability of the independent event intersection. When only the empty set of activities can be executed in s, i.e. Exec(s)= ∅, we take PF (∅, s) = 1, since we stay in s in this case. Note that for s ∈ DRT (G) we have PF (∅, s) ∈ (0; 1], hence, we can stay in s at the next time moment with a certain positive probability.
If s ∈ DRV (G) then PF (Υ, s) could be interpreted as the overall (cumulative) weight of the immediate multiactions from Υ, i.e. the sum of all their weights. The summation here is used since the weights can be seen as the rewards which are collected. In addition, this means that concurrent execution of the immediate multiactions has more importance than that of every single one. Since execution of immediate multiactions takes no time, we prefer to execute in a step as many parallel immediate multiactions as possible to get more progress in behaviour of the embedded discrete time Markov chains of expressions while evaluating performance. This reasoning is the same as that used to define the probability of synchronized immediate multiactions in the rule Sy2i. The definition of PF (Γ, s) (and those of other probability functions we shall present) is based on the (implicit) enumeration of activities.
Let Υ ∈ Exec(s).  The probability to execute the set of activities Υ in s is

PT (Υ, s) =
PF (Υ,s)
Ξ∈Exec(s) PF (Ξ,s)
.	Thus, PT (Υ, s) is the probability of the set of

stochastic multiactions or the weight of the set of immediate multiactions Υ which
is ready for execution in s normalized by the probabilities or the weights of all the sets executable in s. The denominator of the fraction is a sum, since it reflects the probability of the mutually exclusive event union.
If s is tangible, then PT (∅, s) ∈ (0; 1], hence, there is a non-zero probability to stay at the state s in the next time moment, and the residence time in s is at least 1 time unit. Observe that ∀s ∈ DR(G),  Υ∈Exec(s) PT (Υ, s) = 1, by definition of PT (Υ, s); hence, it defines a probability distribution.
The probability to move from s to s˜ by executing any set of activities is
PM (s, s˜) =	{Υ|∃H∈s, ∃H˜∈s˜, H→Υ H˜} PT (Υ, s). Since PM (s, s˜) is the probability to move from s to s˜ by executing any set of activities, we use summation.
Definition 3.4 Let G be a dynamic expression. The (labeled probabilistic) transi- tion system of G is a quadruple TS (G)= (SG, LG, TG, sG), where
the set of states is SG = DR(G);
the set of labels is LG ⊆ 2E£L × (0; 1];

the set of transitions is TG = {(s, (Υ, PT (Υ, s)), s˜) | s ∈ DR(G), ∃H ∈ s,
Υ
the initial state is sG = [G]≈.
The definition of TS (G) is correct: for every state, the sum of the probabilities of all the transitions starting from it is 1. This is guaranteed by the note after the definition of PT (Υ, s). Thus, we have defined a generative model of probabilistic processes [18], since the sum of the probabilities of the transitions with all possible labels should be equal to 1, not only of those with the same labels (up to enumeration of the activities included) as in the reactive models, and we do not have a nested probabilistic choice as in the stratiﬁed models.
The transition system TS (G) associated with a dynamic expression G describes all the steps that occur at discrete time moments with some (one-step) probability and consist of sets of activities. Every step consisting of stochastic multiactions or the empty step (i.e. that consisting of the empty set of activities) occurs in- stantaneously after one discrete time unit delay. Each step consisting of immediate multiactions occurs instantaneously without any delay. The step can change the current state. The states are the structural equivalence classes of dynamic expres- sions obtained by application of action rules starting from the expressions belonging

to [G]≈. A transition (s, (Υ, P), s˜) ∈ TG is written as s →Υ P
probability to change s to s˜ by executing Υ is P.
s˜, interpreted as the

For tangible states, Υ can be the empty set, and its execution does not change the current state (i.e. the equivalence class), since we have a loop transition s →∅ P s from a tangible state s to itself. This corresponds to the application of the empty loop rule to the expressions from the equivalence class. We have to keep track of such executions, called empty loops, because they have non-zero probabilities. This follows from the definition of PF (∅, s) and the fact that multiaction probabilities cannot be equal to 1 as they belong to the interval (0 ; 1). For vanishing states Υ cannot be the empty set, since we must execute some immediate multiactions from them at the current instant.
The step probabilities belong to the interval (0; 1], being 1 when we cannot leave a tangible state s and there only exists one transition from it, the empty loop one s →∅ 1 s, or there is just one transition from a vanishing state.

We write s →Υ
s˜ if ∃P, s →Υ P s˜ and s → s˜ if ∃Υ, s →Υ
s˜. For E ∈ RegStatExpr ,

let TS (E)= TS (E).
Example 3.5 The expression Stop = ({g}, 1 ) rs g specifies a non-terminating pro- cess that is only able to perform empty loops with probability 1.
Let E = [({a}, ρ) ∗ (({b}, χ); ((({c}, l); ({d}, θ))[](({e}, m); ({f}, φ)))) ∗ Stop].
We have DRT (E)= {s1, s2, s4, s5} and DRV (E)= {s3}, where
s1 = [[({a}, ρ) ∗ (({b}, χ); ((({c}, l); ({d}, θ))[](({e}, m); ({f}, φ)))) ∗ Stop]]≈,

s2 = [[({a}, ρ) ∗ (({b}, χ); ((({c}, l); ({d}, θ))[](({e}, m); ({f}, φ)))) ∗ Stop]]≈,
s3 = [[({a}, ρ) ∗ (({b}, χ); ((({c}, l); ({d}, θ))[](({e}, m); ({f}, φ)))) ∗ Stop]]≈,



s4 = [[({a}, ρ) ∗ (({b}, χ); ((({c}, l); ({d}, θ))[](({e}, m); ({f}, φ)))) ∗ Stop]]≈,
s5 = [[({a}, ρ) ∗ (({b}, χ); ((({c}, l); ({d}, θ))[](({e}, m); ({f}, φ)))) ∗ Stop]]≈.
In Figure 2 we can see the transition system TS (E) of E.
Denotational semantics
Labeled DTSIPNs. We introduce a class of labeled discrete time stochastic and immediate Petri nets (LDTSIPNs), a subclass of DTSPNs [14] (the transition prob- abilities cannot be equal to 1) extended with transition labeling and immediate transitions. Let us present a formal definition of LDTSIPNs.
Definition 4.1 A labeled discrete time stochastic and immediate Petri net (LDTSIPN) is a tuple N = (PN , TN , WN , ΩN , LN , MN ), where
PN and TN = TsN  Ti N are sets of places and stochastic and immediate transi-
tions, s.t. PN ∪ TN /=∅ and PN ∩ TN = ∅. Let M ∈ NPN be markings.
WN : (PN × TN ) ∪ (TN × PN ) → N is a function providing the weights of arcs
between places and transitions;
ΩN : TN → (0; 1) ∪ (N \{0}) is the probability/weight function associating stochas- tic transitions with probabilities and immediate ones with weights;
LN : TN →L is the labeling function assigning multiactions to transitions;

MN ∈ NPN
is the initial marking.

The graphical representation of LDTSIPNs is like that for standard labeled PNs, square boxes of normal thickness depict stochastic transitions, and those with thick borders represent immediate transitions. Let N be an LDTSIPN and t ∈ TN , U ∈ NTN . The precondition •t and the postcondition t• of t are the multisets of places defined as (•t)(p) = WN (p, t) and (t•)(p) = WN (t, p). The precondition •U and
the posΣtcondition U• of U are the multisets of places defined as •U = Σt∈U •t and
they fire first if they can. A transition t ∈ TN is enabled at marking M if •t ⊆ M , and one of the following holds: t ∈ Ti N or ∀u ∈ TN , •u ⊆ M ⇒ u ∈ TsN . A transition is therefore enabled at a marking M if there are enough tokens on its precondition places in the usual sense, but if it is stochastic there cannot be any immediate transition enabled. Let Ena(M ) be the set of all transitions enabled at M . By definition, it follows that Ena(M ) ⊆ Ti N or Ena(M ) ⊆ TsN . A set of transitions U ⊆ Ena(M ) is enabled at M if •U ⊆ M . Firings of transitions are atomic operations, and transitions may fire concurrently in steps. We assume that all transitions participating in a step should differ, hence, only the sets (not multisets) of transitions may fire. Thus, we do not allow self-concurrency, i.e. firing of transitions concurrently to themselves. This restriction is introduced to avoid some technical difficulties while calculating probabilities for multisets of transitions as we shall see after the following formal definitions. Moreover, we do not need to consider self-concurrency, since denotational semantics of expressions will be defined via dtsi-boxes which are safe LDTSIPNs (hence, no self-concurrency is possible).

A marking M is tangible, denoted by tang (M ), if Ena(M ) ⊆ TsN or Ena(M ) = ∅. Otherwise, the marking M is vanishing, denoted by vanish(M ), and in this case Ena(M ) ⊆ Ti N and Ena(M ) /=∅. If tang (M ), then a stochas- tic transition t ∈ Ena(M ) fires with probability ΩN (t) when no other stochastic transitions conflicting with it are enabled.
Let U ⊆ Ena(M ), U /=∅, •U ⊆ M . The probability of the set of stochastic transitions or the weight of the set of immediate transitions U which is ready for
 t∈U ΩN (t) ·  u∈Ena(M )\U (1 − ΩN (u)), tang (M );
For U = ∅ and tang (M ), let PF (∅,M )=	 u∈Ena(M )(1 − ΩN (u)), Ena(M ) /= ∅;
1,	Ena(M )= ∅.
Thus, if tang (M ) and Ena(M ) /=∅, then PF (U, M ) could be interpreted as a joint probability of independent events. Each such an event is interpreted as readi- ness or not readiness for firing of a particular transition from U . The multiplication in the definition is used because it reflects the probability of the independent event intersection. When no transitions are enabled at M , i.e. Ena(M ) = ∅, we take PF (∅,M ) = 1, since we stay in M in this case. Note that if tang (M ) then we have PF (∅,M ) ∈ (0; 1], hence, we can stay in M at the next time moment with a certain positive probability. If vanish(M ) then PF (U, M ) could be interpreted as the overall weight of the immediate transitions from U , i.e. the sum of all their weights.
Let U ⊆ Ena(M ), U /=∅, •U ⊆ M . The concurrent firing of the transitions

from U changes the marking M to M˜ = M −
U + U
, denoted by M →P M˜, where



PT (U, M )= Σ
PF (U,M )
{V |•V ⊆M} PF (V,M )

PF (∅,M )

For U = ∅, tang (M ), we have M = M and PT (∅,M )= Σ{V |•V ⊆M} PF (V,M ) .
Thus, PT (U, M ) is the probability of the set of stochastic transitions or the weight of the set of immediate transitions U which is ready for firing at M normalized by the probabilities or weights of all the sets enabled at M . The denominator of the fraction above is a sum, since it reflects the probability of the mutually exclusive event union.
If tang (M ) then PT (∅,M ) ∈ (0; 1], hence, there is a non-zero probability to stay at M in the next moment, and the residence time in M is at least 1 time unit. The sum of all outgoing probabilities is 1, i.e. ∀M ∈ NPN , PT (∅,M )+ 
Σ	f

We write M → M˜ if ∃P, M →P M˜ and M → M˜ if ∃U, M → M˜. The prob-
ability to move from M to M˜ by ﬁring any set of transitions is PM (M, M˜) =
{U|M →U M˜} PT (U, M ).	Since PM (M, M˜) is the probability for any (possibly
empty) transition set to change M to M˜, we use summation.

Definition 4.2 Let N be an LDTSIPN.
The reachability set RS (N ) of N is the minimal set of markings s.t.

MN ∈ RS (N ) or, if M ∈ RS(N ) and M → M , then M ∈ RS (N ).
The reachability graph RG (N ) of N is a directed labeled graph with the nodes
U
RS (N ) and the arcs labeled by (U,	) between M, M iff M	P
RST (N ) denotes the set of all tangible markings and RSV (N ) denotes that of all vanishing markings from RS (N ). Thus, RS (N )= RST (N )  RSV (N ).
Algebra of dtsi-boxes. We now introduce discrete time stochastic and immediate Petri boxes, and the algebraic operations to define a net representation of dtsiPBC expressions.
Definition 4.3 A discrete time stochastic and immediate Petri box (dtsi-box) is a tuple N = (PN , TN , WN , ΛN ), where
PN and TN are sets of places and transitions, s.t. PN ∪ TN /=∅, PN ∩ TN = ∅;
WN : (PN × TN ) ∪ (TN × PN ) → N is a function providing the weights of arcs
between places and transitions;
ΛN is the place and transition labeling function s.t.
ΛN |PN : PN → {e, i, x} (it specifies entry, internal and exit places);
E£L
ΛN |TN : TN → {Q | Q ⊆ 2	×SIL} (it associates transitions with the relabeling
relations on activities).
Moreover, ∀t ∈ TN , •t /=∅ /=t•. Next, for the set of entry places of N , defined as ◦N = {p ∈ PN | ΛN (p) = e}, and for the set of exit places of N , defined as N◦ = {p ∈ PN | ΛN (p)= x}, it holds: ◦N /=∅ /=N ◦, •(◦N )= ∅ = (N◦)•.
A dtsi-box is plain if ∀t ∈ TN , ΛN (t) ∈ SIL, i.e. ΛN (t) is the constant rela- beling that will be defined later. In the case of constant relabeling, the shorthand notation (by an activity) for ΛN (t) will be used. A marked plain dtsi-box is a
pair (N, MN ), where N is a plain dtsi-box and MN ∈ NPN  is its marking. We

shall use the following notation: N = (N, ◦N ) and N = (N, N◦). Note that a marked plain dtsi-box (PN , TN , WN , ΛN , MN ) could be interpreted as the LDT- SIPN (PN , TN , WN , ΩN , LN , MN ), where functions ΩN and LN are defined as fol- lows: ∀t ∈ TN , ΩN (t) = Ω(ΛN (t)) and LN (t) = L(ΛN (t)). The behaviour of marked dtsi-boxes follows from the firing rule of LDTSIPNs. A plain dtsi-box N is n-bounded (n ∈ N) if N is so, i.e. ∀M ∈ RS(N ), ∀p ∈ PN , M (p) ≤ n, and it is safe if it is 1-bounded. A plain dtsi-box N is clean if ∀M ∈ RS(N ),
N ⊆ M ⇒ M = ◦N and N◦ ⊆ M ⇒ M = N◦, i.e. if there are tokens in all its entry (exit) places, then no other places have tokens.
The structure of the plain dtsi-box corresponding to a static expression is con- structed as in PBC [3], i.e. we use simultaneous refinement and relabeling meta- operator (net refinement) in addition to the operator dtsi-boxes corresponding to the algebraic operations of dtsiPBC and featuring transformational transition rela- belings. As we are taking the same structure for the resulting Petri net as in PBC, the obtained plain dtsi-boxes are safe and clean.
The denotational semantics is obtained considering the same standard construc- tions used for PBC. The relabeling relations Q ⊆ 2E£L × SIL are:

N(α,ρ)ι
,,
e
 J
v
tι
,v,
x
N(α,l)ι
,,
e
 J
v
tι
,v,
x
Θ[f ]
,,
e
 J
v
u[f ]
,v,
x
Θrs a
,,
e
 J
v
urs a
,v,
x
Θsy a
,,
e
 J
v
usy a
,v,
x
Θ;
,,
e
 J
v
1
;
,v,
i
Θ[∗∗]
,,
e
 J
v
1
[∗∗]
,	 ,
,,
i	u2

 J	 J
 J
Θ[]
 J	 J
Θ
 J	 zˆJ r
[∗∗]

,,
e
/s/ J
1 []
,, ,,
e	e
 J  J
v	v
2	1	2
[]	
2
;
,v,
x
 J
3
[∗∗]
,v,
x
 J

/

 ,/›,
x
 J
x	x
 J  J


Fig. 1. The plain and operator dtsi-boxes

Qid = {({(α, κ)}, (α, κ)) | (α, κ) ∈ SIL} is the identity relabeling;
Q(α,κ) = {(∅, (α, κ))} is the constant relabeling identified with (α, κ) ∈ SIL;
Q[f ] = {({(α, κ)}, (f (α), κ)) | (α, κ) ∈ SIL};
Qrs a = {({(α, κ)}, (α, κ)) | (α, κ) ∈ SIL, a, aˆ /α∈};
Qsy a is the least relabeling relation containing Qid s.t. if (Υ, (α, κ)),
(Ξ, (β, λ)) ∈ Qsy a, a ∈ α, aˆ ∈ β then
· (Υ+ Ξ, (α ⊕a β, κ · λ)) ∈ Qsy a, if κ, λ ∈ (0; 1);
· (Υ+ Ξ, (α ⊕a β, κ + λ)) ∈ Qsy a, if κ, λ ∈ N \ {0}.
The plain and operator dtsi-boxes are presented in Figure 1. The label i of internal places is often omitted. ι denotes the numberings of (α, ρ) and (α, l).
An enumeration function can also be defined in accordance with the activity numbering. All transitions maintain their numbering when they are preserved as result of an operation (assuming they are different from each other), and those obtained from synchronization are assigned the concatenation of the parenthesized numberings of the synchronized transitions. The main novelty here is the computa- tion of the probability/weight for the synchronization, so let us see how we compute it. Let Boxdtsi(E)= (PE, TE, WE, ΛE), then Boxdtsi (E sy a)= Θsy a(Boxdtsi (E)).
Now, ∀v, w ∈ TE, s.t.	ΛE(v) = (α, κ), ΛE(w) = (β, λ) and a ∈ α, aˆ ∈ β,
the new transition t resulting from synchronization of v and w has the label Λ(t) = (α ⊕a β, κ · λ), if t is a stochastic transition, or Λ(t) = (α ⊕a β, κ + λ), if t is an immediate one.
By definition of Qsy a, the synchronization is only possible when all the transi- tions in the set are stochastic or when all of them are immediate. If we synchronize the same set of transitions in different orders, we obtain several resulting transitions with the same label and probability or weight, but with the different numberings having the same content. We only consider a single one from the resulting transi- tions in the plain dtsi-box to avoid introducing redundant ones. Let us define the denotational semantics as a homomorphism.



TS(E)
, ),	 ,
N	RG(N )
,,	, ),	 ,

z  s1 J
p1 . e
z  100000 J

∅,1−ρ
, ) s	(  ,
 J
νt1
∅,1−ρ
, )	,	,

  2 J
010000 ( 
	J

∅,1−χ
,χ),χ
,ν,p2
 )
∅,1−χ




({c},l),
,	(	
({e},m),	 J

 l 	t ,  m 

 l   /
  m 
t ,
l+m
  4 l+m

l,+ m/  , , l+m,	ν2	, / , ,  ,

 s4
J s5 J


 000100 J 000010 J

({d},θ), ˆ	ˆ({f },φ),	ˆ	ˆ

 θ  Jz r
z r φ J
 t5 ,θ Jz r
z r t6 ,φ J

∅,1−θ  ∅,1−φ
p3
t /s/ J t
∅,1−θ  ∅,1−φ



,ν,
p4 J
,ν,
p5
 J

t5 ν	νt6

 J,,  J
x p6
 J

Fig. 2. The transition system of E, the marked dtsi-box N = Boxdtsi (E) and its reachability graph for
E = [({a}, ρ) ∗ (({b}, χ); ((({c}, l); ({d}, θ))[](({e}, m); ({f}, φ)))) ∗ Stop]
Definition 4.4 Let (α, κ) ∈ SIL, a ∈ Act and E, F, K ∈ RegStatExpr . The denotational semantics of dtsiPBC is a mapping Boxdtsi from RegStatExpr into the domain of plain dtsi-boxes defined as follows:
Boxdtsi ((α, κ)ι)= N(α,κ)ι ;
Boxdtsi (E ◦ F )= Θ◦(Boxdtsi (E), Boxdtsi (F )), ◦∈ {; , [], };
Boxdtsi (E[f ]) = Θ[f ](Boxdtsi (E));
Boxdtsi (E ◦ a)= Θ◦a(Boxdtsi (E)), ◦∈ {rs, sy};
Boxdtsi ([E ∗ F ∗ K]) = Θ[ ∗∗ ](Boxdtsi (E), Boxdtsi (F ), Boxdtsi (K)).

For E ∈ RegStatExpr , let Boxdtsi (E)= Boxdtsi (E), Boxdtsi (E)= Boxdtsi (E). Let
 denote isomorphism between transition systems and reachability graphs relating their initial states. The names of transitions of the dtsi-box of a static expression could be identified with the enumerated activities of the latter.
Theorem 4.5 For any static expression E, TS (E)  RG(Boxdtsi (E)).
Proof. For the qualitative behaviour, we have the same isomorphism as in PBC. The quantitative behaviour is the same, since the activities of an expression have the probability or weight parts coinciding with the probabilities or weights of the transitions belonging to the corresponding dtsi-box, and we use analogous prob- ability or weight functions to construct the corresponding transition systems and reachability graphs.	2
Example 4.6 Let E be from Example 3.5. In Figure 2, the marked dtsi-box N = Boxdtsi (E) and its reachability graph RG (N ) are depicted. It is easy to see that TS (E) and RG(N ) are isomorphic.

Performance evaluation
Let us see how Markov chains corresponding to the dynamic expressions can be constructed and then used for performance evaluation.
For a dynamic expression G, a discrete random variable is associated with ev- ery tangible state from DR(G). The variable captures a residence time in the state. One can interpret staying in a state in the next discrete time moment as a failure and leaving it as a success of some trial series. It is easy to see that the random variables are geometrically distributed, since the probability to stay in a tangible state s for k − 1 time moments and leave it at the moment k ≥ 1 is PM (s, s)k−1(1 − PM (s, s)) (the residence time is k in this case). The mean value formula for the geometrical distribution allows us to calculate the average sojourn time in a tangible state s as   1   . Obviously, the average sojourn time in a vanishing state is zero. Thus, the average sojourn time in the state s

is SJ (s) = ,⎨
1
1−PM (s,s)
, s ∈ DRT (G);
The average sojourn time vector SJ of G

0,	s ∈ DRV (G).
has the elements SJ (s), s ∈ DR(G). Analogously, the sojourn time variance in

the state s is VAR(s) = ,⎨

PM (s,s) (1−PM (s,s))2
, s ∈ DRT (G);

The sojourn time variance

0,	s ∈ DRV (G).
vector VAR of G has the elements VAR(s), s ∈ DR(G).
To evaluate performance of the system specified by a dynamic expression G, we should investigate the stochastic process associated with it. The process is the underlying semi-Markov chain (SMC), SMC (G), which can be analyzed by ex- tracting from it the embedded (absorbing) discrete time Markov chain (EDTMC) corresponding to G, EDTMC (G). The construction of the latter is similar to that applied in the context of generalized stochastic PNs (GSPNs) in [12]. EDTMC (G) only describes the state changes of SMC (G) while ignoring its time characteristics. Thus, to construct the EDTMC, we should abstract from all time aspects of be- haviour of the SMC, i.e. from the sojourn time in its states. Let G be a dynamic expression and s, s˜ ∈ DR(G).
Let s → s. The probability to stay in s due to k (k ≥ 1) self-loops is (PM (s, s))k. Let s → s˜ and s /=s. ˜The probability to move from s to s˜ by executing any set of activities after possible self-loops is
∗	 PM (s, s˜) Σ∞ (PM (s, s))k =  PM (s,s˜)  , s → s;
PM (s, s˜),	otherwise;
Notice that PM ∗(s, s˜) defines a probability distribution, since ∀s ∈ DR(G), s.t.
s is not a terminal state, we have	PM ∗(s, s˜)= 
	1	 Σ{s˜|s→s˜, s/=s˜} PM (s, s˜)= 	1	 (1 − PM (s, s)) = 1.
Definition 5.1 Let G be a dynamic expression. The embedded (absorbing) discrete time Markov chain (EDTMC) of G, EDTMC (G), has the state space DR(G), the

initial state [G]≈ and the transitions s →P
PM ∗(s, s˜).
s˜, if s → s˜ and s /=s, ˜where P =



SMC (E)
,	 ,
SMC (N )
,	 ,

s1 1
	
1
100000 

Jρ	Jρ

, ) s2 (χ

, , ) 010000 (χ	,

	J

0
 l  /	 m 
	J

0
 l  /	 m 

,l+m/	 l+m	,l+m/	 l+m


	
1  s4	s5  1
1 000100	000010  1

θ	J	Jφ	θ	J	Jφ

 1 J	 1
J 1
J	 1 J


	
Fig. 3. The underlying SMCs of E and N = Boxdtsi(E) for E = [({a}, ρ) ∗ (({b}, χ); ((({c}, l);
({d}, θ))[](({e}, m); ({f}, φ)))) ∗ Stop]

Let G be a dynamic expression. The elements P∗
(1 ≤ i, j ≤ n = |DR(G)|) of

the transition probability matrix (TPM) P∗ for EDTMC (G) are defined as P∗ =
PM ∗(si, sj ), si → sj , si /= sj ; 0,	otherwise.
The transient (k-step, k ∈ N) probability mass function (PMF) ψ∗[k] = (ψ∗[k](s1),..., ψ∗[k](sn)) for EDTMC (G) is a solution of the equation system ψ∗[k] = ψ∗[0](P∗)k, where ψ∗[0] = (ψ∗[0](s1),..., ψ∗[0](sn)) is the initial PMF

defined as ψ∗[0](s )=	1, si = [G]≈;
0, otherwise.
Note that ψ∗[k + 1] = ψ∗[k]P∗ (k ∈ N).

The steady-state PMF ψ∗ = (ψ∗(s1),..., ψ∗(sn)) for EDTMC (G) is a solution of the equation system ψ∗ (P∗ − I)= 0 , where I is the identity matrix of size n and
0 is a row vector with n values 0, 1 is that with n values 1. When EDTMC (G) has a single steady state, we have ψ∗ = limk→∞ ψ∗[k].
The steady-state PMF for the underlying semi-Markov chain SMC (G) is calcu- lated via multiplication of every ψ∗(si) (1 ≤ i ≤ n) by the average sojourn time SJ (si) in the state si, after which we normalize the resulting values. Remember that for a vanishing state s ∈ DRV (G) we have SJ (s) = 0. Thus, the steady-state PMF ϕ = (ϕ(s1),..., ϕ(sn)) for SMC (G) is

  Σ ψ∗ (si )SJ (si )
, s ∈ DR
(G);

0,	si ∈ DRV (G).
Example 5.2 Let E be from Example 3.5. In Figure 3, the underlying SMC SMC (E) is presented. The average sojourn time in the states of the underlying SMC is written next to them in bold font.
Let G be a dynamic expression and s, s˜ ∈ DR(G), S, S ⊆ DR(G). Standard
performance indices (measures) can be calculated based on ϕ [6, 15]:
The average recurrence (return) time in the state s (the number of discrete time units required for this) is  1  .
The fraction of residence time in the state s is ϕ(s).
The fraction of residence time in the set of states S ⊆ DR(G) or the probability of the event determined by a condition that is true for all states from S is	s∈S ϕ(s).
The relative fraction of residence time in the set of states S with respect to that

Σ	ϕ(s)
in S is	s∈S	 .
s˜∈S˜ ϕ(s˜)
The rate of leaving the state s is ϕ(s) .
The steady-state probability to perform a step with an activity (α, κ) is
s∈DR(G) ϕ(s)	{Υ|(α,κ)∈Υ} PT (Υ, s).
The probability of the event determined by a reward function r on the states is
s∈DR(G) ϕ(s)r(s).
Let N = (PN , TN , WN , ΩN , LN , MN ) be a LDTSIPN and M, M ∈ NPN . Then
the average sojourn time SJ (M ), the sojourn time variance VAR(M ), the proba- bilities PM∗(M, M ), the transition relation M →P M , the EDTMC EDTMC (N ), the underlying SMC SMC (N ) and the steady-state PMF for it are defined like the corresponding notions for dynamic expressions.
As we have mentioned earlier, every marked plain dtsi-box could be interpreted as the LDTSIPN. Therefore, we can evaluate performance with the LDTSIPNs corresponding to dtsi-boxes and then transfer the results to the latter. Let  denote isomorphism between SMCs that binds their initial states.
Proposition 5.3 For any static expression E

SMC (E)  SMC (Boxdtsi(E)).
Proof. By Theorem 4.5, definitions of underlying SMCs for dynamic expressions and LDTSIPNs, and the following. For the associated SMCs, the average sojourn time in the states is the same since it is defined via the analogous probability functions. The transition probabilities of the associated SMCs are the sums of those belonging to transition systems or reachability graphs.	2
Example 5.4 Let E be from Example 3.5. In Figure 3, the underlying SMC SMC (N ) is presented. Clearly, SMC (E) and SMC (N ) are isomorphic. Thus, both the transient and steady-state PMFs for SMC (N ) and SMC (E) coincide.
Shared memory system
We now demonstrate how steady-state probability mass function (PMF) is used for performance evaluation, with the shared memory system case study. This illus- trative example demonstrates our modeling and analysis technique. More complex systems can be easily constructed with the flexible and powerful operations of dt- siPBC, taking advantage of the algebraic compositionality.
Consider a model of two processors accessing a common shared memory in the continuous time setting on GSPNs [13]. We shall analyze this shared memory sys- tem in the discrete time stochastic setting of dtsiPBC, where concurrent execution of activities is possible. The model works as follows. After activation of the system (turning the computer on), two processors are active, and the common memory is available. Each processor can request an access to the memory after which the in- stantaneous decision is made. When the decision is made in favour of one processor,

Processor 1
Memory
Processor 2



Fig. 4. The diagram of the shared memory system


it starts acquisition of memory, the other processor must therefore wait until the first one terminates its memory operations, the system then returning to a state in which memory is available and both processors are active. The diagram of the system is in Figure 4.
Let us explain the meaning of actions from the dtsiPBC expressions specifying the system modules. Action a corresponds to system activation. Actions ri (1 ≤ i ≤ 2) represent the common memory request of processor i. Instantaneous actions di correspond to the decision on the memory allocation in favour of processor i. Actions mi represent the common memory access of processor i. The other actions are used for communication purposes only via synchronization, so we will abstract from them by using the restriction.
The static expression of the first processor is
E1 = [({x1}, 1 ) ∗ (({r1}, 1 ); ({d1, y1}, 1); ({m1, z1}, 1 )) ∗ Stop].
2	2	2
The static expression of the second processor is
E2 = [({x2}, 1 ) ∗ (({r2}, 1 ); ({d2, y2}, 1); ({m2, z2}, 1 )) ∗ Stop].
2	2	2
The static expression of the shared memory is
E = [({a, x , x }, 1 ) ∗ ((({y }, 1); ({z }, 1 ))[](({y }, 1); ({z }, 1 ))) ∗ Stop].

3	^1 ^2	2	^1
^1	2	^2
^2	2

The static expression of the shared memory system with two processors is
E = (E1  E2  E3) sy x1 sy x2 sy y1 sy y2 sy z1 sy z2 rs x1 rs x2 rs y1 rs y2 rs z1 rs z2.
Let us illustrate an effect of synchronization. The result of synchronization of immediate multiactions ({di, yi}, 1) and ({yi}, 1) is ({di}, 2) (1 ≤ i ≤ 2). The synchronization of stochastic multiactions ({m ,z }, 1 ) and ({z }, 1 ) produces

i	i	2
1
1^i	2	1

({mi}, 4 ) (1 ≤ i ≤ 2). The result of synchronization of ({a, x1, x2}, 2 ) with ({x1}, 2 )
is ({a, x }, 1 ), and that of ({a, x , x }, 1 ) with ({x }, 1 ) is ({a, x }, 1 ). After ap-

^2	4
^1 ^2	2
2	2	^1	4

1 ^2	4	1 2	2
^1	4

({x1}, 2 ), we obtain the same activity ({a}, 8 ).
DR(E) consists of 9 equivalence classes s1,..., s9, interpreted as follows: s1 is the initial state, s2: the system is activated and the memory is not requested, s3: the memory is requested by the first processor, s4: the memory is requested by the second processor, s5: the memory is allocated to the first processor, s6: the memory is requested by two processors, s7: the memory is allocated to the second processor, s8: the memory is allocated to the first processor and the memory is requested by the second processor, s9: the memory is allocated to the second processor and the memory is requested by the first processor. We have DRT (E)= {s1, s2, s5, s7, s8, s9} and DRV (E)= {s3, s4, s6}.



TS(E)
,		,
2	s	2

{({r1}, 1 ),
({m2 }, 1 )}, 1
{({r2 }, 1 ),
1	({m1 }, 1 )}, 1

z¬zz 4	8
J 4  8 

z	∅, 7
({a}, 1 ), 1

\’ `	zzz8 zˆr	8 8 
/’ /´

\	zz z 
/ //

({d1 },2),1	\
zzzz / /
({d2 },2),1

\	({r1 }, 1 ), 1
/z
({r2 }, 1 ), 1	z/

,v  \
2 4 v
2 4/
/ zz,z	v	,

,	,	,
,)	(  ,

z 	s
	\	)	s	(	/
s	  r

∅, 3
8
\
1   1	 1
2	J//
7	∅, 3
8
1 1

({m1 }, 4 ), 8
zz∅, 4zzˆr
({m2 }, 4 ), 8

z z 

({r }, 1
z	({r }, 1 ), 3

2 2	zz
1 2 8

m }, 1 ), 1
{({r1 }, 1 ),({r2 }, 1 )}, 1 z
({m }, 1 1

1 4 4 
2	2  4
zz 2 4 ), 4

,	v
,)	1
z
,
1	(  ,

z 3	 s8 
(({d1 },2), 2  	s6
({d2 },2), 2 )
 s9 
  r
∅, 3

4	J	J4
Fig. 5. The transition system of the shared memory system

SMC (E)
,		,

0	z¬z  1
s1	8	1	0

` zz5	J 5 
\’	zzz	1	/’
\	zz z	/
1	\\	zzz	/	/
z/zz /

v    \	 1
4  1 /	/zz

,	,\
\
 3,v3
3, /	,
/

8	s	\ )	s	( /	s	8

5  5	J1
5

3
5
\
  2	J/

zz
1   7	J5
5

3
5

1 
,v	1
zz  1
v	,
0	1

4	 s8  (	2
2	)	 s9 	4

J	J

Fig. 6. The underlying SMC of the shared memory system

In Figure 5, the transition system TS(E) is presented. In Figure 6, the under- lying SMC SMC (E) is depicted.

3	5	5

⎛ 0 1 0 0 0 0 0 0 0 ⎞
25	25

0 0 1 1	1 0 0 0

The TPM for EDTMC (E) is P∗ =	0 1	1 0 0 0 3 0	.
⎜ 0 0 0 0 0 0 0 1 1 ⎟
⎜	2 2 ⎟
0 0 0 1 0 0 0 0 0
0 0 1 0 0 0 0 0 0
In Table 4, the transient and the steady-state probabilities ψ∗[k] (i  ∈
{1, 2, 3, 5, 6, 8}) for the EDTMC of the shared memory system at the time mo- ments k (0 ≤ k ≤ 10) and k = ∞ are presented, and in Figure 7, the evolution

Table 4
Transient and steady-state probabilities for the EDTMC of the shared memory system



Fig. 7. Transient probabilities alteration diagram for the EDTMC of the shared memory system

in time for the transient probabilities is depicted. It is sufficient to consider the probabilities for the states s1, s2, s3, s5, s6, s8 only, since the corresponding values coincide for s3, s4, as well as for s5, s7, and for s8, s9.



The steady-state PMF ψ∗ weighted by SJ is 0,  1 44
88 88
3

88 , 44 , 88 44 44

It remains to normalize the steady-state weighted PMF dividing it by the sum of its components ψ∗SJT = 17 . Thus, the steady-state PMF for SMC (E) is
ϕ = 0,  1 , 0, 0,  3 , 0,  3 , 511 5 . We now calculate some performance indices.
The average recurrence time in the state s2, where no processor requests the

memory, called the average system run-through, is  1
2
= 17.

The common memory is available only in the states s2, s3, s4, s6. The steady-state
probability for the memory to be available is ϕ2+ϕ3+ϕ4+ϕ6 =  1 +0+0+0 =  1 .
17	17
The steady-state probability for the memory to be used (i.e. not to be available),
called the shared memory utilization, is 1 −  1	16

N1	N3
,,	,,
N2	N
,,	,,,,,,

. e	. e
. e	. e . e . e

 J	 J
 J	 J J/ J

v	v
({a,x^1,x^2 }, 1 )

,)
v

,v,
(



 ,)

 
/
,,
v/s
 
 ,,
(

 J	 J
v	v
 J	 J
v	v



,v,
 J
,v,
/ J
,v,
 J
,v,,v,,v,
  J/ J J

/s
({y1 },1)
v,	,v,
ˆˆ 
({y2},1)
,v,


/r/


\\f
ˆˆ

/r/


\\f


 J	 J	 J	 J
,,,,,,,,
 J J J J


(
v

)

(
v
)
\
(
/r/	\
)	(
/r/
)


							
x	x	x	x	x	x
 J	 J	 J	 J J J

Fig. 8. The marked dtsi-boxes of two processors, shared memory and the shared memory system
After activation of the system, we leave the state s1 for ever, and the common memory is either requested or allocated in every remaining state, with exception of s2. Thus, the rate of emerging the shared memory necessity coincides with the

rate of leaving s2, calculated as  ϕ2  =  1
· 3 =  3 .

SJ 2	17  4	68
The common memory request of the first processor ({r1}, 1 ) is only possible from the states s2, s7. At both states, the request probability is the sum of the execution probabilities for all sets of activities containing ({r1}, 1 ). The steady-state probability of the shared memory request from the ﬁrst processor is

ϕ2 Σ
1	PT (Υ,s2)+ϕ7 Σ
1	PT (Υ,s7)=  1 ( 1 + 1 )+  3 ( 3 + 1 )=  2 .

{Υ|({r1}, 2 )∈Υ}
{Υ|({r1}, 2 )∈Υ}
17 4  4
17 8  8	17

In Figure 8, the marked dtsi-boxes corresponding to the dynamic expressions of two processors, shared memory and the shared memory system are presented, i.e. Ni = Boxdtsi(Ei) (1 ≤ i ≤ 3) and N = Boxdtsi(E).
7	Conclusions
We have proposed a discrete time stochastic extension dtsiPBC of a finite part of PBC enriched with iteration and immediate multiactions. The calculus is equipped with a step operational semantics based on labeled probabilistic transition systems and a denotational semantics in terms of a subclass of LDTSIPNs. A method of performance evaluation in the framework of the calculus has been presented applied to the shared memory system case study.
The advantage of our framework is twofold. First, one can specify in it concur- rent composition and synchronization of (multi)actions, whereas this is not possible in classical Markov chains. Second, algebraic formulas represent processes in a more compact way than PNs and allow one to apply syntactic transformations and comparisons. Process algebras are compositional by definition and their operations

naturally correspond to operators of programming languages. Hence, it is much easier to construct a complex model in the algebraic setting than in PNs. The com- plexity of PNs generated for practical models in the literature demonstrates that it is not straightforward to construct such PNs directly from the system specifications. Strong points of dtsiPBC are the multiaction labels, immediate multiactions, pow- erful operations, a step operational and a Petri net denotational semantics allowing for concurrent execution of activities (transitions), as well as analytical performance evaluation. dtsiPBC is well suited for the discrete time applications, such as busi- ness processes, neural and transportation networks, computer and communication systems, whose discrete states change with a global time tick, as well as for those, in which the distributed architecture or the concurrency level should be preserved while modeling and analysis (remember that, in step semantics, we have additional transitions due to concurrent executions).
Our future work will consist in constructing a congruence for dtsiPBC, i.e. the equivalence withstanding application of all operations of the algebra. The first candidate is a stronger version of step stochastic bisimulation equivalence defined via transition systems equipped with two extra transitions skip and redo, like in [3]. We also plan to extend the calculus with deterministically timed multiactions having a fixed time delay (including the zero one which is the case of immediate multiactions) to enhance expressiveness of the calculus and to extend the application area of the associated analysis techniques. Further, recursion may be added to dtsiPBC to increase its specification power.

References
Bernardo, M. and R. Gorrieri, A tutorial on EMPA: a theory of concurrent processes with nondeterminism, priorities, probabilities and time, Theor. Comput. Sci. 202 (1998), pp. 1–54.
Best, E., R. Devillers and J. G. Hall, The box calculus: a new causal algebra with multi-label communication, Lect. Notes Comp. Sci. 609 (1992), pp. 21–69.
Best, E., R. Devillers and M. Koutny, “Petri net algebra,” EATCS Monographs on Theor. Comput. Sci., Springer Verlag, 2001.
Hermanns, H. and M. Rettelbach, Syntax, semantics, equivalences and axioms for MTIPP, in: Proc. of 2nd Workshop on PAPM, number 27 in Arbeitsberichte des IMMD (1994), pp. 71–88.
Hillston, J., “A compositional approach to performance modelling,” Cambridge University Press, Great Britain, 1996.
Katoen, J.-P., Quantinative and qualitative extensions of event structures, CTIT Ph. D.-thesis series 96-09, CTIT, University of Twente, Enschede, The Netherlands (1996).
Koutny, M., A compositional model of time Petri nets, Lect. Notes Comp. Sci. 1825 (2000), pp. 303– 322.
Maci`a, H., V. Valero, F. Cuartero and M. C. Ruiz, sPBC: a Markovian extension of Petri box calculus with immediate multiactions, Fundamenta Informaticae 87 (2008), pp. 367–406.
Maci`a, H., V. Valero and D. de-Frutos, sPBC: a Markovian extension of finite Petri box calculus, in:
Proc. of 9th IEEE International Workshop on PNPM (2001), pp. 207–216.
Markovski, J. and E. P. de Vink, Performance evaluation of distributed systems based on a discrete real- and stochastic-time process algebra, Fundamenta Informaticae 95 (2009), pp. 157–186.

Marroqu´ın, O. and D. de-Frutos, Extending the Petri box calculus with time, Lect. Notes Comp. Sci.
2075 (2001), pp. 303–322.
Marsan, M. A., Stochastic Petri nets: an elementary introduction, Lect. Notes Comp. Sci. 424 (1990),
pp. 1–29.
Marsan, M. A., G. Balbo, G. Conte, S. Donatelli and G. Franceschinis, “Modelling with generalized stochastic Petri nets,” John Wiley and Sons, 1995.
Molloy, M. K., Discrete time stochastic Petri nets, IEEE Transactions on Software Engineering 11
(1985), pp. 417–423.
Mudge, T. N. and H. B. Al-Sadoun, A semi-Markov model for the performance of multiple-bus systems, IEEE Transactions on Computers C-34 (1985), pp. 934–942.
Niaouris, A., An algebra of Petri nets with arc-based time restrictions, Lect. Notes Comp. Sci. 3407
(2005), pp. 447–462.
Tarasyuk, I. V., Stochastic Petri box calculus with discrete time, Fundamenta Informaticae 76 (2007),
pp. 189–218.
van Glabbeek, R. J., S. A. Smolka and B. Steffen, Reactive, generative, and stratified models of probabilistic processes, Information and Computation 121 (1995), pp. 59–80.
