

Electronic Notes in Theoretical Computer Science 267 (2010) 29–42
www.elsevier.com/locate/entcs

Abstract Fixpoint Computations with Numerical Acceleration Methods
Olivier Bouissou1 and Yassamine Seladji2
CEA, LIST, Laboratory for the Modeling and Analysis of Interacting Systems 91191 Gif-sur-Yvette, France
Alexandre Chapoutot3
Universit´e Pierre et Marie Curie, LIP6 – Paris, France

Abstract
Static analysis by abstract interpretation aims at automatically proving properties of computer programs. Basically, an over-approximation of program semantics, defined as the least fixpoint of a system of semantic equations, must be computed. To enforce the convergence of this computation, widening operator is used but it may lead to coarse results. We propose a new method to accelerate the computation of this fixpoint by using standard techniques of numerical analysis. Our goal is to automatically and dynamically adapt the widening operator in order to maintain precision.
Keywords: Abstract numerical domains, acceleration of convergence, widening operator.


Introduction
In the field of static analysis of embedded numerical programs, abstract interpreta- tion [8,10] is widely used to compute over-approximations of the set of behaviors of programs. This set is usually defined as the least fixpoint of a monotone map on an abstract domain given by the (abstract) semantics of the program. Using Tarski’s theorem [22], this fixpoint is computed as the limit of the iterates of an abstract function starting from the least element. These iterates build a sequence of abstract elements that (order theoretically) converges towards the least fixpoint. Since this sequence may converge slowly (or only after infinitely many steps), the theory of abstract interpretation introduces the concept of widening [10].

1 Email: olivier.bouissou@cea.fr
2 Email: yassamine.seladji@cea.fr
3 Email: alexandre.chapoutot@lip6.fr


1571-0661 © 2010 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2010.09.004

A widening operator is a two-argument function ∇ which tries to predict the limit of the iterates based on the relative position of two consecutive iterates. For example, the standard widening operator on the interval abstract domain consists in comparing the limits of the intervals and setting the unstable ones to ∞ (or −∞). A widening operator often makes large over-approximation because it must make the sequence of iterates converge in a finite time. Over-approximation may be reduced afterward using a narrowing operator but the precision of the final approximation still strongly depends on the precision of ∇. Various techniques have been proposed to improve it. Delayed widening makes use of ∇ after n iteration steps only (where n is a user-defined integer), thus letting the first loop iterates execute before trying to predict the limit. The delay parameter n usually has to be defined a priori. Another approach is to use a widening with thresholds [2]: the upper bound of the interval (for example) is not directly set to ∞, but is successively increased using a set of thresholds that are candidates for the value of the fixpoint upper bound. In practice, these techniques are necessary to obtain precise fixpoint approximations for industrial-sized embedded programs. However, they suffer from their lack of automatization: thresholds must be chosen a priori and are defined by the user. Some methods try to automatically discover thresholds from the program [16,21]: whenever an inequality (e.g. the condition of a loop) is found, a threshold (or landmark in [21]) is added, its value depending on the constants appearing in the inequality. So the thresholds are based on a syntactic criterion; in our work we define thresholds using the dynamics of the program variables. As a consequence, the use of a static analyzer is difficult as these (non-trivial) parameters are often hard to find.
In this article, we present some ongoing work which shows that it is possible to use sequence transformation techniques in order to automatically and efficiently derive an approximation to the limit of Kleene iterates. This approximation may not be safe (i.e. may not contain the actual limit), but we show how to use it in the sense of abstract interpretation. Sequence transformation techniques (also known as convergence acceleration methods) are widely studied in the field of numerical analysis [5]. They transform a converging sequence (xn)n∈N of real numbers into a new sequence (yn)n∈N which converges faster to the same limit (see Section 3.2). In some cases (depending on the method), the acceleration is such that (yn)n∈N is ultimately constant. Some recent work [7] applied these techniques in the case of sequences of vectors of real numbers: vector sequence transformations introduce relations between elements of the vector and perform better than scalar ones. Our main contribution is to show that we can use these methods in order to improve the fixpoint computation in static analysis: we define dynamic thresholds for widen- ing that are very close to the actual fixpoint. This increased precision is obtained because sequence transformations use all iterates and quantitative information (i.e. relative to the distance between elements) to predict the limit. They thus exploit more information than the widening and make a better prediction. In this work, we focus on the interval domain, but we believe that this work may be applied to any abstract domain, especially the ones with a pre-deﬁned shape (octagons [18],


1
2
3
4
5
6

Fig. 1. A simple linear program.
templates [20], etc.). Let us remark that our techniques are well-suited for acceler- ating the invariant generation of numerical programs with floating-point variables and that we do not address the case of integer variables as in [11,17].
This article is organized as follows. In Section 2, we explain on a simple example how acceleration methods may be used to speed-up the fixpoint computation. In Section 3, we recall the theoretical basis of this work and present our main theoret- ical contribution in Section 4. Section 5 presents some early experiments on various floating-point programs that show the interest of our approach, while Sections 6 and 7 discuss related works and perspectives.
Notations. In the rest of this article, (xn) will denote a sequence of real numbers (i.e.  (xn) ∈ RN), while (xn) denotes a sequence of vector of real numbers (i.e.
(xn) ∈  Rp  for some p ∈ N). The symbol X  will be used to represent abstract
N
iterates, i.e. Xn ∈ A for some abstract lattice A.

An introductive example
In this section, we explain, using a simple example, how sequence acceleration tech- niques can be used in the context of static analysis. In short, our method works as follows: let (Xn) be a sequence of intervals computed by the Kleene iteration and that is chosen to be widened (see [4] for details on how to choose the widening points). From (Xn) we extract a vector sequence (xn): at stage k, xk is a vector that contains the infimum and supremum of each variable of the program. As Kleene iteration converges towards the least fixpoint of the abstract transfer function, the sequence (xn) converges towards a limit x which is the vector containing the infi- mum and the supremum of this fixpoint. We then compute an accelerated sequence (yn) that converges towards x faster than (xn). Once this sequence has reached its limit (or is sufficiently close to it), we use x as a threshold for a widening on (xn) and thus obtain, in a few steps, the least fixpoint. In the rest of this section, we detail these steps.
The program. We consider a linear program which iterates the function F (X)= A · X + B · U where A, B and U are constant matrices and X is the vector of vari- ables (see Figure 1). Initially, we have x1 ∈ [1, 2], x2 ∈ [1, 4], x3 ∈ [1, 20], u1 ∈
[1, 6], u2 ∈ [1, 4] and u3 ∈ [1, 2]. Using an interval analysis, we showed that this program converges in 55 iterations (without widening) and obtained the invariant [−5.1975, 8.8733] for x1 at line 2.
Extracting the sequence. From this program, we can define a vector sequence


	
5	10	15	20	25	30	5	10	15	20	25	30
Fig. 2. Sequences extracted from the program of Figure 1 and their accelerated version.


of size 6, xn =  x1 , x1 , x2 , x2 , x3 , x3 , which represents the evolution of the
n	n	n	n	n	n
		
supremum and the infimum of each variable x1, x2 and x3 at line 2. For example,
the sequence (x1 ) is recursively defined by:



x1	= max x1 , −0.4375 ∗ x1 + 0.0625 ∗ x2 + 0.2652 ∗ x3 + 0.1 ∗ u1  .	(1)

Note that we are not interested in the formal definition of these sequences (as given by Equation (1)), but only in their numerical values that are extracted from
Kleene iterates. Each sequence (xi ) (resp. (xi )) is increasing (resp. decreasing)
n	 n
and the sequence (xn) converges towards a vector x containing the infima and
the suprema of the fixpoint (see Figure 2, dotted lines).
Accelerating the sequence. We then used the vector ε-algorithm [7] to build a new sequence that converges faster towards x. This method works as follows (a more formal definition will be given in Section 3.2): it computes a series of
sequences (εk ) for k = 1, 2,... such that each sequence (εk ) for k even converges
n	n
towards s and the diagonal (dn)= (ε2n) also converges towards s. This diagonal
sequence is the result of the ε-algorithm and it is called the accelerated sequence. It converges faster than the original sequence: in only 8 iterates (which require 16 iterates of the original sequence, as will be explained later), it reached the fixpoint and stayed constant (see Figure 2, bold lines).
Using the accelerated sequence. When the accelerated sequence reaches the limit (or is sufficiently close to it), we modify the Kleene iteration and directly jump to the limit. Formally, if the limit is (x1, x1, x2, x2, x3, x3) and if the cur- rent Kleene iterate is Xp, we construct the abstract element X whose bounds are x1, x1,... and set Xp+1 = Xp ∪ X and re-start Kleene iteration from Xp+1. In this way, we remain sound (Xp ⊆ Xp+1) and we are very close to the fixpoint, as X ⊆ Xp+1. In this example, Kleene iteration stopped after 2 steps and reached the same fixpoint as the one obtained without widening and acceleration. Fig- ure 3 shows the original Kleene iteration and the modified one, for the infimum of variable x1. Let us recall that the Kleene iteration needed 55 steps to converge, where the modified iteration stops after 18 steps.



5	10	15	20	25
Fig. 3. Infimum value of x1. We only display the iterates 5 to 25. At the 15th iteration, the accelerated value is used as a widening with thresholds, and the iteration stops after 18 steps.

Theoretical frameworks
In this section, we briefly recall the basics of abstract interpretation, with an em- phasis on the widening operator. Next, we present the theory of sequence transfor- mations in more details.

Overview of abstract interpretation theory
Abstract interpretation is a general method to compute over-approximations of program semantics defined by a monotone semantic function F . The two key ideas are:
Safe abstractions of sets of states based on, in the more general framework [9, Sect. 7], concretization functions. More precisely let ⟨C, ±C ⟩ be the lattice of con- crete states and let ⟨A, ±A⟩ be the lattice of abstract states. The concretization function is a monotonic map γ : A → C. We consider x ∈ A as a safe abstraction of y ∈ C if y ±C γ(x).
Moreover, the abstract monotone semantic function F is a safe abstraction of F
iff ∀x ∈ A, F (γ(x)) ±C γ(F (x)).
An effective computation method using a widening operator when abstract se- mantics are based on infinite height lattices. The abstract program semantics is a set of states X of a lattice ⟨A, ±A⟩ such that X = F (X). The solution X is iteratively constructed by Xi+1 = Xi H F (Xi), starting from X0 = ⊥. The value ⊥ and the operation H denote the smallest element and the join operation of A respectively. The sequence (Xn) defines an increasing chain of elements of
A. This chain may be infinite, so to enforce the convergence of this sequence, we substitute the operator H by a widening operator ∇, see Definition 3.1, that is an over-approximation of H.
Definition 3.1 (Widening operator [8]) Let ⟨A, ±A⟩ be a lattice. The map ∇ : A × A → A is a widening operator iff i) ∀v1, v2 ∈ A, v1 H v2 ±A v1∇v2. ii) For each increasing chain v0 ±A ··· ±A vn ±A ··· of A, the increasing chain deﬁned by s0 = v0 and sn = sn−1∇vn is stationary: ∃n0, ∀n1, n2, (n2 > n1 > n0) ⇒ sn1 = sn2 .

The widening operator plays an important role in static analysis because it allows to consider infinite state spaces where the ascending chain condition is not satisfied. Many abstract domains are thus associated with a widening operator; for the interval domain, for example, it is usually defined by:


[a, b]∇[c, d]=	a	if a ≤ c
−∞  otherwise
,	b	if b ≥ d
+∞  otherwise

Note that we only consider two consecutive elements to extrapolate the potential fixpoint. The main drawback with this widening is that it may generate too coarse results by quickly going to infinity. A solution of this is to add intermediate steps among a finite set T ; that is the idea behind the widening with thresholds ∇T . For the interval domain, it is defined [3] by:


[a, b]∇ [c, d]=	a	if a ≤ c
max{t ∈ T : t ≤ c}  otherwise
,	b	if b ≥ d
min{t ∈ T : t ≥ d}  otherwise

While widening with thresholds gives better results, we are facing with the problem to define a priori the set T . Finding relevant values for T is a difficult task for which only syntactic-based techniques exist [16,21].

Acceleration of convergence
We give an overview of the techniques of acceleration of convergence in numerical analysis (for more details, we refer to [5]). The goal of convergence acceleration techniques, also named sequence transformations, is to increase the rate of conver- gence of a sequence. Formally, let D, d be a metric space, i.e. a set D with a distance d : D → R+ (D will be R or Rp for some p ∈ N). The set of sequences over D (denoted DN) is the set of functions between N and D. A sequence (xn) ∈ DN converges to l iff we have limn→∞ d(xn, l)= 0. A sequence transformation is a func- tion T : DN → DN (T designs a particular acceleration method) such that whenever (xn) converges to l then (yn)= T (xn) also converges to l and limn→∞ d(yn,l) = 0. This means that (yn) is asymptotically closer to l than (xn). An important notion for a sequence transformation T is its kernel KT which is the set of sequences (xn) for which T (xn) is ultimately constant. We now present some acceleration methods that we used in our experimentation.

The Aitken Δ2-method
It is probably the most famous sequence transformation. Given a sequence (xn) ∈ RN, the accelerated sequence (yn) is defined by: 6n ∈ N, yn = xn —   xn+1−xn	 . It should be noted that in order to compute yn for some n ∈ N, three values of (xn) are required: xn, xn+1 and xn+2. The kernel KΔ2 of this method is the set of all sequences of the form xn = s + a.λn where s, a and λ are real constants such that a /= 0 and λ /= 1 (see [6]). The Aitken Δ2-method is an efficient method for accelerating sequences, but it highly suffers from numerical instabilities when xn, xn+1 and xn+2 are close to each other.

The ε-algorithm
It is often cited as the best general purpose sequence transformation for slowly converging sequences [23]. From a converging sequence (xn) ∈ RN with limit l, the ε-algorithm builds the following sequences:

(ε−1): ∀n ∈ N, ε−1 = 0,	(2)
n	n
(ε0 ): ∀n ∈ N, ε0 = xn,	(3)
n	n
(εk ): ∀k ≥ 1, ∀n ∈ N, εk+1 = εk−1 +  εk	− εk −1	(4)
For a fixed k, the sequence ((εk )n∈N) is called the k-th column, and its construction can be graphically represented as on Figure 4. The even columns (ε2k) (in gray on Figure 4) converge faster to l. The even diagonals ((ε2k)k∈N) also converges faster to l. In particular, the first diagonal (circled in Figure 4) converges very quickly to l, and it is the accelerated sequence. Let us remark that in order to compute the p-th element of that sequence, (2p — 1) elements of (xn) are required, as stated by Proposition 3.2.
Proposition 3.2 Let ((SI )n) be a sequence and let ((SA)n)= (ε2n) its accelerated version given by the ε-algorithm. Then the p-th element of ((SA)n) is deﬁned by 2p — 1 elements of ((SI )n).
Proof. We call G(n, k) the number of elements from ((SI )n) required to compute
the element εk of indices n and k in the ε-algorithm. By construction, we have:

6k ≥ 1, 6n ∈ N, εk+1 = εk−1 + εk
— εk −1 so G(n, k + 1) = max G(n +

n	 n+1

n+1	n

k, so G(n, k + 1) = G(n + 1, k).  Thus, we define the function G by: G(n, k) = 

n +1	if k =0 
G(n + 1,k − 1)  otherwise
.	Moreover following the ε-algorithm, we know that (SA)p,

the element of index p in ((SA)n), i.e. the (p + 1)-th element, is ε2p. We easily prove
by recurrence that 6p ∈ N, G(0, 2p)= 2p + 1.
G(0, 2p) = G(1, 2p − 1)
= G(1 + 2p − 1, 0) (By recurrence on: G(n,k)=G(n+k,0))
= G(2p, 0) = 2p +1 
So, to have the element (SA)p, we need (2p + 1) elements from ((SI )n). We know that the element (SA)p is the (p + 1)-th element of ((SA)n). So, to obtain p elements of ((SA)n), 2p — 1 elements of ((SI )n) are required.	2
Acceleration of vector sequences
Many acceleration methods were designed to handle scalar sequences of real num- bers. For almost each of these methods, extensions have been proposed to handle vector sequences (see [15] for a review of them). The simplest, yet one of the most powerful, of these methods is the vector ε-algorithm (VEA). Note that, in this article, we only consider VEA for the acceleration method of vector sequences. Given a vector sequence (xn), the VEA computes a series of vector sequences (εk ) using Equations (2)-(4) where the arithmetic operations + and — are computed


0
Arrows depict dependencies: the element at the beginning of the arrow is required to compute the element at the end. For example, the second element of the accel- erated sequence is:
ε2 = ε0 +  1

0
ε3	0	1	ε1 − ε1

1	0
0	1
.	= x1 + ε−1 +   1   − ε−1 +   1 
.	2	ε0 −ε0	1	ε0 −ε0
.	2  1	1  0
1

.
. .	= x1 +   1   −   1 

.
.	x2 −x1	x1 −x0


Fig. 4. The ε-table
component-wise and the inverse of a vector v is computed as v−1 = v/(v · v), with
/ being the component-wise division and · the scalar product. The VEA differs from a component-wise application of the (scalar) ε-algorithm as it introduces relations between the components of the vector: the scalar product v · v computes a global information on the vector v which is propagated to all components. Our exper- iments show that this algorithm works better than a component-wise application of the ε-algorithm. The kernel Kε of the VEA contains all sequences of the form xn+1 = Axn + B, where A is a constant matrix and B a constant vector [7].

Accelerated Kleene iteration
In this section, we combine acceleration methods with the abstract fixpoint com- putation. Our goal is to be as non-intrusive as possible in the classical iterative scheme. In this way, our method can be implemented with minor adaptations in current static analyzers.

Methodology
As seen in Section 3.1, the Kleene iteration for finding the least fixpoint is based on abstract values from some abstract lattice A. In order to use acceleration techniques on the abstract iterates, we need to extract a vector of real numbers from the abstract elements Xn ∈ A. We obtain a sequence of real vectors that we can accelerate, and we quickly reach its limit. We then construct an abstract element X that corresponds to this limit and use it as a candidate for the least fixpoint. This process of transforming an abstract value into a real vector and back is formalized by the notion of extraction and combination functions that are given in Definition 4.1.
Definition 4.1 [Extraction and combination.] Let ⟨A, ±A⟩ be an abstract domain, and let p ∈ N. The functions ΛA : A → Rp and ΥA : Rp → A are called extraction and combination function, respectively, iff for each sequence Xn ∈ AN that order
theoretically converges, i.e. Hn∈NXn = X for some X ∈ A, then the sequence

ΛA(Xn
) ∈ Rp N converges for the usual metric on Rp, i.e. lim

n→∞
ΛA(Xn
) = S,

and X ±A ΥA(S).

Intuitively, these functions transpose the convergence of the sequence of iterates into the theory of real sequences, in such a way that the real sequence does not lose any information. Note that the order on Rp induced by the usual metric is unrelated with the order ±A on A, so the notion of extraction and combination is different from the notion of Galois connection used to compare abstract domains. For the interval domain I = Iv, where v is the number of variables of the program and I is the set of floating-point intervals, the extraction and the combination functions are defined in Equation (5).
,	I → R2v	
ΛI :	 	 
(i ,. .. , iv ) '→  i ,i ,.. ., iv, iv

,	R2v → I
(5)

ΥI :
(x ,x ,. .., x	,x  ) '→  [x ,x ],. .., [x
,x  ] 


For other domains, these functions must be designed specifically. For example, we believe that such functions can be easily defined for the octagon abstract do- main [18]: the function Λ associates a vector containing all its coefficients with a difference bound matrix. Special care should be taken in the case of infinite coeffi- cients. More generally, we believe that for domains with a pre-defined shape, the functions Λ and Υ can be easily defined. Note that if there is a Galois connection (αI , γI ) between a domain A and the interval domain I, the extraction and combi- nation functions can be defined as ΛA = ΛI ◦ αI and ΥA = γI ◦ ΥI. We use this method in the last experiment in Section 5.2.
Accelerated abstract ﬁxpoint computation
We describe the insertion of acceleration methods in the Kleene iteration process in Algorithm 1. We compute in parallel the sequence (Xn) coming from the Kleene’s iteration and the accelerated sequence (yn) computed from an accelerated method. Once the sequence (yn) seems to converge, that is, the distance between two consec- utive elements of (yn) is smaller than a given value δ, we combine the two sequences. That is we compute the upper bound of the two elements of the current iteration. Note that the monotonicity of the computed sequence (Xn) is still guaranteed.

Algorithm 1 Accelerated abstract fixpoint computation
1: repeat
2:	Xi := Xi−1 H F (Xi−1)
3:	yi := Accelerate (ΛA(X0),... , ΛA(Xi))
4:	if ||yi — yi−1|| ≤ δ then
5:	Xi := Xi H ΥA(yi)
6:	end if
7: until Xi ± Xi−1
The use of acceleration methods may be seen as an automatic delayed application of the widening with thresholds. Let us remark that we are not guaranteed to terminate in finitely many iterations: we know that asymptotically, the sequence yi from Algorithm 1 gets closer and closer to the fixpoint, but we are not guaranteed


	
50	100	150	200
Fig. 5. The Butterworth program (left) and the sequence of supremum of variable x1 (right).

that it reaches it. To guarantee termination of the fixpoint computation, we have to use more “radical” widening thresholds, for example after n applications of the accelerated method. So this method cannot be a substitute for widening, but it improves it by reducing the number of parameters (delay and thresholds) that a user must define.

Experimentation
To illustrate our acceleration methods, we used a simple static analyzer 4 working on the interval abstract domain that handles C programs without pointers. Fur- thermore, we associated to the analyzer our OCaml library of acceleration methods that transform an input sequence (given as a sequence of values) into its accelerated version. The obtained results are presented in the following sections. Note that we tested all these examples on the Interproc analyzer 5 . In each case, with standard parameters, the widening removed any constraints on the interesting variables. We only could obtain precise results by replacing the widening by a join, i.e. computing the standard Kleene iteration without widening.

Butterworth order 1
To test the acceleration method, we use a first-order Butterworth filter (see Fig- ure 5, left). This filter is designed to have a frequency response which is as flat as mathematically possible in the band-pass and is often used in embedded systems to treat the input signals for a better stability of the program.
The static analysis of this program using the interval abstract domain defines 10 sequences, two for each variable (x1, xn1, y, u, i). These sequences converge toward the smallest fixpoint after a lot of iterations, our acceleration methods allow us to obtain the same fixpoint faster. In this example, we accelerate just the upper bound sequences because the lower ones are constant for all the variables. We next present the result obtained with different methods on the variable x1 only, results obtained with other variables are very alike.

4 This analyzer is based on Newspeak, http://penjili.org/newspeak.html.
5 http://pop-art.inrialpes.fr/interproc/interprocweb.cgi. The SIMPLE programs corresponding to these examples can be found at www.lix.polytechnique.fr/˜bouissou/NSAD10.


20.0086

20.0084

20.0082


50	100	150	175	20	40	60
Fig. 6. Accelerated sequences (in bold) compared with the original Kleene sequence (dotted). Left is the sequence obtained with Aitken (zooming on the numerical problems), right with the ε-algorithm (zooming on the first iterates).
The Aitken Δ2-method.  In Figure 5, right, with Kleene iteration and with- out widening, this program converges in 156 iterations, and we get the invariant [0, 20.0084] for x1. With the Aitken Δ2-method, we obtain only in 3 iterations a value very close to 20.0084, but problems of numerical instabilities prevent the sta- bilization of the program. However the values of the accelerated sequence stay in the interval [20.0082, 20.0086] between the third and the last iteration (see Figure 6, left), which is a good estimate of the convergent point.
The ε-algorithm. In Figure 6, right, we notice a important improvement in the computation of the fixpoint, thanks to the ε-algorithm. With this method, the fixpoint of the variable x1 is approximated with a precision of 10−6 after exactly 8 iterations, while Kleene iteration needed 156 steps. Note that to obtain 8 elements of the accelerated sequence we need 15 elements from the initial one. We obtain the same results with the vector ε-algorithm.
Butterworth order 2
An order 2 Butterworth filter is given by the following recurrence equation, where
xn is a two-dimensional vector, xn = (x1, x2)T :



xn+1 =
0.9858 −0.009929
0.00929	1
· xn + u ·
0.9929
0.004965

,  yn+1 =
4.965e−5
0.01
· xn + 2.482e−5 · u

On this program, the results obtained using the interval abstract domain are not stable. To address this problem we have used Fluctuat [14], a static analyzer using a specific abstract domain based on affine arithmetic, a more accurate extension of interval arithmetic. It returns the upper and lower bounds of each variable. We
Before: number of iterations to reach the condition on δ. After: the remaining number of Kleene itera- tions to reach the invariant using the accelerated result.
Fig. 7. Numbers of iterations needed to reach an invariant.

applied the vector ε-algorithm on this example with 3 different values of δ (see Algorithm 1): this gives Figure 7. For example, for the variable x1 and δ = 10−3, the over-approximation of the fixpoint is reached after 26 iterations (6 iterations before re-injection and 20 iterations after). Note that we obtain the same fixpoint as with Kleene iteration. We notice that the performance of the Algorithm 1 does not strongly depend on δ. Until now, we use the acceleration just once (unlike in Algorithm 1), a full implementation of it will probably reduce the number of iterations even more.

Related work
Most of the work in abstract interpretation based static analysis concerned the definition of new abstract domains (or improvements of existing ones), and the ab- stract fixpoint computation remained less studied. Initial work from Cousot and Cousot [10] discussed various methods to define widening operators. Bourdoncle [4] presented different iteration strategies that helps to reduce the over-approximation introduced by widening. These methods are complementary to our technique: as explained in Section 4, acceleration should be done at the same control point as the one chosen for widening, and does not replace standard widening as the termina- tion of the fixpoint computation is not guaranteed. However, acceleration methods greatly improve widening by dynamically and automatically finding good thresh- olds.
Gopan and Reps in their guided static analysis framework [12,13] also used the idea of computing in parallel the main iterates and a guide that shows where the iterates are going. In their work, the precision of the fixpoint computation is in- creased by computing a pilot value that explores the state space using a restricted version of the iteration function. Once this pilot has stabilized, it is used to accel- erate the main iterates; in a sense, this pilot value is very similar to the value yi of Algorithm 1, but we do not modify the iteration function as done in [13].
Maybe the work that is the closest to ours is the use of acceleration tech- niques in model checking [1], that have recently been applied to abstract interpreta- tion [11,17]. In this framework, the term acceleration is used to describe techniques that try to predict the effect of a loop on an abstract state: the whole loop is then replaced with just one transition that safely and precisely approximates it. These techniques perform very well for sufficiently simple loops working on integer vari- ables, and gives exact results for such cases. Again, this method is complementary to our usage of acceleration: it statically modifies the iteration function by replac- ing simple loops with just one transition, while our method dynamically predicts the limit of the iterates. We believe that our method is more general, as it can be applied to many kinds of loops and is not restricted to a specific abstract domain (changing the abstract domain only requires changing the ΛA and ΥA functions).
Note also that the computation of symbolic loop invariants such that [19] pro- duce precise results. Nevertheless, they have to limit the constructions of analyzed programs unlike our approach.

Conclusion
We presented a technique to accelerate abstract fixpoint computations using numer- ical acceleration methods. This technique consists in building numerical sequences by extracting, at every iteration, supremum and infimum from every variable of the program. To the obtained sequences we apply the various convergence acceleration methods, which allows us to get significantly closer or to reach the fixpoint more quickly than the Kleene iteration. To make sure that the fixpoint returned by the accelerated method is indeed the fixpoint of the abstract semantics, we re-inject it in the static analyzer. This guarantees us the fast stop of the analyzer with a good over-approximation of the fixpoint. The experiments made on a certain number of examples (linear programs) show a good acceleration of the fixpoint computation especially when we use the ε-algorithm, where the number of iterations is divided by four. Let us note that we have assumed in this article that the sequences of iterates and the corresponding vector sequences converge towards a finite limit. In case of diverging sequences, traditional widening can be used as sequence transformation will not perform as well as for converging ones.
For now, we made the experimentation using two separate programs: one that computes the Kleene iterates, and one that accelerates the sequences. The Algo- rithm 1 is thus still not fully implemented, its automatization is the object of our current work. Since the use the interval abstract domain allows us to cover just a small set of programs, our future work will also consist in extending this technique to relational domains such as octagons and polyhedra. Moreover, we presented ex- amples made of a simple loop that iterates a linear transformation, we will test our techniques on more realistic programs. Early experiments show that acceleration behaves well on loops iterating a non-linear function. It will be more difficult to treat loops that are less regular, e.g. loops with if statements, as the extracted se- quences are less regular. However we believe that our technique can be mixed with guided static analysis [13] to achieve a precise and efficient result in these cases.

Acknowledgement
The authors want to thank X. Allamigeon and E. Goubault for their helpful dis- cussions and precious advices and S. Zennou for her technical help on the analyzer based on Newspeak. The authors are also thankful to the anonymous reviewers for their helpful comments and suggestions.

References
Bardin, S., A. Finkel, J. Leroux and L. Petrucci, FAST: acceleration from theory to practice, Journal on Software Tools for Technology Transfer 10 (2008), pp. 401–424.

Blanchet, B., P. Cousot, R. Cousot, J. Feret, L. Mauborgne, A. Min´e, D. Monniaux and X. Rival, Design and implementation of a special-purpose static program analyzer for safety-critical real-time embedded software, in: The Essence of Computation: Complexity, Analysis, Transformation, LNCS 2566, Springer, 2002 pp. 85–108.


Blanchet, B., P. Cousot, R. Cousot, J. Feret, L. Mauborgne, A. Min´e, D. Monniaux and X. Rival, A Static Analyzer for Large Safety-Critical Software, in: Programming Language Design and Implementation (2003), pp. 196–207.
Bourdoncle, F., Efficient chaotic iteration strategies with widenings, in: International Conference on Formal Methods in Programming and their Applications (1993), pp. 128–141.
Brezinski, C. and M. Redivo Zaglia, “Extrapolation Methods-Theory and Practice,” North-Holland, 1991.
Brezinski, C. and M. Redivo Zaglia, Generalizations of Aitken’s process for accelerating the convergence of sequences, Computational and Applied Mathematics (2007).
Brezinski, C. and M. Redivo Zaglia, A review of vector convergence acceleration methods, with applications to linear algebra problems, International Journal of Quantum Chemistry 109 (2008),
pp. 1631–1639.
Cousot, P. and R. Cousot, Abstract interpretation: a unified lattice model for static analysis of programs by construction or approximation of fixpoints, in: Principles of Programming Languages (1977), pp. 238–252.
Cousot, P. and R. Cousot, Abstract Interpretation Frameworks, Journal of Logic and Computation 2
(1992), pp. 511–547.
Cousot, P. and R. Cousot, Comparing the Galois connection and widening/narrowing approaches to abstract interpretation, in: Programming Language Implementation and Logic Programming, LNCS 631 (1992), pp. 269–295.
Gonnord, L. and N. Halbwachs, Combining widening and acceleration in linear relation analysis, in:
Static Analysis Symposium, LNCS 4134 (2006), pp. 144–160.
Gopan, D. and T. W. Reps, Lookahead Widening, in: Computer Aided Verification, LNCS 4144 (2006),
pp. 452–466.
Gopan, D. and T. W. Reps, Guided static analysis, in: Static Analysis Symposium, LNCS 4634 (2007),
pp. 349–365.
Goubault, E., M. Martel and S. Putot, Asserting the precision of floating-point computations: a simple abstract interpreter, in: European Symposium on Programming, LNCS 2305 (2002), pp. 209–212.
Graves-Morris, P. R., Extrapolation methods for vector sequences, Numerische Mathematik 61 (1992),
pp. 475–487.
Halbwachs, N., Y.-E. Proy and P. Roumanoff, Verification of real-time systems using linear relation analysis, Formal Methods in System Design 11 (1997), pp. 157–185.
Leroux, J. and G. Sutre, Accelerated data-flow analysis, in: Static Analysis Symposium, LNCS 4634
(2007), pp. 184–199.
Min´e, A., “Weakly Relational Numerical Abstract Domains,” Ph.D. thesis, E´cole Polytechnique, Palaiseau, France (2004).
Rodriguez-Carbonell, E. and D. Kapur, Generating All Polynomial Invariants in Simple Loops, Journal of Symbolic Computation 42 (2007), pp. 443–476.
Sankaranarayanan, S., H. B. Sipma and Z. Manna, Scalable analysis of linear systems using mathematical programming, in: Verification, Model Checking, and Abstract Interpretation, LNCS 3385 (2005), pp. 25–41.
Simon, A. and A. King, Widening Polyhedra with Landmarks, in: Asian Symposium on Programming Languages and Systems, LNCS 4279 (2006), pp. 166–182.
Tarski, A., A lattice-theoretical fixpoint theorem and its applications, Pacific Journal of Mathematics 5
(1955), pp. 285–309.
Wynn, P., The epsilon algorithm and operational formulas of numerical analysis, Mathematics of Computation 15 (1961), pp. 151–158.
