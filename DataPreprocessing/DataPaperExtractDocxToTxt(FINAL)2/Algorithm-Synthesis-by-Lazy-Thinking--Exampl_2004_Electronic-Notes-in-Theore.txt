	Electronic Notes in Theoretical Computer Science 93 (2004) 24–59	
www.elsevier.com/locate/entcs




Algorithm Synthesis by Lazy Thinking: Examples and Implementation in Theorema
Bruno Buchberger 1 and Adrian Cra˘ciun 2
RISC - Research Institute for Symbolic Computation Johannes Kepler University
Linz, Austria

Abstract
Recently, we proposed a systematic method for top-down synthesis and verification of lemmata and algorithms called ”lazy thinking method” as a part of systematic mathematical theory exploration (mathematical knowledge management). The lazy thinking method is characterized:
by using a library of theorem and algorithm schemes
and by using the information contained in failing attempts to prove the schematic theorem or the correctness theorem for the algorithm scheme for inventing lemmata or requirements for subalgorithms, respectively.
In this paper, we give a couple of examples for algorithm synthesis using the lazy thinking paradigm. These examples illustrate how the synthesized algorithm depends on the algorithm scheme used. Also, we give details about the implementation of the lazy thinking algorithm synthesis method in the frame of the Theorema system. In this implementation, the synthesis of the example algorithms can be carried out completely automatically, i.e. without any user interaction.
Keywords: algorithm invention, algorithm verification, program synthesis, algorithm correctness, re-usable algorithms, algorithm schemes, learning from failure, conjecture generation, lazy thinking, requirement engineering, didactics of programming, mathematical knowledge retrieval, mathematical knowledge management, sorting, merging, merge-sort, Theorema.


1 Sponsored by FWF (O¨ sterreichischer Fonds zur Fo¨rderung der Wissenschaftlichen Forschung; Austrian Science Foundation), Project SFB 1302, in the frame of the SFB ”Scientific Computing” at the Johannes Kepler University, Linz, Austria.
Email: buchberger@risc.uni-linz.ac.at
2 Sponsored by the Calculemus European Project. Email: acraciun@risc.uni-linz.ac.at



1571-0661 © 2004 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2003.12.027

Introduction

The lazy thinking approach to the synthesis of correct algorithms was intro- duced by the first author in various talks since 2001, see the proceedings paper [5]. The lazy thinking approach to algorithm synthesis is an adaptation of the lazy thinking paradigm for lemmata invention introduced in [4]. Lemmata in- vention is part of a general philosophy of systematic theory exploration, see [4], as an alternative to the isolated theorem proving paradigm that prevailed for many decades in the area of automated theorem proving. Systematic theory exploration is one of the main topics in the emerging field of ”mathematical knowledge management” initiated in September 2001 by the 1st International Workshop on Mathematical Knowledge Management (MKM), see [7] and [10], which engendered MKM 2003 [2] and also parallel events in North America, see [11].
Roughly, our lazy thinking algorithm synthesis method proceeds as follows:
We start with a (predicate logic) specification of the algorithm in a partic- ular data domain. We assume that all the auxiliary operations (functions and predicates) occurring in the specification are defined and all important properties of these operations are already known, i.e. that the ”theory of these operations” is completely explored.
The method now tries out, one after the other, various ”algorithm schemes” that are stored in a library of algorithm schemes for the given mathematical domain. An algorithm scheme is a predicate logic formula that describes an algorithm (recursively) in terms of unspecified subalgorithms together with a proof method appropriate for (induction) proofs of properties of algorithms following this scheme.
For the chosen algorithm scheme, the proof method is called for proving the correctness theorem, i.e. for proving that the unknown algorithm satisfies the given specification. Typically, this proof will fail because nothing is known about the unspecified subalgorithms.
From the failing proof situation, by a conjecture generating algorithm, ”re- quirements” (specifications) for the unknown subalgorithms are generated that enable the prover to complete the proof successfully. These require- ments are added to the knowledge base and the proof of the correctness theorem is attempted again. Now, the proof will get over the failing situa- tion and will either succeed or will fail again at some later proof situation.
This procedure is iterated in a recursive cascade until the proof of the cor- rectness theorem goes through (or one gives up). After successful termina- tion, the following will be true: Under the assumption that all ingredient

subalgorithms satisfy the requirements generated, the main algorithm sat- isfies the problem specification.
In this stage, there are two possibilities: Either, in the initial knowledge base, algorithms are available that satisfy the requirements for the subalgo- rithms described in the lemmata and we are done, i.e. a correct algorithm has been synthesized for the initial problem and its correctness proof has been generated. Or subalgorithms that satisfy the requirements can be syn- thesized by another application of the same method in a next round of the procedure.
The distinctive features of our algorithm synthesis method, as compared to other methods, are:
the use of algorithm schemes taken from a library of algorithm schemes,
the crucial role of failing proofs and conjecture generation from failing proofs,
the decomposition of theory exploration and, in particular, algorithm in- vention and verification into theory layers,
the naturalness of the approach, which makes it attractive both for com- plete or partial automation in computer-supported systems for formal math- ematics and also for usage as a strategy for human algorithm invention and teaching. (In fact, the idea for the lazy thinking paradigm for algorithm syn- thesis arose while the first author was preparing a course on mathematical algorithm verification for high-school teachers in October 2001.)
Similar ideas were introduced in synthesis literature (see [3] for an overview). However, in one respect or the other, our synthesis method is different from each of the above. In the following, we go through a few of these.
The deductive synthesis method, of the type described in [1],[14] use proof planning to set up the proof of the correctness of an algorithm, replaces the unknown parts of the algorithm (existential parts of the specification) with metavariables which will be instantiated as the proof planning progresses.
In formal methods, starting from a specification, by a series of transforma- tions a correct program is reached. Adding to this setting, additional knowl- edge about algorithm development (data abstractions, design abstractions - that correspond to algorithm schemes such as divide-and-conquer [16]) has led to the implementation of powerful systems, such as KIDS [17] and its successor Specware [19] that support the use of schemes for the synthesis of programs. In the same spirit, schemas of logic programs, with added semantic mean- ing, are transformed into programs by a series of steps that preserve correct-
ness in [13].

In (automated) software engineering, there are already catalogues of soft- ware design patterns available, which again, accumulate knowledge on software development (”recurring solutions to standard problems”, see [15]). These are directed towards specific object-oriented or concurrent, parallel and dis- tributed programming languages (for pattern resources, see [20]).
The lazy thinking algorithm synthesis method is independent of any system for formal mathematics. However, the chosen system must have a couple of properties in order to qualify as a frame for the method:
The proof objects generated by the automated theorem proving part of the system must be open for post-processing. In other words, black-box provers are not suitable for the method because the important (automated) requirement generation for subalgorithms is based on a detailed analysis of the proof objects generated.
For the same reason, it is also crucial that the automated theorem provers used in the system yield proof objects also in the case that proofs fail. In distinction to other algorithm synthesis methods, which extract algorithms from successful proofs, the essence of our method is the automated genera- tion of requirements for subalgorithms from failing proofs!
The automated theorem provers used in the system should be ”natural style” provers, e.g. natural deduction provers or variants thereof: The gen- eration of requirements for the unknown subalgorithms is crucially based on the analysis of the temporary assumptions and temporary proof goals in the failing proof object.
In this paper, all our formal developments will be given in the Theorema system, see [8], [9]. In particular, all formulae will be given in the Theorema syntax. Also, the implementation of the method is described in the concrete example of the Theorema system.
This paper consists of three case studies of algorithm synthesis and remarks on the implementation of the method in the frame of Theorema, which was carried out by the second author based on an earlier version of the Theorema induction prover and conjecture generator by the first author. The first case study, sorting by merging, is the one of [5], which we summarize here because it is best suited for explaining the general method. The other two case studies are new. The second case study (synthesis of a merge algorithm) illustrates particularly well that, although finding the induction proofs and the require- ments for the subalgorithms is quite easy, keeping track of the organization and the details of these proofs and requirements is a quite demanding task that needs automation for making the entire method practically attractive. The third case study shows how, for a fixed algorithm specification, changing

the algorithm scheme fed into the synthesis procedure changes the algorithm synthesized, i.e. the specification (requirements) generated automatically for the subalgorithms.

First Case Study: Sorting by Merging
Problem Specification
We want to synthesize an algorithm ’sorted’ that meets the following specifi- cation:
∀	is–sorted–version[X, sorted[X]],

where
is–tuple[X]






is–tuple[Y ]	

∀
is–tuple[X],Y
is–sorted–version[X, Y ] ⇔	X ≈ Y
is–sorted[Y ]
 .

The predicate ’is-sorted-version’ is defined in terms of the two auxiliary predicates ’≈’ and ’is-sorted’. (For X ≈ Y read ’Y is a permuted version of X’ or ’X and Y contain the same elements equally often’):
is–sorted[⟨⟩],
∀is–sorted[⟨x⟩],
x			




and
∀
x,y,z¯
is–sorted[⟨x, y, z¯⟩] ⇔  x ≥ y
 is–sorted[⟨y, z¯⟩]

⟨⟩ ≈ ⟨⟩,
∀ ⟨⟩ /≈ ⟨y, y¯⟩,
y,y¯
∀ (⟨x, x¯⟩ ≈ ⟨y¯⟩⟩ ⇔ (x ∈ ⟨y¯⟩∧ ⟨x¯⟩≈ df o[x, ⟨y¯⟩])) .
x,x¯,y¯
(For the ”sequence variables” notation x¯ etc., see the papers on Theorema,
e.g. [8]. Sequence variables can be replaced by arbitrarily many terms. Thus, for example, the terms ⟨⟩, ⟨2⟩, ⟨4, 3, 2, 2⟩, ⟨4, y¯, a, z¯, a + b⟩ are instances of the term ⟨x¯⟩. We use angle brackets as constructors for tuples: for example,
⟨2, 2, 3, 1, 4⟩ is the tuple consisting of the elements 2, 2, 3, 1, 4.)

The definitions of ’is-sorted’ and ’≈’, again, contain auxiliary operations like ’∈’ (read: ’is element’) and ’df o’ (read: ’delete first occurrence’) that must be defined in terms of other auxiliary functions until we arrive at the basic operations on tuples. The definitions of all these auxiliary operations and also the formulae describing various properties of these auxiliary operations are supposed to be contained in the knowledge base, see appendix.
(In [5] we discuss the question of ”completeness” and ”sufficiency” of knowledge bases.)


Algorithm Scheme
In our view, an ”algorithm scheme” (or ”algorithm type”) for a given data domain,
is a recursive definition of an unspecified ”main” operation in terms of other unspecified ”auxiliary” operations and the basic operations of the data do- main,
together with a proof method that corresponds to the recursive definition and the data domain in a natural way.
In our case (a problem on the data type of tuples), a possible recursive defini- tion of the solution function is the well-known ”divide–and–conquer” scheme (in a version which is appropriate to the data type of tuples):



∀
is–tuple[X]
sorted[X]=  merged[sorted[left–split[X]],




where you should think about the ”main function” ’sorted’ and the ”auxiliary functions” ’special’, ’merged’, ’left–split’, and ’right–split’ as completely un- specified (except that ’sorted’ is related to the auxiliary functions as described in the scheme). In fact, at this moment, nothing is known about these func- tions that would justify to give them names like ’sorted’, ’special’, ’merged’ etc.
Note also, that in contrast to the operations ’sorted’ etc., the predicate ’is-trivial-tuple’ is not unspecified but, rather, is defined by a formula in the knowledge base, see the appendix.

Also, we include the following natural ”type requirements” on the auxiliary functions as a part of the algorithm scheme:


∀
is–tuple[X]
is–tuple[special[X]],

is–trivial–tuple[X]
∀
is–tuple[X]
¬is–trivial–tuple[X]
 is–tuple[left–split[X]]	,
 is–tuple[right–split[X]]

∀	is–tuple[merged[Y, Z]] .
is–tuple[Y,Z]
The type requirements will be important for being able to prove that the function ’sorted’, for tuple arguments, yields tuples as results.
Finally, we also consider the following requirement


∀
is–tuple[X]
¬is–trivial–tuple[X]
 X > left–split[X]
 X > right–split[X]

as a part of the recursive definition, which guarantees termination of the al- gorithm in case ’>’ is a Noetherian predicate. (In our case, we will use the predicate ’has shorter length’ for ’>’, see the definition in the appendix.)
Second, we include the following special induction method into the algo- rithm scheme:
In order to prove, for an arbitrary property A,	∀	A[X] it suffices
is–tuple[X]
to prove, for an arbitrary but fixed x¯0, A[⟨x¯0⟩] under the assumptions
is–tuple[⟨x¯0⟩] and	∀	A[Y ].
is–tuple[Y ]
⟨x¯0⟩>Y
This particular induction method is based on the property that > is a Noetherian relation.
One might argue that, with the inclusion of an appropriate inductive proof method into the algorithm scheme, already very much of the ”invention” is taken away from the automated invention system. However, in future mathe- matical knowledge management systems (and, in particular, verified algorithm invention systems), it would be silly to throw away the accumulated knowledge of mathematicians on problem solving ”schemes”. Rather, in future systems, the accumulated algorithm invention knowledge of mathematicians should be kept available in ”algorithm schemes libraries” that can then be used, in the way which we demonstrate in this paper, for inventing concrete algorithms for concrete problems.

A completely automatic search through a library of possible algorithm schemes to be applied for a particular algorithm synthesis problem may seem to be combinatorially prohibitive. However, in practice, we think that our strategy is viable for the following reasons:
Given a data type (which is part of the problem specification), experience shows that there are not too many possible algorithm schemes that are worth storing in a library of algorithm scheme. There are many algorithms but, in contrast, there are only a few algorithm schemes. In other words, given a data type, there are only of few basic ideas how to attack problems specified for the given data type but there are many variations or instantiations of these ideas and even more combinations of theses ideas with ideas (schemes) for the subalgorithms.
Of course, not all algorithm schemes in the library of algorithm schemes for a given data type will lead to reasonable algorithms for the problem specified. More concretely, it will turn out the requirements for the subalgorithms derived from analyzing failing proofs of the respective correctness theorem may not be easily satisfiable or not be satisfiable at all in the next round of the synthesis procedure. We guess that some user interaction will be necessary to follow only promising paths in the overall synthesis procedure through a couple of layers of subalgorithms, subsubalgorithms etc. However, at the moment, we do not yet have sufficiently much experimental material from case studies in order to make a well-founded statement on the amount of user interaction necessary or sufficient in our approach.

Algorithm Synthesis by Lazy Thinking: First Round
We now start from the following situation:
We have a knowledge base consisting of all the definitions and essential properties of the operations and auxiliary operations (functions and predi- cates) occurring in the problem specification (in our case: the specification of the binary predicate ’is–sorted–version’ and all auxiliary operations, like ’>’ etc., see appendix).
We have chosen an algorithm scheme (including an induction scheme) from a finite library of algorithm schemes for the domain of tuples (in our case: the ”divide–and–conquer” algorithm scheme; in the third case study we will start from some other scheme!).
We do now the following:
We include the algorithm scheme for ’sorted’, the type requirements for the auxiliary functions, and the requirements on the decreasing length of

’left-split’ and ’right-split’ into the knowledge base.
Then we start attempting to prove the correctness theorem
∀	is–sorted–version[X, sorted[X]].
is–tuple[X]
Of course, this proof will not succeed because, at this moment, essentially nothing is known about the auxiliary functions ’merged’, ’left–split’ etc. We proceed with the proof until the proof gets stuck.
When it got stuck, we analyze the current, failing proof situation and try to conjecture requirements (properties) of the auxiliary subalgorithms ’special’, ’left-split’, ’right–split’, ’merged’ that would make it possible to get over the failing proof situation. (It is essential for the automation of the method that this step of conjecturing suitable requirements can be au- tomated!)
We add the conjectured requirements to the knowledge base and repeat the whole process, i.e. we go to the next round in the algorithm invention process.
In the example, the failing proof attempt (which can be generated completely automatically by the Theorema induction prover) is as follows:
proof Attempt Begin
For proving the correctness theorem, we use well-founded induction w.r.t.
> on X:
We assume is–tuple[⟨x¯0⟩] and the induction hypothesis


∀
is–tuple[Y ]
⟨x¯0 ⟩>Y
is–sorted–version[Y, sorted[Y ]]


and we show
is–sorted–version[⟨x¯0⟩, sorted[⟨x¯0⟩]].
We use the algorithm scheme for ’sorted’ and distinguish two cases:
CASE is-trivial-tuple[⟨x¯0⟩]:
In this case, we have to show

is–sorted–version[⟨x¯0⟩, special[⟨x¯0⟩]]

i.e., by the definition of ’is-sorted-version’, we have to show

is–tuple[special[⟨x¯0⟩]], (G1) special[⟨x¯0⟩] ≈ x¯0,	(G2) is–sorted[special[⟨x¯0⟩]]. (G3)


For (G2), by the fact that
∀

((X ≈ Y ) ⇔ (X = Y ))

is–trivial–tuple[X],is–tuple[Y ]
it suffices to prove that special[⟨x¯0⟩]= ⟨x¯0⟩.
(G1) is true by the type requirement on special. We can not prove (G2) and (G3).
proof Attempt End
(The proof attempt generated automatically by the Theorema induction prover for tuples is basically exactly like the proof attempt above including the ex- planatory English text, see the papers on Theorema. However, for the presen- tation in this paper, we leave out some intermediate steps of the Theorema proofs.)
Now we analyze the failing proof situation and find:
We have the case assumption as the only temporary assumption:
is–trivial–tuple[⟨x¯0⟩].
We have the temporary goal:
special[⟨x¯0⟩]= ⟨x¯0⟩.
It is obvious to conjecture (and our current Theorema conjecture gener- ating algorithm can do this automatically) that the following requirement on the function ’special’
∀	(special[X]= X)
is–trivial–tuple[X]
will make it possible to get over the failing proof situation.
We add this requirement to the knowledge base and proceed to the next invention round.

Algorithm Synthesis by Lazy Thinking: Second Round
Since we have added a requirement on the auxiliary function ’special’ we will get now over the failing proof situation and we will be stuck at some later situation in the proof in which, again, we will try to invent a requirement on the auxiliary functions that will make it possible to proceed further.
The next proof attempt (which again can be generated completely auto- matically by the Theorema induction prover) will now proceed as follows:
proof Attempt Begin
CASE ¬is-trivial-tuple[⟨x¯0⟩]:
In this case, we have to show
is–sorted–version[⟨x¯0⟩, merged[sorted[left–split[⟨x¯0⟩]], sorted[right–split[⟨x¯0⟩]]]].
For this, by the definition of ’is-sorted-version’, it suffices to show
is–tuple[merged[sorted[left–split[⟨x¯0⟩]], sorted[right–split[⟨x¯0⟩]]]], (H1)
⟨x¯0⟩≈ merged[sorted[left–split[⟨x¯0⟩]], sorted[right–split[⟨x¯0⟩]]],	(H2)
is–sorted[merged[sorted[left–split[⟨x¯0⟩]], sorted[right–split[⟨x¯0⟩]]]]. (H3)
From the case assumption, by the type requirements on ’left-split’ and ’right-split’, the property that ’left-split’ and ’right-split’ shorter tuples, and the induction hypothesis we obtain
is–sorted–version[left–split[⟨x¯0⟩], sorted[left–split[⟨x¯0⟩]]],
is–sorted–version[right–split[⟨x¯0⟩], sorted[right–split[⟨x¯0⟩]]].
From this, by the definition of ’is-sorted-version’, we obtain
is–tuple[sorted[left–split[⟨x¯0⟩]]],				(AL1) left–split[⟨x¯0⟩] ≈ sorted[left–split[⟨x¯0⟩]],	(AL2) is–sorted[sorted[left–split[⟨x¯0⟩]]],	(AL3) is–tuple[sorted[right–split[⟨x¯0⟩]]],	 (AR1) right–split[⟨x¯0⟩] ≈ sorted[right–split[⟨x¯0⟩]], (AR2) is–sorted[sorted[right–split[⟨x¯0⟩]]].		(AR3)

(H1) follows from (AL1) and (AR1) by the type requirement on ’merged’.
We cannot prove (H2) and (H3).
proof Attempt End
Now we analyze the failing proof situation and find:
We have the case assumption and the formulae (AL1), ..., (AR3) as tem- porary assumptions.
We have the temporary goals (H2) and (H3).
It is not so near at hand but, after some thinking, relatively easy to conjec- ture (and our current Theorema conjecture generating algorithm can produce this conjecture automatically) that the following requirement on the functions ’left–split’, ’right–split’ and ’merged’

 left–split[X] ≈ Y
∀	

⇒ 	

right–split[X] ≈ Z

merged[Y, Z] ≈ X


is–tuple[X,Y,Z]
 is–sorted[Y ]

 is–sorted[merged[Y, Z]] 

will make it possible to get over the failing proof situation.
We add this requirement to the knowledge base and now (H2) and (H2) can be proved and the entire proof can be completed.

Result of Synthesis
If we now collect the requirements on the functions ’special’,’left–split’,’right–split’ and ’merged’, we see that we invented and ”Relative Correctness Theorem for Merge-Sort”:
Knowledge[is-sorted-version]	⇒
Is-Merge-Sort-Algorithm[sorted, special, merged,
left-split, right-split]
∀	.
⇒

special,merged,left–split,right–split

∀	is–sorted–version[X, sorted[X]]	

is–tuple[X]
Here, ’Knowledge’ is the conjunction of all (some of the) formulae known about the predicate ’is-sorted-version’ and all its ingredient operations (func- tions and predicates), like ’is-sorted’, ’≈’, etc.  (see appendix) and

’Is–Merge–Sort–Algorithm’ is defined as follows:
	Is-Merge-Sort-Algorithm[sorted, special,	

∀
special,merged,left–split,right–split
merged, left-split, right-split]

	 special[X]	⇐ is–trivial–tuple[X]
	∀	sorted[X]=  merged[sorted[left–split[X]],
	

is–tuple[X]

	sorted[right–split[X]]]	otherwise

(special[X]= X)

is–trivial–tuple[X]


 is–tuple[left–split[X]]



∀
is–tuple[X]
 ¬is–trivial–tuple[X]

 X > left–split[X]
is–tuple[right–split[X]]	.
 X > right–split[X]

	∀	is–tuple[merged[Y, Z]]

is–tuple[Y,Z]


 left–split[X] ≈ Y	
		

	∀	 right–split[X] ≈ Z ⇒  merged[Y, Z] ≈ X	

is–tuple[X,Y,Z]
 is–sorted[Y ]
 is–sorted[merged[Y, Z]] 

  ¬is–trivial–tuple[X] 
is–sorted[Z]	

The theorem says that,
if
the predicate ’is-sorted-version’ and its sub-operations satisfy the properties described in knowledge (see the appendix),
the function ’sorted’ is defined recursively in the ”divide–and–conquer” style from the auxiliary functions ’special’, ’merged’, ’left–split’, and ’right–split’,
the functions ’merged’, ’left–split’, and ’right–split’ preserve the data type ’is-tuple’,
the functions ’left–split’ and ’right–split’, on non-trivial arguments, reduce the length,
the function ’special’, on trivial arguments, is the identity,
the function ’merged’, on sorted arguments, yields sorted tuples, and
the function ’merged’, on arguments Y and Z that contain the same el- ements as left-split[X] and right–split[X], respectively, yields a tuple that

contains the same elements as X,
then
the function ’sorted’ solves the problem of sorting, i.e. the problem specified by the binary predicate ’is–sorted–version’.
The most important and most interesting parts of this theorem are the two requirements stating that the function ’merged’ preserves sortedness and elements. These two requirements are exactly what people would naturally consider as the characteristic properties of merging. The amazing phenomenon is that exactly these two requirements are invented completely automatically, without any prior intuition or semantic understanding, by our ”lazy thinking” method. In fact, the exact formulation of the requirements invented by our method, are slightly more general than the requirements one would expect naturally. This is, of course, good because the weaker the requirements the more functions ’merged’, ’left-split’, and ’right-split’ satisfy the requirements! Note that our algorithm synthesis method does not only find one partic- ular algorithm for sorting by merging but, rather, finds a whole spectrum of algorithms, namely all those that follow the divide–and–conquer scheme but may have very different instantiations of the subalgorithms ’left–split’, ’right–split’, and ’merged’. All triples of subalgorithms qualify that satisfy
the requirements stated in the relative correctness theorem.
In [5] we go a step further and analyze the knowledge base from which we started with the objective to find out those ”minimal” properties of the ingredient operations that suffice for proving the relative correctness theorem. We do not describe this idea in the present paper.

Mathematical Knowledge Retrieval
After generating the requirements for the sub-functions ’merged’, ’left-split’, and ’right-split’, the question arises whether functions satisfying these require- ments already exist in our knowledge base. Seemingly, this is an easy question and, in traditional knowledge retrieval, the question is answered by looking to functions that have these names or, at least, similar names. Thus, for ex- ample, if one wants to know what is known about ”Bessel functions” in some function library then, of course, one would just look for terms in the library whose outermost function symbol is ”Bessel”. However, this ad-hoc solution to the knowledge retrieval problem is not appropriate for the needs arising in the frame of the above approach to algorithm synthesis (and in other areas of ”mathematical knowledge management”).
Rather, we are faced with the following problem:

Given a knowledge base K, operation names f , ..., and a requirement on
f , ..., i.e. a formula R[f, ...],
find operation names F , ... occurring in K such that R[F,... ] is a logical consequence of K.
Hence, knowledge retrieval in our context is essentially a proving problem!
For example, given the knowledge base K in the appendix augmented by the following definitions
M [⟨⟩, ⟨⟩]= ⟨⟩,
∀ (M [⟨⟩, ⟨y, y¯⟩]= ⟨y, y¯⟩),
y,y¯
∀ (M [⟨x, x¯⟩, ⟨⟩]= ⟨x, x¯⟩),
x,x¯


∀	M [⟨x, x¯⟩, ⟨y, y¯⟩]= 
 x × M [⟨x¯⟩, ⟨y, y¯⟩] ⇐ x > y	
y × M	 ,

x,x¯,y,y¯
L[⟨⟩]= ⟨⟩,
∀(L[⟨x⟩]= ⟨x⟩),
x
	[⟨x, x¯⟩, ⟨y¯⟩] ⇐ ¬x > y

∀ (L[x, y, z¯]= x × L[⟨z¯⟩]),
x,y,z¯
R[⟨⟩]= ⟨⟩,
∀(R[⟨x⟩]= ⟨⟩),
x
∀ (R[x, y, z¯]= x × R[⟨z¯⟩])
x,y,z¯
and the following requirement R[left-split, right-split, merged]











∀
is–tuple[X]
¬is–trivial–tuple[X]
 is–tuple[left–split[X]]
 X > left–split[X]	,
is–tuple[right–split[X]]
 X > right–split[X]

∀	is–tuple[merged[Y, Z]],

is–tuple[Y,Z]

∀
 left–split[X] ≈ Y


⇒ 	 ,

right–split[X] ≈ Z

merged[Y, Z] ≈ X


is–tuple[X,Y,Z]
 is–sorted[Y ]

 is–sorted[merged[Y, Z]] 








then ”finding” operations in K that satisfy the requirement consists in trying out all possible triples of functions l, r, m that occur in K and finding out whether the requirement R[l, r, m] can be proved from the formulae in the knowledge base. In our case, in particular, one could try L, R, M and try to prove that R[L, R, M ] holds. One sees that this task is nothing else than proving that the algorithms L, R, M are correct w.r.t. to the specification R[L, R, M ]. Of such proofs, may be difficult, moderately difficult, easy, or trivial depending on how much knowledge is available in the knowledge base. We have explained this in big detail in a recent technical report, see [6]. In particular, if no suitable functions l, r, m are available in the knowledge base, then the problem becomes another synthesis problem, namely the problem of synthesizing algorithms l, r, m satisfying the requirement R[l, r, m]. We will solve this problem, again by our lazy thinking algorithm synthesis method in the next section.

Second Case Study: Merging by Comparison
Problem Specification
Now we want to synthesize algorithms ’L’, ’R’, ’M ’ that satisfy the specifica- tion





∀
is–tuple[X]
¬is–trivial–tuple[X]
 is–tuple[L[X]]
 X > L[X]	,
is–tuple[R[X]]
 X > R[X]

∀	is–tuple[M [Y, Z]],

is–tuple[Y,Z]
 L[X] ≈ Y	

∀	
R[X] ≈ Z
⇒  M [Y, Z] ≈ X	 .

is–tuple[X,Y,Z]
 is–sorted[Y ]


 is–sorted[M [Y, Z]] 



In principle, this synthesis would be possible applying again our lazy think- ing method. However, it turns out that this synthesis, technically, is very cumbersome. The reason for this is that the above specification of the three unknown algorithms L, R, and M are ”coupled”. Namely, the last formula in the specification contains all three algorithm names ’L’, ’R’, and ’M ’. In such a situation, it is always advisable trying to ”decouple” the specification before one embarks on the synthesis problem. In our case, this is relatively easy: One can prove by pure ”symbolic computation proving” (rewriting), i.e. by easy proving without any induction, that the above specification is implied by the following, slightly stronger specification:




∀
is–tuple[X]
¬is–trivial–tuple[X]
 X > L[X]	,
is–tuple[R[X]]
 X > R[X]



∀
is–tuple[X]
(L[X] = R[X]) ≈ X,

¬is–trivial–tuple[X]
∀	is–tuple[M [Y, Z]],

is–tuple[Y,Z]
∀
 is–sorted[Y ]
⇒  M [Y, Z] ≈ (Y = Z)  ,

is–tuple[Y,Z]  is–sorted[Z]
 is–sorted[M [Y, Z]]	



where ’=’ denotes concatenation of tuples.
Remark. In fact the second formula is a natural specification for the split functions. What it says is that when we split a tuple X by the functions L and R then, if we put the splits together by concatenation, we again get a tuple that contains exactly the elements of the original X.
Note that, now, the specification of L and R is decoupled from the spec- ification of M . We could now synthesize L and R and then embark on the synthesis of M . In this paper, for lack of space, we do not show the synthesis of some concrete L and R. (In fact, in the previous section, we have provided concrete examples of suitable L and R.) Rather, we only show the synthesis of an algorithm c satisfying
∀	is–tuple[c[Y, Z]],

is–tuple[Y,Z]
∀
 is–sorted[Y ]
⇒  c[Y, Z] ≈ (Y = Z)  .

is–tuple[Y,Z]  is–sorted[Z]
 is–sorted[c[Y, Z]]	

(We are choosing a different name ’c’ now in order to indicate that this synthesis problem is completely independent of, i.e. decoupled from, any knowledge on ’L’ and ’R’.)





Algorithm Scheme

We use the following algorithm scheme, which we again suppose to be available in our ”algorithm schemes library”:



c[⟨⟩, ⟨⟩]= cee,
∀ c[⟨⟩, ⟨y, y¯⟩]= ceg[y, y¯],
y,y¯
∀ c[⟨x, x¯⟩]= cge[x, x¯],
x,x¯
∀ c[⟨x, x¯⟩, ⟨y, y¯⟩]=  cgg1[x, c[⟨x¯⟩, ⟨y, y¯⟩]] ⇐ p[x, y]	,

x,x¯,y,y¯

with the type requirements
 cgg2[y, c[⟨x, x¯⟩, ⟨y¯⟩]] ⇐ ¬p[x, y]


is–tuple[cee],
∀ is–tuple[ceg[x, x¯]],
x,x¯
∀ is–tuple[cge[x, x¯]],
x,x¯
∀	 is–tuple[cgg1[x, X]] ,
x,is–tuple[X]  is–tuple[cgg2[x, X]]

where cee, ceg, cge, cgg1, cgg2, and p are the unknown subalgorithms.
The corresponding inductive proof technique is:
For proving	∀	A[X] do the following:
is–tuple[X]
Prove A[⟨⟩].
Take x0 and x¯0 arbitrary but fixed, assume A[⟨x¯0⟩] and prove A[⟨x0, x¯0⟩].
This proof technique can be expanded to the following proof technique for conditioned formulae:
For proving	∀	B[X] do the following:
is–tuple[X]
C[X]
Assume C[⟨⟩]and show B[⟨⟩].
Take x0 and x¯0 arbitrary but fixed. Assume ¬C[⟨x¯0⟩] and C[⟨x0, x¯0⟩]and prove B[⟨x0, x¯0⟩].
Now assume C[⟨x¯0⟩], B[⟨x¯0⟩] and C[⟨x0, x¯0⟩] and prove B[⟨x0, x¯0⟩]. Note that (2) and (3) are appropriate because the assumption C[⟨x¯0⟩] ⇒
B[⟨x¯0⟩] is equivalent to ¬C[⟨x¯0⟩] ∨ (C[⟨x¯0⟩] ∧ B[⟨x¯0⟩]) and, hence, the proof
splits into the two cases ¬C[⟨x¯0⟩] and (C[⟨x¯0⟩] ∧ B[⟨x¯0⟩]).

Algorithm Synthesis by Lazy Thinking: First Round
We first prove
∀	is–tuple[c[Y, Z]]

by induction on Y and Z.
is–tuple[Y,Z]

This easy proof succeeds because of the type requirements on the subal- gorithms cee, ceg, etc. and the algorithm scheme. Thus, we immediately continue with the proof.
Now we try to prove
∀	 is–sorted[Y ] ⇒  c[Y, Z] ≈ (Y = Z) 

is–tuple[Y,Z]  is–sorted[Z]
 is–sorted[c[Y, Z]]	

by induction for formulae with conditions.


Induction Base for Y : Assume is–sorted[⟨⟩]. Prove

∀


 ⟨⟩ = Z ≈ c[⟨⟩, Z] .

is–tuple[Z]	is–sorted[c[⟨⟩, Z]]
is–sorted[Z]
Induction Base for Y , Induction Base for Z: Assume is–sorted[⟨⟩]. Prove
⟨⟩ = ⟨⟩ ≈ c[⟨⟩, ⟨⟩],
is–sorted[c[⟨⟩, ⟨⟩]].
Now, ⟨⟩ = ⟨⟩ ≈ c[⟨⟩, ⟨⟩] ↔ ⟨⟩≈ cee.
This proof fails but straightforwardly leads to the requirement cee = ⟨⟩. Furthermore, using already this requirement,
is–sorted[c[⟨⟩, ⟨⟩]] ↔ is–sorted[cee] ↔ is–sorted[⟨⟩] ↔ true.
Induction Base for Y , Induction Step for Z, Z, First Case: Assume ¬is–sorted[⟨z¯0⟩], is–sorted[⟨z0, z¯0⟩].
Prove ⟨⟩ = ⟨z0, z¯0⟩ ≈ c[⟨⟩, ⟨z0, z¯0⟩] and is–sorted[c[⟨⟩, ⟨z0, z¯0⟩]].
The assumption ¬is–sorted[⟨z¯0⟩] and is–sorted[⟨z0, z¯0⟩] contradict each other.
Hence, this case is not possible.

Induction Base for Y , Induction Step for Z, Z, Second Case:
Assume
is–sorted[⟨z¯0⟩], ⟨⟩ = ⟨z¯0⟩ ≈ c[⟨⟩, ⟨z¯0⟩], is–sorted[c[⟨⟩, ⟨z¯0⟩]], is–sorted[⟨z0, z¯0⟩]. Prove ⟨⟩ = ⟨z0, z¯0⟩ ≈ c[⟨⟩, ⟨z0, z¯0⟩] and is–sorted[c[⟨⟩, ⟨z0, z¯0⟩].
CASE z¯0 =(the empty sequence):
⟨⟩ = ⟨z0, z¯0⟩ ≈ c[⟨⟩, ⟨z0, z¯0⟩] ↔ ⟨z0⟩ ≈ ceg[z0] ↔ (⟨z0⟩∈ ceg[z0] ∧ ⟨⟩ ≈
df o[z0, ceg[z0]]) ← (z0 ∈ ceg[z0] ∧ (df o[z0, ceg[z0]] = ⟨⟩)).
This proof fails but (by our requirement generation algorithm automatically) leads to the requirement
∀(z ∈ ceg[z] ∧ (df o[z, ceg[z]= ⟨⟩)).
z
Furthermore,
is–sorted[c[⟨⟩, ⟨z0, z¯0⟩] ↔ is–sorted[c[⟨⟩, ⟨z0⟩]] ↔ is–sorted[ceg[z0]].
The proof fails but (automatically) leads to the requirement
∀(is–sorted[ceg[z]]).
z



Algorithm Synthesis by Lazy Thinking: Second Round
It is clear that, with the requirements for the subalgorithm ’ceg’ introduced in the preceding round, one can get over the proof situation in which the first proof attempt was stuck and we come to the following proof situation:
Induction Base for Y , Induction Step for Z, Second Case:
Assume
is–sorted[⟨z¯0⟩], ⟨⟩ = ⟨z¯0⟩ ≈ c[⟨⟩, ⟨z¯0⟩], is–sorted[c[⟨⟩, ⟨z¯0⟩]], is–sorted[⟨z0, z¯0⟩]. Prove ⟨⟩ = ⟨z0, z¯0⟩ ≈ c[⟨⟩, ⟨z0, z¯0⟩] and is–sorted[c[⟨⟩, ⟨z0, z¯0⟩]].
CASE z¯0 = z1, z¯ (for certain z1, z¯): From the assumptions we know:
⟨⟩ = ⟨z1, z¯⟩ ≈ c[⟨⟩, ⟨z1, z¯⟩] ↔ ⟨z1, z¯⟩≈ ceg[z1, z¯], is–sorted[c[⟨⟩, ⟨z¯0⟩]] ↔ is–sorted[ceg[z1, z¯]], (is–sorted[⟨z0, z¯0⟩] ↔ is–sorted[⟨z0, z1, z¯⟩]
— (z0 ≥ z1 ∧ is–sorted[⟨z1, z¯⟩]) ↔ z0 ≥ z1 .

Now,
⟨⟩ = ⟨z0, z¯0⟩≈ c[⟨⟩, ⟨z0, z¯0⟩] ↔ ⟨z0, z1, z¯⟩≈ ceg[z0, z1, z¯]
— (z0 ∈ ceg[z0, z1, z¯] ∧ ⟨z1, z¯⟩ ≈ df o[z0, ceg[z0, z1, z¯]])
← (z0 ∈ ceg[z0, z1, z¯] ∧ (ceg[z1, z¯] ≈ df o[z0, ceg[z0, z1, z¯]])).
This proof fails but it leads to the requirement
∀ (z0 ∈ ceg[z0, z1, z¯] ∧ (ceg[z1, z¯] ≈ df o[z0, ceg[z0, z1, z¯]])).
z0,z1,z¯
Furthermore,
is–sorted[c[⟨⟩, ⟨z0, z¯0⟩]] ↔ is–sorted[c[⟨⟩, ⟨z0, z1, z¯⟩]] ↔ is–sorted[ceg[z0, z1, z¯]]. The proof fails, but it leads to the requirement

∀	 is–sorted[ceg[z1, z¯]]

⇒ is–sorted[ceg[z ,z , z¯]]	.

z0 ,z1,z¯  z0
≥ z1
0	1	


Algorithm Synthesis by Lazy Thinking: Third Round
It is clear that, with the additional requirements for the subalgorithm ’ceg’ introduced in the preceding round, one can get over the proof situation in which the proof attempt in the preceding round was stuck and we come to the following proof situation
Induction Step for Y, First Case:
Assume ¬is–sorted[⟨y¯0⟩] and is–sorted[⟨y0, y¯0⟩]. The assumptions contra- dict each other and, hence, this case is not possible.
Induction Step for Y, Second Case, Induction Base for Z: Assume:
is–sorted[⟨y¯0⟩],
 ⟨y¯0⟩= ⟨⟩ ≈ c[⟨y¯0⟩, ⟨⟩] ,
 is–sorted[c[⟨y¯0⟩, ⟨⟩]]
is–sorted[⟨y0, y¯0⟩] . 



Prove
 ⟨y0, y¯0⟩= ⟨⟩ ≈ c[⟨y0, y¯0⟩, ⟨⟩] .
 is–sorted[c[⟨y0, y¯0⟩, ⟨⟩]]

We will skip the details of the proof here. In fact it is similar to the proof in the previous round of exploration. The failing situations in the proof will lead to the following requirements:
∀is–sorted[cge[y]],
y
∀ (y0 ∈ cge[y0, y1, y¯] ∧ (cge[y1, y¯] ≈ df o[y0, cge[y0, y1, y¯]])),

y0,y1,y¯
∀
 is–sorted[cge[y1, y¯]]

⇒ is–sorted[cge[y ,y , y¯]]	.

y0,y1,y¯  y0
≥ y1
0	1	


Algorithm Synthesis by Lazy Thinking: Fourth Round
It is clear that, with the additional requirements for the subalgorithm ’cge’ introduced in the preceding round, one can get over the proof situation in which the proof attempt in the third round was stuck and we come to the following proof situation:
Induction Step for Y, Second Case, Induction Step for Z, First Case: Assume ¬is–sorted[⟨z¯0⟩] and is–sorted[⟨z0, z¯0⟩]. The assumptions contra-
dict each other. Hence, this case is not possible.

Induction Step for Y, Second Case, Induction Step for Z, Second Case:
Assume
is–sorted[⟨z¯0⟩],
⟨y0, y¯0⟩= ⟨z¯0⟩≈ c[⟨y0, y¯0⟩, ⟨z¯0⟩] ↔ ⟨y0, y¯0, z¯0⟩≈ c[⟨y0, y¯0⟩, ⟨z¯0⟩],
is–sorted[c[⟨y0, y¯0⟩, ⟨z¯0⟩]],
is–sorted[⟨z0, z¯0⟩] . 
Prove
⟨y0, y¯0⟩ = ⟨z0, z¯0⟩≈ c[⟨y0, y¯0⟩, ⟨z0, z¯0⟩] ↔ ⟨y0, y¯0, z0, z¯0⟩≈ c[⟨y0, y¯0⟩, ⟨z0, z¯0⟩] and
is–sorted[c[⟨y0, y¯0⟩, ⟨z0, z¯0⟩]].

Now we distinguish two cases.
CASE p[y0, z0]:
In this case,
⟨y0, y¯0, z0, z¯0⟩ ≈ c[⟨y0, y¯0⟩, ⟨z0, z¯0⟩] ↔ ⟨y0, y¯0, z0, z¯0⟩≈ cgg1[y0, c[⟨y¯0⟩, ⟨z0, z¯0⟩]]. (*) By the induction hypothesis on Y
∀	 ⟨y¯0⟩= Z ≈ c[⟨y¯0⟩, Z]
is–tuple[Z]	is–sorted[c[⟨y¯0⟩, Z]]
is–sorted[Z]
we know, in particular, ⟨y¯0, z0, z¯0⟩ ≈ c[⟨y¯0⟩, ⟨z0, z¯0⟩].
We are now stuck at the proof of (*).
Now, with the requirements
∀	(Y ≈ Z ⇒ cgg1[x, Y ] ≈ cgg1[x, Z]),
x,is–tuple[Y, Z]
∀ ⟨y, y¯, z, z¯⟩≈ cgg1[y, ⟨y¯, z, z¯⟩]
y,y¯,z,z¯
we can prove (*):
(*) ↔ ⟨y0, y¯0, z0, z¯0⟩ ≈ cgg1[y0, ⟨y¯0, z0, z¯0⟩] ↔ true .
Furthermore,
is–sorted[c[⟨y0, y¯0⟩, ⟨z0, z¯0⟩]] ↔ is–sorted[cgg1[y0, c[⟨y¯0⟩, ⟨z0, z¯0⟩]]]. (**) We already know, by induction hypothesis on Y:
is–sorted[c[⟨y¯0⟩, ⟨z0, z¯0⟩]],
⟨y¯0, z0, z¯0⟩ ≈ c[⟨y¯0⟩, ⟨z0, z¯0⟩]
and we also know
is–sorted[⟨y0, y¯0⟩].
We are now stuck at the proof of (**).
However, with the (automatically generated) requirement
 is–sorted[Y ]	
 Y ≈ ⟨y¯, z, z¯⟩	
∀		is–sorted[⟨y, y¯⟩] ⇒ is–sorted[cgg1[y, Y ]]

y,y¯,z,z¯,is–tuple[Y ]
	is–sorted[⟨z, z¯⟩]
 p[y, z]


we can successfully get over this proof situation. CASE ¬p[y0, z0]:
This case is similar. We do not give the details. From the proof situation
in which the proof in this branch is stuck, the following requirements can be generated (automatically):

∀	(Y ≈ Z ⇒ cgg2[x, Y ] ≈ cgg2[x, Z]),
x,is–tuple[Y, Z]
∀ ⟨y, y¯, z, z¯⟩ ≈ cgg2[z, ⟨y, y¯, z¯⟩],

y,y¯,z,z¯


∀
 is–sorted[Y ]
 Y ≈ ⟨y, y¯, z¯⟩
	is–sorted[⟨y, y¯⟩]



⇒ is–sorted[cgg2[z, Y ]] .

y,y¯,z,z¯,is–tuple[Y ]
 is–sorted[⟨z, z¯⟩]
 ¬p[y, z]



Summary of the Requirements for the Subalgorithms
We now collect all the requirements on the subalgorithms cee, ceg, cge, cgg1, cgg2:
is–tuple[cee],
∀ is–tuple[ceg[x, x¯]],
x,x¯
∀ is–tuple[cge[x, x¯]],
x,x¯
∀	 is–tuple[cgg1[x, X]] ,
x,is–tuple[X]  is–tuple[cgg2[x, X]]
cee = ⟨⟩,
∀(z ∈ ceg[z] ∧ (df o[z, ceg[z]]) = ⟨⟩,
z
∀(is–sorted[ceg[z]]),
z
∀ (z0 ∈ cge[z0, z1, z¯] ∧ (ceg[z1, z¯] ≈ df o[z0, ceg[z0, z1, z¯]])),
z0,z1,z¯

∀	 is–sorted[ceg[z1, z¯]]

⇒ is–sorted[ceg[z ,z , z¯]]	,

z0,z1,z¯  z0
≥ z1
0	1	

∀is–sorted[cge[y]],
y
∀ (y0 ∈ cge[y0, y1, y¯] ∧ (cge[y1, y¯] ≈ df o[y0, cge[y0, y1, y¯]])),

y0,y1,y¯

∀
 is–sorted[cge[y1, y¯]]

⇒ is–sorted[cge[y ,y , y¯]]	,

y0,y1,y¯  y0
≥ y1
0	1	

∀	(Y ≈ Z ⇒ cgg1[x, Y ] ≈ cgg1[x, Z]),
x,is–tuple[Y, Z]
∀ ⟨y, y¯, z, z¯⟩ ≈ cgg1[y, ⟨y¯, z, z¯⟩],

y,y¯,z,z¯



∀
 is–sorted[Y ]
 Y ≈ ⟨y¯, z, z¯⟩
	is–sorted[⟨y, y¯⟩]



⇒ is–sorted[cgg1[y, Y ]] ,

y,y¯,z,z¯,is–tuple[Y ]
 is–sorted[⟨z, z¯⟩]
 p[y, z]


∀	(Y ≈ Z ⇒ cgg2[x, Y ] ≈ cgg2[x, Z]),
x,is–tuple[Y, Z]
∀ ⟨y, y¯, z, z¯⟩ ≈ cgg2[z, ⟨y, y¯, z¯⟩],

y,y¯,z,z¯



∀
 is–sorted[Y ]
 Y ≈ ⟨y, y¯, z¯⟩
	is–sorted[⟨y, y¯⟩]



⇒ is–sorted[cgg2[z, Y ]].

y,y¯,z,z¯,is–tuple[Y ]
 is–sorted[⟨z, z¯⟩]
 ¬p[y, z]


The most natural definitions of algorithms satisfying these requirements



are the following:

cee = ⟨⟩,
∀(ceg[x¯]= ⟨x¯⟩),
x¯
∀(cge[y¯]= ⟨y¯⟩),
y¯

∀	(cgg1[x, Z]= x × Z),
x,is–tuple[Z]
∀	(cgg2[y, Z]= y × Z) . 
y,is–tuple[Z]
(However, if one embarks on synthesizing cgg1, cgg2 from the elementary tuple operations available in the knowledge base, it is again advisable to first simplify the above requirements to a few essential ones using simple symbolic computation proof techniques, without induction.)

Third Case Study: Sorting by Insertion
Remark
Of course, sorting by insertion can be viewed as a degenerate case of sorting by merging: If left-split degenerates to the function that just takes the left-most element out of a given tuple then sorting by merging (an n log n algorithm) becomes sorting by insertion (an n2 algorithm).
The interest of the third case study does, therefore, not lie in the fact that
sorting by insertion can be synthesized but lies in the investigation of what happens if we start with the same algorithm specification of ’is-sorted-version’ as in the first case study, namely,
∀	is–sorted–version[X, sorted[X]]
is–tuple[X]
but throw in a different algorithm scheme.

Algorithm Scheme
This time we use the following algorithm scheme
sorted[⟨⟩]= c,
∀(sorted[⟨x⟩]= d[x]),
x
∀ (sorted[⟨x, y, z¯⟩]= i[x, sorted⟨y, z¯⟩]),
x,y,z¯
with the following natural type requirements on the auxiliary functions


is–tuple[c],
∀is–tuple[d[x]],
x
∀	is–tuple[i[x, Y ]] .
x,is–tuple[Y ]
The corresponding inductive proof technique is:
For proving	∀	A[X] do the following:
is–tuple[X]
Prove A[⟨⟩].
Take x0 arbitrary but fixed and prove A[⟨x0⟩].
Take x0, y0 and z¯0 arbitrary but fixed, assume A[⟨y0, z¯0⟩] and prove A[⟨x0, y0, z¯0⟩].

Algorithm Synthesis
We start with an attempt to prove
∀	is–sorted–version[X, sorted[X]].
is–tuple[X]
We do not show the proof attempts for the two base cases. Analyzing the failing situations in these two attempts readily leads to the two requirements
c = ⟨⟩
and
∀d[x]= ⟨x⟩.
x
Now we do the induction step. For this, we take x0, y0, and z¯0 arbitrary but fixed and assume
is–sorted–version[⟨y0, z¯0⟩, sorted[⟨y0, z¯0⟩]]

i.e.




and prove i.e

is–tuple[sorted[⟨y0, z¯0⟩]] (A1),
⟨y0, z¯0⟩≈ sorted[⟨y0, z¯0⟩] (A2),
is–sorted[sorted[⟨y0, z¯0⟩]] (A3),

is–sorted–version[⟨x0, y0, z¯0⟩, sorted[⟨x0, y0, z¯0⟩]]
is–sorted–version[⟨x0, y0, z¯0⟩, i[x0, sorted[⟨y0, z¯0⟩]]]

which we expand to

is–tuple[i[x0, sorted[⟨y0, z¯0⟩]]]  (G1),
⟨x0, y0, z¯0⟩ ≈ i[x0, sorted[⟨y0, z¯0⟩]] (G2),
is–sorted[i[x0, sorted[⟨y0, z¯0⟩]]]  (G3).
Now, (G1) follows from the type requirement on i and (A1).
The proof of (G2) and (G3) fails. However, the following requirements for i can be readily (i.e. automatically) generated from the temporary assumptions and goals:
∀	 ⟨y, z¯⟩ ≈ Y	⇒  ⟨x, y, z¯⟩≈ i[x, Y ]  .

x,y,z¯,is–tuple[Y ]  is–sorted[Y ]
 is–sorted[i[x, Y ]] 

With these requirements, the proof can be completed.
In fact, together with the type requirement on i, these requirements char- acterize the natural properties of ”insertion algorithms”.

Automation of the Lazy Thinking Algorithm Synthe- sis Procedure
The ”lazy thinking” procedure for inventing algorithms together with their correctness proofs can be made completely automatic (algorithmic) if we man- age
to automate (inductive) proving in the specific area and
to automate generating conjectures (requirements on auxiliary functions) from the temporary assumptions and the left-over goals in failing proof attempts.
In fact, for the case of inductive domains, there are powerful automated provers around and we have implemented various such provers in the Theorema system. Also, we already implemented a first version of a conjecture generation algorithm which, together with our automated inductive provers, is powerful enough to completely automate the ”lazy thinking” algorithm invention and verification process in the case of quite some problems on tuples.
Our current conjecture (requirements) generation algorithm implements two stratregies that can handle the two situations in the above example but also in many other examples. Both strategies take the conjunction A of all temporary assumptions and the (conjunction of the) temporary goals G and conjecture a variant of (A ⇒ G):
The first strategy can handle simple failing proof situations in proofs (proof

branches) without induction: It replaces all ”arbitrary but fixed” constants in (A ⇒ G) by variables v,... and produces the conjecture ∀ (A ⇒ G). By
v,...
this strategy, one can produce, for example, the conjecture (requirement)
∀	(special[X]= X)
is–trivial–tuple[X]
in the first round of the first case study.
The second strategy can handle failing proof situations in the induction step parts of proofs. It first looks in (A ⇒ G) for terms whose head is the function constant for the algorithm to be synthesized (in our case, this is the function constant ’sorted’) and replaces these with new variables v,... of the same type as the output of the unknown function and then, again, replaces all ”arbitrary but fixed” constants by variables w,.  The variant
∀	(A ⇒ G) is taken as the new conjecture. By this strategy, one can
v,...,w,...
produce the requirements in the induction steps of all the above case studies, for example the requirement
 left–split[X] ≈ Y	

∀	
right–split[X] ≈ Z
⇒  merged[Y, Z] ≈ X	

is–tuple[X,Y,Z]
 is–sorted[Y ]


 is–sorted[merged[Y, Z]] 

in the first case study.
Our future research will focus on adding more and more strategies to the conjecture generation algorithm. Of course, never, one conjecture generation algorithm will be able to handle ”all” failing proof situations. However, we think that the lazy thinking cascade will be a useful tool for organizing the theory exploration process and, in particular, the algorithm invention process. The cascade becomes more and more powerful the more powerful theorem provers and conjecture generation algorithms will be used as subalgorithms and the better we understand and organize libraries of algorithm schemes.
With the current Theorema induction prover and the current Theorema conjecture generator, the above synthesis process can be executed completely automatically. This means that the user has only to compile the knowledge on the predicate ’is-sorted-version’ and its auxiliary notions shown in the appendix and then to call Theorema by


Prove[T heorem[”correctness of sorting”], using → T heory[”sorting”],
by → Cascade[SqnsEqCaseP C, GenerateConjectures]]
Here, T heory[”sorting”] is the name of the theory consisting of the formulae in the appendix. In Theorema, this name can be assigned to the formulae by executing
Theory [”sorting”,


∀
is–tuple[X]

is–sorted–version[X, Y ] ⇔

is–sorted[⟨⟩]
∀is–sorted[⟨x⟩]
x
is–tuple[Y ]	
is–sorted[Y ]	

... all formulae in the appendix ... ]
Similarly, T heorem[”correctness of sorting”] is the name of the correctness theorem for sorting. This name can be assigned by executing
Theorem[”correctness of sorting”,
∀	is–sorted–version[X, sorted[X]]]
is–tuple[X]
’SqnsEqCasePC’ is the name of the particular induction prover that cor- responds to the ”divide–and–conquer” algorithm scheme. This prover adds the formulae that constitute the algorithm scheme, i.e. the formulae



∀
is–tuple[X]
sorted[X]=  merged[sorted[left–split[X]],	,



∀
is–tuple[X]
sorted[right–split[X]]]	otherwise
is–tuple[left–split[X]],

¬is–trivial–tuple[X]
... etc ... 

to the knowledge and organizes the main loop of the proof by the particular induction scheme. The strategy implemented by this prover is the following: first apply the induction scheme, then expand the case statement (from the definition of the algorithm), then finally apply rewriting and natural deduction

to carry the proof through.
We are now working on a general induction prover that gets the information on the algorithm scheme (including the type requirements for the auxiliary functions and the appropriate induction scheme) directly from the library of algorithm schemes so that, without user interaction in between, the prover can attempt various algorithm syntheses successively.
Future work will also be dedicated to the development of algorithm type libraries and classification of algorithm types (some of this type of work has already been carried out by D.R. Smith, for instance in [18]).
As result of the above Theorema call ’Prove[Theorem[”correctness of sort- ing”],. . . ]’, after approximately 5 minutes computation time (on a Compaq Evo N610c, with Intel Pentium 4 1.8 GHz), the user will get
an augmented knowledge base that contains the requirements on the auxil- iary functions
∀	(special[X]= X),

is–trivial–tuple[X]

∀
 left–split[X] ≈ Y


⇒ 	

right–split[X] ≈ Z

merged[Y, Z] ≈ X


is–tuple[X,Y,Z]
 is–sorted[Y ]

 is–sorted[merged[Y, Z]] 

and a complete correctness proof for the divide–and–conquer algorithm that essentially looks like the proof developed in the preceding sections.

Conclusion
We presented a procedure for automated algorithm invention and verification. The proposed procedure
is natural
can also be used as a heuristic and didactic guide for the development of correct algorithms and their correctness proofs
uses algorithm schemes as condensed algorithmic knowledge
exploits the information gained from failing proof attempts of the correct- ness theorem
is able to generate conjectures (requirements on the sub-algorithms) from failing proofs
invents verified algorithms that can be used with an infinite spectrum of

possible subalgorithms (all those that satisfy the requirements)
emphasizes a layered approach in repeated, small extensions of theories.

References
Armando, A., A.Smaill, I. Green, Automatic Synthesis of Recursive Programs: the Proof- Planning Paradigm. Automated Software Engineering, Vol. 6(1999), pp. 329-356 .
Asperti, A. , B. Buchberger, J. H. Davenport (eds), ”Mathematical Knowledge Management, Proc. of the Second International Conference on Mathematical Knowledge Management, MKM 2003, February 2003, Bertinoro, Italy”. Lecture Notes in Computer Science, Vol. 2594(2003), Springer, Berlin - Heidelberg - New York, 223 pages.
Basin, D. , Y. Deville, P. Flener, A. Hamfelt, J. Fischer Nilsson. Synthesis of Programs in Computational Logic. In: M. Bruynooghe and K. K. Lau, ”Program Development in Computational Logic”, Springer-Verlag, to appear.
Buchberger, B., Theory Exploration with Theorema. Analele Universitatii Din Timisoara, Ser. Matematica-Informatica, Vol. XXXVIII, Fasc.2, (2000), (”Proceedings of SYNASC 2000, 2nd International Workshop on Symbolic and Numeric Algorithms in Scientific Computing”, Oct. 4-6, 2000, Timisoara, Rumania, T. Jebelean, V. Negru, A. Popovici eds.), pp. 9-32.
Buchberger, B., Algorithm Invention and Verification by Lazy Thinking. In: D. Petcu, V. Negru, D. Zaharie, T. Jebelean (eds), ”Proceedings of SYNASC 2003 (Symbolic and Numeric Algorithms for Scientific Computing, Timisoara, Romania, October 1-4, 2003)”, Mirton Publishing, ISBN 973-661-104-3, pp. 2-26.
Buchberger, B., Algorithm Retrieval: Concept Clarification and Case Study in Theorema. SFB Scientific Computing, Technical Report 2003-25, Research Institute for Symbolic Computation, Johannes Kepler University, Linz, Austria, October 2003.
Buchberger,B., O. Caprotti (eds.), ”Electronic Proceedings of the 1st International Workshop of	Mathematical	Knowledge Management”, September 24-26, 2001, Research Institute for Symbolic Computation (RISC), Hagenberg, Austria, http://www.risc.uni-linz.ac.at/institute/conferences/MKM2001/.
Buchberger, B., T. Jebelean, F. Kriftner, M. Marin, D. Vasaru, An Overview on the Theorema Project, In: W. Kuechlin (ed.), ”Proceedings of ISSAC’97 (International Symposium on Symbolic and Algebraic Computation, Maui, Hawaii, July 21-23, 1997)”, ACM Press 1997,
pp. 384-391.
Buchberger, B., C. Dupre, T. Jebelean, F. Kriftner, K. Nakagawa, D. Vasaru, W. Windsteiger, Theorema: A Progress Report. In: M. Kerber and M. Kohlhase (eds.), ”Symbolic Computation and Automated Reasoning (Proceedings of CALCULEMUS 2000, Symposium on the Integration of Symbolic Computation and Mechanized Reasoning, August 6-7, 2000, St. Andrews, Scotland)”, A.K. Peters, Natick, Massachusetts, pp. 98-113.
Buchberger, B., G. Gonnet, M. Hazewinkel (eds.) , ”Mathematical Knowledgement Management”, Special Issue of the Journal Annals of Mathematics and Artificial Intelligence, Vol. 38(2003), Nos. 1-3, Kluwer Academic Publishers.
Farmer, W.(ed.), The First North American Workshop on MKM (NA-MKM 2002) in Hamilton, Ontario, Canada, http://imps.mcmaster.ca/na-mkm-2002/.
Flener, P., Logic Program Schemata: Synthesis and Analysis. Technical Report BU-CEIS-9502, Bilkent University, Ankara (Turkey), 1995.
P.Flener, K.K. Lau, M.Ornaghi, Correct-schema-guided Synthesis of Steadfast Programs. In ”Proceedings of the Twelfth IEEE International Automated Software Engineering Conference”,
pp. 153-160, IEEE Computer Society, 1997.


Kraan, I., ”Logic Program Synthesis via Proof Planning”. Phd. thesis, Department of Artificial Intelligence, University of Edinburgh, 1993.
Schmidt, D.C., R.E. Johnson, M. Fayad, Software Patterns. Guest editorial for the Communications of the ACM, Special Issue on Patterns and Pattern Languages, Vol. 39, No. 10, October 1996.
Smith, D.R., Top-Down Synthesis of Divide-and-Conquer Algorithms. Artificial Intelligence 27(1)(1985),pp. 43-96. (Reprinted in ”Readings in Artificial Intelligence and Software Engineering”, Eds. C. Rich and R. Waters, Morgan Kaufmann Pub. Co., Los Altos, CA, 1986,
pp. 35-61).
Smith, D.R., KIDS: A semiautomatic program development system. IEEE Transactions on Software Engineering Special Issue on Formal Methods in Software Engineering 16(9)(M. Kerber and M. Kohlhase (eds.))(1990), pp.1024-1043.
Smith, D.R., Mechanizing the Development of Software. In ”Calculational System Design, Proceedings of the NATO Advance Study Institute”, Eds. M. Broy and R. Steinbrueggen, IOS Press, Amsterdam, 1999, pp. 251-292.
Srinivas, Y.V., R. Ju¨llig. Specware: Formal support for composing softwar e. In ”Proceedings of the Conference on Mathematics of Program Construction”, B. Moeller, Ed. LNCS 947, Springer-Verlag, Berlin, 1995, pp. 399-422.
http://hillside.net/patterns


Appendix


Definitions


is–tuple[Y ]	

∀
is–tuple[X],Y
is–sorted–version[X, Y ] ⇔
X ≈ Y
is–sorted[Y ]
,

is–sorted[⟨⟩],
∀is–sorted[⟨x⟩],
x
∀ is–sorted[⟨x, y, z¯⟩] ⇔  x ≥ y	,

x,y,z¯ 
⟨⟩ ≈ ⟨⟩,
∀ ⟨⟩ /≈ ⟨y, y¯⟩,
y,y¯
 is–sorted[⟨y, z¯⟩] 

∀ (⟨x, x¯ ≈ ⟨y¯⟩⟩ ⇔ (x ∈ ⟨y¯⟩∧ ⟨x¯⟩) ≈ df o[x, ⟨y¯⟩]),
x,x¯,y¯
∀x /∈ ⟨⟩,
x

∀ (x ∈ ⟨y, y¯⟩) ⇔ ((x = y) ∨ (x ∈ ⟨y, y¯⟩)),
x,y,y¯
∀df o[a, ⟨⟩]= ⟨⟩,
a
∀ df o[a, ⟨x, x¯⟩]=  ⟨x¯⟩	⇐ x = a  ,

a,x,x¯
∀⟨⟩ 9 ⟨y¯⟩,
y¯
∀ ⟨x, x¯⟩ > ⟨⟩,
x,x¯
 x × df o[a, ⟨x¯⟩] otherwise

∀ ⟨x, x¯⟩> ⟨y, y¯⟩ ⇔ ⟨x¯⟩ > ⟨y¯⟩,
x,x¯,y,y¯
∀ (x × ⟨y¯⟩ = ⟨x, y¯⟩),
x,y¯
∀(is–tuple[X] ⇔ ∃(X = ⟨x¯⟩)),
X	x¯
∀(is-empty-tuple[X] ⇔ (X = ⟨⟩)),
X
∀(is-singleton-tuple[X] ⇔ ∃(X = ⟨x⟩)),
X	x
∀(is–trivial–tuple[X] ⇔ (is-empty-tuple[X] ∨ is-singleton-tuple[X]).
X

Axioms
∀ (⟨x, x¯⟩ = ⟨y, y¯⟩) ⇔ ((x = y) ∧ (⟨x¯⟩ = ⟨y¯⟩)),
x,x¯,y,y¯
∀ ⟨x, x¯⟩ /= ⟨⟩.
x,x¯
Properties
∀	is–sorted[X],

is–trivial–tuple[X]
∀

(X ≈ Y ⇔ (X = Y )),

is–trivial–tuple[X],is–tuple[Y ]
∀	X ≈ X,
is–tuple[X]
∀	(X ≈ Y ⇒ Y ≈ X),
is–tuple[X,Y ]

∀	((X ≈ Y ∧ Y ≈ Z) ⇒ X ≈ Z),
is–tuple[X,Y,Z]
∀	(X > Y ⇒ Y /> X),
is–tuple[X,Y ]
∀	((X > Y ∧ Y > Z) ⇒ X > Z).
is–tuple[X,Y,Z]
