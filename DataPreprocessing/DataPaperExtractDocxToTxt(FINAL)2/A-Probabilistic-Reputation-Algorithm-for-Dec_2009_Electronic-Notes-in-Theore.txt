

Electronic Notes in Theoretical Computer Science 244 (2009) 139–149
www.elsevier.com/locate/entcs

A Probabilistic Reputation Algorithm for Decentralized Multi-Agent Environments
Mozhgan Tavakolifard1,3
Centre for Quantifiable Quality of Service in Communication Systems Norwegian University of Science and Technology, Trondheim, Norway
Svein J. Knapskog2,3
Centre for Quantifiable Quality of Service in Communication Systems Norwegian University of Science and Technology, Trondheim, Norway

Abstract
The importance of trust in electronic transactions is well understood. The majority of current trust models consist of a central entity that verifies compliance with the trust requirements, using standardized evaluation methods and criteria. In decentralized environments, the communication scenarios are more complex, and no universally accepted objective requirements or evaluation criteria exist. It should be noted that the situation would get even more complicated when agents are interacting with each other. The goal of this research is to model trust and reputation in decentralized multi-agent systems. To achieve this, we have chosen the Ntropi model, among several other models, as a starting point, The efficiency of the model in such scenarios has been significantly improved by introducing a new probabilistic reputation algorithm for the Ntropi model.
Keywords:  Bayesian inference, Dirichlet distribution, Maximum-likelihood estimation, Reputation, Trust.


Introduction
The rapidly changing environments of the internet suffer from problems like fragile trustworthiness of millions active entities on the internet, e.g., humans and mobile agents. This problem is nontrivial, as more and more commercial transactions get carried out over the internet. Therefore, devising an effective approach for verifi- cation of trustworthiness in such complex environments is essential, since the trust mechanisms play a key role in the security of multi-agent systems. Also the trust

1 Email: mozhgan@q2s.ntnu.no
2 Email: knapskog@q2s.ntnu.no
3 "Centre for Quantifiable Quality of Service in Communication Systems, Centre of Excellence" appointed by The Research Council of Norway, funded by the Research Council, NTNU and UNINETT. http://www.q2s.ntnu.no


1571-0661 © 2009 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2009.07.043

establishment is nontrivial, since the traditional and social means of trust cannot be applied directly to virtual settings of these environments because in many cases the involved parties did not have any previous interaction. In such scenarios, reputation techniques may be used to stimulate service quality and acceptable user behavior in online markets and communities, and also sanction possible unacceptable user behavior. To this end, the Ntropi model [1] was designed to facilitate the exchange of trust and reputation in information and/or business environments. The Ntropi classifies the trust into direct (explicit) and recommended classes. The direct class is based on the truster agent’s previous personal experiences with the trustee agent. But the recommended trustworthy class is derived from word-of-mouth (e.g., opin- ions), which is called reputation, and can be translated into direct or regular trust. This paper presents an automated and autonomous trust system using Bayesian inference along with improved Dirichlet distribution. Our main contributions are the application of maximum likelihood method in the trust/reputation model to estimate the parameters used in Dirichlet distribution, and also the introduction of a hierarchical Bayesian method in the proposed reputation management model. The maximum likelihood estimation method has been previously introduced in [5] as a feedback aggregation strategy. However, in this work the bootstrapping (when two unfamiliar agents face each other) is the main concern.
The rest of this paper is organized as follows: section 2 covers the relevant literature. In section 3 the Ntropi model and its analysis are presented. Section 4 discusses the proposed model in detail. Section 5 explains the experimental results and presents the evaluation process. Section 6 presents the conclusion and suggests future work.

Literature Review
We chose the Ntropi model [1] among several other models because: 1) this model is mainly designed for decentralized multi-agent systems, 2) it covers more trust aspects in this area than other models, 3) it is a well received model in academia, 4) its proposed elements have been incorporated into Sun’s JXTA framework [3] and Ericsson’s trust model [9,10]. The JXTA is an open source and a general purpose P2P framework currently available. Furthermore, the implementations have been analyzed in various popular P2P platforms such as Gnutella [7], Free Haven [12] and Freenet [4].
On the basis of recent surveys among existing reputation algorithms, the proba- bilistic algorithms, especially those with Bayesian inference seems to be more pop- ular. Because these algorithms have a sound mathematical basis and are known to be suitable to formulate human characteristics, they are more flexible than the Ntropi’s ad-hoc algorithm and need less interaction with users. Thus, the first feature in agent’s definition, autonomy, seems more realistic.
The majority of Bayesian-based reputation algorithms are binomial (e.g. [2]), allowing two-valued ratings, as either positive (e.g. good) or negative (e.g. bad). The main disadvantage of a binomial model is that it is not able to represent rat-

ings with graded levels such as e.g. mediocre - bad - average - good excellent. In addition, the binomial models are in principle not able to distinguish between polarized ratings (i.e. many very bad and many very good ratings) and average ratings. The Ntropi offers graded multinomial ratings: for example “very trust- worthy”, “trustworthy”, “moderate”, “untrustworthy”,and “very untrustworthy” which is more realistic. There are also several Bayesian based reputation models with graded ratings which seem more suitable. Some of these models have used Dirichlet as a priori distribution and multinomial models as likelihood distribution in their Bayesian inference.
Ntropi Model
In this section the Ntropi model by Farez Abdul-Rahman [1] which forms the basis of our proposed model, is explained and an analysis of the model is given.
Model Description
The Ntropi is a trust model that is truly decentralized. It has no reliance on any third party and all entities can decide for themselves how to trust. It uses both rep- utational and experiential information. Recommendation which is a single opinion and reputation which is multiple opinions are combined. Trust values have a five- level scale: “very trustworthy”, “trustworthy”, “moderate”, “untrustworthy”,and “very untrustworthy”. After receiving recommendations from recommenders about a prospect, a truster agent may decide to go ahead with the interaction. After that, he may give his experience a rating and notice the difference between his own rating and the recommended rating. This difference (called semantic distance in this model) shows the difference in rating standards.
These differences are recorded so that in the future the truster agent can adjust his trust values accordingly. Based on this history of differences, a translation table will be formed and recommendations will be translated. In order to turn “what he said” into “what we think he means” we get the most common semantic distances and add that to the recommended value. In order to combine more than one recommendation and calculating reputations, we need to know the trust in each recommender and give more weight to recommendations from more trustworthy recommenders. In Ntropi model, a trust relationship goes through phases. At any point in time, a trust relationship will exist in one of four phases, as shown in Fig.1. Recommendations in different phases may be considered in different ways.
We calculate our trust in the recommender based on the consistency of the recommenders’ previous recommendations. If the distributions of semantic distances are more spread out, then there is less consistency. The less the spreading is, the more consistent the recommender is regarded to be. In this model the consistency is obtained by first finding the semi-interquartile ranges (SIQR) of the ordered set of semantic distances for the active context, rounded to the nearest integer. Then a lookup table is used to convert the SIQR into a trustworthiness level. Then we assign weights to recommenders according to their trust value. For each recommended



Fig. 1. Phases of a trust relationship, with arrows indicating possible direction of phase transition.
trust value the weights of those who recommended it will be summed up. The final reputation value is the trust value with the highest sum-of-weights.
If a recommender is not known by the recommendation requester, the requester can obtain recommendations about the unknown recommender. There is also the scenario where a recommendation requester may carry out a network search for a particular agent and the received recommendation may be the result of the re- quest being forwarded through a number of intermediary recommenders. In both scenarios, when a recommender recommends another recommender, the result is a recommendation chain. The heads of the chain may contain more than one known recommender, all of which recommends the same first intermediary of the chain. an agent seeking recommendations about an unknown prospect will request recom- mendations from those recommenders that he already knows and trusts. Thus, a chain’s heads should be a known recommender [1].
Model Analysis
Our analysis of Ntropi model is as follows:
The SIQR method is just one approach for finding the spread of semantic distances in this model. Other measures of dispersion in the data may be more appropriate for different applications, especially one where the requirement of unbounded, unimodal and symmetrical distribution (for which the SIQR is suitable for) does not exist.
The SIQR, however, does not include all data points in the distribution, which may be another consideration when determining an appropriate spread measure- ment the standard deviation, for example, does include all data points.
Furthermore, when converting the SIQR (or whatever the spread measure is) into a trust level, linear conversion need not be assumed. However, one may select different trust values for each SIQR value, depending on the weight one gives to the different SIQR/spread values.
Another possible weakness of the approach taken in the Ntropi, where all chain heads must be known, is that it will not be possible to accept recommendations from chains with unknown heads, even if the requester is willing to use those

recommendations. An example where unknown recommenders may be useful is when the alternative is to have no recommendation at all. This situation is analogous to asking for directions on the street, and demonstrate that at times one may successfully use advice from a stranger, i.e. when nothing is known about the recommending agent. This is particularly true in situations where possession of any information is better than no information, and, at the same time, there is belief in the benevolence of the recommender as well as low perceived risk.
We shall observe here that the weighted trust level approach provides a potential for customization and flexibility in weighting recommendations based on the trust levels of their recommenders. However, it also adds to the user’s list of tasks to perform, namely that he must be able to define, and, if required, adjust the weights for each application that uses this model. In reality, this is not a very satisfactory situation since it will require additional help from the application itself in terms of either hardwiring the weighting based on well known properties of agents in the application domain, or employing some form of learning algorithm that can dynamically update the weights based on experience.
Since its reputation algorithm results in the selection of recommendations with the highest weightings, it will potentially be ignoring other recommendations that also originated from trustworthy recommenders, albeit from those with lower com- parative trustworthiness levels. Given a sufficiently high number of recommen- dations (for the same trust value) from lower trust recommenders, their recom- mended trust values may still be the winning value because their sum-of-weights will outweigh the recommenders with higher trust but with a lower population within the local set of recommendations. A better algorithm would be one where a new trust value is produced by the reputation/combination algorithm based on the recommendations received from all the trusted recommenders from the whole range of trust levels.

The Proposed Reputation Algorithm
The new reputation algorithm proposed in this paper is based on the Dirichlet reputation algorithm (as also) proposed by A. Jøsang [8]. We have improved this algorithm by using Maximum Likelihood Estimation method to estimate the pa- rameters (for this algorithm) based on the observed data.
Jøsang’s reputation algorithm is based on Bayes Theorem.
P (Θ|X) ∝ P (X|Θ).P (Θ)	(1)
Reading from left to right, the formula is interpreted as saying: the probability of the hypotheses Θ posterior to the outcome of experiment X is proportional to the likelihood of such outcome under the hypotheses multiplied by the probability of the hypotheses prior to the experiment. In the present context, the prior Θ will be an estimate of the probability of each potential outcome in our next interaction with principal p, whilst the posterior will be our amended estimate after one such

interaction took place with outcome X.
It is important to observe here that P (Θ|X) is in a sense a second order notion, and we are not interested in computing it for any particular value of Θ. Indeed, as Θ is the unknown in our problem, we are interested in deriving the entire distri- bution in order to compute its expected value, and use it as our next estimate for trustworthiness.
In Ntropi model, trustworthiness of an agent can be referred as “very trustwor- thy”, “trustworthy”, “moderate”, “untrustworthy”,and “very untrustworthy”. So the rating level is a discrete set. But in the Bayesian model the rating is a real number between 0 and 1. We should use a multinomial probability distribution for the likelihood in the Bayesian inference. Then the conjugate prior distribution will be Dirichlet distribution.
Definition 4.1 Agent A’s trust in agent B is the accumulation of evaluations that agent A has of its past interactions with B. It reflects agent A’s subjective viewpoint of B’s capability. Trust value is denoted by θdt because it is direct trust.
Definition 4.2 The reputation of agent B, from agent A’s perspective, is the col- lective evaluation based on other agents’ evaluations of B. It is an objective measure for agent B’s capability, resulting from the evaluations of many other agents. Rep- utation value is denoted by θrt because it is recommendation trust.
The estimator for successful cooperation is a combination of trust value and reputation value.
θˆ = w1θˆdt + w2θˆrt	(2)
Where w1 and w2 satisfy w1 +w2 = 1. They are weights to represent the importance of these two probabilities respectively and are decided by the personal characteristics of the agents.
The Unfamiliar Phase
The maximum-likelihood method estimates the parameters for the Dirichlet dis- tribution. The parameters are not available in closed-form. We use a simple and efficient iterative scheme for obtaining the parameter estimates in this model from past experiences with other agents. This is our main contribution.
The Dirichlet distribution captures a sequence of observations of the k possible outcomes with k positive real parameters α(θi), i = 1...k, each corresponding to one of the possible outcomes. The parameter α can be estimated from a training set with proportions: D = {p1, p2, ..., pN }.
If agents A and B are complete strangers, i.e. B is in the unfamiliar phase with respect to A when these two strangers first meet, then A will need to collect those past experiences within the same context (context qualifies a trust opinion, describing what the truster’s belief in another’s trustworthiness is really about) as that in which he encounters B and summarize that set of experiences which will be the training set D. There are two classes of generalized information, called classifiers, which A can use for forming the set D when estimating the parameter

α: Context Experience and Stereotype. Table 1 details these two generalization classifiers.
Table 1
Generalized information classifier for first encounters


The maximum likelihood estimate of α maximizes p(D|α) =  i p(Pi|α). The log-likelihood can be written
log p(D|α)= N log Γ(Σ αk)−N Σ log Γ(αk)+ N Σ (αk − 1) log p¯k	(3)
k	k	k
Where log p¯k =  1 Σ log pik
i
This objective is convex in in α since the Dirichlet distribution is the exponential family. This implies that the likelihood is unimodal and the maximum can be found by a simple search. The gradient of the log-likelihood with respect to one αk is

g  = d log p(D|α) = N Ψ(Σ α ) − N Ψ(α )+ N log p¯
(4)

k	dαk
k	k	k
k



Ψ(x)= d log Γ(x)
dx
(5)

Ψ is known as the digamma function and is similar to the natural logarithm. As always with the exponential family, when the gradient is zero, the expected sufficient statistics are equal to the observed sufficient statistics. In this case, the expected sufficient statistics are
E[log pk]= Ψ(αk) − Ψ(Σ αk)	(6)
k
The observed sufficient statistics are a log pk.A fixed-point iteration for maximizing the likelihood, and can be derived as follows. Given an initial guess for α, we construct a simple lower bound on the likelihood which is tight at α. The maximum

of this bound is computed in closed-form and it becomes the new guess. Such iteration is guaranteed to converge to a stationary point of the likelihood. For the Dirichlet, the maximum is the only stationary point.
As shown in [11], a bound on Γ(Σ αk) leads to the following fixed-point iteration:
k
Ψ(αnew)= Ψ(Σ αold) + log p¯k	(7)
k	k
k
This algorithm requires inverting the Ψ function a procedure which is described in [11].

The Trusted and the Unstable Phases
Assume that A is the truster agent, B is the trustee agent and C is the recommender agent. Let there be k different discrete rating levels. This translates into having a state space of cardinality k for the Dirichlet distribution (in the case of our model k is 5). Let the rating level be indexed by i.
Each new rating of agent B by an agent C takes the form of a trivial vector where only one element has value 1, and all other vector elements have value 0. The index i of the vector element with value 1 refer to the specific rating level.
As a result of a new rating, the rating vector will be updated by adding the newly received rating vector r to the previously stored vector R (Bayesian infer- ence). Agents may change their behavior over time, so it is desirable to give rela- tively greater weight to more recent ratings. This can be achieved by introducing a longevity factor λ ∈ [0, 1]; which controls the rate at which old ratings are aged and discounted as a function of time. With λ = 0, ratings are completely forgotten after a single time period. With λ = 1, ratings are never forgotten. After encounters with other agents new α will be calculated as follows:
αnew = αold.λ + R	where 0 ≤ λ ≤ 1	(8) In order to adjust λ after each interaction (8) is used.

λnew =
λold + SIM n
where	SIM =1 −
θˆrt − outcome k − 1
and n ≥ 2	(9)

In this formula, the similarity value (SIM ) between our estimate and the outcome of the interaction is calculated first. If θˆrt and outcome are the same, then SIM
will be equal to 1, otherwise will be less than 1 and greater than 0. The maximum value of their difference is k − 1 , and in this case SIM will be equal to 0. Based on the similarity between our estimation and the outcome of the interaction, the new value of λ will be calculated. In this formula, n is a natural number greater than or equal to 2 and is decided based on the application. For example, in risky applications, after a change in the behavior of the agent, the value of λ should be decreased sharply. Therefore greater value of n is needed.

Then we calculate the expected value for the Dirichlet distribution:
	α(θi)	

E(p(θi)|α)=	k
i=1
(10)
α(θi)

The reputation score can be expressed as a single value in some predefined interval. This can be done by assigning a point value θˆrt to each rating level i (evenly dis- tributed oint values in the range [0, 1] for k different rating levels), and computing
the normalized weighted point estimate score. The point estimate reputation score is then computed as:
θˆ = Σ i − 1 E(p(θ )|α)	(11)

rt
i=1
k − 1	i

Evaluation
To evaluate the performance and efficiency of the proposed algorithm a popular trust and reputation testbed for agent systems was used which is called ART. It is devel- oped through a joint effort of Texas University, EMSE from France, ISTC from Italy and CWI from the Netherlands. The Agent Reputation and Trust (ART) Testbed
[6] initiative has been launched with the goal of establishing a testbed for agent reputation- and trust related technologies. The ART Testbed serves two purposes:
(1) as a competition forum in which researchers can compare their technologies against objective metrics, and (2) as a suite of tools with flexible parameters, allow- ing researchers to perform customizable, easily repeatable experiments. Annually, a workshop regarding ART’s application is held in connection with the Autonomous Agent and Multi-agent Systems conference (AAMAS) which aims to bring together researchers who can contribute to a better understanding of trust and reputation in agent societies.
The reasons for this choice are: 1) as a versatile, universal experimentation site, the ART Testbed covers relevant trust research problems and unites researchers towards solutions via unified experimentation methods 2) Through objective, well- defined metrics, the testbed provides researchers with tools for comparing and val- idating their scientific models and the possibility of comparing a new model with previous models, 3) Standing on the shoulder of giants, and 4) reusability. We com- pared the proposed model with the Ntropi and have shown a considerable increased efficiency.
Metrics of Analysis in the testbed
In general, the most successful agent is selected as the appraiser with the highest bank account balance. In other words, the appraiser who is able to (1) estimate the value of its paintings most accurately and (2) purchase information most prudently, is deemed most successful. The Testbed also provides functionality to compute the average accuracy of the appraiser’s final appraisals and the consistency of that accuracy, represented as its final appraisal error mean and standard deviation, re-

spectively. In addition, the quantities of each type of message passed between appraisers are recorded [6].
Simulation Results
The Agent Skeleton is designed to allow researchers to implant within their appraiser agent-customized trust representations and algorithms while permitting standard- ized communication protocols with other entities. All appraiser agents participating in the ART Testbed are descendants of the same abstract class Agent. This class de- fines a set of abstract methods to be coded by the researcher to define the behavior of his/her appraiser agent, as well as a set of methods to facilitate the commu- nication with other appraiser agents. The Agent class also provides methods for interacting with the Simulation Engine (for tasks such as verifying bank balances).
We used game rules similar to the rules in ART Testbed Competition 2007:
Average-Clients-Per-Agent=20
Client-Fee=100.0
Opinion-Cost=10.0
Reputation-Cost=0.1
Timesteps-per-Session: 40
The game consisted of 12 agents from 4 different types:
Simple: agents that do not use any model for trust related decisions.
Ntropi: agents that use the Ntropi model for trust related decisions.
Improved: agents that use the improved model for trust related decisions.
Dummy: three dummy agents from the testbed itself which we used to have a more realistic environment.
Fig. 2 shows the results. The horizontal axis in Fig. 2 shows timesteps and the vertical axis is bank Total (the agent’s bank balance). All of the improved agents have higher bank accounts during all time steps, and this shows their better performance.
Conclusion
The main contributions of this paper are that we have employed a second Bayesian algorithm in order to estimate the parameters for the priori trust, used a Dirich- let distribution and introduced a new Hierarchical Bayesian-based reputation al- gorithm. In addition, we used the Maximum Likelihood Estimation algorithm to estimate the parameters of the Dirichlet distribution.

References
A. Abdul-Rahman and S. Hailes. A distributed trust model. Proceedings of the 1997 workshop on New security paradigms, pages 48–60, 1998.








Fig. 2. Results.
S. Buchegger and J.Y. Le Boudec.  A Robust Reputation System for Mobile Ad-hoc Networks.
Proceedings of P2PEcon, June, 2004.
R. Chen and W. Yeager. Poblano: A Distributed Trust Model for Peer-to-Peer Networks. JXTA Security Project White Paper, pages 1–26, 2001.
I. Clarke, SG Miller, TW Hong, O. Sandberg, and B. Wiley. Protecting free expression online with Freenet. Internet Computing, IEEE, 6(1):40–49, 2002.
Z. Despotovic and K. Aberer. Maximum Likelihood Estimation of Peers’ Performance in P2P Networks.
2nd Workshop on Economics of Peer-to-Peer Systems, Cambridge, MA, USA, June, 2004.
K.K. Fullam, T.B. Klos, G. Muller, J. Sabater, A. Schlosser, Z. Topol, K.S. Barber, J.S. Rosenschein,
L. Vercouter, and M. Voss. A specification of the Agent Reputation and Trust (ART) testbed: experimentation and competition for trust in agent societies. Proceedings of the fourth international joint conference on Autonomous agents and multiagent systems, pages 512–518, 2005.
Gnutella Protocol DevelopmentAn Overview of 0.6. Protocol Specification.
A. Jøsang and J. Haller. Dirichlet reputation systems. Proc of the Second International Conference on Availability, Reliability and Security (ARES), 2007.
K. Quinn and A. Leddy. ebs/cd/a- 04:000737 uen. Technical report, Ericsson research, 2004.
K. Quinn, D. OSullivan, D. Lewis, R. Brennan, and V.P. Wade. deepTrust Management Application for Discovery, Selection, and Composition of Trustworthy Services. Proceedings of IDIP/IEEE 9th International Symposium on Integrated Network Management (IM 2005), Nice, France, May, 2005.
G. Ronning. Maximum likelihood estimation of dirichlet distributions. Journal of Statistical Computation and Simulation, 32(4):215–221, 1989.
B.T. Sniffen. Trust Economies in the Free Haven Project. PhD thesis, MASSACHUSETTS INSTITUTE OF TECHNOLOGY, 2000.
