Electronic Notes in Theoretical Computer Science 171 (2007) 21–41	
www.elsevier.com/locate/entcs

Handshake Games
Luca Fossati1 ,2
Dipartimento di Informatica Universita` di Torino Torino, Italia

Abstract
In this paper I present a game model for the semantical analysis of handshake circuits. I show how the model captures effectively the composition of circuits in an associative way. Then I build a compact-closed category of handshake games and handshake strategies. I then consider the language Tangram and I define a semantics for this language simply by giving a denotation in the model to each handshake component that is used in the compilation of Tangram programs.
Keywords: Game semantics, handshake circuits, nondeterminism, concurrency, associativity.


Introduction
The handshake protocol has experienced a great commercial success as a paradigm for asynchronous communication and computation. It is a protocol of communica- tion between circuits, which are connected through channels over which they ex- change information. In particular a circuit sends a message over a channel through an interface called port. In a communication over a single channel, one circuit takes the active role and sends the first message while the other is initially waiting for an activation sign. Then the former waits for the latter to reply, and so on. From a circuit’s point of view, this behavior induces an alternating sequence of input and output messages, requests and acknowledges.
The handshake technology has been employed in parts of several integrated sys- tems and in the Philips Research Labs Van Berkel et al. have developed a language called Tangram, a Hardware Design Language (HDL), so that hardware design be- comes simply a programming task. One reason why this is possible is modularity, with an architecture that does not rely on a central clock. Modularity also helps

1 I thank Felice Cardone for having started me on the subject, Russ Harmer, Paul-Andr´e Melli`es and Pierre-Louis Curien for useful hints on the critical part, Simonetta Ronchi Della Rocca for support and directions.
2 Email: fossati@di.unito.it

1571-0661 © 2007 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2006.11.034

these circuits gain in efficiency and speed, a slow module has a lower impact on the overall system. Another language in which programs are compiled into handshake circuits has been developed by the Department of Computer Science at the Uni- versity of Manchester [6] and is called Balsa. But in contrast with the increase of interest in the implementations of the protocol, the foundational investigation rests still as it was ten years ago. For example, in the semantics of Tangram proposed by Van Berkel data exchange is not taken into account [7], and since then no other semantics has filled this hole. Moreover all the literature relies on Van Berkel’s model [28]: indeed, a very natural characterization of circuits with a nice analysis of their behavior; however some points are still not treated in sufficient detail.
The main of these is surely the analysis of composition. The property of delay insensitivity allows us to ignore the order in which messages reach destination, to do as if it was the same order in which they have been sent ([28], page 75). Still, it remains not trivial to model composition precisely. Surely handshake circuits compose and surely they compose in the same way no matter the order of compo- sitions (associativity): in the end it is just the same physical phenomenon observed from different angles... but, does the model capture the observation of the physical phenomenon faithfully? Is any quiescent point (inside a communication) taken into account by the model? As expected, the problem rises in presence of the “infa- mous” inﬁnite internal chatters and really causes big troubles, as associativity of composition is a fundamental property.
While looking deeper into the issue I found a counter-example to the associa- tivity of composition in Van Berkel’s model. Later on, Russ Harmer pointed out to me another counter-example, due to Roscoe [27], which tells that any model of un- bounded nondeterminism must list explicitly the possibly infinite communications inside the process’ description. My counter-example is detailed in the Appendix (section 6).
The search for a solution was based on previous game semantics of nondeter- minism and concurrency [13][14][4][19][15][22] in which the problem of composition is treated in full detail. The choice is in part motivated by the many similarities between the game paradigm and the handshake protocol. The common view of computation as interaction is the key ingredient, from which follow several other correspondences, where all the dualisms are reflected. In most cases it is just a matter of switching to a new vocabulary:
player/opponent ⇐⇒ system/environment;
negative/positive ⇐⇒ passive/active;
move ⇐⇒ message;
P − move/O − move ⇐⇒ input/output;
query/response ⇐⇒ request/acknowledge.
One could also argue that games correspond to handshake structures and strate- gies to handshake processes 3 but on these aspects the correspondence is not so clear

3 This would allow one to give a neat definition of handshake circuits as specifications of behaviors over

in the handshake circuits literature. There is no clear distinction between a process and its structure, no concept of a type. This is another motivation for adopting the game formalism: definitely game models rely on powerful mathematical structures such as categories and logic, and these are the perfect tools for defining a type theory. The work could be placed inside Abramsky’s program to bridge the histori- cal gap in formal semantics, between the family of functional models (denotational semantics) and models of concurrency (process calculi) ([1] and [2], among other works).
Combining nondeterminism with concurrency and asynchrony has been a major issue to deal with. Moschovakis published several works in that direction (starting from [24]) but I believe the aim there was more directed to the verifications of prop- erties (fairness) than to the structural analysis, which makes his works essentially different from mine. A reasonable choice was to extend the model for finite non- determinism of Harmer and McCusker [13] but unfortunately that is justified only with the assumption of sequentiality of the overall communication (the strict alter- nance within plays). So I turned to countable nondeterminism [14], reformulated in a way that allows extension to parallelism. Basically in the new formalism, nonde- terministic strategies are seen as sums of deterministic strategies. The idea of such a presentation was given me by Paul-Andr´e Melli`es during a discussion and follows quite a few works in the literature, starting from [26] and including the works by Moschovakis.

Notations
In the following I will give a few definitions that always turn out useful when dealing with the formal aspects of concurrency. Some are inherited from Mazurkiewicz’s seminal work on trace theory [21], even though I changed them in order to fit them in the current context.
We define a concurrent alphabet as an alphabet M equipped with a binary reflexive symmetric and transitive relation D over its letters (moves, as we will call them). D is called the dependence relation. Being an equivalence relation, D decomposes the alphabet into equivalence classes which we call partitions. A string over ⟨M, D⟩ is just a string over M . The complementary relation is independence, I. Sometimes I might use D and I as relations on strings. In particular, for two strings s and t, s D t if there are two moves m and n, appearing in s and t respectively, and such that m D n.
Let ⟨M, D⟩ be a concurrent alphabet. Every string s over M has an underlying graph induced by D. The vertices are the moves in s and edges between two moves are present if and only if the two moves are dependent with each other. Any maximal clique is the underlying graph of a unique string t contained in s, where moves appear in the same order in t as they appear in s. We say t is a thread of
s. A thread could also be seen as a string over a partition of ⟨M, D⟩. The initial

structures.

move of a thread t is the first move that appears in t. The initial moves of a string
s are the initial moves of each of its threads.
Consider the above concurrent alphabet and let D'⊆D. D' is a full subdepen- dence of D when it preserves reflexivity, transitivity, and symmetry (the dependence relation of a partition is a full subdependence, for example). m ∈ M is involved in D' when ∃n ∈ M such that (m D' n). Now let D' be a full subdependence of D, s a string over M and M ' ⊆ M the set of moves involved in D'. We can define s T⟨M ', D'⟩ as the string obtained by keeping only the moves from M ' in the same order as they appear in s. Normally we write just s T M ' assuming we have a full subdependence associated to it.
Finally recall the standard order ± on strings s and t:
s ± t ⇐⇒ t = st'
where t' is a string over ⟨M, D⟩. We say that t is an extension of s with the moves in t'. We write len(s) for the length of a string s.

Handshake Games
Game. We can imagine a game as providing a universal structure over which several processes of the same kind can be implemented.
Definition 3.1 A handshake game is a structure A = ⟨MA, DA, λA⟩, where MA is a set of moves and DA a dependence relation on them. Together they form a concurrent alphabet on which we impose a finite number of partitions. λA :
MA → {−, +}× {R, A} is a labelling function, we denote with λ−+ and λRA its two
A	A
projections. The first one determines the polarity, the moves with positive polarity
are called player moves and those with negative polarity are called opponent moves. The second projection distinguishes requests (R) from acknowledges (A). We impose no ambiguity of labels within a partition. Given m, n ∈ MA such that m DA n:
λ−+(m)= λ−+(n) ⇐⇒ λRA(m)= λRA(n)
Example 3.2 The simplest case is the game 4 associated to a port structure, where all moves are in the same equivalence class, as they represent a set of messages which are all going to be sent over the same channel. For example, we can associate a generic passive port to a game A = ⟨MA = M1 ∪ M2, DA, λA⟩ such that:
M1 = {req(v) | v ∈ V1} and M2 = {ack(v) | v ∈ V2};
DA= MA × MA;
∀m ∈ M1, (λ−+(m)= −) ∧ (λRA(m)= R);
∀m ∈ M2, (λ−+(m)= +) ∧ (λRA(m)= A).
The port is passive, and this finds semantic correspondence in that only the oppo- nent can issue a request, only the opponent is allowed ‘to start’. The sets V1 and V2

4 From now on we can leave the adjective, handshake, implicit.

represent the sets of values the two players can attach to their moves. Special cases occur when these sets are singletons, or equivalently when no data are added. In particular when there are only one request and one acknowledge we are representing a nonput port. Input ports are obtained by allowing the opponent to encode data in its moves while in output ports it is the player who can encode data in its moves. If they both can, then we have a biput port.
Connectives. A simple operation allows us to change a game’s polarity:
A⊥ = ⟨MA, DA, λA⊥ ⟩.
Where λA⊥ = ⟨−λ−+, λRA⟩, and −λ−+ gives − when λ−+ gives + and viceversa.
A	A	A	A
So for example, a generic active port can be described as the dual A⊥ of the generic passive port A, described above.
We also have a binary connective, the ostar product. This allows us to give a representation to more complex structures, structures with more than one port. Given two games A and B their ostar product is:
A  B = ⟨MA + MB, DA + DB, λA + λB⟩

Note that DA and DB are full subdependencies of DA B and MA (MB) is exactly the set of moves involved in DA (DB). Then we can relax the definition of restriction and write s T A (s T B) instead of s T⟨MA, DA⟩ (s T⟨MB, DB⟩).
Play. As usual in games, player and opponent take turn to play the respective moves. Here though we liberalize things a little as we are working in a concurrent framework, we impose the turn alternation only on the threads of our play (look at it as if we were playing several games in parallel). Formally a play, on a game
⟨MA, DA, λA⟩ 5 is just a string over the concurrent alphabet ⟨MA, DA⟩. A play is
legal if and only if:
all its initial moves are requests;
all its threads are alternating sequences of requests and acknowledges, player and opponent moves.

We write LA for the set of legal plays over the game A. We write Lfin and Lω
for

A	A
the subsets of finite and infinite legal plays, respectively. Note that a play over a
game can only contain a finite number of threads (finite concurrency) because the alphabet of the game can only have a finite number of partitions. The equivalence on moves (DA) induces an equivalence on plays, the homotopy relation ∼A. Let s, t ∈ LA, we say that s ∼A t just when they have the same set of threads 6 .
Prestrategy. I will introduce strategies gradually: starting from the general class of prestrategies I will characterize positionality and determinism; by then we will be working with actual strategies but in order to consider nondeterministic behaviors as

5 The term play is inherited from game semantics. It corresponds to the handshake traces in the handshake circuits theory.
6 The use of homotopy in concurrent games is due to Melli`es and Mimram [22][23].

well we will need a new generalization. All of these classes really need the adjective handshake as we are working in a handshake framework, but since it will be clear from the context I will leave it implicit. I start with some formal notions. Given a set of plays σ on a game A:
The prefix-closure of σ is
σ≤ = {s ∈ LA | s ± t ∈ σ}
For a play s ∈ σ≤, its successors set (with respect to σ) is:
suc · (s, σ)= {m ∈ MA | sm ∈ σ≤}
s is passive in σ, pas · (s, σ), iff there is no move the player can make at s:
m ∈ suc · (s, σ) ⇒ λ−+(m)= −
Pas · (σ) is the set of passive plays in the prefix-closure of σ:
Pas · (σ)= {s ∈ σ≤ | pas · (s, σ)}
Given two independent moves, m, n ∈ MA, and four plays r, s, t, u, of A, we define rA as the smallest binary relation such that:
· (mn rA nm) ⇐⇒ ((λ−+(m)= −) ∨ (λ−+(m)= λ−+(n))) 7 ;
t rA t;
(r rA s) ∧ (s rA t) ⇒ (r rA t);
(r rA s) ∧ (t rA u) ⇒ (rt rA su).
We say that s reorders t in A when s rA t 8 ;
Let s, t be two plays of A and define s xA t if and only if s ± t and t contains only opponent moves after s (we say that t is an input-extension of s in A).
Definition 3.3 A (handshake) prestrategy σ on a game A is a set of legal plays of
A such that:
σ /= ∅ (non-empty);
Pas · (σ) ± σ (closed under passive prefixes);
(t ∈ σ ∧ s rA t) ⇒ s ∈ σ (reorder closed);
(s ∈ σ≤ ∧ s xA s') ⇒ s' ∈ σ≤ (receptive).
σ is conveniently described as a couple ⟨Qσ, Iσ⟩. Where Qσ is called the set of
quiescent and Iσ the set of inﬁnite plays of σ.
The explicit inclusion of infinite plays allows to distinguish when a strategy may follow an infinite communication but at a certain point will surely stop and when

7 Let me give one intuition here ... We may receive two inputs in any order and we may output two messages in any order. Also, an input may arrive before we output. The converse does not hold though, we may have to wait for an input before we can output.
8 I chose to keep the definition as in the original model instead of extending it to infinite sequences of reorderings, this is coherent with the degree of ’intensionality’ in the model

instead it could continue to the infinite. The quiescent plays represent the finite points in which the player may stop to wait for the opponent to move. The passive plays represent those points at which the player has no other choice but to wait: they need to be quiescent. The notions of reorder-closedness and receptivity are inherited from the handshake circuits literature, but curiously I discovered then that they had already been introduced to the game semantics community. Ghica and Murawski in their works on concurrent games for model-checking consider O- complete (receptive) and saturated (reorder-closed) strategies (look for example at [11]). Also, Mimram and Melli`es [23] have an ongoing work on games in the more general context of diagrams and there they introduce a constraint called courtesy which seems to correspond to reorder-closedness.
In the case of nonput ports, some well known prestrategies are STOP and SKIP . STOP simply accepts opponent moves without acknoledging them, while SKIP does acknowledge to requests, but never starts a handshake itself:
STOPA = {s ∈ LA | (s)+ = 0};
SKIPA = {s ∈ LA | (s)− = (s)+}.
Where (s)− and (s)+ stand for the number of opponent and that of player moves in s, respectively. It is interesting to see that if we add data to moves, a prestrat- egy like SKIP becomes a highly nondeterministic specification after which a wide range of possible prestrategies could be implemented. Let’s consider the simple case where A represents a single passive port. If data were added to requests no non- determinism would be introduced. On the other hand if only booleans were added to acknowledges, the player would have many available options. It could always answer tt or ff , or alternate the two answers, ... Even more interesting if the port is a biput. Here the number of possible implementations is extremely high: identity, boolean not, constant, integer successor, test for zero, ... 
Composition. Given two prestrategies, σ on A⊥ B and τ on B⊥ C, their composition is soon defined:
τ ◦ σ = {u T A, C | u ∈ LA,B,C ∧ u T A, B ∈ σ ∧ u T B, C ∈ τ }

Two definitions related to composition. s ∈ Lfin
is an interleaving in the

composition of σ and τ if and only if s T A, B ∈ σ≤ and s T B, C ∈ τ ≤. s is a witness (for s T A, C) in the composition of σ and τ if and only if s T A, B ∈ σ and s T B, C ∈ τ .
Unfortunately, composition of prestrategies is not well-defined. Informally: con- sider the general prestrategy RUN which is always eager to get engaged in a hand- shake, whether its role is to start or to answer. With abuse of notation we could say that the prestrategy RUN on a game B contains all and only those plays which are passive with respect to B. Consider the composition of RUNB with RUNB⊥ . Being dual processes they will never agree on being quiescent at the same time, each one will be willing to continue (or to start over) immediately when its turn comes. Then if the infinite play which emerges from this eternal ping-pong is not itself contained in the two prestrategies, the composition is empty. Somehow we

need to force certain infinite plays to be included in the strategies.
Positionality. We need to focus on a subset of the set of prestrategies for which composition works. It seems natural then to start with deterministic prestrate- gies. However it turns out that determinism is preserved by composition only in presence of another very important property of concurrent strategies, positionality. Positionality is based on the relation of homotopy between plays.
Definition 3.4 A prestrategy σ on a game A is positional if and only if, for finite
s, s' ∈ σ≤ and infinite t, t' ∈ Lω , with s ∼ s' and t ∼ t', we have:
s · s¯ ∈ σ≤ ⇒ s' · s¯ ∈ σ≤ (positionality and prefixes);
s ∈ σ ⇒ s' ∈ σ (positionality and quiescence);
t ∈ σ ∧ (∀t¯ и t', t¯ ∈ σ≤) ⇒ t' ∈ σ (positionality and infinite plays);
Intuitively, a position is a state and we can reach a certain state in different ways but then however we got there we have the same options to move on or to wait.

Determinism. Let A be a game and a and b two distinct player moves of A. A positional prestrategy σ on A is deterministic just when:
ta ∈ σ≤ ⇒ t ∈/ σ;
ta ∈ σ≤ ∧ tb ∈ σ≤ ⇒ tab ∈ σ≤;
Iσ = {t ∈ Lω | ∀t' и t, m ∈ suc · (t', σ), λ−+(m)= +, ∃t'' и t s.t. t' и t'' · m и
t}.
The first two conditions are the usual conditions for determinism. Moreover a deterministic strategy that has engaged in an infinite chatter may not decide to quit anyhow. A malicious opponent could force a deterministic strategy to follow the course that he wants, even to diverge. If the opponent acts in this way there is no means for the deterministic strategy to escape the malicious design. The third condition tells exactly which are the infinite plays that a deterministic strategy must contain.
It’s clear that the third condition of determinism implies the third condition of positionality. So for deterministic prestrategies positionality can be expressed with two properties.
Composition. We now proceed to the proof that composition is well-defined for deterministic positional prestrategies. In the following let σ and τ be two determin- istic positional prestrategies on A⊥  B and B⊥  C, respectively. We start with two definitions.
Given u and v such that u r v, we define dr (u, v), the reordering distance
between u and v:
dr (u, v)=0 ⇐⇒ u = v
dr (u, v)=1 ⇐⇒ (u = u' · a · b · u'') ∧ (v = u' · b · a · u''), for two moves a and b;
In general dr (u, v)= n > 0 if and only if u /= v and there are n + 1 (and no less) plays u0, u1,... un such that u = u0, un = v and dr (ui, ui+1)= 1.

In exactly the same way we define the homotopy distance d∼ (u, v) on homotopic plays u ∼ v.

Lemma 3.5 Let s ∈ Lfin
be an interleaving in the composition of σ and τ. Then

there is t ± s and t is a witness in the composition of σ and τ.
Proof. If s T A, B ∈ σ and s T B, C ∈ τ , s itself is the witness. Otherwise, suppose σ is not quiescent at s. Then s is not passive in σ, σ can play a move after s. We start by saturating the external threads of σ with player moves. Then we let σ play in B until quiescence, while τ must be ready to accept this stream (receptivity). Now, if τ is quiescent we are done, otherwise we saturate it outside. If it becomes quiescent we are done as well otherwise we let it play inside until quiescence. Then it’s σ’s turn again, and so on. If after a while they both become quiescent then we have our witness. Otherwise they run to the infinite, but then we also have our witness (determinism, third condition).	□
Lemma 3.6 Let t ∈ (τ ◦ σ)≤ and let u and v be two interleavings for t in τ ◦ σ. Then u can be completed with all the occurrences of moves that are in v \ u so to obtain an interleaving z for t in τ ◦ σ.
Proof. A few remarks. After σ (τ ) makes a move m it can still play all the moves it could play before but m itself (determinism, second condition). τ (σ) instead can still play all the moves it could play before (receptivity and reordering) and possibly more. It follows that if m is initial in v and m I u then u' · m · u'' is still an interleaving for t in τ ◦ σ, for any factorization u' · u'' of u. Else if m D u then u = u' · n · u'', where m I u' and m D n. Then both m and n could be played after u' and they would extend the same thread, since they are dependent. Then they have the same polarity (definition of thread). Then m = n since both σ and τ are deterministic.
We can obtain z as the result of calling the following recursive algorithm on u and v (the language is informal and untyped, nonetheless it should be pretty clear in my opinion):
union(u, v){
m := head(u);
u¯ := tail(u);
if (m I v) then
if (u¯ = ε) then z := m · v; else z := m · union(u¯, v);
else if (v = v' · m · v'') then
z := m · union(u¯, v' · v''); return z;
}
□

Theorem 3.7 Let σ and τ be two deterministic positional prestrategies on A⊥  B
and B⊥  C, respectively. Then,
pre) τ ◦ σ is a prestrategy; pos) τ ◦ σ is positional; det) τ ◦ σ is deterministic.
Proof.
pre) I skip the proof that every play in τ ◦ σ is legal as it is almost immediate.
τ ◦ σ is non-empty. Since neither σ nor τ is empty, then ε is an interleaving of their composition. Then lemma 3.5 applies and yields a witness t ± ε for some play in τ ◦ σ;
Let s ± s¯, with s¯ ∈ τ ◦ σ and s ∈ Pas · (τ ◦ σ). By definition there is t¯ ∈ LA,B,C
such that t¯T A, B ∈ σ, t¯T B, C ∈ τ and t¯T A, C = s¯. Just cut t¯ right after s is played out in the external game and call the resulting play t. Then lemma 3.5 applies and yields a witness t' ± t for some play in τ ◦ σ. s is passive then t' is actually a witness for s 9 ;
Let s rA⊥,C s¯. Consider d =dr (s, s¯):
d = 0 Then there is a witness u¯ of s¯ which is also a witness of s;
d = n Then there are s0, s1,... sn ∈ LA,C and such that s = s0, sn = s¯, dr (si, si+1)= 1 for all 0 ≤ i ≤ n. For assumption we know that s1 ∈ (τ ◦ σ). Let s1 = s' · m · n · s'' and s0 = s' · n · m · s''. Moreover let’s take a witness u1 ∈ LA,B,C of s1 of the form u1 = u' · m · ub · n · u'', where u' and u'' are interleavings of s' and s'', respectively, and ub is a sequence of moves in B. If n is an opponent move then we define u0 = u' · n · m · ub · u'' else m is a player move and then we define u0 = u' · ub · n · m · u''. In any case u0 T A, C = s, u0 T A, B rA⊥,B u1 T A, B ∈ σ and u0 T B, C rB⊥ ,C u1 T B, C ∈ τ , then s ∈ τ ◦ σ.
Let s ∈ (τ ◦ σ)≤ and let s x s · s'. Reasoning as in the second point we can find
an interleaving u for s in the composition τ ◦ σ. It follows from receptiveness of the two prestrategies that u · s' is also an interleaving. Then lemma 3.5 applies and we are done.
pos) As already remarked, the third property of positionality follows from determinism which will be proved later on. The first two properties can be proved in exactly the same way, so I prove just the first one. Let s, s' ∈ (τ ◦ σ)≤, with s ∼ s', and let s · s¯ ∈ (τ ◦ σ)≤. The proof that s' · s¯ ∈ (τ ◦ σ)≤ is by induction on d∼ (s, s'):
If s = s' then trivially s' · s¯ ∈ (τ ◦ σ)≤;
If d∼ (s, s')= n + 1 then there is sn such that d∼ (s, sn)= n and d∼ (sn, s')= 1. By inductive hypothesis sn · s¯ ∈ (τ ◦ σ)≤. Now, sn factorizes as t' · a · b · t'' while s' = t' · b · a · t''. So sn has an interleaving un = u' · a · ub · b · u'', where ub is a sequence of internal moves. The two prestrategies are deterministic then it follows from the remarks made inside lemma 3.6 that u' · b · a · ub · u'' is also an interleaving of τ ◦ σ (in particular if b is by the opponent, receptivity also plays

9 Note that in the proof of the lemma no external opponent move is taken while making t', then really no move is played outside.

a role). Finally by positionality of σ and τ we conclude s' · s¯ ∈ (τ ◦ σ)≤.
det)(i) Let t · a ∈ (τ ◦ σ)≤, where a is a player move. For contradiction, t ∈ τ ◦ σ. Then t has a witness u ∈ LA,B,C. Consider the case where u is finite. Since u T A, B ∈ σ and u T B, C ∈ τ , neither prestrategy can play at this point, the next move must be an opponent move in A or C, and this is enough for the first case. If u is infinite then any move that could be played after a finite prefix will eventually be played somewhere in u, including a;
Let s · a, s · b ∈ (τ ◦ σ)≤, where a and b are two distinct player moves. An interleaving for s · a is of the form u' · a · v' and an interleaving for s · b is of the form u'' · b · v''. Where u' and u'' are both interleavings for s and v' and v'' are sequences of internal moves. Then we can apply lemma 3.6 and complete u' with the moves that are not in it but in u''. In the same way we can complete u'' with the moves that are not in it but in u'. The two results are homotopic. Take one of them, u. By the remarks made inside lemma 3.6 and by positionality we have that u · a is both an interleaving of s · a and of s · b, then the conclusion follows;

This is actually a double implication. Let s ∈ Lω
such that all its prefixes

are in the prefix-closure of τ ◦ σ:
⇒) Suppose s ∈ (τ ◦ σ) and m ∈ suc · (s',τ ◦ σ), where s' и s and such that

λ−+(m)= +. Then s has a witness u ∈ Lω
. If either u T A, B or u T B, C

is finite then respectively σ and τ cannot move anymore. That means that if
it was σ’s (τ ’s) duty to play (the occurrence of) m then the move occurs in the finite restriction (first condition of determinism). Suppose that m could be played on the side of the communication which is infinite. Then again we know that the move will eventually occur (third condition of determinism);
⇐) Suppose that forall s' и s and m ∈ suc·(s',τ ◦σ) with λ−+(m)= + there exists

s'' и s such that s' и s'' · m и s. Take u ∈ Lω
such that all the prefixes

of u T A, B are in the prefix-closure of σ, all the prefixes of u T B, C are in the prefix-closure of τ and u T A, C = s. For any u' и u we know that if either prestrategy could play an external move after u' then this eventually occurs in u, because the same move could be played by τ ◦σ after the external restriction of u'. If either prestrategy could play an internal move and the (occurrence of the) move does not appear in u yet, then we add it, say, ten moves after u'. This way we are assured that every move that could be played after a finite prefix actually occurs inside a finite prefix 10 . The final u¯ is actually a witness for s in τ ◦ σ.
□
Sums and Strategies. We define the binary operation ⊕ (sum) which takes two prestrategies σ and τ on a game A and returns the union of their sets of plays.
Lemma 3.8 The sum of σ and τ is again a prestrategy.

10 Note that the number of moves that can be played at any point is finite, as the number of threads is finite (finite concurrency) and the two prestrategies are deterministic.

Proof.
The union of two non-empty sets is non-empty. (ii)
s ∈ Pas · (σ ⊕ τ ) ⇒ s ∈ (σ ⊕ τ )≤ ∧ pas · (s, σ ⊕ τ )
⇒ (s ∈ σ≤ ∧ pas · (s, σ)) ∨ (s ∈ τ ≤ ∧ pas · (s, τ ))
⇒ (s ∈ Pas · σ) ∨ (s ∈ Pas · τ )
⇒ (s ∈ σ) ∨ (s ∈ τ )
⇒ s ∈ σ ⊕ τ

(iii) Reorder-closedness and receptivity can be proven similarly, so we prove only the first one of the two. Let t ∈ (σ ⊕ τ ) ∧ s rA t:
t ∈ σ ⊕ τ ⇒ (t ∈ σ) ∨ (t ∈ τ )
t ∈ σ ∧ s rA t ⇒ s ∈ σ t ∈ τ ∧ s rA t ⇒ s ∈ τ
(s ∈ σ) ∨ (s ∈ τ ) ⇒ s ∈ σ ⊕ τ

□
We extend this operation to an arbitrary number of arguments in the expected way, then we are ready for strategies.
Definition 3.9 A (handshake) strategy σ is the sum of deterministic positional (handshake) prestrategies:
σ =   σi
i∈I
where σi are deterministic positional prestrategies indexed by elements of a non- empty set I.
A strategy represents a process. A strategy is a description of the behavior to follow. It is as if strategies could choose once and for all among a set of possible behaviors. Afterwards they act deterministically all the way. It follows that a deterministic positional prestrategy σd is just a particular case of strategy where the opponent may choose only from a singleton set. We will just say that σd is a deterministic strategy, assuming implicitly that it is positional, even if strategies are not positional in general.
Lemma 3.10 Given two strategies σ and τ on a game A, their composition is again a strategy.


Proof. Let

σ =   σi	τ =   τj

i∈I	j∈J
where all σi’s and τj’s are deterministic prestrategies. Then we have:

τ ◦ σ = {u T A, C | u ∈ LA,B,C ∧ u T A, B ∈ σ ∧ u T B, C ∈ τ } =
= {u T A, C | u ∈ LA,B,C ∧ u T A, B ∈ ⊕i∈Iσi ∧ u T B, C ∈ ⊕j∈Jτj} =
= {u T A, C | u ∈ LA,B,C ∧ (∃i ∈ I, j ∈ J s.t. u T A, B ∈ σi ∧ u T B, C ∈ τj)} =

=	 
i∈I,j∈J
=	 
i∈I,j∈J
{u T A, C | u ∈ LA,B,C ∧ u T A, B ∈ σi ∧ u T B, C ∈ τj} = (τj ◦ σi)
□

Category. We can form a category H whose objects are games and with mor- phisms from A to B the strategies on A⊥  B. With abuse of notation we write σ for both the morphism σ : A → B and the strategy σ : A⊥  B. The identity morphism idA : A → A is the well-known copycat strategy:
idA = {s ∈ LA⊥ A | s T A1 = s T A2},
where the indices are used only to distinguish the left and the right copy of A. It is easy to check that idA is a well-defined prestrategy, that it is positional and deterministic, and that the identity equations
σ ◦ idA = σ = idB ◦ σ,

hold. There only remains the proof of associativity of composition, which we do next.
Theorem 3.11 Consider games A, B, C and D, and strategies σ : A → B and
τ : B → C and ρ : C → D:
(ρ ◦ τ ) ◦ σ = ρ ◦ (τ ◦ σ)
Proof. Let s ∈ (ρ ◦ τ ) ◦ σ. There is a witness u ∈ LA,B,D for s. Analogously we find a witness v ∈ LB,C,D for u T B, D. Working in an asynchronous world sometimes makes things easier (but only sometimes) so now we need no zipping or infinite zipping lemma, we can interleave u and v in no matter which way, we always end up with some w ∈ LA,B,C,D which satisfies:
w T A, B = u T A, B ∈ σ;
w T B, C = v T B, C ∈ τ ;
w T C, D = v T C, D ∈ ρ;
w T A, D = u T A, D = s.
Then by definition we have w T A, C ∈ τ ◦ σ and s ∈ ρ ◦ (τ ◦ σ). The opposite direction is proved in exactly the same way.	□
Lifting to morphisms allows one to derive the description of a circuit from the descriptions of its independent components. Given σ : A → B and σ' : A' → B', we

define σ  σ' : A  A' → B  B' as
σ  σ' = {s ∈ LA,A',B,B' | s T A, B ∈ σ ∧ s T A', B' ∈ σ'}
The functoriality properties, (τ ◦ σ)  (τ ' ◦ σ') = (τ  τ ') ◦ (σ  σ') and idA idB = idA B, are easily verified. Suppose we want to compose strategies σ : A → B and τ : B  B' → C. A possible way of doing this is by ‘extending’ σ with the identity of B'. The composition becomes τ ◦ (σ  idB' ). Another way is to restrict τ and substitute it with τ ◦ (idB  SKIPB' →I ), where I is the game with just no moves.
The category of handshake games and handshake strategies H is *-autonomous, it is symmetric monoidal closed with respect to  and has an isomorphism from A to A⊥⊥. In particular the isomorphisms A → I  A and A → A  I are just copycat strategies and they follow from the isomorphisms between sets of moves, MA → ∅+MA and MA → MA+∅, respectively. The other isomorphisms required for symmetric monoidal closure are also copycat strategies derived from isomorphisms between sets of moves. The case of self-duality is even simpler, A and A⊥⊥ are the same game and the isomorphism between them is just the identity on A.
We can further note that H is more than *-autonomous, it is compact-closed, as you can easily check A  B = (A⊥  B⊥)⊥. Computationally this feature allows the modeling of loops. To see this, remember that arrows are just games of the form A⊥  B (this is the essence of compact-closedness) and that the isomorphisms of symmetric monoidal closure allow to move freely subcomponents from one side to the other. Then the trick is easily accomplished by composing the desired sub- components together, for example with a wire (the identity or, better, a strategy isomorphic to it).

Semantics
Tangram is a Hardware Design Language in which programs are compiled directly into circuits constructed from a set of standard handshake components. Van Berkel proposes a semantics for Core Tangram 11 [28] which he calls calculus of handshake processes and is a calculus derived from Hoare’s CSP. Then he proves a compilation theorem which states that the circuit resulting from the compilation of a Tangram program is equivalent to the meaning of that program in the calculus of handshake processes. In an alternative approach, handshake circuits themselves can be used as a semantics. Handshake components can be seen as special combinators which are described as handshake strategies, thus morphisms in H. For simplicity I use the same uniform compilation strategy as in [28], and to keep this short I will also skip the syntax of Tangram and the compilation function which can be found on the same paper. So there only remains to define the required components in terms of strategies. I already defined the strategies for the three most general components, RUN , SKIP and STOP . Each one of them is actually a family of components,

11 Where data are not considered.

parameterized by the particular structure it is implemented on, and similarly there is a family of strategies describing it. The other required components are all im- plemented on particular structures. The constant component is implemented on a passive output port. Semantically this corresponds to a game with an opponent request r, the values v from a set V as acknowledges and a single dependency class (the one containing all moves). Then the associated strategy is
CSTc = {ε, rc, rcrc,.. .}
where c ∈ V . A bit more complex, consider a structure with two nonput ports, one passive (A) and one active (B). And here are our strategies on such a game:

CONA,B = {ε, rArB, rArBaBaA,.. .}
REPA,B = {ε, rArB, rArBaBrB,.. .}
REPNA,B = {ε, rArB,... , rArB ... (n handshakes on B) ... aBaA,.. .}

Where the indices on moves are used to distinguish the component over which these moves are played. As for the labels rA and rB are requests, aA and aB are acknowledges, rA and aB are opponent moves, aA and rB are player moves. The connector behaves like a wire. REP is initially activated by a request on A and then handshakes infinitely many times on B. REPN does the same, except that after the N th time it stops handshaking on B and acknowledges the initial request on A, waiting for a new one to come. Adding data to both acknowledges allows us to define two more strategies that we need. In the game we consider aA is replaced by the set {vA | v ∈ τA} and aB by {vB | v ∈ τB}, where τA and τB are two sets of values. The rest of the structure is modified accordingly. So we have:
ADAP TτA ,τB = {ε, rArB}∪ {rArBvBvA | v ∈ τA}∪ ... U N□ = {ε, rArB, rArBvB(□v)A,.. .}
They both behave similarly to CON with the addition of data in the acknowledges. When possible the adapter transmits the value received on B through A, otherwise it is undefined. Assuming □ is a unary function from τB to τA, UN applies it to the value received from B and sends the result on A. Back to the case of nonput ports we add an active port C. The strategies we consider are:

SEQA,B,C = {ε, rArB, rArBaBrC , rArBaBrC aCaA,.. .} ORA,B,C	= {ε, rArB, rArC, rArBaBaA, rArC aCaA,.. .}
P ARA,B,C = {ε, rArBrC, rArCrB, rArBrCaB, rArBaBrC, rArC rBaB, rArBrCaC, rArCaCrB, rArCrBaC, rArBrCaBaCaA, rArBrC aCaBaA, rArBaBrC aCaA, rArC rBaBaCaA, rArCrBaC aBaA, rArCaCrBaBaA,.. .}

They are all activated by the request on A. Then the sequencer starts two hand- shakes in sequence on the active ports, the P AR starts them in parallel and the OR does either of the two (nondeterministically). Afterwards they all acknowledge to the first request. SEQ denotes the standard directive of sequential composition of commands and should not look new to the game semantics community, basically any model of (a variant of) Ideal Algol will do (to my knowledge, the first of these models is described in [3]). Similarly P AR denotes the standard directive for paral- lel execution of commands and has also been modeled with games [19][11]. Basically any variant of P AR on a game with values in place of the plain acknowledges will give semantics to some binary operator:
BIN□ = {ε, rArBrC,... , rArBrCvBwC(v□w)A,.. .}

Variants of the sequencer are also possible. For example if we add values (of the same type) in the acknowledges of B and in the requests of C, we can define the transferrer :
TRFA,B,C = {ε, rArB, rArBvBvC, rArBvBvCaC aA,.. .}

After activation, the transferrer asks for a value from B which is then sent over to C. Another variant of the sequencer (but on a different game) allows for representation of the branching construct:
IFA,B,C = {ε, rArB, rArBttBrC, rArBttBrCaCaA,.. .}

The only data are in the acknowledges of B and are booleans. Straight to the crucial point: if the acknowledge on B contains tt then IF starts a handshake on C, otherwise the behavior is undefined (it may decide to stop and wait or to continue in any possible way). Still on the same game we can define a strategy which allows looping:
DOA,B,C = {ε, rArB, rArBttBrC, rArBffBaA, rArBttBrC aCrB,.. .}

We now move to structures with two passive ports. The first game we consider has as set of moves the disjoint sum of sets MA = {rA} ∪ {vA | v ∈ V } and MB = {vB | v ∈ V }∪ {aB}, where V is a given set of values. The dependency relation is as expected and the labelling assigns (−, R) to rA and all vB’s, and (+, A) to aB and all vA’s. The variable is defined by the strategy
V ARA,B = {ϵ, rAmA,... ,... nBaBrAnArAnA ... ,.. .}

To the first read request it may respond in any way (undefined behavior) but once a value is written, that value will be returned at any following read (until a new value is written over). The next game represents a structure with two passive (A

and B) and one active (C) ports, all nonput. Two strategies on this game:

MIXA,B,C = {ε, rArC, rArCaCaA,... , rBrC, rBrC aCaB,.. .} JOINA,B,C = {ε, rA, rB, rArBrC, rArBrCaCaAaB,.. .}
The mixer mixes two communication flows into a single one. Whenever it receives a request on either passive port it sends a request on the active one, when this is acknowledged, it acknowledges the request it received. The join joins two con- current threads. It initially waits for both requests from A and B to arrive, then it sends a request on C. When this is acknowledged, it sends acknowledges on A and on B and returns to the initial state. The last component is needed for Tangram’s guarded-commands and has by far the most complex structure, two pas- sive and four active ports, with boolean values in the acknowledgements of one passive port (an output port) and of two active ports (two input ports). The re- maining three are nonput ports. The associated game contains the set of moves
{rB, ttB,ffB, rC , aC, rBL, ttBL,ffBL, rCL, aCL, rBR, ttBR,ffBR, rCR, aCR}.   The
dependency relation is as expected and the labels are all request for the r∗ moves and acknowledge for the others; moreover rB and rC are opponent moves and the cor- responding acknowledges are player moves, all the other requests are player moves and the corresponding acknowledges are opponent moves. The BAR component ini- tially waits for rB, then sends in parallel rBL and rBR. It will receive two boolean values in the acknowledges, then it does the logical or of these two and sends the result as acknowledge to rB. At that point, once rC is arrived, it starts behaving according to the boolean values previously received in the acknowledges to rBL and rBR. If only one of them was true it sends the paired request 12 ; if both of them were it chooses nondeterministically which request to send; finally if both values were false then the behavior is left unspecified. Here is the strategy:

BARB,C = {ϵ, rBrBLrBR,... , rBrBLrBRbBLb'	(b ∨ b')B,... , rBrBLrBRbBLttBR
ttBrCrCRaCRaC ,.. .}

For clarity reasons, in the last four examples I only wrote the plays that help un- derstand the internal logic of the components, you may think that the other plays are hidden behind the dots. In fact, properties such as receptivity and reorder- closedness imply that several other ‘sequentializations’ of the global concurrent be- havior may take place 13 . Still, all these components have cyclic behaviors, they sooner or later return to previously seen states, then a fully satisfactory description with all possible plays that may occur in a cycle (like the one I gave for P AR) is possible.

12 Where pairing corresponds to intuition: ports BL and CL form one pair, and ports BR and CR form the other.
13 For example, in the case of BAR, rc could arrive at any time before the acknowledge to rB, even before
rB itself.

Conclusions and Further Work
So, I built a model for handshake circuits and I showed how it could be put into use as a semantics of Tangram, bridging two apparently distant worlds: games and circuits. In the process, I dealt with the problems arising in the modeling of circuits’ composition and I ended with a finer characterization of handshake strate- gies. In particular, the new property of positionality seems very interesting and worth exploiting. But the model contains also a deeper structural analysis, with the construction of a compact-closed category H. This provides us with tools like composition of morphisms and the bifunctor which turn out useful: once I had defined such a model the following step was almost immediate. I considered the language Tangram and took advantage of the compilation function proposed by Van Berkel [28], from Tangram programs to handshake circuits. The obtained cir- cuits were all constructed from standard handshake components connected together. Then these components can be seen as combinators and represented as handshake strategies in H.
The compact-closedness of H allows for the modeling of internal loops, which is already a good thing; however a finer characterization of this category can be given. One can take advantage from models of the Geometry Of Interaction [12][5][9] and make structural comparison. The aim is to provide a general framework which may contain larger classes of asynchronous circuits 14 : in this sense, the categorical way is an especially feasible one. As starting point we may take the family of process algebras developed by Mark Josephs [17][16][18] on one hand of the bridge, and the implementations of the geometry of interaction with circuits [20] on the other.
This continous “river-crossing”, shifting the viewpoint from circuits to games/GOI and back, might return positive feedbacks to both ends. By the for- mal banks of game semantics, the community could benefit from an implementa- tion of their formalism with real physical devices. Moreover, the use of handshake components as combinators for the semantics of a language looks promising: one could think of using the same combinators in the semantics of languages which are radically different from Tangram. At the other side of the river, some mod- est contributions already got ashore along with this work, as I have noted above. More feedback can come from parallelisms with games for the verification of prop- erties [24][10][25]. An orthogonal direction is in the abstraction of the formalism. I already pointed out that the standard handshake components all follow a cyclic life, then this suggests more abstract representations, ways that could allow to treat composition more mathematically. The aim is to find alternatives for simplifying reasoning while keeping the substance unchanged.
As far as semantics is concerned, the current work can be seen as an extension of Van Berkel’s, who only gives a semantics to the fragment of Tangram without data. Surely there is more work to do: the focus of this paper was on the construc- tion of a model for handshake circuits, along with full details on the description of the solution to the pre-existing problem of associativity of composition, while the

14 Two of these classes are speed-independent and delay-insensitive circuits.

semantical aspect still needs to be regarded more systematically. First of all, in my opinion, it is not completely clear in which direction to look at the denotation func- tion. One can for example consider circuits and model them with a calculus which in a way mimics the language, as in [28]; but one can as well use circuits directly as a semantics for the language, as a description of what a program does. Since the compilation of a program yields a circuit, two programs should be considered equivalent just when they yield two observationally equivalent circuits 15 . Then a property like full abstraction for a model which describes so closely the external behavior of circuits (for a model like mine) becomes trivial. But of course other interpretations of program equivalence in Tangram may be possible.

References
S. Abramsky. Interaction categories (extended abstract). In G. L. Burn, S. J. Gay, and M. D. Ryan, editors, Theory and Formal Methods 1993: Proceedings of the First Imperial College Department of Computing Workshop on Theory and Formal Methods, pages 57–70. Springer-Verlag Workshops in Computer Science, 1993.
S. Abramsky, S. Gay, and R. Nagarajan. Interaction categories and the foundations of types concurrent programming. In M. Broy, editor, Proceedings of the 1994 Marktoberdorf Summer School on Deductive Program Design, pages 35–113. Springer-Verlag, Berlin, 1996.
S. Abramsky and G. McCusker. Linearity, sharing and state: a fully abstract game semantics for idealized algol. In P. O’Hearn and R.D. Tennent, editors, Algol-like Languages, pages 317–348. Birkhauser, 1997.
S. Abramsky and P.-A. Melli`es. Concurrent games and full completeness. In Logic in Computer Science 99, pages 431–442, Trento, July 1999. IEEE Computer Society Press.
Samson Abramsky and Radha Jagadeesan.	New foundations for the geometry of interaction.
Information and Computation, 111(1):53–119, 1994. Conference version appeared in LiCS ’92.
A. Bardsley. Balsa: an Asynchronous Circuit Synthesis System. master’s thesis. Department of Computer Science, University of Manchester, 1998.
I. Benko. Theory of handshake circuits. highlights, 1994.
Andreas Blass. A game semantics for linear logic. Annals of Pure and Applied Logic, 56(1-3):183–220, 1992.
V. Danos and L. Regnier. Proof-nets and the hilbert space. In Proceedings of the workshop on Advances in linear logic, pages 307–328, New York, NY, USA, 1995. Cambridge University Press.
D.R. Ghica and A.S. Murawski. Compositional model extraction for higher-order concurrent programs. In TACAS’06, Lecture Notes in Computer Science 3920, pages 303–317. Springer-Verlag, 2006.
D.R. Ghica, A.S. Murawski, and C.-H. L. Ong. Syntactic control of concurrency. In ICALP’04, Lecture Notes in Computer Science 3142, pages 683–694. Springer-Verlag, 2004.
J.-Y. Girard. Geometry of interaction I: interpretation of system F. In Ferro, Bonotto, Valentini, and Zanardo, editors, Logic Colloquium ’88, pages 221–260, Amsterdam, 1989. North-Holland.
Russell Harmer and Guy McCusker. A fully abstract game semantics for finite nondeterminism. In
Logic in Computer Science, pages 422–430, 1999.
Russell Harmer and Guy McCusker. A game semantics for countable nondeterminism. Unpublished, 2002.
M. Hyland and A. Schalk. Games on graphs and sequentially realizable functional. In IEEE Computer Society Press, pages 257–264, Kopenhavn, July 2002.
Mark B. Josephs. Receptive process theory. Acta Inf., 29(1):17–31, 1992.

15 Note that this view of program equivalence is consistent with the algebraic treatment of handshake processes given in [18].


Mark B. Josephs and Jan Tijmen Udding. An algebra for delay-insensitive circuits. In CAV ’90: Proceedings of the 2nd International Workshop on Computer Aided Verification, pages 343–352, London, UK, 1991. Springer-Verlag.
M.B. Josephs, J.T. Udding, and Y. Yantchev. Handshake algebra. Technical Report SBU-CISM-93-1, School of Computing, Information Systems and Mathematics, South Bank University, London, 1993.
J. Laird. A game semantics of idealized csp. Electronic notes in Theoretical Computer Science, 45, 2001. Seventeenth Conference on Mathematical Foundations of Programming Semantics, MFPS’01.
Ian Mackie. The geometry of interaction machine. In POPL ’95: Proceedings of the 22nd ACM SIGPLAN-SIGACT symposium on Principles Of Programming Languages, pages 198–208, New York, NY, USA, 1995. ACM Press.
A. Mazurkiewicz. Trace theory. In W. Brauer, W. Reisig, and G. Rozenberg, editors, Advances in Petri Nets, pages 279–324. Springer, 1986.
P.-A. Melli`es. Asynchronous games 2: the true concurrency of innocence. In P. Gardner and N. Yoshida, editors, CONCUR’04, Lecture Notes in Computer Science. Springer Verlag, September 2004.
Samuel Mimram and Paul-Andr´e Melli`es. Asynchronous games 5: Non-alternating innocence. Work in progress, 2006.
Y. Moschovakis. A game-theoretic modeling of concurrency. In fourth annual symposium on Logic In Computer Science, pages 154–163. IEEE Computer Society Press, 1989.
C.-H. L. Ong. Some results on a game-semantic approach to the verification of infinite structures. To appear in the proceedings of CSL 2006.
D. Park. The “fairness” problem and nondeterministic computing networks. Foundations of Computer Science IV. Matematisch Centrum, Amsterdam, 1983.
A. W. Roscoe. Unbounded nondeterminism in CSP, volume 3 of Journal of Logic and Computation. April 1993.
K. Van Berkel. Handshake circuits: an Asynchronous architecture for VLSI design, volume 5 of
Cambridge International Series on Parallel Computation. Cambridge University Press, 1993.

Appendix:	Associativity in the Calculus of Hand- shake Processes
Associativity of composition is often a “tough beast”, especially when dealing with processes which may present degrees of parallelism and/or of nondeterminism [8][13]. In this appendix I claim, and show with a counter-example, that the problem has been underestimated in Van Berkel’s Calculus of Handshake Processes. I will re- formulate the example in terms of handshake games and handshake prestrategies (handshake processes can be redefined equivalently as handshake prestrategies with no infinite plays). Even though infinite plays are not explicitly there, the case of infinite chattering between two prestrategies does not disappear and composition requires a special treatment in this particular case: here is where the problem lies. In particular, composition for finite plays is as defined in section 3. Moreover, con- sider those infinite interleavings of the two strategies, σ and τ , whose finite prefixes are all in the prefix-closures of σ and τ (under the proper restriction of course). We complete the composed strategy by adding the plays obtained from exactly these interleavings after hiding internal threads.
Here follows the counter-example. Let Act = ⟨{rA, aA}, DA, λA⟩ be the game associated to a nonput active port (rA and aA are dependent with each other, λA(rA) = (+, R), λA(aA) = (−, A)). Let Pas = ⟨{rP , aP }, DP , λP ⟩ be the game associated to a nonput passive port (.. .). Finally, let Sing = ⟨{rS}, (rS, rS), rS '→ (+, R)⟩ be the game containing a single player request. Now consider for a moment

the handshake process 16 RUNAct→Sing : Act → Sing, which might also be regarded as RUNP as Sing, or as RUNP as  RUNSing. Then it is actually composed of two prestrategies acting independently and concurrently: the first one replies to each request coming from the opponent on Pas, the second one does the only thing it can possibly do, it sends a request on Sing. The prestrategy is quiescent just after the request on the right side has been sent while on the left side there is no request which is still pending (unanswered). The other prestrategies are RUNI→Act : I → Act and STOPSing⊥  RUNSing : Sing → Sing. In particular this last prestrategy becomes quiescent once it has sent the request on the right, both if the request on the left is already arrived or not.
We start with RUNI→Act and RUNAct→Sing, composing them Van Berkel’s style. As a result we get a nondeterministic prestrategy on I → Sing which might stay quiescent or send a request, let’s call it τ . If we compose τ with STOPSing⊥ RUNSing we get RUNI→Sing as a result. It can be easily seen that doing the compositions in the other order, the obtained result is τ : two different results then. Note also that using this style of composition, two deterministic processes may compose into a nondeterministic one. In H, for RUNAct→Sing to be deterministic it must contain all and only the infinite plays where the request on Sing appears at some point. A nondeterministic variant of this strategy can be possible as well: in any case the final composition yields the unique play RUNI→Sing, as expected. Note that this counterexample has nothing to do with nondeterminism apriori,
we are trying to observe the interaction of deterministic strategies, even if we do it
inside a model specific for nondeterminism. Then it is yet a new counter-example, different from Roscoe’s one. Interestingly, they both bring to the same conclusion: that in a model of unbounded nondeterminism infinite plays (traces, dialogues, .. .) must be listed explicitly.
















16 I call it handshake process in order to stress the fact that it does not contain infinite plays.
