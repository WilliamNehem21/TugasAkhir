Available online at www.sciencedirect.com


Electronic Notes in Theoretical Computer Science 324 (2016) 165–179
www.elsevier.com/locate/entcs

A Unified Procedure for Provability and Counter-Model Generation in Minimal Implicational Logic
Jefferson de Barros Santos1,2
Departamento de Inform´atica PUC-Rio
Brazil
Bruno Lopes Vieira4
Instituto de Computa¸c˜ao UFF
Brazil
Edward Hermann Haeusler3
Departamento de Inform´atica PUC-Rio
Brazil

Abstract
This paper presents results on the definition of a sequent calculus for Minimal Implicational Propositional Logic (M→) aimed to be used for provability and counter-model generation in this logic. The system tracks the attempts to construct a proof in such a way that, if the original formula is a M→ tautology, the tree structure produced by the proving process is a proof, otherwise, it is used to construct a counter-model using Kripke semantics.
Keywords: theorem proving

Introduction
Proof search (validity) in Minimal Implicational Propositional Logic (M→) is a PSPACE-Complete problem as stated by Statman in [14] who also shows that

1 The authors thank to CNPq and CAPES for supporting this research
2  Email:jsantos@inf.puc-rio.br
3  Email:hermann@inf.puc-rio.br
4 Email:bruno@ic.uff.br

http://dx.doi.org/10.1016/j.entcs.2016.09.014
1571-0661/© 2016 The Author(s). Published by Elsevier B.V.
This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).

M→ polynomially simulates Intuitionistic Propositional Logic (IPL). This simula- tion can be used to polynomially simulate Classical Logic too, although Classical Logic seems to be in a smaller complexity class 5 . This result points out that M→ is as hard to implement as the most popular propositional logics. Haeusler shows in
[7] that M→ can polynomially simulate not only Classical and Intuitionistic Propo- sitional Logic but also Full Minimal Propositional Logic and any other decidable propositional logic with a Natural Deduction system with the sub-formula property. Because of those features, M→ can be used as a base tool to study complexity of many other logics.
Our goal here is to present a sequent calculus for M→ which allows the definition of a unified procedure for provability and counter-model generation in this logic. The calculus is based on a set of rules and in a general strategy for application of the rules in such a way that we can avoid the usage of loop checkers and the necessity of working with different systems for provability and refutation. To the best of our knowledge, this is the first proof calculus for M→ where validity and counter-model generation are done in a single procedure.
Counter-model generation (using Kripke semantics) is achieved as a consequence of the completeness of the system. We are also developing an interactive theorem prover for M→ based on the in here proposed calculus. Its source code can be found at https://github.com/jeffsantos/sequent-prover.
Minimal Implicational Logic
Semantics
The Minimal Implicational Logic (M→) is the fragment of Minimal Logic containing only the logical constant →. Its semantics is the intuitionistic semantics restricted to → only. Thus, given a propositional language L, a M→ model is a structure
⟨U, ≤, V⟩, where U is a non-empty set (worlds), ≤ is a partial order relation on U and V is a function from U into the power set of L, such that if i, j ∈ U and i ≤ j then V(i) ⊆ V(j). Given a model, the satisfaction relationship |= between worlds in models and formulae is defined as in Intuitionistic Logic, namely:
⟨U, ≤, V⟩ |=i p, p ∈ L, iff, p ∈ V(i)
⟨U, ≤, V⟩ |=i α1 → α2, iff, for every j ∈ U , such that i ≤ j, if ⟨U, ≤, V⟩ |=j α1
then ⟨U, ≤, V⟩ |=j α2.
As usual a formula α is valid in a model M, namely M |= α, if and only if, it is satisfiable in every world i of the model, namely ∀i ∈ U, M |=i α. A formula is a M→ tautology, if and only if, it is valid in every model.
Syntax
It is known that Prawitz Natural deduction system for Minimal Logic with only the
→-rules (→-Elim and →-Intro) is sound and complete for the M→ regarding Kripke

5 We remember that we do not know whether NP = PSPACE or not.

semantics. As a consequence of this, Gentzen’s LJ system ([15, p. 81]) containing only right and left →-rules is also sound and complete. As it is well known the
→-left rule of LJ does not preserve invalidity. Figure 1 shows structural and logic rules of an adapted Gentzen’s sequent calculus for M→ based on [16, p. 18, §3]. Basically, we restrict the right side of a sequent to one and only one formula (we are in M→thus sequents with empty right side does not make sense). This implies that structural rules can only be considered for main formulae on the left side of a sequent.
A central aspect when considering mechanisms for proof search in M→(and also for IPL) is the application of the →-left rule. Sequent calculus for classical logic (Gentzen’s LK system - [15, p. 81]) ensures that each rule when applied in a bottom-up manner in the proof search reduces the degree of the main formula of the sequent (the formula to which the rule is applied). This implies the termination of the system. For LJ we have the restriction that the right side of a sequent only allows one formula and, as we can reuse a hypothesis in different parts of a proof, the main formula must be available to be used again by the generated premises. Thus, →-left rule has the repetition of the main formula in the premises, a scenario that allows the occurrence of loops in automatic procedures.

Fig. 1. Rules of Gentzen’s LJ


The Sequent Calculus LMT→
In this section we present a sound and complete sequent calculus for M→. We call this system LMT→. We can prove for each rule that if all premises are valid, then the conclusion is also valid and if at least one premise is invalid then the conclusion also is. Besides that, this proof is constructive in the sense that for any sequent we

have an effective way to produce either a proof or a counter-model of it.
We start defining the concept of sequent used in the proposed calculus. A sequent in our system has the following general form:
{Δj}, Υp1 , Υp2 , ..., Υpn , Δ ⇒ [p1, p2, ..., pn],ϕ	(1)
1	2	n

where ϕ is a formula in L and Δ, Υp1 , Υp2 , ..., Υpn
are bags 6 of formulae. Each

1	2	n
Υpi represents formulae associated with an atomic formula pi.
A sequent has two focus areas, one in the left side (curly bracket) and another in the right (square bracket). Curly brackets are used to control the application of the
→-left rule and square brackets are used to keep control of formulae that are related to a particular counter-model definition. Δj is a set of formulae and p1, p2, ..., pn is a sequence that does not allow repetition. We call context of the sequent a pair (α, q), where α ∈ Δj and ϕ = q, where q is an atomic formula on the right side of the sequent.
The axioms and rules of LMT→ are presented in Figure 2. In each rule, Δj ⊆ Δ. Rules are inspired by their backward application. In a →-left rule application, the atomic formula, q, on the right side of the conclusion goes to the []-area in the left premise. Δ formulae in the conclusion are copied to the left premise and marked with a label relating each of them with q. Left premise also has a copy of Δ formulae without the q-label. This is a mechanism to keep track of proving attempts. The form of the restart rule is better understood in the completeness proof on Section 6.
A forward reading of rules can be achieved considering the notion of validity, as described Section 5.

A Termination Strategy for LMT→
The following is a general strategy to be applied with the rules of LMT→ to generate proofs from an input sequent (a sequent that is candidate to be the conclusion of a proof), that is based on bottom-up application of the rules. From the proposed strategy, we can then state a proposition about termination of the proving process. A goal sequent is a new sequent in the form of 1, premise of one of the system’s rule, generated by the application of this rule during the proving process. If the goal sequent is an axiom, this branch stops. If it is not and this goal can not be expanded anymore in this branch, then halt and empty the bag of goals. A goal can not be expanded anymore in a branch when we have applied the restarted rule for every atomic formula that appear on the right side over that branch. Otherwise
apply the first applicable rule in the following order:
Apply →-right rule if it is possible, i.e., if the formula on the right side of the sequent, outside de []-area is not atomic. The premise generated by this application is the new goal of this branch.
Choose the leftmost formula of a highest degree on the left side of the sequent,

6 Sets that take repetitions into account: {A, A, B} is not the same set as {A, B}






















pi


























Fig. 2. Rules of LMT→


not labeled yet, i.e., a formula α ∈ Δ that is not occurring in Δj, then apply the focus rule. The premise generated by this application is the new goal of this branch.
If all formulae on the left side have already been focused, choose the first formula α ∈ Δj such that the context (α, q) was not yet tried since the last application of a restart rule. We say that a context (α, q) is already tried when a formula α on the left was expanded (by the application of →-left rule) with q as the formula outside the []-area on the right side of the sequent. The premises generated by this application become new goals of the respective new branches.
Choose the leftmost formula inside the []-area that was not chosen before in this branch and apply the restart rule. The premise generated by this application is the new goal of this branch.

Figure 3 shows an attempt proof tree generated by the application of the afore- mentioned strategy.

Proposition 4.1 Given that the bag of goals contains only one copy of
{Δj}, Υp1 , Υp2 , ..., Υpn , Δ ⇒ [p ,p ,...,p ],ϕ then, based on the aforementioned

1	2	n
1	2	n

strategy, LMT→ eventually stops.
Proof.
→-right rule is applied until we obtain an atomic formula on the right side.
focus rule is applied until every non-labeled formula become focused. The same formula can not be focused twice, unless a restart rule is applied.
→-left rule can not be applied more than once to a formula, unless a restart rule is applied.
between two applications of the restart rule in a branch there is only one possible application of a →-left rule for a context (α, q).
restart rule is applied only once for each atomic formula that appears on the right side of sequents in a branch. This implies a finite number of application of the restart rule.
2
Observation 4.1 From the proof strategy we can make the following observations about a tree generated during a proving process:
A top sequent is the highest sequent of a branch in the tree.
In a top sequent of a branch on the form of sequent 1, if ϕ ∈ Δ then the top sequent is an axiom and the branch is called a closed branch. Otherwise, we say that the branch is open and ϕ is an atomic formula.
In every sequent of the tree, Δj ⊆ Δ.
For i = 1,... n, Υpi−1 ⊆ Υpi .
i—1	i
The proof of completeness of LMT→ is closely related with this strategy and with the way the proof tree is labeled during the proving process. Section 5 presents the soundness proof of LMT→ and Section 6, the completeness proof.


{Δj}, Υp1 , Υp2 , Υpi−1 ,..., Υpi, Δ ⇒ [p1, p2,..., pi—1, pi], pk  (where k = 1, 2, . . . , i)
1	2	i—1	i
.
a sequence of focus, →-left and →-right
{}, Υp1 , Υp2 ,..., Υpi−1 , Δ ⇒ [p1, p2,..., pi—1], pi
1	2	i—1
.
a sequence of focus, →-left, →-right and restart (for each atomic formula in the []-area)
{ϕ → ψ}, Υp2 ,..., Υpi−1 , Δpi, Υp1 , Υ1, ϕ1,..., ϕn ⇒ [p2,..., pi—1, pi, p1], p2

2	i—1	1
.
p	p	p
→-right	.

{ϕ → ψ}, Υ 2 ,..., Υ i−1 , Δpi, Υ 1 , Υ1 ⇒ [p2,..., pi—1, pi, p1],ϕ	.
2	i—1	1

{ϕ → ψ}, Υp2 ,..., Υpi−1 , Δpi, Υ
⇒ [p ,...,p	,p ],p 
→-left

2	i—1
1	2	i—1 i	1

{}, Υp2 ,..., Υpi−1 , Δpi, Υ
⇒ [p ,...,p	,p ],p 
focus

	2	i—1	1	2	i—1  i	1  restart-p

{Δj}, Υp1 , Υp2 ,..., Υpi−1 , Δ ⇒ [p ,p ,...,p 
1
],p 

1	2	i—1
.
1  2	i—1	i

a sequence of focus, →-left and →-right
{ϕ → ψ}, Υp1 , Υ1, ϕ1,..., ϕn ⇒ [p1], p2

.
a sequence →-right
{ϕ → ψ}, Υp1 , Υ1 ⇒ [p1],ϕ 
	.	
{ϕ → ψ, ψ}, ψ, Υ1 ⇒ [], p1
{ϕ → ψ}, ψ, Υ1 ⇒ [], p1

focus

	1	 →-left
{ϕ → ψ}, Υ1 ⇒ [], p1

{},ϕ → ψ, γ1,..., γm ⇒ [], p1
.
{},ϕ → ψ ⇒ [],γ 
focus

{} ⇒ [], (ϕ → ψ) → γ
Fig. 3. General attempt proof tree
→-right

Soundness of LMT→
In this section we prove the soundness of LMT→. A few basic facts and definitions used in the proof follow.
Definition 5.1 A sequent {Δj}, Υp1 , Υp2 ,..., Υpn , Δ ⇒ [p ,p ,...,p ],ϕ is valid,

1	2	n
i
1	2	n

if and only if, Δj, Δ |= ϕ or ∃i( [ Υpk ) |= pi, for i = 1,... n.
k=1
Definition 5.2 We say that a rule is sound, if and only if, in the case of the premises of the sequent are valid sequents, then its conclusion also is.
A calculus is sound, if and only if, each of its rules are sound. We prove the soundness of LMT→ by showing that this is the case for each one of its rules.

Proposition 5.3 Considering validity of a sequent as deﬁned in Deﬁnition 5.1,
LMT→ is sound.
Proof. We show that supposing that premises of a rule is valid then, the validity of the conclusion follows. In the sequel we analyze each rule of LMT→.
→-left We need to analyze both premises together, thus we have the combina- tions described below.
Supposing the left premise is valid because α → β, Δj, Δ |= α and the right premise is valid because α → β, Δj, Δ,β |= q. We also know that α → β ∈ Δ and Δj ⊆ Δ. In this case, the conclusion holds:
α → β Δ′ Δ Π
α	α → β
β q
Supposing the left premise is valid because ∃i( [ Υpk ) |= pi, for i = 1,..., n,
k=1
the conclusion holds as it is the same.  Supposing the left premise is true
because Δq |= q, the conclusion also holds, as Δq = Δ.
Supposing the right premise is valid because ∃i( [ Υpk ) |= pi, for i = 1,..., n,
k=1
then conclusion also holds.
restart Here, we have three cases to evaluate.
i
Supposing the premise is valid because Υ1, Υ2,..., Υi |= pi, then ∃i( [ Υpk ) |=

pi, for i = 1,..., n. The conclusion is also valid.
j
k=1

Supposing the premise is valid because ∃j(
then conclusion also holds.
[

k=i+1
Υpk ) |= pj, for j = i + 1,..., n,

Supposing the premise is valid because Δq |= q, then Δ |= q and, as Δj ⊆ Δ, Δj, Δ |= q.
→-right
Supposing the premise is valid because Υ1, Υ2,..., Υi |= pi, then ∃i( [ Υpk ) |=

pi, for i = 1,..., n. This is also valid in the conclusion.
k=1

Supposing the premise is valid because Δj, Δ,α |= β, then every Kripke model that satisfies Δj, Δ and α also satisfies β. We know that Δj ⊆ Δ. Those models also satisfies α → β and, then, conclusion also holds.
focus
Supposing the premise is valid because Υ1, Υ2,..., Υi |= pi, then ∃i( [ Υpk ) |=

pi, for i = 1,..., n. This is also valid in the conclusion.
k=1

Supposing the premise is valid because Δj, α, Δ,α |= β, then the conclusion also holds as Δj, Δ,α |= β.
2
From Proposition 5.3, we conclude that LMT→ only prove tautologies.
Completeness of LMT→
By observation 4.1 iii we know that a top sequent of an open branch in an attempt proof tree has the general form bellow, where q is an atomic formula:
{Δj}, Υp1 , Υp2 , ..., Υpn , Δ ⇒ [p1, p2, ..., pn],q 
1	2	n
From Definition 5.1, we can say that a sequent is invalid if and only if Δj, Δ $ q
i
pk k
k=1
Definition 6.1 We can construct a Kripke counter-model M that falsifies a top sequent of an open branch. This can be done in the following way:
The model M has an initial world w, i.e., w is not accessible by any other world. In w set every atomic formula inside the []-area as false. That is, M $w pi, for i = 1,... n.
Consider a world w0 in M, such that w ≤ w0. By the definition of an invalid sequent, Δj, Δ $ q. w0 will be used to guarantee this. We set q false in w0, i.e, M $w0 q. This implies that M $w q. We also set every atomic formula

that is in Δ (remember that Δj ∈ Δ) as true, i.e., ∀p, p ∈ Δ, M ▶w
consistent with the values of the same atomic formulae in w.
p. This is

By the definition of an invalid sequent, we also need that ∀i( [ Υpk ) $ pi, for
k=1

i = 1,... n. Thus, for each i, i = 1,...n we define a world wi in M, such that
w ≤ wi. We set ∀p, p ∈ Υpi ,p atomic, M ▶w p. We also set M $w pi.
i
The general schema of the counter-model generated by the definition 6.1 is
w
$ pi,i = 1,...n 



wn
∀p, p ∈ Υpn
p atomic
▶ p
...	w1
∀p, p ∈ Υp1
p atomic
▶ p
w0
$ q
∀p, p ∈ Δ
▶ p

Fig. 4. General schema of counter-models

This schema to construct counter-model allows us to state the following lemma:
Lemma 6.2 Let S be a top sequent of an open branch in an attempt proof tree generated by the strategy presented in Section 4. Then we can construct a Kripke model M with a world u where M $u S, using the aforementioned counter-model generation schema.
Proof. We can prove this by induction on the degree of formulas in Δ and in Υpi , for i = 1,... n. From definition 6.1 ii we know that every atomic formula in Δ is true in w0 and that $w0 q. From definition 6.1 iii we know that every atomic

formula in Υpi is true in wi and that $w
pi. The inductive hypothesis is that every
p

formula in Δ is true in w0 and that every formula in Υi i is true in wi.
Thus, we have two cases:
Let α → β be a formula in M→ that is in Δ. We show that M ▶w α → β. Consider that α ≡ (γ1 → (γ2 → ... → (γm → q))). By the proof strategy, γ1, γ2,..., γm also are in Δ. The degree of each of these formulae are less than the degree of α → β and, by the induction hypothesis, all of them are true in w0. This makes $w0 α and ▶w0 α → β.
Let α → β be a formula in M→ that is in Υpi , for i = 1,... n. We show that
M ▶wi α → β.
Consider that α ≡ (γ1 → (γ2 → ... → (γm → q))). By the proof strategy, γ1, γ2,..., γm also are in Υpi . The degree of each of these formulae are less than the degree of α → β and, by the induction hypothesis, all of them are true in wi. This makes $wi α and ▶wi α → β.
2

Definition 6.3 A rule is said invertible or double-sound iff the validity of its con- clusion implies the validity of its premisses.
In other words, by Definition 6.3 we know that a counter-model for a top se- quent of a proof tree which can not be expanded anymore can be used to construct a counter-model to every sequent in the same branch of the tree until the conclu- sion (root sequent). In the case of →-right rule in our system, not just that if a premiss of the rule has a counter-model then so does the conclusion, but the same counter-model will do. Weich called rules with this property preserving counter model rules [19]. Dyckhoff proposed call them strongly invertible rules (personal communication).
Lemma 6.4 The rules of LMT→are invertible.
Proof. We show that the rules of LMT→are invertible when considering a proof tree labeled in the schema presented in Section 3. We prove that from the existence of a Kripke model that makes a premise of the rule invalid then, conclusion is also invalid.
→-right If the premise is invalid, then there is a Kripke model M where Δj, Δ,α $ β and ∀i( [ Υpk ) $ pi, for i = 1,...,n from a given world u. Thus,
k=1
in the conclusion we have:
By the definition of semantics of Section 2.1, there have to be a world v, u ≤ v, in the model M where Δj, Δ,α are satisfied and where β is not. Thus, in v, α → β can not hold.

By the model M, for each i, exists a world vi, u ≤ vi, where ▶vi
Thus, the conclusion is also invalid.
Υpi and $v
pi.

→-left Considering that one of the premises of →-left are not valid, the conclu- sion also is. Thus, we have to evaluate both cases:
If the right premise is invalid then there is a Kripke model M where α →
β, Δj, Δ,β $ q and ∀i( [ Υpk ) $ pi, for i = 1,...,n from a given world u.
k=1
Thus, in the conclusion we have:
By the model M, there have to be a world v, u ≤ v, in the model where
α → β, Δj, Δ,β are satisfied and where q is not.

By the model M, for each i, exists a world vi, u ≤ vi, where ▶vi
$vi pi.
Thus, the conclusion is invalid too.
Υpi and

If the left premise is invalid then there is a Kripke model M where α →
β, Δj $ α and ∀i( [ Υpk ) $ pi, for i = 1,..., n, and Δq $ q from a given world
k=1
u. Thus, in the conclusion we have:
· By the model M, there have to be a world v, u ≤ v, in the model where

α → β, Δj are satisfied and where α is not.
By the model M, for each i, exists a world vi, u ≤ vi, where ▶vi
$vi pi.
We also know by M that there is a world vq, u ≤ vq, where ▶vq
Υpi and Δq and

$vq
q. We also have that Δj ⊆ Δ and that α → β ∈ Δ. Therefore, ▶v Δj

and ▶vq α → β.
· Thus, the conclusion can not be valid.
focus If we have a model that invalidates the premise, this model also invalidates the conclusion as the sequents in the premise and in the conclusion are the same despite the repetition of the focused formula α.
restart If the restart premise is invalid, then there is a Kripke model M and a world u from which Υ1, Υ2,..., Υi $ pi and ∀j( [ Υpk ) |= pj, for j = i + 1,..., n,

and Δq $ q. Thus, in the conclusion we have:
k=1

By the model M, there have to be a world v, u ≤ v, in the model where Υ1, Υ2,..., Υi are satisfied and where pi is not. Each Υk has the same formulae as Υpk and, by the restart condition, we know that $ pk, for k = 1,..., i.

By the model M, for each j, exists a world vj, u ≤ vj, where ▶vj
$vj pj.
pj and

q
We also know by M that there is a world vq, u ≤ vq, where ▶vq Δ and $v q.

We also have that Δj ⊆ Δ. Therefore, ▶v
Thus, the conclusion is invalid.
Δj.

2

Now we can state a proposition about completeness of LMT→:
Proposition 6.5 LMT→ is complete regarding the proof strategy presented in Sec- tion 3
Proof. It follows direct from Proposition 4.1 (the process always terminates) and Lemmas 6.4 and 6.2 above.	2

An automatic theorem prover for M→
Based on the aforementioned system, we developed a theorem prover for M→ (its source code can be found at https://github.com/jeffsantos/sequent-prover). Figure 5 shows a fragment of the proof tree generated by this prover for the formula:
((((A → C) → A) → A) → C) → C,
a formula that is shown in [2] to need to use the assumption (((A → C) → A) →
A) → C at least twice to be proved in M→. As presented in [6] this formula is used as the base to define a family of formulae in M→with no bounds on the use of assumptions. Figure 5 shows the expansion of the left branch of the final proof.

Related Work
A common way to control the proof search procedure in M→ (and in IPL) is by the definition of routines for loop verification as proposed in [17]. Loop checkers are very expensive procedures, although they are effective to guarantee termination in automatic provers for M→ (and other logics with the same characteristic). The work in [9] and in [10] are examples of techniques that can be used to minimize the performance problems that can arise with the usage of such procedures.
To avoid the use of loop checkers, Dyckhoff [3] proposed a terminating contraction-free sequent calculus for IPL, named LJT, using a technique based on the work of Vorob’ev [18] in the 50s. Pinto and Dyckhoff, in [13], extended this work showing a method to generate counter-examples in this system. They pro- posed two calculi, one for proof search and another for counter-model generation, forming a way to decide about the validity or not of formulae in IPL. A character- istic of their systems is that the sub-formula property does not hold on them. In [5], a similar approach is presented using systems where the sub-formula property holds. They also proposed a single decision procedure for IPL which guarantee minimal depth counter-model.
Focused sequent calculi appeared initially in the Andreoli’s work on linear logic ([1]). The author identified a subset of proofs from Gentzen style sequent calculus, which are complete and tractable. Liang and Miller [12] proposed the focused sequent calculi LJF where they used a mapping of IPL into linear logic and adapted the Andreoli’s system to work with the image. Dyckhoff and Lengrand [4] presented the focused system LJQ that work direct in IPL. Focusing is used in their system as a way to implement restrictions in the →-left rule as proposed by [18] and [11]. The work of Dyckhoff and Lengrand follows from the calculus with the same name presented in [8]. In our approach, focusing is used as a technique to guarantee the completeness of the system and to produce the counter-model from a failed proof search process.


Conclusion and Future Work
We presented here the definition of a unified procedure (the LMT→system) to generate Kripke counter-models from trees generated by unsuccess proving processes for M→.
Regarding the LMT→system, we know that the size of the generated counter- model still takes into account every possible combination of sub-formulae yielding Kripke models with quite a lot worlds. There are still work to be done in order to produce smaller models.
On the theorem prover side, our research has a lot of work to be done. Further work includes the implementation of user strategies that can be combined with the built-in prover strategy to customize the way the prover conducts the proving process. Interface and user interaction with the system are other options to improve.

Acknowledgment
We would like to thank Roy Dyckhoff for all revisions, critics and suggestions.

References
Andreoli, J.-M., Logic programming with focusing proofs in linear logic, Journal of Logic and Computation 2 (1992), pp. 297–347.
Dowek, G. and Y. Jiang, Eigenvariables, bracketing and the decidability of positive minimal predicate logic, Theoretical Computer Science 360 (2006), pp. 193–208.
Dyckhoff, R., Contraction-free sequent calculi for intuitionistic logic, The Journal of Symbolic Logic
57 (1992), pp. 795–807.
Dyckhoff, R. and S. Lengrand, LJQ: a strongly focused calculus for intuitionistic logic, in: Logical Approaches to Computational Barriers, Springer, 2006 pp. 173–185.
Ferrari, M., C. Fiorentini and G. Fiorino, Contraction-free linear depth sequent calculi for intuitionistic propositional logic with the subformula property and minimal depth counter-models, Journal of automated reasoning 51 (2013), pp. 129–149.
Haeusler, E. H., How many times do we need an assumption to prove a tautology in minimal logic? examples on the compression power of classical reasoning, Electronic Notes in Theoretical Computer Science 315 (2015), pp. 31–46.
Haeusler, E. H., Propositional logics complexity and the sub-formula property, Electronic Proceedings in Theoretical Computer Science 179 (2015), pp. 1–16, proceedings of DCM2014, Vienna, 2014.
Herbelin, H., A λ-calculus structure isomorphic to Gentzen-style sequent calculus structure, in:
Computer Science Logic, Springer, 1995, pp. 61–75.
Heuerding, A., M. Seyfried and H. Zimmermann, Efficient loop-check for backward proof search in some non-classical propositional logics, in: Theorem Proving with Analytic Tableaux and Related Methods, Springer, 1996 pp. 210–225.
Howe, J. M., Two loop detection mechanisms: a comparison, in: Automated Reasoning with Analytic Tableaux and Related Methods, Springer, 1997 pp. 188–200.
Hudelmaier, J., An O(n log n)-space decision procedure for intuitionistic propositional logic, Journal of Logic and Computation 3 (1993), pp. 63–75.
Liang, C. and D. Miller, Focusing and polarization in intuitionistic logic, in: Computer Science Logic, Springer, 2007, pp. 451–465.
Pinto, L. and R. Dyckhoff, Loop-free construction of counter-models for intuitionistic propositional logic, in: Symposia Gaussiana, Conf A, Walter de Gruyter & Co (Berlin), 1995, pp. 225–232.
Statman, R., “Structural Complexity of Proofs,” PhD thesis, Stanford University (1974).
Szabo, M. E., The collected papers of Gerhard Gentzen 160 (1969).
Takeuti, G., Proof theory 81 (2013).
Underwood, J., A constructive completeness proof for intuitionistic propositional calculus, Technical report, Cornell University (1990).
Vorob’ev, N. N., A new algorithm for derivability in the constructive propositional calculus, American Mathematical Society Translations 94 (1970), pp. 37–71.
Weich, K., Decision procedures for intuitionistic propositional logic by program extraction, in:
Automated Reasoning with Analytic Tableaux and Related Methods, Springer, 1998 pp. 292–306.


		
