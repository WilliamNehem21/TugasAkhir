	Electronic Notes in Theoretical Computer Science 171 (2007) 111–126	
www.elsevier.com/locate/entcs

A Fully Labelled Lambda Calculus: Towards Closed Reduction in the Geometry of Interaction Machine
Nikolaos Siafakas1
Department of Computer Science King’s College London, UK

Abstract
We investigate the possibility of performing new reduction strategies with the Geometry of Interaction Machine (GOIm). To this purpose, we appeal to L´evy’s labelled lambda calculus whose labels describe: a) the path that the GOIm will follow in the graph of a term and b) the operations that the GOIm requires to compute the multiplicative part from the Multiplicative and Exponential Linear Logic encoding that the machine uses. Our goal is to unveil the missing exponential information in the structure of the labels. This will provide us with a tool to talk about strategies for computing paths with the GOIm.
Keywords: Lambda calculus, Labels, Paths, Geometry Of Interaction


Introduction
There is a well established connection between labels in L´evy’s labelled λ-calculus and paths in the graph of a term [1,4,2]. If we compute the normal form of a term in the labelled λ-calculus, then the resulting label will describe a path in the graph of the term. The Geometry Of Interaction Machine [12], which is an implementation of Girard’s Geometry of Interaction semantics for Linear Logic [10], will follow exactly the path induced by the label. The investigation of the structure of the labels allowed the identification of the call-return symmetry [4], which has led to optimisations [6,7] where the length of the path to be traversed is significantly reduced. However:
The structure of the labels is different from the structure of paths: labels talk about redex contractions whereas paths in the GOIm about the dynamics of Linear Logic cut elimination.

1 email:nikolaos.siafakas@kcl.ac.uk

1571-0661 © 2007 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2006.12.040

The structure of the paths depends on the choice of translation of the λ-calculus into Linear Logic proof nets (call-by-value or call-by-name).
Many equivalences are known to date but properties found in the labels have to be transposed to paths and vice versa.
Our goal is to identify structure in the labels that will allow us to reason about new ways for computing paths with the GOIm. Therefore, we investigate a new set of labels, which corresponds closer to the paths.

Background and Motivation
In this section we set up the conventions that we will use in the rest of the paper. Our point of departure is L´evy’s labelled λ calculus [11] whose labels give a simple notion for a “path in a term”.
Definition 2.1 The set of labels is formed by the following grammar:
α, β := a | αβ | α | α
where (Latin) a is an atomic label. Labelled terms are terms of the λ-calculus where each sub-term T has a label attached on it: Tα. Subterms in the initial form of a term receive a distinct atomic label. Labelled β-reduction is given by
((λx.M )αN )β → βα • M [α • N/x]
where • concatenates labels with labelled terms, defined by β • Tα = Tβα. Substi- tution is implicit and operates as follows
xα[N/x]	= α • N
yα[N/x]	= yα
(λy.M )α[N/x] = (λy.M [N/x])α
(MN )α[P/x]	= (M [P/x]N [P/x])α
Example 2.2 The term III, I = (λx.x) reduces as follows:
hebabdcebabdg


λx	λx	x
f	c	f
x	x

x	x
If we reverse the underlines then the resulting label induces a path that the GOIm will compute without reducing the term. However, the GOIm does not act on syntax trees of the λ-calculus but on graphs, which are translations of the

λ-calculus into Linear Logic proof-nets [9]. Computation then follows the idea of a token traversing the edges of the graph. Here we provide the call-by-value translation T (·) with which we will work throughout this paper [12].
Definition 2.3 The general form of a term is given by
a	a

≡
...

where we attach an atomic label to the root of each sub-term. Edges at the bottom of the structure denote the free variables of the term. The translation is given by the following recursive definition:




T (x) = 
T (λx.M ) = 
T (MN ) = 


...	...



Some remarks are in order: In T (λx.M ), we assume that the bound variable x is at the leftmost edge of the free variables of T (M ). We attach a node W if x /∈ fv(M ). Intuitively, the box structure can be thought of as “the scope” of a function. In terms of Linear Logic, it is a net that can be used in a non-linear way.
The graphs presented here are proof nets, which are oriented in a way that closely resembles λ-calculus syntax trees. Notice that axiom and cut links are hidden within the structures. We distinguish between two kinds of nodes:
Multiplicative nodes: Tensor (⊗), Par( )
Exponential nodes: Of Course (!), Dereliction (D), Weakening (W ), Why Not (?), Contraction (R, S)
The arrows on the nodes are not standard proof net notation but we place them in order to keep track of the original orientation of the nets. This idea is borrowed from Interaction Net notation where arrows are used to indicate principal ports of nets. We will not require the full power of MELL cut elimination but only Closed MELL cut elimination, which we present in Figure 1 with the original orientation of the nets. We refer the reader to [13] for a more formal treatment.
The overlining and underlining in L´evy’s labelled λ-calculus captures redexes that have been contracted during reduction. In other words, these labels mark the points of contact of the (virtual) redexes in a term. If we transpose this information to proof-nets then overlining and underlining hints about where the multiplicative nodes are located in the labels. This is also the case for the call-by-name translation, which we do not consider here.





Axiom Cut	⇒






Multiplicative Cut







Dereliction Cut







Contraction Cut

...


















...















...

...
⇒	...












⇒



⇒



















...

...































...






Weakening Cut
...	⇒


...







Commutative Cut	⇒




Fig. 1. Closed Cut Elimination

In the next section we show that it is possible to add the missing exponential information during labelled reduction where we make use of a weak, α-conversion free λ-calculus. A weak λ-calculus is also studied in [5], which has been related to Wadsworth’s graph representations. In section 4 we relate the structure obtained from the labels with Linear Logic cut elimination where we make the notion of “connectivity” important (see for instance [3]). In section 5 we comment on how the extra structure helps in understanding and exploring new strategies for the

GOIm.





Paths in the calculus of closed functions

Our approach is similar to L´evy’s labelled reduction where we attach labels to terms and capture information during reduction. The labelled β-rule can provide some information about the location of the exponential nodes. In the call-by-value trans- lation, it is trivial to identify the location of D-nodes and !-nodes since these live beneath the multiplicative nodes. This is because the translation of a redex involves multiplicative nodes, which are intercepted by a D and a !-node. Unfortunately, the β-reduction step cannot help further; we have to focus on the substitutions in order to identify the locations of the remaining exponential nodes. However, substitutions are propagated exhaustively and in an uncontrolled way. For instance, it is known that paths can be copied but this is not resembled by copying the substitution in:

(MN )α[P/x] = (M [P/x]N [P/x])α

The explicit substitution calculi in [8] overcome these deficiencies. In this section we provide a labelled version of the “calculus of closed functions” (λcf ), which will allow us to obtain explicit paths for the call-by-value translation.


Definition 3.1 Terms in the λcf -calculus are λ-terms with explicit constructs for copying (δ) and erasing (ϵ) and are presented along with their variable constraints.

δy,z.M	x /∈ fv(M ),y /= z, {y, z} ⊆ fv(M )	(fv(M ) − {y, z}) ∪ {x}
M [N/x]	x ∈ fv(M ), (fv(M ) − {x}) ∩ fv(N ) = ∅  (fv(M ) − {x}) ∪ fv(N )


Definition 3.2 Lambda terms are compiled into this set of terms (λc) via the translation ⟨·⟩. We assume compilation of closed terms:

⟨x⟩	= x
⟨MN ⟩	= ⟨M ⟩⟨N ⟩
⟨λx.M ⟩	= λx.[x]⟨M ⟩ if x ∈ fv(M )
= λx.ϵx.⟨M ⟩ otherwise
We define [·]:
[x]x	= x
[x](λy.M )	= λy.[x]M
[x](MN )	= δy,z.[y](M [x := y])[z](N [x := z]) x free in M and N (y, z fresh)
= ([x]M )N	x free in M only
= M ([x]N )	x free in N only [x](ϵy.M )	= ϵy.[x]M
[x](δu,v.M )	= δu,v.[x]M
y	y

Example 3.3 Here we provide some example terms that are yielded by the com- pilation:
⟨λx.λy.x⟩ = λx.λy.ϵy.x
⟨(λx.xx)(λx.x)⟩ = (λx.δy,z.yz)(λx.x)
Notice that the compilation does not apply to open terms. For instance,

⟨(λx.x)(yy)⟩ = (λx.x)(yy)

but the translated application (yy) does not satisfy the variable constraints of λc- terms. We refer the reader to [8] for the full version of the compilation.
Definition 3.4 Labelled terms are λc-terms where every sub-term T has a label:
Tα. The set of labels is defined by the following grammar:

α, β := a | αβ | α | α | C;
−→ | ←−
E := D | ! | ? | R | S | W ;


This is the same set as the set of L´evy’s labels where we add (atomic) markers for exponential nodes, each of which has an associated direction. Multiplicative information is kept implicit via overlining and underlining.
Definition 3.5 The Beta rule of the labelled calculus λlcf is defined by

Beta:	((λx.M )αN )β →λlcf β−→D α←−! • M [(−→D α←−! )r • N/x]
where we impose the condition that fv((λx.M )α) = ∅.  The operator • and the

function (·)r which reverses labels are defined as follows::

(a)r	= a	β • xα	= xβα
(αβ)r = (β)r · (α)r	β • (λx.M )α = (λx.M )βα

(α)r	= (α)r	β • (MN )α  = (MN )βα
(α)r	= (α)r	α • (δyz.M ) = (δyz.α • M )
x	x
−→ r	←−

( E )
←−
( E )
= E	α • (ϵx.M )	= (ϵx.α • M )
−→
= E

Substitution rules (σ) are placed at the same level as the Beta rule and are pre- sented below.

Rule	Reduction	Condition

Lam
(λy.M )α[N/x]	→λ
−→ • N/x])α	fv(N ) = ∅


App1 App2
lcf	(λy.M [ ?
(MN )α[P/x]	→λ	(M [P/x]N )α	x ∈ fv(M )
(MN )α[P/x]	→λ	(MN [P/x])α	x ∈ fv(N )

Cpy1	(δyz.M )[N/x]	→
Cpy2	(δyz.M )[N/x']	→
λlcf λlcf
M [−→R • N/x][−→S • N/x]	fv(N ) = ∅
(δyz.M [N/x'])	˜

Ers1	(ϵx.M )[N/x]	→λ	M,	{−→W • N }∪ B	fv(N ) = ∅
Ers2	(ϵx.M )[N/x']	→λ	(ϵx.M [N/x'])	˜
Var	xα[N/x]	→λ	α • N	˜
Cmp	M [P/y][N/x]	→λlcf	M [P [N/x]/y]	x ∈ fv(P )

Remark 3.6 The only rule that creates a substitution is the Beta rule. The rule Lam captures the situation where the substitution has to leave the function scope of the abstraction in which the substitution has been originally created and enters a sub-function scope. The controlled copying and erasing (Cpy1 and Ers1) of substitutions allows the identification of paths that start from contraction nodes
and weakening nodes respectively. Erased paths are kept in a set B. Notice that explicit labelling on copying (δ) and erasing (ϵ) constructs is omitted: these are used just to guide the substitutions. We inherit a number of properties from λcf : our calculus is α-conversion free and closed substitutions do not remain blocked. On the other hand, the calculus is weak but is adequate for the evaluation of programs (closed terms).

A closer look at how the calculus operates will be presented via the graphical representation of the rewrite rules. For this reason, we define a translation for λc

terms into Linear Logic proof nets, which we present below:
G(x) =	G(λx.M ) =	G(MN ) = 


















...	...


G(δy,z.M ) =	G(ϵx.M ) =	G(M [N/x]) =








...










...

Example 3.7 Here is the graphical representation of the left and right hand sides of the Beta rule. There are two cut elimination steps involved in order to achieve this rewrite: 1) a closed dereliction cut and 2) a multiplicative cut.







G(LHS) = 






The rules Cpy1 and Ers1 behave as follows:
G(RHS) = 







G(M )

R S

...



G(LHS) = 
α
G(RHS) 
G(LHS) = 
α
G(RHS) = 



{	}  B




Remark 3.8 There are many paths in a program and the task of the GOIm is to

find the path that survives the process of reduction. In other words, there exist erased sub-paths that are not part of the normal form of a program. However, when studying strategies for the GOIm, it is of interest to identify paths that lead to discarded arguments. Since substitutions are discarded in a controlled way, we keep these paths in the set B.
Example 3.9 We provide an example path yielded by the reduction of (λxy.xy)II,
I = (λx.x).


where
(((λx.(λy.(xayb)c)d)e(λx.xf )g)h(λx.xi)j)k →∗
(λx.xi)φ

φ = k−→D h −→D e←−! d←−! c −→D a−→? −→! e←D− g ←−!  f −→! g −→D e←−! ←−? a←D−b−→! d−→! e←D−h←D− j
The corresponding graph is presented below:

In the remainder of this section we show that the labelled case preserves con- fluence. The proofs presented here are an adaption from [8] to the labelled case.

Lemma 3.10 For • and substitution we have (β • M )[N/x] = β • (M [N/x]).
Proof. By induction on the structure of M . We show the case for δ-terms: M = (δyz.P ). The lhs is
(β • (δyz.P ))[N/x]	= (δy z.(β • P ))[N/x] by definition of •

x





and the rhs:
x
→λ	(β • P )[−→R • N/y][−→S • N/z]
= β • (P [−→R • N/y])[−→S • N/z] by IH

β • ((δy z.P )a1 [N/x]) →

λlcf
β • P [−→R • N/y][−→S • N/z]

where substitution associates to the left.	 
Lemma 3.11 (local confluence) There are seven criticalpairs in λlcf all of which are joinable.
Proof. We distinguish the cases which are interesting w.r.t. the labels.
Superposition of Beta-App2: ((λy.M )αN )β[P/x], where x ∈ fv(N ), gives rise to the critical pair c1 ≈ c2 with
c1 = β−→D α←−! • M [−→! αr←D− • N/y][P/x]	c2 = ((λy.M )α(N [P/x]))β which converges as shown below:
c1 →Cmp β−→D α←−! • M [−→! α←D− • N [P/x]/y]
c2 →Beta β−→D α←−! • M [−→! α←D− • (N [P/x])/y] and c1 = c2 by the previous lemma.
For yα[N/y][P/x], c1 = α • N [P/x] and c2 = yα[N [P/x]/y]. After one applica- tion of the rule Beta we have c2 → α • N [P/x] = c1
The remaining critical pairs arise from superpositions between App1-Cmp, App2-

Cmp,
Cpy2-Cmp,
Ers2-Cmp and Cmp-Cmp. Additionally, these critical pairs

converge without requesting label sensitive rules (Beta, Lam, Cpy1, Ers1, and
Var).	 
Remark 3.12 The conditions on the rewrite rules are essential. If we drop the condition of the beta rule then the overlap ((λy.M )αN )β[P/x], x ∈ M gives rise to a critical pair which is not joinable:
((λy.M )αN )β[P/x]


((λy.M )α[P/x]N )β



−→
((λy.M [ ? • P/x])α
N )β




β−→D α←−! • M [−→! αr←D− •
≡?	−→D α←−! •
−→ •
−→ r ←−

In this case, searching for a property of commutation of substitutions would not
−→
help because there is still a ? in the branch on the right to deal with.
In order to show confluence, we will split λlcf into two relations: →σ and ⇒beta. Then we will make use of Rosen’s lemma, which states that the union of two rewrite
systems is confluent if both are confluent and commute.
The first system consists of all σ-rules in λlcf . Notice that the critical pairs of →σ are the ones presented earlier except the first one. Additionally, these critical pairs do not the request the Beta rule and therefore →σ is locally confluent. Moreover, there are no infinite reduction sequences in →σ. Hence, →σ is confluent.

⇒beta is defined to be the Beta rule of λlcf which contracts in parallel all
beta redices at any position in a λlcf -term. To obtain confluence we show that
⇒beta has the diamond property (strong confluence), that is, if M ⇒beta M ' and
M ⇒beta M '' then there exists N such that M ' ⇒beta N and M '' ⇒beta N . The

proof is by induction on M ⇒beta M '. Clearly, →beta⊆⇒beta and →∗
beta,

which also makes the original beta rule confluent.
Proposition 3.13 (commutation of ⇒ /σ) If M ⇒∗

M ' and M →∗ M '' then

there exists N such that M '
→∗ N and M ''
∗
beta
beta	σ

Proof. We first show that the diagram weakly commutes by induction on the def- inition of ⇒beta . We distinguish the following cases:
Let M = ((λy.P )αO)β; ⇒beta applies at the root of the term, M ' = β−→D α←−! •
Pb[−→! αr←D− • Ob/x], P →beta Pb, O →beta Ob; →σ is internal to P or O, M '' =
((λy.Pσ)O)β or M '' = ((λy.P )Oσ)β whenever P →σ Pσ or O →σ Oσ. By IH , there exists a term Pv such that Pb →σ Pv and Pσ →beta Pv or there exists a term Ov such that Ob →σ Ov and Oσ →beta Ov. Take N = Pv[Ob/x] for the first case and N = Pb[Ov/x] for the second case.
Let M = P [O/x], M ' = Pb[Ob/x], M '' = Pσ[O/x] or M '' = P [Oσ/x], where a
σ-rule does not apply at the root of M and all reductions are internal to P or
O. Hence the property holds by IH. On the other hand, if a σ-rule is applicable at the root of M then we have to consider different cases: a) we may have an overlap between a Beta rule (P is a beta redex) and the σ-rule. In this case
only App2 can be applied since the functional part of the beta redex has to be
closed. This case is similar to the first critical pair presented earlier where the pair converges at N . b) In any other case, take P to be the lhs (L) of one of the σ-rules, M = L[O/x], M ' = L[Ob/x] , M '' = R[O/x]; the diagram commutes with N = R[Ob/x].
Commutation is obtained by induction on the length of the derivation M ⇒∗

'	∗	∗
Beta

M . Since →beta=⇒beta we close the diagram and conclude that λlcf is confluent by Rosen’s lemma.	 

Structure of the labels
The markers in the labels add only positions of exponential information to the paths, that is, we still only know about the points of contact between multiplicative nodes (and consequently D−! nodes). This is understood as an interaction between the functional part of the redex and the argument. The question we try to answer in this section is whether it is possible to mark the remaining exponential points of contact in the labels. The problem is that the remaining rules describe interactions between terms and substitutions. In particular, we would like to treat interactions
in the rewrite rules Lam, Cpy1 and Ers1 as interactions with abstractions. We
remind that all exponential cut rules involve a box structure which, in case of the lambda calculus translation, is an abstraction. A solution to our problem is

to substitute only evaluated terms (i.e. simulate a call by value strategy) and ensure that substitutions evaluate to abstractions. It has been shown in [8] that closed terms in λcf evaluate to weak head normal form by simulating a call-by-value strategy. Notice that weak head normal forms of closed terms are also closed terms and thus the only possible results are abstractions. The conditions of the rules of
interest require that substitutions are closed and this allows us to treat rules Cpy1, Lam and Ers1 as desired. Additionally, we remind that the rule Beta also involves
a closed dereliction cut and this completes the picture of exponential cut elimination steps that we can simulate via our reasoning.
Example 4.1 In the following example we show how to apply these ideas to the rule Lam: we first evaluate the substitution of the left hand side of the rewrite rule and then move to the right hand side of the rule. This simulates a closed commutative cut elimination step and we can capture this situation in the label as
follows:
We usually add labels to the paths once nodes have been removed from the graph. For this example only, we slightly abuse this intuition and add a trailing Of Course label to mark the points of contact. Notice that the root of the box in G(N ') has survived the reduction and is subject to further exponential cut elimination steps until the box gets involved with a dereliction cut.
However, it is not necessary to simulate a call-by-value strategy to identify these points of contact. It turns out that the structure of the multiplicative overlining and underlining provides enough information to recover the exponential connectivity. As in L´evy’s calculus, overlining and underlining does not only add connectivity to the labels but also depth.
Definition 4.2 We define depth(φ) to be the overall nesting of a label. This is the total number of overlines and underlines that surround a label.
By adding depth to a label, we achieve to place the sub-label that is irrelevant to further Beta reductions into history.
Lemma 4.3 Let L(M ) denote the external label of a term. By using only the rules

in σ, if M →∗ M ' then depth(L(M )) = depth(L(M '))
Proof. Substitutions add only positions for Why Not, Contraction and and Weak- ening nodes. It is the Beta rule that adds depth to the labels.	 
Additionally, due to confluence of σ, the positions in which these markers are recorded do not depend on the order in which we apply the substitutions.
Proposition 4.4 (Virtual Cuts) Let γ be an overlined (resp. underlined) sub- label at depth k and let Exp be the multiset of all atomic exponential markers at

depth k + 1. The multiplicity of
−→
! ∈ Exp (resp.
←−
! ∈ Exp) is 1. Each exponential

marker other than the Of Course marker in the multiset forms a virtual exponential cut with that Of Course marker.
Proof (Sketch) From the previous discussion, it follows that only labels with depth 0 play a role in further Beta reductions. We consider the situation where we apply σ-rules only in which case exponential markers ?, W and R (resp. S) are added at depth 0 and retain this depth by the previous lemma. The ! marker that forms the other end of the cut has to be located in a relevant portion of the label, that is, at depth 0. But this marker is provided only during a Beta rewrite step, which also places a D marker at depth 0 (marking the final dereliction cut that
destroys the box) and then increments all depths by surrounding the label with an overline / underline.	 
Example 4.5 Here we repeat the example of the labelled reduction of (λxy.xy)II where we now add exponential connectivity to the paths.



with
(((λx.(λy.(xayb)c)d)e(λx.xf )g)h(λx.xi)j)k →∗
(λx.xi)φ


φ = k−→D h −→D e←−! d←−! c −→D a−→?	f −→g −→ ←−←− ←− −→ −→ ←− ←−
!	D e ! ? a D b ! d ! e D h D j


where we highlight the boundaries of the box and the virtual commutative (!−?) cut. Notice that the direction of the arrow of each Of Course marker faces the direction of the arrow of the exponential marker with which it forms a cut. A slightly more complicated example is the reduction of the term (λx.xx)(II)I, which shows how information flows through contraction nodes:

(((λx.(δp,o(paob)c))d((λx.xe)f (λx.xg)h)i)j(λx.xk)l)m →∗
(λx.xk)φ

x

with φ = mψgψrl and ψ is given below:
λlcf



We have split the contraction nodes into R and S in order to capture the different routes that paths can take through contraction nodes. The corresponding graph is presented in Figure 2.



Fig. 2. Translation of (λx.xx)(II)I

Towards Closed Reduction in the GOIm
The main interest in examining strategies for the GOIm comes from the fact that the length of the paths to be traversed can be significantly reduced. The reader should notice that strategy here means computing the same paths differently. For instance, the Jumping Abstract machine presented in [6] shortcuts paths that are underlined: these are the same as the overlined paths, but in reverse order. The Call-By-Value GOIm presented in [7] adds on top of this idea and shortcuts sub-redundancies like the exponential virtual cuts, which are highlighted in our second example. These sub-redundancies describe repeated evaluations of arguments. Notice that this level of redundancy is not immediately present in L´evy’s labels.
A common approach that has been adopted to achieve these optimisations is to borrow features from environment machines. The Jumping Abstract machine and the Call-By-Value GOIm have been related to Krivine’s (call-by-name) machine and to the Categorical Abstract Machine (CAM) respectively. The approach is to take “snapshots” of the environment during the traversal of the graph such that this environment is restored at the time a shortcut is taken. The price to pay is that copying and discarding environments is an expensive operation. On the other hand, the Geometry of Interaction machine is free from these deficiencies but does not take any shortcuts.
Our interest in focusing on a closed strategy is in that the dynamics of closed cut elimination are much simpler than in the full case but powerfull enough for implementing functional languages. An important point to notice is that the Call- By-Value GOIm demonstrates that one has not to follow the paths exactly in the same order as they appear in the labels (from left to right).
Here we provide an informal description on how a closed strategy acts. Com- putation is initialised by following a normal flow in the traversal of the graph but once the strategy detects the appearance of ?-nodes in boxes, the normal flow is put on hold in order to deal with the ?-nodes first. The goal is to remove ?-nodes from

the graph by installing shortcuts such that ?-nodes are practically invisible once the normal flow of the computation resumes. In terms of Linear Logic, the strategy tries to close boxes as soon as possible in order to allow only closed cut elimination steps to take place.
We recall the graph and the label from our first example (4.5) for a more concrete situation: Computation starts by traversing the edges kDhDe!d. Up to this point, we follow exactly what the label φ dictates. Since we arrive at a box that contains a ?-node we have to initialise a search starting from that ?-node to find the !-node with which it forms a virtual commutative cut. The path that we traverse is ?!eDg which leads us to the matching !-node. Now we rewire the edge a of the ?-node with the root of the matching !-node and resume the normal flow of the computation. This was at edge d. The path that we traverse from now and on is exactly what the label φ dictates but now we jump all virtual commutative cuts that are highlighted in the label.

Conclusion
In this work we presented a calculus whose labels provide sufficient structure in order to experiment with new strategies for the Geometry Of Interaction machine. The calculus unveils a fine grained level of redundancy in the labels and also provides us with a tool that will help to prove properties of a closed GOI machine.
It is important to note that our calculus can only capture exponential informa- tion for the call-by-value translation. If we try to use the call-by-name translation of Linear Logic instead, then our calculus would run into problems. This is because the call-by-name translation places the exponential box structure in argument positions. As pointed out earlier, the multiplicative information in the labels is not affected by this change but the exponential markers will have to reflect the new situation. An extension of the labels to the call-by-name translation and the comparison of the structures obtained from both approaches is left for future work.

Acknowledgements
We thank Ian Mackie for his contributions throughout this work and our anonymous referees for their helpful comments.

References
A. Asperti, V. Danos, C. Laneve, and L. Regnier. Paths in the lambda-calculus. In Logic in Computer Science, pages 426 – 436, 1994.
A. Asperti and S. Guerrini. The optimal implementation of functional programming languages. Cambridge University Press, New York, NY, USA, 1998.
A. Asperti and C. Laneve. Interaction systems i: The theory of optimal reductions. Mathematical Structures in Computer Science, 4(4):457–504, 1994.
A. Asperti and C. Laneve. Paths, computations and labels in the lambda-calculus. In RTA-93: Selected papers of the fifth international conference on Rewriting techniques and applications, pages 277–297, Amsterdam, The Netherlands, The Netherlands, 1995. Elsevier Science Publishers B. V.


T. Blanc, J.-J. L´evy, and L. Maranget. Sharing in the weak lambda-calculus. In A. Middeldorp, V. van Oostrom, F. van Raamsdonk, and R. C. de Vrijer, editors, Processes, Terms and Cycles, volume 3838 of Lecture Notes in Computer Science, pages 70–87. Springer, 2005.
V. Danos and L. Regnier. Reversible, irreversible and optimal lambda-machines. Theoretical Computer Science, 227:79 – 97, 1999.
M. Fern´andez and I. Mackie. Call-by-value lambda-graph rewriting without rewriting. In ICGT ’02: Proceedings of the First International Conference on Graph Transformation, pages 75–89, London, UK, 2002. Springer-Verlag.
M. Fern´andez, I. Mackie, and F.-R. Sinot. Closed reduction: explicit substitutions without α-conversion.
Mathematical. Structures in Comp. Sci., 15(2):343–381, 2005.
J.-Y. Girard. Linear logic. Theoretical Computer Science, 50:1–102, 1987.
J.-Y. Girard. Geometry of interaction 1: Interpretation of System F. In R. Ferro, C. Bonotto,
S. Valentini, and A. Zanardo, editors, Logic Colloquium 88, volume 127 of Studies in Logic and the Foundations of Mathematics, pages 221–260. North Holland Publishing Company, Amsterdam, 1989.
J.-J. Levy. Reductions correctes et optimales dans le lambda-calcul. these de doctorat d’etat, universite paris vii. 1978.
I. Mackie. The geometry of interaction machine. In POPL ’95: Proceedings of the 22nd ACM SIGPLAN-SIGACT symposium on Principles of programming languages, pages 198–208, New York, NY, USA, 1995. ACM Press.
I. Mackie. Interaction nets for linear logic. Theor. Comput. Sci., 247(1-2):83–140, 2000.
