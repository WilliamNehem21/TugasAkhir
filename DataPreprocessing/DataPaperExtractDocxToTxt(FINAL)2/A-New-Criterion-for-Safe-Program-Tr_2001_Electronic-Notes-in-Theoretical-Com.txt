Electronic Notes in Theoretical Computer Science 41 No. 3 (2000)
URL: http://www.elsevier.nl/locate/entcs/volume41.html pages 20–34


A New Criterion for Safe Program Transformations

Yasuhiko Minamide
Institute of Information Sciences and Electronics University of Tsukuba
and PRESTO
Japan Science & Technology Corporation Email: minamide@score.is.tsukuba.ac.jp

Abstract
Previous studies on safety of program transformations with respect to performance considered two criteria: preserving performance within a constant factor and pre- serving complexity. However, as the requirement of program transformations used in compilers the former seems too restrictive and the latter seems too loose. We propose a new safety criterion: a program transformation preserves performance within a factor proportional to the size of a source program. This criterion seems natural since several compilation methods have effects on performance proportional to the size of a program. Based on this criterion we have shown that two semantics formalizing the size of stack space are equivalent. We also discuss the connection between this criterion and the properties of local program transformations rewriting parts of a program.

Introduction
Recent compilers utilize advanced program transformations to obtain high- performance executable code. For these advanced program transformations, it is not so straightforward to guarantee that they are safe with respect to performance. In fact, some program transformations have been shown to improve the performance of most programs, while degrading the performance of some programs severely [9,12].
To remedy this situation, several papers have discussed the safety of pro- gram transformations based on semantics formalizing the performance of pro- grams [7,6,11,2,8]. In those studies, two safety criteria for whole-program transformations were discussed. However, these criteria do not seem appro- priate to impose on program transformations used in compilers, for reasons we
◯c 2000 Published by Elsevier Science B. V. Open access under CC BY-NC-ND license.


discuss below. In this paper we focus on the space requirement of programs in call-by-value functional languages, but the general framework can be adopted for other languages and performance metrics.
The first of the above two criteria ensures that a program transformation preserves space requirement within a constant factor. If a program trans- formation satisfies this property, we say that the program transformation is space efficient. Many program transformations seem to satisfy this criterion, but there are some useful transformations that do not satisfy this criterion. Furthermore, to show this criterion is satisfied we must formalize the de- tails of semantics formalizing space requirements. In the study of the CPS transformation, it was necessary to revise the space profiling semantics of a call-by-value functional language by Blelloch and Greiner [3], to show that this transformation satisfies this criterion [8].
The second criterion is space safety: a program transformation is space safe if it does not raise the complexity of programs. Clearly, program trans- formations used in a compiler must satisfy this criterion. However, we think that this criterion is too loose. This criterion does not impose any restric- tion for programs without inputs. However, showing space safety is simpler than showing space efficiency, in the sense that it is possible to adopt a sim- pler profiling semantics that ignores details such as sizes of closures and stack frames.
In this paper we propose a new criterion that falls between the above two criteria. The new criterion is that a program transformation preserves the space requirement within a factor proportional to the size of a source program. Most useful transformations used in a compiler seem to satisfy this criterion. This criterion seems natural because several compilation methods have effects on performance proportional to the size of a program. Furthermore, we can show this criterion based on semantics ignoring some details as we show space safety.
Based on the new criterion we have shown that two semantics of a simple call-by-value functional language profiling stack space are equivalent. One models evaluation by an interpreter and the other models execution based on compilation. They are not equivalent in the sense of space efficiency, but they are equivalent in the sense of our new criterion. We also show that A- normalization preserves stack space modeled by the second semantics. This backs the claim that the second semantics models stack space required for execution based on compilation.
The criterion we propose is a property of a whole-program transformation. On the other hand, some transformations used in compilers are based on local program transformations. We therefore also study the connection between the properties of local transformations and the properties of global transfor- mations. We will show that some restricted class of local transformations induces whole-program transformations satisfying our new criterion.

This paper is organized as follows. We begin by reviewing the two safety criteria discussed in previous studies and discussing why they are not suit- able as the criterion we impose on the transformations used in a compiler. In Section 3 we introduce our new safety criterion and the equivalence of se- mantics on a programming language induced by the criterion. In Section 4, based on this new safety criterion, we show that two operational semantics of a call-by-value functional language are equivalent. In Section 5 we discuss the connection between the properties of local transformations and our new criterion. Finally, we give our conclusions and directions for future work.
Safety criteria of program transformations
We review the safety criteria of program transformations with respect to per- formance discussed in previous studies. To formalize safety criteria we must first develop semantics to formalize performance of programs. We call such semantics profiling semantics. For a simple programming language, profiling semantics can be given as a partial function eval(M ):
eval(M )= (v, n)
This function gives the computation result v and a non-negative integer n, which represents such performance values of programs as execution time or space required for execution.
In this paper, to simplify our discussion, we focus on the space requirement of a program and ignore the computation result. For this purpose we define space(M ) as below:
space(M )= n iff eval(M )= (v, n) for some v
This function is only defined if the evaluation of M terminates. We call this semantics for specifying space required for execution of a program space semantics.
Let us now review two space safety criteria of program transformations discussed in previous work [1,3,8]. In this paper, we consider a program trans- formation as a binary relation between programs in a source language and a target language. Let us consider a program transformation ❀ between a source language and a target language that have space semantics space(M ) and space'(M') respectively: M ❀ M' means that M is translated to M' by the program transformation.
The first criterion ensures that a program transformation preserves the space required for execution of a program within a constant factor.
Definition 2.1 We say that a program transformation ❀ is space efficient if constants k1 and k2 exist such that:
space(M )= n  =⇒  space'(M') ≤ k1n + k2

for any programs M and M' with M ❀ M'.
We admit constants k1 and k2 because they seem dependent on the details of definition of space semantics and not essential. Moreover, there are several transformations in which k1 > 1 is required to show this property. This property was first discussed by Blelloch and Greiner for an implementation of NESL [3]. Minamide also showed that the CPS transformation is space efficient [8].
The second criterion is called space safety: a transformation is space safe if it does not increase the space complexity of programs [1]. To formalize this idea we must consider programs with an input; thus we can consider a programming language with input commands and the semantics space(M, I), which formalizes the space required for execution of the program M for the input I.
Definition 2.2 We say that a program transformation ❀ is space safe if for any programs M and M' such that M ❀ M', constants k1 and k2 exist such that for any input I the following holds:
space(M, I)= n  =⇒  space'(M', I) ≤ k1n + k2
The key difference from space efficiency is that the constants k1 and k2 are program-dependent. Space efficiency usually implies space safety because space efficiency provides the constants k1 and k2 to show space safety without depending on programs.
Although many program transformations used in compilers seem space efficient, some useful transformations are not space efficient, but only space safe. Furthermore, to show that a program transformation is space efficient we must consider too many details of the operational semantics of the source language. In the study of the CPS transformation it was necessary to revise the semantics proposed by Blelloch and Greiner [3] to show that the CPS transformation was space efficient [8].
Code motion is a typical example of a transformation that is space safe, but not space efficient. Consider the following expression where M is a pure expression that contains the variable n but does not contain a function appli- cation:
fun loop 0 = ()
| loop n = let val x = M in loop (n - 1) end
The value of M is loop-invariant, thus we want to hoist the binding of x as follows:
val x = M
fun loop 0 = ()
| loop n = loop (n - 1)
This usually improves the performance of the program. However, if the func-

tion loop is used only as loop 0 or is not actually used, this transformation results in extra computation of M. The extra time and space to evaluate M is not uniformly bounded by a constant, but depends on M.
On the other hand, space safety seems too weak as a requirement of trans- formations used in compilers. Space safety is trivial for programs without inputs. Even for programs with inputs, it is impossible to estimate the per- formance of a program since the constants k1 and k2 are program-dependent. Thus in this paper we propose a new criterion that falls between space effi- ciency and space safety.
A new criterion
In this section, we propose a new safety criterion for program transforma- tions. First, to simplify our discussion, we compare two space semantics of a programming language.
Let us consider two space semantics space1(M ) and space2(M ) of a pro- gramming language. As a natural extension of space efficiency, we can consider the following property: there exists a polynomial f such that
space1(M )= n =⇒ space2(M ) ≤ f (n)
However, this property is not suitable as a criterion that space2(M ) is safe with respect to space1(M ). By extending the language and the semantics with inputs, we have the following property:
space1(M, I)= n =⇒ space2(M, I) ≤ f (n)
Even if this holds, it might happen that for an input of size n space1 requires n space, but space2 requires n2 space, because f (x)= x2. Thus, this extended property does not imply safety and is therefore not suitable as a criterion that space2 is safe with respect to space1.
When we consider various semantics of a language, the difference in space
usage often depends on the size of a program. Thus, it is natural to consider the following relation of semantics.
Definition 3.1 We say that the semantics space1 is weakly simulated by
space2 if
space1(M )= n  =⇒  space2(M ) ≤ f1(|M|)n + f2(|M|)
where f1(x) and f2(x) are polynomials with positive coefficients and |M| is the size of M .
Hereafter in this paper we simply say “a polynomial” for “a polynomial with positive coefficients.”
This relation induces equivalence of semantics as follows.

Definition 3.2 We say that semantics space1 is weakly space equivalent to space2 if space1 is weakly simulated by space2 and space2 is weakly simulated by space1.
Most reasonably defined semantics of a language seem weakly space equiv- alent. Moreover, it is possible to define simpler semantics weakly space equiv- alent to the semantics considered in previous studies.
Example 3.3 Let space1 be a semantics of a functional language that ac- counts for the sizes of closures: the size of a closure with n free variables is n + 1. Let space2 be a semantics where the sizes of closures are ignored: the sizes of closures are always 1. Then space1 and space2 are weakly equivalent, since the sizes of the closures constructed during evaluation of a program are bounded by the size of the program.
Example 3.4 Let space1 and space2 be a semantics that accounts for the size of each stack frame and a semantics that ignores the size of each stack frame, respectively. Then space1 and space2 are weakly equivalent, since the sizes of the stack frames constructed during evaluation of a program are bounded by the size of the program.
Although these examples are rather straightforward, they show that we can adopt a simple space semantics when we consider weak simulation. We will also show that two space semantics profiling stack space are equivalent in Section 4. The proof of this equivalence requires detailed analysis of the space semantics.
Now we extend weak simulation as a safety criterion for program transfor- mations. Consider a program transformation ❀ between a source language and a target language that have space semantics space(M ) and space'(M'), respectively, as before.
Definition 3.5 We say that a program transformation ❀ is weakly space efficient if polynomials f1(x) and f2(x) exist such that:
space(M )= n =⇒ space'(M') ≤ f1(|M|)n + f2(|M|) for any programs M and M' with M ❀ M'.
This criterion clearly falls between space efficiency and space safety. It
admits that a program transformation degrades performance within a factor dependent on the size of a program. This gives us much more freedom to design program transformations used in compilers than is possible with space efficiency.
To construct a compiler that is a weakly efficient transformation as a whole, the composition of transformations must be weakly space efficient since actual compilers consist of many phases. To make the composition weakly space efficient we should restrict program transformations so that the expansion of the size of a program is limited by some polynomial.

Definition 3.6 We say that a program transformation M ❀ M' is polyno- mial size safe if |M'|≤ f (|M|) for all programs M where f (x) is a polynomial of x.
This is a natural restriction because actual compilers already avoid expo- nential blowup of code size. We can now construct a weakly space efficient compiler by composing weakly space efficient and polynomial size safe trans- formations.
Theorem 3.7 Let ❀1 and ❀2 be program transformations from L1 to L2 and from L2 to L3 respectively. If ❀1 is weakly space eﬃcient and polynomial size safe, and ❀2 is weakly space eﬃcient, then their composition ❀1 ◦ ❀2 is a weakly space eﬃcient transformation from L1 to L3.
Proof. Let M ❀1 ◦ ❀2 N . Then P exists such that M ❀1 P and P ❀2 N . By weak space efficiency we have:
space2(P ) ≤ f 1(|M|)space1(M )+ f 1(|M|)
1	2
space3(N ) ≤ f 2(|P |)space2(P )+ f 2(|P |)
1	2
By polynomial size safety we have |P|≤ g(|M|). Then:
space3(N ) ≤ f 2(g(|M|))(f 1(|M|)space1(M )+ f 1(|M|)) + f 2(g(|M|))
1	1	2	2
Here, f 2(g(x))f 1(x) and f 2(g(x))f 1(x)+ f 2(g(x)) are clearly polynomials of
1	1	1	2	2
x.	✷
This proof clarifies why we adopted a polynomial instead of a linear func- tion in the definition of weakly efficient transformation. Even if two trans- formations are bounded by linear functions of the size of a program, their composition is not necessarily bounded by some linear function.
Weak equivalence on stack space
In this section we consider two space semantics profiling stack space for a simple call-by-value functional language. One semantics models evaluation by an interpreter and the other models evaluation based on compilation. Both semantics properly model tail calls. We show that although they allocate different numbers of stack frames during evaluation, the semantics are weakly space equivalent. Furthermore, it is shown that A-normalization preserves stack space for the second semantics.
Equivalence of two semantics proﬁling stack space
We consider the following untyped call-by-value λ-calculus with a constant c: M ::= x | c | λx.M | M1M2



E ▶ c ↓1 c	E ▶ x ↓1 E(x)	E ▶ λx.M ↓1 ⟨cl E, x, M⟩
E ▶ M1 ↓l ⟨cl E', x,M⟩	E ▶ M2 ↓m v2	E'[v2/x] ▶ M ↓n v E ▶ M1M2 ↓max(l+1,m+1,n) v
Fig. 1. Operational semantics profiling stack size (interpreter-based)


E ▶2 c ↓0 c	E ▶2 x ↓0 E(x)	E ▶2 λx.M ↓0 ⟨cl E, x, M⟩
E ▶n M1 ↓l ⟨cl E', x,M⟩	E ▶n M2 ↓m v2	E'[v2/x] ▶t M ↓n v
2	2	2
E ▶n M1M2 ↓max(l,m,n+1) v
E ▶n M1 ↓l ⟨cl E', x,M⟩	E ▶n M2 ↓m v2	E'[v2/x] ▶t M ↓n v
2	2	2
E ▶t M1M2 ↓max(l,m,n) v
Fig. 2. Operational semantics profiling stack size (compiler-based)

We define two space semantics spaceλ(M ) and spaceλ(M ) by deductive sys-
1	2
tems. For the definition of the deductive systems, we first define values: a
value v is either a constant c or a closure ⟨cl E, x, M⟩ consisting of an envi- ronment E mapping variables to values, a variable and an expression.
v ::= c | ⟨cl E, x, M⟩

The space semantics spaceλ(M ) models evaluation by an interpreter and is defined by the deductive system given in Figure 1.
spaceλ(M )= n iff ∅▶ M ↓n v

The space semantics spaceλ(M ) models stack space required for execution based on compilation and is defined by the deductive system given in Figure 2.
spaceλ(M )= n iff ∅ ▶t M ↓n v
2	2
The deductive system is defined mutually inductively by the following two
judgments: E ▶t M ↓n v models execution at tail call positions and E ▶n
M ↓n v models execution at non-tail call positions. The application at a tail call position does not allocate a new stack frame. In the figure, we write
E ▶2 M ↓n v for E ▶t M ↓n v and E ▶n M ↓n v.
2	2
We have shown that the two semantics spaceλ(M ) and spaceλ(M ) are
1	2
weakly equivalent.

Theorem 4.1 If ∅▶ M ↓i v and ∅ ▶t M ↓i' v, then i' +1 ≤ i ≤ |M |· (i' + 1).
To prove this theorem we must generalize the claim so that non-empty environments can be treated. To treat non-empty environments we define the size of a value and an environment as follows:
|c|v = 0
|⟨cl E, λx.M ⟩|v  = max(|E|v, |M|v)
|E|v = e max{|E(x)|v | x ∈ Dom(E)}
Then the theorem is generalized to the following lemma. This lemma is proved by induction on the derivation of evaluation.
Lemma 4.2 Let K be a constant such that |M|≤ K and |E|v ≤ K.
If E ▶ M ↓i v and E ▶t M ↓i' v, then i' +1 ≤ i ≤ K · (i' + 1).
If E ▶ M ↓i v and E ▶n M ↓i' v, then i' ≤ i ≤ K · i' + |M|.
Preservation of stack space by A-normalization
In this section we show that A-normalization preserves stack space given by
spaceλ(M ) and thus spaceλ(M ) actually models execution based on compi-
2	2
lation. This also shows that A-normalization is weakly space efficient with
respect to spaceλ(M ).
We define the syntax of the language of A-normal forms as follows:
Values	V ::= x | λx.M
Expressions M ::= V  | V1V2 | let x = V1V2 in M
The application V1V2 represents tail calls and the application in let x =
V1V2 in M represents non-tail calls.
The semantics of this language is naturally given by the CaEK Machine defined in Figure 3 [5]. In this operational semantics continuation clearly corresponds to stack. The size of continuation is naturally defined as follows:
size(stop) = 0 
size(⟨ar x, M, E, K⟩) = size(K)+1 
In this definition we ignore the size of each frame because it is bounded by the size of the program and we discuss weak space efficiency in this paper. To discuss space efficiency it is natural to count the number of free variables of M .
The stack space of state ⟨M, E, K⟩ is defined by size(K). Then we define the space semantics of this language as follows: spaceA(M )= n if ⟨M, ∅, stop⟩ '→∗
⟨V, E'', stop⟩ and n is the maximum size of the states in the transition.







Transition Rules:
State S = ⟨M, E, K⟩
Continuation K = stop | ⟨ar x, M, E, K⟩

⟨v, E, ⟨ar x, M, E', K'⟩⟩ '→ ⟨M, E'[γ(v, E)/x], K'⟩
⟨let x = V1V2 in M, E, K⟩ '→ ⟨M ', E'[V2/x], ⟨ar x, M, E, K'⟩⟩
where γ(V1, E)= ⟨cl x, M', E'⟩
⟨V1V2, E, K⟩ '→ ⟨M ', E'[V2/x], K⟩
where γ(V1, E)= ⟨cl x, M', E'⟩
γ(V, E)=  E(x)	if V ≡ x
 ⟨cl x, M, E⟩ if V ≡ λx.M
Fig. 3. The CaEK Abstract Machine

A-normalization can be defined as one pass translation [5,4]. In the follow- ing definition, we use a two-level lambda calculus where λ and @ are meta-level abstraction and application. ||M||Aκ translates expressions at non-tail call

positions and ||M||'
translates expressions at tail call positions. The entire

program is translated by ||M||' .
|x|A = x
|λx.M |A = λx.||M ||'

||V ||Aκ = k@|V |A
||M1M2||Aκ = ||M1||A(λx1.||M2||A(λx2.let z = x1x2 in κ@z))

||v||'
||M1M2||'
= |v|A
= ||M1||A(λx1.||M2||A(λx2.x1x2))

Then it is shown that the stack space required for execution is preserved by A-normalization.
Theorem 4.3 If spaceλ(M )= n, then spaceA(||M||' )= n.
2	A
This theorem shows that spaceλ(M ) models the stack space required for execution based on compilation. Furthermore, since spaceλ(M ) is weakly equivalent to spaceλ(M ), it is enough to consider spaceλ(M ) even when we
1	1

consider weak efficiency of program transformations with respect to execution based on compilation.
Local transformations
In this section we discuss the connection between our new criterion and the properties of local program transformations. We show that some class of local transformations induces weakly space efficient transformations.
Based on the classification of local transformations by Gustavsson and Sands [7] we define two classes of local transformations.
Definition 5.1 Let R be a relation on terms of a programming language.
We say that R is a strong improvement relation if we have:
space(C[M ]) = n  =⇒  space(C[N ]) ≤ n
for all (M, N ) ∈ R and all context C[·] producing a whole program for
M and N .
We say that R is a weak improvement relation if there exists some linear function f such that the following holds for all (M, N ) ∈ R and all context C[·] producing a whole program for M and N .
space(C[M ]) = n =⇒ space(C[N ]) ≤ f (n)
We should remark that there is one subtle difference in our definition of weak improvement from that of Gustavsson and Sands. They defined a single weak improvement relation as follows. M ✄ N if some linear function f exists
≈
such that for all contexts C[·] the following holds:
space(C[M ]) = n =⇒ space(C[N ]) ≤ f (n)
The relation ✄ is the union of all the weak improvement relations. However,
≈
this relation ✄ itself is not a weak improvement relation in our sense.
≈
To discuss the connection between these properties and the properties of global transformations, we first define the induced global transformation M ❀R N as follows: M ❀R N if some C[·], M' and N' exist such that M = C[M'], N = C[N'], and (M',N') ∈ R. Then we immediately obtain the following theorem.
Theorem 5.2 If R is a weak or strong improvement relation, ❀R is space eﬃcient.
On the other hand, the relation ✄ does not induce a space efficient trans-
≈
formation.	This is because there is no single linear function f such that
space(C[N ]) ≤ f (space(C[M ])) for all M ✄ N .
≈


The theorem above is still not enough to use a local transformation in a compiler. In a compiler we usually apply local transformations n times in one phase of a compiler where n is proportional to the size of a program. Even for such composition, a strong improvement relation induces a space efficient transformation.

Theorem 5.3 If R is a strong improvement relation, ❀∗
is space eﬃcient.

On the other hand, a weak improvement relation does not necessarily in- duce a weakly space efficient transformation. Consider the following sequence of transformations where R is a weak improvement relation with space(C[N ]) ≤ kspace(C[M ]) for all (M, N ) ∈ R.
M0 ❀R M1 ❀R M2 ❀R M3 ❀R ... ❀R Mn
The space requirement of Mn can be calculated as follows:
space(M2) ≤ kspace(M1)
space(M3) ≤ kspace(M2) ≤ k2space(M1)
space(Mn) ≤ knspace(M1)
Then it is clear that there is no single linear function f such that:



for M ❀∗
space(N ) ≤ f (space(M ))
N . Even if we restrict the number of repetitions to |M0|, kn is not

a polynomial of |M0|. Thus, it is not even weakly space efficient.
We therefore must consider stricter conditions on local transformations. In the following definition a local transformation is permitted to add only a constant amount of extra space.
Definition 5.4 We say that R is a semi-strong improvement relation if some constant k exists such that:
space(C[M ]) = n  =⇒  space(C[N ]) ≤ n + k
for all (M, N ) ∈ R and all context C[·] producing a whole program for M and
N .
It can be shown that this class of local transformations induces weakly space efficient transformations if the number of applications of the transfor- mation is limited by the size of a source program. We write M '→R N if
M ❀n N where n ≤ |M |.
Theorem 5.5 If R is a semi-strong improvement relation, M '→R N is weakly eﬃcient.

Although this theorem relates a semi-strong improvement relation to weakly efficient transformations, semi-strong improvement relations seem too restric- tive. There are many useful transformations R that are not semi-strong im- provement relations, but '→R seem weakly space efficient. The following trans- formation is an example.
λx.let y = M in N ⇒ let y = M in λx.N
We have not shown formally that this transformation is weakly space efficient. For such proof we think that we require further study on the connections between global transformations and local transformations.
Discussion and future work
We have shown weak efficiency only for stack space for two semantics of a simple functional language. It will not be very difficult to deal with execution time or heap space. For example, the proof that the CPS transformation is space efficient [8] can easily be modified to show that the CPS transformation is weakly space efficient with respect to a simpler space semantics of the source language that ignores the sizes of closures and stack frames.
We have shown no examples of local program transformations that are weak improvement relations or semi-strong improvement relations. We are planning to show that various optimizations formalized as local program trans- formations have these kinds of properties. In this area, Gustavsson and Sands have developed a theory of space improvement relations for call-by-need pro- gramming languages and have shown that several local transformations are weak improvements [7]. Their work will be also applicable to call-by-value languages.
We think that the framework we have developed in this paper requires further refinement. For example, although intuitively clear, it is not proved that space safety, weak space efficiency and space efficiency ensure that the space complexity of programs is preserved. Bakewell and Runciman discussed these kinds of issues more formally in their study on the comparison of space usage of lazy evaluators [2]. They modeled lazy evaluators by graph rewriting systems. This kind of uniform formalization of semantics may help develop a theory of safe program transformations.
There is an implementation strategy of ML that is not space efficient, but is space safe. That is the implementation strategy that uses types as param- eters at runtime [10,13]. This is because the extra work and space necessary for type parameters cannot be bounded by any constant. Furthermore, this implementation strategy is not even weakly space efficient, because the types appearing in the typing derivation of a program may have a size exponen- tial to the size of the program. However, if we take the sum of the size of a program and the maximum size of types appearing in typing derivation of the program as the size of the program, this implementation strategy can be

considered weakly space efficient. By choosing the definition of the size of a program in this way we can control the class of transformations that can be used in compilers of the language.
Acknowledgement
This work is partially supported by the Ministry of Education, Science, Sports and Culture, Grant-in-Aid for Encouragement of Young Scientists of Japan No. 11780216, 1999. We would like to thank anonymous reviewers for their many helpful comments and suggestions.

References
Appel, A. W., “Compiling with Continuation,” Cambridge University Press, 1992.
Bakewell, A. and C. Runciman, A model for comparing the space usage of lazy evaluators, in: 2nd International Conference on Principles and Practice of Declarative Programming (PPDP 2000), 2000.
Blelloch, G. E. and J. Greiner, A provably time and space efficient implementation of NESL, in: Proc. of ACM SIGPLAN International Conference on Functional Programming, 1996, pp. 213–225.
Danvy, O. and A. Filinski, Representing control: a study of the CPS transformation, Mathematical Structures in Computer Science 2 (1992), pp. 361 – 391.
Flanagan, C., A. Sabry, B. F. Duba and M. Felleisen, The essence of compiling with continuations, in: Proc. of ACM SIGPLAN Conference on Programming Language Design and Implementation, 1993, pp. 237–247.
Greiner, J. and G. E. Blelloch, A provably time-efficient parallel implementation of full speculation, in: Proc. of ACM Symposium on Principles of Programming Languages, 1996, pp. 309 – 321.
Gustavsson, J. and D. Sands, A foundation for space-safe transformations of call-by-need programs, in: Proc. of the Third International Workshop on Higher Order Operational Techniques in Semantics (HOOTS99), ENTCS 26, 1999.
Minamide, Y., A space-proﬁling semantics of call-by-value lambda calculus and the CPS transformation, in: Proc. of the Third International Workshop on Higher Order Operational Techniques in Semantics (HOOTS99), ENTCS 26, 1999.
Minamide, Y. and J. Garrigue, On the runtime complexity of type-directed unboxing, in: Proc. of ACM SIGPLAN International Conference on Functional Programming, 1998, pp. 1–12.


Ohori, A. and N. Yoshida, Type inference with rank 1 polymorphism for type-directed compilation of ML, in: Proc. of ACM SIGPLAN International Conference on Functional Programming, 1999, pp. 160– 171.
Santos, A. L., “Compilation by Transformation in Non-strict Functional Languages,” Ph.D. thesis, Department of Computing Science, University of Glasgow (1995).
Shao, Z., Flexible representation analysis, in: Proc. of ACM SIGPLAN International Conference on Functional Programming, 1997, pp. 85 – 98.
Tarditi, D., G. Morrisett, P. Cheng, C. Stone, R. Harper and P. Lee, TIL: A type-directed optimizing compiler for ML, in: Proc. of ACM SIGPLAN Conference on Programming Language Design and Implementation, 1996, pp. 181–192.
