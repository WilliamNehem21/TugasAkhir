

Electronic Notes in Theoretical Computer Science 247 (2009) 139–155
www.elsevier.com/locate/entcs
Formal SOS-Proofs for the Lambda-Calculus
Christian Urban1
TU Munich, Germany
Julien Narboux2
University of Strasbourg, France

Abstract
We describe in this paper formalisations for the properties of weakening, type-substitutivity, subject- reduction and termination of the usual big-step evaluation relation. Our language is the lambda-calculus whose simplicity allows us to show actual theorem-prover code of the formal proofs. The formalisations are done in Nominal Isabelle, a definitional extention of the theorem prover Isabelle/HOL. The point of these formalisations is to be as close as possible to the “pencil-and-paper” proofs for these properties, but of course be completely rigorous. We describe where Nominal Isabelle is of great help with such formalisations and where one has to invest additional effort in order to obtain formal proofs.
Keywords: Structural operational semantics, proof assistants, lambda-calculus, Nominal Isabelle.



Introduction
Structural operational semantics (SOS) introduced in 1981 by Plotkin [14] has been very successful in describing what programs are supposed to do. These descriptions can often be used directly in proofs establishing properties about programming languages via induction over the structure of terms or inductions over rules of in- ductively defined predicates. However, if one wants to formalise such proofs in a theorem prover, then dealing with binders, renaming of bound variables, capture- avoiding substitution, etc., is very often a major problem. Nominal Isabelle [15] is designed to make such proofs easy to formalise: It provides an infrastructure for declaring nominal datatypes (that is α-equivalence classes) and for defining func-

1 Email: urbanc@in.tum.de
2 Email: Julien.Narboux@dpt-info.u-strasbg.fr

1571-0661 © 2009 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2009.07.053

tions over them by structural recursion. It also provides induction principles that have Barendregt’s variable convention already built in.
The na¨ıve method of representing binders using abstract syntax-trees is too concrete: it does not take into account α-equivalence where expressions are regarded as equal, if they only differ in the naming of bound variables. As a result one has to deal explicitly with naming issues and has to prove properties modulo α-equivalence. This leads to formal proofs where one has to deal with many details, even if one proves only very simple properties (for an illustrative example see the proof given in [6, Pages 94–104]). Of course one can reconcile abstract syntax-trees and binders by using de-Bruijn indices. This alleviates the problems about too many details and in some cases leads to very slick proofs. Unfortunately, by using de-Bruijn indices, proofs involve a rather large amount of arithmetic on indices, which is not present in informal descriptions [3]. Another method of representing binders is by using higher-order abstract-syntax (HOAS) where the meta-language provides binding- constructs. The disadvantage we see with HOAS is that one has to encode binders of the object language with variable binders of the meta-language. In practice this means that one does not have direct access anymore to bound variables. This can be a problem if one wants to formalise the classic typing algorithm W presented by Damas and Milner [7]. Recently Aydemir et al have reported that a locally nameless representation for terms with binders has been very useful for formalising informal SOS-proofs in Coq [1]. The disadvantage we see with this approach, however, is that one often has to reformulate definitions in order to get through proofs involving bound variables. Also the problem of performing arithmetic over indices, like with “pure” de-Bruijn indices, cannot be completely avoided in the locally nameless representation.
Here we describe Nominal Isabelle, which provides an infrastructure in the the- orem prover Isabelle/HOL [11] for representing binders as named α-equivalence classes. The paper does not present any new results, rather we describe Nomi- nal Isabelle with some typical proofs from SOS. Our object language will be the lambda-calculus, whose simplicity will allow us to give actual Isar-code [19] for those proofs. Nominal Isabelle adapts ideas from the nominal logic work by Pitts [12]. For example it defines the notion of freshness, written x # e, of a variable x with respect to an expression e.
The paper is organized as follows: Terms and substitutions are defined in Sec. 2, together with a description of strong structural induction principles that have the usual variable convention already built in. Sec. 3 defines types and the typing- judgement for terms Sec. 4 introduces the big-step evaluation relation for terms and in Sec. 5 we show how the proof of the termination property for the evaluation relation proceeds.

Terms and Substitutions
We consider here α-equated lambda-terms. For building up these terms we assume the existence of a type name for variables. The only property we need to know

about name is that it consists of infinitely many variables. The terms are then defined by the grammar
Definition 2.1 (Terms)  trm ::= Var name — App trm trm — Lam name.trm
where in the Lam-clause, as usual, a variable is bound. Because Nominal Isabelle allows us to write terms as Lam x.e, one might assume that this definition represents “raw”, or un-quotient, syntax-trees. However, this is not the case: in Nominal Isabelle this definition really represents α-equivalence classes. This can be seen by the fact that the following two terms are equal :
Lam x.(Lam y.(App (Var x) (Var y))) = Lam y.(Lam x.(App (Var y) (Var x))) which would not be the case if our terms were syntax-trees.
The most important operation we need for terms is substitution. In the proofs
we present later on it will be necessary to introduce the slightly more complicated notion of simultaneous substitution, which we represent as finite lists of (name,trm)- pairs. One reason for this choice is that it is easier to deal with finite structures in Nominal Isabelle than with infinite ones (a potentially infinite representation of substitutions is, for example, partial maps from name to trm). The second reason is that it is usually easier to define functions by recursion over lists, than by recursing over sets [10]. Using our list representation we define:
Definition 2.2 (Simultaneous Substitution)
θ(Var x)	= lookup θ x
θ(App e1 e2) = App θ(e1) θ(e2)
θ(Lam x.e)	= Lam x.θ(e)	provided x # θ
where in the first clause we use the auxiliary function lookup defined by the clauses: lookup [] x	= Var x
lookup ((y, e)::θ) x = if x = y then e else lookup θ x
Single substitutions are a derived concept by defining e[x:=e’] d=ef [(x, e’)](e) where [(x, e’)] is a singleton list.
Despite the side-condition attached to the Lam-clause, the definition above yields a total function, since we work with α-equivalence classes where renamings are always possible. Clearly, if defined over syntax-trees, this definition would be a partial function. While the totality of the substitution operation is rather convenient in a formal proofs, it also means that we must be careful when defining functions over the structure of α-equated terms. This is because we can specify functions over the structure of such terms that lead to inconsistencies. One example is the function that returns the immediate subterms of an α-equated lambda-term, specified by
ist (Var x)   = ∅
ist (App e1 e2) = –e1, e2˝ ist (Lam x.e)  = –e˝
If this function could be defined for α-equivalence classes, then we can prove false. This is because we expect that functions always return the same output for

the same input. The problem with the inconsistency can then be seen by considering the α-equivalent terms
Lam x.(Var x) = Lam y.(Var y)
and the two calculations
ist (Lam x.(Var x)) = –Var x˝    ist (Lam y.(Var y)) = –Var y˝
If we force both right-hand sides to be equal by assuming that ist is a function, then we have an inconsistency since –Var x˝ /= –Var y˝ in case /x = y.
In order to prevent such inconsistencies, the recursion combinator in Nominal Isabelle only allows to define functions that respect α-equivalence classes [16]. For this we are required in our formalisation to manually check that certain conditions about the clauses in Def. 2.2 are satisfied. To state these condition requires some slightly complicated machinery involving the notion of support of functions (see [13,16]). This notion corresponds roughly to the free variables of an object. In Nominal Isabelle the support is defined not just for functions, but also for pairs, tuples, lists, sets as well as terms. The definition of the latter requires that a permutation operation is defined for terms. This permutation operation, written π
· e, takes a term e and a permutation π, which is a finite list of (name, name)-pairs and permutes every variable in the term e. We write such permutations as (a1 b1)(a2 b2)··· (an bn); the empty list [] stands for the identity permutation. The permutation operation over terms is defined by
Definition 2.3 (Permutations Acting on Terms)
π · Var x	= Var (π · x)
π · Lam x.e	= Lam (π · x).(π · e)
π · App e1 e2 = App (π · e1) (π · e2)
using the auxiliary operation of a permutation acting on a variable [] · a = a

(a1 a2)::π · a =
a2	if π · a = a1
a1	if π · a = a2
⎩ π · a	otherwise

The support of an object x is then defined as the set of names satisfying supp x d=ef –a — infinite –b — [(a, b)] · x /= x˝˝
which in case of α-equated lambda-terms coincides with the usual notion of free
variables.
Using the permutation operation, Nominal Isabelle also defines the notion of α-equivalence for abstractions, which are written x.e. This definition distinguishes whether the binders of two abstractions are equal or not:

e1 = e2 x.e1 = x.e2
x /= y 
1 e= (x y)·e2	x # e2 x.e1 = y.e2

In the second rule x # e2 stands for x not being in the support of e2, which, as mentioned above, coincides with x being not a free variable in e2. Having the

notion of α-equivalence for abstractions in place, Nominal Isabelle defines under which conditions two lambda-terms are equal, namely

x = y Var x = Var y 
x.e1 = y.e2


Lam x.e1 = Lam y.e2
e1 = e1’	e2 = e2’ App e1 e2 = App e1’ e2’

Equipped with the rules about α-equivalence, we can start to prove properties about terms and substitutions. Later on, for example, we will need the property how a single and a simultaneous substitution interact. For this we prove the following lemma:
Lemma 2.4 If x # θ then θ(e)[x:=e’] = ((x, e’)::θ)(e).
whose proof is by induction on the structure of e. For such proofs Nominal Is- abelle derives two versions of the structural induction principle—a weak one and a strong one. The weak proves a property P e for all terms e provided one establishes for each term-constructor an implication that assumes the property for the argu- ments and concludes the property for the term-constructor. This pattern follows what Plotkin [14, Page 49] describes as structural induction for expressions. As an inference rule the weak induction principle looks as follows:
∀ x. P (Var x)
∀ x e. P e −→ P (Lam x.e)
∀ e1 e2. P e1 ∧ P e2 −→ P (App e1 e2)
P e 
Using this principle, the cases in Lem. 2.4 for Var and App are quite routine, but in the Lam-case one has to analyse a binder. We have the induction-hypothesis:
∀ x θ e’. x # θ −→ θ(e)[x:=e’] = ((x, e’)::θ)(e)
and have to show
θ(Lam y.e)[x:=e’] = ((x, e’)::θ)(Lam y.e)
for arbitrary y and e. However we only know that x # θ holds. In order to apply the definition of substitution and subsequently use the induction hypothesis we need to rename the binder y to a fresh variable z, say. This makes the proof quite clunky and too hard to be found by the automatic search tools available in Isabelle. In informal proofs establishing such properties by induction, one usually ignores the fact that one has to establish the property at hand for an arbitrary bound variable y; rather one employs the convention that binders are always assumed to be suitable fresh (see for example [2]). In the case above this means we have the convention that y is fresh for θ, x and e’, that is y # θ, y # x and y # e’ hold. With this convention also the case Lam is trivial.
To support this kind of informal reasoning where one does not consider truly arbitrary bound variables, but rather bound variables about which various fresh- ness assumptions are made, Nominal Isabelle derives automatically from the weak induction principle a strong induction principle (see [18]). This strong induction principle looks as inference rule as follows:

∀ c x. P c (Var x)
∀ c x e.  x#c  ∧ (∀ c. P c e) −→ P c (Lam x.e)
∀ c e1 e2. (∀ c. P c e1) ∧ (∀ c. P c e2) −→ P c (App e1 e2) P c e 
The purpose of the parameter c, called the induction context, is to accommodate the assumptions we make in informal reasoning about the freshness of the binder. In the Lam-case we can then assume that the binder for which the property needs to be established is fresh with respect to this context (see highlighted formula). With these assumptions in place the case for Lam is also completely routine: we just have to instantiate the induction context with the tuple (θ, x, e’). The only requirement we have to observe with this instantiations is that the context may only mention finitely many free variables. This holds in our case. We then have the same induction hypothesis as in the weak version
∀ x θ e’. x # θ −→ θ(e)[x:=e’] = ((x, e’)::θ)(e)
However additionally we have that y # θ, y # x and y # e’. These additional assumptions help us in the proof obligation in Lem. 2.4:
θ(Lam y.e)[x:=e’] = ((x, e’)::θ)(Lam y.e)
We can now move θ and the single substitution under the lambda-abstraction on the left-hand side (similarly with (x, e’)::θ on the right-hand side), and then apply the induction hypothesis. As a result all cases of Lem. 2.4 are routine and the formal proof is completely automatic, except for setting up the induction and for the need of mentioning two properties about lookup, namely:
If x # θ then lookup θ x = Var x 
If z # θ and z /= x then (lookuθp x)[z:=e] = lookup θ x
With these properties, named lookup˙fresh1 and lookup˙fresh2 below, the formal proof establishing of Lem. 2.4 is:
1  lemma psubst˙subst:
2  assumes a: ”x # θ”
3  shows ”θ(e)[x:=e’] = ((x,e’)::θ)(e)”
4  using a by (nominal˙induct e avoiding: θ x e’ rule: trm.strong˙induct)
5	(auto simp add: lookup˙fresh1 lookup˙fresh2)
In line 4, we set up the induction and instantiate the induction context by avoiding θ, x and e’. The argument is then just by calculation, which Isabelle can do automatically.
To sum up this section, Nominal Isabelle derives automatically strong versions of the induction principle for all term-calculi involving single binders, not just the one defined in Def. 2.1. This often makes reasoning by structural induction over α-equivalence classes rather pleasant, because no explicit α-conversions are needed. This is a theme which will reoccur frequently in the proofs we shall describe in the

next sections.

Typing
Many SOS-proofs involve typing-information for terms. In this section we define types and a typing relation for our terms. The definition of types, for which we use the letter T, consists of type variables and function types:
Definition 3.1 (Types)  ty ::= TVar x — ty→ty
Before we can define a typing-judgement, we need to state what typing contexts are. For them we use lists of (name,ty)-pairs since, as mentioned before, in Nominal Isabelle it is easier to work with finite structures than with infinite ones (if we use sets of (name,ty)-pairs instead, then it is inconvenient to exclude potentially infinitely large typing-contexts). The disadvantage of using lists is, of course, that we distinguish the order of how variables are associated to types. However, in terms of convenience this choice will only cause minor problem in the proofs we shall present.
A typing-context Γ is valid, provided it includes only a single association for every variable occurring in Γ . This can be defined inductively by the two rules
valid Γ    x # Γ
valid []	valid ((x, T)::Γ )
where x # Γ stands for x not occurring in Γ . Having the definition of validity at our disposal, the rules for the typing-judgements are relatively standard:
valid Γ	(x, T) ∈ Γ t-Var	Γ ▶ e1 : T1→T2	Γ ▶ e2 : T1 t-App
	
Γ ▶ Var x : T	Γ ▶ App e1 e2 : T2
x # Γ	(x, T1)::Γ ▶ e : T2 t-Lam
Γ ▶ Lam x.e : T1→T2
In rule t-Var we use the notation (x, T) ∈ Γ to stand for list-membership. Note the freshness condition in the rule t-Lam, which makes this rule sound with respect to the typing-judgements we intend to be derivable.
From the definition of the typing rules, Nominal Isabelle can again derive a stronger induction principle, where in the lambda-case we can assume that the binder satisfies some chosen freshness constraints (this is similar to the stronger structural induction principle for lambda-terms). The ability to choose some fresh- ness constraints is already greatly helpful in proofs of simple properties, for example the weakening lemma. In order to prove this lemma for our typing contexts repre- sented as lists, we first define the notion of a sub-context as follows: 3
Definition 3.2 (Sub-Contexts) Γ  ⊆ Γ  d=ef ∀ x T. (x, T) ∈ Γ  −→ (x, T) ∈ Γ .
We can then state the weakening-lemma in terms of sub-contexts:

3 This is a neat trick we have learned from Randy Pollack.

Lemma 3.3 (Weakening) If Γ 1 ▶ e : T and valid Γ 2 and Γ 1 ⊆ Γ 2 then Γ 2 ▶
e : T.
In the proof of this lemma, again the t˙Var and t˙App cases are routine. Un- fortunately not the t˙Lam-case. This is because the usual (that is weak) induction principle coming with the definition of the typing-rules does not cope well with binders. Consider the na¨ıve attempt of proving the suitably generalised property of weakening, namely
Γ 1 ▶ e : T −→ (∀ Γ 2. valid Γ 2 −→ Γ 1 ⊆ Γ 2 −→ Γ 2 ▶ e : T).
Then in the t˙Lam case we have the induction hypothesis
∀ Γ 2. valid Γ 2 −→ (x, T1)::Γ 1 ⊆ Γ 2 −→ Γ 2 ▶ e : T2
which we like to use with the instantiation Γ 2 = (x, T1)::Γ 2. However this will not allow us to make any progress as we cannot obtain (x, T1)::Γ 2 ▶ e : T. The reason is that we only know that x is fresh for the smaller typing context Γ 1 and we cannot infer anything for the bigger context Γ 2. Consequently, we cannot ascertain whether valid ((x, T1)::Γ 2) holds. To get the proof through the na¨ıve way, we have to rename the binder first, at which point the simplicity of the proof disappears (see [8,9]): the inductive hypothesis is much harder to show applicable because it mentions e, but the desired goal is in terms of e[x:=z]. This will require a lemma establishing the invariance of the typing-judgement under renamings.
The renaming can be completely avoided if we use the strong version of the induction principle that has the usual variable convention built in. The formal proof is then very close to being straightforward:
1  lemma weakening:
2	fixes Γ 1 Γ 2::”(name×ty) list”
3	assumes a: ”Γ 1 ▶ e: T” and b: ”valid Γ 2” and c: ”Γ 1 ⊆ Γ 2”
4	shows ”Γ 2 ▶ e: T”
5 using abc proof (nominal˙induct Γ 1 e T avoiding: Γ 2 rule: typing.strong˙induct)
6	case (t˙Lam x Γ 1 T1 t T2 Γ 2)
7	have vc: ”x # Γ 2” by fact
8	have ih: ”[[valid ((x,T1)::Γ 2); (x,T1)::Γ 1 ⊆ (x,T1)::Γ 2]] =⇒ (x,T1)::Γ 2 ▶ t: T2”
9by fact
10	have ”valid Γ 2” by fact
11	then have ”valid ((x,T1)::Γ 2)” using vc by auto
12	moreover
13	have ”Γ 1 ⊆ Γ 2” by fact
14	then have ”(x,T1)::Γ 1 ⊆ (x,T1)::Γ 2” by simp
15	ultimately have ”(x,T1)::Γ 2 ▶ t : T2” using ih by simp
16	with vc show ”Γ 2 ▶ Lam x.t : T1→T2” by auto
17  qed (auto)
Line 5 sets up the induction to avoid Γ 2; therefore we can assume in Line 7 that the binder x is fresh w.r.t. Γ 2. This fact is used in Line 10 to infer validity

of valid ((x,T1)::Γ 2) and in Line 15 to apply the typing rule. Line 8 states the induction hypothesis (which is already instantiated with (x, T1)::Γ 2) and the rea- soning in Lines 9–13 ensures that the induction hypothesis is applicable. The cases for variables and applications are derived automatically in Line 16. In fact all the calculation involved in this lemma can be done automatically by Isabelle as can be seen below:
lemma weakening:
fixes Γ 1 Γ 2::”(name×ty) list”
assumes a: ”Γ 1 ▶ e: T” and b: ”valid Γ 2” and c: ”Γ 1 ⊆ Γ 2”
shows ”Γ 2 ▶ e: T”
using a b c by (nominal˙induct Γ 1 e T avoiding: Γ 2 rule: typing.strong˙induct) (auto)
Next we will establish the type-substitutivity lemma, which we will be crucial later on when showing the type-preservation property.
Lemma 3.4 (Type-Substitutivity)
If (x, T’)::Γ ▶ e : T and Γ ▶ e’ : T’ then Γ ▶ e[x:=e’] : T.
There are a number of ways to prove this lemma. One is to use the strong induction principle for lambda-terms and perform an induction over the structure of e. This involves a fair amount of straightforward calculations, but they cannot be found by the automated tools of Isabelle. It is more convenient if we first generalise Lem. 3.4 and prove
Lemma 3.5
If Δ @ [(x, T’)] @ Γ ▶ e : T and Γ ▶ e’ : T’ then Δ @ Γ ▶ e[x:=e’] : T.
by a strong induction on the first typing relation. For this we have to fix the typing context in the induction to be Δ @ [(x, T’)] @ Γ and avoid e’ and Δ. Fixing the typing context to be Δ @ [(x, T’)] @ Γ is a slightly roundabout way of saying that the type association for the variable x occurs somewhere inside the typing context (this is needed in order to get the Lam-case trough). The avoiding part will give us the necessary assumptions in order push the substitution under the lambda-abstraction in the t˙Lam-case: we have in this case the induction hypothesis
∀ Δ e’. Γ ▶ e’ : T’ −→ Δ @ Γ ▶ e[x:=e’] : T2 and need to show that
Γ ▶ e’ : T’ −→ Δ @ Γ ▶ Lam y.e[x:=e’] : T1→T2
under the assumption that y # Δ, y # e’ and y # (Δ @ [(x, T’)] @ Γ ) (the former two come from the strong induction and the latter from the premise of the t˙Lam- rule). Having these assumptions at our disposal, we can move the substitution under the lambda-abstraction and then apply the t˙Lam-rule, which is possible since y # (Δ @ [(x, T’)] @ Γ ) implies that also y # (Δ @ Γ ) holds (a fact called fresh˙list˙append in the proof below). Finally we can use the induction hypothesis to complete the proof. This reasoning leads to the following quite automatic formal

proof. We only have to give the details for the variable case, because there we have to do a case distinction that cannot be found automatically be Isabelle.
1 lemma type˙substitutivity˙aux:
2	assumes a: ”Δ@[(x,T’)]@Γ ▶ e : T” and b: ”Γ ▶ e’ : T’”
3	shows ”Δ@Γ ▶ e[x::=e’] : T”
4 using ab 
5 proof (nominal˙induct Γ = ”(Δ@[(x,T’)]@Γ )” e T avoiding: e’ Δ rule: typing.strong˙induct)

6
7
8
9
10
11
12
13}
14
15
16
17
18
19
20
case (t˙Var Γ ’yT e’ Δ)
then have a1: ”valid (Δ@[(x,T’)]@Γ )” and a2: ”(y,T) ∈ set (Δ@[(x,T’)]@Γ )”
and a3: ”Γ ▶ e’ : T’” by simp˙all
from a1 have a4: ”valid (Δ@Γ )” by (rule valid˙insert)
{ assume eq: ”x=y”
from a1 a2 have ”T=T’” using eq by (auto intro: context˙unique)
with a3 have ”Δ@Γ ▶ Var y[x::=e’] : T” using eq a4 by (auto intro: weakening)
moreover
{ assume ineq: ”x/=y”
from a2 have ”(y,T) ∈ set (Δ@Γ )” using ineq by simp
then have ”Δ@Γ ▶ Var y[x::=e’] : T” using ineq a4 by auto }
ultimately show ”Δ@Γ ▶ Var y[x::=e’] : T” by blast
qed (force simp add: fresh˙list˙append)+


In line Line 5 we set up the strong induction principle by fixing the typing context and avoiding e’ and Δ. Lines 7 and 8 mention the assumption that are available in the t˙Var-case. Line 9 contains the fact valid (Δ @ Γ ) which follows from the assumption valid (Δ @ [(x, T’)] @ Γ ). In Lines 10 to 12 we treat the case where the variables x and y are equal. In order to complete this case we have to use weakening. In Lines 14 to 16 we tread the case where x /= y. As a result we can conclude the t˙Var-case in Line 17. The remaining cases for rules t˙App and t˙Var can be found automatically in in Line 18.
Lemma 3.4 is now a simple corollary of Lemma 3.5. Later on we will need the following inversion properties for the typing relation.
Lemma 3.6 (Type-Inversion)
If Γ ▶ App t1 t2 : T then ∃ T’. Γ ▶ t1 : T’→T ∧ Γ ▶ t2 : T’.
If Γ ▶ Lam x.t : T and x # Γ then ∃ T1 T2. (x, T1)::Γ ▶ t : T2 ∧ T = T1→T2.
Note that the second inversion property needs the precondition x # Γ , which means we can only invert the typing relation provided the bound variable x is sufficiently fresh [4].

Big-Step Evaluation Relation

In this section we define the usual big-step call-by-value semantics. The inference rules are
x # (e1, e2, e’)	e1 ⇓ Lam x.e	e2 ⇓ e2’	e[x:=e2’] ⇓ e’ b-App
App e1 e2 ⇓ e’
Lam x.e ⇓ Lam x.e b-Lam
In order to take advantage of the automatic facilities in Nominal Isabelle, we have to state the b˙App-rule so that it includes the freshness constraints x # (e1, e2, e’). An important property we can establish for evaluation is that it preserves types.
Lemma 4.1 (Subject Reduction) If e ⇓ e’ and Γ ▶ e : T then Γ ▶ e’ : T. The proof of this lemma is quite routine when we have a strong induction prin-
ciple for the evaluation relation at our disposal. The only lemmas we need are Lem. 3.4 and the two inversion properties from Lem. 3.6 (Lines 8 and 13).
1  lemma subject˙reduction:
2	assumes a: ”e ⇓ e’” and b: ”Γ ▶ e : T”
3	shows ”Γ ▶ e’ : T”
4 using ab proof (nominal˙induct avoiding: Γ arbitrary: T rule: big.strong˙induct)
5
6	case (b˙App x e1 e2 e’ e e2’ Γ T)
7	have vc: ”x # Γ ” by fact
8	have ”Γ ▶ App e1 e2 : T” by fact
9	then obtain T’ where a1: ”Γ ▶ e1 : T’→T” and a2: ”Γ ▶ e2 : T’” by (auto
10elim: t˙App˙elim)
11	have ih1: ”Γ ▶ e1 : T’ → T =⇒ Γ ▶ Lam x . e : T’ → T” by fact
12	have ih2: ”Γ ▶ e2 : T’ =⇒ Γ ▶ e2’ : T’” by fact
13	have ih3: ”Γ ▶ e[x:=e2’] : T =⇒ Γ ▶ e’ : T” by fact
14	have ”Γ ▶ Lam x.e : T’→T” using ih1 a1 by simp
15	then have ”(x,T’)::Γ ▶ e : T” using vc by (auto elim: t˙Lam˙elim)
16	moreover
17	have ”Γ ▶ e2’: T’” using ih2 a2 by simp
18	ultimately have ”Γ ▶ e[x:=e2’] : T” by (simp add: type˙substitutivity)
19	then show ”Γ ▶ e’ : T” using ih3 by simp
20  qed (force)
In Line 6 we can assume that x # Γ holds. We invert the assumed typing derivation in Lines 7 and 8. The three induction hypotheses of this case are men- tioned in Lines 9 to 11. The first one is used in Line 12 and 13 to infer (x, T’)::Γ ▶ e : T; the second in Line 15 to infer Γ ▶ e2’ : T’. From these two facts follows that Γ ▶ e[x:=e2’] : T holds. Using the third induction hypothesis in Line 17, we can

conclude the b-App-case. Since the reasoning is quite routine, Isabelle will be able to find the proof as shown below.
lemma subject˙reduction:
assumes a: ”e ⇓ e’” and b: ”Γ ▶ e : T”
shows ”Γ ▶ e’ : T”
using a b by (nominal˙induct avoiding: Γ arbitrary: T rule: big.strong˙induct) (force elim: t˙App˙elim t˙Lam˙elim simp add: type˙substitutivity)+
Another important property is that the evaluation relation produces unique results. This can be stated as follows.
Lemma 4.2 (Unicity) If e ⇓ e1 and e ⇓ e2 then e1 = e2.
The proof of this lemma is by rule induction over the evaluation relation. The reasoning is similar to Lem. 4.1 and therefore omitted.
A small lemma which is often overlooked in informal reasoning is that freshness is preserved by evaluation.
Lemma 4.3 (Freshness Preservation) If e ⇓ e’ and x # e then x # e’.
This lemma can in our formalisation be discharged by a completely automatic induction on the evaluation relation. It will play an important roˆle when we show in the next section that evaluation terminates for well-typed terms.

Termination
The last property we formalise in this paper is that for every typable closed lambda- term evaluates to a value, that means in our context here to a lambda-abstraction.

Theorem 5.1 (Termination) If [] ▶ e : T then ∃ v. e ⇓ v ∧ val v.
The proof of the this lemma is not straightforward and we cannot expect that the automatic proof search tools of Isabelle are of much help in finding this proof. The proof atually only goes through if one proves a stronger result. For this we use the well-known technique of logical relations. The specific logical relation we use here we will call valuation. They are sets of terms and defined as follows:
V (TVar x) = –e — val e˝
V (T1→T2) = –Lam x.e — ∀ v∈V T1. ∃ v’. e[x:=v] ⇓ v’ ∧ v’ ∈ V T2˝
where the first clause contains the predicate val, which only holds for lambda- abstractions, and the second clause includes the standard closure property for lambda-abstractions. In the main lemma we will show that a typable term to- gether with a closing substitution evaluates. In order to define what is meant by a closing substitution we introduce for simultaneous substitutions the notion θ maps x to e, which ensures that θ contains the association (x, e).
Definition 5.2 θ maps x to e d=ef lookup θ x = e.

Next, we introduce a notion for when a substitution θ closes a typable term, that means has an assignment for every (x, T)-pair in a typing context Γ , whereby the assignment in θ must come from the valuation V T.
Definition 5.3 θ Vcloses Γ d=ef ∀ x T. (x, T) ∈ Γ −→ (∃ v. θ maps x to v ∧ v ∈ V T).
The first lemma we show is that Vcloses is preserved under suitable additional assignments to simultaneous substitutions and typing-contexts. This property is often called the monotonicity, or preservation under weakening [5].
Lemma 5.4 (Monotonicity) If θ Vcloses Γ and e ∈ V T and valid ((x, T)::Γ ) then (x, e)::θ Vcloses (x, T)::Γ .
The proof of this lemma is a routine case-distinction on the extended typing- context and simultaneous substitution. Now we are in a position to give a proof Theorem 5.1, where, however, we do not prove termination just for closed expres- sions, but for arbitrary typable terms.
Lemma 5.5 (Termination on open Terms)
If Γ ▶ e : T and θ Vcloses Γ then ∃ v. θ(e) ⇓ v ∧ v ∈ V T.
Proof. This proof is by a strong structural induction on e, where we generalise over T and set up the induction so that in the lambda-cases we can assume the binders are fresh for Γ and θ. The interesting cases are App and Lam which we give below.
1  case (App e1 e2 Γ θ T)
2  have ih1: ” θ Γ T. [θ Vcloses Γ ; Γ ▶ e1 : T]] =⇒ ∃ v. θ(e1) ⇓ v ∧ v ∈ V T” by
3fact
4  have ih2: ” θ Γ T. [θ Vcloses Γ ; Γ ▶ e2 : T]] =⇒ ∃ v. θ(e2) ⇓ v ∧ v ∈ V T” by
5fact
6  have as1: ”θ Vcloses Γ ” by fact
7  have as2: ”Γ ▶ App e1 e2 : T” by fact
8  then obtain T’ where ”Γ ▶ e1 : T’ → T” and ”Γ ▶ e2 : T’” by (auto elim:
9t˙App˙elim)
10 then obtain v1 v2 where ”(i)”: ”θ(e1) ⇓ v1” ”v1 ∈ V (T’ → T)”
11	and ”(ii)”: ”θ(e2) ⇓ v2” ”v2 ∈ V T’” using ih1 ih2 as1 by
12blast
13  from ”(i)” obtain x e’
14	where ”v1 = Lam x.e’”
15	and ”(iii)”: ”(∀ v ∈ (V T’).∃ v’. e’[x::=v] ⇓ v’ ∧ v’ ∈ V T)”
16	and ”(iv)”: ”θ(e1) ⇓ (Lam x.e’)”
17	and fr: ”x # (θ,e1,e2)” by (blast elim: V˙arrow˙elim˙strong)
18  from fr have fr1: ”x # θ(e1)” and fr2: ”x # θ(e2)” by (simp˙all add: fresh˙psubst)
19 from ”(ii)” ”(iii)” obtain v3 where ”(v)”: ”e’[x::=v2] ⇓ v3 ∧ v3 ∈ V T” by auto
20  from fr2 ”(ii)” have ”x # v2” by (simp add: big˙preserves˙fresh)
21  then have ”x # e’[x::=v2]” by (simp add: fresh˙subst)
22  then have fr3: ”x# v3” using ”(v)” by (auto simp add: big˙preserves˙fresh)

23 from fr1 fr2 fr3 have ”x # (θ(e1),θ(e2),v3)” by simp
24 with ”(iv)” ”(ii)” ”(v)” have ”App (θ(e1)) (θ(e2)) ⇓ v3” by auto
25  then show ”∃ v. θ(App e1 e2) ⇓ v ∧ v ∈ V T” using ”(v)” by auto
By induction hypothesis (Lines 2 and 3) we know that:
(ih1)		∀ θ Γ T. θ Vcloses Γ ∧ Γ ▶ e1 : T −→ (∃ v. θ(e1) ⇓ v ∧ v ∈ V T) (ih2)	∀ θ Γ T. θ Vcloses Γ ∧ Γ ▶ e2 : T −→ (∃ v. θ(e2) ⇓ v ∧ v ∈ V T)
By assumption (Lines 4 and 5) we know
(as1)  θ Vcloses Γ	and  (as2)  Γ ▶ App e1 e2 : T 
From the second assumption we can derive that Γ ▶ e1 : T’→T and Γ ▶ e2 : T’ hold by inversion of t-App for some type T ' (Line 6). Using the induction hypotheses and the first assumption (Lines 7 and 8) we can derive that there exists a v1 and v2 such that:
(i )  θ(e1) ⇓ v1  and  v1 ∈ V (T’→T) (ii )  θ(e2) ⇓ v2  and  v2 ∈ V T’
From the first fact, we obtain by definition of V that v1 must be of the form Lam x.e’ (Line 10) whereby x can be assumed to be fresh for θ, e1 and e2 (Line 13; in this step we need a strong elimination rule for the function V). This also implies that x is fresh for θ(e1) and θ(e2) (Line 14). We can further infer from the definition of V that (Lines 11 and 12):
(iii ) ∀ v∈V T’. ∃ v’. e’[x:=v] ⇓ v’ ∧ v’ ∈ V T and (iv ) θ(e1) ⇓ Lam x.e’
Now we combine (ii ) and (iii ) to obtain a v3 (Line 15) such that
(v )  e’[x:=v2] ⇓ v3 and v3 ∈ V T 
holds. Since x is fresh for θ(e2) and freshness is preserved under evaluation (see Lem. 4.3), we have by (ii ) that x is fresh for v2 (Line 16). In turn this means that x is fresh for e’[x:=v2] (Line 17), and hence by (v ) also for v3 (Line 18). Now (Line 19) we have x # (θ(e1), θ(e2), v3) which we can combine with (iv ), (ii ) and (v ) to obtain by rule b-App that (Line 20)
App θ(e1) θ(e2) ⇓ v3
holds. Using v3 we can conclude (Line 21) that there exists a v such that:
θ(App e1 e2) ⇓ v and v ∈ V T.
This completes the application-case. The lambda-case is as follows:
1  case (Lam x e Γ θ T)
2 have ih:” θ Γ T. [θ Vcloses Γ ; Γ ▶ e: T]] =⇒ ∃ v. θ(e) ⇓ v ∧ v ∈ V T” by fact

3  have as1: ”θ Vcloses Γ ” by fact
4  have as2: ”Γ ▶ Lam x.e : T” by fact
5  have fs: ”x # Γ ” ”x # θ” by fact
6 from as2 fs obtain T1 T2
7	where ”(i)”: ”(x,T1)::Γ ▶ e:T2” and ”(ii)”: ”T = T1 → T2” using fs by (auto
8elim: t˙Lam˙elim)
9  from ”(i)” have ”(iii)”: ”valid ((x,T1)::Γ )” by (simp add: typing˙implies˙valid)
10 have ”∀ v ∈ (V T1). ∃ v’. (θ(e))[x::=v] ⇓ v’ ∧ v’ ∈ V T2”
11  proof
12	fix v
13	assume ”v ∈ (V T1)”
14	with ”(iii)” as1 have ”(x,v)::θ Vcloses (x,T1)::Γ ” using monotonicity by auto
15	with ih ”(i)” obtain v’ where ”((x,v)::θ)(e) ⇓ v’ ∧ v’ ∈ V T2” by blast
16  then have ”θ(e)[x::=v] ⇓ v’ ∧ v’ ∈ V T2” using fs by (simp add: psubst˙subst˙psubst)
17	then show ”∃ v’. θ(e)[x::=v] ⇓ v’ ∧ v’ ∈ V T2” by auto
18  qed
19 then have ”Lam x.θ(e) ∈ V (T1 → T2)” by auto
20  then have ”θ(Lam x.e) ⇓ (Lam x.θ(e)) ∧ Lam x.θ(e) ∈ V (T1→T2)” using fs by
21auto
22  then show ”∃ v. θ(Lam x.e) ⇓ v ∧ v ∈ V T” using ”(ii)” by auto
By induction hypothesis (Line 2) we know that:
(ih)	∀ θ Γ T. θ Vcloses Γ ∧ Γ ▶ e : T −→ (∃ v. θ(e) ⇓ v ∧ v ∈ V T)
By assumption (Lines 3 and 4) we know
(as1)  θ Vcloses Γ	and    (as2)  Γ ▶ Lam x.e : T
Since we use a strong induction principle we know further the freshness condi- tions that x # Γ and x # θ (Line 5). We can use them and the second assumption to infer (Lines 6–8) that
(i )	(x, T1)::Γ ▶ e : T2	(ii )	T = T1→T2	(iii )	valid ((x, T1)::Γ )
Where (iii ) follows from (i ) since the judgment (x, T1)::Γ ▶ e: T2 implies that (x, T1)::Γ must be valid.
Next we are going to show (Lines 9–18) that Lam x.θ(e) ∈ V (T1→T2). By definition of V, it therefore suffices to show that (Line 9)
∃ v’. θ(e)[x:=v] ⇓ v’ ∧ v’ ∈ V T2
holds for all v ∈ V T1. We can use Lemma 5.4, (iii ) and the first assumption to infer (Line 13) that (x, v)::θ Vcloses (x, T1)::Γ . We can use this and (i ) to instantiate the induction hypothesis, which gives us a v’ such that (Line 14)
((x, v)::θ)(e) ⇓ v’ ∧ v’ ∈ V T2
holds. We know by Lem. 2.4 that this is equivalent to θ(e)[x:=v] ⇓ v’ ∧ v’ ∈ V T2,

since x is fresh for θ (Line 15). This means we have shown that Lam x.θ(e) ∈ V (T1→T2) holds (Line 18) and we also know by the freshness of x that θ(Lam x.e) is equal to Lam x.θ(e) and evaluates to Lam x.θ(e) (Line 19). Using this and (ii ) we can take v to be Lam x.θ(e) and conclude (Line 20) with
θ(Lam x.e) ⇓ v ∧ v ∈ V T.
 The proof for Theorem 5.1 is now by instantiating θ to be the identity substi- tution [] and the facts that [] Vcloses [] and that V T is a set of values (the latter
can be shown by a simple induction over the type T).

Conclusion
We have described a formalisation of some very typical proofs from SOS. The main point we want to convey is that such proofs can be done relatively easily using Nominal Isabelle. This must however be qualified insofar as Nominal Isabelle only supports languages involving simple, lambda-calculus-like binders. Although they can be of different type and can be iterated (see [17]), more complicated binding structures, such as binding a finite set of variables, are not yet supported. One can encode such general binders using the simple binding, but this makes proofs quite complicated. The second qualification we must mention is that even though we based our formalisation on α-equivalence classes, reasoning about them can be quite subtle. Many of the complications can be hidden from the user, for example by automatically providing strong versions of the induction principles, but they cannot be hidden completely. Most notably issues about α-equivalence show up in definitions of functions by structural recursion. On “paper” one is usually not concerned with questions about whether a function is compatible with α-equivalence classes or whether it leads to an inconsistency. In Nominal Isabelle, conditions need to be verified which guarantee the compatibility with α-equivalence classes. Nevertheless most presented formal proofs really proceed like the corresponding informal proofs done with “pencil-and-paper”.

Acknowledgement
To do this formalisation we have been inspired by Adam Chlipala who mailed some of the problems as challenge on the PoplMark list. We are very grateful to Nick Benton who outlined to us the proof for the termination property described in Sec. 5.


References
B. Aydemir, A. Chargu´eraud, B. C. Pierce, R. Pollack, and S. Weirich. Engineering Formal Metatheory. In Proc. of the 35rd Symposium on Principles of Programming Languages (POPL), pages 3–15. ACM, 2008.


H. Barendregt. The Lambda Calculus: Its Syntax and Semantics, volume 103 of Studies in Logic and the Foundations of Mathematics. North-Holland, 1981.
S. Berghofer and C. Urban. A Head-to-Head Comparison of de Bruijn Indices and Names. In Proc. of the International Workshop on Logical Frameworks and Meta-Languages: Theory and Practice (LFMTP), ENTCS, pages 46–59, 2006.
S. Berghofer and C. Urban. Nominal Inversion Principles. In Proc. of the 21th International Conference on Theorem Proving in Higher Order Logics (TPHOLs), volume 5170 of LNCS, pages 71–85, 2008.
K. Crary. Advanced Topics in Types and Programming Languages, chapter on Logical Relations and a Case Study in Equivalence Checking, pages 139–160. MIT Press, 2005.
H. B. Curry and R. Feys. Combinatory Logic, volume 1 of Studies in Logic and the Foundations of Mathematics. North-Holland, 1958.
L. Damas and R. Milner. Principal type schemes for functional programs. In Proc. 9th ACM Symp. Principles of Programming Languages, pages 207–212, 1982.
J. H. Gallier. Logic for Computer Science: Foundations of Automatic Theorem Proving. Harper & Row, 1986.
J. McKinna and R. Pollack. Some Type Theory and Lambda Calculus Formalised. Journal of Automated Reasoning, 23(1-4), 1999.
T. Nipkow and L. C. Paulson. Proof Pearl: Defining Functions Over Finite Sets. volume 3603 of LNCS, pages 385–396. Springer Verlag, 2005.
T. Nipkow, L. C. Paulson, and M. Wenzel. Isabelle HOL: A Proof Assistant for Higher-Order Logic, volume 2283 of LNCS. Springer-Verlag, 2002.
A. M. Pitts. Nominal Logic, A First Order Theory of Names and Binding. Information and Computation, 186:165–193, 2003.
A. M. Pitts. Alpha-Structural Recursion and Induction. Journal of the ACM, 53:459–506, 2006.
G. Plotkin. A Structural Approach to Operational Semantics. Journal of Logic and Algebraic Programming, 60–61:17–139, 2004.
C. Urban. Nominal Techniques in Isabelle/HOL. Journal of Automated Reasoning, 40(4):327–356, 2008.
C. Urban and S. Berghofer. A Recursion Combinator for Nominal Datatypes Implemented in Isabelle/HOL. In Proc. of the 3rd International Joint Conference on Automated Reasoning (IJCAR), volume 4130 of LNAI, pages 498–512, 2006.
C. Urban, J. Cheney, and S. Berghofer. Mechanizing the Metatheory of LF. In Proc. of the 23rd IEEE Symposium on Logic in Computer Science (LICS), pages 45–56, 2008.
C. Urban and C. Tasson. Nominal Techniques in Isabelle/HOL. In Proc. of the 20th International Conference on Automated Deduction (CADE), volume 3632 of LNCS, pages 38–53, 2005.
M. Wenzel. Isar — A Generic Interpretative Approach to Readable Formal Proof Documents. In Proc. of the 12th Conference on Theorem Proving in Higher Order Logics (TPHOLs), number 1690 in LNCS, pages 167–184, 1999.
