Available online at www.sciencedirect.com



Electronic Notes in Theoretical Computer Science 276 (2011) 335–351
www.elsevier.com/locate/entcs

Concurrent Separation Logic and Operational Semantics
Viktor Vafeiadis
Max Planck Institute for Software Systems (MPI-SWS), Germany

Abstract
This paper presents a new soundness proof for concurrent separation logic (CSL) in terms of a standard operational semantics. The proof gives a direct meaning to CSL judgments, which can easily be adapted to accommodate extensions of CSL, such as permissions and storable locks, as well as more advanced program logics, such as RGSep. Further, it explains clearly why resource invariants should be ‘precise’ in proofs using the conjunction rule.
Keywords: Separation logic; concurrency; soundness; race condition

Introduction
Concurrent separation logic [15] (CSL) is a concurrent program logic, a formal sys- tem for proving certain correctness properties of concurrent programs. It is based on the notion of resource ownership, where the resource typically is dynamically al- located memory (i.e., the heap). Since its inception by O’Hearn, it has become quite popular, because it permits elegant correctness proofs of some complex concurrent pointer programs that keep track of their memory consumption and explicitly deal- locate any unused memory. Its popularity is evident by the number of extensions to CSL (e.g., permissions [2,1], locks in the heap [9,13], variables as resource [16], re-entrant locks [11]).
Besides having many extensions, CSL also has many soundness proofs. Some proofs [3,12,10] are about plain CSL, some [5,9,13,11] are about a particular exten- sion, while others [6,4] are abstract.
Following Brookes’s original proof [3], several proofs [13,6,4] give the semantics of triples in terms of a non-standard ‘intermediate’ semantics that keeps explicit track of resource ownership during execution. In such semantics, acquiring and releasing a lock, operations that normally update a single bit, instead allocate or deallocate part of the heap (receiving it from or sending to a shared resource). The

1571-0661 © 2011 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2011.09.029

adequacy of the intermediate semantics is usually justified by an ‘erasure’ theorem stating that the intermediate semantics simulates a standard semantics.
Some other proofs [11,14,9,10] instead are completely syntactic: they never de- fine the meaning of CSL judgments, but rather establish a global invariant that ensures data-race freedom and that is preserved under execution steps. This proof technique is similar to the “progress and preservation” strategy that is common in soundness proofs of type systems and is rather fragile. If, for instance, a new con- struct were to be added to the language, the soundness of the existing rules would have to be reproved. Moreover, as the meaning of CSL judgments is never de- fined except perhaps for closed ‘top-level’ programs, it is never clear what program specifications actually mean.
In this paper, we take a direct approach to proving soundness of CSL. We define the meaning of CSL judgments directly in terms of a standard concrete operational semantics for the programming language. Our definition is concise and results in a relatively simple soundness proof, which we have formalised in Isabelle/HOL. 1 Our soundness statement has three important benefits:
It encompasses the framing aspect of separation logic. As a result, the proof does not technically require that the operational semantics satisfies the “safety monotonicity” and the “frame” properties [20].
It does not insist on resource invariants being precise. Similar to Gotsman et al. [10], we prove (a) that CSL with possibly imprecise resource invariants and without the conjunction rule is sound, and (b) that the conjunction rule is sound provided that the resource invariants in scope are precise. Both proofs use the same semantics for CSL judgments.
It can easily be adapted to cover CSL extensions, such as permissions [2,1], RGSep [19], deny/guarantee, and concurrent abstract predicates [7].
Paper Outline. For pedagogic reasons, we will first focus on a cut down version of CSL where the only construct for synchronisation is an atomic block executing in one atomic step (§2). We shall give the syntax and semantics of the programming language and of separation logic assertions, as well as the CSL proof rules. We shall then define carefully the semantics of the CSL judgments (§3) and prove that the proof rules are sound (§4).
Later, in §5, we shall consider O’Hearn’s original setting with multiple named conditional critical regions that execute non-atomically, but in mutual exclusion, and prove CSL’s data race freedom result. Finally, we will adapt our correctness statements to handle extensions of CSL, such as permissions (§6) and RGSep (§7).





1 The proof scripts are available at http://www.mpi-sws.org/~viktor/cslsound [18].



(skip; C2),σ → C2,σ 
	C1,σ → C′ , σ′
(Seq1)

(Seq2)
C, σ →∗ skip, σ′
(Atom)
(atomic C),σ → skip, σ′
C1,σ → C′ , σ′

(C1; C2),σ → (C′ ; C2), σ′
	1		(Par1)

1	(C1  C2),σ → (C′ 
C2), σ′

C1,σ → abort

(C ; C ),σ → abort
(SeqA)
	C2,σ → C′ , σ′

(Par2)

1  2
(C  C ),σ → (C
C′ ), σ′

σ = (s, h)  [B]](s)


(if B then C1 else C2),σ → C1,σ 

(If1)
1	2	1	2
(Par3)

σ = (s, h)  ¬[[B]](s)


(if B then C1 else C2),σ → C2,σ C, σ →∗ abort
atomic C, σ → abort
(If2)

(AtomA)
C1,σ → abort

C2,σ → abort
(ParA1)

(ParA2)

(Loop)

(while B do C),σ → (if B then (C; while B do C) else skip),σ 
(Assign) x := E, (s, h) → skip, (s[x := [E]](s)], h)
(Read)  x := [E], (s, h) → skip, (s[x := v], h)	if h([[E]](s)) = v
(ReadA) x := [E], (s, h) → abort	if [E]](s) ∈/ dom(h) (Wri)  [E]:=E′, (s, h) → skip, (s, h[[[E]](s) := [[E′]](s)])	if [E]](s) ∈ dom(h) (WriA) [E]:=E′, (s, h) → abort	if [E]](s) ∈/ dom(h) (All)  x := alloc(E), (s, h) → skip, (s[x := l], h[l := [E]](s)]) where l ∈/ dom(h)
(Free)  dispose(E), (s, h) → skip, (s, h[[[E]](s) := ⊥])	if [E]](s) ∈ dom(h) (FreeA) dispose(E), (s, h) → abort	if [E]](s) ∈/ dom(h)
Fig. 1. Small-step operational semantics for commands.
Concurrent Separation Logic
Consider the following simple language of commands:
E ::= x | n | E + E | E − E | ... 
B ::= B ∧ B | ¬B | E = E | E ≤ E | ... 
C ::= skip | x := E | x := [E] | [E] := E | x := alloc(E) | dispose(E)
| C1; C2 | C1  C2 | if B then C1 else C2 | while B do C | atomic C
Arithmetic expressions, E, consist of program variables, integer constants, and arithmetic operations. Boolean expressions, B, consist of arithmetic equalities and inequalities and Boolean operations. Commands, C, include the empty command, variable assignments, memory reads, writes, allocations and deallocations, sequen- tial composition, parallel composition, conditionals, loops, and atomic commands. We assume a domain of variable names (VarName), a domain of memory loca- tions (Loc) and a domain of values (Val) that includes memory locations and define
the following composite domains:
s ∈ Stack d=ef VarName → Val	stacks (interpretations for variables)
h ∈ Heap d=ef Loc ~fin Val	heaps (dynamically allocated memory)
σ ∈ State d=ef Stack × Heap	program states

Arithmetic and Boolean expressions are interpreted denotationally as total func- tions from stacks to values or Boolean values respectively:


[[ ]] : Exp → Stack → Val
[[x]](s) d=ef s(x)
[[E1 + E2]](s) d=ef [[E1]](s)+ [[E2]](s)
[[ ]] : BoolExp → Stack → {true, false}
[[B1 ∧ B2]](s) d=ef [[B1]](s) ∧ [[B2]](s)
[[E1 ≤ E2]](s) d=ef [[E1]](s) ≤ [[E2]](s)

Commands are given a small-step operational semantics in Figure 1. Configu- rations are pairs (C, σ) of a command and a state. There are transitions from one configuration to another as well as transitions from a configuration to abort de- noting execution errors such as accessing an unallocated memory location. Parallel composition interleaves executions of its two components, while atomic commands execute their body, C, in one transition. In the premise of Atom, →∗ stands for zero or more → transitions. 2
Separation logic assertions include Boolean expressions, all the classical connec- tives, first order quantification, and five assertions pertinent to separation logic. These are the empty heap assertion (emp), the points-to assertion (E1 '→ E2) indi- cating that the heap consists of a single memory cell with address E1 and contents
E2, separating conjunction (∗), separating implication (−∗), and an iterative version of separating conjunction (②):
P, Q, R, J ::= B | P ∨ Q | P ∧ Q | ¬P | P ⇒ Q | ∀x. P | ∃x. P
| emp | E1 '→ E2 | P ∗ Q | P −∗ Q | ②i∈£ Pi
Assertions denote sets of states. Their semantics is given as a modelling relation,
s, h |= P , stating that the state (s, h) satisfies the assertion P .

s, h |= emp
s, h |= E '→ Ej s, h |= P ∗ Q s, h |= P −∗ Q
⇐de⇒f
⇐de⇒f
⇐de⇒f
⇐de⇒f
dom(h)= ∅
dom(h)= [[E]](s) ∧ h([[E]](s)) = [Ej]](s)
∃h1, h2. h = h1  h2 ∧ (s, h1 |= P ) ∧ (s, h2 |= Q)
∀h1. def(h  h1) ∧ (s, h1 |= P ) =⇒ (s, h  h1 |= Q)

Here, h1  h2 stands for the union of the two heaps h1 and h2 and is undefined unless dom(h1) ∩ dom(h2) = ∅. We write def(X) to say that X is defined. The other assertions are interpreted classically. Finally, we write E '→− as a shorthand for ∃v. E '→ v where v ∈/ fv(E).
An important class of assertions are the so-called precise assertions, which are assertions satisfied by at most one subheap of any given heap. Formally, if there are satisfied by two such heaps, h1 and hj , the two must be equal:
Definition 2.1 An assertion, P , is precise iff for all h1, h2, hj , and hj , if def(h1 h2)

and h1  h2 = hj  hj
and s, h1 |= P and s, hj
1	2
|= P , then h1 = hj .

1	2	1	1

2 Normally, in addition to Atom, there should be another rule for infinite executions for the body of atomic blocks. For simplicity, we omit such a rule. In §5, we will present a different semantics that does not involve
→∗ and does not suffer from this problem.



J ▶ {P} skip {P}
x ∈/ fv(J)
(Skip)
J ▶ {P1} C1 {Q1}
J ▶ {P2} C2 {Q2}
fv(J, P1, C1, Q1) ∩ wr(C2)= ∅

(Assign)
J ▶ {[E/x]P} x := E {P}
x ∈/ fv(E, E′,J)
(Read)
J ▶ {E '→ E′} x := [E] {E '→ E′ ∧ x = E′}
(Write)
J ▶ {E '→ −} [E] := E′ {E '→ E′}
x ∈/ fv(E, J)
(Alloc)
J ▶ {emp} x:=alloc(E) {x '→ E}
(Free)
J ▶ {E '→ −} dispose(E) {emp}
fv(J, P2, C2, Q2) ∩ wr(C1)= ∅


J ∗ R ▶ {P} C {Q}


J ▶ {P ∗ R} C {Q ∗ R}
J ▶ {P} C {Q}
fv(R) ∩ wr(C)= ∅


J ▶ {P ∗ R} C {Q ∗ R}
J ▶ {P} C {Q}
P′ ⇒ P	Q ⇒ Q′

(Par) (Share)

(Frame)

J ▶ {P} C1 {Q}  J ▶ {Q} C2 {R}

J ▶ {P} C1; C2 {R}
J ▶ {P ∧ B} C1 {Q}
J ▶ {P ∧ ¬B} C2 {Q}

J ▶ {P} if B then C1 else C2 {Q}
J ▶ {P ∧ B} C {P}


J ▶ {P} while B do C {P ∧ ¬B}
emp ▶ {P ∗ J} C {Q ∗ J} J ▶ {P} atomic C {Q}

(Seq)


(If)

(While) (Atom)


J ▶ {P′} C {Q′}
J ▶ {P1} C {Q1}
J ▶ {P2} C {Q2}

J ▶ {P1 ∨ P2} C {Q1 ∨ Q2}
J ▶ {P} C {Q}	x ∈/ fv(C)


J ▶ {∃x. P} C {∃x. Q}
J ▶ {P1} C {Q1}
J ▶ {P2} C {Q2}  J precise

J ▶ {P1 ∧ P2} C {Q1 ∧ Q2}
(Conseq)


(Disj)

(Ex)


(Conj)

Fig. 2. Concurrent separation logic proof rules.


CSL judgments are of the form, J ▶ {P} C {Q}, where J is known as the resource invariant, P as the precondition, and Q as the postcondition. Informally, these specifications say that if C is executed from an initial state satisfying P ∗ J , then J will be satisfied throughout execution and the final state (if the command terminates) will satisfy Q ∗ J . There is also an ownership reading attached to the specifications saying that the command ‘owns’ the state described by its precon- dition: the command can change it and can assume that no other parallel thread can change it. In contrast, the state described by J can be changed by other con- currently executing threads. The only guarantee is that it will always satisfy the resource invariant, J .
The proof rules are shown in Figure 2. Among the proof rules, some are partic-
ularly noteworthy. Read and Write both require that the memory cell accessed
is part of the precondition: this ensures that the cell is allocated (and hence, the
access will be safe) and that no other thread is accessing it concurrently. Atom
allows the body of atomic blocks to use the resource invariant, J , and requires them
to re-establish it at the postcondition. Par allows us to compose two threads in
parallel if and only if their preconditions describe disjoint parts of the heap. This prevents data races on memory locations. The side-conditions ensure that there are also no data races on program variables—here, fv returns the set of free variables of a command or an assertion, whereas wr(C) returns the set of variables being as-

signed to by the command C. 3
Share allows us at any time to extend the resource

invariant by separatingly conjoining part of the local state, R. Frame allows us
to ignore part of the local state, the frame R, which is not used by the command, ensuring that R is still true at the postcondition.
Finally, the conjunction rule, Conj, has a perhaps surprising side-condition.
This side-condition is necessary for soundness as illustrated by Reynolds’s coun- terexample [15, §11]. Most presentations require precise J ’s in all judgments. This, however, is unnecessary: only Conj needs precision.

The Meaning of CSL Judgments
We define the semantics of CSL judgments in terms of an auxiliary predicate, safen(C, s, h, J, Q), stating that the command C executing with a stack, s, and a local heap, h, is safe with respect to the resource invariant J and the post-condition Q for up to n execution steps. A CSL judgment, J |= {P} C {Q}, simply says that the program C is safe with respect to J and Q for every initial local state satisfying the precondition, P , and for any number of steps:
Definition 3.1 (Configuration Safety)
safe0(C, s, h, J, Q) holds always.
safen+1(C, s, h, J, Q) holds if and only if (i ) if C = skip, then s, h |= Q; and
for all hJ and hF, if s, hJ |= J and (h  hJ  hF) is defined, then
C, (s, h  hJ  hF) /→ abort; and
for all Cj, hJ , hF, hj and sj, if s, hJ |= J , and (h  hJ  hF) is defined, and
C, (s, h  hJ  hF) → Cj, (sj, hj), then there exist hjj and hj such that hj =

hjj  hj
  hF and sj, hj
|= J and safen(Cj, sj, hjj, J, Q).

Definition 3.2 J |= {P} C {Q} if and only if for all n, s, and h, if s, h |= P , then
safen(C, s, h, J, Q).
Intuitively, any configuration is safe for zero steps. For n + 1 steps, it must (i ) satisfy the postcondition if it is a terminal configuration, (ii ) not abort, and (iii ) after any step, re-establish the resource invariant and be safe for another n steps. The number of steps merely ensures the definition is structurally decreasing.
In more detail, h is the part of the heap that is ‘owned’ by the command: the command can update h and no other command can access it in parallel. In conditions (ii ) and (iii ), hJ represents the part of the heap that is shared among threads, and must hence satisfy the resource invariant. So, condition (iii ) ensures that after the transition a new such component, hj , can be found. Finally, hF represents the remaining part of the heap owned by the rest of the system. In condition (ii ), the command must not abort regardless of what that remaining part

3 For simplicity, we impose draconian variable side-conditions. In effect, only heap cells may be shared among threads, as J cannot mention any updateable variables.

is. In condition (iii ), the command must not change any part of the heap that could be owned by another thread. Therefore, hF must be a subheap of the new heap hj.
Safety Monotonicity & Frame Property. The purpose of the hF quantifications is to admit the frame rule. In condition (ii ), hF essentially plays the role of “safety monotonicity” [20], which requires that if (C, h) is safe (i.e., does not abort), then (C, h hF) is also safe.
Similarly, in condition (iii ), hF plays the role of the “frame property” [20], which requires that whenever (C, h) is safe and C, (s, h hF) → Cj, (sj, hj), then there exists hjj such that C, (s, h) → Cj, (sj, hjj) and hj = hjj hF. Condition (iii ) does not quite imply the frame property, as it does not require that C, (s, h) → Cj, (sj, hjj). It rather takes the transition C, (s, h) → Cj, (sj, hjj) into account even though it might not be present.
The difference is quite subtle. In particular, if the operational semantics satisfies the safety monotonicity and frame properties (which it does in our case), we can drop the hF quantification. (See [18] for a proof.) Having the quantification, however, is crucial for some of the CSL extensions (see §6) and even simplifies some of the proofs for the normal CSL (Par and Frame).
Discussion. A nice aspect of Definition 3.1 is that the straightforward lemmas about safety of compound commands are usually already inductive, thereby ren- dering the otherwise most challenging part of soundness proofs trivial. The only exception is Lemma 5.3 about the resource declaration rule (for an extension of Definition 3.1 to handle multiple named CCRs), which was arguably the most in- tellectually challenging part of the proof.
A second benefit is that we do not strictly require an abort semantics to prove the soundness of CSL: if we drop condition (ii ) from Definition 3.1, we can still prove the soundness of CSL without ever referring to an abort semantics. In contrast, proofs relying on the safety monotonicity and frame properties heavily depend on an abort semantics (e.g., [3,4,5,6,9,10]).
Soundness Proof
We start with some basic –but important– properties of the semantics. In the following, let [s ∼ sj]X stand for ∀x ∈ X. s(x) = sj(x) and X for the complement of set X.
Proposition 4.1 If C, (s, h) → Cj, (sj, hj), then fv(Cj) ⊆ fv(C), wr(Cj) ⊆ wr(C), and [s ∼ sj]wr(C).
Proposition 4.2  (i) If [s ∼ sj]fv(E), then [[E]](s)= [[E]](sj).
If [s ∼ sj]fv(B), then [[B]](s)= [[B]](sj).
If [s ∼ sj]fv(P ), then s, h |= P if and only if sj,h |= P.
If [s ∼ sj]fv(C) and C, s → abort, then C, sj → abort.

If X ⊇ fv(C) and [s ∼ sj]X and C, s → C1, s1, then there exist sj
such that

C, sj → Cj , sj and [s1 ∼ sj ]X.
1	1	1
Now, consider Definition 3.1. By construction, safe is monotonic with respect to n: if a configuration is safe for a number of steps, n, it is also safe for a smaller number of steps, m. (This is proved by induction on m.)
Lemma 4.3 If safen(C, s, h, J, Q) and m ≤ n, then safem(C, s, h, J, Q).
Further, as a corollary of Proposition 4.2, safen(C, s, h, J, Q) depends only on the values of variables that are mentioned in C, J , Q.
Lemma 4.4 If safen(C, s, h, J, Q) and [s ∼ sj]fv(C,J,Q), then safen(C, sj, h, J, Q).
The soundness theorem for CSL is the following:
Theorem 4.5 (CSL Soundness) If J ▶ {P } C {Q}, then J |= {P} C {Q}.
Our proof strategy is to prove that each proof rule is a sound implication if we replace all the ▶ by |=. Then, the theorem follows by a straightforward rule induction. For brevity, we only show the proofs of the most interesting rules.
(Skip) The rule for skip follows immediately from the following lemma, whose proof is trivial because there are no transitions from skip.
Lemma 4.6 For all n, s, h, J, and Q, if s, h |= Q, then safen(skip, s, h, J, Q).
(Atom) We need an auxiliary lemma for code executing in atomic blocks:
Lemma 4.7 If ∀n. safen(C, s, h, emp, Q) and def(h  hF), then
¬(C, (s, h  hF) →∗ abort); and
if, moreover, C, (s, h  hF) →∗ skip, (sj, hj), then there exists hjj such that
hj = hjj  hF and sj, hjj |= Q.
This lemma is proved by an induction on the length of the →∗ traces, not- ing that when J = emp, the second clause of Definition 3.1 simplifies to safen+1(C, s, h, emp, Q) if and only if
if C = skip, then s, h |= Q; and
for all hF, if def(h  hF), then C, (s, h  hF) /→ abort; and
for all hF, Cj, sj, hj, if C, (s, h hF) → Cj, (sj, hj), then there exists hjj such that hj = hjj  hF and safen(Cj, sj, hjj, J, Q).
The main lemma for atomic commands is as follows:
Lemma 4.8 If emp |= {P ∗ J} C {Q ∗ J}, then J |= {P} atomic C {Q}.
Proof. Assume (*) emp |= {P ∗ J} C {Q ∗ J}, and pick arbitrary s, h |= P and
n. We have to show that safen(atomic C, s, h, J, Q). If n = 0, this is trivial; so consider n = m + 1. Condition (i ) is trivial as atomic C /= skip.
If atomic C, (s, h  hJ  hF) → abort, then from the operational semantics
C, (s, h  hJ  hF) →∗ abort, which with Lemma 4.7 contradicts (*).

The only way for atomic C, (s, h hJ  hF) → Cj, (sj, hj) is if Cj = skip and C, (s, h hJ hF) →∗ skip, (sj, hj). Hence, from assumption (*) and Lemma 4.7, there exists hjj such that hj = hjj  hF and sj, hjj |= Q ∗ J . So, there exist hjjj and

hj such that hjj = hjjj  hj , sj, hjjj |= Q, and sj, hj
|= J . Finally, from Lemma 4.6,

J	J	J
we get safem(skip, sj, hjjj, J, Q).	2

(Par) For parallel composition, we need the following auxiliary lemma:
Lemma 4.9 If safen(C1, s, h1, J, Q1), safen(C2, s, h2, J, Q1), h1   h2 is
fv(J, C1, Q1) ∩ wr(C2)= ∅, and fv(J, C2, Q2) ∩ wr(C1)= ∅, then
safen(C1  C2, s, h1  h2, J, Q1 ∗ Q2).
Proof. By induction on n. In the inductive step, we know IH (n) d=ef

deﬁned,

∀C1, h1, C2, h2. safen(C1, s, h1, J, Q1) ∧ safen(C2, s, h2, J, Q1) ∧ def(h1  h2)
∧ fv(J, C1, Q1) ∩ wr(C2)= ∅∧ fv(J, C2, Q2) ∩ wr(C1)= ∅
=⇒ safen(C1  C2, s, h1  h2, J, Q1 ∗ Q2)
and we have to show IH (n + 1). So, pick arbitrary C1, h1, C2, h2 and assume
(1) safen+1(C1, s, h1, J, Q1), (2) safen+1(C2, s, h2, J, Q2), (3) def(h1  h2) and (4) the variable side-conditions, and try to show safen+1(C1  C2, s, h1 h2, J, Q1 ∗ Q2). Condition (i ) is trivial.
If C1  C2, (s, h1 h2 hJ hF) → abort, then according to the operational semantics C1, (s, h1 h2 hJ hF) → abort or C2, (s, h1 h2 hJ hF) → abort, contradicting our assumptions (1) and (2).
Pick arbitrary Cj, hJ , hF, sj, hj such that s, hJ |= J , (h1 h2 hJ hF) is defined, and C1  C2, (s, h1  h2  hJ  hF) → (Cj, sj, hj). The operational semantics has three possible transitions for C1  C2.
Case (Par1). Cj = Cj  C2 and C1, (s, h1  h2  hJ  hF) → Cj , (sj, hj).

From (1), there exist hj and hj
such that hj = hj  hj  (h2  hF), sj, hj
|= J , and

1	J
safen(Cj , sj, hj , J, Q1).
1	J	J

1	1
From (2) and Proposition 4.3, we have safen(C2, s, h2, J, Q2). Then, from Propo-
sitions 4.4 and 4.1, and assumption (4), we have safen(C2, sj, h2, J, Q2). Also, from Proposition 4.1 and (4), fv(Cj , Q1) ∩ wr(C2)= ∅ and fv(C2, Q2) ∩ wr(Cj )= ∅, and

hence from IH (n), safen(Cj
1	1
 C2, sj, hj  h2, J, Q1 ∗ Q2).

Case (Par2). This case is completely symmetric.
Case (Par3). C1 = C2 = Cj = skip, hj = h1  h2  hJ  hF. From (1) and (2), unfolding the definition of safe, we have that s, h1 |= Q1 and s, h2 |= Q2. So, s, h1  h2 |= Q1 ∗ Q2, and, from Lemma 4.6, safen(skip, s, h1  h2).	2
(Frame) The frame rule is a cut-down version of the parallel composition rule. It follows directly from the following lemma:

Lemma 4.10 If safen(C, s, h, J, Q), fv(R) ∩ wr(C) = ∅, h  hR is
s, hR |= R, then safen(C, s, h  hR, J,Q ∗ R).
deﬁned, and

Proof. By induction on n. The base case is trivial. For the inductive step, assume

(*) safen+1(C, s, h, J, Q), (†) fv(R) ∩ wr(C)= ∅, and (‡) s, hR |= R. Now, we have to prove safen+1(C, s, h  hR, J,Q ∗ R).
From (*), we get s, h |= Q and so, using (‡), s, h  hR |= Q ∗ R.
Pick hJ and hF. Then, from (*), C, (s, h  hR  hJ  hF) /→ abort.
If C, (s, h  hR  hJ  hF) → Cj, (sj, hj), then from (*), there exist hjj, hj





such

that hj = hjj  hj
  (hR  hF) and sj, hj
|= J and safen(Cj, sj, hjj, J, Q). Now, from

(†), (‡), Prop. 4.1 and 4.2, we get sj, hR |= R and fv(R) ∩ wr(Cj) = ∅. Therefore, from the induction hypothesis, safen(Cj, sj, hj  hR, J,Q ∗ R).	2
(Share) We need the following lemma, which is similar to the previous one.
Lemma 4.11 If safen(C, s, h, J ∗ R, Q), h  hR is deﬁned, and s, hR |= R, then
safen(C, s, h  hR, J,Q ∗ R).
Proof. By induction on n. For the inductive step,
From our assumptions, s, h |= Q and s, hR |= R, and so s, h  hR |= Q ∗ R. (ii ) C, (s, h  hR  hJ  hF) /→ abort follows directly from our assumptions.
If C, (s, h hR hJ  hF) → Cj, (sj, hj), then from our assumptions, there exist

hjj, hj
such that hj = hjj hj
  hF and sj, hj
|= J∗R and safen(Cj, sj, hjj,J∗R, Q).

From the definition of ∗, there exist hj and hj such that hj	= hj  hj and sj, hj |=
J	R	JR	J	R	J
J and sj, hj	|= R. Therefore, from the induction hypothesis, safen(Cj, sj, hjj 
hj , J,Q ∗ R), as required.	2
(Conj) Now consider the conjunction rule. Its soundness rests upon the validity of the following implication:
safen(C, s, h, J, Q1) ∧ safen(C, s, h, J, Q2) =⇒ safen(C, s, h, J, Q1 ∧ Q2) .
Naturally, one would expect to prove this implication by induction on n with an induction hypothesis quantifying over all C and h. The base case is trivial; so consider the n + 1 case. The first two subcases are easy; so consider subcase (iii ). From the first assumption, we know that there exist h1 and h1 such that hj = h1 h1
J	J
and h1 |= J and safen(Cj, h1, J, Q1). Similarly, from the first assumption, there exist
h2 and h2 such that hj = h2 h2 and h2 |= J and safen(Cj, h2, J, Q2), but, in general,
J	J	J
we do not know that h1 = h2 which would allow us to complete the proof. Since,
however, J must be precise, then (from Definition 2.1) h1 = h2 , and since  is
cancellative, we also have h1 = h2 and the result follows by applying the induction hypothesis.	2
5	Multiple Resources & Data Race Freedom
In this section, we consider the programming language used by O’Hearn [15] and Brookes [3], which has multiple named resources and permits the execution of critical regions acting on different resources to go on in parallel. The programming language replaces atomic commands, atomic C, with two new constructs and an intermediate

(C1, σ) → (C′ , σ′)
 locked(C′ ) ∩ locked(C2)= ∅


(Par1)
(C2, σ) → (C′ , σ′)
 locked(C1) ∩ locked(C′ )= ∅


(Par2)

(C1  C2, σ) → (C′ C2, σ′)
(C1  C2, σ) → (C1  C′ , σ′)

(accesses(C1, s) ∩ writes(C2, s)) ∪ (accesses(C2, s) ∩ writes(C1, s)) /= ∅

(RaceDetect)


(Res1)	resource r in C, σ → resource r in C′, σ′ if C, σ → C′, σ′
(Res2)	resource r in skip,σ → skip,σ 
(With1) with r when B do C, σ → within r do C, σ	if σ = (s, h) and [B]](s) (With2)		within r do C, σ → within r do C′, σ′	if C, σ → C′, σ′ (With3)	within r do skip,σ → skip,σ 
(ResA)	resource r in C, σ → abort	if C, σ → abort
(WithA)	within r do C, σ → abort	if C, σ → abort
Fig. 3. Operational semantics for CCRs.
command form:
C ::= ... | resource r in C | with r when B do C | within r do C

The first declares a new mutual exclusion lock, r, known as a resource or a resource bundle in CSL terminology. The second construct denotes a conditional critical region (CCR) which runs in isolation with respect to any other CCRs with the same lock. Executing a CCR blocks until the resource is available and the condition B is true, and then executes the body C in isolation to other CCRs acting on the same resource. This is achieved by holding a lock for the duration of testing whether B is satisfied and the execution of its body. Finally, within r do C represents a partially executed CCR: one that has acquired the lock, tested the condition, and still has to execute C. We define locked(C) to be the set of regions syntactically locked by C: those r for which C contains a within r do Cj subterm.
The operational semantics is given by the rules of Figure 1 (excluding Par1, Par2, Atom, AtomA) and the new rules shown in Figure 3. The reduction rules for parallel composition (Par1, Par2) have been adapted to check that two threads do not hold the same lock at the same time. This was unnecessary in the simpler setting because atomic blocks executed in one step.
To show absence of data races, we have added a rule (RaceDetect) that aborts whenever a data race is observed. Here, the functions accesses(C, s) and writes(C, s) return the set of heap locations accessed or modified by C respectively. Their formal definitions can be found in [18].
CSL judgments for multiple resources are of the form Γ ▶ {P } C {Q}, where Γ is a mapping from resource names, r, to their corresponding resource invariants, which are normal assertions. We have the proof rules from Figure 2 –except (Atom) and (Share)– uniformly replacing J by Γ. In addition, we have the following two rules concerning resource declarations and CCRs:

Γ,r : J ▶ {P } C {Q}


Γ ▶ {P ∗ J} resource r in C {Q ∗ J}
Γ ▶ {(P ∗ J ) ∧ B} C {Q ∗ J}


Γ,r : J ▶ {P } with r when B do C {Q}

The first rule is analogous to the Share rule: it allows us to declare a new

resource bundle, r, and associate a resource invariant with it. The second rule is analogous to Atom, allowing the verifier to assume that the relevant resource invariant holds separately at the beginning of the CCR and requiring him to be re-establish it at the end of the CCR.
The definition of configuration safety is adapted as follows:
Definition 5.1
safe0(C, s, h, Γ, Q) holds always.
safen+1(C, s, h, Γ, Q) if and only if (i ) if C = skip, then s, h |= Q; and
(ii ) for all hF, if (h  hF) is defined, then C, (s, h  hF) /→ abort; and (iii ) accesses(C, s) ⊆ dom(h); and
for all Cj, hΓ, hF, sj, hj, Lj, if s, hΓ |= ②r∈locked(C′)\locked(C) Γ(r), and (C, (s, h 
hΓ  hF), L) → (Cj, (sj, hj), Lj), then there exist hjj and hj such that hj =

hjj  hj
  hF and sj, hj
|= ②r∈locked(C)\locked(C′) Γ(r) and safen(Cj, sj, hjj, Γ, Q).

Similar to Definition 3.1, here h is the part of the heap owned by the command; hΓ is the part that belongs to definitely unacquired resources (since any memory cells belonging to a currently acquired resource are part of the local heap of the thread that holds the lock for that resource); and hF represents the frame, namely memory cells belonging to other parts of the system. The set locked(Cj) \ locked(C) represents the set of locks that have been acquired by the transition from C to Cj: for all of those, we assume that the resource invariant holds. Conversely, locked(Cj)\ locked(C) is the set of locks released by the transition: for all those, we check that the resource invariant is established. Finally, the new conjunct accesses(C, s) ⊆ dom(h) is included so that we can show that safe programs do not have any data races.
As before, the semantics of triples is given in terms of the safe predicate:
Definition 5.2 Γ |= {P} C {Q} if and only if for all n, s, h, if s, h |= P then
safen(C, L, s, h, Γ, Q).
The proof of soundness proceeds as before and has been fully formalised in Isabelle/HOL. See [18] for details. We say that a command is well-formed if and only if it does not have two different subcommands simultaneously having acquired the same CCR lock, as this cannot occur in a normal execution. To prove the soundness of the two new rules, we use the following lemmas:
Lemma 5.3 If safen(C, s, h, (Γ,r : R), Q) and C is well-formed and fv(R)∩wr(C)= 
∅, then
if r ∈/ locked(C), then for all hR, if dom(h) ∩ dom(hR) = ∅ and s, hR |= R, then safen(resource r in C, s, h  hR, Γ,Q ∗ R); and
if r ∈ locked(C), then safen(resource r in C, s, h, Γ,Q ∗ R).
Lemma 5.4 If safen(C, s, h, Γ,Q ∗ R) and within r do C is well-formed, then
safen(within r do C, s, h, (Γ,r : R), Q).

The proofs of these lemmas can be found in [18]. Our formalisation also covers local variable declarations as well as the auxiliary variable elimination rule as in Brookes’s original proof [3].
Permissions
Permissions [2,1] are an extension to the standard heap model that enables read-sharing between parallel threads. Consider, for example, the Hoare triple:
{10 '→ −} x := [10]  y := [10] {10 '→ −}. Standard CSL cannot verify that the program satisfies its specification because to read from [10] both threads must know that the cell is allocated (i.e., have 10 '→ − as a precondition), but the assertion 10 '→− ∗ 10 '→− (required by the parallel composition rule) is unsatis- fiable. With permissions, one can instead split 10 '→ − into two half permissions, (10 0'→.5 −) ∗ (10 0'→.5 −), and give one to each thread. The idea then is such partial permissions are read-only: they allow the cell to be read, but not updated. This is captured by the following new proof rule:


x ∈/ fv(E, Ej, Ejj,J )

J ▶ {E E′ Ejj} x := [E] {E E′ Ejj ∧ x = Ejj}

(Read2)

At the postcondition, the two half permissions are collected and joined to give back
10 '→ −, which is just shorthand notation for 10 '→1 −.
Permission models are sets, K, with a distinguished element, T ∈ K, called full permission, and a commutative and associative partial operator, ⊕, denoting addition of two permissions, satisfying the following properties:
∀k ∈ K. ¬def(T⊕ k)	and	∀k ∈ K \ {T}. ∃kj ∈ K. k ⊕ kj = T
The first equation says that T is the greatest permission, as it cannot be combined with any other permission. The second equation says that every non-full permission has a complement permission which when added to it gives full permission. The model we saw previously is known as fractional permissions. K is the set of numbers in the range (0, 1], ⊕ is ordinary addition and is undefined when the result falls out of the range, and T = 1. The complement of fractional permission k is simply 1 −k.
To model a heap with permissions, we extend ⊕ to act on permission-value pairs as follows:
(k ,v ) ⊕ (k ,v ) d=ef ((k1 ⊕ k2, v1)	if v1 = v2 and def(k1 ⊕ k2)


We also extend ⊕ to act on permission-heaps, PH d=ef
Loc ~ (Perm × Val), as

follows. We take h1 ⊕ h2 to be defined if and only if h1(a) ⊕ h2(a) is defined for all
a ∈ (dom(h1) ∩ dom(h2)). If h1 ⊕h2 is defined, it has domain dom(h1) ∪ dom(h2)

with the following values:

(h1 ⊕ h2)(a) d=ef


h1(a) ⊕ h2(a)	if a ∈ (dom(h1) ∩ dom(h2))
h (a)	if a ∈ (dom(h ) \ dom(h ))

1	1	2
⎪h2(a)	if a ∈ (dom(h2) \ dom(h1))
As expected, adding two permission-heaps is defined whenever for each location in their overlap, the heaps store the same value and permissions that can be added together. The result is a permission-heap whose permissions for the location in the overlap is just the sum of the individual heaps.
Assertions are now modelled by permission-heaps, PH. The new assertion form
E1 '→E2 E3 has the following semantics:


s, h |= E1 '→E2 E3
⇐de⇒f
dom(h)= {[[E1]](s)}∧ h([[E1]](s)) = ([[E2]](s), [[E3]](s))

We can consider the set of concrete heaps as being a subset of that of permission- heaps by equating a concrete heap, h, with the permission-heap, hj, which has the same domain as h and for each location l ∈ dom(h), hj(l) = (T, h(l)). In other words, hj has full permission and the same values for every location in h, and no permission for any other location. Observe that every permission-heap can be extended to a normal heap:
∀h ∈ PH. ∃hF ∈ PH. (h ⊕ hF) ∈ Heap .
This allows us to use the same definitions for safe predicate as we have seen already, uniformly replacing with ⊕ and having the h, hF, etc. range over permission- heaps rather than normal heaps. The definition is a bit subtle: as the operational semantics is defined over normal heaps, (C, h ⊕ hJ ⊕ hF) → ... makes sense only when h ⊕ hJ ⊕ hF is a normal heap, a condition that is always possible to achieve as hF is universally quantified.
The check in the safe definition that hF does not change by transitions ensures that programs update the values only of heap locations they have full permission to, but allows threads to access any memory they partially own.
The soundness proof carries over to permission-heaps with no difficulty. See the machine-checked proof [18] for details.
RGSep
RGSep [19] is a more radical extension to CSL replacing resource invariants by two binary predicates, R and G, known as the rely and the guarantee respectively. As in CSL, the heap is logically divided into parts owned by threads and other parts owned by resources (and hence shared among threads, but accessed only within an atomic commands). The rely, R, describes the changes made to the resource-owned states by the environment (i.e., every other thread in the system that could execute

concurrently with the current command), whereas the guarantee, G, describes the changes made by the command itself.
Preconditions and postconditions are also changed into binary predicates de- scribing both the local (thread-owned) and the shared (resource-owned) components of the state. We shall use the notation s, (h1, h2) |= P to denote that the stack s and the heaps h1 and h2 satisfy the binary assertion P , whether it is a pre-, a post-, a rely or a guarantee condition. 4
The safeRG predicate records not only the local heap, hL, but also the shared heap, hS, as this is needed for R and G:
Definition 7.1
safeRG(C, s, hL, hS, R, G, Q) holds always.
safeRG (C, s, hL, hS, R, G, Q) if and only if (i ) if C = skip, then s, (hL, hS) |= Q; and
for all hF, C, (s, hL  hS  hF) /→ abort; and

whenever C, (s, hL  hS  hF) → Cj, (sj, hj), then there exist hj
and hj
such

that hj = hj  hj  hF and s, (hS, hj ) |= G and safeRG(Cj, sj, hj , hj , R, G, Q);
L	S	S	n	L	S
whenever s, (hS, hj )|=R and def(hL  hj ), then safeRG(C, s, hL, hj , R, G, Q).
S	S	n	S
A configuration is safe for n + 1 steps if (i) whenever it is a terminal configu- ration, it satisfies the postcondition; and (ii) it does not abort; and (iii) whenever it performs a transition, its change to the shared state satisfies the guarantee and the new configuration remains safe for n steps; and finally (iv) whenever the envi- ronment changes the shared state according to the rely, the resulting configuration remains safe for another n steps.
The semantics of RGSep judgments is defined in terms of safeRG in the standard way:
Definition 7.2 R; G |=RGSep {P} C {Q} if and only if for all s, hL, hS, and n, if
s, (hL, hS) |= P , then safeRG(C, s, hL, hS, R, G, Q).
Note that the RGSep definitions use exactly the same operational semantics for commands as the CSL definitions: we did not have to come up with a new special semantics. As we did earlier with CSL, it is possible to extend the RGSep definitions to multiple shared regions. The soundness proof goes through in pretty much the same way as in §4 and in [17].
Conclusion
The paper has presented a concise soundness proof of CSL and related program logics that does not involve any intermediate instrumented semantics, unlike most proofs in the literature (e.g., [3,5,9,13,6]). We have shown that inventing elabo- rate semantics is unnecessary and have argued that it is also harmful because it

4 RGSep uses different syntax to denote pre- and postconditions than the one used to denote rely and guarantee conditions. In this paper, however, we shall not go into the syntax of RGSep assertions, and so we overlook such syntactic differences.

obscures the soundness argument. This becomes increasingly problematic as one moves towards larger languages and more complicated concurrent program logics.
As mentioned already, there exist several soundness proofs for concurrent sep- aration logic, while even the first proof by Brookes [3] came 3-4 years after the CSL proof rules were conceived. This is partly due to the intricacy of the sound- ness resulting from imprecise assertions (cf., Reynolds’s counterexample [15, §11]) and partly due to the numerous extensions to CSL that came along (e.g., permis- sions [2,1], “variables as resource” [16], “locks-in-the-heap” [9,13]) for which existing proofs required adaptation (e.g. [5]) or new proofs were developed [9,11,13].
A partial solution to the plethora of adapted proofs was given by Calcagno et al. [6] with abstract separation logic, a soundness proof of CSL with respect to an abstract operational semantics to commands that could be instantiated to the various permission and variables-as-resource models. This unifying approach, unfortunately, has a significant drawback: the soundness of any particular instance of the logic (e.g., CSL with fractional permissions) tells us nothing about how verified programs behave when executed by the hardware. This is because the instantiated abstract semantics bears little resemblance to the ‘machine semantics.’ To get a meaningful correspondence, one would have to relate the two semantics, a task that is most likely non-trivial. This is why our proof is instead based on a concrete semantics.
The style of semantic definitions presented in this paper has also been used to justify the soundness of more advanced program logics, such as the concurrent abstract predicates of Dinsdale-Young et al. [7]. So far, however, we have used this style of semantic definitions to justify the correctness only of program logics about partial correctness. It is quite possible to extend these definitions in order to capture certain kinds of liveness properties. For example, we can define the meaning of a Hoare triple for obstruction-freedom by changing safe0(C, h, ...) instead of always being true to require that C terminates under no environment interference. In the future, I would like to explore this direction further.
Acknowledgement
I would like to thank Stephen Brookes, Matthew Parkinson, Peter O’Hearn, and Glynn Winskel, who encouraged me to write this paper, and also John Wickerson and the anonymous reviewers for their valuable comments.

References
Bornat, R., Calcagno, C., O’Hearn, P. W., Parkinson, M. J., Permission accounting in separation logic, in: POPL (2005), pp. 259–270.
Boyland, J., Checking interference with fractional permissions, in: 10th SAS, LNCS 2694 (2003), pp. 55–72.
Brookes, S., A semantics for concurrent separation logic, Theor. Comput. Sci. 375 (2007), pp. 227–270.
Brookes, S., Fairness, resources, and separation, Electr. Notes Theor. Comput. Sci. 265 (2010), pp. 177– 195.

Brookes, S., Variables as resource for shared-memory programs: Semantics and soundness, Electr. Notes Theor. Comput. Sci. 158 (2006), pp. 123–150.
Calcagno, C., O’Hearn, P. W., Yang, H., Local action and abstract separation logic, in: LICS (2007),
pp. 366–378.
Dinsdale-Young, T., Dodds, M., Parkinson, M., Gardner, P., Vafeiadis, V., Concurrent abstract predicates, in: ECOOP, LNCS 6183 (2010), pp. 504–528.
Gotsman, A., “Logics and analyses for concurrent heap-manipulating programs,” Ph.D. dissertation, University of Cambridge Computer Laboratory (2009), also available as Technical Report UCAM-CL- TR-758.
Gotsman, A., Berdine, J., Cook, B., Rinetzky, N., Sagiv, M., Local reasoning for storable locks and threads, in: Shao, Z., editor, APLAS, LNCS 4807 (2007), pp. 19–37.
Gotsman, A., Berdine, J., Cook, B., Precision and the conjunction rule in concurrent separation logic, in: MFPS, (20011)
Haack, C., Huisman, M., Hurlin, C., Reasoning about Java’s reentrant locks, in: Ramalingam, G., editor,
APLAS, LNCS 5356 (2008), pp. 171–187.
Hayman, J., Winskel, G., Independence and concurrent separation logic, in: LICS (2006), pp. 147–156.
Hobor, A., Appel, A. W., Zappa Nardelli, F., Oracle semantics for concurrent separation logic, in:
S. Drossopoulou, editor, ESOP, LNCS 4960 (2008), pp. 353–367.
Jacobs, B., Piessens, F., Expressive modular fine-grained concurrency specification, in: POPL (2011).
O’Hearn, P. W., Resources, concurrency and local reasoning, Theor. Comput. Sci. 375 (2007), pp. 271– 307.
Parkinson, M. J., Bornat, R., Calcagno, C., Variables as resource in Hoare logics, in: LICS (2006), pp. 137–146.
Vafeiadis, V., “Fine-grained concurrency verification,” Ph.D. dissertation, University of Cambridge Computer Laboratory (2007), available as Technical Report UCAM-CL-TR-726.
Vafeiadis, V., Concurrent separation logic and operational semantics (Isabelle proof) (2011), http:
//www.mpi-sws.org/~viktor/cslsound/.
Vafeiadis, V., Parkinson, M., A marriage of rely/guarantee and separation logic, in: Caires, L., Vasconcelos, V. T., editors, CONCUR, LNCS 4703 (2007), pp. 256–271.
Yang, H., O’Hearn, P. W., A semantic basis for local reasoning, in: Nielsen, M., Engberg, U., editors,
FoSSaCS, LNCS 2303 (2002), pp. 402–416.
