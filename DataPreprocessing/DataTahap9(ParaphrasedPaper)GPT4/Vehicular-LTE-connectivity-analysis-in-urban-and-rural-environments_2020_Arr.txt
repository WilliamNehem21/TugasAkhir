Rapid advancements in information and communication technologies have led to the emergence of vehicle connectivity as a means to enhance traffic safety and management. Central to the concept of intelligent transportation systems (ITS), this vehicle connectivity promises to revolutionize travel by enabling vehicles to communicate with each other and roadside units (RSUs) to prevent accidents and other hazards. Pilot programs in New York City, Tampa, and Wyoming demonstrate the commitment to advancing these technologies, with the US Department of Transportation suggesting that connected vehicles could reduce non-impaired crashes by up to 80%.

Research has been focused on improving LTE-based vehicle-to-everything (V2X) applications. This includes both direct vehicle-to-vehicle (V2V) and vehicle-to-infrastructure (V2I) communications. It has been observed that for V2V, effective resource allocation can be managed by base stations (BSs), which is crucial in ensuring collision-free transmission â€“ a significant improvement over contention-based approaches like those used in DSRC technology.

The effective functioning of these V2X communications depends on managing propagation losses and interference, which traditionally require knowledge of base station locations. In contemporary studies, locations are often sourced from public databases like OpenCellID, which employs crowd-sourced information to estimate BS locations using GPS coordinates and LTE's global identifier (ECGI).

The measurement of V2I communication path loss plays a critical role, which in rural and suburban settings is less affected by multipath components. Studies use the two-ray ground reflection model to analyze signal degradation across distances.

For post-processing analysis, unambiguous identification of BSs is essential to evaluate vehicular communication performance. Such identification is facilitated by ECGI, which can decode system information for analysis. This decoding helps measure connectivity performance across networks.

Within dense areas, where small cells may be deployed, there can be confusion due to the limited range of physical cell identifiers (PCI). To avoid this ambiguity, systems utilize ECGI, which is broadcast within system information for unique identification. Information like the SIB1 on PDSCH can be decoded to identify cells within a mobile network.

Acquiring downlink control information (DCI) from PDCCH provides scheduling insights for data transmission. Access to this information allows for analysis of control channel elements (CCEs) and blind decoding to identify resource assignments for the system.

Finally, the extraction of ECGI information relies on decoding SIB1 bits using an ASN.1 compiler on a Linux platform. This data helps define a cell's identity in the public land mobile network (PLMN).

Network performance is also managed through handover decisions based on reference signal received power (RSRP) levels. An "A3 condition" triggers handovers when a user moves away from the coverage of a serving BS toward one with a stronger signal, following a specified "time to trigger" (TTT) period.

Signal strength, reflected in both RSRP and reference signal received quality (RSRQ), directly influences packet error rates and jitter (variability in packet latency), as shown in studies focused on voice traffic over real-time transport protocols (RTP).

The collaborative work of Karthik Vasudeva, Ozgur Ozdemir, Sugan R.S. Chandar, Fatih Erden, and Ismail Guvenc across various aspects of the research ensures the comprehensiveness of the study, from conceptualization and methodology to software implementation, analysis, and manuscript preparation.