The academic paper provides an informal overview of computational behaviors of terms within the context of lambda calculus, emphasizing two primary approaches to examining these behaviors. The first approach involves placing a term within a context, possibly including extensions of the lambda calculus, and observing certain properties like termination. The second approach involves reducing the term repeatedly to extract meaningful information, leading to a tree representation that captures the information implicit in the original term. The role of Böhm's theorem is central to these examinations.

Böhm's theorem states that given two distinct lambda-normal forms, there exists a lambda calculus context where one normal form can converge to a value (terminate), while the other diverges (does not terminate). The paper goes on to organize its contents as follows: Section 2 discusses term behaviors within pure lambda calculus contexts concerning different sets of values, while Section 3 examines lambda calculus extensions that discriminate terms analogous to well-known tree representations. Conclusions are drawn in Section 4.

The paper further elaborates on the leftmost-outermost reduction strategy to compute normal forms, drawing parallels to the creation of infinite normal forms through an inductive process. It introduces approximate or partial terms, and corresponding partial Böhm trees, using a symbol "?" to denote subterms not yet in head normal form.

The concept of approximate trees ensures the uniqueness of limits and, consequently, the uniqueness of meaning from a syntactic perspective. Additionally, the distinction is made between infinite terms possibly containing the undefined symbol "?" and ordinary finite terms, formalized through the definition of Böhm trees. Here, "?" denotes unsolvable terms, as opposed to unsolved terms in the approximants, where it means a redex yet to be computed.

To effectively use a nondeterministic choice operator for replacing variables in terms, a standard numerical system with controls is necessary, consisting of a constructor, a destructor, a zero test, and the constant 0, to ensure that diverging substitutions can be controlled.

The paper revisits different types of reductions apart from the ordinary beta-reduction, such as head reduction, weak head reduction, or lazy reduction, each with its associated normal form where the specific reduction rules no longer apply. It explains how a normalizing leftmost-outermost strategy can reduce a term using weak head reduction and then recursively reduce the subterms.

Furthermore, the paper introduces the Lévy-Longo tree as a tree representation for weak head normal forms, alongside approximate Lévy-Longo trees, drawing a parallel to approximate Böhm trees. These trees provide smaller, distinct components of information.

Lastly, the paper clarifies that zero terms are either unsolvable terms of order zero or can be reduced to terms of a specific form (applications of a free variable to any number of arguments). The underlined part within a representation reveals the atom of relevant information within the context of head normal forms and weak head normal forms.