This paper discusses the current advances and challenges in the field of knowledge graph embeddings (KGEs), which are methods used to represent entities and relations in a knowledge graph within a low-dimensional space. Emphasis is placed on the importance of using a consistent evaluation framework to compare KGE techniques, as different training regimes, objective functions, and hyperparameters can impact the assessment of new model architectures.

Several studies have demonstrated that simpler models with well-tuned hyperparameters can rival or outperform complex ones. The stability of model performance across various dataset splits was questioned, and the importance of using realistic data splits, especially in the biomedical domain, was highlighted.

The paper continues to explore the application of KGE techniques in the field of drug discovery, where predicting relationships between entities such as genes, diseases, and drugs is crucial. Biomedical knowledge graphs like Hetionet are used to predict such interactions, and the structure of these graphs differs from the benchmark datasets used to test KGE models.

The authors stress the need for rigorous evaluation procedures for fair comparisons between different KGE approaches and suggest that simple performance metrics may not always be the best indicators of a model's utility, particularly in real-world drug discovery applications.

Experiments and evaluations in this study were conducted using the PyKEEN framework and Optuna library for hyperparameter optimization, on hardware setups including Intel Xeon CPUs and NVIDIA V100 GPUs. It was found that older methods like TransE can still be effective with the right setup and that hyperparameter optimization should consider the specific application to ensure generalizability.

In summary, the paper enlightens readers on the current state of KGE techniques, particularly their use in drug discovery, the challenges in evaluating their performance fairly, and the significance of considering different factors in the machine learning pipeline beyond just novel model architectures.