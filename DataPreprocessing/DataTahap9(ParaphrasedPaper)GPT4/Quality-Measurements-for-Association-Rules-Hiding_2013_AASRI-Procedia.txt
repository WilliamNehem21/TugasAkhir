Data mining technologies have emerged as powerful tools that enable people to make informed decisions and generate significant profits. However, as effective as these technologies are, they raise privacy concerns because they can extract sensitive information, which may inadvertently jeopardize privacy and reveal confidential data.

The field of privacy preserving data mining addresses the privacy implications of data mining by aiming to protect sensitive information during the analytics process. This discipline involves altering the original dataset to ensure that sensitive information becomes undetectable, while maintaining the integrity of non-sensitive information to the greatest extent possible.

One focus within this area is the concept of association rule hiding. The objective here is to modify an existing database, referred to as the "original" (D-original), into a "sanitized" version (D-sanitized). The aim is for the sanitized database to enable the derivation of non-sensitive association rules while preventing the discovery of sensitive ones (R-sensitive) at the same minimum support and confidence thresholds. The intention is to minimize the impact on non-sensitive rules.

To achieve this, strategies are applied based on a specific theorem (Theorem 1) that details how to effectively hide an association rule. If an association rule like A{i-left}->{i-right} needs to be concealed, subsequent dependent rules like A{i-left} B{i-right}(B) must also be hidden. The process involves examining transactions containing both items (i-left and i-right) and then either increasing the frequency of item i-left to boost the support of the left item set, or decreasing the frequency of item i-right to lower the support of the right item set. The transaction database is transformed in this manner until an acceptable level of data quality is achieved.