The academic paper discusses the improvement of convolutional neural network (CNN) models in reconstructing seismic data that includes complex, detailed features. It introduces the Multi-Layer Wavelet Convolutional Neural Network (MWCNN), which incorporates discrete wavelet transform (DWT) and inverse discrete wavelet transform (IWT) within a U-Net architecture. The MWCNN utilizes U-Net as its backbone, with a high number of feature channels in the upsampling section, which helps in relaying context information to higher resolution layers.

The MWCNN is designed to preserve detailed information that may be lost in standard CNNs due to pooling operations. Additionally, it employs IWT to reconstruct high-resolution feature maps and achieves substantial receptive fields with limited computational costs. MWCNN also generalizes dilated filtering and subsampling, which are useful for image restoration tasks.

The paper then introduces a new network called the Wavelet-based Convolutional Block Attention Deep Learning Network (W-CBADL), which integrates wavelet transform with traditional CNNs to improve the reconstruction of seismic data. This network benefits from the multi-scale nature of wavelets, along with the orthogonality of the wavelet transform for non-destructive image restoration. The W-CBADL further includes a Convolutional Block Attention Module (CBAM) that refines feature maps by learning specific weights, thus applying channel and spatial attention to multi-scale seismic data from DWT and IWT.

The authors test W-CBADL on synthetic data, as well as on a case of irregularly sampled seismic data where 70% of traces in each patch are randomly omitted. They compare the performance of W-CBADL against state-of-the-art U-Net and MWCNN models, both quantitatively and qualitatively, demonstrating the proposed network's superior ability to handle irregularly sampled seismic data reconstruction with large gaps and weak reflections.

Computations for this study were carried out on an NVIDIA GTX 3090 graphics processing unit with 24 GB of GPU memory, with models trained on a batch size of 40 for a maximum of 500 epochs, balancing training efficiency with convergence.

The research received funding from the National Natural Science Foundation of China and acknowledges data contributions from Sandia National Laboratory and Mobil Oil Company. The authors also express gratitude to the associate editor and anonymous reviewers for their valuable feedback.