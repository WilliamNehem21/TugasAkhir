Our study involves a model where threads operate in a shared memory environment, with individual stacks and distinct thread-local storage for private data. We use POSIX standards, benefiting from the efficiency of context switching in lightweight thread processes over full-fledged isolated processes, which allows us to deploy more threads than CPUs with minimal performance loss.

Regarding processor cache, we distinguish between two primary architectures: either each CPU has its own private level 2 cache, or two cores within the same package share a level 2 cache. Current machines typically use dual-core CPUs with shared cache; however, caches are not shared across different dual-core units. Cache architecture significantly influences system performance, which we explore further in the paper.

In symmetric multiprocessing (SMP) systems, the single shared memory bus connecting RAM necessitates serialized access by multiple processors. This serialization potentially limits overall memory bandwidth, creating a bottleneck for memory-intensive tasks, such as model checking.

Our algorithm is a variant of the "one way catch them young" method, designed to eliminate vertices from a graph that cannot form part of an accepting cycle, either by having no successors or by being unable to reach an accepting vertex. The process continues until no more vertices can be removed, determining the presence or absence of accepting cycles in the original graph.

We examine three lock strategies: static partitioning with a fixed lock count, dynamic partitioning with a lock per thread, and a square root-based compromise. The experimental section assesses these methods based on lock contention and granularity.

An alternative strategy utilizes a shared queue for state distribution instead of partitioning, aiming for optimal load balancing at the expense of potential locking and contention issues.

Our implemented algorithms, reachability and OWCTY, are order-independent and can operate with breadth-first or depth-first search strategies. We exclude parallel nested DFS as it doesn't use partitioning.

Our primary test bed was a 16-core AMD Opteron 885 system, compiling programs with GCC 4.1.2 in 32-bit mode, allowing access to 3GB of memoryâ€”sufficient for our tests as the system possesses 64GB of RAM, preventing data swapping.

Initially, we aimed to enhance performance and scalability of our model checking platform, DIVINE. However, the various communication strategies did not significantly differ in their performance impact as much as expected, yielding somewhat unconvincing results.