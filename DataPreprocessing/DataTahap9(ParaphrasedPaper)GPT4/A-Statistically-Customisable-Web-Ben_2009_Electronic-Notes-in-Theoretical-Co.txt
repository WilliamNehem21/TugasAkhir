In this paper, we present a web benchmarking solution that is statistically customizable and consists of three main components: a tool for generating HTTP traffic, a system for creating static and dynamic web pages on the test server, and a performance monitoring system that measures key performance metrics during testing. Our tool is uniquely designed to simulate various statistical properties of internet traffic, such as the incoming traffic's inter-arrival rates, the number of objects on a web page, and the size of these objects. Users can tailor these properties to mimic specific scenarios for capacity planning and analysis. We detail the web page generation method, the adjustable traffic characteristics used in benchmarks, and the monitoring process, including a validation of the included probability distributions.

The objective is to produce customizable workloads for benchmarking that are defined by probability distributions. These distributions replicate statistically relevant properties of web traffic: the server's incoming traffic inter-arrival rate, web page complexity in terms of object count, and object sizes. Utilizing probability distributions when customizing benchmarks is beneficial, as it allows for the reproduction of particular workloads cited in literature, the emulation of real traffic in simulations, and the verification of results from network simulators like OPNET Modeler or ns-2.

The paper is structured as follows: Section 2 discusses the rationale behind using probability distributions to characterize benchmark workloads. Sections 3 and 4 introduce the web page and web traffic generators, respectively, followed by a description of the monitoring process in Section 5. Experimental results substantiate the validity of these distributions.

A key aspect covered is the variety of objects, beyond text, that a web page can include, such as images, audio, video, and scripts. The Pareto distribution models the number of objects per web page.

Building the web server involves two steps: first creating web objects according to the distribution for object size, and then assembling these objects into web pages using the distribution that models object count per page.

The client sends user-defined characteristics to the web server, which then creates the requested file structure that will be subsequently accessed by the client.

Prior to initiating the workload generator, the tool performs server performance monitoring to collect CPU usage data. This process considers both the web server and database server processes, the latter only if dynamic pages are involved.

Our test environment consists of two computers connected via a Fast Ethernet switch, with the server powered by an Intel Pentium D processor with 2 GB of RAM, and the client running an AMD Turion 64 with 512 MB of RAM.

To summarize, our flexible web benchmarking tool allows for statistical customization to generate realistic workloads, a web page generator, and a performance monitoring process that captures critical metrics. The paper concludes with a validation of the customizable properties, positioning this tool as a new contribution to the array of existing benchmarks.