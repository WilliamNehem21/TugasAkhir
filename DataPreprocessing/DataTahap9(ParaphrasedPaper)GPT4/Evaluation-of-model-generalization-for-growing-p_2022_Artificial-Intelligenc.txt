The purpose of this paper is to enhance the generalization abilities of semantic segmentation models specific to crop and weed differentiation, a critical area in precision agriculture. The authors investigate two distinct training approaches: traditional and adversarial training, to determine their efficacy on a specified encoder-decoder architecture. They employ three different segmentation networks—U-Net, SegNet, and DeepLabV3+ with a ResNet-50 backbone—trained using cross-entropy loss for classical training and PatchGAN loss for adversarial training. They adopt a conditional generative adversarial network (CGAN) framework, penalizing multiple generators using both a PatchGAN-based discriminator and L1 loss to produce segmentation results. The objective is to create models that demonstrate robust performance across different growth stages of crops without extensive retraining.

To test the models, images from varying development stages of the sugar beet crop are used, with the networks being trained exclusively on the final, fully-grown stage while earlier stages are reserved for testing. The U-Net architecture, when trained adversarially, proved more adaptable to dataset changes, showing a 10% improvement in performance with mean intersection over union (mIoU) scores increasing across successive growth stages (0.34, 0.55, 0.75, 0.85).

Herbicides are commonly sprayed uniformly across fields to control weeds, causing damage to the crops and unnecessary environmental impact. Robots equipped with selective weed and crop detection capabilities could mitigate this problem by enabling precise herbicide application. However, existing detection methods struggle with new, unseen data types, necessitating time-consuming updates for each new weed type or field environment.

The paper investigates different semantic segmentation models' ability to generalize well across different stages of plant growth, an essential aspect given the scarcity of labeled data and the intricacy of pixel-level annotation. By training the models on data from the last stage of the sugar beet crop but using datasets with varied illumination, weed types, and soil textures, the authors explored mechanisms to bolster model performance on different crop stages.

The paper is organized into five sections. The second section reviews existing methods for weed detection. Section three describes the dataset, experiments, and model architectures. The fourth section compares the performance of the models. The paper concludes in section five.