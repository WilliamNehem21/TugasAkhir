In 2004, Guangdong Province initiated the computerized English testing component for the College Entrance Examination. By 2009, CET Band-4 and Band-6 tests were administered in certain colleges and universities, which also witnessed reforms in English listening and speaking assessments. In 2011, more than 60 national higher education institutions offered an online examination for adult learners desiring to take entrance exams for graduate studies.

The computerized exam platform primarily consists of using a keyboard and mouse for interaction. Test-takers can utilize a mouse to interact with text or images within the exam, such as selecting, dragging, or organizing elements. Alternative input devices include touch screens, stylus pens, trackballs, joysticks, and microphones for collecting verbal responses.

The degree of interactivity within computerized tests varies. While most exams are non-interactive, requiring straightforward input such as mouse clicks for selection, others feature limited interaction involving a sequence of actions, such as responding to a scenario depicted in a video and then answering related multiple-choice questions. This two-stage approach enhances interactivity in assessments, including computerized speaking tests.

Scoring methodologies in computerized exams can range from basic to advanced, with some using simple feature identification while others deploy complex computational linguistic theories. Automatic scoring software, like PEG, e-rater, Intelligent Essay Assessor, and InQuizit, offer varying standards yet function similarly to human scorers.

The testing process typically begins with a standard test for all candidates, followed by an optimization test that begins its assessment based on the initial abilities demonstrated in the first stage. It then tailors item selection to maximize information yielded from the fewest questions, utilizing the maximum information principle for test termination and an average difficulty scoring method for ability estimation.

The difficulty of test items indicates a candidate's capacity to answer questions correctly. In controlled testing environments, the starting point is based on moderate difficulty, with variations adopting the same fundamental procedure. Candidates proceed through questions, moving from simpler to more challenging ones based on their responses, using maximum likelihood estimation to gauge their abilities. These processes form the core of four basic computer-adaptive test models that apply different strategies to essential aspects of the exam.

For examination venues, several factors such as the number of seats and computers, security, data storage and transmission, and compatible software constraints play critical roles in the selection process. Consistency across various locations in terms of software and hardware is essential for maintaining standardization of the exams.