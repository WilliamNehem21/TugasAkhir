In their research, the authors implemented an algorithm designed by Angluin to learn finite automata, seeking to assess its practical suitability. Through the application of the algorithm to both synthetically produced data and real-world scenarios, the research evaluated the effects of the state count and alphabet size on the number of membership queries required during the learning process. Furthermore, an enhanced algorithm specifically tailored to learning prefix-closed regular languages was developed and tested.

The researchers observed that one of the main challenges in applying the algorithm to larger examples was significant memory requirements. In the broader context, the field generally relies on pre-existing formal models of systems to perform code and model-based testing, though this research aimed at generating such models with minimal manual intervention, potentially even retrospectively from an existing system.

This study demonstrated the construction of a minimal deterministic finite automaton (DFA), guaranteeing both a minimal state count and an isomorphic structure to the constructed DFA. The researchers analyzed a variety of simple transition systems, including models such as buffers, vending machines, and mutual exclusion protocols, which ranged from 2 to 13 states and 3 to 6 letters. However, limitations arose when they attempted to learn larger systems, attributed to difficulties in efficiently finding counterexamples and memory constraints.

Their experimental findings concluded that learning random prefix-closed automata is more challenging than completely random automata, with membership query counts being roughly linear in the number of transitions for random examples, but approximately quadratic for prefix-closed ones. However, the optimized algorithm for prefix-closed automata yielded a 20% decrease in the need for membership queries. Moreover, when applied to real-world examples, the optimization was even more effective, resulting in a 60% reduction in queries compared to the unoptimized approach.

In comparing the learning outcomes of both real-world and random prefix-closed examples of similar sizes, they found that real-world examples required fewer membership queries, notably with the application of the optimization, suggesting that these examples possessed intrinsic properties more conducive to learning. This insight might inform future efforts to further refine the learning process.