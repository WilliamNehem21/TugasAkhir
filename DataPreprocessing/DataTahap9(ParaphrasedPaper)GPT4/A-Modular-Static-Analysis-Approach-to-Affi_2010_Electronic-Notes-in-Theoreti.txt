Our study focuses on an abstraction mechanism that uses affine constraints, or polyhedra, to define preconditions, postconditions, and state transformations for programs. We introduce an algorithm that calculates the transitive closure of state transformers, which is demonstrated through various examples. This algorithm is unique in that it employs discrete methods of differentiation and integration, differing significantly from the traditional fixed-point computations in abstract interpretation that utilize widening. We've validated our approach through experiments with previously documented cases, achieving comparable outcomes without the need for heuristics.

We approximate all kinds of program commands, including simple statements, compound statements, and procedure calls, with affine transformers, extending the concept from individual states to state transitions. Our method mirrors the concept of transformers from related works like those by Boigelot et al.

The possible program states before execution are represented by a precondition, and the states after execution by a postcondition, which is the precondition transformed by the applicable command. Our abstract postcondition—although an over-approximation—successfully contains the actual postcondition.

We employ a practical example, considering a robot car tasked with autonomously following a floor track, which must not crash if it loses track and must maintain a safe velocity during the search for the track. The safety controller ensures the car operates within time and speed constraints, guaranteeing safety if the track is sufficiently distant from walls.

Our use of polyhedra is not about achieving superior accuracy compared to methods using Presburger arithmetic; rather, we emphasize real-world applications over artificial ones, claiming only that our straightforward algorithm achieves results similar to those of iterative approaches.

The abstract acceleration concept, which aims to achieve similar results to our algorithm, typically involves pattern matching for specific cases, as opposed to our modular computation method that can handle function calls and control constructs like loop bodies. Furthermore, while the use of accelerated cycles is heuristic-based, our method incorporates it into the actual program transformation.

Kelly et al. describe an approach to calculate the transitive closure of a relation described by a Presburger formula, advising the use of a d-form relation for an explicit closure at the cost of precision. Our study demonstrates that converting a relation into a d-form is unnecessary for a precise transitive closure, by turning any relation into constraints that monitor state evolution and deferring convex hull operations for accuracy.

Our technique draws from dual methods to derive predicates about array content, such as using monotonicity analysis to detect induction variables, the counterpart to strength reduction. We focus on whether assignment statements within loops are monotonic in nature, abstracted by the direction of change rather than the exact difference. While this doesn't yield loop invariants, it is instrumental for tests of dependency and array bound checking. By incorporating difference variables and eliminating program variables, we can deduce similar information.

We present a straightforward algorithm that computes affine invariants for integer scalar variables within while loops. Its design direction has been guided by practical applications, targeting automated program analysis and alteration, with its simplicity being crucial for analyzing extensive scientific codes up to 100,000 lines of code. Our experiences have shown that it succeeds in conventional test cases but may falter with complex automata with states and transitions that cannot be simplified into C language encodings.