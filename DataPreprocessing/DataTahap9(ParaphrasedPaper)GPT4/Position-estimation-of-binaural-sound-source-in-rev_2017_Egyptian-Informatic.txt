This academic paper discusses the human auditory system's ability to determine the spatial location of sound sources, including the direction (azimuth and elevation) and distance. While there has been considerable research on directional perception, especially azimuth estimation, studies on elevation and distance perception using binaural hearing have been less common.

Previous studies have shown that combining azimuth and distance information can greatly improve localization accuracy. Despite this, most 3D audio systems have neglected distance, focusing primarily on direction. Only a few studies have investigated the link between azimuth and distance for sound source localization, frequently using microphone arrays rather than binaural auditory processing.

The current research aims to estimate both azimuth and distance simultaneously using binaural audio signals. By analyzing statistical characteristics of binaural cues, particularly the standard deviation of spectral magnitude differences between the left and right ear signals, the study proposes a new approach for sound source localization.

The paper outlines its structure as follows: an introduction of the model approach and feature extraction process, a detailed explanation of the classification method for estimating sound source position, simulation and database information, experiment results, and a final conclusion.

In terms of azimuth estimation, the study draws inspiration from the human auditory system and uses binaural cues like the interaural time difference (ITD) and interaural level difference (ILD), which have been well explored in existing localization systems. The research mentions recent studies that use Gaussian mixture models (GMMs) and neural networks for azimuth estimation in robotics contexts.

The researchers use an efficient approach involving expectation-maximization algorithms and variance normalization prior to classification to deal with computational complexity and variability in feature scales.

The system proposed in the paper effectively estimates sound source position by integrating distance and directional cues in reverberant environments, utilizing a combination of features fed into GMMs. The results show the system's accuracy and robustness under various conditions, including its ability to generalize to untrained positions.