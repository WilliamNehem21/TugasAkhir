Related work. Our framework evolves from the process calculus model proposed by Mitchell and colleagues. While several alternative models cited [1,6,3,11,4,10] could have offered a viable foundation, we find Mitchell et al.'s framework particularly suitable for our purposes. This model's advantage stems not only from its rigorous formal structure but also from its applicability to actual computational processes present in modern cryptography. It achieves this by operating at the cryptographic level and extending the CCS process algebra to include both finite replication and probabilistic polynomial-time terms, which represent cryptographic operations. This probabilistic aspect proves essential for simulating the inherent randomness of security systems' functioning. Differing from other formalisms [6,4,10], its probabilistic scheduling mirrors the attacker's potential influence on communication networks more accurately. Moreover, it serves as a comprehensive formal environment conducive to examining and understanding key cryptographic concepts.

Our design also contemplates whether to render internal actions totally undetectable to would-be attackers, thus endowing users with the liberty to exclude non-ideal schedulers from the specification phase. However, this flexibility is not without drawbacks; protocol designers, who might lack a complete understanding of the system, may rely on their intuitive grasp of the protocol. This, in turn, can lead to expected properties that may not necessarily hold in the actual implementation of the protocol.

When a protocol outputs, and the information becomes accessible to an intruder as input, the latter has the autonomy to choose both the communication channel and its input elements. Conversely, if the communication is initiated from the intruder, they can dictate not only the channel but also the precise message and its output components. In cases where the communication occurs internally within the intruder's components, the intruder exercises full control over the process.

Definition A.3 defines an oracle Turing machine as an advanced form of a Turing machine that includes an additional oracle tape and three special states: qquery, qyes, and qno. When the machine enters the qquery state, the decision to transition to either the qyes or qno state is contingent on whether the data on the oracle tape is part of the oracle set, with a positive match leading to the qyes state and a negative outcome to qno.