Modern engineering systems have become self-aware to an extent—employing sensors and monitors to evaluate their own efficacy and safety. Consider progressive transportation networks: contemporary buses are outfitted with numerous instruments to transmit real-time statistics like position, velocity, and direction to vehicle tracking systems, which serve other applications including real-time passenger information.

As we look ahead, emerging technology suggests a future with systems that can self-organize and self-repair based on the information they acquire. Yet the very mechanisms that gather data can be complex and flawed, leading to issues that may not be immediately apparent until one engages with them. When used for regulatory purposes, these challenges can become more prominent.

Conventionally, service performance was monitored by human inspectors at the roadside, blending keen observation with seasoned judgment. This human element ensured data was vetfully considered before metrics were established. However, in automated systems that lack human insight, misinterpretations can arise—these are the errors this paper aims to address.

Our data details individual buses identified by unique numbers, tracking their positions using specific geographic measures convertible into latitude and longitude. Bus schedules guide their routes, but these can change unpredictably throughout the day, complicating data interpretation for performance metrics.

This paper's subsequent structure includes an exploration of automatic vehicle location (AVL) data visualization, strategies for identifying and omitting data inaccuracies, visualization of headway data, its impact on service quality commitments, a comparison with related research, culminating in a conclusive summary.

The visual tools used lack the capacity to predict or reason, but they have proven invaluable for exposing significant data missteps, leading to a methodical data cleaning effort.

Different perspectives on the data have yielded diverse insights, but apprehending collective behaviors remains challenging. In contexts where overall trends matter more than individual actions, aggregating data to unearth patterns is most enlightening.

In this study, sparse observations indicate swiftness on certain route sections, such as roads leading to the airport. By using visual tools, problematic data can be pruned manually but efficiently, resulting in a refined dataset to evaluate headway—a measure indicative of service regularity.

A well-operated bus service ideally maintains a certain spatial and temporal distance between buses, allowing flexibility in resolving service disruptions while satisfying regulatory metrics—even if this metric is not chosen by authorities in this case.

The paper also describes the "runz" simulation algorithm that projects departure events forward in time and manages them according to a predefined schedule of events.

In our collective experience within the QUANTICOL project, leveraging human expertise has proven essential for preprocessing data before any algorithmic analysis. Anomalies are recognized as such only through the lens of human interpretation.

Acknowledgement follows for the QUANTICOL project's support, contributors, and local collaborators who facilitated access to the case study's data and offered constructive feedback on earlier drafts of the paper.