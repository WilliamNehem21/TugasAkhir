Modern applications frequently run on distributed systems set up through on-demand infrastructure. Technologies like application containers enhance the management of intricate systems, and architectures based on microservices have emerged as a promising framework for addressing software development and scalability. The paper presents an investigative method examining the automatic scalability of microservices architectures within both public and private cloud environments. It employs a fluid Petri net model to capture the characteristics of the platform, with real-world usage data shaping a realistic analysis. The study aims to assess performance, cost, and energy consumption from the perspectives of both service and infrastructure providers.

The analysis is broken into two segments: examining autoscaling strategies and provisioning methods. The autoscaling approach is documented with pseudocode algorithms, whereas provisioning processes rely on fluid stochastic Petri nets (FSPNs). The strategies cover two main elements: the initial allocation of microservices on virtual machines (VMs) at system start-up and the dynamic re-mapping based on the fluctuating workload.

Furthermore, the paper considers the cloud resources and their management policy's implications on costs, which largely depend on the number and duration of VM usage. A distinction is made between private and public cloud scenarios, as public clouds usually charge standardized rates based on the time VMs are employed. Effective cost reduction, in this case, aligns with maximizing VM resource utilization within each charged time unit.

VMs are defined by their start-up and shut-down times, during which they cannot process incoming traffic but still consume energy. The transition to and from operational status is captured with deterministic transitions in the Petri net model. VMs can be in these transitional states concurrently due to the model's infinite server semantics.

The study observes and emphasizes the impact of the billing cycle duration, noting that strategically keeping VMs active until the next billing period could better handle workload variations and potentially provide improved service quality.

Cost analysis in the study revealed that with billing periods quantized, VM usage costs step up accordingly. The consolidated autoscaling policy, categorized as Strategy C, offered the lowest running costs, with non-consolidating approaches being the most expensive.

To sum up, the research seeks to quantify how effectively microservices architectures can automatically scale in cloud environments by evaluating performance, costs, and energy usage, considering different autoscaling and resource provisioning strategies.