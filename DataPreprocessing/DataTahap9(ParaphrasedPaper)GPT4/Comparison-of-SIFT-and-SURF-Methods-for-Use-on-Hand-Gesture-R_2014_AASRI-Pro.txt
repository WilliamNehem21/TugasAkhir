In this academic paper, the authors present a comparative analysis of two widely utilized feature extraction techniques—Scale-Invariant Feature Transform (SIFT) and Speeded Up Robust Features (SURF)—by testing them on a series of depth maps that capture ten specific left-hand gestures using a Microsoft Kinect camera. These depth maps are then utilized for gesture classification via a Support Vector Machine (SVM), with the study's outcomes focusing on the accuracy of SVM predictions based on the extracted feature vectors.

The initial portion of the paper outlines the theory underlying SIFT and SURF descriptors, followed by a detailed description of the experiment. Concluding remarks are provided at the end of the paper.

A database of depth images is generated for the experiment, with SIFT and SURF applied to these images to obtain feature vectors. These vectors are partitioned into training and testing sets. The SVM model is trained with the training set, and the testing set is used for the final prediction. The experiment's results report the prediction accuracies for all images evaluated using both SIFT and SURF.

SIFT is highlighted as a commonly used local visual descriptor, functioning in a two-step process: first, detecting feature points, and second, describing features. Initially, pixel gradients' magnitudes and orientations are computed in the key point's vicinity at a scale relative to the key point, influencing the choice of Gaussian kernel for image blurring. A normalized feature vector is then created based on orientation histograms within sub-regions surrounding the feature point.

The paper discusses that capturing and segmenting a color image of the hand can be computationally intensive. Traditional segmentation methods focusing on skin color often face variability due to lighting conditions and individual skin tones. However, the Microsoft Kinect camera, which operates within the infrared spectrum, circumvents these issues with its capacity to track body parts independently of lighting conditions and skin color.

The results indicate a notable disadvantage of the SIFT descriptor's rotational invariance, particularly when distinguishing between hand gestures that share similar shapes but appear in different orientations, such as gestures 1 and 5. Although these gestures hold distinct meanings, they are often misinterpreted as identical due to their rotational similarity. Similarly, gestures 7 and 2, while not identical in shape, exhibit sufficient resemblance to cause classification errors.

Overall, the paper provides an insightful analysis into the practical application and effectiveness of SIFT and SURF feature extraction methods when used in conjunction with SVM classification on depth map data for hand gesture recognition, using the Microsoft Kinect camera system.