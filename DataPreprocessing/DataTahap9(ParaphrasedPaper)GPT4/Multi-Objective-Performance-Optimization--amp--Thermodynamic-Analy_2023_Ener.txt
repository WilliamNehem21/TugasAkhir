The study conducted by Siddique et al. looked into the prediction of net power output from a Combined Cycle Power Plant (CCPP) using six years of data, with particular parameters including temperature, humidity, and pressure as inputs. The performance of five different machine learning algorithms was compared for this task, with the Gradient Boosted Regression Tree model outperforming the others, achieving the lowest RMSE and AE when utilizing 450 trees.

Tufekci et al. created a model for predicting the hourly energy production for the next day in a base load operated CCPP using Bagging technique with REPtree predictor, demonstrating the model's feasibility.

Wang et al. introduced a novel machine learning-based method to predict and optimize the operational performance of Organic Rankine Cycles (ORC). Both Back Propagation Neural Network (BPNN) and Support Vector Regression (SVR) models were found to provide accurate predictions, signifying successful research and effective models, with SVR additionally improving cycle parameter prediction.

The key contribution of this study involves a detailed examination and optimization of the operating conditions for supercritical CO2 (sCO2) Brayton cycles, with a focus on mean cycle inlet temperature (MCIT), turbine inlet temperature (TIT), and climate. This was accomplished through advanced machine learning algorithms and optimization frameworks using Genetic Algorithm (GA). This research highlighted the importance of optimizing machine learning model hyperparameters, especially for Artificial Neural Networks (ANN), to achieve optimal modeling and prediction performance.

The study presented a systematic investigation of design improvements for sCO2 Brayton cycles, like the potential integration of a pre-compressor for recompression cycles, and the impact of various factors including climate conditions on system performance. ANN models were emphasized for their ability to quickly adapt and manage complex systems, with a recommendation that they be used alongside thermodynamic models for optimal results. To refine design parameters, Multi-Objective GA was combined with the best machine learning model, and MATLAB software, with the solver `ga` from the Genetic Algorithm and Direct Search Toolbox, was used.

The research involved training six machine learning algorithms: XGBoost, Random Forest, LightGBM, AdaBoost, KNN, and ANN. The best model was selected based on prediction accuracy for the subsequent optimization stage.

XGBoost was explained as a supervised learning algorithm that precisely predicts a target variable by using regression trees as weak learners and reducing an objective function through gradient boosting. Random Forest was depicted as an ensemble learning method using multiple decision trees for accurate predictions, with Optuna library aiding hyperparameter optimization. The KNN algorithm, a proximity-based prediction method, was noted for its increased accuracy using adaptive neighbor and weighting strategies, albeit being time-intensive. The ANN approach employed was a feedforward neural network, using Bayesian regularization (trainbr) as the training method to accommodate difficult datasets and ensure generalization.

In summary, the paper encompasses various machine learning techniques for model training and optimization, emphasizing the integration of machine learning with traditional thermodynamic modeling and the significance of hyperparameter optimization within the context of power generation and thermal performance improvements.