Traditional local algorithms, which often rely on k-nearest neighbors (kNN) for defining the local region around data points, tend to produce subpar results. The kNN approach assumes spherical neighborhoods, which can be problematic for data with non-spherical clusters. Furthermore, selecting the appropriate value for k is challenging, with the required computational resources increasing significantly for large datasets. For instance, a dataset with 1 million samples would necessitate over 7 terabytes of memory, likely exceeding the capabilities of a standard computer and hindering further analysis stages.

Clustering-based methods, like Clustering-Based Local Outlier Factor (CBLOF) and histogram-based outlier score (HBOS), offer alternatives with lower computational and memory demands. These methods, such as those integrated into the Scalable Unsupervised Outlier Detection (SUOD) framework, combine multiple classical detection approaches to handle large, high-dimensional datasets.

The paper introduces a novel detection algorithm, LDNOD, and its complementary framework, LDNOD-KM. The LDNOD algorithm is designed to produce high-quality, robust detection results, while LDNOD-KM, which incorporates k-means clustering, allows for efficient processing of extensive datasets without compromising accuracy.

LDNOD constructs a shared neighborhood for proximate data points based on Dynamic Reverse Nearest Neighbors (DRNN), differentiating it from conventional methods that produce a fixed number of top outliers (top-n). Instead, LDNOD uses a threshold-based approach (LNOF) for determining outliers. This method scores local neighborhoods rather than individual data points, enhancing both efficiency and the ability to detect singular as well as collective outliers.

The algorithm aims for preliminary partitioning of the data into a larger number of segments than the actual number of classes present, enabling more accurate identification of pure partitions and outliers. The parameters for testing the algorithm, such as the J value and LNOF threshold, are fixed for consistency across different datasets, with other baseline methods' parameters set following respective prior research.

The paper concludes that LDNOD demonstrates insensitivity to neighborhood parameters and provides significant time efficiency due to neighborhood sharing and scoring local regions. The hybrid approach combining LDNOD with k-means demonstrates effectiveness in handling large-scale datasets without losing accuracy. Future work will seek to further refine LDNOD-KM for even larger and higher-dimensional datasets.