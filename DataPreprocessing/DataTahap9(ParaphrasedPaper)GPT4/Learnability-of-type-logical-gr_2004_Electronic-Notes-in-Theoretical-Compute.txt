The paper discusses a method for teaching a computer system to understand language by learning both word meanings and structures (lexical assignments) alongside the rules that govern sentence construction (syntactic and semantic categories). This is done within the confines of a specific type-logical grammar, which is a version of the Lambek calculus, a logical system that governs grammar with certain extensions and without unrestricted rules (cut-free). This method ensures that the language generated is finite, avoiding an infinite proliferation of categories.

This type-logical grammar consists of a vocabulary, a function that assigns lexical meanings, and a specific type logic. Modal operators and multiple slash operators, which signify different modes of combining words or phrases, are included in the extended type logic to control how rules apply in different contexts.

A general algorithm has been created to potentially learn any natural language's syntax and lexical assignments. The data used for learning includes sentences paired with their meaning representations in typed lambda calculus. The sentences either have types associated with every meaning subunit or have no types at all. Typed lambda calculus is a standard way to represent how the meanings of words combine to form the meaning of sentences.

The paper includes a proof showing that, given a certain type logic complying with a finiteness condition and a comprehensive set of sample sentences, there exists a limited number of possible lexical assignments to learn. This number is finite even though it may vary depending on the specific language sample and the logic used.

An important finding of the paper is the realisation that the full range of the algorithm cannot learn every conceivable class of grammatical systems, contrary to the claims of an earlier version of this work. However, valuable subsets of natural languages can still be inferred from the data through the learning algorithm, suggesting that natural languages are indeed learnable using this approach.

The key to learnability, according to the paper, lies in avoiding infinite ambiguity in lexical assignments by selecting the most unified options with the smallest number of elements, ensuring that a language can only be generated in one specific way rather than multiple, potentially infinite ways. This approach identifies the classes of grammars within the algorithm that are practical and capable of generating real-world natural languages.