This paper discusses an approach to semantic dependency analysis (SDA) for the Chinese language, emphasizing the integration of multiple classifiers—namely, a Naive Bayesian classifier, a Decision Tree, and a Maximum Entropy classifier—using a "majority wins" voting system. The classifiers were trained on a manually annotated subset of the Penn Chinese Treebank and collectively determined semantic relations in test data by selecting the relation with the most votes. This method yielded an 86% accuracy rate, highlighting its promise for Chinese SDA tasks.

Significant research has been performed for European languages, particularly English, in building annotated resources like FrameNet and PropBank. However, Chinese has seen less research due in part to the scarcity of publicly available, semantically annotated corpora, though there have been efforts to create them.

The paper emphasizes that SDA, which builds complete sentence dependency trees, is distinct and broader than Semantic Role Labeling (SRL), which focuses on semantic relationships surrounding the main verb only.

The researchers used a majority voting method to choose the optimal semantic relations, with their experiments showing that this simple approach outperformed more complex probabilistic selection methods and single classifier models.

A semantic dependency relation tag set was imported from HowNet, a Chinese lexical database that organizes lexical knowledge semantically and in relation to English.

Due to the limited availability of annotated Chinese corpora, the authors annotated a segment of the Penn Chinese Treebank with headwords and semantic relations according to dependency grammar, resulting in a data set they used to train and test their models.

The paper concludes that using a multi-classifier system can improve semantic relation assignment between headword-dependent pairs. The integration of multiple classifiers can mitigate individual classifier weaknesses and increase overall accuracy.

Moving forward, the authors suggest expanding the corpus to validate results further and exploring the potential of new classifiers, such as Support Vector Machines, as well as experimenting with different feature sets and classifier combinations.