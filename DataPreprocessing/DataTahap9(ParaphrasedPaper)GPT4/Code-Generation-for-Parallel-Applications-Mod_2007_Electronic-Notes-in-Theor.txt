In this paper, the authors present a method for developing parallel applications using Object-Based Graph Grammars (OBGG), a formal visual language designed for specifying concurrent systems reliant on asynchronous message passing. OBGG's implicit parallelism, supported non-determinism, and relatively simple learning curve make it an effective tool for designers to create high-level models of parallel applications.

The core proposal is to use OBGG to model parallel applications and then automatically generate corresponding C code that uses the Message Passing Interface (MPI) suitable for cluster environments. By incorporating model-checking into the development process, functional properties of the OBGG model can be verified early on, which streamlines debugging and reduces overall development time. The authors illustrate their approach with a sample parallel application modeled in OBGG, verified through model-checking, and then translated to a C/MPI implementation. This translation creates the foundation for performance analysis and practical application.

The paper also discusses how OBGG can be supplemented with design patterns to offer an extensible approach to building parallel programs. Furthermore, it outlines how to handle OBGG rules, messages, object attributes, and model termination. Attributes can be primitive or user-defined under certain conditions, and all object rule actions are atomic. Translation to Promela, the input language for the SPIN model checker, is provided to verify the model with temporal logic specifications.

In terms of implementation, OBGG objects are mapped to MPI processes, messages are sent using C data structures, and a special protocol detects when there are no more possible matches, signaling all processes to terminate. However, the non-deterministic nature of OBGG means performance can suffer due to the overhead of handling message lists and matches.

Performance evaluations of the generated applications demonstrate the trade-off between programming abstraction and execution efficiency. The high level of abstraction offered by OBGG can lead to performance penalties, but further optimizations are proposed to mitigate these drawbacks, such as defining multiple MPI message types to reduce overhead.