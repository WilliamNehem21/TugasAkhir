This paper discusses the phenomenon of dual degeneracy in linear programming (LP) solutions and its implications on the search process used in solving mixed-integer programs. Dual degeneracy occurs when a dual solution has a corresponding primal non-basic variable with a zero reduced cost, and it indicates the possibility of multiple optimal solutions to the LP.

The authors structure the paper by first defining dual degeneracy and its measures. They analyze its prevalence at the root node of the branch-and-bound tree using a collection of benchmark instances and then assess how degeneracy evolves during the search process. They find that the average degree of dual degeneracy remains relatively constant across different levels of the tree and explore the impact of dual degeneracy on potential branching variable selection.

Through their computational experiments, carried out on a cluster with 48 nodes equipped with Intel Xeon Gold 5122 CPUs, they observed that out of 496 instances, many revealed a significant degree of dual degeneracy after the root node preprocessing and cutting plane phase. The instances had wide-ranging rates of degeneracy, with a notable number showing either very high or very low rates.

The paper posits that dual degeneracy significantly affects the branching variable selection process, as variables that can change to an integer value within the set of optimal solutions are poor candidates for branching, leading to less improvement in the dual bound.

Finally, the authors recommend that solvers consider the implications of dual degeneracy when selecting branching variables, and they suggest that high dual degeneracy often coincides with a greater number of possible branching variables that may reach integer values in alternative optimal LP solutions.