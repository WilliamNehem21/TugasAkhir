Earlier research has treated fault detection as a semantic segmentation task, lacking exploration into the relationships among faults and the construction of a spatial and topological fault structure. To decrease manual labor costs and enhance fault detection efficacy, we propose the use of instance segmentation. Unlike semantic segmentation, which differentiates between faults and non-fault areas, instance segmentation uniquely identifies and labels different fault instances (e.g., fault 1, fault 2, etc.).

We borrow concepts from video instance segmentation due to the temporal continuity in video data and the spatial continuity in seismic data. Video object segmentation can be split into propagation-based and detection-based methods. Propagation-based techniques utilize the temporal connections of object motion, while detection-based methods learn an object's appearance from annotated frames and detect it across all frames.

Our method blends these two approaches, implementing fault segmentation based on a reference profile and tracking from prior profiles. We've created a set of 3D fault instance segmentation labels from synthetic seismic data as per Wu (2019), and used them for training a mask propagation neural network. This process iteratively handles fault instance segmentation within a user-defined range and presents the reconstructed fault outcome. 

Employing a convolutional neural network with multiple inputs and a multi-level encoder-decoder architecture, we learn the distribution and combination rules of fault instances between adjacent and reference profiles. The reference profile is pre-marked with faults and used as a baseline, while marks from adjacent profiles are transferred progressively. This method not only identifies faults but also describes the inter-fault relationships, facilitating more effective fault interpretations.

The network employs two main streams: the reference stream, which focuses on the preset fault marks in a reference profile, and the target stream, which aims to specify and locate faults in new profiles using key previously determined locations. Both streams use a multi-level encoder built upon ResNet50 architecture and a global convolution block to synthesize features between the streams. The decoding layers, equipped with up-sampling and skip connections, ultimately generate the fault instance segmentation mask for the target profile.

During training, if we select the p^th profile as the reference and the t^th profile as the target, the reference stream retains the p^th profile and its fault mask. The target stream then includes the t^th profile and the (t-1)^th fault mask. The neural network processes these streams to output the fault mask for the t^th profile, which is then used as the previous fault mask in the target stream for subsequent iterations. We process 32 adjacent profiles as a single data set and train 256 such data sets for 100 epochs.