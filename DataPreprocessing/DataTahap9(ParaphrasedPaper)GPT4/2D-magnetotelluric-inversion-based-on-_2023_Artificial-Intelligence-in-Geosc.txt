In this research, the authors explore the application of deep learning, specifically the use of convolutional neural networks (CNNs), to address the inversion of two-dimensional magnetotelluric (MT) data. Unlike traditional linear iterative inversion methods, the CNN-based approach does not depend on choosing initial model parameters and avoids becoming trapped in local optima. However, CNN inversion models can sometimes predict abrupt electrical interfaces which may not accurately reflect true underground conditions.

To address this, the study introduces a neural network with a residual architecture, ResNet-50, ensuring appropriate training using apparent resistivity and phase pseudo-section data as inputs and resistivity parameters of the geoelectric model as labels. Experiments demonstrated that training the ResNet-50 with a dice loss function mitigated issues of over-segmentation by the cross-entropy function, provided smoother inversions, and improved computational efficiency compared to iterative methods. These benefits were validated with MT data from a geothermal field survey in Huanggang, Hubei Province, suggesting that deep learning has significant potential for MT data inversion.

The paper contextualizes this work within the broader field of nonlinear inversion methods, such as simulated annealing, genetic algorithms, particle swarm optimization, and Bayesian inversion, which have been successfully applied to electromagnetic fields. It mentions previous applications of artificial neural networks (ANNs) to two-dimensional MT inversion, supporting the relevancy of artificial intelligence to this domain.

The authors also address various deep learning-based methods in geophysical prospecting, including applications to resistivity data inversion, subsurface conductivity layer estimation with electromagnetic induction (EMI) data, and imaging of time-domain airborne electromagnetic data. Additionally, they discuss the use of deep learning for seismic full-waveform inversion and other fields like gravity and magnetism, noting the high computational efficiency and accuracy of such methods.

The paper covers activation functions and their respective advantages and disadvantages, such as sigmoid, tanh, and ReLU, along with the role of convolution layers, pooling operations (maximum and average pooling), and the importance of a loss function in training models.

To generate diverse and representative training samples, a production strategy uses permutations and combinations of various resistivity values and geoelectric model characteristics while adding noise to increase realism. This is necessary due to the computational cost and the challenge of modeling observation data, which often contains noise and inaccuracies leading to multiple potential inversion solutions.

The collaboration aspect is highlighted, with Ningbo Bai contributing theoretical understanding and formula revisions, Bo Han providing supervision and methodological support, and Xiangyun Hu supplying data and conceptual improvements.