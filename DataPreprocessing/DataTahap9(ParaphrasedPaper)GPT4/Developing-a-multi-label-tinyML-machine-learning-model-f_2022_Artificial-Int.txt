Alipio et al. (2017) explored the use of a Bayesian Network (BN) to automatically adjust factors in hydroponic agriculture, including light intensity, soil pH, water temperature, and humidity to optimize plant growth. Their approach enhanced production by approximately 66.67% compared to traditional manual methods. However, BNs typically provide probability density functions rather than specific parameter estimates, which led the researchers to include an extra output neuron activated through a sigmoid function to generate values between 0 and 1.

The researchers trained their model for 250 epochs with batches of 2048 samples using the Adam optimizer and a categorical cross-entropy loss function. They tracked the model's performance across both training and validation datasets by evaluating the loss and accuracy after each epoch.

Experiments indicated that adding neurons to the Multilayer Perceptron (MLP) architecture generally improved model performance, as this allowed for the modeling of more complex data patterns. Conversely, simpler models underperformed on complex datasets due to an insufficient number of trainable parameters. Models were denoted as model(i) for single-layer or model(i, j) for two-layer architectures, where i and j represent the number of neurons in the respective layers.

The study found that the most complex model tested (model(7,8)) demonstrated a mean loss convergence to 0.16 and a mean accuracy of 0.97, with no significant difference between training and cross-validation results, indicating no underfitting or overfitting issues. The model also performed well on a separate test set.

The goal was to design an efficient TinyML (machine learning for devices with limited computational power) solution for autonomous greenhouse climate control using an MLP and considering multiple sensing variables. Ninety different MLP models were trained using a five-fold cross-validation on a balanced dataset to identify the optimal model from a performance metric standpoint. From a TinyML perspective, the researchers prioritized the model with the fewest parameters to optimize computational efficiency.

While the performance metrics achieved were considered satisfactory, the researchers proposed two potential avenues for improvement: a model-centric approach focusing on adjusting the model's parameters and hyperparameters, and a data-centric approach concentrating on collecting additional, higher-quality data for training.