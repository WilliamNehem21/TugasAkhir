Transforming arbitrary propositional formulas into Conjunctive Normal Form (CNF) while keeping the same number of propositional variables leads to potentially exponential growth in the size of the formula. To manage this, verification systems usually use transformations that are satisfiability-preserving, which involve adding a manageable number of auxiliary variables to keep the encoding size linear. However, this method has the trade-off of causing the search space to potentially grow exponentially when backtracking is required during search processes. Remarkably, this significant growth can often be circumvented because the Davis-Putnam-Loveland-Logemann (DPLL) procedure for finding satisfying assignments generalizes well to Zero-One Linear Constraint Systems (ZOLCS), allowing the encoding of complex systems, such as gate-level netlists, in a linear-sized format without the need for auxiliary variables.

These encoding techniques create many structurally similar sub-formulas, particularly when repeatedly applying the transition relation or when simulating continuous evolution in repetitive system unrollings. An example of such a technique is given, which is like what has been used in previous work on bounded model checking (BMC) of linear hybrid automata.

Classic DPLL algorithms often encounter an issue known as thrashing, which is when the same problem repeatedly causes the algorithm to fail. Modern SAT solvers address this by employing conflict-driven learning, which involves identifying general reasons for conflicts, deducing a minimal set of assignments that led to the conflict, and storing this information as a new clause in the database to guide future searches. Additionally, past the basic DPLL procedure, modern solvers enhance decision-making with sophisticated heuristics, non-chronological backtracking, employ random restarts, and use lazy clause evaluation, all contributing to more efficient searches.

During the solving process, if no Boolean conflict arises after the deduction phase, the SAT solver checks if there have been any additions to the linear program. If there are new constraints, the solver calls the linear programming routine to assess their feasibility. If the linear program finds inconsistencies, it feeds back a conflict to the SAT solver; otherwise, the solver can proceed to the next decision step.

However, BMC isn't entirely symmetric due to initialization properties and possibly the verification goal, which could lead to constraints on the replication of learned conflict clauses. Dependencies on asymmetric parts of a formula are controlled through marking the related predicates, thereby avoiding incorrect inferences in iterative processes.

For incremental BMC, where longer paths in the system are checked over time, a large number of clauses are shared between consecutive unrollings. From one step to another (from the k-instance to the k+1-instance), the conflict clauses discovered at the k-instance can be conjoined to the formula of the next step, as long as they came from clauses present in both. Currently, a conflict clause is included if inferred only from automaton clauses, excluding the verification goal. Proposals for more sophisticated methods to decide on clause inclusion have been researched in the realm of propositional BMC.