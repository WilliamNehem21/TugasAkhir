The paper discusses the growing traffic challenges associated with urban development and vehicle proliferation, such as congestion, violations, theft, and criminal activity. To address these issues, various systems like autonomous driving technologies, traffic surveillance, and vehicle tracking and speed detection have been developed. Of particular importance is the License Plate Detection and Recognition (LPDR) technology, which is crucial for intelligent transport systems involved in electronic payments for tolls, parking, and public transit.

LPDR systems involve three primary steps: image pre-processing (color space conversion, resizing, noise reduction), license plate localization (identifying potential plate regions using image features), and Optical Character Recognition (OCR) for reading plate numbers. Despite the research, limitations still exist mostly due to problems with lighting, complex scenes, and distortions affecting license plates, as well as the wide range of character shapes and styles across different countries.

The paper introduces an efficient and budget-friendly automatic LPDR system divided into two main stages: license plate localization and character recognition. The localization uses two-dimensional wavelet decomposition (2D-WD) to detect vertical edges in an image, where plates are identified by a high density of these edges. The accuracy of plate candidates is enhanced using a trained Convolutional Neural Network (CNN) classifier. In the character recognition stage, characters are segmented by identifying the spaces between them, and classified using another CNN.

The system prioritizes license plate detection efficiency, employing vertical edges for locating license plate candidates, which are then verified through CNN classification after entropy-based methods determine the regions of high edge density. The process also utilizes morphological operations to refine the binary images.

The paper elaborates on the classification process, where pre-trained CNN models minimize the need for large datasets. The CNN models are re-trained with specific datasets for both detection and recognition purposes. They exhibit improved accuracy and reduced processing time compared to other methods by focusing on selected features extraction and leveraging the entropy function for identifying potential regions.

The work was contributed by Ibtissam Slimani, Abdelmoghit Zaarane, Wahban Al Okaishi, Issam Atouf, and Abdellatif Hamdoun, each bringing expertise in conceptualization, methodology, resources, software, writing, editing, investigation, validation, and supervision.