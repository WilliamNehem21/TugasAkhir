The academic paper discusses methods to improve the performance of one-stage object detectors when they are applied to different, unseen domains—a process known as domain adaptation. This is a challenge as one-stage detectors like YOLO and SSD predict object locations and classes all at once, which is different from two-stage detectors that first propose regions and then classify them.

In previous work, domain adaptation for two-stage detectors has often relied upon adversarial discriminative methods, which align features at multiple levels. Example techniques include aligning features at image and instance levels. However, applying the same methods to one-stage detectors is not straightforward due to their concurrent bounding box and class prediction.

To improve domain adaptation for one-stage detectors, the paper introduces a method that combines adversarial generative methods and self-supervision-based methods. Adversarial generative methods are able to use accurate labels from the source domain, while self-supervision-based methods take advantage of unlabeled original target images. By merging these methods, specifically Domain Transfer (DT) and Weak Self-Training (WST), researchers can better train one-stage detectors with unlabeled data. DT transfers annotated images from the source to the target domain, whereas WST minimizes the impact of inaccurate pseudo-labels during training.

The study utilizes a Single Shot Multibox Detector (SSD), which is a representative one-stage detector known for its simplicity and balance between inference speed and performance. The SSD's performance on the task was compared using various datasets—Clipart1k, Watercolor2k, and Comic2k—that represent different domains with differing levels of variance from the source domain.

The researchers found that the effectiveness of the adversarial generative method, DT, varied depending on the dataset. While DT performed less effectively with the Watercolor2k dataset, it did better with Clipart1k and Comic2k. The performance differences were attributed to the magnitude of domain shift between the adapted and target images, measured by the Fréchet Inception Distance (FID).

In conclusion, the paper provides a novel approach to unsupervised domain adaptation for one-stage detectors by uniting adversarial generative and self-supervision-based methods, and demonstrates its effectiveness in training SSD models for object detection across different domains without requiring labeled target data.