This academic paper discusses an autonomous vision navigation system developed for a small mobile robot, Adept MobileRobots PT 3-AT, designed to navigate known outdoor routes. The system features a recognition module, stop line and zebra crossing detection, an obstacle sensing module, a control module, and a communication module. Utilizing multi-threading technology, the system synchronizes various modules within a control cycle and leverages an automatic state machine to switch between control modes. According to the paper, the robot is capable of autonomously cruising along predetermined paths and is stable under favorable lighting conditions.

Unlike larger intelligent vehicles, small intelligent mobile robots encounter unique challenges like lower image stability, control precision, and a limited camera angle view. This necessitates higher accuracy in environmental awareness and the integration of multi-sensor data for effective self-control. These robots excel in tasks such as environmental exploration and autonomous cruising.

The paper outlines the system which includes a finite state machine (FSM) with different states such as straight traveling, turning, and road finding, and outlines a strategy for manual control mode activation. Distinct road-edge detection algorithms are presented for unstructured or poorly defined roads involving color-based and grayscale segmentation. For structured roads, another color-based algorithm identifies lane lines. The deviations in distance and angle from the correct path are calculated via inverse affine transformation.

To enhance turning accuracy and adapt to different environments, the system employs high-contrast signs recognized through a combination of HSV color threshold segmentation, edge detection, RANSAC ellipse fitting, and misrecognition filtering. These signs help the robot to switch from straight traveling to turning at the correct points.

Since a monocular camera is used for vision sensing, there are slight deviations in distance estimation which pose challenges for control strategy. The robot's coordinate system is detailed, along with the definitions for distance and angle deviations. These deviations feed into a fuzzy control system, which processes the information to determine the robot's angular velocity.

The paper highlights a comparison between deviation data from inertial navigation and vision navigation, choosing the most reliable source. During turns, image recognition is less reliable due to vibration, so the system relies on predefined turning points and angles determined through experimentation.

Post-turn, the robot employs a path-finding strategy, searching within a 45-degree angle range to find the correct path. Simulation tests with the robot revealed that a fuzzy controller helped reduce oscillation and provided a more stable correction process.

The conclusion of the paper is that the combination of computer vision, pattern recognition, and fuzzy control technologies enables intelligent visual navigation on small robot platforms. With a limited number of states, the system manages the robot's travel, coordinates with other modules effectively, and through experimentation on six known roads, the paper demonstrates that fuzzy controllers and inertial navigation can significantly enhance the stability of vision navigation. The experiments confirm that with adequate lighting, the small mobile robot can successfully perform automatic cruising on diverse outdoor road types.