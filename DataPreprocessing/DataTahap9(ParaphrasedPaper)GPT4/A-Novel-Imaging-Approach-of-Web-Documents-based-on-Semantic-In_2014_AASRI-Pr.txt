This paper introduces a new methodology for image-based search engine results using a technique termed Semantic Inclusion of Images and Textual (SIIT) segments. The intention behind SIIT is to improve search results by providing a concise web document that semantically links images with text. The process of creating such documents involves three steps: extracting images and text from the main content of web pages, analyzing images to derive semantic descriptions of objects within them, and linguistically linking these images with textual segments.

L.P. Florence has developed a tool called TNT, which enhances text mining by factoring in images and their associated annotations, restructuring the text in relation to these visual elements.

In applying this approach, simpler methods like character counting proved ineffective for content-heavy web pages or dynamic sites utilizing extensive text for drop-down menus and other interactive elements, often manipulated with JavaScript. To better differentiate relevant text from non-essential strings, a natural language approach using full sentence counting was adopted, relying on the structural characteristics of sentences punctuated with appropriate end markers.

The testing of the proposed algorithm on a sample set of documents yielded an 88.99% success rate for text extraction. Image extraction success was contingent upon accurately identifying the main content block of the web document.

For the image analysis aspect, first, images were processed with an SVM model, followed by segmentation into three parts using k-means clustering, based on elements (like water, trees, and sky) identified within the image. SIFT descriptors were then used to extract features from these segments, with a modification threshold set between 5 to 8 pixels, based on findings from previous research. This threshold was limited as the test image did not yield vectors longer than eight pixels, making higher thresholds unnecessary.