This paper discusses the examination of reduction incorporated (RI) automata in relation to given grammars, particularly highlighting the balance between automaton size and stack activity during runtime. By using examples from ANSI-C, IBM VS-COBOL, and Pascal, the authors reveal that small adjustments in the level of stack activity suppression can lead to significant reductions in automaton size without greatly affecting runtime stack activity. The paper outlines heuristics to help specify these automata and mentions the development of a tool aimed at optimizing RI automaton size automatically.

The study considers the limitations of nesting levels in grammars, pointing out that while regular grammars for languages with bracket nesting can be written with a finite maximum nesting level through enumeration, the rapid growth in the size of such grammars necessitates a low nesting level limit.

Separating regular grammar portions from truly context-free parts—that is, those containing fully embedded recursion—is proposed as a more appealing approach, and RI parsing is presented as a technology that achieves this separation.

The authors also introduce their closely-related RIGLR (Reduction Incorporated Generalized LR) algorithm, which permits the use of fully general context-free grammars. This algorithm differs from Aycock and Horspool's original RI algorithm by allowing hidden left recursion and explaining an alternative automaton construction process.

The paper goes on to detail experiments highlighting the effects of small changes in grammar terminalization on RI automata size and parsing time. These experiments suggest that overall characterizations of the RI automata space will become clearer once automated tools have been completed.

One discussion point is the delineation between lexical analyzers, which utilize regular sets over characters to produce tokens, and parsers, which perform context-free matching on the token stream. This division is noted as advantageous for performance, error reporting, and reduced non-determinism in grammars.

The authors also note that automaton size reduction can be achieved by adding extra terminalizations within the grammar. Through experimentation, they expect that by breaking a chain of nonterminals and inserting an additional terminalization, the size of the automaton will be most significantly reduced when the change occurs around the midpoint of the chain.

Lastly, the paper discusses how COBOL's clear rule structure makes it amenable to manual grammar adjustments, while the more intertwined rule systems of C and Pascal make manual intervention less effective. Profiling is suggested as a method to identify effective terminalizations for these languages.

The work is attributed to Adrian Johnstone, Elizabeth Scott, and Giorgios Economopoulos, as presented at the 4th Workshop on Language Descriptions, Tools, and Applications (LDTA 2004) and published in the Electronic Notes in Theoretical Computer Science by Elsevier in 2004.