Software Visualization (SV) tools are designed to be used at the beginning stages of a programmer's education, aimed at teaching programming fundamentals, algorithms, and the software development process. SV tools employ graphics or animations to convey critical information. While these visual methods are thought to be helpful, prior assessments of SV tools reveal that they don't substantially enhance learning outcomes. However, some studies indicate they do increase student motivation when learning algorithms or basic programming concepts.

The educational benefits of using Jeliot 2000 (a precursor to Jeliot 3) were examined by Ben-Bassat Levy et al. against using an Integrated Development Environment (IDE), Turbo Pascal, for program tracing. In their study involving high schoolers in a beginner's programming class, two groups emerged. Both groups attended identical lectures; however, during lab sessions, one group utilized Jeliot 2000, and the other Turbo Pascal.

The research presented Jeliot 2000 as a practical model for program execution that was easily understood and traced by students. But it was either too basic or too intricate for the very strongest or weakest students, thus not benefiting them significantly. In a separate study, 35 students in their second programming course, using Jeliot 3, provided qualitative feedback. They reflected on using the tool for programming and debugging tasks. This study identified challenges faced by students with prior programming experience and those new to Jeliot 3. Again, novice students responded more favorably towards the tool.

Kehoe et al. proposed that algorithm animation tools' effectiveness might be better measured through interactive use, such as with homework assignments, and should be simultaneously delivered with corresponding instruction. In a meta-study, the focus was on the method of presenting the animation to students rather than the content itself.

Students generally adopted an iterative approach for completing tasks: reading instructions, writing methods, and creating and running short tests. Initial iterations were part of learning, and later iterations had a clearer debugging focus. Using Jeliot 3, students visualized and identified bugs.

Lab observations showed that complete beginners had common behavior patterns. Students had two goals: to pragmatically finish the course by completing the tasks and to understand the methods behind their solutions. Regardless of whether using Jeliot 3 animations or a standard Java console output, students didn't utilize these resources to grasp programming basics unless they were explicitly instructed to do so.

Students struggled to comprehend compound assignments like 'a+=3;'. For those using Jeliot 3, the animated steps were not clear until explanations were provided.

Initial findings suggest that Jeliot 3 animations can be challenging for novices to understand, and knowledge transfer from the tool to student isn't successfulâ€”even for those who received direct explanations of the animations. Nonetheless, both groups deemed animation assistance helpful for debugging programs. Additionally, Jeliot 3 was considered user-friendly, and most who began using it continued to do so.