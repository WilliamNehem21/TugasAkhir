Original Article
A machine learning framework for sport result prediction
Rory P. Bunkera, Fadi Thabtahb,⇑
aAuckland University of Technology, Auckland, New Zealand
bApplied Business, Nelson Marlborough Institute of Technology, Auckland, New Zealand
article info
Article history:Received 4 May 2017Revised 8 September 2017Accepted 16 September 2017Available online 19 September 2017Keywords:Machine learningEvent forecastingData miningSport result predictionabstract
Machine learning (ML) is one of the intelligent methodologies that have shown promising results in thedomains of classiﬁcation and prediction. One of the expanding areas necessitating good predictive accu-racy is sport prediction, due to the large monetary amounts involved in betting. In addition, club man-agers and owners are striving for classiﬁcation models so that they can understand and formulatestrategies needed to win matches. These models are based on numerous factors involved in the games,such as the results of historical matches, player performance indicators, and opposition information.This paper provides a critical analysis of the literature in ML, focusing on the application of ArtiﬁcialNeural Network (ANN) to sport results prediction. In doing so, we identify the learning methodologiesutilised, data sources, appropriate means of model evaluation, and speciﬁc challenges of predicting sportresults. This then leads us to propose a novel sport prediction framework through which ML can be usedas a learning strategy. Our research will hopefully be informative and of use to those performing futureresearch in this application area./C2112017 The Authors. Production and hosting by Elsevier B.V. on behalf of King Saud University. This is anopen access article under the CC BY-NC-ND license ( http://creativecommons.org/licenses/by-nc-nd/4.0/ ).
1. IntroductionOne of the common machine learning (ML) tasks, whichinvolves predicting a target variable in previously unseen data, isclassiﬁcation[28,1]. The aim of classiﬁcation is to predict a targetvariable (class) by building a classiﬁcation model based on a train-ing dataset, and then utilizing that model to predict the value ofthe class of test data[45]. This type of data processing is calledsupervised learning since the data processing phase is guidedtoward the class variable while building the model (see Fig. 1) [41]. Some common applications for classiﬁcation include loanapproval, medical diagnoses, email ﬁltering, among others [2,42]. Sport prediction is usually treated as a classiﬁcation problem,with one class (win, lose, or draw) to be predicted [33]. Although some researchers e.g.[7], have also looked at the numeric predic-tion problem, where they predict the winning margin – a numericvalue. In sport prediction, large numbers of features can be col-lected including the historical performance of the teams, resultsof matches, and data on players, to help different stakeholdersunderstand the odds of winning or losing forthcoming matches.The decision of which team is likely to win is important becauseof the ﬁnancial assets involved in the betting process; thus book-makers, fans, and potential bidders are all interested in approxi-mating the odds of a game in advance [9]. Once a predicted result for the match is obtained, an additional problem is to thendecide whether to bet on the match, given the bookmaker’s odds.In addition, sport managers are striving to model appropriatestrategies that can work well for assessing the potential opponentin a match[31]. Therefore, the challenge of predicting sport resultsis something that has long been of interest to different stakehold-ers, including the media. The increasing amount of data related tosports that is now electronically (and often publically) available,has meant that there has been an increasing interest in developingintelligent models and prediction systems to forecast the results ofmatches.In this paper, we provide a critical survey of the literature on MLfor sport result prediction, focusing on the use of neural network(NN) for this problem. Several studies in the statistical and opera-tions research literature have previously considered sport resultsprediction, but the use of the NN paradigm for this purpose is amore recent area of study. The powerful NN technique has provento be effective in deriving highly accurate classiﬁcation models inother domains[29]. Discussions on the challenges that arise when
https://doi.org/10.1016/j.aci.2017.09.0052210-8327//C2112017 The Authors. Production and hosting by Elsevier B.V. on behalf of King Saud University.This is an open access article under the CC BY-NC-ND license ( http://creativecommons.org/licenses/by-nc-nd/4.0/ ).⇑Corresponding author.E-mail address:fadi.fayez@nmit.ac.nz(F. Thabtah). Peer review under responsibility of King Saud University.
Production and hosting by ElsevierApplied Computing and Informatics 15 (2019) 27–33
Contents lists available atScienceDirect
Applied Computing and Informatics
journal homepage: www.sciencedirect.com
using these intelligent models for sport results prediction is alsoprovided. Our main contribution is that a CRISP-DM type frame-work for sport result prediction is proposed (SRP-CRISP-DM), basedon the six steps of the standard CRISP-DM framework [38]. This paper serves researchers, sport fans, club managers, bookmakers,academics, and students who are interested in intelligent solutionsbased on NN for the challenging problem of sport results predic-tion. This paper will be of use to those who are interested in pur-suing future research within this application domain.This remainder of this paper is organized as follows. In Section 2, studies that have used ANN exclusively, which was the keyapproach used in earlier research papers in the sport predictionapplication, are reviewed. Section 3then provides critical discus- sion and observations on prior work in this application domain,in the context of the proposed SRP-CRISP-DM framework, conven-tional measures of model performance, and how we propose thatmodel performance should be measured for the problem of sportresults prediction. Finally, Section4concludes the paper.2. Literature review and critical analysisArtiﬁcial Neural Networks (ANNs) [10]are perhaps the most commonly applied approach among ML mechanisms to the sportresult prediction problem. Thus, for this review, we focus on stud-ies that have applied ANNs. An ANN usually contains intercon-nected components (neurons) that transform a set of inputs intoa desired output[45]. SeeFig. 2for an example of an ANN struc-ture. The power of ANN comes from the non-linearity of the hiddenneurons in adjusting weights that contribute to the ﬁnal decision.ANN output often relies on input features and other componentsassociated with the network, such as these weights. The ANNmodel is constructed after processing the training dataset that con-tains the features used to build the ANN classiﬁcation model. Inother words, weights associated with interconnected componentsare continuously changing to accomplish high levels of predictiveaccuracy. These changes are performed by the ANN algorithm tofulﬁll the desired model’s accuracy given earlier by the user. Thismay lead in some cases to the problem of overﬁtting, as well aswasting computing resources such as training time and memory[27]. An appealing feature of ANNs is that they are quite ﬂexiblein terms of how the class variable is deﬁned e.g. whether it is prob-ability of victory e.g.[25], or whether two classes are used e.g. withhome goals and away goals represented in the two different classese.g.[3].Purucker[32]conducted one of the initial studies on predictingresults in the National Football League (NFL) using an ANN model.Data from the ﬁrst eight rounds of the competition and ﬁve fea-tures were used, consisting of yards gained, rushing yards gained,turnover margin, time of possession, and betting line odds. Unsu-pervised methods based on clustering were used to distinguishbetween good and poor teams. An ANN with backward-propagation (BP) was then used[37]. Purucker achieved 61% accu- racy compared with 72% accuracy of the domain experts. The BPalgorithm was found to be the most effective approach. A limita-tion of this study is that only a relatively small number of featureswere used.Kahn[18]extended the work of Purucker[32]and achieved greater accuracy, performing slightly better than experts in theNFL who were making predictions on the same games. Data on208 matches in the 2003 season were collected. The features thatwere used were: total yardage differential, rushing yardage differ-ential, turnover differential, away team indicator and home teamindicator. There were two classes: away team outcome and hometeam outcome – a value of/C01 indicating that the team lost thematch, and a value of +1 indicating that the team won the match.The problem was treated as a classiﬁcation problem. The ﬁrst 192matches were used as the training data set, and the remainingrounds (week 14 and 15) were used as the test set. Through testing,a network structure of 10-3-2 was found to be optimal. Accuracy of75% was achieved across the week 14 and 15 matches. The resultswere compared to the predictions of eight sportscasters fromESPN.com. Across the same matches, the domain experts predictedan average of 63% of matches correctly.McCabe and Trevathan[25]
attempted to predict results in fourdifferent sports: NFL (Rugby League), AFL (Australian Rules foot-ball), Super Rugby (Rugby Union), and English Premier LeagueFootball (EPL) using data back to the year 2002. A multi-layerperceptron, trained with BP and conjugative-gradient algorithmswas used. The ANN had 20 nodes in the input layer, 10 nodes in
Fig. 1.Supervised learning versus unsupervised learning [24].
Fig. 2.Example structure of an ANN with 4 input nodes in the input layer, 5 hiddennodes in the hidden layer and one output node in the output layer [30].28 R.P. Bunker, F. Thabtah / Applied Computing and Informatics 15 (2019) 27–33the hidden layer, and 1 node in the output layer (20-10-1). Fea-tures that were used were the same across all the sports and attri-butes related to speciﬁc events within a rugby or soccer matchwere not considered. The average performance of the ANN algo-rithm in predicting results was around 67.5%, compared withexpert tipster predictions that achieved around 60–65% accuracy.ANN has also been applied by Davoodi and Khanteymoori [6]to predict the results of horse races. The authors used data from 100races at the Aqueduct Race Track held in New York during Januaryof 2010. One ANN was used for each horse in the race, with the out-put being the ﬁnishing time of that horse. Eight features were usedfor the input nodes in each NN. These were horse weight, type ofrace, horse trainer, horse jockey, number of horses in race, race dis-tance, track condition, and weather. This optimal network architec-ture (8-2-1), in terms of mean-squared error, consisted of fourlayers: an input layer (with eight input nodes), two hidden layers,and an output layer (with horse ﬁnishing time). Five differenttraining algorithms were applied to the data: gradient-descentBP (BP), gradient-descent with a momentum parameter (BPM),Levenberg-Marquadt (LM), and conjugate gradient descent (CGD)[37,39,20,46]. It was found that with 400 epochs, the BPM (withmomentum parameter of 0.7) and the BP algorithms were mosteffective at predicting the winner of the race, with BP obtainingan accuracy of 77%. However, the disadvantage of BP was thatthe training time was lengthy (LM had the shortest training time).Tax and Joustra[40]used Dutch football competition data fromthe past 13 years to predict the results of football matches. Theauthors were interested in how a model with betting odds alonecompared with a hybrid model of both betting odds and othermatch features. Importantly, and something that has most oftenbeen missed in previous studies, they mentioned that cross valida-tion is not appropriate for sport prediction because of the time-ordered nature of the data. A structured literature review from sta-tistical and sport science papers was conducted to identify relevantfeatures to include. Principal component analysis (PCA), sequentialforward selection, ReliefF attribute evaluation, and correlationbased feature subset selection were used [16,21,19,11,19]. Nine classiﬁcation algorithms were used in the experimentation, utiliz-ing the machine learning software WEKA, namely naive Bayes,LogitBoost (with decision stumps), NN with BP, Random Forest,CHIRP, FURIA, DTNB, C4.5, and hyper pipes [13,43,14,12,35]. The highest performing classiﬁers on the full feature set were naiveBayes (used with a 3-component PCA), and the ANN (used with a3 or 7-component PCA). Both achieved a classiﬁcation accuracyof 54.7%. In a model including only betting odds features, the high-est accuracy of 55.3% was achieved with the FURIA classiﬁer, andwas slightly higher than the model with the full feature set(although not statistically signiﬁcant). In a hybrid model of thepublic data features with the betting odds features, LogitBoost withReliefF attribute selection provided the highest classiﬁcation accu-racy of 56.1%. The difference between the public data model andthe betting odds model was, however, not statistically signiﬁcantaccording to McNemar’s test. However, this did highlight that bet-ting odds alone can be a reasonable predictor of match outcome.In non-team sports, researchers have used machine learningmodels to predict the performance of the individual player. Forinstance, Maszczyk et al.[23]compared neural networks andnon-linear regression to predict the distance of Javelin throws.The aim of the investigation was to identify the usefulness of neu-ral networks as an athlete recruitment tool, and how this com-pared to the commonly used regression models. The data setconsisted of 70 javelin throws – a training set consisting of 40cases, a validation set consisting of 15 cases, and a test set consist-ing of 15 cases. Their initial statistical analysis using a correlationmatrix and regression analysis found four signiﬁcant predictorsof Javelin throw length: cross step, speciﬁc power of the armsand the trunk, speciﬁc power of the abdominal muscles, and grippower. The numeric class variable used was the average distanceof three throws from a full run-up after a 30 min warm up.Through experimentation, the best architecture in terms of nor-malized root mean squared error, of the neural network was foundto be 4-3-1 (four input neurons/variables, one hidden layer withthree neurons, and one outcome). The javelin throws of 20 javelinthrowers from the Polish national team were predicted using themodels, and were compared with the actual length of the throws.Their results showed that the neural network models offered muchhigher quality of prediction than the nonlinear regression model.The absolute network error was found to be 16.77 m, versus theabsolute regression error of 29.45 m.Edelmann-Nusser et al.[8]investigated modelling the perfor-mance of an elite female swimmer in the ﬁnals of the 200 m back-stroke at the Olympic Games in 2000 in Sydney. Data consisted ofthe performance output of 19 competitions in 200 m backstrokeprior to the Olympics and data from the swimmer’s training period– the last 4 weeks prior to the competition. An MLP with 10 inputneurons, 2 hidden neurons and 1 output neuron was used. Theresults show that the MLP was accurate; the error of the predictionwas only 0.05 s. The MLP was also compared with linear regres-sion, which did not provide as accurate results. This paper as wellas Maszczyk et al.[23]
highlight the potential usefulness formachine learning techniques to be used by high performance staffand analysts in professional sport for identifying the factors tofocus on when developing training programs, not just purely forresult prediction.Wiseman[44]predicted winning PGA golf score based on scoresafter round 1 of a competition. Note that they were predicting win-ning score, not tournament winner itself. The authors comparedthe performance of: linear regression, neural network regression,Bayesian linear regression, decision forest regression and boosteddecision tree regression, in the Microsoft Azure service. Theauthors performed correlation matrix analysis of different featuresand selected Round 1 leading score, round 1 average score, coursepar, major event, course yardage and total prizemoney as the pre-dictors. R-squared value and MSE were used to evaluate algorithmaccuracy. Data from 2004 to 2015 was used to construct the mod-els, and tournaments from 2016 were used to validate them. Linearregression and Bayesian linear regression were the best performingmodels on the 2016 data set, predicting the winning score towithin 3 shots 67% of the time.3. The proposed sport result prediction intelligent frameworkWe would argue that the use of a structured experimentalapproach to the problem of sport results prediction is useful toobtain the best possible results with a given data set. In this sec-tion, an intelligent architecture for sport results prediction is pre-sented, proposing steps of a possible ML framework, anddescribing the characteristics of the data used for sport results pre-diction, and how this ﬁts within the framework. Our framework(Fig. 4) focuses on result prediction for team sports rather thanindividual sport. Our Sport Result Prediction CRISP-DM frameworkor SRP-CRISP-DM framework consists of six main steps, based onthe steps of the standard CRISP-DM ( Fig. 3) framework[38].3.1. Domain understandingDomain understanding includes comprehending the problem,the goal of the modelling, and the speciﬁc characteristics of thesport itself. This involves having some understanding of how thesport is played and what factors are potentially involved in deter-mining the outcome of matches. This could be obtained throughR.P. Bunker, F. Thabtah / Applied Computing and Informatics 15 (2019) 27–33 29personal knowledge of the sport or obtained by surveying existingliterature or by consulting experts in the sport.There also needs to be clarity regarding the objective of themodel. It could be to predict results to compete with expert predic-tions, online competitions, or it could be to ultimately use theresults of the model to bet on matches. If the predictive model isused for betting, there needs to also be consideration of whichmatches will be bet on. For example, there will likely be somebetting odds threshold where, although the model predicts avictory for that team, the betting odds are so low that the returndoes not warrant betting on that match at all (e.g. if a team ispaying $1.01 to win, meaning that a $100 bet placed would onlyreturn $1).3.2. Data understandingData for sport prediction is often able to be obtained onlinefrom publically available sources. Some prior studies have auto-mated the data collection process, writing scripts that automati-cally extract the online data and then load it into some form ofdatabase. Some studies have also built an end-user interface,where users can input data for an upcoming match and the predic-tion is then generated.The granularity/level of the data is something that needs to beconsidered. Previous studies have generally had training data thatis at the match/team level. It is also possible to include player-leveldata, which contains statistics on the players that have played ineach of the matches. Player level data will generally be containedin a separate data set that would then have to be transposed andjoined with the match level data so that each match has certainplayer statistics as attributes in the data set. Including player leveldata would have the advantage that we can investigate whetherspeciﬁc players’ actions or presence are important for the perfor-mance of the team in terms of whether they win or lose.The deﬁnition of the class variable needs to also be considered.Most prior work has treated the sport prediction problem as a 2 or3 class values classiﬁcation problem (home win, away win) or(home win, draw, away win). Delen et al. [7], also considered the problem as a numeric prediction problem, using regression tech-niques to predict the points margin (home points minus away
Fig. 3.The six phases of the traditional CRISP-DM Model [38].
6. Deploy Model 
 Automate source data extract and data pre-processing if possible 
 Re-train model based on fresh data 
 Generate predictions for upcoming matches 1.Domain Understanding 
 Understand the problem and the objective of the model 
 Understand characteristics of the sport itself 
2. Data Understanding 
 Source data (automate if possible) 
 Consider the level/granularity of the data (whether to include player level data) 
 Decide on the class variable  
3. Data Preparation & Feature Extraction 
 Split original feature set into different subsets (in-play, external, expert-selected, betting odds) 
 Apply feature selection algorithms to select most important variables from original features and feature subsets  
 Preprocess data by averaging in-play variables for a certain match history for each team, and re-merge with the external features 
4. Modelling 
 Select candidate models based on literature survey 
 Experiment with these candidate models on a range of different machine-selected and human-selected feature sets  5. Model Evaluation 
 Select measure of model performance – accuracy is fine if data is not imbalanced 
  Preserve order of instances/matches – Cross-validation is not appropriate to use 
 Decide on training test split – recommend round-by-round split within each season as described. Select best performing model 
Preprocessed data sets 
Fig. 4.Steps of our proposed SRP-CRISP-DM framework.30 R.P. Bunker, F. Thabtah / Applied Computing and Informatics 15 (2019) 27–33points), and then making a win-loss prediction based on the pre-dicted points margin. The authors ultimately found that treatingthe problem as a classiﬁcation resulted in superior results, but thatis not to say that this would be the case on all sports or all datasets.3.3. Data preparation & feature extraction3.3.1. Creating feature subsetsFeatures in sport result data can be divided into several differ-ent subsets. Miljkovic et al.[26], for example, split the features intomatch-related and standings features. Tax and Joustra [40], consid- ered how a hybrid model of betting odds and public data featurescompared with a feature set of betting odds alone. Hucaljuk andRakipovic[15]used a separate expert-selected feature set againsttheir own feature set, to investigate the value of expert opinionfor feature selection. And of course, there are feature sets thatare selected based on feature selection algorithms – either on thefull feature set or a subset of the original feature set. Ideally,researchers should test several different feature selectionapproaches in conjunction with testing their candidate classiﬁca-tion models. Then, as Tax and Joustra [40]did, one can investigate which classiﬁer and feature selection algorithm together producesthe best classiﬁcation accuracy.Hucaljuk and Rakipovic[15]included an expert-selected fea-ture set in addition to their initial feature set. Although this wasnot found to result in improved accuracy, this could depend onthe characteristics of the sport, and perhaps the experts them-selves. Another way that expert opinion can be used is in compar-ing the predictive accuracy of the predictive models, with thepredictions of the experts. To incorporate expert opinion, one couldeither generate an expert-selected feature set to compare withmachine-learned feature selection approaches, or alternatively,compare their model with expert predictions.3.3.2. Data preprocessing: match features versus external featuresThere can be a distinction made between ‘match-related’ and‘external’ features (seeFig. 5). Match-related features relate toactual events within the sport’s match. For example, in footballthese could be meters gained, passes made, and so on [17]. Exter- nal features do not relate to events within the match, that is areexternal to the match itself (e.g. recent form, travel, players avail-able for the match, etc.). This distinction is important for data pre-processing purposes. External features are known prior to theupcoming match to be played. For example, we know the distancethat both teams have travelled and we know both teams’ recentform leading into the upcoming match. Match-related featureshowever, are not known until the match has been played. Thus,we only know an average of these features for a certain numberof past matches for these teams. For example, we would knowthe average passes made per match by both teams prior to thematch, but do not know the actual passes made in the upcomingmatch until after it has been played. This means that only pastaverage statistics for these features can be used to predict anupcoming match. Therefore, match-related features shouldundergo a separate averaging process before being re-merged withthe external features. Buursma[4]followed this process, and found, through experimentation, that using an average across thepast 20 matches resulted in the best classiﬁcation accuracy.3.4. ModellingThe ﬁrst step in the modelling process is to select which candi-date models will be used in the experimentation [34]. This would involve a review of past literature, and identiﬁcation of commonlyapplied predictive models that have previously been successful.Each model can then be trialed on each feature subset, and subsetsthat have been selected by feature selection algorithms. Experi-mentation with these different feature selection methods and clas-siﬁcation models will identify the best combination of classiﬁerand feature selection technique.3.5. Sport prediction model evaluation3.5.1. Measuring model performanceTo evaluate model performance, one would classify matchresults into home wins, away wins and draws (if the sport hasdraws) and then look at the number of matches that the modelhas correctly identiﬁed, using a standard classiﬁcation matrix.There is unlikely to be a great degree of imbalance in the class val-ues for the dataset, although given the commonly observed homeadvantage phenomenon, one is likely to see a slight skew in favorof home wins. In this case, classiﬁcation accuracy is a reasonablemeasure of evaluation. In cases where the data is highly imbal-anced, ROC curve evaluation may be more appropriate.3.5.2. Training and testingAs has been mentioned, it is important to preserve the order ofthe training data for the sport prediction problem, so that upcom-ing matches are predicted based on past matches only. Cross-validation (Fig. 6) generally involves shufﬂing the order of theinstances and therefore is not an appropriate means of splittingthe data into training and testing, for the sport result prediction
problem. A held-out training test split is more appropriate, withthe order of the instances being preserved. Machine learning soft-ware such as WEKA provide the option to preserve the order ofinstances.An appropriate training-test split needs to be decided on. Thismay depend on the amount of data that the researcher has on hand– whether they have only one season of data, or multiple seasons.Usually professional sport competitions are organized in rounds,with teams playing matches over the weekend. Teams usually playone match in each round unless they have a ‘bye’. In the case whereone season of data is on hand, the number of rounds that will beused for training the model, and the number of rounds that willbe used for testing the model needs to be determined. For example,in a data set with 10 rounds of data, the ﬁrst 7 rounds of the com-petition could be used for training the model and the last 3 roundsof the competition could be used for testing the model. However,to obtain a more realistic measure of model performance, round1 could be used as training to test on round 2, round 1 & 2 couldbe used as training to test on round 3, round 1–3 could then beused as training to test on round 4, and so on. So, within a seasonwhich contains a certain number of competition rounds, we userounds 1 to n/C01 to train our model, and use round n as the testdata set, for each round n in N, where N is the total number ofrounds in the competition. We thus obtain a classiﬁcation accuracyfor each of these training/test splits, and take an average of theaccuracies to give an overall measure of model performance.Rather than round-by-round prediction, another possibility is toupdate the training data set after every match has been played. Inthis case, all past matches up to the current match as training data,and the upcoming match as the training data (i.e. only having thatone record as the training data). This is essentially like order-preserved leave-one-out cross-validation. This match-by-matchapproach is probably not necessary unless teams play more thanone match over the same competition round.Some papers have used multiple seasons of data. A commonapproach has been to use earlier seasons as training data, to predictthe later seasons as the test data set. For example, Cao [5]used sea- sons up from 2005/2006 to 2009/2010 were used as the trainingdata, and the 2010/2011 season was used as the test data, to eval-R.P. Bunker, F. Thabtah / Applied Computing and Informatics 15 (2019) 27–33 31uate models that predict basketball match results. Prior seasonsmay not be relevant to predict matches in future seasons, particu-larly in sports where team rosters and strengths can change signif-icantly from year to year. This approach may not give a reliablepicture of model performance (although this could be mitigatedto some extent if player level data is included, and so playerchanges would be captured from season to season). We wouldargue that, although more computationally intensive and labori-ous, our round-by-round training test split approach mentionedabove should be usedwithin each season. An average model classi- ﬁcation accuracy could then be produced for each season, and aplot could be shown of model accuracy by season.3.6. Model deploymentIdeally, one can automate the process so that new round data isobtained from the web, and added to the match database (or other-wise added to the database manually by the end-user). The train-ing data and test data are then adjusted, the model is retrainedwith the new training data, and new matches are predicted. Predic-tions are then returned to the end user. The learning model in theproposed architecture could also be online and dynamically receiv-ing input data prior to the match beginning (external features) andwhile the match is played (match features). It also should be incre-mental in the way that the training data set is continuouslyupdated, and thus the classiﬁer would keep changing to reﬂectthose of the learning environment.4. ConclusionsOne of the vital applications in sport that requires good predic-tive accuracy is match result prediction. Traditionally, the resultsof the matches are predicted using mathematical and statisticalmodels that are often veriﬁed by a domain expert. Due to the speci-ﬁc nature of match-related features to different sports, resultsacross different studies in this application can generally not becompared directly. Despite the increasing use of ML models forsport prediction, more accurate models are needed. This is due tothe high volumes of betting on sport, and for sport managers seek-ing useful knowledge for modelling future matching strategies.Therefore, ML seems an appropriate methodology for sport predic-tion since it generates predictive models that can predict matchresults using predeﬁned features in a historical dataset.This article critically analyses some recent research on sportprediction that have used ANN, and following this, we proposeda sport result prediction ‘SRP-CRISP-DM’ framework for the com-plex problem of sport result prediction. Moreover, challenges fac-ing the sport prediction application were shown to pinpointfuture work for scholars in this important application. Future stud-ies concerning ML in sport result prediction research will hopefullybe beneﬁtted by this study.
Original data or subset Match Related Features 
External Features Averaging process across past matches 
Pre-processed data 
Fig. 5.Match-Related statistics should go through an averaging process across a certain number of historical matches for each team, and then be re-merged wi th the external match features.
Fig. 6.Diagrammatic representation of 10-fold Cross-Validation [36].32 R.P. Bunker, F. Thabtah / Applied Computing and Informatics 15 (2019) 27–33References
[1]N. Abdelhamid, A. Ayesh, F. Thabtah, S. Ahmadi, W. Hadi, MAC: A multiclassassociative classiﬁcation algorithm, J. Info. Know. Mgmt. (JIKM) 11 (2) (2012)125001-1–1250011-10, WorldScinet
. [2]
N. Abdelhamid, F. Thabtah, Associative classiﬁcation approaches: review andcomparison, J. Inform. Knowl. Manage. (JIKM) 13 (3) (2014)
. [3]
A.C. Arabzad, M.E.T. Araghi, S.N. Soheil, Football match results prediction usingartiﬁcial neural networks: the case of Iran pro league, Int. J. Appl. Res. Ind. Eng.1 (3) (2014) 159–179
.[4] D. Buursma, Predicting sports events from past results ‘‘Towards effectivebetting on football matches”, in: Conference Paper, presented at 14th TwenteStudent Conference on IT, Twente, Holland, 21 January 2011, 2001.[5] C. Cao, Sports data mining technology used in basketball outcome prediction.Master’s Thesis, Dublin Institute of Technology, Ireland, 2012.[6]
E. Davoodi, A. Khanteymoori, Horse racing prediction using artiﬁcial neuralnetworks, Recent Adv. Neural Networks, Fuzzy Syst. Evol. Comput. 2010 (2010)155–160
.[7]
D. Delen, D. Cogdell, N. Kasap, A comparative analysis of data mining methodsin predicting NCAA bowl outcomes, Int. J. Forecast. 28 (2) (2012) 543–552
. [8]
J. Edelmann-Nusser, A. Hohmann, B. Henneberg, Modeling and prediction ofcompetitive performance in swimming upon neural networks, Eur. J. Sport Sci.2 (2) (2002) 1–10
.[9] M. Fernandez, B. Ulmer, Predicting Soccer Match Results in the English PremierLeague, 2014.[10]
S. Grossberg, Nonlinear neural networks: principles, mechanisms, andarchitectures, Neural Networks (1988) 17–61
. [11] M.A. Hall, Correlation-based Feature Subset Selection for Machine Learning,PhD Dissertation, Department of Computer Science, University of Waikato,1999.[12] M. Hall, E. Frank, Combining naive Bayes and decision tables, in: Proc 21stFlorida Artiﬁcial Intelligence Research Society Conference, Miami, Florida,AAAI Press, 2008.[13]
M. Hall, E. Frank, G. Holmes, B. Pfahringer, P. Reutemann, I. Witten, The WEKAdata mining software: an update, SIGKDD Explor. 11 (1) (2009) 10–18
. [14]
J. Hühn, E. Hüllermeier, FURIA: an algorithm for unordered fuzzy ruleinduction, Data Min. Knowl. Disc. 19 (3) (2009) 293–319
. [15] J. Hucaljuk, A. Rakipovic ´, Predicting football scores using machine learningtechniques, in: MIPRO, 2011 Proceedings of the 34th International Convention,IEEE, 2011, pp. 1623–1627.[16]
I.T. Jolliffe, Principal Component Analysis, second ed., Springer-Verlag, Berlin,2002
.[17]
A. Joseph, N.E. Fenton, M. Neil, Predicting football results using Bayesian netsand other machine learning techniques, Knowl.-Based Syst. 19 (2006) 544–553
.[18]
J. Kahn, Neural network prediction of NFL football games, World Wide WebElectronic Publication 2003 (2003) 9–15
. [19]
F. Kamalov, F. Thabtah, A feature selection method based on ranked vectorscores of features for classiﬁcation, Ann. Data Sci. (2017) 1–20, Springer
. [20]
C. Kanzow, N. Yamashita, M. Fukushima, Levenberg-Marquardt methods withstrong local convergence properties for solving nonlinear equations withconvex constraints, JCAM 172 (2) (2004) 375–397
. [21]
Igor Kononenko et al., Overcoming the myopia of inductive learningalgorithms with RELIEFF, Appl. Intell. 7 (1) (1997) 39–55
. [22] A. Marcano-Cedeno, J. Quintanilla-Dominguez, M. Cortina-Januchs, D. Andina,Feature selection using sequential forward selection and classiﬁcationapplying artiﬁcial metaplasticity neural network, in: 36th Annual Conferenceon IEEE Industrial Electronics Society, 2010, pp. 2845–2850.[23] A. Maszczyk, A. Gołas´, P. Pietraszewski, R. Roczniok, A. Zaja ˛c, A. Stanula, Application of neural and regression models in sports results prediction, Proc.– Soc. Behav. Sci. 117 (2014) 482–487.[24] Mathworks (n.d.). machinelearning_su pervisedunsupervised.png. Retrieved from <https://de.mathworks.com/help/stats/machinelearning_supervisedunsupervised.png>.[25] A. McCabe, J. Trevathan, Artiﬁcial intelligence in sports prediction, in:Information Technology: New Generations, ITNG 2008. Fifth InternationalConference on, IEEE, 2008, pp. 1194–1197.[26] D. Miljkovic´, L. Gajic´, A. Kovacˇevic´, Z. Konjovic´, The use of data mining for basketball matches outcomes prediction, in: Intelligent Systems andInformatics (SISY), 2010 8th International Symposium on, IEEE, 2010, pp.309–312.[27]R. Mohammad, F. Thabtah, L. McCluskey, Predicting phishing websites basedon self-structuring neural network, Neural Comput. Appl. 25 (2) (2014) 443–458
.[28]
R. Mohammad, F. Thabtah, L. McCluskey, Tutorial and critical analysis ofphishing websites methods, Comput. Sci. Rev. J. 17 (2015) 1–24
. [29]
R. Mohammad, F. Thabtah, L. McCluskey, An improved self-structuring neuralnetwork, in: Paciﬁc-Asia Conference on Knowledge Discovery and DataMining, Auckland, New Zealand, 2016, pp. 35–47
. [30] H. Mohamed, A. Negm, M. Zahran, O.C. Saavedra, Assessment of artiﬁcialneural network for bathymetry estimation using High Resolution Satelliteimagery in Shallow Lakes: case study El Burullus Lake, in: International WaterTechnology Conference, 2015.[31]
S. Nunes, N. Sousa, Applying data mining techniques to football data fromEuropean championships, Proceedings of Conferência de Metodologias deInvestigação Cientíﬁca (2006) 4–16
. [32]
M.C. Purucker, Neural network quarterbacking, IEEE Potentials 15 (1996) 9–15
.[33] D. Prasitio, D. Harlili, Predicting football match results with logistic regression,in: Proceedings of the 2016 International Conference On AdvancedInformatics: Concepts, Theory And Application (ICAICTA), 16–19 Aug. 2016,Penang, Malaysia, 2016.[34]
I. Qabajeh, F. Thabtah, F. Chiclana, A dynamic rule-induction method forclassiﬁcation in data mining, J. Manage. Anal. 2 (3) (2015) 233–253
. [35] J. Quinlan, C4.5: Programs for Machine Learning. Morgan Kaufmann, SanMateo, CA, 1993.[36] Raschka (n.d.). k-fold.png. Retrieved from < https://sebastianraschka.com/ images/faq/evaluate-a-model/k-fold.png >. [37]
D.E. Rumelhart, G.E. Hinton, R.J. Williams, Learning representations by back-propagating errors, Nature 323 (6088) (1986) 533–536
. [38]
C. Shearer, The CRISP-DM model: the new blueprint for data mining, J. DataWarehousing 5 (4) (2000) 13–22
. [39] R.S. Sutton, Two problems with backpropagation and other steepest-descentlearning procedures for networks, in: Proc. 8th Annual Conf. Cognitive ScienceSociety, 1986.[40]
N. Tax, Y.P. Joustra, Predicting the Dutch football competition using publicdata: A machine learning approach, Trans. Knowl. Data Eng. 10 (10) (2015) 1–13
.[41] F. Thabtah, S. Hammoud, H. Abdeljaber, Parallel associative classiﬁcation datamining frameworks based mapreduce, To Appear in Journal of ParallelProcessing Letter, March 2015, World Scientiﬁc, 2015.[42] F. Thabtah, R.M. Mohammad, L. McCluskey, A dynamic self-structuring neuralnetwork model to combat phishing, Neural Networks (IJCNN), 2016International Joint Conference, Vancouver, Canada, 2016, pp. 4221–4226.[43] L. Wilkinson, A. Anand, D. Tuan, CHIRP: a new classiﬁer based on compositehypercubes on iterated random projections, in: Proceedings of the 17th ACMSIGKDD International Conference on Knowledge Discovery and Data Mining(KDD), 2011, vol. 11, pp. 6–14.[44] O. Wiseman, Using Machine Learning to Predict the Winning Score ofProfessional Golf Events on the PGA Tour (Doctoral dissertation, Dublin,National College of Ireland), 2016.[45]
I.H. Witten, E. Frank, M.A. Hall, Data Mining: Practical Machine Learning Toolsand Techniques, Morgan Kaufmann, Burlington, MA, 2011
. [46]
N. Yvan, Flexible conjugate gradients, SIAM J. Sci. Comput. 22 (4) (2000) 1444 .R.P. Bunker, F. Thabtah / Applied Computing and Informatics 15 (2019) 27–33 33