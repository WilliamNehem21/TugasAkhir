Corn kernel classiﬁcation from few training samples
Patricia L. Suáreza,⁎, Henry O. Velesacaa,D a r i oC a r p i oa, Angel D. Sappaa,b
aESPOL Polytechnic University, CIDIS, Campus Gustavo Galindo, Guayaquil 09-01-5863, Ecuador
bComputer Vision Center, Universitat Autònoma de Barcelona, 08193-Bellaterra, Barcelona, Spain
abstract article info
Article history:Received 4 January 2023Received in revised form 17 August 2023Accepted 20 August 2023Available online 22 August 2023This article presents an efﬁcient approach to classify a set of corn kernels in contact, which may contain good, ordefective kernels along with impurities. The proposed approach consists of two stages, the ﬁrst one is a next-generation segmentation network, trained by using a set of synthesized images that is applied to dividethe given image into a set of individual instances. An ad-hoc lightweight CNN architecture is then proposed toclassify each instance into one of three categories (ie good, defective, and impurities). The segmentation networkis trained using a strategy that avoids the time-consuming and human-error-prone task of manual data annota-tion. Regarding the classiﬁcation stage, the proposed ad-hoc network is designed with only a few sets of layers toresult in a lightweight architecture capable of being used in integrated solutions. Experimental results and com-parisons with previous approaches showing both the improvement in accuracy and the reduction in time areprovided. Finally, the segmentation and classi ﬁcation approach proposed can be easily adapted for use with other cereal types.© 2023 The Authors. Publishing servic es by Elsevier B.V. on behalf of KeAi Communications Co., Ltd. This is an openaccess article under the CC BY-NC-ND license ( http://creativecommons.org/licenses/by-nc-nd/4.0/ ).
Keywords:Corn kernel classiﬁcationComputer vision approachesQuality inspectionFood grain identiﬁcationMachine visionInstance segmentationSynthesized dataset generation
1. IntroductionAccording to the FAO, world grain trade is forecast to expand to anew record in 2021=2022. Corn continues to predominate in theworld cereal market.
1Based on the shown statistics and the importanceof this cereal in the world economy, it is imperative to de ﬁne standards in its commercialization processes and quality analysis is one of them.At present, the quality analysis of corn kernels is carried out manuallyby experts (e.g.,Paulsen et al. (2019)), however, this task is tedious, complex, and prone to errors, since there is a visual and subjective in-spection process.As mentioned above, it is necessary to deﬁne policies and standards that allow fair trade (e.g.,Bacon (2005),Naylor (2017),Wilson (2010)); subjectivity should be eliminated from the quality analysis process.In recent years some approaches have been proposed for the analysisof the quality of different types of kernels. In general, these newapproaches are based on the usage of deep learning techniques(e.g.,Velesaca et al. (2020),Shamim et al. (2020),Singh andChaudhury (2020),Li et al. (2019)) on visible spectra images (i.e., RGBimages). In addition to these approaches, a few contributions workingon other spectral bands (e.g., ultraviolet near-infrared) have been alsoproposed byCheng et al. (2019). Although interesting results havebeen obtained, as will be presented in the next section, most of themimpose constraints in the given sample set (e.g., non-touching kernels)making difﬁcult their use in real scenarios. The main drawback of deeplearning-based techniques is related to the requirement of a largenumber of labeled images to obtain a reliable and generalizable solu-tion. In general, image annotation is manually performed becoming atime-consuming task and sometimes a bottleneck in the whole process.To overcome this problem some authors have proposed to use synthe-sized datasets (e.g.,Toda et al. (2020),Kar et al. (2019)), which allow the generation of large annotated datasets, as large as required by thetraining process.This paper presents a technique for classifying the content of a givensample of corn grains into three categories: good grains, defectivegrains, and impurities. Good grains are those that meet the desiredquality standards and are suitable for consumption or processing; de-fective corn grains include broken samples or samples infected byfungi or bacteria, which makes them undesirable for consumption orprocessing;ﬁnally, impurities are foreign materials that are found inthe given sample, they can be organic (e.g., pieces of grass or other ce-reals) or inorganic (e.g., pebbles). The classi ﬁcation problem is tackled without imposing constraints on the distribution of the grains or thepresence of impurities. The proposed approach consists of two stages,Artiﬁcial Intelligence in Agriculture 9 (2023) 89 –99
⁎Corresponding author at: ESPOL Polytechnic University, CIDIS, Campus GustavoGalindo, Guayaquil 09-01-5863, Ecuador.E-mail addresses:plsuarez@espol.edu.ec(P.L. Suárez),hvelesac@espol.edu.ec (H.O. Velesaca),dncarpio@espol.edu.ec(D. Carpio),asappa@espol.edu.ec, asappa@cvc.uab.es(A.D. Sappa).
1http://www.fao.org/in-action/inpho/crop-compendium/cereals-grains/en .
https://doi.org/10.1016/j.aiia.2023.08.0062589-7217/© 2023 The Authors. Publishing services by Elsevier B.V. on behalf of KeAi Communications Co., Ltd. This is an open access article under the CC BY-NC-ND license (http:// creativecommons.org/licenses/by-nc-nd/4.0/ ).
Contents lists available atScienceDirect
Artiﬁcial Intelligence in Agriculture
journal homepage:http://www.keaipublishing.com/en/journals/artificial-intelligence-in-agriculture/instance segmentation, and classiﬁcation, as normally proposed in thesetypes of solutionsVelesaca et al. (2021b).I nt h eﬁrst stage, a novel strategy is proposed to avoid the time-consuming data annotation pro-cess. In the second stage, an efﬁcient and lightweight architecture isproposed, which overcomes state-of-the-art corn kernel classi ﬁcation approaches The core idea is to implement an independent lightweightclassiﬁcation module that may be used independently in further appli-cations. The manuscript is organized as follows. Section 2presents works related to the segmentation and classi ﬁcation problems. Section 3presents the approach proposed for classifying elementsfrom the given sample set, together with a summary of the datasetgenerated for the current work. Experimental results and comparisonswith different approaches are given in Section 4. Finally, conclusions are presented inSection 5.2. Related worksAs described above, this paper presents an approach to perform cornkernel segmentation and classiﬁcation. This technique addresses theinspection of the quality of corn samples, which could contain goodkernels, defective kernels, and impurities. In this section, state-of-the-art algorithms in these topics are reviewed. Firstly, the most relevantsegmentation approaches generally used in the detection step, are sum-marized; secondly, classiﬁcation techniques related to classical anddeep learning-based approaches, are presented. Table 1presents a summary of all literature reviewed in this section.2.1. Segmentation techniquesInstance segmentation has been largely studied in the computervision community for different topics. Regarding its usage in thesegmentation of sets of cereal kernels, there are studies based on theusage of threshold to split up the given image into background and fore-ground; these techniques work with grayscale images and performbinarization using a speciﬁc threshold value, which depends on thetype of grain analyzed and the color of the used background(e.g.,Paliwal et al. (2003),Kaur and Singh (2015),Arboleda et al. (2018)). More elaborated approaches have been also considered, for in-stance, the watershed technique has been used to segment grains fromthe given image; this technique uses grayscale images where thevariations in tonality represent a topographic surface and the highest in-tensity values are the peaks while the lowest values are the valleys. Theprocess begins,ﬁlling each valley with a different color, then continuestoﬁll until adjacent regions begin to touch and the boundaries betweeneach region are well deﬁned. The result of this process is the imagesegmented in each region with different colors. In Huang et al. (2019) andShrestha et al. (2016)the authors propose to use the watershedmethod to obtain the segmented instance of corn and wheat kernelsrespectively.Like in most computer vision tasks, recently convolutional neuralnetworks (CNN) are used for the instance segmentation task overcom-ing state-of-the-art approaches (e.g., Aukkapinyo et al. (2019),Ganesh et al. (2019),Toda et al. (2020),Velesaca et al. (2020)). Among the different proposals, the Mask R-CNN architecture
He et al. (2017)has become a benchmark in the area of object detection and instance seg-mentation; this architecture extends the Faster R-CNN object detectionframeworkRen et al. (2016)by adding a branch for the generation ofthe masks at the end of the model, thus achieving the segmentation ofinstances for each output bounding box. Regarding the usage of theaforementioned approaches in the cereal kernel segmentation, in Toda et al. (2020)the authors propose to use the Mask R-CNN network to de-termine the morphological phenotype of barley grains. For the trainingphase, the authors use a dataset where each image is generated by thecollage of real corn kernels. In general, the model trained with thesesynthesized images has given better results compared to the trainingwith manually annotated real-world images. The strategy is validatedusing other types of grains such as oats, rice, lettuce, and wheat. Anotherwork to perform the instance segmentation of corn kernels is presented
Table 1Summary of literature reviewed in Section 2grouped by type of grain—classiﬁcation accuracy corresponds to the values given by the authors in their experimental result sections.Kernel Author(s) Segmentation Classi ﬁcation Classif. % Acc.
CornJavanmardi et al. (2021) Multi-Threshold CNN 98.10 Velesaca et al. (2021a) Mask R-CNN –– Zhang et al. (2021a) Otsu CNN 93.30 Zhang et al. (2021b) Otsu CNN 97.50 Adke et al. (2020) Mask R-CNN Mask R-CNN 97.50 Ali et al. (2020) Thresholding Multilayer Perceptron 98.93 Velesaca et al. (2020) Mask R-CNN CNN (CK-CNN) 95.60 Cheng et al. (2019) – Random Forest 95.00 Effendi et al. (2019) Thresholding K-NN 90.00 Huang et al. (2019) Watershed CNN (GoogLeNet) 95.00 Li et al. (2019) Line Proﬁle Segmentation Method Maximum Likelihood Estimator 85.72 Ni et al. (2019) Background removal ResNet 98.20 Qiu et al. (2019) – PLS-DA 99.19 Ribeiro and Yao (2019) – LBP + PCA 99.00 Daskalov et al. (2018) – SVM 93.05 Ni et al. (2018) Thresholding + Morphological Operations CNN 97.00 Qiu et al. (2018) – Fourier Transform Near-Infrared Spectroscopy 98.70 Wu et al. (2018) Thresholding Support Vector Machine-Grid Search 97.44 Zhu et al. (2018) Thresholding K-SVD method 94.00 Ambrose et al. (2016b) – PLS-DA 95.00 Ambrose et al. (2016a) Thresholding PLS-DA 95.60 Williams and Kucheryavskiy (2016) Thresholding Object-Wise Method 93.00 Yuan et al. (2016) – SVM 91.11 Yang et al. (2015) Background segmentation SVM 97.25 Zhu et al. (2015) – K-NN 92.67BarleyToda et al. (2020) Mask R-CNN Mask R-CNN 95.00 Paliwal et al. (2003) Thresholding ANN 96.00RiceShao et al. (2021) Watershed Localization-based Counting Fully CNN 89.88 Aukkapinyo et al. (2019) Marker-based watershed Mask R-CNN 81.00 Kaur and Singh (2015) Grayscale thresholding Geometric features 97.21 WheatShrestha et al. (2016) Watershed ANN 72.80 CoffeeArboleda et al. (2018) – Geometric features 100P.L. Suárez, H.O. Velesaca, D. Carpio et al. Artiﬁcial Intelligence in Agriculture 9 (2023) 89 –99
90in our previous workVelesaca et al. (2020). In this work, the segmenta- tion is carried out through the Mask R-CNN network that uses thedefault parameters of the framework. Also, ResNet 101 is used as abackbone, and the pre-trained weights from the COCO dataset are con-sidered. The segmentation approach has been fed with a set of real-world images manually annotated with the open collaboration toolLabelbox
2; this tool allows drawing off the contour of each element(i.e., corn kernels and impurities) present in the given image. One ofthe main problems of this pipeline is to label a large dataset; it is atime-consuming task that can be affected by wrong annotations. Morerecently, trying to avoid this time-consuming task, we propose a novelstrategy that generates synthesized images of clusters of corn kernelsVelesaca et al. (2021a). A dataset, as large and diverse as required isgenerated, thus reducing the use of resources.Contrary to previous works where clusters of corn kernels areconsidered, inAdke et al. (2020), the instances segmentation of cornears are tackled to estimate the total consumption of the grains by ani-mals in the wild. The authors use the Mask R-CNN network to addresstwo approaches to instance segmentation: identifying whole corn earsand bare cob parts with and without corn kernels. It can be highlightedthat the results obtained by the Mask R-CNN network when evaluatedin images with different lighting conditions and backgrounds withwhich it was not trained, the network was able to identify certain in-stances of segmentation with acceptable precision. The training set con-tains 70 manually annotated images, although this is not a large numberit should be highlighted that the contour of every single kernel in the earshould be drawn, hence it is a tedious and time-consuming task.InShao et al. (2021), similar to the previous work, the author per-forms the segmentation of grains on the ears, but with rice kernels, ituses the LC-FCN semantic segmentation network to perform thesegmentation of rice ears, then applies the Watershed algorithmRoerdink and Meijster (2000)to obtain all individual instances presentin the image. The experimental results obtained by the authors showbetter results than traditional machine learning methods and SSD objectdetection algorithms. The model allows the calculation of the number ofears of rice in theﬁeld and provides basic data to estimate the yields ofrice production. Like the previous work, it has the problem that the im-ages were manually labeled, which represents a time-consuming task.The Watershed segmentation technique used by the authors is verysensitive to lighting conditions, resulting in an over-segmentation andgeneration of a greater number of instances than there are.2.2. Classiﬁcation techniquesOnce every single instance from the given image is segmented, theyneed to be classiﬁed according to the categories deﬁned in theﬁnal application. Recently, some approaches for the corn kernel classi ﬁcation problem have been proposed, especially focused on determining thequality of the grain to minimize time and costs in the veri ﬁcation pro- cesses. For instance, inCheng et al. (2019)the authors propose a pattern recognition-based technique to detect contaminated corn kernels usinga back-propagation neural network; the main limitation of thisapproach lies in the fact that kernels should not touch each other.Also, there is another technique based on the Fourier transform usingnear-infrared images, with which the most representative characteris-tics were extracted to evaluate their quality Qiu et al. (2018).A n o t h e r work focused on the corn kernel classiﬁcation problem has been pre- sented inQiu et al. (2019), where the authors introduce a corn classi ﬁ- cation algorithm that extracts the most representative features todifferentiate between good and defective corn kernels. The success ofthis approach depends on a pre-processing and normalization process.Another approach that performs corn classi ﬁcation of three types ofgrades (A, B, C) is presented byWu et al. (2018). This technique is based on a support vector machine to perform the classi ﬁcation. InAli et al. (2020)the authors also present a corn seed classi ﬁcation technique using hybrid features to determine the corn seed quality.This approach has been developed using Random Forest Breiman (2001), BayesNetPearl (1985), LogitBoostFriedman et al. (2000)an MLP model, which reaches the best results.InZhu et al. (2018), an approach to classify 4 types of corn kernelshas been proposed using a learning model based on a multi-kernel dic-tionary. Similarly, inEffendi et al. (2019), a traditional classiﬁcation method based on the KNN algorithm that extracts color and texturehas been proposed to determine the quality of the corn grains. InAmbrose et al. (2016b)the authors propose an approach to determinethe viability of seed germination, for which, they have implementedthe use of techniques based on Raman spectroscopy and Fourier trans-form using images of the near-infrared spectrum. Similarly, inWilliams and Kucheryavskiy (2016) an approach is proposed for the classiﬁcation of corn grains according to the hardness of the grain. Forthe experiments, images of the hyperspectral near-infrared spectrumhave been used based on the object-wise algorithm. Another techniqueto determine the purity of the corn seed is proposed in Yang et al. (2015), where the corn seed classiﬁer is based on texture, spectral, and morphological characteristics using SVM. The authors do not indi-cate whether the samples used in their experiments include seedswith occlusion or that are touching each other, which would be impor-tant to consider to see if it works with partial parts of the images ofgrains or with undeﬁned edges that make look like a grain has twogerm core.InZhu et al. (2015)a method is proposed to classify maize kernelscontaminated with aﬂatoxins using the KNN algorithm. For this work,hyperspectral images of the near-infrared spectrum have been used.InYuan et al. (2016), the authors propose a technique to detect moldycorn kernels with different levels of mildew using a support vector ma-chine and images of the near-infrared spectrum. In Daskalov et al. (2018), the authors also present a corn kernel classi ﬁcation algorithm to detect or rule out the presence of kernels affected with Fusariummoniliforme disease by implementing a support vector machine. Alsousing images beyond the visible spectrum, in Ambrose et al. (2016a) the authors propose a hyperspectral imaging technique to classifycorn seeds; the proposed approach receives the characteristics ex-tracted from partial least squares discriminant analysis (PLS-DA) Wold et al. (2001)for the grading of aged (heat-treated) and normal (un-treated) corn seeds. In this work, the authors propose a technique thatis not invariant to the multiple positions of the grains, in the experi-ments they are only based on the diagonal and intercalated position ofthe seeds. Also, inRibeiro and Yao (2019), the authors propose a com- bined HSV color space image processing technique to classify corn ker-nels between good and rotten. The authors describe that their data sethas been based on the same set of images at three different resolutions.Contrary to previous approaches, which are based on traditional ma-chine learning techniques, inZhang et al. (2021a)aC N N - b a s e d approach has been proposed to perform four varieties of corn seed clas-siﬁcation, to determine the quality of the corn kernels. The model workswith hyperspectral images of certain wavelength ranges, correspondingto the seed zone. The results obtained by the convolutional networkwere better when compared with techniques such as K-nearest neigh-borsCover and Hart (1967)and support vector machineCortes and Vapnik (1995). On the other hand, inLi et al. (2019), the authors propose a deep learning method to differentiate defective classes ofcorns. Although interesting results are presented, it is not clear what isthe behavior of the model with touching or occluding grains. In thesame way,Ni et al. (2018)
proposes deep convolutional networks,such as AlexNetKrizhevsky et al. (2012)and VGGSimonyan and Zisserman (2015), to classify dual touching kernels. Another proposalfor the classiﬁcation of grains is presented inZhang et al. (2021b), where the authors propose the classiﬁcation of corn grains by their
2labelbox.com.P.L. Suárez, H.O. Velesaca, D. Carpio et al. Artiﬁcial Intelligence in Agriculture 9 (2023) 89 –99
91level of freezing (mild, moderate, and severe). Two machine learningmodels (KNN and SVM) and one convolutional neural network modelwere tested using hyperspectral imaging. The results obtained betterquantitative values for the convolutional network model.Also, inLi et al. (2019), the authors propose a deep learning-basedtechnique to discriminate different defective types of corns. In thesame way, inNi et al. (2019)the authors propose the use of very deepconvolutional networks, such as VGG Simonyan and Zisserman (2015) and Residual Network (ResNet)He et al. (2016), which performs the task of classiﬁcation on dual touching kernels. Recently, anotherclassiﬁcation technique has been presented in Javanmardi et al. (2021), it follows a multiclass classiﬁcation approach of corn grain using a convolution network to extract the most representative charac-teristics. The authors just use the CNN to extract representative features,but not to perform the whole classiﬁcation process.3. Proposed approachThis section presentsﬁrst the strategy proposed to generate areal-world and synthesized image dataset; then, it gives details of theMask R-CNN network used to perform the instances segmentation. Fi-nally, it presents the proposed corn kernels classi ﬁcation network used to classify each instance into one of the three categories.3.1. Dataset generationOn the contrary, to other pattern recognition problems, where thereis a large literature and available datasets (e.g., pedestrian or vehicle de-tection and classiﬁcation), on the seed classiﬁcation domain there are just a few approaches, and most of them trained and evaluated ontheir datasets—in most of the cases just a few annotated images.Without a common benchmark, it is impossible to do comparisons, aswell as to know the limits of the state-of-the-art approaches. In thecurrent work, a strategy for dataset generation is proposed and the ob-tained dataset is released to the community for further evaluation andcomparisons.
3
The dataset generation process consists ﬁrst of taking different samples of corn kernels according to the three categories consideredin the current work (i.e., good grains, defective grains, and impurities).Samples from each category are manually grouped to avoid furtherimage annotation tasks. Then, a set of images from each of the threeclusters are acquired with a 12MP camera orthogonal to the backgroundplane (A4 sheet) containing the samples in a natural lighting scenario.Each image contains just the A4 sheet with the instances regularly dis-tributed; a rectangular grid is used to make easy the split-up of eachimage into (5/C24) cells, and each cell contains just a single grain. Thisprocess is repeated for the three categories, obtaining approximately1000 instances per category. Finally, images from each ROI (cells inthe A4 sheet) are stored as single images for further processing —see individual grain croppingillustration inFig. 1. Once a large dataset of single instances, of the three categoriesconsidered in this work, has been acquired synthesized corn kernelclusters are generated. The goal of this process is to avoid the time-consuming, and possible source of error, image annotation task. Thesynthesized image generator (seeFig. 1) allows the generation of corn kernel cluster images of different sizes containing different percentagesof the three categories. Each instance is randomly placed and rotatedavoiding overlapping between them. The user-de ﬁned parameters for the synthesized image generator are the size of the resulting image,the number of images, the minimum and the maximum number ofinstances, the percentage of goods, defective and impurities, the per-centage of grains touching and cutting the image boundary, and back-ground color. In case the number of instances is too large for the sizeof the deﬁned image, the scale of the grains can be con ﬁgured to fulﬁll the requirements. The synthesized image generator consists of threestages as shown inFig. 1(right): background subtraction, grain posi-tioning, and background replacement.Background subtractionis performed in the HSV color space, withthresholding parameters empirically obtained; it is robust to differentlighting conditions tested during the image acquisition step. After theimage thresholding, the obtained grain mask is re ﬁned with the applica- tion of morphological operators to eliminate shadows and improve con-tour deﬁnition. Then, the obtained grain mask is used to extract thepoints that deﬁne the contour of the grain; this contour is used asground truth for training the instance segmentation algorithm. Thisbackground subtraction and contour estimation is applied over everysingle image obtained from the splitting-up of the original grid cells.Grain positioningrandomly selects masks, obtained from the back-ground subtraction step mentioned above, according to the parametersprovided to the generator. Then, it inserts them into an empty image ofthe speciﬁed dimensions applying a random rotation, in each iteration,the algorithmﬁnds available spaces in the synthesized image being gen-erated and scrolls the grain until it does not overlap with previousmasks. The relative position of grains contours is stored in a datastructure to generate the grains annotated ﬁle—ground truth. Finally, a background replacementstage is applied to replace the providedbackground in the full synthesized image.In addition to the acquisition process mentioned above, where seedsare placed in cells of a regular grid, a small set of images containing acluster of corn kernels has been also acquired. Seeds and impurities inthis small set of images are manually annotated, using the Labelboxcrowdsourcing annotation tool, and used as ground truth to evaluate
Fig. 1.Overall pipeline for synthesized clusters of grains generation. Firstly, each grain from the real-world images —i.e., grids of grains—is cropped. Then, the grain's area is extracted using background subtraction. Next, grains are inserted into an empty synthetic image by the positioning algorithm; and ﬁnally, a custom background is applied to the synthesized image.
3Code and dataset will be available through the following link: https://github.com/ vision-cidis/CK-CNNLW.P.L. Suárez, H.O. Velesaca, D. Carpio et al. Artiﬁcial Intelligence in Agriculture 9 (2023) 89 –99
92the performance of the segmentation algorithm. This evaluation datasetcontains 3 images with about 204 instances each.3.2. Image segmentationAs presented inSection 2there are different approaches in theliterature to segment instances from a given image. Among the differentoptions, the Mask R-CNN architecture He et al. (2017)has become one of the best deep-learning-based options. The Mask R-CNN frameworkconsists of three stages (seeFig. 2). First, the backbone extracts featuremaps from the input images. Second, the feature maps generated bythe backbone are sent to the Region Proposal Network (RPN) to gener-ate Regions of Interest (ROI). Third, the ROIs generated by RPN aremapped to extract the corresponding target features on the shared fea-ture maps, and then map them to a fully connected layer, for the targetclassiﬁcation and segmentation instances. The process generates theclassiﬁcation scores, bounding boxes, and segmentation masks. Moredetails on the Mask R-CNN implementation are given in Section 4. In general, the use of deep learning algorithms requires having largesets of annotated images for the training stage. In the particular case ofthe current work, where there are not a large set of annotated imagesavailable, a manual annotation process is required. It is a challengingtask that requires a lot of time and resources. To avoid this problem, inour previous workVelesaca et al. (2021a)the usage of a synthesized data set has been evaluated. It contains just 20 synthesized imagesand has shown appealing results. In the current work, we propose tofollow the same strategy, hence a large set of single instances hasbeen acquired allowing the generation of a scale-annotated dataset. Asmentioned inSection 3.1the algorithm proposed for a synthesized clus-ter of grains generation allows generating datasets with different:amounts of images, percentages of instances, and seeds distribution,among other variables. It is expected that as large is the dataset as betterthe result; hence, to deﬁne how many images should be used for train-ing the Mask R-CNN algorithm different datasets have been generatedwith an increasing number of synthesized images; more informationon these datasets is given inTable 2, together with the information ofother datasets (i.e.,Velesaca et al. (2020),Velesaca et al. (2021a)) used for comparison in the experimental result section.3.3. ClassiﬁcationRegarding the classiﬁcation stage, a novel and lightweight architec-ture has been designed in order to facilitate its usage in an embeddedapplication, reducing computational complexity. The proposed archi-tecture, referred to as CK-CNNLW, is shown in Fig. 3. The architecture consists of only four layers of convolutional operations with the corre-sponding activation functions. The architecture uses a leaky recti ﬁedlinear unit, which is an activation function based on a ReLU that servesto avoid sparse gradients at training time, not pruning the negativepart to zero during backpropagation. To measure the loss of the traininga cross-entropy loss function has been used. The model ends with twofully connected layers toﬂatten and connect the features extractedonto the output layer. The CK-CNNLW network has been trained witha learning rate of 0.00027, in order to generalize the model, whichprovides a faster convergence.The model could be used to perform a multiclass classi ﬁcation problem, changing only the last layer according to the number of classesto be classiﬁed. In our case, this model has been used for a 2-class clas-siﬁcation (good or defective corn kernels) and a 3-class classi ﬁcation (good corn kernels, defective corn kernels, and impurities). TheCK-CNNLW network has been trained from scratch using NesterovADAM (NADAM) optimizer with a learning rate of 0.000275, andleaky-relu of 0.15 for average pooling and max-pooling layers. A TitanV NVIDIA GPU was used to train our model, this process takes only 5 h
given the simplicity of our model. The obtained results have been com-pared with the previous approaches, including networks of the state ofthe art like VGGSimonyan and Zisserman (2015)or ResNetHe et al. (2016), these comparisons are presented in the next section.4. Experimental resultsThis section presents results obtained with the proposed pipeline,including both evaluations of the segmentation trained with synthe-sized images as well as classiﬁcation of the segmented instances(i.e., good kernels, defective kernels, and impurities).
Fig. 2.Mask R-CNN architecture used for grain instance segmentation. Images of synthesized clusters of corn grains are shown as an example (classi ﬁcation module is not used).
Table 2Datasets used for training segmentation algorithm (Mask R-CNN) (Real y: dataset with real imagesVelesaca et al. (2020);S y ny: dataset with synthetized images Velesaca et al. (2021a);S y n
i: current work).Dataset # of images # of instancesTrain Val Train ValGood Def. Imp. Good Def. Imp.Realy16 4 2835 466 84 673 83 23Syny16 4 2384 494 80 600 124 20Syn
1 24 6 3543 734 120 896 185 30Syn
2 32 8 4741 974 160 1189 245 40Syn
3 40 10 5946 1217 200 1485 307 50Syn
4 48 12 7145 1465 240 1785 367 60Syn
5 56 14 8365 1715 280 2083 430 70Syn
6 72 18 10,768 2210 359 2661 550 90Syn
7 96 24 14,359 2949 479 3557 736 120P.L. Suárez, H.O. Velesaca, D. Carpio et al. Artiﬁcial Intelligence in Agriculture 9 (2023) 89 –99
934.1. Instance segmentationThe results obtained by training the Mask R-CNN network He et al. (2017)using real-world and synthesized clusters of corn kernelsdatasets are evaluated in this section. The Mask R-CNN network imple-mentation used in this work is based on ResNet-101 as the backboneand pre-trained COCO weight. The images in the training dataset havebeen resized to 1024/C21024 to reduce the computational cost of theentire process. The distribution of images used in the different datasetsis shown inTable 2, where the number of images for training and vali-dation is varied, and the number of instances per image is also shown.Fig. 2shows the architecture of the Mask R-CNN network used in thiswork.The performance on the different datasets is evaluated as follows:iÞby taking into account the number of grain instances correctlydetected;iiÞusing the intersection over union (IoU), and iiiÞthrough the average precision (AP) in IoU 75% ( AP
75), and the average value of IoU 50% to 95% with a step size of 5% (AP@[0.5:0.95]). Tables 3 and 4 show experimental results obtained with the Mask R-CNN networktrained with the different datasets. Table 3shows the obtained number of instances and the IoU metric computed on the set of threemanually annotated images, considered as ground truth, mentioned inSection 3.1.T h eﬁrst row (GT) corresponds to the number of instancesper ground truth image; the second row shows results obtained whentrained with the dataset presented in Velesaca et al. (2020)—it should be mentioned this dataset only contains manually annotated real-worldimages; the third row corresponds to the results obtained from the eval-uation of the Mask R-CNN network when trained with a synthesizeddatasetVelesaca et al. (2021a). Results from rows 4 to 10, correspondto the results obtained with the Mask R-CNN network trained with differ-ent datasets containing synthesized images, the number of images wasincreased in the training stage of each dataset. On the other hand,Table 4shows the average precision (AP) in IoU 75% ( AP75), and the aver- age value of IoU 50% to 95% with a step size of 5% (AP@[0.5:0.95]).Looking at the results depicted inTable 3, it can be appreciated that the number of detected instances is the same when real-world imagesor synthesized images are considered for training; on the contrary, itdoes not happen in the case of the IoU metric. The results of the IoUmetric show better performance, in all cases when the synthesizeddataset is considered, an improvement of up to almost 1.4% can be ob-served in theﬁrst test image. On the other hand, the AP results for thiscase study are shown inTable 4, where AP@[0.5:0.95] and AP
75metric values are shown. It can be observed that the Mask R-CNN trainedwith synthesized images presents a better performance in the AP@[0.5:0.95] and AP
75metrics. The results obtained in the IoU and AP met-rics show that the use of synthesized datasets allows a high percentageof precision to correctly delimit the area and contour of the corn kernels,conﬁrming the effectiveness and validity of the proposed approach.In order to determine the dataset with the best con ﬁguration and performance, four metrics (i.e., number of instances, IoU, AP@[0.5:0.95], and AP
75) are considered, although each metric is individu-ally evaluated, the metric of the number of instances in the presentwork has the highest priority, importance, and is used to discarddatasets show takes in the number of detected instances directly affectthe value obtained in the other three evaluated metrics. For the afore-mentioned, among the results obtained in the evaluation of the differentdatasets, the Re, Syn
4, and Syn6datasets show the best results about thenumber of detected instances and also taking into account the IoU met-ric, the Syn
4dataset presents the best performance of the 3 datasets for
Fig. 3.Proposed lightweight classiﬁcation architecture.
Table 3Results ontesting images(manually annotated ground truth) when the Mask R-CNN net-work is trained with: real images (Real y)Velesaca et al. (2020); and synthesized clusters dataset (Syny)Velesaca et al. (2021a)—GT: Ground Truth.Dataset # of instances IoUT1 T2 T3 Sum T1 T2 T3 AvgGT 200 190 223 613 –––– Realy199 189 215 603 0.901 0.897 0.898 0.899Syny198 188 215 601 0.914 0.911 0.900 0.908Syn
1 199 188 215 602 0.909 0.913 0.897 0.906Syn
2 199 189 214 602 0.909 0.910 0.897 0.906Syn
3 198 189 215 602 0.915 0.914 0.900 0.910Syn
4 198 189 216 603 0.913 0.913 0.898 0.908 Syn
5 199 188 215 602 0.909 0.913 0.897 0.906Syn
6 198 189 216 603 0.911 0.911 0.896 0.906Syn
7 198 189 215 602 0.913 0.909 0.914 0.909Table 4Results using the AP metric on testing images(manually annotated ground truth) when the Mask R-CNN network is trained with real images (Real y)Velesaca et al. (2020);a n d synthesized clusters dataset (Syn y)Velesaca et al. (2021a).Dataset AP@[0.5:0.95] AP
75
T1 T2 T3 Avg T1 T2 T3 AvgRealy0.790 0.800 0.780 0.793 0.964 0.978 0.950 0.958Syny0.830 0.830 0.790 0.818 0.980 0.984 0.945 0.964Syn
1 0.790 0.800 0.760 0.784 0.978 0.984 0.937 0.966Syn
2 0.790 0.820 0.770 0.793 0.979 0.973 0.932 0.961Syn
3 0.810 0.830 0.780 0.804 0.975 0.989 0.941 0.968Syn
4 0.800 0.830 0.770 0.799 0.970 0.989 0.941 0.967 Syn
5 0.800 0.810 0.760 0.791 0.985 0.984 0.928 0.965Syn
6 0.810 0.820 0.770 0.802 0.974 0.978 0.936 0.963Syn
7 0.800 0.820 0.770 0.797 0.974 0.984 0.941 0.966P.L. Suárez, H.O. Velesaca, D. Carpio et al. Artiﬁcial Intelligence in Agriculture 9 (2023) 89 –99
94both metrics. Taking into account the previous results evaluated of thetwo metrics, it was observed that in the AP@[0.5:0.95] and AP
75metrics for the datasets Re, Syn
4,a n dS y n6,i tw a so b s e r v e dt h a tf o rA P @ [0.5:0.95] and AP
75metrics the Syn4dataset obtains the best results on average. In general, in the four evaluated metrics, it was observedthat the conﬁguration presented by the Syn
4dataset obtains the best performance.Finally, the qualitative results and the annotations of the groundtruth in the three test images are shown in Fig. 4, where the number of instances predicted by Mask R-CNN and the values of the groundtruth are presented. For easy visualization of the qualitative evaluation,the area of each grain segmented by the Mask R-CNN is colored brownwhile the manual annotations are shown in green. Additionally, a bluecircle has been used to highlight each individual instance along withthe corresponding instance number, to verify that there are no duplicateor poorly segmented kernels.4.2. ClassiﬁcationThis section presents results obtained with the proposed lightweightnetwork for classifying corn grains according to their quality. Thisapproach receives as an input an instance obtained in the previous in-stance segmentation stage. The proposed approach is evaluated in twoscenarios:iÞtwo-class classiﬁcation problem (i.e., good and defectivecorn kernels), andiiÞthree-class classiﬁcation problem (i.e., good, defective, and impurity). The results obtained with both approaches
P.L. Suárez, H.O. Velesaca, D. Carpio et al. Artiﬁcial Intelligence in Agriculture 9 (2023) 89 –99
95are better than those obtained with the state-of-the-art architectures,such as VGG16, ResNet50, and Mask R-CNN, which were used for quan-titative comparisons.The two-class classiﬁcation approach has been trained using a set of3710 images (2000 images of good and defective grains for training,1350 images of good and defective grains for testing, and 360 imagesof good and defective grains for validating the model after the trainingprocess). On the other hand, in the three-class classi ﬁcation scenario, the proposed approach has been trained using 6800 images (2100 im-ages of good corns, 2600 images of defective corns, and 2100 imagesof impurities), 1800 images are used for testing the training process(600 images of good corns, 600 images of defective corns and 600images of impurities). Finally, regarding the validation process, a totalof 2060 images are considered (700 images of good corns, 700 imagesof defective corns, and 660 images of impurities). All the images avail-able for the training and testing processes have been enlarged throughthe application of data augmentation techniques, performing opera-tions of rotation,ﬂipping, and horizontal and vertical shifts, to ensurethe effectiveness and faster convergence of the model to be trained.As mentioned above, the proposed model is much lighter than thecorn grain classiﬁcation architecture proposed byVelesaca et al. (2020), with which the extraction process of the most relevant charac-teristics is carried out more effectively. Results from the proposed light-weight network, CK-CNNLW, can be seen in Table 5andTable 6, for the
Fig. 4.Segmentation results obtained on testing images(manually annotated ground truth images) when Mask R-CNN is trained with real (Real y) and synthesized (Syny)d a t a s e t s—the number of obtained instances is shown in each case. ( 1st row) Ground truth labeled with Labelbox. ( 2nd row) Results when the real-world image dataset (Real y)Velesaca et al. (2020)is used for training. (3rd row) Results when the synthesized cluster dataset (Syn y)Velesaca et al. (2021a)is used for training. (4th to 10th row) Results when different synthesized cluster datasets are used for training (see Table 2).
Table 5Results of classiﬁcation stage for the two-class scenario.Network Good Defective Avg. Avg. Test Time # of Net.Corn Corn Acc per Image ( sec) Param.Mask R-CNN 0.962 0.644 0.803 0.0080 63,738 KVGG16 0.950 0.917 0.933 0.0097 134,268 kResNet50 0.906 0.917 0.911 0.0106 23,591 KCK-CNN 0.956 0.933 0.945 0.0074 3306 KCK-CNNLW 0.98 0.983 0.965 0.0063 548 KTable 6Results of classiﬁcation stage for the three-class scenario.Network Good Def. Imp. Avg. Avg. Test Time # of Net.Corn Corn Acc per Image (sec) Param.Mask R-CNN 0.960 0.695 0.286 0.647 0.0140 63,738 KVGG16 0.974 0.876 0.819 0.890 0.0112 134,272 kResNet50 0.986 0.860 0.931 0.925 0.0121 23,593 KCK-CNN 0.979 0.900 0.973 0.956 0.0095 3306 KCK-CNNLW 0.990 0.930 0.986 0.967 0.0075 597 KP.L. Suárez, H.O. Velesaca, D. Carpio et al. Artiﬁcial Intelligence in Agriculture 9 (2023) 89 –99
96classiﬁcation problem of two and three classes respectively. These ta-bles show the results of the proposed architecture together with the re-sults of the state-of-the-art models, such as the Mask R-CNN He et al. (2017), VGG-16Simonyan and Zisserman (2015), ResNet-50He et al. (2016)and CK-CNNVelesaca et al., 2020. As can be seen, the proposed architecture shows better quantitative results than all the previous ap-proaches. Furthermore, it should be noted that the proposed architec-ture requires almost six times fewer parameters than our previousapproach (CK-CNNVelesaca et al. (2020)) and more than forty times fewer parameters than the rest of the architectures.In addition to the quantitative values presented in previous tables,the ROC curves corresponding to the results obtained with the proposedarchitecture for the three-class classiﬁcation case are depicted inFig. 5.Figs. 6, 7 and 8present comparisons of ROC curves for the defective, im-purity, and good corn classes between the proposed approach and ourprevious work (CK-CNNVelesaca et al. (2020)). It can be appreciated, in all the cases, that the proposed approach reaches a higher perfor-mance and precision when compared with CK-CNN Velesaca et al. (2020).5. ConclusionsThis paper presents a novel approach to classify clusters of touchingcorn kernels, which may contain good and defective kernels togetherwith impurities; it consistsﬁrst of a simple but efﬁcient strategy to avoid the time-consuming annotation task for training the instanceFig. 5.ROC curves of the proposed CK-CNNLW architecture for the three-class classi ﬁcation case.
Fig. 6.ROC curves of the CK-CNN and the proposed CK-CNNLW model for the defective corn class (three-class classi ﬁcation case).P.L. Suárez, H.O. Velesaca, D. Carpio et al. Artiﬁcial Intelligence in Agriculture 9 (2023) 89 –99
97segmentation Mask R-CNN algorithm. Results obtained by the MaskR-CNN network trained with synthetized datasets reach better perfor-mance, both IoU and AP than when training with manually annotatedimages. Then, as asecond contribution, a novel and lightweight networkis proposed (CK-CNNLW) to classify the obtained instances. This net-work is considerably lighter than previous approaches (six timesfewer parameters than our previous approach and more than fortytimes fewer parameters than other state-of-the-art architectures).Furthermore, obtained results show better performance than all previ-ous approaches. In future work we will try to develop our own segmen-tation model, trying to obtain a lightweight architecture. Additionally,we plan to extend the proposed solution to other types of grains.CRediT authorship contribution statementPatricia L. Suárez:Software, Methodology, Validation, Writing – original draft, Investigation, Visualization, Writing –review & editing.Henry O. Velesaca:Investigation, Software, Validation, Writing – original draft.Dario Carpio:Software, Writing–original draft.Angel D. Sappa:Conceptualization, Resources, Supervision, Investigation,Writing–review & editing.Declaration of Competing InterestThe authors declare that they have no known competing ﬁnancial interests or personal relationships that could have appeared toinﬂuence the work reported in this paper.AcknowledgementsThis work has been partially supported by: Grant PID2021-128945NB-I00 funded by MCIN/AEI/10.13039/501100011033 and by“ERDF A way of making Europe”;a n dt h e“CERCA Programme / Generalitat de Catalunya“; and the ESPOL project CIDIS-20-2021. TheFig. 7.ROC curves of the CK-CNN and the proposed CK-CNNLW model for the impurity class (three-class classi ﬁcation case).
Fig. 8.ROC curves of the CK-CNN and the proposed CK-CNNLW model for the good corn class (three-class classi ﬁcation case).P.L. Suárez, H.O. Velesaca, D. Carpio et al. Artiﬁcial Intelligence in Agriculture 9 (2023) 89 –99
98authors gratefully acknowledge the NVIDIA Corporation for donating aTitan V GPU used for this research.References
Adke, S., Haro Von Mogel, K., Jiang, Y., Li, C., et al., 2020. Instance segmentation to estimate consumption of corn ears by wild animals for gmo preference tests. Front. Artif.Intelligen. 3, 1–14.Ali, A., Qadri, S., Mashwani, W.K., Brahim Belhaouari, S., Naeem, S., Ra ﬁque, S., Jamal, F., Chesneau, C., Anam, S., 2020. Machine learning approach for the classi ﬁcation of corn seed using hybrid features. Int. J. Food Prop. 23, 1110 –1124. Ambrose, A., Kandpal, L.M., Kim, M.S., Lee, W.-H., Cho, B.-K., 2016a. High speed measure- ment of corn seed viability using hyperspectral imaging. Infrared Phys. Technol. 75,173–179.Ambrose, A., Lohumi, S., Lee, W.-H., Cho, B.K., 2016b. Comparative nondestructive mea- surement of corn seed viability using fourier transform near-infrared (ft-nir) andraman spectroscopy. Sensors Actuators B Chem. 224, 500 –506. Arboleda, E.R., Fajardo, A.C., Medina, R.P., 2018. An image processing technique for coffee black beans identiﬁcation. IEEE Int. Conf. On innovative Research and Development,pp. 1–5.Aukkapinyo, K., Sawangwong, S., Pooyoi, P., Kusakunniran, W., 2019. Localization and classiﬁcation of rice-grain images using region proposals-based convolutional neuralnetwork. Int. J. Autom. Comput. 1 –14. Bacon, C., 2005.Confronting the coffee crisis: can fair trade, organic, and specialty coffeesreduce small-scale farmer vulnerability in northern Nicaragua? World Dev. 33,497–511.Breiman, L., 2001.Random forests. Mach. Learn. 45, 5 –32. Cheng, X., Vella, A., Stasiewicz, M.J., 2019. Classiﬁcation of aﬂatoxin contaminated single corn kernels by ultraviolet to near infrared spectroscopy. Food Control 98, 253 –261. Cortes, C., Vapnik, V., 1995.Support-vector networks. Mach. Learn. 20, 273 –297. Cover, T., Hart, P., 1967.Nearest neighbor pattern classiﬁcation. IEEE Trans. Inf. Theory 13, 21–27.Daskalov, P., Kirilova, E., Georgieva, T., 2018. Performance of an automatic inspection sys- tem for classiﬁcation of fusarium moniliforme damaged corn seeds by image analysis.MATEC Web of Conferences. 210. EDP Sciences, p. 02014.Effendi, M., Jannah, M., Effendi, U., 2019. Corn quality identiﬁcation using image process- ing with k-nearest neighbor classi ﬁer based on color and texture features. IOP Confer- ence Series: Earth and Environmental Science, pp. 12 –66. Friedman, J., Hastie, T., Tibshirani, R., 2000. Additive logistic regression: a statistical view of boosting (with discussion and a rejoinder by the authors). Ann. Stat. 28, 337 –407. Ganesh, P., Volle, K., Burks, T., Mehta, S., 2019. Deep orange: mask R-CNN based orange detection and segmentation. IFAC-PapersOnLine 52, 70 –75. He, K., Zhang, X., Ren, S., Sun, J., 2016.
Deep residual learning for image recognition. Pro- ceedings of the IEEE Conference on Computer Vision and Pattern Recognition,pp. 770–778.He, K., Gkioxari, G., Dollár, P., Girshick, R., 2017. Mask R-CNN. IEEE Int. Conf. On Computer Vision, pp. 2961–2969.Huang, S., Fan, X., Sun, L., Shen, Y., Suo, X., 2019. Research on classiﬁcation method of maize seed defect based on machine vision. J. Sens. 2, 1 –10. Javanmardi, S., Ashtiani, S.-H.M., Verbeek, F., Martynenko, A.I., 2021. Computer-vision classiﬁcation of corn seed varieties using deep convolutional neural network.J. Stored Prod. Res. 92.Kar, A., Kulshreshtha, P., Agrawal, A., Palakkal, S., Boregowda, L.R., 2019. Annotation-free quality estimation of food grains using deep neural network. 30th British Machine Vi-sion Conference, pp. 1–12.Kaur, S., Singh, D., 2015.Geometric feature extraction of selected rice grains using imageprocessing techniques. Int. J. Comput. Appl. 124, 41 –46. Krizhevsky, A., Sutskever, I., Hinton, G.E., 2012. Imagenet classiﬁcation with deep convolutional neural networks. In: Pereira, F., Burges, C., Bottou, L., Weinberger, K.(Eds.), Advances in Neural Information Processing Systems. 25. Curran Associates,Inc.Li, X., Dai, B., Sun, H., Li, W., 2019. Corn classiﬁcation system based on computer vision. Symmetry 11, 1–12.Naylor, L., 2017.Auditing the subjects of fair trade: coffee, development, and surveillancein highland Chiapas. Environ. Plann. D: Soc. Spac. 35, 816 –835. Ni, C., Wang, D., Holmes, M., Vinson, R., Tao, Y., 2018. Convolution neural network based automatic corn kernel qualiﬁcation. ASABE Annual Int. Meeting. American Society ofAgricultural and Biological Engineers.Ni, C., Wang, D., Vinson, R., Holmes, M., Tao, Y., 2019. Automatic inspection machine for maize kernels based on deep convolutional neural networks. Biosyst. Eng. 178,131–144.Paliwal, J., Visen, N., Jayas, D., White, N., 2003. Cereal grain and dockage identiﬁcation using machine vision. Biosyst. Eng. 85, 51 –57. Paulsen, M.R., Singh, M., Singh, V., 2019. Measurement and maintenance of corn quality. Corn. Elsevier, pp. 165–211.Pearl, J., 1985.Bayesian netwcrks: a model cf self-activated memory for evidential reason-ing. Proceedings of the 7th Conference of the Cognitive Science Society. University ofCalifornia, Irvine, CA, USA, pp. 15 –17. Qiu, G., Lü, E., Lu, H., Xu, S., Zeng, F., Shui, Q., 2018. Single-kernel ft-nir spectroscopy for detecting supersweet corn (zea mays l. saccharata sturt) seed viability with multivar-iate data analysis. Sensors 18, 1010.Qiu, G., Lü, E., Wang, N., Lu, H., Wang, F., Zeng, F., 2019. Cultivar classiﬁcation of single sweet corn seed using fourier transform near-infrared spectroscopy combined withdiscriminant analysis. Appl. Sci. 9, 1530.Ren, S., He, K., Girshick, R., Sun, J., 2016. Faster R-CNN: towards real-time object detection with region proposal networks. IEEE Trans. Pattern Anal. Mach. Intell. 39, 1137 –1149. Ribeiro, S.S., Yao, J., 2019.Toward a three-way image classiﬁcation model: a case study oncorn grain images. IEEE Int. Symposium on Multimedia, pp. 177 –1776. Roerdink, J.B., Meijster, A., 2000. The watershed transform: deﬁnitions, algorithms and parallelization strategies. Fundamenta Informat. 41, 187 –228. Shamim, M.I., Pal, B., Arora, A.S., Pial, M.A., 2020. A deep convolutional neural network ap- proach to rice grain purity analysis. Progress in Computing, Analytics and Network-ing. Springer, pp. 179–189.Shao, H., Tang, R., Lei, Y., Mu, J., Guan, Y., Xiang, Y., 2021. Rice ear counting based on image segmentation and establishment of a dataset. Plants 10, 1 –12. Shrestha, B.L., Kang, Y.-M., Yu, D., Baik, O.-D., 2016. A two-camera machine vision ap- proach to separating and identifying laboratory sprouted wheat kernels. Biosyst.Eng. 147, 265–273.Simonyan, K., Zisserman, A., 2015. Very deep convolutional networks for large-scale image recognition. 3rd International Conference on Learning Representations. ICLR,San Diego, CA, USA.Singh, K.R., Chaudhury, S., 2020. A cascade network for the classi ﬁcation of rice grain based on single rice kernel. Complex & Intelligent Systems, pp. 1 –14. Toda, Y., Okura, F., Ito, J., Okada, S., Kinoshita, T., Tsuji, H., Saisho, D., 2020. Training in- stance segmentation neural network with synthetic datasets for crop seed phenotyp-ing. Communicat. Biol. 3, 1–12. Velesaca, H.O., Mira, R., Suarez, P.L., Larrea, C.X., Sappa, A.D., 2020. Deep learning based corn kernel classiﬁcation. IEEE Int. Conf. on Computer Vision and Pattern RecognitionWorkshops, pp. 294–302.Velesaca, H.O., Carpio, D., Suarez, P.L., Sappa, A.D., 2021a. Synthesized image datasets: to- wards an annotation-free instance segmentation strategy. 16th Int. Symposium onVisual Computing, pp. 1–13.Velesaca, H.O., Suárez, P.L., Mira, R., Sappa, A.D., 2021b. Computer vision based food grainclassiﬁcation: a comprehensive survey. Comput. Electron. Agric. 187, 106287. https:// doi.org/10.1016/j.compag.2021.106287 . Williams, P.J., Kucheryavskiy, S., 2016. Classiﬁcation of maize kernels using nir hyperspectral imaging. Food Chem. 209, 131 –138. Wilson, B.R., 2010.Indebted to fair trade? Coffee and crisis in Nicaragua. Geoforum 41,84–92.Wold, S., Sjöström, M., Eriksson, L., 2001. Pls-regression: a basic tool of chemometrics. Chemom. Intell. Lab. Syst. 58, 109 –130. Wu, A., Zhu, J., Yang, Y., Liu, X., Wang, X., Wang, L., Zhang, H., Chen, J., 2018. Classiﬁcation of corn kernels grades using image analysis and support vector machine. Adv. Mech.Eng. 10, 1–9.Yang, X., Hong, H., You, Z., Cheng, F., 2015. Spectral and image integrated analysis of hyperspectral data for waxy corn seed variety classi ﬁcation. Sensors 15, 15578–15594.Yuan, Y., Wang, W., Chu, X., Xi, M., 2016. Selection of characteristic wavelengths using spa and qualitative discrimination of mildew degree of corn kernels based on svm.
Spectrosc. Spectr. Anal. 36, 226 –230. Zhang, J., Dai, L., Cheng, F., 2021a. Corn seed variety classiﬁcation based on hyperspectral reﬂectance imaging and deep convolutional neural network. J. Food Measure.Characterizat. 15, 484–494.Zhang, J., Dai, L., Cheng, F., 2021b. Identiﬁcation of corn seeds with different freezing dam- age degree based on hyperspectral re ﬂectance imaging and deep learning method. Food Anal. Methods 14, 389–400. Zhu, F., Yao, H., Hruska, Z., Kincaid, R., Brown, R., Bhatnagar, D., Cleveland, T., 2015. Clas- siﬁcation of corn kernels contaminated with a ﬂatoxins usingﬂuorescence and reﬂec- tance hyperspectral images analysis. Sensing for Agriculture and Food Quality andSafety VII. SPIE, p. 9488.Zhu, H., Yue, J., Li, Z., Zhang, Z., 2018. Multi-kernel dictionary learning for classifying maize varieties. Int. J. Agricult. Biol. Eng. 11, 183 –189.P.L. Suárez, H.O. Velesaca, D. Carpio et al. Artiﬁcial Intelligence in Agriculture 9 (2023) 89 –99
99