Non-destructive silkworm pupa gender classiﬁcation with X-ray imagesusing ensemble learning
Sania Thomas ⁎,J y o t h iT h o m a s
Department of Computer Science and Engineering, Christ (Deemed to be University), Bangalore, India
abstract article info
Article history:Received 2 March 2022Received in revised form 4 August 2022Accepted 5 August 2022Available online 10 August 2022Sericulture is the process of cultivating silkworms for the production of silk. High-quality production of silkwithout mixing with low quality is a great challenge faced in the silk production centers. One of the possibilitiesto overcome this issue is by separating male and female cocoons before extracting silk ﬁbers from the cocoons as male cocoon silkﬁbers areﬁner than females. This study proposes a method for the classi ﬁcation of male and female cocoons with the help of X-ray images without destructing the cocoon. The study used popular single hy-brid varieties FC1 and FC2 mulberry silkworm cocoons. The shape features of the pupa are considered for the clas-siﬁcation process and were obtained without cutting the cocoon. A novel point interpolation method is used forthe computation of the width and height of the cocoon. Different dimensionality reduction methods are em-ployed to enhance the performance of the model. The preprocessed features are fed to the powerful ensemblelearning method AdaBoost and used logistic regression as the base learner. This model attained a mean accuracyof 96.3% for FC1 and FC2 in cross-validation and 95.3% in FC1 and 95.1% in FC2 for external validation.© 2022 The Authors. Publishing servic es by Elsevier B.V. on behalf of KeAi Communications Co., Ltd. This is an openaccess article under the CC BY-NC-ND license ( http://creativecommons.org/licenses/by-nc-nd/4.0/ ).
Keywords:SericultureGender classiﬁcationStratiﬁed k-fold cross-validationMachine learningAdaBoost
1. IntroductionSericulture is a widely used term for the cultivation of silkworms forthe production of silk which comprises multiple ﬁelds together such as mulberry cultivation, rearing of cocoons, reeling of silk ﬁbers, twisting, dyeing, and weaving (Ganga, 2019). Sericulture is mainly the combina-tion of the cultivation of cocoons and the production of silk. The silk-worm breeds play an important role in high cocoon yield and silkquality. The hybrid breed CSR2 x CSR4 was introduced in India in1997 that has revolutionized the Indian sericulture industry. The CSRhybrids (single hybrids FC1 (CSR6 x CSR26), and FC2 (CSR2 x CSR27))are robust and more productive, that can be easily reared by thefarmers. However, more care is required in handling these pure racesand small ignorance may lead to non-availability of parental cocoons.To overcome this, bivoltine double hybrid breeds were developed. Thedouble hybrids can withstand adverse climatic conditions and hence re-sulting in crop stability than single hybrids. The double hybrid devel-oped in India is (CSR2 x CSR27) x (CSR6 x CSR26) which can yieldaround 68.00 kg/100 dﬂs. Male silkworm cocoon has distinctﬁner silk ﬁlament than female (Zhang et al., 2010). Separating male and female cocoons based on gender improves the quality of the silk ( Yu et al., 2005). The methods employed for the gender classi ﬁcation of cocoons include the Near-infrared spectroscopy method, Hyper Spectral Imagingtechnology, Optical penetration method, Camera imaging technology,X-ray method, etc. (Thomas and Thomas, 2020). The near-infrared method for the silkworm gender classi ﬁcation (Tao et al., 2018a, 2018b;Zhu et al., 2018;Lin et al., 2019;Qiu et al., 2021) uses the spectral characteristics of the pupa for the classi ﬁcation. In terms of accuracy, the system provides good accuracy but theinstrument and calibration costs are very high ( Ozaki et al., 2018). The accuracy of the iPLS-CARS-PLSDA model by Qiu et al. is as high as98.41% (Qiu et al., 2021). They have used near-infrared spectroscopyfor the classiﬁcation of male and female silkworm pupa. This methodconsiders the pupa for gender classiﬁcation which requires cutting of cocoon, which is a demerit. Any method which can ﬁnd the volume of pupa accurately without cutting the cocoon may improve the result.Hyperspectral imaging method (Tao et al., 2018a, 2018b;Tao et al., 2019a, 2019b) uses the spectral and spatial information of the pupafor classiﬁcation. The limitations include the high equipment costand computational complexity (Schneider and Feussner, 2017). The optical penetration method (Sumriddetchkajorn and Kamtongdee,2012;Sumriddetchkajorn et al., 2013;Kamtongdee et al., 2015; Sumriddetchkajorn et al., 2015) used the wavelength of light to discrim-inate the gender of silkworm pupa by locating the chitin gland insidethe tale part of the female pupa. The chitin gland is not present in themale pupa. Slight displacement of pupa cannot obtain the region of
interest which may cause misclassiﬁcation in this case. The above- mentioned methods require the cutting of cocoons to ﬁnd the features of the pupa. The camera imaging method applied for genderArtiﬁcial Intelligence in Agriculture 6 (2022) 100 –110
⁎Corresponding author.E-mail address:sania.thomas@res.christuniversity.in (S. Thomas).
https://doi.org/10.1016/j.aiia.2022.08.0012589-7217/© 2022 The Authors. Publishing services by Elsevier B.V. on behalf of KeAi Communications Co., Ltd. This is an open access article under the CC BY-NC-ND license (http:// creativecommons.org/licenses/by-nc-nd/4.0/ ).
Contents lists available atScienceDirect
Artiﬁcial Intelligence in Agriculture
journal homepage:http://www.keaipublishing.com/en/journals/artificial-intelligence-in-agriculture/classiﬁcation (Mahesh et al., 2017;Joseph Raj et al., 2019) is a low-cost method but in this method, cocoon characteristics are considered, andnot possible to analyze the pupa characteristics. The X-ray method is apromising method that can be used to get the shape characteristics ofthe pupa without cutting the cocoon.In imaging methods like the X-ray method and camera imagingmethod, researchers focus more on feature selection and classi ﬁcation al- gorithms based on machine learning methods. Agricultural researchersare working to develop fast, non-destructive, and robust methods toapply in theﬁeld of agricultural engineering. Przyby ło et al. used Convolutional Neural Networks (CNN) for the acorn classi ﬁcation based on the color and intensity of the image of sections of the seeds(Przybyłoa n dJ a błoński, 2019). Researchers have developed novel com-puter vision systems for the analysis and classi ﬁcation of seed images (Gulzar et al., 2020;Loddo et al., 2021;Loddo et al., 2021;Loddo et al., 2022). Loddo et al. have proposed a novel CNN architecture, SeedNetfor seed image classiﬁcation and retrieval (Loddo et al., 2021). Two very different datasets were tested using SeedNet and attained an accuracyof above 95% in both cases. Gulzar et al. proposed a seed image classi ﬁca- tion system using CNN and transfer learning. Fourteen commonly knownseeds were classiﬁed using advanced deep learning techniques ( Gulzar et al., 2020). In the validation set using234 images, the proposed model attained an accuracy of 99%. In recent work, Loddo et al. proposed twoplugins for seed image analysis, one able to extract morphological, tex-ture, and color features from seed images, and the second one for the clas-siﬁcation of the seeds based on the extracted features ( Loddo et al., 2022). X-rays are a type of electromagnetic radiation, the wavelengthranges from 0.1 to 10 nm which penetrates through the object(Moulet et al., 2017). Agricultural research such as quality determina-tion of fruits and vegetables uses soft x-rays ( Du et al., 2019;Xia et al., 2019;Van De Looverbosch et al., 2020). The soft X-ray wavelength ranges from 1 to 10 nm.In the X-ray method, X-ray images of the cocoon were acquiredusing soft X-ray and then pre-processed. The shape features of thepupa were extracted and then classiﬁcation was performed. Cai et al. used the X-ray method for the gender classi ﬁcation of the Pupa. In this, the author obtained an accuracy of 93.31% with the linear discrim-inant analysis used as a classiﬁer (Cai et al., 2014). Various researchers
have done gender classiﬁcation of silkworm pupa using the methodsdiscussed earlier. All the methods have attained an accuracy of above90% and the minimum accuracy for gender classi ﬁcation obtained was 91.3% by Mahesh et.al for the CSR2 variant by fusing Zernike momentfeatures with shape features of camera images ( Mahesh et al., 2017). In the proposed method Soft X-rays were used to acquire the X-rayimages of the silkworm cocoon. An X-ray of the cocoon is used to extractthe shape features of the pupa. 1156 FC1, and 1226 FC2 samples wereused in this study. The shape features of the pupa such as width, height,area, perimeter, rectangularity, circularity, height to width ratio, solidity,convexity, volume, and weight were extracted. The novelty of this studyincludes the number of samples used each variety is high compared toother studies also tried a novel feature extraction method for widthand height computation and a proposed classi ﬁcation model using AdaBoost integrated with Linear discriminant analysis. The major advan-tage of this study is that the cutting of cocoons is not required for genderdiscrimination. Cutting of cocoons leads to economic loss in the sericul-ture industry and also it can be done only by skilled laborers.The remainder of the paper is organized as follows. Section 2dis- cusses the materials and methods which include sample collection,image pre-processing techniques, feature extraction, and classi ﬁcation method. The classiﬁcation results are presented inSection 3and it is dis- cussed in detail inSection 4. The major conclusions are given inSection 5.2. Materials and methodsTheﬂow of the research work includes the sample collection of FC1and FC2 cocoons then an X-ray image was acquired. Pre-processing wasperformed on the images for segmentation and noise reduction. Theprominent features were extracted and the dataset was prepared. Theentire dataset was divided into training and testing set on the ratio of80:20. The training dataset was used for the classi ﬁcation model devel- opment with 10-fold cross-validation and the remaining 20% testingdataset was used for external validation. The entire process is depictedinFig. 1.2.1. Sample collectionTwo single hybrid varieties of silkworm cocoon FC1(CSR6 x CSR26)and FC2(CSR2 x CSR27) were used for this research. Samples werecollected from the state sericulture department authorized FC1 andFC2 silkworm rearer. A total of 2382 samples were used in this study.The samples include 1156 FC1 cocoons with 589 males and 567 females,1222 FC2 cocoons with 623 males, and 599 females. Fig. 2shows some of the silkworm cocoons used in the study. It is hard to discriminatebetween male and female cocoons with the human eye. In seed produc-tion centers cocoons are cut and the pupae are taken out for the genderclassiﬁcation.Fig. 3shows some of the pupae of the single hybrid varietyused for our work.A single X-ray image of a single silkworm cocoon is used for thestudy. X-rays of the cocoon were acquired on the 10th day of cocooning.The pictorial representation of the x-ray imaging system is shown inFig. 4and some of the sample x-ray images of cocoons are shown inFig. 5. Gender classiﬁcation of the pupa was done with the help ofexperts in the silkworm seed production center, Palakkad, Kerala,India. Soft x-rays are employed for this study as soft x-rays are betterfor agricultural studies. The X-ray wavelength ranges from 1 to 10 nm,the X-ray tube voltage was 40 kV and the current was 0.6 mA.2.2. Image pre-processing2.2.1. Segmentation of the region of interestSegmentation is a very important task in image classi ﬁcation and object detection problems. Region of interest (ROI) provides the mostimportant information about an object in the image. Separating theROI from the noise was performed by segmentation. Thresholding isone of the segmentation methods where it considers the pixel value.Simple thresholding can be done in different ways in which if thepixel value is greater than the threshold then the pixel value is assignedto a maximum speci
ﬁed value otherwise set to zero or this can be donein reverse. Another simple thresholding is that if the pixel value isgreater than the threshold then that pixel value is truncated to thethreshold value otherwise zero. If the problem does not require chang-ing the source pixel value of the ROI then it can be done by making thepixels values to zero which are less than the threshold and keeping thepixel values greater than the threshold intact this can be done in reverse
Fig. 1.Flowchart of the work.S. Thomas and J. Thomas Artiﬁcial Intelligence in Agriculture 6 (2022) 100 –110
101also (Al-Amri and Kalyankar, 2010). The major disadvantage of thismethod isﬁnding the threshold value of an image with different lightingconditions in different areas of the image.In this study, the focus was given to the shape feature extraction ofthe image. Binary thresholding was an apt choice of segmentation, butidentifying the optimum threshold value is a tedious process in simplebinary thresholding. To overcome this Otsu's Binarization approachwas used in this study. Otsu's is a global image thresholding method.In this method, it obtains the histogram of the image then computesthe threshold value and replaces the image pixels with white if thepixel value is greater than the threshold and black otherwise. This bestworks with bimodal images. Otsu's binarization provides automaticthresholding while ordinary binary thresholding requires manualinput of threshold value. Otsu's binarization best performs with differ-ent lighting conditions and provides the optimum threshold value.The x-ray images of the pupa are bimodal so Otsu's binarization can pro-vide a better segmentation (Sund and Eilertsen, 2003).Img
output¼255src x;yðÞ>t0otherwise/C26/C27 ð1ÞOtsu's binarization reduces the within-class variance and maximizesthe between-class variance. The general representation of the weightedwithin-class variance and between-class variance of the two classes areexpressed asσ
2wtðÞ¼q1tðÞσ21tðÞ þq2tðÞσ22tðÞ ð 2Þσ2btðÞ¼q1tðÞq2tðÞμ1/C0μ2 ½/C1382ð3Þwhereq
1(t)a n dq 2(t) are the probabilities of the two classes.q
1tðÞ¼∑ti¼1PiðÞ ð 4Þq
2tðÞ¼∑Ii¼tþ1PiðÞ ð5ÞPiðÞ¼
ni
n; n is the total number of pixels in an image and n iis the number of pixels with aniintensity value.The next step is toﬁnd the foreground and background means whichare denoted byμ
1(t)a n dμ 2(t).μ
1tðÞ¼∑ti¼1iP iðÞq
1tðÞ ð6Þandμ
2tðÞ¼∑ti¼1iP iðÞq
2tðÞ ð7ÞNowσ
12(t)a n dσ 22(t) are computedσ
21tðÞ¼∑ti¼1i/C0μ1tðÞ½/C1382PiðÞq
1tðÞ ð8Þσ
22tðÞ¼∑Ii¼tþ1i/C0μ2tðÞ½/C1382PiðÞq
2tðÞ ð9ÞTotal variance can be denoted as the sum of within-class varianceand between-class variance.σ
2TtðÞ¼σ2wtðÞ þσ2btðÞ ð 10ÞThe optimum threshold value is computed by minimizing thewithin-class variance and maximizing between-class variance.Before performing Otsu's binarization a gaussian blur of kernel sizeof 7 × 7 is performed to reduce the noise and improve the result.Fig. 6shows the result of thresholding without performing Gaussianblur and the noise is visible in the result. Fig. 7shows the result of thresholding after applying gaussian blur to the image. The resultshowed a noise-free segmented image.2.2.2. Skewness correctionWhile taking the x-ray of the cocoon, the position of the pupa insidethe cocoon is unpredictable and it can be in any direction. Therefore,skewness correction was performed on the image. The operationinvolves the identiﬁcation of the angle of the pupa segmented fromthe x-ray image, and rotating the segmented image to correct theskew. Initially, a minimum area rectangle is drawn around the pupaand the rotation angleθis measured by the angle between the horizon-tal x-axis and theﬁrst edge of the identiﬁed minimum area rectangle. The expected angle will be between−90 degrees to 0 degrees. To compute the actual angle, if the angle of rotation obtained is−45 de- grees, then it is required to add 90 degrees to the angle and inverse itotherwise just inverse the angle. Based on this obtained angle the skew-ness correction was performed. The rotation matrix was identi ﬁed for this purpose. A rotated image was obtained by simple matrix multipli-cation of the original image with the rotation matrix.R
rotated ¼Ioriginal /C2M rotation matrix ð11Þwhere R
rotated is the rotated image, I original is the original image and M
rotation matrix is the rotation matrix. The rotation matrix of angle θis deﬁned as
Fig. 2.Silkworm cocoons of single hybrid variety.
Fig. 3.Silkworm pupae of single hybrid variety.S. Thomas and J. Thomas Artiﬁcial Intelligence in Agriculture 6 (2022) 100 –110
102Fig. 4.X-ray imaging system.
Fig. 5.X-ray images of the silkworm cocoon.
Fig. 6.Otsu's binarization without applying gaussian blur a) Original Image b) Histogram c) Segmented image.S. Thomas and J. Thomas Artiﬁcial Intelligence in Agriculture 6 (2022) 100 –110
103Mrotation matrix ¼cosθ−sinθsinθcosθ/C20/C21 ð12ÞThis matrix rotates the image about the origin and in this case, theorigin is the center of the image. But if required to rotate the image inan arbitrary coordinate, a modiﬁed rotation matrix is used whichincludes translation, rotation, and translation. The modi ﬁed rotation matrix is shown below.M¼αβ1−αðÞ /C2c
x−β/C2c y
−βαβ/C2c xþ1−αðÞ/C2c y/C20/C21 ð13Þwhereαis the scale value multiplied with the cosθandβis the scale value multiplied withsinθ. The scale value used for this problem is 1.c
xandc yare the arbitrary center about which the rotation needs to beperformed. In this problem, the center for rotation is used as thecenter of the contour identiﬁed around the pupa. This can becomputed by identifying the moments of the image.c
x¼m10
m00ð14Þc
y¼m01
m00ð15ÞThe skewness correction of the pupa image will help to identify thewidth of the pupa more accurately which is shown in Fig. 8.S u bﬁgure 8. a, 4.b, 8.c shows the stages of skewness correction. Fig. 8.d shows the original image after skewness correction for better understanding andFig. 8.e shows the contour drawn around the pupa after thresholdingand skewness correction.2.3. Feature extraction2.3.1. Measuring width and length of the pupaMethods that are used for the dimension measurement methodsinclude ellipseﬁtting and minimum rectangularﬁt method which helps in the width and height estimation of regularly shaped objects.In the ellipseﬁt method, an ellipse is inscribed within the object contourand used a minor axis for width estimation and a major axis for heightestimation. In the minimum rectangleﬁt method, a minimum area rect- angle isﬁtted around the object, and then use the width of the rectanglefor the width of the object and the height of the rectangle for the heightof the object. These two methods fail in some cases. Hence a newmethod was proposed in this study.In the proposed method, a point interpolation method was used. Thesteps are given below.Step 1: Identify the center of the contour by ﬁnding the moment features of the contour. Centre of the contour was measured using eq.(14)and eq.(15).Step 2: Identify the width and height of the image by considering thedimension of the image. Then calculate the extreme left, and right usingthe Eq.(16)and Eq.(17).Left end¼cX/C0w=2ðÞ ð 16ÞRight end¼c
Xþw=2ðÞ ð 17ÞStep 3: Perform Interpolation from center to endpoints by keeping c
y
as constant. The point which intersects with the contour is consideredas the width point.Step 4: Calculate the height by computing the extreme top and bot-tom points of the contour.Step 5: Compute the distance of the points by Euclidean distancemeasure.Fig. 9shows the width and height calculated with the ellipse method(Fig. 9.a), minimum area rectangle method ( Fig. 9.b), and proposed width calculation method (Fig. 9.c). From theﬁgures, it is clear that the ellipse method and rectangular method are not providing theexpected and accurate width of the pupa. Better accuracy of widthand height was obtained in the proposed method.2.3.2. Other predominant featuresOther predominant features considered for this study were area,perimeter, volume, circularity, rectangularity, solidity, convexity,width to height ratio, and weight apart from width and height. Thearea and perimeter of the pupa were calculated by considering thearea and arc length of the contour respectively. Circularity wasmeasured byﬁtting a minimum enclosing circle around the pupa anddividing the area of the circle with the area of the pupa. Rectangularitywas computed byﬁtting a minimum area rectangle around the pupaand dividing the area with the area of the pupa. Solidity was computedbyﬁnding the convex closure of the pupa and then dividing the area ofthe convex closure by the area of the pupa. Convexity was identi ﬁed by dividing the perimeter of the convex hull with the pupa perimeter.Calculating volume from a two-dimensional image is a dif ﬁcult task as it is not providing depth information. To overcome this issue manuallychecked the width and depth of the pupa using vernier caliper andfound out that there was not much difference in the width and depthof the pupa. Width and height information was computed from theimage. With the available height and width information, the volume iscomputed using the volume of the ellipsoid formula as the shape ofthe pupa resembles an ellipsoid.Table 1shows the summary of pre- dominant features and their calculations.
Fig. 7.Otsu's binarization after applying gaussian blur a) Original Image b) Applying gaussian blur c) Histogram d) Segmented image.S. Thomas and J. Thomas Artiﬁcial Intelligence in Agriculture 6 (2022) 100 –110
1042.3.3. Dimensionality reductionDimensionality reduction techniques help in reducing redundancy,noise, and the complexity of the algorithm which in turn improves the ac-curacy of the model (Huang et al., 2019). Dimensionality reduction methods were applied in variousﬁelds such as data mining, patternrecognition, machine learning, etc., (Xu et al., 2019). Different dimension- ality reduction methods such as Principal Component Analysis, LinearDiscriminant Analysis, Truncated Singular Value Decomposition,t-distributed Stochastic Neighbor Embedding (t-SNE), and Multidimen-sional Scaling (MDS) were used and the results were compared.
Fig. 9.Width and length estimation using various methods a) Ellipse methodb) Rectangular method c) Proposed method.Table 1Predominant features.Features CalculationArea Area of the contourPerimeter Arc length of the contourCircularity Area/Area of the minimum enclosing circleRectangularity Area/Area of the minimum area rectangleSolidity Area/Area of the convex closureConvexity Arc length of the convex closure/PWidth to height ratio Width/heightVolume (4/3)*(22/7)*(height/2)*(width/2)
2
Weight Weight of the cocoon with pupaWidth Proposed methodHeight Extreme points of the top and bottom contour
Fig. 8.Skewness correction a) Original image b) Segmented image c) Skewness corrected image d) Skewness corrected original image e) Original image with con tour.S. Thomas and J. Thomas Artiﬁcial Intelligence in Agriculture 6 (2022) 100 –110
1052.4. ClassiﬁcationIn ensemble learning, a single problem is solved based on the train-ing of multiple learners. A set of hypotheses are constructed and theyare combined to get a solution for the problem. This consists of baselearners or weak learners. In ensemble methods, the performance ofthe weak learners (base learners) is boosted. Base learners are devel-oped from the training data by base learning algorithms such asdecision-tree, logistic regression, etc. ( Binson et al., 2021a, 2021b, 2021c;Schapire, 2013;Wang et al., 2021). AdaBoost is used for the classiﬁcation of the data. AdaBoost is an en-semble learning method that converts weak learners into strong(Schapire, 2013). It is employed for this research as it is the bestmodel for a binary classiﬁcation problem (Wang et al., 2021). AdaBoost is used for both classiﬁcation and regression and it is a predictive jointlearning algorithm. AdaBoost uses multiple iterations to generate a sin-gle composite learner strong and hence it is adaptive. “It creates the strong learner (a classiﬁer that is well correlated to the true classi ﬁer) iteratively adding the weak learners (a classi ﬁer that is only slightly correlated with the true classiﬁer). During each round of training, anew weak model is added and is trained with the weighted trainingdata.”This step is repeated until the development of a preset numberof weak learners or no new enhancements could be made to the trainingdata (Binson et al., 2021a, 2021b, 2021c). AdaBoost is used in different applications such as disease diagnosis ( Sevinç, 2022;Binson et al., 2021a, 2021b, 2021c), quality prediction (Bai et al., 2021), gender clas- siﬁcation (Wang, 2021), banking (Lahmiri et al., 2020), etc., In this study, two weak learners such as decision tree and logistic regressionwere used.2.5. Computing environmentFor this research python, 3.8.8 version was used along with OpenCV4.5.2 and scikit learn 0.24.1 libraries. The operating system used wasMicrosoft windows 10, RAM 16GB, processor Intel core i7.3. Results3.1. Data analysis3.1.1. 10-fold cross-validationIn this study, the classiﬁer employed was AdaBoost and trieddecision tree and logistic regression as weak learners with different di-mensionality reduction techniques. To obtain the best performingmodel 10-fold cross-validation was employed ( Bey et al., 2020). The performance matrices such as accuracy, precision, recall, f1 score, andAUC score were used for analyzing the performance of the classi ﬁcation model which is shown inTable 2. The accuracy score provides informa-tion about how effectively the model classi ﬁed female cocoons and male cocoons. Precision gives information about how effectively the classi ﬁer performed the classiﬁcation based on misclassi
ﬁcation also known as false negatives. Recall gives the performance ef ﬁciency of the model based on false positives. F1 score provides an ef ﬁciency score of the model by using precision and recall which is the weighted average ofprecision and recall. Area under the ROC curve determines the effective-ness of the model in distinguishing the classes.The classiﬁcation of the dataset is done using Adaptive Boosting. Toobtain performance improvements various dimensionality reductiontechnologies such as Principal Component Analysis, Linear DiscriminantAnalysis, Truncated Singular Value Decomposition, t-distributed Sto-chastic Neighbor Embedding (t-SNE), and Multidimensional Scaling(MDS) were used. Two weak learners such as decision tree and logisticregression were tried and it is found that logistic regression used as theweak learner for the AdaBoost performed better than decision tree asthe weak learner in our binary classiﬁcation problem.Table 3shows the mean performance metrics score of FC1 cocoon classi ﬁcation of 10-fold cross-validation with different dimensionality reduction algo-rithms and logistic regression and decision tree as the weak learnerswhich are graphically represented using Figs. 10 and 11.Fig. 10visual- izes the performance evaluation of AdaBoost with Logistic regressionas a weak learner integrated with various dimensionality reductionmethods of FC1 variety.Fig. 11shows the evaluation metrics ofAdaBoost with the decision tree as the weak learner and different di-mensionality reduction methods for FC1. Hereby analyzing the perfor-mance metrics it is visible that the dimensionality reduction methodLDA applied with the classiﬁer AdaBoost and Logistic regression as theweak learner performed better with less time of 0.698 s for FC1.Table 4shows the mean score of the performance metrics such asaccuracy,f1, precision, recall, AUC, and time of the FC2 cocoon genderclassiﬁcation with different dimensionality reduction techniques alongwith the boosting ensemble learning method AdaBoost with Logisticregression and decision tree as the classiﬁer.Figs. 12 and 13represents the graphical representation of the performance of the classi ﬁer with Logistic regression and decision tree used as the weak learners alongwith different dimensionality reduction methods. By analyzing the per-formance metrics, it shows that LDA along with AdaBoost and Logisticregression as the weak learner attained better performance in 0.732 s.The classiﬁer model is also tried without using dimensionalityreduction techniques and the performance is depicted in Table 5.A n a - lyzing the data in the table shows that the performance of the classi ﬁer is enhanced by the use of the Linear Discriminant Analysis dimensional-ity reduction method.3.1.2. Proposed modelThe proposed model for the classiﬁcation of the pupa based on gen- der was designed using LDA + AdaBoost with Logistic regression as theweak learner. Hyperparameter tuning is done using the grid searchmethod. Theﬁnal model contains 100 estimators at which boosting isterminated. The weight applied to the boosting iterations is 0.0005.Stagewise Additive Modeling using a Multi-class Exponential loss func-tion (SAMME) is used as the boosting algorithm. The proposed model istested with the remaining 20% of data kept for the external validationpurpose. External validation is performed to view the performance ofthe model. The data used for the external validation is obtained withthe same acquisition condition as the main dataset. The number of im-ages used for external validation is 232 images of FC1(111 males and121 females) and 245 images of FC2(137 males and 108 females).The results showed that the proposed model attained an accuracy of95.3% in FC1 classiﬁcation and 95.1% in FC2 classiﬁcation.
Fig. 14shows the confusion matrix of the external validation of FC1 and FC2 using theproposed classiﬁer. The performance matrix derived from this confu-sion matrix is depicted inFig. 15.4. DiscussionGender classiﬁcation of the pupa is an important task in the mul-berry silkworm sericulture industry. This can help in improving thequality production of silkﬁlament as well as export. The classiﬁcation can be done before cutting the cocoon by using the X-ray imagingmethod which can penetrate through the cocoon so that we can extract Table 2Performance evaluation parameters.Evaluation MetricAccuracy Score
True PositiveþTrue Negative ðÞTrue
PositiveþFalse PositiveþTrue NegativeþFalse Negative ðÞnoPrecision Score
True PositiveTruePositiveþFalse Positive ðÞnoRecall Score
True PositiveTruePositiveþFalse Negative ðÞnoF1 Score
2/C2Recall/C2PrecisionðÞRecallþPrecisionðÞnoAUC Area under the ROC CurveS. Thomas and J. Thomas Artiﬁcial Intelligence in Agriculture 6 (2022) 100 –110
106Table 3Classiﬁer performance with Different dimensionality reduction methods for FC1.Classiﬁer Accuracy F1 Precision Recall AUC TimePCA + AdaBoost(Logistic Regression) 0.957 0.953 0.984 0.926 0.96 3.639 sPCA + AdaBoost(Decision Tree) 0.949 0.948 0.942 0.955 0.957 1.219 sLDA + AdaBoost(Logistic Regression) 0.971 0.97 0.974 0.967 0.971 0.698 sLDA + AdaBoost(Decision Tree) 0.968 0.967 0.967 0.966 0.969 0.778 sMDS + AdaBoost(Logistic Regression) 0.955 0.952 0.959 0.946 0.954 2.219 sMDS + AdaBoost(Decision Tree) 0.962 0.961 0.958 0.964 0.963 0.844 st-SNE + AdaBoost(Logistic Regression) 0.946 0.943 0.951 0.937 0.946 1.573 st-SNE + AdaBoost (Decision Tree) 0.827 0.834 0.777 0.91 0.876 0.806 sSVD + AdaBoost(Logistic Regression) 0.955 0.951 0.981 0.924 0.953 1.389 sSVD + AdaBoost(Decision Tree) 0.949 0.948 0.942 0.955 0.957 1.254 s
Fig. 10.FC1 data classiﬁcation using AdaBoost (Logistic Regression) with different dimensionality reduction methods.
Fig. 11.FC1 data classiﬁcation using AdaBoost (Decision Tree) with different dimensionality reduction methods.S. Thomas and J. Thomas Artiﬁcial Intelligence in Agriculture 6 (2022) 100 –110
107Table 4Classiﬁer performance with Different dimensionality reduction methods for FC2.Classiﬁer Accuracy F1 Precision Recall AUC TimePCA + AdaBoost(Logistic Regression) 0.938 0.936 0.954 0.921 0.94 2.131 sPCA + AdaBoost(Decision Tree) 0.867 0.871 0.847 0.898 0.872 9.732 sLDA + AdaBoost(Logistic Regression) 0.963 0.963 0.962 0.965 0.963 0.732 sLDA + AdaBoost(Decision Tree) 0.953 0.954 0.959 0.959 0.955 0.498 sMDS + AdaBoost(Logistic Regression) 0.936 0.936 0.936 0.937 0.951 2.586MDS + AdaBoost(Decision Tree) 0.938 0.936 0.959 0.916 0.938 0.669 st-SNE + AdaBoost(Logistic Regression) 0.9 0.9 0.898 0.904 0.899 1.513 st-SNE + AdaBoost (Decision Tree) 0.812 0.798 0.855 0.754 0.83 0.762 sSVD + AdaBoost(Logistic Regression) 0.927 0.927 0.938 0.917 0.927 0.889 sSVD + AdaBoost(Decision Tree) 0.867 0.871 0.847 0.898 0.872 0.974 s
Fig. 12.FC2 data classiﬁcation using AdaBoost (Logistic Regression) with different dimensionality reduction methods.
Fig. 13.FC2 data classiﬁcation using AdaBoost (Decision Tree) with different dimensionality reduction methods.S. Thomas and J. Thomas Artiﬁcial Intelligence in Agriculture 6 (2022) 100 –110
108the pupa features without destructing the cocoon. The proposed widthcalculation method provides a better width compared to the minimumarea rectangularﬁtting method and ellipseﬁtting method. The height computation was also better by considering the extreme points of thecontour than the ellipseﬁtting and rectangularﬁtting method. Feature extraction also plays a major role in classi ﬁer performance. The results session depicted the data analysis of the AdaBoost modelwith different weak classiﬁers such as decision tree and logistic regres-sion and performed different dimensionality reduction methods. Theclassiﬁer is analyzed with the help of the performance metrics such asaccuracy, precision, recall, f1-score, and AUC. Based on the analysis theproposed model is developed with AdaBoost using Logistic regressionas a weak learner with Linear Discriminant Analysis as the dimensional-ity reduction method. The AdaBoost model without using the dimen-sionality reduction method is also tried and the results are depicted intheTable 5. Comparing this table withTables 3 and 4, it is clear that applying the dimensionality reduction method LDA enhances theperformance of the classiﬁer. This proposed model was tested withthe validation dataset and obtained 95.3% of accuracy for FC1 and95.1% for FC2 gender classiﬁcation.X-ray imaging for mulberry silkworm pupa classi ﬁcation used in the research by Cai et al. reported accuracy of 93.31% with the LDA classi ﬁ- cation model (Cai et al., 2014). In this model, the author used shapesdescribing features such as ellipse major axis, ellipse minor axis, theratio of the major axis to minor axis, eccentricity, concave-convex char-acteristics, roundness, rectangularity, and complexity. The sample sizeused for this work was a total of 1071 of four hybrid varieties witharound 531 female and 540 male cocoons.The present research was carried out with 1156 FC1 and 1226 FC2samples which helped in a better understanding of the features of thepupa. Other methods used for pupa gender classi ﬁcation were NIR spec- troscopy (Tao et al., 2018a, 2018b;Zhu et al., 2018;Lin et al., 2019;Qiu et al., 2021), Hyper Spectral Imaging (HSI) (Tao et al., 2018a, 2018b;Tao et al., 2019a, 2019b), and the optical penetration method(Sumriddetchkajorn and Kamtongdee, 2012 ;Sumriddetchkajorn et al.,2013;Kamtongdee et al., 2015;Sumriddetchkajorn et al., 2015). The main concerns include that these methods required the destruction ofcocoons for the pupa gender classiﬁcation, the sample size used for each variety was less, and the cost of the machinery. Present researchwork showed a better accuracy compared with the existing methodsand the sample size used was higher compared with the existingstudies.If any method that accurately computes the volume irrespective ofassuming it to be a particular shape will contribute more to the research.The researchers have not proved the information that the exposure of acocoon to an X-ray can cause any damage to the pupa. Therefore, theproposed method can be adopted in seed production centers for thequality production of seeds. This requires more studies on how X-raysaffect the pupa when cocoons are exposed to x-rays.5. Conclusion
The Sericulture industry is an inevitableﬁeld that contributes to the cultural and economical development of a country. India is the second-largest exporter of silk. The quality of silk production can be improvedby separately reeling silkﬁbers of male and female cocoons. This canavoid the mixing of silk. The proposed model uses the x-ray images ofthe cocoons through which we can identify the shape features of thepupa without destructing the cocoon. The proposed width extractionand height extraction provides more accurate feature extraction.Table 5Classiﬁer performance without dimensionality reduction methods.classiﬁer Variety Accuracy Precision Recall F1-score AUCAdaBoost (Weaklearner: Logisticregression)FC1 0.921 0.914 0.924 0.918 0.935FC2 0.934 0.939 0.933 0.935 0.934AdaBoost (Weaklearner: DecisionTree)FC1 0.903 0.913 0.936 0.924 0.934FC2 0.883 0.884 0.887 0.885 0.887
Fig. 14.Confusion matrix of External Validation a) Confusion Matrix of FC1 b) Confusion Matrix FC2.
Fig. 15.Performance evaluation on external validation of FC1 and FC2.S. Thomas and J. Thomas Artiﬁcial Intelligence in Agriculture 6 (2022) 100 –110
109Application LDA as the dimensionality reduction method enhancedthe efﬁciency and performance of the classiﬁer. The proposed model with 10-fold cross-validation in the training data provided a meanaccuracy of 96.3% for both FC1 and FC2 variety. In external validation,the proposed model obtained an accuracy of 95.3% for FC1 and 95.1%for FC2.FundingThis research was funded by the Department of Science & Technol-ogy (DST) with grant reference number: SEED/WS/2019/135.CRediT authorship contribution statementSania Thomas:Conceptualization, Data curation, Investigation,Methodology, Software, Visualization, Writing –original draft.Jyothi Thomas:Conceptualization, Data curation, Funding acquisition,Methodology, Supervision, Validation, Writing –review & editing.Declaration of Competing InterestThe authors declare that they have no known competing ﬁnancial interests or personal relationships that could have appeared to in ﬂu- ence the work reported in this paper.AcknowledgmentThe authors would like to acknowledge the support of the seedproduction center, Palakkad, Kerala, India for the assistance in samplecollection.References
Al-Amri, S.S., Kalyankar, N.V., 2010. Image segmentation by using threshold techniques. arXiv preprint 2 (5), 83–86 (arXiv:1005.4020).Bai, Y., Xie, J., Wang, D., Zhang, W., Li, C., 2021. A manufacturing quality prediction model based on AdaBoost-LSTM with rough knowledge. Comput. Ind. Eng. 155, 107227.Bey, R., Goussault, R., Grolleau, F., Benchou ﬁ, M., Porcher, R., 2020.Fold-stratiﬁed cross- validation for unbiased and privacy-preserving federated learning. J. Am. Med.Inform. Assoc. 27 (8), 1244 –1251. Binson, V.A., Subramoniam, M., Mathew, L., 2021a. Detection of COPD and lung Cancer with electronic nose using ensemble learning methods. Clin. Chim. Acta 523,231–238.Binson, V.A., Subramoniam, M., Ragesh, G.K., Kumar, A., 2021b. Early detection of lung cancer through breath analysis using adaboost ensemble learning method. 20212nd International Conference on Advances in Computing, Communication, Embed-ded and Secure Systems (ACCESS). IEEE, pp. 183 –187. Binson, V.A., Subramoniam, M., Sunny, Y., Mathew, L., 2021c. Prediction of pulmonary dis- eases with electronic nose using SVM and XGBoost. IEEE Sensors J. 21 (18),20886–20895.Cai, J.R., Yuan, L.M., Liu, B., Sun, L., 2014. Nondestructive gender identiﬁcation of silkworm cocoons using X-ray imaging with multivariate data analysis. Anal. Methods 6 (18),7224–7233.Du, Z., Hu, Y., Ali Buttar, N., Mahmood, A., 2019. X-ray computed tomography for quality inspection of agricultural products: a review. Food Sci. Nutr. 7 (10), 3146 –3160. Ganga, G., 2019.An Introduction to Sericulture. Oxford and IBH Publishing.Gulzar, Y., Hamid, Y., Soomro, A.B., Alwan, A.A., Journaux, L., 2020. A convolution neural network-based seed classiﬁcation system. Symmetry 12 (12), 2018. Huang, X., Wu, L., Ye, Y., 2019. A review on dimensionality reduction techniques. Int.J .P a t t e r nR e c o g n i t .A r t i f .I n t e l l .3 3( 1 0 ) ,1 9 5 0 0 1 7 .Joseph Raj, A.N., Sundaram, R., Mahesh, V.G., Zhuang, Z., Simeone, A., 2019. A multi-sensor system for silkworm cocoon gender classi ﬁcation via image processing and support vector machine. Sensors 19 (12), 2656.Kamtongdee, C., Sumriddetchkajorn, S., Chanhorm, S., Kaewhom, W., 2015. Noise reduc- tion and accuracy improvement in optical-penetration-based silkworm gender iden-tiﬁcation. Appl. Opt. 54 (7), 1844 –1851.Lahmiri, S., Bekiros, S., Giakoumelou, A., Bezzina, F., 2020. Performance assessment of en- semble learning systems inﬁnancial data classiﬁcation. Intell. Syst. Account. Finance Manag. 27 (1), 3–9.Lin, X., Zhuang, Y., Dan, T., Guanglin, L., Xiaodong, Y., Jie, S., Xuwen, L., 2019. The model updating based on near infrared spectroscopy for the sex identi ﬁcation of silkworm pupae from different varieties by a semi-supervised learning with pre-labelingmethod. Spectrosc. Lett. 52 (10), 642 –652. Loddo, A., Loddo, M., Di Ruberto, C., 2021. A novel deep learning based approach for seed image classiﬁcation and retrieval. Comput. Electron. Agric. 187, 106269.Loddo, A., Di Ruberto, C., Vale, A.M.P.G., Ucchesu, M., Soares, J.M., Bacchetta, G., 2022. An effective and friendly tool for seed image analysis. Vis. Comput. 1 –18.Mahesh, V.G., Raj, A.N.J., Celik, T., 2017. Silkworm cocoon classiﬁcation using fusion of zernike moments-based shape descriptors and physical parameters for quality eggproduction. Int. J. Intell. Syst. Technol. Appl. 16 (3), 246 –268. Moulet, A., Bertrand, J.B., Klostermann, T., Guggenmos, A., Karpowicz, N., Goulielmakis, E.,2017.Soft x-ray excitonics. Science 357 (6356), 1134 –1138. Ozaki, Y., Huck, C.W., Beć, K.B., 2018.Near-IR Spectroscopy and its Applications. Molecular and Laser Spectroscopy. Advances and Applications, pp. 11 –38. Przybyło, J., Jabłoński, M., 2019.Using deep convolutional neural network for oak acornviability recognition based on color images of their sections. Comput. Electron.Agric. 156, 490–499.Qiu, G., Tao, D., Xiao, Q., Li, G., 2021. Simultaneous sex and species classi ﬁcation of silk- worm pupae by NIR spectroscopy combined with chemometric analysis. J. Sci. FoodAgric. 101 (4), 1323–1330.Schapire, R.E., 2013.Explaining adaboost. Empirical inference. Springer, Berlin, Heidel-berg, pp. 37–52.Schneider, A., Feussner, H., 2017. Biomedical Engineering in Gastrointestinal Surgery. Academic Press.Sevinç, E., 2022.An empowered AdaBoost algorithm implementation: a COVID-19 datasetstudy. Comput. Ind. Eng. 165, 107912 107912.Sumriddetchkajorn, S., Kamtongdee, C., 2012. Optical penetration-based silkworm pupa gender sensor structure. Appl. Opt. 51 (4), 408 –412. Sumriddetchkajorn, S., Kamtongdee, C., Sa-Ngiamsak, C., 2013. May. Spectral imaging analysis for silkworm gender classi ﬁcation. Sensing Technologies for Biomaterial, Food, and Agriculture 2013. vol. 8881. SPIE, pp. 21 –25. Sumriddetchkajorn, S., Kamtongdee, C., Chanhorm, S., 2015. Fault-tolerant optical- penetration-based silkworm gender identi ﬁcation. Comput. Electron. Agric. 119, 201–208.Sund, T., Eilertsen, K., 2003.An algorithm for fast adaptive image binarization with appli-cations in radiotherapy imaging. IEEE Trans. Med. Imaging 22 (1), 22 –28. Tao, D., Wang, Z., Li, G., Qiu, G., 2018a. Accurate identiﬁcation of the sex and species of silkworm pupae using near infrared spectroscopy. J. Appl. Spectrosc. 85 (5), 949 –952. Tao, D., Wang, Z., Li, G., Xie, L., 2018b. Simultaneous species and sex identi ﬁcation of silk- worm pupae using hyperspectral imaging technology. Spectrosc. Lett. 51 (8),446–452.Tao, D., Qiu, G., Li, G., 2019a.A novel model for sex discrimination of silkworm pupae fromdifferent species. IEEE Access 7, 165328 –165335. Tao, D., Wang, Z., Li, G., Xie, L., 2019b. Sex determination of silkworm pupae using VIS-NIR hyperspectral imaging combined with chemometrics. Spectrochim. Acta - A: Mol.Biomol. Spectrosc. 208, 7 –12.
Thomas, S., Thomas, J., 2020.A review on existing methods and classi ﬁcation algorithms used for sex determination of silkworm in sericulture. International Conference onIntelligent Systems Design and Applications. Springer, Cham, pp. 567 –579. Van De Looverbosch, T., Bhuiyan, M.H.R., Verboven, P., Dierick, M., Van Loo, D., DeBeenbouwer, J., Sijbers, J., Nicolaï, B., 2020. Nondestructive internal quality inspection of pear fruit by X-ray CT using machine learning. Food Control 113, 107170.Wang, J., 2021.Research on facial feature-based gender intelligent recognition based onthe Adaboost algorithm. Int. J. Biom. 13 (1), 40 –50. Wang, X., Ma, Y., Hsieh, M.H., Yung, M.H., 2021. Quantum speedup in adaptive boosting of binary classiﬁcation. Sci. China Phys. Mech. Astron. 64 (2), 1 –10. Xia, Y., Xu, Y., Li, J., Zhang, C., Fan, S., 2019. Recent advances in emerging techniques for non-destructive detection of seed viability: a review. Artif Intell Agr 1, 35 –47. Xu, X., Liang, T., Zhu, J., Zheng, D., Sun, T., 2019. Review of classical dimensionality reduc- tion and sample selection methods for large-scale data processing. Neurocomputing328, 5–15.Yu, X.H., Wang, C.L., Jiang, J.C., Jia, Z.W., 2005. Effect of cocoon dry and cooking conditions and silkworm gender on silk quality. Silk Monthly 3, 12 –15. Zhang, Y., Yu, X., Shen, W., Ma, Y., Zhou, L., Xu, N., Yi, S., 2010. Mechanism ofﬂuorescent cocoon sex identiﬁcation for silkworms Bombyx mori. Sci. China.Life Sci. 53 (11),1330–1339.Zhu, Z., Yuan, H., Song, C., Li, X., Fang, D., Guo, Z., Zhu, X., Liu, W., Yan, G., 2018. High-speed sex identiﬁcation and sorting of living silkworm pupae using near-infrared spectros-copy combined with chemometrics. Sens. Actuators B Chem. 268, 299 –309.S. Thomas and J. Thomas Artiﬁcial Intelligence in Agriculture 6 (2022) 100 –110
110