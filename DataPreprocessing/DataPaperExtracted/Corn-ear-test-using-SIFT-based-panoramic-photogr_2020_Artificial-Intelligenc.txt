Corn ear test using SIFT-based panoramic photography and machinevision technology
Xinyi Zhang, Jiexin Liu, Huaibo Song ⁎
College of Mechanical and Electronic Engineering, Northwest A&F University, Yangling 712100, Shaanxi, ChinaKey Laboratory of Agricultural Internet of Things, Ministry of Agriculture and Rural Affairs, Yangling 712100, Shaanxi, ChinaShaanxi Key Laboratory of Agricultural Information Perception and Intelligent Service, Yangling, Shaanxi 712100, China
abstract article info
Article history:Received 10 May 2020Received in revised form 6 September 2020Accepted 6 September 2020Available online 9 September 2020
Keywords:Corn earPanoramic photographyImage segmentationImage stitchingImage rectiﬁcationCorn ear test is important to modern corn breeding. The test indexes mainly include lengths, radiuses, rows andnumbers of corn ears and the kernels they bear, which can bene ﬁt the study on breeding new andﬁne corn va- rieties. These corn traits are often collected by traditional manual measurement, which is dif ﬁcult to meet the needs of high throughput corn ear test. In this study, image sequences of corn ear samples were captured bybuilding a panoramic photography collecting system. And then, to get the lengths and radiuses indexes, thecorn area images were processed based on Lab color space and adaptive threshold segmentation. The sequenceimages were then matched and the panoramic image of a corn surface were extracted using Scale-invariant fea-ture transform (SIFT). Finally, by using Exponential transformation (ETR) and Sobel-Hough algorithm, ears androws indexes were acquired. Test results showed that the accuracy of the radiuses and lengths were 93.84%and 94.53%, respectively. Meanwhile, the accuracy of kernels and rows indexes were 98.12% and 96.14%,which were 4.03% and 7.25% higher than that of common mosaiced panoramic image. And the accuracy of kernelarea and length-width ratio were 95.36% and 97.42%, respectively. All the results showed that the proposedmethod can be used for corn ear test effectively.© 2020 The Authors. Publishing services by Elsevier B.V. on behalf of KeAi Communications Co. Ltd. This is an openaccess article under the CC BY license ( http://creativecommons.org/licenses/by/4.0/ ).
1. IntroductionCorn, an important food crop, is a valuable source of multiple foodsand industrial products (Timsina et al., 2010;Talaviya et al., 2020). In 2019, global corn yield is expected to be 1.106 billion tons, and thecorn cultivated area in China has reached 0.65 billion hectares. It is anurgent task to make good usage of limited cultivated area to achievegood quality and high yield of corn ( Yang et al., 2006;Shiferaw and Tesfaye, 2006). Using genetic breeding technology to improve thecorn ear test (lengths, radiuses, rows and numbers of corn ears, andthe kernels) is an important way of modern corn breeding ( Cao et al., 2011;Zhao et al., 2009). It is also the foundation of analyzing reasonableyield structure of corn in different conditions and cultivating ﬁne varie- ties. Traditional manual measurement ( Wu et al., 2016) mainly depends on hiring lots of workers to calculate and measure corns at present,which is time-consuming and subjective. Owing to the low ef ﬁciency and the high cost of traditional manual measurement, researchers areturning to use machine vision technology for the detection and analysisof corn (Zayas et al., 1990;Jin and Tang, 2010;Jiang et al., 2019;Ireriet al., 2019;Xia et al., 2019), but there are only few methods for nonde-structive measurement of corn ear (Liu et al., 2015). The technology of corn test based on machine vision and panoramic photography has be-come an attracting trend of high throughput corn farming and hasattracted increasing attention.The objective of this study was to realize the detection of corn earusing panoramic image analysis by building a panoramic photographycollecting system. The lengths and radiuses indexes were calculated ac-cording to the rotation angle of the device and the ear radiuses of eachimage sequence, and the ears and rows indexes were got using theSIFT-based panoramic image.2. Related worksThe nondestructive measurement of corn ear test methods can beroughly divided into two categories according to the usage of ear im-ages: corn ear test based on side-view images and corn ear test basedon panoramic image.The corn ear test based on side-view image can be classi ﬁed accord- ing to the number of ear images, that is the phenotypic calculationmethod of single and multiple images. In the research based on singleimage,Miller et al. (2016)used Fourier transform sliding window to an-alyze the average size of kernels in the ears, and the Bayesian analysisArtiﬁcial Intelligence in Agriculture 4 (2020) 162 –171
⁎Corresponding author at: College of Mechanical and Electronic Engineering,Northwest A&F University, Yangling 712100, Shaanxi, China.E-mail address:songhuaibo@nwsuaf.edu.cn(H. Song).
https://doi.org/10.1016/j.aiia.2020.09.0012589-7217/© 2020 The Authors. Publishing services by Elsevier B.V. on behalf of KeAi Communications Co. Ltd. This is an open access article under the C C BY license (http:// creativecommons.org/licenses/by/4.0/ ).
Contents lists available atScienceDirect
Artiﬁcial Intelligence in Agriculture
journal homepage:http://www.keaipublishing.com/en/journals/artificial-intelligence-in-agriculture/was applied to calculate the geometric characteristics of the long andshort axes and contours of the ears. The results showed that the averageaccuracy of each index was above 90.00%. Zhou et al. (2015)obtained the 3D phenotypic parameters of corns through two-dimensional imag-ing, and combined the color characteristics of corns and the biologicallaws of corns to establish the model. The average measurement speedof the test system was 32.30 kernels/min. The zero-error rate of earrows and kernels per row was above 93.00%. When using multiple im-ages for corn ear test,Wang et al. (2014)presented an automatic 3D re- construction method of corn ear surface with binocular stereo visionunder multiple side-view images, each point cloud from differentviews was stitched, and the results showed that the volume of the 3Dreconstructed corn ear has no signiﬁcant difference from the manualmeasured value. It took about 3 h for each corn to complete 3D recon-struction.Grift et al., 2017calculated the number of kernels using ma-chine vision technology. By inferring the number of arti ﬁcially calculated rows and the number of ear rows in a single row in the arbi-trarily selected mid-cylindrical middle section, the total number of earnucleus after peeling was estimated. Although this method requiredsufﬁcient human interaction, it was simple to operate and an errorfrom−7.67% to +8.60% was got in 23 kernels of corns. In terms ofcorn ear image acquisition, although the single phenotype calculationmethod is more efﬁcient, it is easy to cause inaccurate measurement re-sults and poor stability due to incomplete surface information of thewhole ear. As for the multiple phenotype calculation method, it can im-prove the accuracy but the complexity of the algorithm is high due tothe redundant information on the corn ear surface.Panoramic photography is mainly a comprehensive image of the ob-ject. Panoramic photos are generally obtained by a panoramic camerawith a rotatable lens, but the hardware equipment is expensive andhard to operate. In recent years, to composite panoramic photographywith image sequences shooting by ordinary imaging devices has be-come the tendency (Szeliski, 1996;Brown and Lowe, 2007;Yu and Jungpil, 2010;Laraqui et al., 2017). For corn ear test using panoramicimages,Wang et al. (2013)rotated the corn ear in aﬁxed angle interval in order to capture image sequences. Then SIFT algorithm was carriedout to extract image feature points. Then the points were matched upin the neighboring images, and the relative motion between the two im-ages can be described by homography. According to the motion direc-tion, when the consistency detection was performed and the outlierswere excluded, the two images were registered to the same coordinatesystem. The dynamic programming method was used to ﬁnd a seam- line, and the redundancy regions in the two images along the seam-line were cut to get a fused image. This method consumed about 30sfor each corn ear. Experimental results showed that under the conditionof a signiﬁcant level ofα= 0.05, there was no signiﬁcant difference be- tween the method and manual measurement, but the gray value transi-tion phenomenon still existed in some areas of the panorama and themethod had much higher complexity. Based on a vertically ﬁxed indus- trial camera,Du et al. (2018)collected an image dataset of single cornear consisting of side-view images in different positions, the smallestarea of the center distortion of the corn ear was extracted, and the pan-oramic image of the ear surface was stitched. The system image acquisi-tion efﬁciency was 12 kernels/min, and phenotypic calculationefﬁciency is 4 kernels/min. The results showed that the accuracy ofthe length and the number of rows could reach 99.00% and 98.89%, re-spectively. But the number of sequence images was too large and thepanoramic images stitched had an obvious dislocation, which would af-fect the follow-up test work.3. Materials and methods
3.1. The capturing device of panoramic imageIn order to obtain the side-view images of a single corn ear, and toshoot around the ear in aﬁxed sequence, in this study, a steppingmotor and a single-chip microcomputer were selected as the main con-trol components for capturing the sequence images of corn. The captur-ing device was shown inFig. 1. The 51 single-chip microcomputer wasused to generate a 1000 Hz pulse signal with a ﬁxed frequency off
n
and the signal was inputted as the pulse signal terminal of a 42-typestepping motor, thereby generating a rotation with an angle θto drive aﬁxed frame to rotate the corn ear. The step angle θof the 42-type stepping motor was related to the natural step angle of the motor andthe open and shut status of the dial switch on the driver. After calcula-tion, the step angle used in this study was 0.1125°. On this basis, the51 single-chip microcomputer was used to generate a pulse signalwith a frequencyf
n= 160 Hz, which was the input to the driver's signalport, so that the stepping motor can rotate 18°. Therefore, 20 sequenceimages can be obtained.The digital camera used in this research was NIKON-D90 and themaximum pixel resolution was 4288 × 2848 pixel. The server platformwas conﬁgured as an Intel® Core (TM) i5-6300 HQ with 8GB runningmemory, 1 TB hard drive capacity, and the operating system was Win-dows 10 and the programming environment was MATLAB. In terms ofdevice design, a 51 single-chip microcomputers and a 42-type steppingmotor were selected to design a corn ear image acquisition device.Among them, the stepping angle of the 42-type stepping motor was1.8°, the step angle accuracy was ±5%, the maximum radial runout
Fig. 1.Systems consist of the capturing system.X. Zhang, J. Liu and H. Song Artiﬁcial Intelligence in Agriculture 4 (2020) 162 –171
163was 0.02 mm and the maximum axial runout was 0.08 mm under 450 gload.As shown inFig. 1, a corn ear isﬁxed on the bracket. When the angel18° was set by the 51 single-chip microcomputer and the 42-typestepping motor, the corn ear was rotated and one image was capturedby the camera. After a whole rotation of 360°, 20 sequence imageswere obtained for one corn ear and the following operation can be car-ried out.3.2. MaterialsIn order to verify the performance of the proposed method, 5 differ-ent varieties (Zheng Dan 958, Xian Yu 335, Zheng Da 12, Qin Long 14,Zhong Ke 11), and 10 corn ears were selected. They were air-driedand completely ripe when capturing images. And they were stored innormal temperature between 25 °C and 28 °C. Some corn ears wereprone to worm eggs due to their own characteristics, and the diseasedarea can be easily identiﬁed on image sequences of corn ear. Due tothe diversity of the selected samples, the parameters of the algorithmneeded to be adjusted to enhance the robustness of the algorithm. Apart of the sequence images was shown in Fig. 2, it consisted 10 corn ear images in the same angle. As can be seen from Fig. 2, the corn ears were always irregular cylinders, the kernels were arranged unevenly,and the axial direction was not aﬁxed line. Meanwhile, the size andshape of the selected samples were different, and the kernels of somesamples were deteriorated or missing. Furthermore, due to the limita-tion of shooting conditions, there were irrelevant backgrounds andshadows in sequence images, which needed to be removed in subse-quent operations. These problems made it dif ﬁcult for corn ear test. In order to check the quality of subsequent panoramic imagestitching, a label paper printed with tick marks and cosine curves wasdesigned in this study as shown inFig. 3. If the cosine curve on the label paper in the panoramic image was complete and continuous, thepanoramic image was considered to basically meet the requirementsof the test. When the ear was wrapped by the label paper around a cir-cle, the conversion relationship between the pixel and the actual dis-tance in the image can be found. After measurement and calculation, aunit length on the label paper was 0.45 cm, which corresponded to apixel distance of 92 pixels in the image. In the subsequent algorithmtest, the actual value of each test index of the corn ear was obtainedthrough the conversion of pixels and distances, and compared withthe manually tested results to show the performance of the proposedalgorithm.3.3. Method3.3.1. Sequence image processing using lab color spaceColor images obtained in natural environments are easily affected bynatural light, occlusion, and shadows, so they are more sensitive tobrightness. However, images in the Lab color space are less affected bysuch interference, and the main color of the image sequences of cornarea is yellow. It is easier to distinguish the ear area from backgroundby using the Lab color space. Therefore, the segmentation of kernelsbased on Lab color space was selected. As the RGB color space can't bedirectly converted to the Lab color space ( León et al., 2006), the RGB color space should be converted to the XYZ color space ﬁrst, which pro- vided necessary conditions for subsequent segmentation of the cornarea.The converted image in Lab color space was shown in Fig. 4(a). The main color of the corn area in the image sequences was yellow, and itwas within the variation range of the b-component of the Lab color space, as shown inFig. 4(b). It can be seen that the gray value of thecorn ear area in the image was high, which met the requirements ofthreshold segmentation, the segmented image was shown in Fig. 4(c). And then the connected domain analysis using the largestcircumscribed rectangle as the calibration area laid the foundation ofthe corn area.
Fig. 2.Image sequences of corn ear samples.
Fig. 3.Label paper with tick marks.X. Zhang, J. Liu and H. Song Artiﬁcial Intelligence in Agriculture 4 (2020) 162 –171
164The results showed that the proposed method can well extract thecorn area in the image sequences and calibrate it. Assuming that theshort side length of the largest circumscribed rectangle is mand the long side length isn, the ear radius and length were determined byEq.(1).R¼
∑Pi¼1mi
2
P,H¼∑Pi¼1ni
P ð1Þwhereirepresents the number of image sequences of corn ear, Rrepre- sents the radius of the corn ear,Hrepresents the length of the corn ear,andPrepresents the number of image sequences of corn ear.3.3.2. Determining and matching of key areas of corn ear image sequencesAfter obtaining image sequences of corn ear, it was necessary to de-termine the key area due to the redundant information of adjacent im-ages. In this way can the characteristic part of this image being cropped,which was different from other images. The determination of the keyarea was related to the ear radius and ear rotation angle calculated bythis image. Assuming that the corn ear radius obtained at the currentmoment isr
1, and after the rotation angleθ, the calculated ear radius isr
2. If the corn ear was a regular cylinder, the state of the rotation ontheﬁxing device can be equivalent to the ear rolling on the plane. Therolling angle was the rotation angleθ, and the rolling distance was thea r cl e n g t hw h e nt h ee a rr o t a t e d .As shown inFig. 5, the earOat pointAis the initial state. According to the scroll direction shown inFig. 5, the rolling distancel1reaches the po- sitionO′after the rolling distancel
1, and the pointsBandCcoincide. The rolling distancel
1should be equal to the arc lengthl 2of theABsegment. Considering the corn ear was an irregular cylinder, the calculation ofthe rolling distancel
1satisﬁes Eq.(2).l
1≈r1þr2
2/C2θ ð2ÞTo obtain the panoramic image of the corn ear surface, image se-quences of the corn ear in each rolling direction were shoot, then thekey areas of each image were intercepted, and all the key areas were or-derly matched on an image plane. The central axis of the key area wasalso the central axis of the corn ear image sequences, which was se-lected as the vertical centerline of the image, and the distance betweenthe central axes of adjacent key areas is the distance L
iafter the rolling angleθon the plane, as shown in Eq.(3).L
i≈riþriþ1
2/C2θ ð3Þwhereicorresponds to the order of the image sequence acquisition.The width of the key area was related to the distance between theadjacent image at the front and back, and the central axis of the keyarea at that time, as shown in Eq.(4).w
i¼Li
2þLi−1
2 ð4Þwherew
iis the width of the key area for the speciﬁed image. Due to the peculiarity of shooting image sequences of the corn ear,that was to take a total ofpimage sequences around the angle of thewhole interval of the corn ear. The relationship satis ﬁesL
pandw 1was s h o w ni nE q .(5).L
p≈rpþr1
2/C2θ,w1¼L1
2þLP
2 ð5ÞIn conclusion, the determination of corn ear's key area was to con-ﬁrm a rectangular regionrect. The coordinate relationship satisfyingthe image sequences of the area was shown in Eq. (6).rect
i:col2− Li−1
2,0 ,wi,row/C18/C19 ð6ÞAmong them,colandroware the width and height of the image se-quences of corn ear and the unit is pixel. The ﬁrst two components of the coordinates refer to the coordinates of the upper left corner of the rect-angular area, and the last two components are the width and height of
Fig. 4.Grayscale by extractingb-component and plotting the corn area in Lab color space. (a) Corn ear in Lab color space (b) image of target in b-component (c) segmented binary image.
Fig. 5.Corn rotating on horizontal plane.X. Zhang, J. Liu and H. Song Artiﬁcial Intelligence in Agriculture 4 (2020) 162 –171
165the rectangular area. Using only the small area closest to the camera caneffectively avoid deformation in other areas, and using the interceptedsmall area is for more stitching accuracy. As shown in Fig. 6,t h ei m a g e was cropped according to the coordinate relationship of Eq. (6), and the corresponding key area image could be obtained.After obtaining all the key area images of the corn ear image se-quences, a simple horizontally stitching operation was conducted. Bystitching the images of all the key areas in order, the panoramic imagecan be synthesized as shown inFig. 7. And the partly zoomed result ofthe panoramic imageFig. 7(a) is shown inFig. 7(b). The corn ear in Fig. 7is manually stitched with a label paper printed with a cosinecurve on the label paper in advance, so that the quality of the panoramicimage can be observed more intuitively. Because corn ear is an irregularcylinder and has the characteristics of radial distortion ( Du et al., 2016), there are obvious stitching marks in the panoramic image and the imageof adjacent key areas still has information redundancy, which will de ﬁ- nitely affect the corn ear test. Therefore, on the basis of existing work, itwas necessary to conduct operations for image recti ﬁcation using the information redundancy of adjacent key area images to make the keyarea image more consistent, which can reduce the error of subsequenttest work.3.3.3. Image rectiﬁcation based on SIFT algorithmAfter the key area image was cropped and the horizontal stitchingwas used to synthesize the panoramic image, there are still problemsof redundant information and obvious stitching marks as shown inFig. 8(a). The image rectiﬁcation algorithm based on SIFT algorithmcan be used to adjust the image according to the positions of imagematching points in adjacent key areas, which can ensure the needs ofhigh-precision test with the corrected panoramic image of the cornear surface.SIFT algorithm can be used to detect and describe parts of the fea-tures in images,ﬁnd extreme points on spatial scales, and extract theirposition, scale, and rotation invariants. Then the image data was trans-formed into scale-invariant coordinates based on the local features(Lowe, 1999). The SIFT algorithm mainly includes detecting scalespace extremes, determining the direction of key points, generatingSIFT feature vectors, and feature matching ( Lowe, 2004).When all the feature points of the image were extracted, the mis-matched points of the corn ear sequence images were deleted and thefeature points registration between the key areas was completed. Theimage with matching points based on SIFT algorithm is shown inFig. 8(b). The image with choosing points based on SIFT algorithm isshown inFig. 8(c). And the obtained matching points laid the founda-tion for subsequent image rectiﬁcation.3.3.4. Image shifting based on matched point coordinatesThe coordinate information of all different groups of matching pointsin the panorama was recorded inFig. 8(c). The distance of two adjacent key area images shifting horizontally was determined. That was to cal-culate the difference between the coordinates of the matching pointsin the same group, as shown in Eq.(7).dy
i¼yi−yi0ð 7Þwherey
iandy i′are the coordinates of the matched points in the adja-cent key area images before and after the moment, respectively, anddy
iis the distance betweeny iandy i′.A ss h o w ni nE q .(8),Krepresents the number of matched pairs in the same group and i≤K. Then, the rel- ative displacement of the two adjacent key area images in the directionof the positivey-axis satisﬁes Eq.(8).Dy¼
∑Ki¼1dyi
K ð8ÞAssuming that there arePimages in the key area of the corn ear,there areP-1 groups ofD
y, and the relative displacement of theﬁrst image in the sequence is 0. The displacement of the image relative totheﬁrst image at the subsequent time satisﬁes Eq.(9).dis_y
j¼0j¼1∑j−1i¼1Dyi1<j≤P8><>: ð9Þ
Fig. 6.Plotting and cropping the key area. (a) Plotting the key area (b) result of cropping.
Fig. 7.Result of panoramic image of corn surface. (a) Panoramic image of corn ear surface(b) result of partly zoomed corn ear surface.X. Zhang, J. Liu and H. Song Artiﬁcial Intelligence in Agriculture 4 (2020) 162 –171
166Then the maximum value ofdis_ywas found, which was recorded as U. The key area image with the maximum displacement dis_ywas regarded as the base point, and the relative distance of each image asDis_ywas calculated, which also represents the height of the ﬁlled area above each image. Theﬁlling pixels are 0, andDis_ysatisﬁes Eq.(10).Dis_y
j¼Uj¼1∣∑j−1i¼1Dyi !−U∣1<j≤P8><>: ð10ÞSimilarly, the minimum value ofdis_ywas recorded asU′, and the relative distance of each image to the key area image was Dis_y′ whose displacementdis_ywas the minimum value, which also repre-sents the height of theﬁlled area below the image. Theﬁlling pixels are 0 and satisﬁes Eq.(11).Dis_y
j0¼−U0j¼1∑j−1i¼1Dyi !−U01<j≤P8><>: ð11ÞIn summary, shifting the key area image vertically was to calculatethe height of each key area imageﬁlling the area above or below which isDis_yorDis_y′, and then the corresponding area wasﬁlled with 0 pixels to ensure that the matched points on the same horizontalline.The information redundancy of the adjacent images was not reducedafter the key area images were shifted vertically according to the coor-dinate of the matched points, but the matched points were correctedto a horizontal line. In order to further improve the accuracy of pano-rama stitching, it was necessary to crop the key area images. The objec-tive of this operation was to make the matched points coincide as muchas possible, and to reduce the information redundancy in the middlearea. Therefore, the horizontally shifting of the images of the key areaneeded to be completed. Assuming that among the same group ofmatching points inKpairs, the coordinates of each matching pointwere known, and the coordinate value of the slit in the two images isthe widthwaof theﬁrst image. Taking the origin ofﬁrst image sequence as the original coordinate, the width w
cof the cropping area satisﬁes Eq.(12).w
c¼∑Ki¼1wa−xi ðÞKþ ∑Ki¼1xi0−w a ðÞK ð12Þamong them,x
iandx i′are the abscissa values of the matching points oftheﬁrst and second image sequences.The coordinate information of the cropped area was set to rect
c.T h e coordinate relationship satisﬁed by the cropped area was shown inEq.(13).rect
c:w a−∑Ki¼1wa−xi ðÞK,0 ,w
c,Hc2666437775ð13Þamong them,H
cis the image height of two adjacent key area images af-ter being shifting vertically. Then the coordinate information of thecropped area was applied to all the key area images of a single corn ear.Theﬁnal panoramic image of the corn ear surface after shifting ver-tically and horizontally were shown in Fig. 9(a) and (b), respectively. After processing, the kernels' areas in the image were basically at thesame horizontal line, and there was no vertical dislocation. The cosinecurve of the label paper was more continuous and the information re-dundancy of the adjacent key areas was reduced, which lays the
Fig. 8.Corn matching and choosing based on SIFT algorithm. (a) Panoramic image of corn ear surface. (b) Matching feature points based on SIFT algorithm. (c) C hoosing feature points based on SIFT algorithm.
Fig. 9.Panoramic of corn surface after shifting the key area image. (a) Panoramic image of corn ear surface after shifting vertically. (b) Panoramic image of corn ear surface after shifting horizontally.X. Zhang, J. Liu and H. Song Artiﬁcial Intelligence in Agriculture 4 (2020) 162 –171
167foundation for the further usage of panoramic images to complete thecorn ear test.3.3.5. Panoramic mosaic corn ear test using computer vision(1) Calculating corn kernel number based on ETRThere is an irrelevant background from the corn ear in the panoramaas shown inFig. 10(a), and it is necessary to remove the background forextracting the ear area. Based on the Lab color space transformation, theb-component was extracted. The irrelevant background was basicallyeliminated in the grayscale image, and the ear area related to the testwas retained as shown inFig. 10(b).In the grayscale of the corn ear, the pixel value of the removed irrel-e v a n tb a c k g r o u n dp a r ti s0 ,a n dt h en u m b e ro fp i x e l si nt h i sp a r ti st o olarge. If the adaptive Otsu algorithm was used directly, the calculationof the optimal segmentation threshold will be affected. Therefore, it isnecessary to set the number of pixels, which has the pixel value ofzero, to zero, and then perform Otsu to obtain a binary image of cornear surface. Based on the analysis of connected domains, it was foundthat there are more kernels adhesion phenomena in the binary imageof kernels surface obtained by the segmentation method, which will af-fect the calculation of kernels indexes and reduce the accuracy of cornear test. As shown inFig. 10(c), a binary image of corn surface was ana-lyzed and the results of connected domain analysis were performed.The adhesive kernels were drawn by a red rectangular frame.In this research, the kernels synthesized from 10 corn ears were con-nected after the segmentation, and the number of connected kernelsvaried, which had an effect on the counting of kernels. The reason forconnected kernels was that the grayscale values in the kernels areaand the kernels gap were similar. Therefore, in order to further reducethe adhesive kernels, a grayscale transformation on the original cornear area was performed to increase the contrast between the area andthe gap, and used for further segmentation.The grayscale transformation was a direct and basic spatial domainimage processing method in image enhancement technology, whichcan improve the image quality and make the image much easier to un-derstand. ETR is also called Gamma transform, which can enhance dif-ferent gray intervals through different gamma coef ﬁcient values. In order to increase the contrast between the kernels and the gap betweenkernels, the brightness of the kernels gap area should be compressed tomake the kernels easier to distinguish. In this research, gamma=2w a s selected to expand the high luminance area (kernels area), and to com-press the low luminance area (the gap between kernels), and increasethe image details to segment the kernels. The enhanced image ofFig. 10(a) was shown inFig. 11.To prevent the background of the original corn ear area image fromparticipating in grayscale transformation, in this study, the distributionprobabilityE
kof each gray level was calculated based on the image ofthe corn ear area. If there was a probability g,w h e nE
k<gand the cor- responding gray level wasf
a, then determined [0,f a] as the background area; whenE
k<1-gand the corresponding gray level was f b, then the area with the gray range [f
a,fb] was used as the input area for the gray-scale transformation. In this way can the irrelevant background fromthe grayscale transformation being avoided.Adaptive Otsu was performed on the panoramic image of the cornear surface after grayscale transformation, and then the structural ele-ment with a template size of 10 × 10 pixel was used to perform mathe-matical morphological open operation on the segmented image toremove noise areas. The connected domain analysis was performed toremove the small area with a connected domain area <1000 pixels.When the kernels area at the edge of the image was removed, a binaryimage of corn ear surface can be obtained as shown in Fig. 12.T h e
Fig. 10.Extracting corn zone about corn ear test. (a) Panoramic image of corn ear surface. (b) Grayscale of corn ear area. (c) Binary image of corn ear surface an d plotting the connective kernels.
Fig. 11.Result of corn ear surface after exponential transformation.X. Zhang, J. Liu and H. Song Artiﬁcial Intelligence in Agriculture 4 (2020) 162 –171
168number of connective areas plotted by the red rectangular frame aresigniﬁcantly reduced but not completely removed.Although the binary image of corn ear surfaces obtained by grayscaletransformation cannot completely remove the connective kernels, theconnective area was reduced and the number of connective kernelswere basically <2 kernels. As it is not accurate to directly counting thekernels, the area and width ratio of all kernels in each connected com-ponent were recorded through connected components analysis, andthe adhesive areas were processed by a predetermined threshold, andafter counting the kernels in the non-adhesion area, the number of ker-nels in the adhesion area was accumulated, thereby the ﬁnal kernels number can be obtained.(2) Calculating the number of ear rows based on Sobel operator andHough transformSobel operator is one of the most important operators for imageedge detection (Chaple and Daruwala, 2014;Xu et al., 2017). It is simple and effective and suitable for detecting edge information of images withsimple texture. Due to the single target in the panoramic image of thecorn ear surface and the obvious gray scale changes between the earrows, Sobel operator was applied to realize edge extraction of the earrows.For detecting the number of ear rows, the x-axis direction difference operatorGxwas selected to convolve with the panoramic image to ex-tract the edges of the ear rows.Fig. 13(a) shows the result of the convo-lution of the Sobelx-axis direction difference operator and thepanoramic image followed by a binarization operation.Hough transform can use the duality of points and lines to change agiven curve in the original image space into a point in the Hough param-eter space through a functional expression, so as to identify the geomet-ric shape in the image. The morphological dilation operation of Fig. 13 (a) was carried out, so that the broken pixel rows of straight pixelunits were connected, and then the points in the image were mappedto the Hough parameter space. The detected lines of corn ear surfacewere shown inFig. 13(b), and the number of linesnlinescan be calculated.4. Results and analysis4.1. Corn ear radius and lengthIn this study, 10 ear corn samples were used for corn test. They werelabeled from 1 to 10, which were number 1 to 2 for Zheng Dan 958,number 3 to 4 for Xian Yu 335, number 5 to 6 for Zheng Da 12, number7 to 8 for Qin Long 14 and number 9 to 10 for Zhong Ke 11. For the cornear radius and length, the results of artiﬁcial and algorithmic tests were compared using the 10 ear corn samples.The method of extracting corn ear area based on Lab color spacetransform can calculate the length and width of the largestcircumscribed rectangle in sequence images of a single corn. The aver-age length of the rectangle's short side was twice the corn ear radius,and the average length of the rectangle's long side was twice the corn
Fig. 13.Calculating the number of ear rows. (a) Binary image after Sobel edge detection in x-axis direction. (b) Results of lines detection based on Hough tran sform.
Fig. 12.Binary image of corn ear surface and plotting the connective kernels after ETR.X. Zhang, J. Liu and H. Song Artiﬁcial Intelligence in Agriculture 4 (2020) 162 –171
169ear length. Based on the results of artiﬁcial test, the accuracy of corn ear based on algorithm was calculated. Experimental results of radius andlength are shown inTable 1. The results showed that the accuracy ofthe algorithm for measuring the ear radius was 93.84%, and the accuracyof the algorithm for ear length was 94.53%.
4.2. Number of kernels and rowsAs for the number of kernels and rows, it was mainly to compare thetest accuracy of the commonly used panoramic algorithm and the SIFT-based feature matching algorithm to record the kernels area and length-width ratio of the sample. Among them, simple stitching referred to theoperation of cropping and stitching without expanding the width of thecropped region of the sequence images.Table 2shows the results of computing the number of kernels androws. As for the number of kernels, the accuracy of the simple stitchingtest was 94.09%. After correction, it was 98.12%, with an increase of4.03%. And the standard deviation was 90.942. As for the number ofrows, the accuracy of the simple stitching test was 88.89%. Aftercorrection it was 96.14%, with an increase of 7.25%. And the standard de-viation was 1.2806.Table 3shows the results of computing the kernels area and length-width ratio. The kernels area of manual test is the average of 100 kernelsample areas of one corn ear. And the kernel area for algorithm test is
the median of all connected domain areas in the binary image. The man-ual test of the length-width ratio is based on manual measurement andthe algorithm test of the length-width ratio is the median of the length-width ratios of the largest circumscribed rectangles of all connected do-mains in the binary image. The results showed that the accuracy of thealgorithm for kernel area was 95.36%, and the accuracy of the algorithmfor length-width ratio was 97.42%.5. ConclusionA total of 10 corn ears samples of 5 different varieties were used fortest. The image sequences of corn ears were used for simple stitching.After shifting transformation, a SIFT-based panoramic image of theTable 1Experiment results of computing corn ear radius and length (mm).Ear number Radius LengthManual test Algorithm test Accuracy Manual test Algorithm test Accuracy1 25.1 24.5
93.84%185.0 200.6
94.53%2 25.4 25.8 185.0 189.83 25.6 23.2 192.0 186.84 24.7 23.8 182.0 184.25 24.1 23.6 178.0 182.46 22.2 21.5 202.5 195.87 25.0 22.6 203.0 191.78 26.1 22.0 193.5 178.89 24.5 25.9 175.0 180.210 24.7 26.7 166.5 196.3
Table 2Experiment results of computing the number of kernels and rows.Ear number The number of kernels The number of rowsSimple stitch Manual test Algorithm test Increase of accuracy Simple stitch Manual test Algorithm test Increase of accuracy1 654 669 655
4.03%16 16 16
7.25%2 723 675 662 15 16 163 780 744 742 17 18 174 693 680 663 15 16 165 685 670 687 19 18 186 694 678 641 17 16 157 560 555 545 16 14 158 626 637 625 17 16 159 525 461 460 12 16 1510 536 444 455 10 14 13
Table 3Results of computing kernel area and length-width ratio.Ear number Kernel area(mm
2) Length-width ratioManual test Algorithm test Accuracy Manual test Algorithm test Accuracy1 13.3025 12.8220
95.36%1.8975 1.9275
97.42%2 11.6848 12.0290 2.1002 2.01723 11.2890 11.5653 1.7988 1.73214 13.0364 12.9734 1.9592 1.91675 12.4992 12.0819 1.5639 1.61296 9.4095 8.2685 1.7264 1.76927 13.0176 12.6802 1.7456 1.70318 12.8892 12.1011 1.6845 1.65579 13.0530 13.9394 1.8382 1.800010 14.3244 14.4944 1.9821 1.9306X. Zhang, J. Liu and H. Song Artiﬁcial Intelligence in Agriculture 4 (2020) 162 –171
170corn ear surface was obtained. Image segmentation and connected do-main analysis were performed to calculate the ﬁnal indexes of the test. The results showed that based on the arti ﬁcial test data, the accu- racy of the corn ear radius was 93.84%, and the accuracy of length was94.53%. The accuracy of the number of kernels was 98.12%, and the ac-curacy of rows was 94.53%, with an increase of 4.03% and 7.25% com-pared with the simple stitching panoramic images method. And theaccuracy of the algorithm for kernel area was 95.36%, and the accuracyof the algorithm for length-width ratio was 97.42%. Except the loadingand rotating time of corn ears, the capture time of one corn ear wasabout 20s for 18 images each corn. The adaptive Otsu combining ETRand the SIFT-based panoramic image are used for the high-precisioncorn ear test and have made a great improvement. Meanwhile, as theSIFT algorithm and adaptive Otsu based on ETR was time-consuming,the generation of panoramic image usually consumed within 15 s. Theresult indicated the method had higher accuracy rate for corn ear test,showing that the proposed algorithm was feasible for corn ear test.In addition, the types and numbers of samples used in this paperwere limited, so more samples should be used for validating the pro-posed algorithm.Declaration of competing interestAll the authors declared that they have no con ﬂicts for publishing the paper.AcknowledgmentThis work was supported by the National Key Research and Develop-ment Program of China (2019YFD1002401) and the National HighTechnology Research and Development Program of China (863 Pro-gram) (No. 2013AA10230402). The authors would like to thank all ofthe authors cited in this article and the anonymous referees for theirhelpful comments and suggestions.References
Brown, M., Lowe, D.G., 2007.Automatic panoramic image stitching using invariant fea-tures. Int. J. Comput. Vis. 74 (1), 59 –73. Cao, J., Ran, Y., Guo, J., 2011.The design and realization of corn test system. Journal ofChangchun Normal University: Natural Science 30 (4), 38 –41. Chaple, G., Daruwala, R.D., 2014. Design of Sobel Operator Based Image Edge Detection Al-gorithm on FPGA. International Conference on Communications & Signal Processing,IEEE.Du, J., Guo, X., Wang, C., Xiao, B., 2016. Computation method of phenotypic parametersbased on distribution map of kernels for corn ears. Transactions of the Chinese Soci-ety of Agricultural Engineering (Transactions of the CSAE), 32(13):168 –176. Du, J., Guo, X., Wang, C., Xiao, B., 2018. Assembly line variety test method and system for corn ears based on panoramic surface image. Transactions of the Chinese Society ofAgricultural Engineering (Transactions of the CSAE) 34 (13), 195 –202.Grift, T.E., Zhao, W., Momin, M.A., Zhang, Y., Bohn, M.O., 2017. Semi-automated, machine vision based maize kernel counting on the ear. Biosyst. Eng. 164, 171 –180. Ireri, D., Belal, E., Okinda, C., Makange, N., Ji, C., 2019. A computer vision system for defect discrimination and grading in tomatoes using machine learning and image process-ing. Artiﬁcial Intelligence in Agriculture 2, 28 –37. Jiang, B., He, J., Yang, S., Fu, H., Li, T., Song, H., He, D., 2019. Fusion of machine vision tech- nology and alexnet-cnns deep learning network for the detection of postharvestapple pesticide residues. Artiﬁcial Intelligence in Agriculture 1, 1 –8. Jin, J., Tang, L., 2010.Corn plant sensing using real-time stereo vision. Journal of Field Ro-botics 26 (6–7), 591–608.Laraqui, A., Saaidi, A., Satori, K., 2017. Msip: multi-scale image pre-processing method ap- plied in image mosaic. Multimedia Tools & Applications 77 (6), 7517 –7537. León, Katherine, Mery, D., Pedreschi, F., León, Jorge, 2006. Color measurement in l*a*b* units from rgb digital images. Food Res. Int. 39 (10), 1084 –1091. Liu, C., Chen, B., Zhang, X., Wang, Q., Yang, X., 2015. Dynamic detection of corn seeds for directional precision seeding. Transactions of the Chinese Society for Agricultural Ma-chinery 46 (9), 47–54.Lowe, D.G., 1999.Object recognition from scale-invariant keypoints. Proc. INT'l Cnof.Conputer Vision 1999.Lowe, D., 2004.Distinctive image features from scale-invariant keypoints. Int. J. Comput.Vis. 20, 91–110.Miller, N.D., Haase, N.J., Lee, J., Kaeppler, S.M., De Leon, N., Spalding, E.P., 2016. Ar o b u s t , high-throughput method for computing maize ear, cob, and kernel attributes auto-matically from images. Plant J. 89 (1), 169 –178. Shiferaw, F., Tesfaye, Z., 2006.Adoption of improved maize varieties in Southern Ethiopia:factors and strategy options. Food Policy 31 (5), 442 –457. Szeliski, R., 1996.Video mosaics for virtual environments. IEEE Comput. Graph. Appl. 16(2), 22–30.Talaviya, T., Shah, D., Patel, N., Yagnik, H., Shah, M., 2020. Implementation of artiﬁcial in- telligence in agriculture for optimisation of irrigation and application of pesticidesand herbicides. Artiﬁcial Intelligence in Agriculture 4, 58 –73. Timsina, J., Jat, M.L., Majumdar, K., 2010. Rice-maize systems of south Asia: current status, future prospects and research priorities for nutrient management. Plant & Soil 335(1–2), 65–82.Wang, C., Guo, X., Wu, S., Xiao, B., Du, J., 2013. Investigate maize ear traits using machine vision with panoramic photography. Nongye Gongcheng Xuebao/Transactions of theChinese Society of Agricultural Engineering 29 (24), 155 –162. Wang, C., Guo, X., Wu, S., Xiao, B., Du, J., 2014. Three dimensional reconstruction of maize ear based on computer vision. Nongye Jixie Xuebao/Transactions of the Chinese Soci-ety of Agricultural Machinery 45 (9) (274-279 and 253).Wu, G., Chen, X., Xie, J., Zheng, Y., Tan, J., 2016. Design and Experiment of Automatic Va- riety Test System for Corn Ear (Transactions of the Chinese Society for AgriculturalMachinery).Xia, Y., Xu, Y., Li, J., Zhang, C., Fan, S., 2019. Recent advances in emerging techniques for non-destructive detection of seed viability: a review. Arti ﬁcial Intelligence in Agricul- ture 1, 35–47.Xu, B., Liu, L., Wu, X., 2017.A new method and simulation of image edge detection basedon sobel operator and FPGA design. Boletin Tecnico/Technical Bulletin 55 (11),285–292.Yang, G., Li, X., Wang, C., Luo, X., 2006. Study on Effects of Plant Densities on the Yield and the Related Characters of Maize Hybrids (Acta Agriculturae Boreali-OccidentalisSinica).Yu, T., Jungpil, S., 2010.De-ghosting for image stitching with automatic content-awareness, International Conference on Pattern Recognition. IEEE 23 (26), 26 –27. Zayas, L., Converse, H., Steele, J., 1990. Discrimination of whole from broken corn kernels with image analysis. Transactions of the ASAE 33 (5), 1642 –1646. Zhao, C., Han, Z., Yang, J., Li, N., Liang, G., 2009. Study on application of image process in ear traits for DUS testing in maize. Entia Agricultura Sinica 42(11).Zhou, J., Ma, Q., Zhu, D., Guo, H., Wang, Y., Zhang, X., Li, S., Liu, Z., 2015. Measurement method for yield component traits of maize based on machine vision. Transactionsof the Chinese Society of Agricultural Engineering 31 (3), 221 –227.X. Zhang, J. Liu and H. Song Artiﬁcial Intelligence in Agriculture 4 (2020) 162 –171
171