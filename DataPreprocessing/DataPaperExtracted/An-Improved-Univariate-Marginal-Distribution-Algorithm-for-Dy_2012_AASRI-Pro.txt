 AASRI Procedia   1  ( 2012 )  166 ‚Äì 170 
2212-6716 ¬© 2012 Published by Elsevier Ltd. doi: 10.1016/j.aasri.2012.06.026 
 
 2012 AASRI Conference on Computational Intelligence and Bioinformatics 
An Improved univariate Marginal Distribution Algorithm for Dynamic Optimization Problem 
Wu Yana*, Liu Xiaoxiongb 
a Department of Mathematics, Xidian University, Xi‚Äôan 710071, China 
bSchool of Automation Northwestern Polytechnical University, Xi‚Äôan 710072, China   
Abstract 
In dynamic environments, it is difficult to track a changing optimal solution over time. An improved univariate marginal distribution algorithm (IUMDA) is proposed to deal with dynamic optimization problems. This approach is composed of the diffusion model, which uses the information of current population, and the inertia model, which uses the part history information of the optimal solution. After an environment ch anged, the strategy is changed by a detecting operator to guide increasing the population diversity. Finally an experimen tal study on dynamic sphere function was carried out to compare the performance of IUMDA and mutation UMDA. The expe rimental results show that the IUMDA is effective for the function with moving optimum and can adapt the dynamic environments rapidly. 
 ¬© 2012 Published by Elsevier B.V. Selection and/or peer review under responsibility of American Applied Science Research Institute 
 Keywords: Evolutionary algorithm, Univariate marginal distribution algorithm (UMDA), Dynamic optimization problems, diversity of population 
1.Introduce Although most of the optimization problems discussed in the scientific literature is static, many real-word problems are dynamic, such as uncertainty dynamic cont rol systems, material processed. In these dynamic optimization problems, the evaluation function (or fitness fu nction) and the constraints may change over time. 
 * Corresponding author. Tel.: +86-029-88431398; fax: +0-000-000-0000 . E-mail address: yanerch@163.com. 
AASRI
Procedia
www.elsevier.com/locate/procediaAvailable online at www.sciencedirect.com
Open access under CC BY-NC-ND license.
Open access under CC BY-NC-ND license.167  Wu Yan and Liu Xiaoxiong  /  AASRI Procedia   1  ( 2012 )  166 ‚Äì 170 
 In such cases the optimization algorithm has to track a movi ng optimum as closely as possible, rather than just finds a single good solution.  It has been argued that evolutionary algorithms (EAs ) may be a particularly suitable candidate for this type of problems. However EAs need to be adapted for optimal results on dynamic optimization problems. When the changes occur, the solution given by the optimization procedure may be no longer effective and may actually be misguiding the search. In order to overco me the problems mentioned above, many methods have been proposed [1-8]. Considered above mentions, a new univariate marginal distribution algorithm (IUMDA) is proposed to solve dynamic optimization problems in this paper. 2.Improved Optimization Algorithm Considered the dynamic multi-objective optimization is as followings: 
12 m i n (,) ( (,) , (,) , , (,) )[, ] M f xt f xt f xt f xtsubject to x L V ¬è"
                                                                                  (1) Where 
t is time variable, x is decision variable, [, ]LV  is search space, (,)fx t  is objective which has the continuous objective function of 
Mand changes with time.  About this problem, the designed aim is that the alg orithm must track a changing optimal solution over time when environments are changed. So we must  use intelligence optimization algorithm to solve this problems. As the tradition evolutionary algorithms, the continue version of univariate marginal distribution algorithm (UMDA) is one sort of Estimation of Dist ribution Algorithms and has been applied to many optimization problems [6-7]. In the static environments, the optimal solution 
*()xtof the current population is usually acted as an attractor, which attracts the other individuals move towa rds the attractor to find the promising region of the optimum. However in the dynamic environments, wh en the problem changes at the end of generation
t, the next optimal solution may move away from*()xt. In order to find the new optimal solution, the algorithm needs increase the diversity and search new space which  is different from the region presented by current population. That is to say the promising region of optimum is away from
*()xt. If the environment changes at the end of generation 
t corresponding to the k-th change, the optimal solution of the current population is denoted by *()xtÀÑ*()xtis the optimal solution of generation tÀÖ, it is applied with the following formula to generate new individual
newx.  
*1(( ) )newxxx x tO                                                                                                                           (2) Where 
1O is random number from [0, 1]. According to th e diffusion model, if the environment changes at the end of generation
t, then *()xt can be considered as a repeller rather than an attractor. The reppeller guides the algorithm to search space away from the re peller and to increase the diversity of the population using the current information.  After the environment changed, it will be effective for dynamic optimization to predict the new optimal position by previous optimal solution. Assume that the environment changes at the end of generation 
t corresponding to the
k-th change, the optimal solution of the current population is*()xt, and then 
**() ( 1 )xt xt  which called velocity of optimal solution at change period 1k is used as the inertia velocity at change period
kto predict the next optimal solution. The model is denoted in the following. 168   Wu Yan and Liu Xiaoxiong  /  AASRI Procedia   1  ( 2012 )  166 ‚Äì 170 
 **2(( ) ( 1 ) )newx x xt xtO                                                                                                    (3)  Where 
xU¬è (Uis the set of selected individuals),2O is a random number from [0, 1], which denotes the step size to move in direction of
(1 )vk . From this model, if the prediction is correct, the prediction set aids the population to discover the new optimal solution quic kly. In order to detect the environment changed automatically, a detecting operator is proposed as follows: 
11, ,(, ) (, 1 )()max ( , ) ( , 1)sniiiiiis nfx fxs n fx fxWWHWWW
   ¬¶
"                                                                                    (4) Where 
ix is individual 1, 2,is n " Ààwhich is choose 10% of the colony dimension. When the 
()HW K! (K is a threshold), the environment is changed. Then by using the inertia prediction the algorithm convergence is increased. Based on the consideration above, the improved approa ch makes useful of the current information and part history information, and guide the population to search the promising region. Then an improved UMDA (IUMDA) is presented by incorporating UMDA with this  approach. The following is the improved algorithm: Step1. 
0tmÀàfor everyone variable, obtain randomly the parameters of a normal probability distribution for each variable. Step2. Draw
tXto obtain a population ()Pop t of N individuals; Step3. Test for change. Calculate
()HW , if the environment no changes, then turn to step 4, otherwise turn to step 6; Step4. Generate 
M neighbor individuals of *()xtto form the neighbor set U, where the neighbor distance is controlled in [0.05. 0.15]; Step5. Apply the formula (2), an individual will be adjusted the new population; Step6. Apply the formula (2) and formula (3) on 
U and get one set of D; Step7. Estimate the parameters of the new density functions according to
()St. Step8. Mutate 1tiVaccording to mutation probability; Step9. If the termination is not satisfied,
1ttm go to step 2, otherwise, stop. 3.Experimental Study In order to test the performance of the proposed algorithm, we used the dynamic sphere function with three dimensions [8]. The function is formulated as: 
22 212 3( , , ,) ( () ) ( () ) ( () )kk kfx y z t x t y t z t GGG                                                                 (5) Where 
(, ,)xyz is a time-invariant ‚Äúbasis‚Äù landscape. 12 3( ( ), ( ), ( ))kkktttGGG are the global optimal solution, which is a time-varying parameter, and moves randomly or period in different trajectories to construct dynamic function. In the above dynamic function, suppose that the environment is periodically changed every 
W generation, and then /ktW ¬´¬ª¬¨¬º is the change period index, where t is the generation counter. According to the different type along which optim al point moves, we can get three different dynamic test functions. 169  Wu Yan and Liu Xiaoxiong  /  AASRI Procedia   1  ( 2012 )  166 ‚Äì 170 
 In the dynamic random type, the optimal location is calculated as follows:         
1(0,1)kkmmsN GG  Àà 1, 2, 3m Àà00mG                                                                      (6) Where 
(0,1)N  is a Gaussian random variable with mean 0 and variance 1. Here the severity parameter determines the variance of the noise added to the previous optimal solution.  In this paper, the search space is set to 
3( 50.0,50.0) and Tis set to 25. In linear type, when the global optimal location moves past the search space, then the location moves in contrary direction by primary change severity. Experiments were carried out to compare the performance of the IUMDA and MUMDA on the test environments constructed above. MUMDA is hyper mutation based UMDA, in which hyper mutation is selected to increase the diversity when the problem is changed. In order to compare performance of different algorithms, the total population size 
Nis fixed at 40 individuals. The other parameters are set to 0.5D , 
0.2r .  The experimental results on test functions with diff erent dynamic type are plotted in Fig 1 and summarized in Table 1. 
 
(a)  The IUMDA results                                            (b) The MUMDA results  
Fig.1. Experimental results on random linear type of dynamic functions. Table 1 Offline error
rstandard error for different change severities on random type 
 Algorithms Shift severity s and change period W 
s=0.1, W=1       s=1.0, W=5       s=5.0, W=10 
IUMDA 0.0161r0.0799 0.1190r0.0500 1.3317r1.2206 
MUMDA 0.2437r0.8173 0.5768r0.2119 12.6367r7.5438 
 Figure 1 show the results of average optimum which plotted against generation. In each figure, three dynamic environments are tested by three algorithms . The environmental dynamics parameters are set to 
s=0.1, W=1; s=1.0, W=5 and s=5.0, W=10 respectively. 170   Wu Yan and Liu Xiaoxiong  /  AASRI Procedia   1  ( 2012 )  166 ‚Äì 170 
 From these figures, it can be seen that, generally, IUMDA outperforms MUMDA in the same environment. One straight forward approach to make EAs more su itable for dynamic environments is to increase the diversity after a change. However the rand om immigrant and hyper mutation approaches increase the diversity by generating the new individuals in the whole search space. Although these two approaches increase the diversity, the diversity is too dispersive to concentrate the promising region of optimum. Thus the computation time needed to track the optimum will be delayed. So in same environment the average optimum of MUMDA is worse than IUMDA. In such cases the improved algorithms has positive effect on the proposed algorithm to adapt the changed environment. 4.Summary In dynamic environments, it is important that the optimization algorithm is able to continuously track the moving optimum over time. In this paper, we proposed a new approach algorithm to tackle dynamic environments. The objective of the approach is to increa se the diversity in a guide fashion after a change. In a dynamic environment, it will be effective to predict th e new optimal position by previous optimal solution.  In this paper, because of considering a new str ategy for dynamic optimal problems, the proposed method only fits for Dynamic test function, and is good than other MUMDA faintly. To get better optimum results in dynamic environments, the algorithm is to improve in future yet. Acknowledgements This work is supported by the National Natural Science foundation of China (No.61105065). This work is supported by the Aeronautical Science Foundation of China (No. 20100753009). References [1] Blackwell, T. M., Branke, J., Multiswarms, Exclusio n, and anti-convergence in dynamic environments, IEEE Transactions on Evolutionary Computation, 2006, 10 (4):459-472 [2] Yaochu, J., Branke, J., Evolutionary optimization in  uncertain environments-a survey, IEEE  transactions on evolutionary computations, 2005, 9(3):1-15 [3] Yang, S., Memory-Enhanced Univariate Marginal Distribution Algorithms for Dynamic Optimization Problems, The IEEE Congress on Evolutionary Computation, 2005, Vol.1:2560-2567 [4] Yang, S., Yao, X., Experimental study on popu lation-based incremental learning algorithms for dynamic optimization problems. Soft Comput, 2005, Vol.9:815-834 [5] Hatzakis, I., Wallace, D., Dynamic multi-objective optimization with evolutionary algorithms: a forward- looking approach, Genetic And Evolutionary Computation Conference, Proceedings of the 8th annual conference. Seattle, Washington, USA, 2006, Vol.2:1201-1208  [6] M√ºhlenbein, H., Zinchenko, L., Kureichik, V. and Mahnig, T., Effective Mutation Rate for Probabilistic Models in Evolutionary Analog Circuit Design, Proceedings of the IEEE International Conference on Artificial Intelligence Systems, 2002, Vol.3:401-406 [7] Tang, M., Raymond Y. K. Lau,  A Hybrid Estimation of Distribution Algorithm for the Minimal Switching Graph Problem, Proceedings of the International Conference on computational Intelligence for Modelling, Control and Automation, and International C onference on Intelligent Agents, Web Technologies and Internet Commerce, 2005, Vol.1:708-713   [8] Angeline, P. J., Tracking, Extrema in Dynamic Environments, Proceedings of the 6th Int Conference on Evolutionary Programming, 1997, Vol.3:335-345  