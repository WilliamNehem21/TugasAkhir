Enhancing lithofacies machine learning predictions with gamma-rayattributes for boreholes with limited diversity of recorded well logs
David A. Wood
DWA Energy Limited, Lincoln, United Kingdom
ARTICLE INFO
Keywords:Rolling average derivativesLog-curve volatilityLithofacies log characteristicsConfusion analysisGamma-ray attributesWell-log feature augmentation.ABSTRACT
Derivative and volatility attributes can be usefully calculated from recorded gamma ray (GR) data to enhancelithofacies classiﬁcation in wellbores penetrating multiple lithologies. Such attributes extract information aboutthe log curve shape that cannot be readily discerned from the recorded well log data. A logged wellbore sectionfor which 8911 data records are available for the three recorded logs (GR, sonic (DT) and bulk density (PB)) isevaluated. That section demonstrates the value of the GR attributes for machine learning (ML) lithofacies pre-dictions. Five feature selection conﬁgurations are considered. The 9-var con ﬁguration including GR, DT, PB and six GR attributes, and the 7-var conﬁguration of GR and the six GR attributes, provide the most accurate and reproducible lithofacies predictions. The other three feature con ﬁgurations evaluated do not include the GR at- tributes but just one to three of the recorded log features. The results of seven ML models and two regressionmodels reveal that K-nearest neighbor (KNN), random forest (RF) and extreme gradient boosting (XGB) are thebest performing models. They generate between 14 and 23 misclassi ﬁcation from 8911 data records for the 9-var model. Multi-layer perceptron (MLP) and support vector classi ﬁcation (SVC) do not perform well with the 7-var model which lacks the PB feature displaying the highest correlation with facies class. Annotated confusionmatrices reveal that KNN, RF and XGB models can effectively distinguish all facies classes for the 9-var and 7-varconﬁgurations (that includes the GR attributes), whereas none of the models can achieve that outcome for the 3-var conﬁguration (that excludes the GR attributes). Accurately distinguishing lithofacies using well-log data insedimentary sections is an important objective in applied geoscience. The straightforward, GR-attribute methodproposed works to improve conﬁdence in ML-lithofacies classiﬁcations based on limited recorded well-log data.
1. IntroductionLithofacies classiﬁcation is a key requirement of sedimentologicalinterpretation and has been a cornerstone of applied sedimentology anddepositional-environment interpretations in the oil and gas industrysince the 1970s (Selley, 1978). The possibility of exploiting recordedwell-log data to assist in lithofacies classi ﬁcation dates back to the mid-twentieth century (Russell, 1944;Krumbein and Sloss, 1951). At that time, the well logs available that were able to provide reasonable reso-lution for lithofacies interpretation were limited to gamma ray (GR) anda compressional velocity/acoustic log providing travel time (DT).Nevertheless, since that time those well logs have been widely exploitedfor lithofacies analysis and stratigraphic sequencing ( Scholle and Spearing, 1982;Rogers et al., 1992;Emery and Myers, 1996). Well-log data has been most successfully exploited to distinguishlithofacies in clastic sedimentary sequences, with the shape and sensi-tivity of the GR log to sandstone/shale facies sequences well documented(Rider, 1986,1990;Cant, 1992). Additionally, the GR responses to grainsize of clastic formations (Hurst, 1990) make it possible to distinguish important lithofacies features such asﬁning- or coarsening upwards (Kesslar and Sachs, 1995;Faga and Oyeneyin, 2000). In carbonates, and other more varied and heterogeneous lithological sequences additionalgeological and mineralogical information is typically required to com-plement well-log data sufﬁciently to provide reliable lithofacies classi ﬁ- cation (Reverdy et al., 1983;Halotel et al., 2020). Such analysis typically requires core data and specialized well logs capable of distinguishingmineralogy, which are expensive and time-consuming to acquire. Mostwells drilled, particularly development wells, do not record compre-hensive well-log suites over the entire wellbore sections drilled. Conse-quently, for most well sections drilled, only a limited set of well logs areavailable. With such limited well-log data, traditional models thatattempt to predict lithofacies classes in multi-lithology sequences tend tolack precision and reliability.Statistical methods, speciﬁcally regression and cluster analysis
E-mail address:dw@dwasolutions.com.
Contents lists available atScienceDirect
Artiﬁcial Intelligence in Geosciences
journal homepage:www.keaipublishing.com/en/journals/artiﬁcial-intelligence-in-geosciences
https://doi.org/10.1016/j.aiig.2022.02.007Received 1 February 2022; Received in revised form 27 February 2022; Accepted 27 February 2022Available online 7 March 20222666-5441/©2022 The Authors. Publishing Services by Elsevier B.V. on behalf of KeAi Communications Co. Ltd. This is an open access article under the CC BY-NC-NDlicense (http://creativecommons.org/licenses/by-nc-nd/4.0/ ).Artiﬁcial Intelligence in Geosciences 2 (2021) 148 –164methods (Goncalves et al., 1995), have been applied to well-log data toassist in lithofacies prediction since the 1980s ( Busch et al., 1987). However, in multi-lithology sections well-log data typically displaysnon-linear relationships with lithofacies, making such methods unreli-able and relatively inaccurate. Various arti ﬁcial-neural-network models, particularly multi-layer perceptrons (MLP), are extensively used to pre-dict facies classes from well-log data ( Rogers et al., 1992;Puskarczyk, 2019;Hossein et al., 2020). One attraction of MLP is that for complexcarbonate sequences they can generally outperform regression, proba-bilistic (e.g., Bayesian classiﬁcation) and fuzzy classiﬁer methods in lithofacies classiﬁcation tasks using multiple well-log curves ( Dubois et al., 2007;Agrawal et al., 2022). Neural networks have also beenusefully hybridized with a Markov transition matrix ( Feng et al., 2018; Feng, 2020) to form Bayesian neural networks ( Feng, 2021) for lith- ofacies classiﬁcation using well-log data.In recent years, the high lithofacies prediction performance ofensemble and boosted-tree-based algorithms has become apparent ( Xie et al., 2019). This is particularly the case for carbonate and complexlithological sequences by several studies ( Hall, 2016;Hall and Hall, 2017; Al-Mudhafar, 2017;Bestagini et al., 2017,Shashank and Mahapatra, 2018). Adjusting the control parameters of boosted-tree models, such asextreme gradient boosting (XGB) with Bayesian optimization canimprove their ensemble-learning performance for lithofacies classi ﬁca- tion (Sun et al., 2020). Additionally, regression-free K-nearest neighbor(KNN) (Merembayev et al., 2021) and the transparent open box algo-rithmWood (2019,2020)have been successfully applied to challenginglithofacies and stratigraphic classiﬁcation and data mining using well-logdata. Combinations of data-matching algorithms with clustering tech-niques have also been usefully applied ( Potratz et al., 2021). Integrating ML models, clustering techniques (Fadokun et al., 2020), geological data (Ippolito et al., 2021) and bio-stratigraphic information ( Tran et al., 2020) with well log data can also be effective for facies classi ﬁcation purposes, in cases where sufﬁcient data is available.Recently (Wood, 2022), has demonstrated that calculating derivativeand volatility attributes from a GR log, associated with a highly variable
clastic sequence, is impressively effective at classifying several faciescharacteristics typically displayed by sandstones and shales, withoutrecourse to other well logs. This method is particular attractive forassessing wellbore sections for which very few well log curves arerecorded and/or for which core, mineralogy and biostratigraphy data arelacking. It is the objective of this study to build on that GR method,speciﬁcally to demonstrate that it is also highly effective at lithofaciesclassiﬁcation in multiple lithology sections with limited well-logcoverage. A logged section though varied lithologies (clastic, carbon-ate, salt and evaporite) is evaluated with this new GR-attribute techniqueto assess its potential applying seven distinct ML models and two linearregression models. The novelty of this study is that it applies theGR-attribute, lithofacies-classiﬁcation technique for theﬁrst time to a complex sedimentary section composed of multiple lithologies.2. Method and materials2.1. Well-log feature augmentationIt has been recently demonstrated using a synthetic GR log that de-rivative and volatility attributes extracted from the gamma-ray curvecould be effectively used to distinguish generic facies characteristics(e.g.,ﬁning upwards) in a clastic section (Wood, 2022). That method- ology is adapted here for application to lithofacies classi ﬁcation in a logged section from a real wellbore penetrating a diverse sequence oflithologies (i.e. limestone, dolomitic mudstone, halite, evaporite, shale,siltstone and sandstone). Six attributes are calculated from the recordedGR log: three derivative attributes; and, three volatility attributes.2.1.1. GR derivative attributesTheﬁrst derivative (d’GR) is calculated with Eq.(1).d
0GR¼ðGR d/C0GR d/C01Þ=Absðd/C0ðd/C01ÞÞ(1)where:GR
d¼recorded GR value at GR curve location d(depth in feet or meters);GR
d/C01¼recorded GR value at GR curve location d-1. The second derivative (d’’GR
dn) is calculated with Eq.(2).d
00GR dn¼ðd0GR d/C0d0GR d/C0nÞ=Absðd/C0ðd/C0nÞÞ(2)where:n¼a speciﬁed depth interval. Annvalue of 10 data points, or 1 m, is applied in this study, established via trial and error analysis.Theﬁrst derivative's moving-average metric (SMA) is calculated withEq.(3).SMAd’GR
dn¼ Xi¼ni¼1d0GR d/C0i!,n (3)Again, annvalue of 10 data points, or 1 m, is applied in this study,established via trial and error analysis. The optimum value of n is likelyto depending on the nature of the lithological section drilled. Finelyinterbedded strata with high volatility are likely to be better character-ized by relatively low values ofn. On the other hand, massive beddedsequences may be more effectively characterized by higher values of n. Trial and error tests are required to determine the n value, or range ofvalues, most suitable for speciﬁc drilled sections.2.1.2. GR volatility attributesWood (2022)proposed the use of volatility attributes as calculated bytheﬁnancial sector in the analysis of trends of traded market indices.The instantaneous movement or change in GR signal ( LnGR
i) repre- sents an intermediate step in establishing volatility. It is calculated withEq.(4)LnGR
iðdÞ¼LnðGR d=GR d/C01Þ (4)where:iðdÞ¼interval between depthsd-1andd(i.e., between sequential GR recorded points).Standard deviation is used to calculate volatility (
σi)o fLnGR iðdÞfor a speciﬁc sequence of GR data points. It is calculated with Eq. (5).
σiðdnÞ¼ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃPni¼1ðLd/C0i/C0L idmeanÞ2
n/C01s (5)where:
σiðdnÞ¼interval volatility between depths d-1andd-n;L d/C0i¼ LnGR
iðdÞfor each GR data point in the interval between depths d-1andd- n;L
idmean¼arithmetic mean ofLnGR iðdÞbetween depthsd-1andd-n;n¼ interval over which
σiis calculated. Annvalue of 10 data points, or 1 m, is applied in this study, established via trial and error analysis.The third volatility attribute is a simple moving average (SMA
σi)o f the GR volatility attribute. It is calculated with Eq. (6).SMA
σiðdnÞ¼ Xi¼ni¼1σd/C0i!,n (6)Again, annvalue of 10 data points, or 1 m, is applied in this study,established via trial and error analysis. As for the derivative SMA (Eq.(3)), the n value can be varied to suit the drilled geological section underconsideration. Furthermore, the value of n could also be different for Eqs.(5) and (6), if the trial and error analysis suggests it.The three derivative GR attributes and the three volatility GR attri-butes deﬁned by Eqs.(1)–(6)are used in this study as additional logfeatures to complement the recorded GR data points. Each of theseD.A. Wood Artiﬁcial Intelligence in Geosciences 2 (2021) 148 –164
149attributes emphasizes subtle changes in the GR trend as it changes withdepth, and these subtleties can be usefully exploited by machine learningalgorithms to classify lithofacies more precisely.2.2. Borehole logged section evaluatedThe logged wellbore section evaluated in this study is from theTriassic section penetrated in the Winterborne Kingston /C01 (WK-1) well bore drilled in 1981 in the western part of the petroliferous Wessex Basinin the Southern United Kingdom (Rhys et al., 1982). The section of in- terest represents an interval of about 900 m between measured depths1560–2460 m. It is selected for evaluating the potential bene ﬁts of GR attributes for multiple lithology facies prediction for several reasons:/C15The section includes a substantial range of primarily non-clastic li-thologies in a relatively small depth interval;/C15Some of the facies involved display quite similar absolute GR rangesand patterns;/C15Substantial parts of the section involve thinly interbedded lithologiesassociated with quite rapidly and extensively oscillating GR signals.This makes some of the lithofacies quite dif ﬁcult to distinguish by machine learning methods and/or cluster analysis using the GR log incombination with the DT and PB logs, as previously noted ( Newell et al., 2021).These feature of the WK-1 Triassic section pose a meaningful chal-lenge for testing GR attributes ability to improve lithofacies prediction inmulti-lithology sections, i.e., quite distinct from the clastic (sand/shale)sequences to which the GR attribute method has recently been success-fully developed and applied (Wood, 2022). The Triassic stratigraphy of the Western Wessex basin is summarizedinFig. 1.The lowest stratigraphic group of the well-log sequence evaluated istheﬁning upwards clastic sequence of the Sherwood Sandstone Group,resting unconformably on the shales of the Aylesbeare Mudstone Group.The Sherwood Sandstone, speciﬁcally the Otter Sandstone Formationlocally) is overlain by the variable lithologies of the Mercia MudstoneGroup. This“mudstone”group contains abundant dolomitic siltstoneinterbeds above and below the central evaporitic sequence constitutingthe Dorset/Somerset Halite. Above the halite zones, within the Bran-scombe Mudstone Formation, a thin but distinctive (from its well-logcharacteristics) anhydrite and limestone zone exists at about 1865mdepth. This is a representation of the Red Rock Gypsum Layer distributedsporadically in the Wessex Basin (Hounslow and Ruffell, 2006). The Blue Anchor formation is the uppermost formation of the Mercia MudstoneGroup. Its grey/green colored dolomitic siltstones with sporadic anhy-drite/gypsum layers display well log characteristics ( Howard et al., 2008), in terms of GR, DT and PB values, which are dif ﬁcult to distin- guish from those of the Otter sandstones. The uppermost stratigraphicgroup of the well-log sequence evaluated is the cream/grey colored, ﬁne grained Lilstock limestone of the Penarth Group (also referred to as theWhite Lias). That limestone represents the uppermost Triassic formation(Rhaetian age) and it overlain by shales of the Blue Lias (Jurassic).The GR, PB and DT, well log curves of the ~900 m thick section ofinterest are sampled at 10 cm intervals (10 data records/meter) with ﬁve lithofacies classes distinguished. Those lithofacies are allocated to classes1t o5 :1 Limestone with sparse anhydrite2 Dolomitic mudstones/siltstones3 Shale4 Salt5 Shaly sandstones and siltstonesIt is the lithofacies class numbers 1 to 5 that are predicted by the MLmodels evaluated.Fig. 2displays the recorded well logs as sampled from recordedcurves versus depth. The intervals of limestone, anhydrite, salt/evaporiteand shale, belonging to lithofacies 1, 4 and 3, display quite distinctive
GR, PB and DT signals and that can be readily distinguished by most MLalgorithms. However, there is a good deal of overlap in the GR, PB and DTvalues between the dolomitic mudstones/siltstones and shaly sandstonesand siltstones lithofacies (2 and 5) of the Mercia Mudstone and SherwoodSandstone formations. Consequently, the ML algorithms struggle todistinguish between portions of lithofacies 2 and 5.There are intrinsic transitional zones between each lithofacies(Fig. 2), which are more gradational between some intervals (e.g., the topof the Sherwood Sandstone and base of the Mercia Mudstone) but quite
Fig. 1.Summary stratigraphy and lithology of the Wessex Basin Triassic section relevant to the Winterborne Kingston WK-1 wellbore location. Incorporatin g in- formation fromUnderhill and Stoneley (1998),Hounslow and Ruffell (2006);Howard et al. (2008);Kaya (2015). BSPB refers to the Budleigh Salterton Pebble Beds.D.A. Wood Artiﬁcial Intelligence in Geosciences 2 (2021) 148 –164
150abrupt between other intervals (e.g., the contact at the top of the Som-erset Halite with the overlying dolomitic mudstone). One of the advan-tages of extracting and using the GR-attributes from the GR recorded datais that they are better able to characterize the gradational transitionzones between lithofacies than the recorded GR data on its own.Figs. 3 and 4display the three GR derivative and three GR volatilityattributes, respectively, calculated for each data record versus depth.Notice that the anhydrite/limestone band within the BranscombeMudstone Formation stands out as extreme values in all of the calculatedderivative/volatility attributes. Also, these attributes show quitedistinctive distributions for the Blue Anchor Formation (near the top ofthe section) and the Otter sandstones (at the base of the section). Such adistinction cannot be discerned from the GR data in isolation.Table 1compares the distribution statistics for the nine well logfeatures under consideration (three recorded well logs GR DT and PB; sixcalculated GR attributes). The cumulative probability distributions ofthese variables and the lithofacies number are displayed in Fig. 5. The derivative attributes, in particular, display quite expansive ranges ofvalues. In order to calculate the moving average attributes, the ﬁrst few data points of the interval are excluded from the data record sequenceevaluated. The sequence evaluated ( Table 1) involves a continuous sequence of 8911 data records (1565.9 m –2456.9 m inclusive). About 53% of those data records belong to facies class 2 (dolomitic mudstone)distributed through the post-Otter Sandstone sequence.Fig. 6displays a heat map of the calculated correlation coef ﬁcient values between the log variables and facies class. The values for all col-umns inFig. 6except the last column to the right are for the Pearson'scorrelation coefﬁcient (R), which assumes that the variable distributionsare parametric and essentially based on linear relationships. The right-side column (Fig. 6) displays Spearman's rank correlation coef ﬁcients (p), a non-parametric statistic that is more representative of distributionsof variables that follow non-linear relationships. The R values betweenGR and its attributes are low (<0.2, left-side column,Fig. 6). The R values between the GR attributes and facies class are substantially lower thanthose displayed by the GR, DT, PB recorded log data. PB displays thehighest negative R value with facies class ( /C00.49), compared to/C00.21 for GR andþ0.21 for DT.The p values for GR (/C00.07), DT (þ0.26) and PB (/C00.54) with facies class are quite distinctive from the R values. This difference is indicativeof non-linearity inﬂuencing the relationships between the threemeasured log curves and facies class, making the p values more repre-sentative of those distribution relationships than the R values. The GRattributes are individually poorly correlated in terms of both R and pvalues (<0.15) with facies class. Such relationships suggest thatregression-type models, particularly those based on linear assumptionsare unlikely to be able to predict facies class accurately using the recor-ded well log variables and/or, in particular the calculated GR-attributevariables.2.3. Regression and machine-learning algorithms appliedTwo linear regression algorithms, together with seven algorithmsconﬁgured for classiﬁcation applying distinct ML methods are used tomodel the log data recorded from the Triassic section of well WK-1,together with the six calculated GR attributes. The algorithms arecoded in Python and developed around SciKit Learn functions ( SciKit Learn, 2022a
).The algorithms evaluated have distinctive methodologies and can becategorized as regression-based (OLR, SGD and SVC), tree/ensemble-based (ADA, DT, RF, XGB), data matching (KNN) and neural network(MLP). These nine models are now deﬁned, in alphabetical order, with theﬁrst cited reference for each method referring to the original
Fig. 2.GR, PB and DT well logs recorded for the Triassic section of the WK-1 wellbore with 5 distinct lithofacies sequences distinguished as classes 1 to 5.D.A. Wood Artiﬁcial Intelligence in Geosciences 2 (2021) 148 –164
151developers of the algorithm for ML applications, and the subsequent ci-tations referring to example recent applications of each model to addresslithofacies classiﬁcation problems.ADA: Adaboost (Freund and Schapire, 1997;Wrona et al., 2018). DT: Decision tree (Quinlan, 1986;Sarkar and Majundar, 2020). KNN: K-nearest neighbor (Fix and Hodges, 1951;Merembayev et al., 2021).MLP: Multi-layer perceptron (Rosenblatt, 1958;Hossein et al., 2020). OLR: Ordinary least-squares regression ( Goldberger, 1964;Gao, 2011).RF: Random forest (Ho, 1998;Kim et al., 2018;Farzi and Bolandi, 2016).SGD: Stochastic gradient descent multi-linear regression ( Bottou, 1998;Agrawal et al., 2022).SVC: Support vector classiﬁer (Cortes and Vapnik, 1995;Mandal and Rezaee, 2019).XGB: Extreme gradient boosting (Chen and Guestrin, 2016;Bestagini et al., 2017).All the algorithms evaluated have been extensively deployed forlithofacies modelling and prediction. These algorithms are well describedin the literature (see for example citations associated with the models inthe list above), therefore their detailed methodologies are not describedhere. However, the models do require con ﬁguration and tuning adjust- ments to suit each dataset. This is achieved by establishing optimumvalues for the control/hyperparameters.Model architecture and hyperparameter selection involves severaltechniques. Trial and error is important to establish a range of suitablestructures and control values. Further reﬁnement of the trial-and-error results can be achieved rapidly using grid search ( SciKit Learn, 2021a)and Bayesian optimization (SciKit Learn, 2021b) to rapidly assess a wide range of control values within speciﬁed ranges. These techniques make itpossible to locate the optimum control parameter values for each modelfor the dataset under investigation, which are shown for the models usedin this study inTable 2. Applying the optimum conﬁgurations and control parameters, the models can then be evaluated with K-fold cross valida-tion (SciKit Learn, 2022b) to establish their repeatability with variousrandom splits of the dataset into training and testing subsets.2.4. Data preprocessingThe well log data and calculated GR attributes fed as input to themodels are each normalized to scale range of /C01t oþ
1. Such normali- zation removes the possibility of scale biases causing certain variables toexert greater inﬂuence than others in the facies class predictions. Thatnormalization is conducted with Eq.(7).Normx
mi¼2*/C18xmi/C0xminm
xmaxm/C0xminm/C19/C01(7)where:Normx
mi¼variable value adjusted to a/C01t oþ1 scale; xmi¼actual recorded/calculated value forith data point in themth variables distri- bution;xmin
m¼minimum value ofmth variable distribution;xmaxm¼ maximum value ofmth variable distribution.2.5. Metrics for assessing classiﬁcation performance and misclassiﬁcationErrors in lithofacies classiﬁcation are assessed in this study usingseveral widely used performance measures for which de ﬁnitions and
Fig. 3.Three GR derivative attributes calculated for each GR data point of the Triassic section of the WK-1 wellbore. These derivative attributes are the ﬁrst derivative (d’GR), the moving average per meter of the ﬁrst derivative (SMAd’GR) and the second derivative (d ’‘GR).D.A. Wood Artiﬁcial Intelligence in Geosciences 2 (2021) 148 –164
152calculation formulas are provided inAppendix A. These metrics are:Root Mean Squared Error (RMSE)Mean Absolute Error (MAE)Coefﬁcient of Determination (R
2)Total number of prediction errors (PError) Accuracy (A)Precision (P)Recall (R)Balanced F-score (F
1)It is essential to consider the statistical measures of prediction per-formance (PError, RMSE, MAE and R2) in conjunction with measures relating speciﬁcally to misclassiﬁcations (A, P, R, F1).3. Results3.1. Models evaluated for WK-1 Triassic well log dataThe base case feature conﬁguration for facies class prediction in theWK-1 Triassic section is the 3-variable model (3-var) considering just the
Fig. 4.Three GR volatility attributes calculated for each GR data point of the Triassic section of the WK-1 wellbore. These volatility attributes are the ins tantaneous change (LnGR
i), volatility ( σGR) and the moving average per meter of the volatility (SMA σGR).
Table 1Statistical characterization of well log variable and facies class distributions for Triassic well log interval of well WK-1.
Statistical Summary of Recorded Well Log and Gamma Ray Attribute Variables8911 Data Points GR DT PB d'GR SMAd'GR d''GRdn LnGRi(d)
σi(dn) SMA σi(dn) Facies<ClassMinimum 13.8 50.7 1.80 /C018.617/C09.362/C09.863/C00.435 0.00000 0.00000 1 5th Percentile 21.4 58.3 2.08 /C04.071/C02.504/C00.803/C00.048 0.00000 0.00007 2 10th Percentile 26.7 60.5 2.10 /C02.217/C01.694/C00.405/C00.024 0.00002 0.00038 2 25th Percentile 74.8 66.1 2.39 /C00.708/C00.658/C00.082/C00.008 0.00021 0.00228 2 50th Percentile 105.6 69.9 2.56 /C00.054/C00.032 0.000 /C00.001 0.00541 0.00830 2 75th Percentile 138.1 74.6 2.63 0.844 0.676 0.083 0.009 0.02148 0.02349 4 90th Percentile 153.7 78.3 2.68 2.058 1.653 0.389 0.022 0.05865 0.05156 5 95th Percentile 165.9 80.3 2.69 3.227 2.496 0.701 0.042 0.08624 0.07546 5 Maximum 197.3 111.2 2.95 88.282 8.396 9.533 1.726 0.61501 0.59969 5 Average 101.7 70.1 2.48 /C00.001 0.001 0.000 0.000 0.01910 0.01912 2.8 Standard Deviation 44.3 7.0 0.20 3.354 1.552 0.540 0.044 0.03617 0.03085 1.1 Standard Error 0.4689 0.0745 0.0022 0.0355 0.0164 0.0057 0.0005 0.0004 0.0003 0.0117 Coefﬁcient of Variation0.435 0.100 0.082 /C04002 2545 3425 /C02669 1.894 1.614 0.397D.A. Wood Artiﬁcial Intelligence in Geosciences 2 (2021) 148 –164
153recorded GR, PB and DT log data. Nine models are trained and testedwith this conﬁguration: two linear models (OLR and SDR) and seven MLclassiﬁcation models (ADA, DT, KNN, MLP, RF, SVC and XGB). The faciesprediction results for the training and testing subsets for the 3-varconﬁguration for all model are shown inTable 3. The perfect results for the training subset achieved by the ADA, DT,KNN and RF models and substantially substantial prediction errors forthe testing subsets suggest that those models are tending to over ﬁt training subsets. However, in terms of the classi ﬁcation accuracies ach- ieved by the trained models with the unseen testing subsets, the RF, SVCand KNN models substantially outperform the other models consideringthe low RMSE, MAE andPError values those models achieve. The linearmodels generate the poorest facies prediction performance for the 3-vartesting subset based on those error metrics. In terms of computerexecution time, the XGB and MLP models take substantially longer toexecute than the other models. Of the high-performing models, KNNtakes the shortest execution time (<6 s) for the 3-var conﬁguration. In addition to the 3-var base case evaluation four other variableconﬁguration are evaluated with each of the nine models. The con ﬁgu- rations evaluated and compared are:/C159-var: (GR) (DT) (PB) (d’GR) (SMAd'GR) (d’‘GR)ðLnGR
i)(σGRi) (SMA
σi(dn))/C157-var: (GR) (d’GR) (SMAd'GR) (d’‘GR)ðLnGR
i)(σGRi) (SMA σi(dn)) /C153-var: (GR) (DT) (PB) [Base Case]/C152-var: (GR) (PB)/C151-var: (GR)Two other 2-var conﬁgurations were also evaluated (GR with DT, andDT with PB). However, the GR with PB combination delivered betterpredictions than those other conﬁgurations, so only the GR with PB 2-varconﬁguration results are presented.The facies class prediction performances of the ﬁve-feature conﬁgu- rations deﬁned are benchmarked against the 3-var con ﬁguration (base case) using each of the nine prediction models considered.
Fig. 5.Cumulative probability distributions for: (A) recorded GR and DT logs; (B) recorded PB log and lithofacies number; (C) calculated GR derivative attr ibutes; and, (D) calculated GR volatility attributes. The extreme ends of some of the GR derivative and GR attribute distributions are excluded to facilitate disp lays on mean- ingful scales.
Fig. 6.Pearson's Correlation coefﬁcients for variables associated with the Triassic well log interval of well WK-1. Both Pearson's and Spearman's coef ﬁcients are displayed for correlations of the variables with facies class.D.A. Wood Artiﬁcial Intelligence in Geosciences 2 (2021) 148 –164
1543.2. Five-fold cross validation analysisAn initial step in the facies classiﬁcation analysis was to conduct K- fold cross validation for each of the nine models using different training:testing subset splits to establish the splits that generate the most reliable/reproduceable results. Trial and error tests were conducted with differentsubset splits and the K-fold method. These revealed that the 80%:20%(training: testing) provided the best results for each of the nine models.Hence, the results of the 5-fold cross validation are shown in Table 4. The 5-fold cross-validation procedure randomly divides the dataset(8911 data records) intoﬁve compartments. Four of those compartmentsare assigned to the training subset (7168 data records) and one to thetesting subset (1743 data records). The assignments are repeated ﬁve time so that each of the compartments serves as the testing subset in onecase. This means that there areﬁve cases evaluated for each run ensuringthat each data record is treated as both a training record and a testingrecord considering allﬁve cases. In this study the 5-fold procedure hasbeen repeated three times, generating results for 15 cases in all. Thiscomprehensive sampling of the dataset provides meaningful statisticalassessments (mean and standard deviation of all 15 cases) of the faciesclass prediction performance of each model evaluated. These 5-foldcross-validation statistics can be usefully compared ( Table 4). Table 4displays the mean MAE values and MAE's standard deviations(σ2MAE) for the 15 cases generated by each ML model. The MAE valuesare expressed on a scale that relates to facies class (1 –5). It is apparent that the are
σ2MAE low in all cases, and more than an order of magnitudelower than the mean MAE values. This demonstrates that all the modelscan be relied upon to generate reproducible results with any randomlyselected 80:20 split of the dataset into training and testing subsets.For the 3-var (base case) and 2-var conﬁgurations, the SVC model generates the lowest 5-fold mean MAE values, but a higher
σ2MAE values than some of the other models. For instance, the KNN and RF modelsgenerate mean MAE values slightly higher than the SVC model but lower
σ2MAE values for those variable conﬁgurations. Also the XGB model is not among the best performing models for the var-3 and var-2 con ﬁgu- rations. However, for the 9-var and 7-var con ﬁgurations, the XGB modelTable 2Set up and control parameters for regression and ML algorithms applied to pre-dict lithofacies class for the WK-1 Triassic well log section evaluated.
Algorithm Control Parameter Values AppliedAdaboost (ADA) Number of estimators ¼750; learning rate¼0.01; base estimator is DT with depth ¼250; splitter¼best Decision Tree (DT) Maximum depth ¼5000; splitter¼best; splitting criteria¼gini K Nearest Neighbor (KNN) Weighted using Manhattan distance; number of neighbours assessed (K) K¼5 for 2-var and 3-varmodels; K¼2 for 7-var and 9-var models; k ¼25 for 1-var model Multi-layer Perceptron(MLP) 3 hidden layers with 100, 50 and 25 neurons;activation fn.¼relu; Solver¼adam; alpha¼0.001 for models 2-var, 3-var, 9-var; alpha ¼0.001 for models 1-var and 7-var; adaptive learning rate Ordinary Least SquaresRegression (OLR) No control parameters requiredRandom Forest (RF) Number of estimators ¼750; maximum depth¼150; splitting criteria¼gini Stochastic Gradient DescentClassiﬁer (SGD)Learning rate/regularization
α¼0.0001; maximum iterations¼10000 Support Vector Classiﬁer(SVC) Kernel¼rbf; C¼750; gamma¼50 for models 1-var, 2-var, 3-var gamma¼75 for 7-var model; gamma¼ 25 for 9-var model XG Boost (XGB) Number of estimators ¼2000; Maximum depth¼7; eta¼0.01; Subsample¼0.7; Columns sampled pertree¼0.5
Table 3Lithofacies classiﬁcation performance for the WK-1 Triassic well log section evaluated with nine models for the base case 3-variable (3-var) model applying the optimal89%:20% split of data records between the training and testing subsets (the testing subsets comprise 1783 of the 8911 data records available).
WK-1 Triassic Section Lithofacies Predictions Using only Recorded Well Log data for GR, DT and PB (3-Variable Model)ModelTraining Subset (80%) Testing Subset (20%) Applied to All 8911 Data RecordsR2 RMSE MAE∑Error R2 RMSE MAE ∑Error R2 RMSE MAE ∑Error Ex TimeADA1.00000 0.00000 0.00000 0 0.57820 0.76153 0.22771 179 0.90795 0.34064 0.04556 179 5.5DT1.00000 0.00000 0.00000 0 0.57868 0.76005 0.22434 175 0.90825 0.33998 0.04489 175 5.5KNN1.00000 0.00000 0.00000 0 0.66229 0.66522 0.17667 143 0.92912 0.29756 0.03535 143 5.6MLP0.54310 0.81124 0.25491 793 0.53628 0.80101 0.25238 202 0.54175 0.80920 0.25440 995 208.2OLR0.26040 0.95610 0.69122 2933 0.26708 0.94032 0.67487 724 0.26174 0.95296 0.68795 3657 8.2RF1.00000 0.00000 0.00000 0 0.67263 0.65202 0.16938 137 0.93179 0.29166 0.03389 137 75.4SGD0.09758 1.19588 0.57295 1957 0.13338 1.12908 0.52328 458 0.10135 1.18765 0.56705 2433 3.4SVR0.85652 0.42772 0.07043 222 0.67006 0.65758 0.17106 135 0.81827 0.48255 0.09056 357 29.3XGB0.77491 0.54175 0.11448 371 0.46875 0.85650 0.29501 246 0.71032 0.61770 0.15060 617 320.3
Notes: (1)RMSE and MAE are expressed in terms of the facies class range of 1 –5; (2)Execution time (Ex Time) is expressed in seconds. It includes the time required for 5- fold cross validation; (3)Error# refers to the number of data records with their facies class misclassi ﬁed.
Table 4Five-fold cross validation assessments involving 15 cases of random splits of the dataset between training and testing subsets. Standard deviation (
σ2) is used to indicate the degree of variation among the 15 cases evaluated for each of the nine models evaluated.
5-Fold Cross-Validation Results for Regression and ML Models Applied to 8911 Data Records (15 Cases Run for Each Model)Model9 Input Variables 7 Input Variables 3 Input Variables 2 Input Variables 1 Input VariablesMAE
σ2MAE MAE σ2MAE MAE σ2MAE MAE σ2MAE MAE σ2MAEADA 0.0979 0.0128 0.1864 0.0214 0.2535 0.0154 0.4119 0.0190 0.7928 0.0243DT 0.0954 0.0127 0.1852 0.0189 0.2537 0.0157 0.4118 0.0213 0.7929 0.0244KNN 0.0205 0.0060 0.1308 0.0104 0.1973 0.0105 0.3578 0.0151 0.6813 0.0167MLP 0.1584 0.0142 0.4328 0.0146 0.2620 0.0197 0.3456 0.0206 0.6289 0.0168OLR 0.6900 0.0085 0.9149 0.0101 0.6880 0.0090 0.7094 0.0087 0.9178 0.0110RF 0.0307 0.0092 0.0643 0.0109 0.1980 0.0132 0.3498 0.0152 0.7917 0.0243SGD 0.5575 0.0235 0.6720 0.0150 0.5607 0.0231 0.6234 0.0193 0.6627 0.0205SVC 0.0501 0.0092 0.2258 0.0213 0.1941 0.0173 0.3309 0.0178 0.6224 0.0154XGB 0.0245 0.0054 0.0499 0.0068 0.3300 0.0219 0.3894 0.0200 0.6317 0.0162D.A. Wood Artiﬁcial Intelligence in Geosciences 2 (2021) 148 –164
155generates the lowest σ2MAE values, together with the lowest mean MAEvalue for the 7-var conﬁguration, and the second lowest mean MAE valuefor the 9-var conﬁguration. The KNN, RF and XGB models outperform theother models for the 9-var and 7-var conﬁgurations, indicating that the SVC model performs less well with the 9-var and 7-var con ﬁgurations involving the GR attributes. Not surprisingly, none of the models per-forms well in lithofacies classiﬁcation for the var-1 (GR only) conﬁgu- ration in terms of mean MAE. However, the SVC, MLP and XGB modelsperform better than the other models. The ordinary least squaresregression (OLR) model shows the poorest prediction performance for allvariable conﬁgurations considered. The gradient descent regressionmodels (SGD) performs less well than all the ML models for the 9-var, 7-var, 3-var and 2-var models, although it outperforms several of the MLmodels for the 1-var case.In addition to conﬁrming reproducibility of the model evaluated, thekey conclusion from the 5-fold cross-validation analysis is that for almostall models their lithofacies prediction performance can be ranked asfollows:(Best) 9-var>7-var>3-var>2-var » 1-var (Worst)There are two exceptions to this general trend: the SVC and MLPmodels provide poorer prediction performance for the 7-var con ﬁgura- tion than they do for the 3-var conﬁguration. Nevertheless, this generalranking trend observed, based onTable 4results, conﬁrms that the addition of the calculated GR attributes to the variable con ﬁgurations is substantially improving their lithofacies prediction performance for theWK-1 Triassic section evaluated.3.3. Detailed lithofacies prediction results for the testing subsetsA clearer understanding of the relative lithofacies prediction perfor-mances of the different models with the different variable con ﬁgurations can be obtained by considering MAE together with the other predictionperformance metric values for a randomly selected testing subset. Theseresults are shown for the four best performing models (KNN, RF, SVC andXGB) inTable 5.Those results for the other poorer performing models are shown inAppendix B Table B1. Considering the four performance metrics (R
2, RMSE MAE andPError) together provides a clearer indication of howeach model is performing with respect to the modelled dataset. The re-lationships between these performance measures are shown in Figs. 7–9. It is apparent fromTable 4that KNN generates the best lithofaciesprediction performance for the 9-var conﬁguration in terms of all error metrics, resulting in only 14 prediction errors among the 1743 data re-cords of the testing subset. For the 7-var con ﬁguration XGB outperforms the other models in terms of all error metrics. For the 3-var model SVCoutperforms the other models with the lowestPError. However, the RF model generates slightly lower RMSE and MAE values, and a slightlyhigher R
2value than the SVC model. The SVC model outperforms theother models for the var-2 and var-1 conﬁgurations. The relatively poor performance of the SVC model for the 7-var model suggest that the PB log(the one displaying the highest R and p values with facies class) need tobe involved in the variable conﬁguration for the SVC model to performwell.Fig. 7reveals that there is a well-deﬁned trend of increasingPError with MAE among the different models evaluated. Excluding con ﬁgura- tion var-1, the OLR and SGD model deliver poorer prediction perfor-mance than the ML models for all other variable con ﬁgurations. Fig. 8displays, on an expanded scale, only the high performing end ofthe trend shown inFig. 7. Thatﬁgure conﬁrms that the ML models (excluding the MLP and SVC for var-7 con ﬁguration) all generate improved facies class prediction performance for var-9 and var-7 con-ﬁgurations compared to the var-3 conﬁguration.Fig. 9reveals the same result for R
2versus RMSE with the ML models following a well-de ﬁned trend.The results presented inTable 4andFigs. 7–9therefore conﬁrm the ﬁndings of the 5-fold cross validation analysis ( Table 3). Thisﬁnding is very encouraging from the perspective of the effectiveness of calculatedGR attributes in improving lithofacies class prediction applying MLmodels to a limited set of well logs. Of particular signi ﬁcance are the var- 7 model results because that conﬁguration only uses the recorded GR logdata plus the calculated GR attributes. Yet the var-7 con ﬁguration pro- vides signiﬁcantly better facies class prediction results than the 3-varmodel involving the three recorded logs GR, DT and PB. A key reasonthis result is that in many wellbores only a limited range of well logs areavailable. Indeed, sometimes only the GR log is recorded over certainintervals. The results indicate that reliable lithofacies classi ﬁcation can be achieved using only the recorded GR log and the six GR-attributevariables for the WK-1 Triassic section.4. Discussion4.1. Confusion analysis of the best performing ML modelsIt is useful to understand in more detail the distributions of faciesprediction errors generated by the high performing models. Annotatedconfusion matrices provide useful insight in this regard by consideringthe classiﬁcation error metrics deﬁned inAppendix 1. The value that such displays provide is illustrated byFig. 10showing confusion matrices for the high performing RF model applied to all 8911 data records of the9-var, 7-var and 3-var models. For the 9-var con ﬁguration the RF model generates only 23 classiﬁcation errors, and 15 of those errors are asso-ciated with misclassiﬁcation of facies class 2 (Fig. 10A). That model generates no misclassiﬁcations for facies class 1 (limestone) and only 1error for facies class 4 (halite/evaporites). However, accuracy, precision,recall and F1 score are high for all classes.For the 7-var conﬁguration, the RF model generates just 47 mis-classiﬁcations (Figs. 10B), 34 of which are misclassiﬁcations of facies class 2 (confused mainly with classes 3 and 5). Eleven of the remainingmisclassiﬁcation errors are associated with data records from otherclasses being confused as facies class 2. However, accuracy, precision,
Table 5Lithofacies class prediction performance of the four better performing modelsapplied to the randomly selected 1783 data records (20% of dataset) of thetesting subsets for theﬁve different variable conﬁgurations evaluated. The results for the otherﬁve models with poorer prediction performance are included asAppendix B.
Better Performing ML Model Results for the Testing SubsetsKNN 9- Var 7-Var 3-Var 2-Var 1-VarTest R2 0.9741 0.7637 0.6623 0.4527 0.0680Test RMSE 0.1772 0.5513 0.6652 0.8772 1.2718Test MAE 0.0146 0.1256 0.1767 0.3186 0.6798Total Error Number 14 110 143 280 613Execution Time (seconds) 7.1 6.6 5.6 5.7 5.3RFTest R2 0.9604 0.9078 0.6726 0.4531 0.0462Test RMSE 0.2196 0.3374 0.6520 0.8791 1.3815Test MAE 0.0224 0.0499 0.1694 0.3163 0.7835Total Error Number 23 46 137 274 702Execution Time (seconds) 113.6 94.3 75.4 61.3 92.3SVCTest R2 0.9248 0.6845 0.6701 0.4603 0.1047Test RMSE 0.3033 0.6416 0.6576 0.8601 1.1898Test MAE 0.0393 0.1884 0.1711 0.3034 0.6046Total Error Number 37 197 135 262 580Execution Time (seconds) 20.2 52.7 29.3 83.1 192.7XGBTest R2 0.9609 0.9351 0.4687 0.4098 0.0962Test RMSE 0.2183 0.2822 0.8565 0.9160 1.2080Test MAE 0.0219 0.0404 0.2950 0.3567 0.6259Total Error Number 22 45 246 326 605Execution Time (seconds) 486.8 466.5 320.3 321.0 62.5D.A. Wood Artiﬁcial Intelligence in Geosciences 2 (2021) 148 –164
156recall and F1 score remain above 0.99 for all classes, indicating excellentprediction performance.For the 3-var conﬁguration, the RF model generates 137 mis-classiﬁcations (Figs. 10C), 67 of which are misclassiﬁcations of facies class 2 (confused mainly with classes 3 and 5). Forty-one of the remainingmisclassiﬁcation errors are associated with data records from otherclasses being confused as facies class 2. The main deterioration in pre-diction performance from the 9-var and 7-var con ﬁgurations is that there are many more confusions between facies class 2 (dolomitic mudstone)and facies class 5 (shaly sandstone). The precision, recall and F1 score fallsubstantially below 0.99 for class 5, whereas accuracy, precision and F1score fall slightly below 0.99 for class 2. The classi ﬁcation performance of the RF model for the 3-var conﬁguration remains very good (98.5%successful predictions) but is clearly inferior to the 9-var and 7-varmodels due primarily to increased confusion between facies classes 2and 5. It is also informative to plot the interpreted versus predicted faciesclass for all data points.Fig. 11presents such displays for the most ac-curate ML models (KNN; XGB; RF), those generating the least misclas-siﬁcation, for conﬁgurations 9-var, 7-var and 3-var, respectively.Fig. 11A displays the results of each data record for the KNN model
Fig. 7.PError versus MAE for the testing subsets of nine prediction models applied to the ﬁve input variable conﬁgurations evaluated, labelled 9, 7, 3, 2, and 1.
Fig. 8.PError versus MAE for the testing subsets of the best performing classi ﬁcation models (Var-9, Var-7 and Var-3). Symbols are the same as those used in Fig. 6.D.A. Wood Artiﬁcial Intelligence in Geosciences 2 (2021) 148 –164
157applied to the 9-var model, highlighting the impressive prediction per-formance achieved (just 14 errors among 8911 data records). Fig. 11B reveals, from the results of each data record for the XGB model applied tothe 7-var model, more misclassiﬁcations of other classes as class 2,particularly for class 5 and class 3.Fig. 11C, from the results of each data record for the RF model applied to the 3-var model, highlights andconﬁrms the misclassiﬁcations already identiﬁed by the confusion matrix shown inFig. 10C.Figs. 10 and 11explain why the inclusion of the GR attributes im-proves facies class prediction performance for the WK-1 Triassic section.They do so speciﬁcally by distinguishing facies classes 2 and 5 withgreater precision.Fig. 12provides the detailed analysis of the misclassi ﬁcations for the best-performing (KNN) model for the 9-var con ﬁguration that involves just fourteen misclassiﬁed data records. Eight of the fourteen mis-classiﬁcations are data records from other lithofacies classes wronglyclassiﬁed as lithofacies class 2. Six of the misclassi ﬁcations occur within 1 m of an actual lithofacies boundary, which are in the lithofacies tran-sition zones that are the hardest for ML algorithms to classify correctly.4.2. Implications of results and additional studies requiredCalculating GR attributes can clearly be bene ﬁcial in improving multiple lithology facies classiﬁcations from wells with limited well logvariables recorded. They add additional perspectives (features) to the GRdata that cannot be easily discerned visually. Those additional featuresmay not correlate highly with the facies classes ( Fig. 5) but can be effectively used by several ML models to improve their classi ﬁcations. Signiﬁcantly, they can do this for the multiple lithology section evaluatedwhen used only in combination with the recorded GR log (the 7-varmodel). This performance has the potential to be exploited for lith-ofacies classiﬁcation in wellbores where GR is the only recorded well logavailable, which is the case in many top hole sections of many ﬁeld development wells drilled. This author is not suggesting that GR and itsattributes be used in isolation for lithofacies classi ﬁcation as a matter of preference. For detailed facies analysis a suite of diverse data inputs isalways preferable, including mineralogy, various core analysis, fossil andfauna characterization, as well as multiple recorded well logs. Despite,such inputs being desirable, there are many wellbores for which suchdata is not available due to both cost and technical constraints. In suchinstances, the GR log plus attributes could offer the best alternativeavailable to provide reliable basic lithofacies characterization with theassistance of an ensemble of ML models.The KNN model provides the best prediction results with the fewestmisclassiﬁcations for the 9-var conﬁguration. However. KNN is out- performed by the RF and XGB models for the 7-var con ﬁguration (including GR and the GR attributes only). Unlike the other ML modelsevaluated, the KNN model uses data matching rather than establishingcomplex relationships between the input variables and dependent vari-able when formulating its lithofacies predictions. For the dataset evalu-ated KNN's performance improves progressively as more input datavariables become available (
Table 5). KNN's correlation-free, data- matching technique seems better able to exploit the additional variationsprovided in the 9-var conﬁguration, by adding the PB and DT data dis-tributions to the 7-var conﬁguration, than the RF and XGB models.An observed outcome worthy of further consideration is the relativelypoor performance of the MLP and SVC models for the 7-var con ﬁgura- tion. The 7-var conﬁguration is the only one not to involve the recordedPB log, the one recorded log that correlates reasonable with facies class;R¼-0.49 and p¼/C00.54 (Fig. 5). It seems that in the absence of the PBdata the MLP and SVC models' prediction performances decline sub-stantially. It is the author's experience with other datasets in which theinput variables are all poorly correlated with the dependent variable thatthe neural-network-based and regression-based models tend to performmuch worse in their predictions they generate than tree-based models(such as ADA, DT, RF and XGB) and regression-free data-matchingmodels (e.g. KNN). This may explain the relatively poor performance ofthe MLP and SVC models with the 9-var and 7-var con ﬁgurations of the WK-1 dataset. However, more research with other logged lithofaciessections is required to conﬁrm this possibility.On the other hand, the XGB model shows the reverse predictionperformance trend to the MLP and SVC models. XGB performs extremely
Fig. 9.R2versus RMSE for the testing subsets for best performing classi ﬁcation models (Var-9, Var-7 and Var-3).D.A. Wood Artiﬁcial Intelligence in Geosciences 2 (2021) 148 –164
158well with the 9-var and 7-var conﬁgurations (including the GR attributes)but relatively less well for the 3-var and 2-var than the other high per-forming models, such as RF and KNN ( Table 4). It is not clear why this should be the case but it implies that the XGB model performs betterwhen it has a larger number of features available to exploit. Once again,more research with other logged lithofacies sections is required toconﬁrm this possibility.The fact that different ML models achieve the best classi ﬁcationperformance with different conﬁgurations (i.e., KNN with 9-var, XGBwith 7-var, RF/SVC with 3-var, SVC/RF/MLP with 2-var) suggests that itis prudent to evaluate an ensemble of ML methods to establish the bestperformers with each speciﬁc dataset and variable conﬁgurations. It appears that one speciﬁc ML model cannot be relied upon in isolation toalways provide the best prediction results. As most of these models can beexecuted in a few seconds on laptop computers for medium sized data-sets, evaluating an ensemble of ML models is typically not too onerous atask in terms of computational effort ( Table 2). The ML models evaluated in this study all, to a degree, lack trans-parency when it comes to revealing exactly how the facies class pre-dictions are generated for each data record. For many applications this isnot a major disadvantage. However, for outlier analysis and detailed datamining more transparent algorithms can provide advantages by revealingspeciﬁc relationships between certain groups of data records. Thetransparent open box (TOB) ML algorithm ( Wood, 2018) has demon- strated its ability to both predict and data mine lithofacies datasets(Wood, 2019). Future studies are planned to apply TOB lithofaciesmodels to provide more details of how the GR attributes are used inspeciﬁc lithofacies predictions.Further work is required and planned to evaluate how effective GRand other well log derivative and volatility attributes are at improvinglithofacies classiﬁcation performance across logged sections in multiplewellbores. This would involve training and validation prediction modelswith and without attributes in some wells and testing them with unseendata records in offset wells drilled through the same stratigraphicsequence. That work is underway based on the encouraging resultsachieved in this study.5. ConclusionsGamma ray (GR) log attributes offer useful features for improvinglithofacies predictions from well logs in boreholes penetrating multiplelithologies but with limited well-log variables recorded. Many wellboresfall into this category, such as development wells for which the sectionsdrilled above the reservoir target typically have minimal well logsrecorded (e.g., GR logs only in many cases). Derivative and volatility GRattributes are of particular value because they extract shape character-istics from GR curves that are not captured by the recorded log values.Theﬁrst and second derivatives plus a moving average of the ﬁrst de- rivative calculated over a relevant depth interval complement therecorded GR data. Similarly, the instantaneous volatility, the standarddeviation of that volatility plus a moving average volatility over a rele-vant depth interval also provide distinctive complementary featuresrelated to the changes in GR curve shape with depth.A logged Triassic section drilled in the Wessex Basin (England; wellWK-1) penetrating diverse lithologies is used to demonstrate how usefulGR attributes relating to its derivatives and volatility components are forimproving lithofacies predictions. Using only three recorded well logs(GR, sonic travel time (DT) and bulk density (PB)), regression and ma-chine learning (ML) models struggle to distinguish reliably between someof theﬁve lithofacies identiﬁed in the studied wellbore section. Ninemodels (two linear regression; seven ML) applied to evaluate ﬁve distinct log feature conﬁgurations (1-var uses the GR curve alone; 2-var uses GRand PB recorded well logs only; 3-var uses GR, DT and PB recorded dataonly; 7-var uses GR plus six GR attributes; 9-var uses GR, DT, PB and six
GR attributes) reveal the substantial beneﬁts to lithofacies prediction of introducing the GR attributes.The 9-var and 7-var models substantially improve upon the predictionmodels using only the recorded log data. The best performing 9-varmodel (K-nearest neighbor (KNN)) generates only 14 facies misclassi ﬁ- cation from 8911 data records. This compares with 135 misclassi ﬁcation for the best 3-var model (Support Vector Classi ﬁcation (SVC)). Even more
Fig. 10.Annotated confusion matrices displaying misclassi ﬁcation error anal- ysis for the 9-var, 7-var and 3-var models evaluated with the random forestmodel for all data records.D.A. Wood Artiﬁcial Intelligence in Geosciences 2 (2021) 148 –164
159impressive, as it only involves GR and GR attributes, the best 7-var model(Extreme Gradient Boosting (XGB)) generates only 45 misclassi ﬁcations. The reproducibility of the ML models is veri ﬁed by 5-fold cross- validation analysis, which also identiﬁes KNN, Random Forest (RF) and XGB as the best performing ML model with the 9-var and 7-var featureconﬁgurations. Annotated confusion matrices reveal that none of the MLmodels can reliably distinguish facies classes 2 (dolomitic mudstones/siltstones) and 5 (shaly sandstones/siltstones) for the 3-var con ﬁgura- tion. Nevertheless, KNN/RF/XGB models manage to do this effectivelyfor the 9-var and 7-var models.A somewhat surprising outcome of the ML model analysis is therelatively poor performance of the multi-layer perceptron (MLP) and SVCmodels with the 7-var conﬁguration. That conﬁguration does not include PB data, which is considered signiﬁcant, as PB is moderately well correlated with facies class (Spearman's correlation coef ﬁcient ~0.54). All the other features are poorly correlated with facies class, especiallythe GR attributes. This implies that the MLP and SVC models are less ableto deal with more poorly correlated feature selections, although thatimplication requires further analysis with additional datasets. A lesssurprising outcome of the analysis is that standard least squares andgradient-descent muti-linear regression models perform substantiallyworse than ML models for facies classiﬁcation with all conﬁgurations, except the 1-var model. The low correlations between the features,especially the GR attributes, and facies class explains that outcome. Forthe logged section studied, the ML models that do not rely on correla-tions, KNN/RF/XGB, clearly provide superior lithofacies prediction per-formance. However, one of those models does not consistentlyoutperform the other taking into account the 9-var, 7-var and 3-varconﬁgurations. That observation suggests that it is better to apply anensemble of those three models to ensure optimum lithofacies predictionfrom a range of feature conﬁgurations.Declaration of interestsThe author declares that he has no known competing ﬁnancial in- terests or personal relationships that could have appeared to in ﬂuence the work reported in this paper.FundingNo funding was received for this study.Conﬂicts of interestThe author has no conﬂicts of interest associated with this study.Appendix A. Deﬁnitions of statistical measures of prediction performance appliedThe prediction performance assessment metrics used in this study are de ﬁned inFigure A1.
Fig. 11.Observed (blue dots) versus ML-predicted (yellow diamonds) facies lithofacies classes for all 8911 data records of WK-1 Triassic section for the bes t per- forming models: (A) KNN for the 9-variable model; (B) XGB for the 7-variable model; and, (C) RF for the 3-variable model. At depths where the observed an d prediction lithofacies are in agreement only the observed lithofacies is displayed as a blue dot. At depths where the observed and prediction lithofa cies are not in agreement both observed (blue dot) and predicted lithofacies (yellow diamond) are displayed. Figs. 10(C) and 11(C)provide complementary information regarding the performance of the RF 3-variable model.D.A. Wood Artiﬁcial Intelligence in Geosciences 2 (2021) 148 –164
160Fig. 12.Misclassiﬁcation analysis for the best-performing KNN model (KNN) applied to the 9-var dataset con ﬁguration. The labels in the lower graphic represent the depth values of the fourteen misclassi ﬁed data records.D.A. Wood Artiﬁcial Intelligence in Geosciences 2 (2021) 148 –164
161Fig. A1.Statistical measures of prediction performance appropriate for both regression and classi ﬁcation analysis.
Appendix B. Lithofacies Class Prediction Performance for Additional ModelsLithofacies class prediction performance is reported here for the ﬁve models with poorer results overall ( Table B1) compared to the KNN, RF, SVC and XGB. Note that the ADA and DT models only slightly underperform the models mentioned. In fact, the ADA and DT models provide better results forthe Var-7 conﬁguration than the SVC model, and better results for the Var-3 con ﬁguration than the XGB model. The OLR and SGD linear regression models are the worst performing models overall. The MLP model does not perform as well as other ML models evaluated for the Var-9 and Var-7conﬁgurations, but its performance improves relative to other ML models for Var-3 and Var-2 con ﬁgurations. Indeed, for the Var-1 conﬁguration the MLP model provides the best prediction performance.D.A. Wood Artiﬁcial Intelligence in Geosciences 2 (2021) 148 –164
162Table B1Lithofacies class prediction performance of the ﬁve models with poorer results overall than the KNN, RF, SVC and XGB models. These results are for the randomly selected 1783 data records (20% of dataset) of the testing subsets for the ﬁve different variable conﬁgurations evaluated. For higher performing model results seeTable 5.
Poorer Performing ML Model Results for the Testing SubsetsADA 9- Var 7-Var 3-Var 2-Var 1-VarTest R2 0.8480 0.8031 0.5782 0.3663 0.0467Test RMSE 0.4283 0.5013 0.7615 0.9762 1.3801Test MAE 0.0746 0.1167 0.2277 0.3842 0.7818Total Error Number 63 120 179 328 704Execution Time (seconds) 5.7 5.6 5.5 5.8 199.9DTTest R2 0.8541 0.7694 0.5787 0.3931 0.0467Test RMSE 0.4302 0.5452 0.7601 0.9520 1.3801Test MAE 0.0752 0.1346 0.2243 0.3702 0.7818Total Error Number 63 136 175 321 701Execution Time (seconds) 5.6 5.7 5.5 5.5 6.1OLRTest R2 0.2730 0.0523 0.2671 0.2535 0.0427Test RMSE 0.9366 1.0694 0.9403 0.9490 1.0747Test MAE 0.6760 0.9052 0.6749 0.7003 0.9080Total Error Number 700 1418 724 736 1453Execution Time (seconds) 4.9 5.3 5.2 5.0 4.7MLPTest R2 0.7340 0.3943 0.5363 0.4521 0.0937Test RMSE 0.5849 0.9279 0.8010 0.8672 1.1817Test MAE 0.1335 0.3932 0.2524 0.3158 0.6012Total Error Number 105 431 202 282 540Execution Time (seconds) 210.6 287.6 208.2 129.5 15.2SGDTest R2 0.1074 0.0623 0.1334 0.1516 0.0681Test RMSE 1.1720 1.2469 1.1291 1.1422 1.2390Test MAE 0.5580 0.6618 0.5233 0.5855 0.6556Total Error Number 491 644 458 602 627Execution Time (seconds) 5.6 3.4 3.4 5.7 3.4
References
Agrawal, R., Malik, A., Samuel, R., Saxena, A., 2022. Real-Time Prediction of litho-faciesfrom drilling data using an artiﬁcial neural network: a comparative ﬁeld data study with optimizing algorithms. J. Energy Resour. Technol. 144, 12. https://doi.org/ 10.1115/1.4051573, 043003.Al-Mudhafar, W.J., 2017. Integrating well log interpretations for lithofacies classi ﬁcation and permeability modeling through advanced machine learning algorithms. J. Petrol.Explor. Prod. Technol. 7, 1023 –1033.https://doi.org/10.1007/s13202-017-0360-0 , 2017.Bestagini, P., Lipari, V., Tubaro, S., 2017. A machine learning approach to faciesclassiﬁcation using well logs. In: Proceedings of the SEG International Exposition and87th Annual Meeting, vol. 2137. https://doi.org/10.1190/segam2017-17729805.1 . Bottou, L., 1998. Online Algorithms and Stochastic Approximations. Online Learning andNeural Networks. Cambridge University Press, ISBN 978-0-521-65263-6 . Busch, J., Fortney, W., Berry, L.N., 1987. Determination of lithology from well logs bystatistical analysis. SPE Form. Eval. 2, 412 –418.https://doi.org/10.2118/14301-PA . Cant, D.J., 1992. Subsurface facies analysis. In: Walker, R.G., James, N.P. (Eds.), FaciesModels, Response to Sea Level Changes. Geol. Assoc., Canada, pp. 27 –45. Chen, T., Guestrin, C., 2016. XGBoost: a scalable tree boosting system. In:Krishnapuram, Balaji, Shah, Mohak, Smola, Alexander J., Aggarwal, Charu C.,Shen, Dou, Rastogi, Rajeev (Eds.), Proceedings of the 22nd ACM SIGKDDInternational Conference on Knowledge Discovery and Data Mining. ACM, SanFrancisco, CA, USA, pp. 785 –794.https://doi.org/10.1145/2939672.2939785 . August 13-17, 2016.Cortes, C., Vapnik, V., 1995. Support-vector networks. Mach. Learn. 20 (3), 273 –297. https://doi.org/10.1007/BF00994018 . Dubois, M.K., Bohling, G.C., Chakrabarti, S., 2007. Comparison of four approaches to arock facies classiﬁcation problem. Comput. Geosci. 33, 599 –617. Emery, D., Myers, K.J., 1996. Sequence Stratigraphy. Blackwell Science, Oxford (U.K.,p. 297.https://doi.org/10.1002/9781444313710Fadokun, D.O., Oshilike, I.B., Onyekonwu, M.O., 2020. Supervised and UnsupervisedMachine Learning Approach in Facies Prediction. SPE-203726-MS. Nigeria AnnualInternational Conference and (Virtual) Exhibition. 2020. https://doi.org/10.2118/ 203726-MS.Faga, A.T., Oyeneyin, B.M., 2000. Effects of Diagenesis on Neural-Network Grain-SizePrediction. SPE-60305-MS. Rocky Mountain Regional/Low-Permeability ReservoirsSymposium and Exhibition, Denver, Colorado, March 2000. https://doi.org/ 10.2118/60305-MS.Farzi, R., Bolandi, V., 2016. Estimation of organic facies using ensemble methods incomparison with conventional intelligent approaches: a case study of the South ParsGas Field, Persian Gulf, Iran. Model. Earth Syst. Environ. 2, 105. https://doi.org/ 10.1007/s40808-016-0165-z. Feng, R., Luthi, S.M., Gisolf, D., Angerer, E., 2018. Reservoir lithology classi ﬁcation based on seismic inversion results by hidden Markov models. Mar. Petrol. Geol. 93,218–229.https://doi.org/10.1016/j.marpetgeo.2018.03.004 . Feng, R., 2020. Lithofacies classiﬁcation based on a hybrid system of arti ﬁcial neural networks and hidden Markov models: applying prior geological information.Geophys. J. Int. 221 (3), 1484 –1498.https://doi.org/10.1093/gji/ggaa083
. Feng, R., 2021. A Bayesian approach in machine learning for lithofacies classi ﬁcation and its uncertainty analysis. Geosci. Rem. Sens. Lett. IEEE 18 (1), 18 –22.https://doi.org/ 10.1109/LGRS.2020.2968356 . Fix, E., Hodges Jr., J.L., 1951. Discriminatory Analysis, Nonparametric Discrimination:Consistency Properties. USAF School of Aviation Medicine. Technical Report . Freund, Y., Schapire, R.E., 1997. A decision-theoretic generalization of on-line learningand an application to boosting. J. Comput. Syst. Sci. 55, 119 –139.https://doi.org/ 10.1006/jcss.1997.1504.Gao, D., 2011. Latest developments in seismic texture analysis for subsurface structure,facies, and reservoir characterization: a review. Geophysics 76 (2). https://doi.org/ 10.1190/1.3553479.W 1–W13. Goldberger, A.S., 1964. Classical Linear Regression. Econometric Theory, vol. 158. JohnWiley&Sons, New York, ISBN 0-471-31101-4 . Goncalves, C.A., Harvey, P.K., Lovell, M.A., 1995. Application of a multilayer neuralnetwork and statistical techniques in formation characterization. In: SPWLA 36thAnnual Logging Symposium, Paris, 26 –29 Jun, Society of Petrophysicists and Well Log Analysts, p. 12. Houston (U.S.A.) . Hall, B., 2016. Facies classiﬁcation using machine learning. Lead. Edge 35 (10), 906 –909. https://doi.org/10.1190/tle35100906.1 , 2016. Hall, M., Hall, B., 2017. Distributed collaborative prediction: results of the machinelearning contest. Lead. Edge 36 (3), 267 –269.https://doi.org/10.1190/ tle36030267.1.Halotel, J., Demyanov, V., Gardiner, A., 2020. Value of geologically derived features inmachine learning facies classiﬁcation. Math. Geosci. 52, 5 –29.https://doi.org/ 10.1007/s11004-019-09838-0 . Ho, T.K., 1998. The random subspace method for constructing decision forests. IEEETrans. Pattern Anal. Mach. Intell. 20 (8), 832 –844.https://doi.org/10.1109/ 34.709601.Hossein, T.M., Watada, J., Aziz, I.A., Hermana, M., 2020. Machine learning inelectrofacies classiﬁcation and subsurface lithology interpretation: a rough set theoryapproach. Appl. Sci. 10, 5940. https://doi.org/10.3390/app10175940 . Hounslow, M.W., Ruffell, A.H., 2006. Triassic: seasonal rivers, dusty deserts and salinelakes. Chapter in. In: Brenchley, P.J., Rawson, P.F. (Eds.), The Geology of Englandand Wales. Geological Society of London .D.A. Wood Artiﬁcial Intelligence in Geosciences 2 (2021) 148 –164
163Howard, A.S., Warrington, G., Ambrose, K., Rees, J.G., 2008. A Formational Frameworkfor the Mercia Mudstone Group (Triassic) of England and Wales. British GeologicalSurvey, Research Report, RR/08/04 . Hurst, A., 1990. Natural gamma-ray spectroscopy in hydrocarbon bearing sandstonesfrom the Norwegian continental shelf. In: Hurst, A., Lovell, M.A., Morton, A.C. (Eds.),Geological Applications of Wireline Logs. Geological Society, London, SpecialPublication, vol. 48, pp. 211 –222. Ippolito, M., Ferguson, J., Jenson, F., 2021. Improving facies prediction by combiningsupervised and unsupervised learning methods. J. Petrol. Sci. Eng. 200, 108300.https://doi.org/10.1016/j.petrol.2020.108300 . Kaya, M., 2015. Provenance and migration of the petroleum ﬂuids in the Wessex basin, Southern England. Bull. Turk. Assoc. Petrol. Geol. 27 (1), 31 –56. Kesslar, L., Sachs, S.D., 1995. Depositional Setting and Sequence StratigraphicImplications of the Upper Sinemurian (Lower Jurassic) Sandstone Interval, 1995, vol.93. North Celtic Sea/St George's, Channel Basins, offshore Ireland. Geol Soc LondSpec Publ, pp. 171–192.https://doi.org/10.1144/GSL.SP.1995.093.01.13 ,1 . Kim, Y., Hardisty, R., Torres, E., Marfurt, K.J., 2018. Seismic facies classi ﬁcation using random forest algorithm. In: SEG International Exposition and 88th Annual Meeting,pp. 2161–2165, 0.1190/segam2018-2998553.1 . Krumbein, W.C., Sloss, L.L., 1951. Stratigraphy and Sedimentation: San Francisco.W.H.Freeman and Co, p. 497. https://doi.org/10.1002/gj.3350010110 , 1951. Mandal, P.P., Rezaee, R., 2019. Facies classi ﬁcation with different machine learning algorithm–an efﬁcient artiﬁcial intelligence technique for improved classi ﬁcation. ASEG Extended Abstracts 1, 1 –6.https://doi.org/10.1080/ 22020586.2019.12072918. Merembayev, T., Kurmangaliyev, D., Bekbauov, B., Amanbek, Y.A., 2021. Comparison ofmachine learning algorithms in predicting lithofacies: case studies from Norway andKazakhstan. Energies 14.https://doi.org/10.3390/en14071896 , 1896. Newell, A.J., Woods, M.A., Graham, R.L., Christodoulou, V., 2021. Derivation oflithofacies from geophysical logs: a review of methods from manual picking tomachine learning. In: British Geological Survey (Nottingham, England) Open Rep..OR/21/006. 43pages.Potratz, G.L., Canchumuni, S.W.A., Castro, J.D.B., Potratz, J., Pacheco, M.A.C., 2021.Automatic Lithofacies Classiﬁcation with T-SNE and K-Nearest Neighbors Algorithm,vol. 44. Anu/C19ario do Instituto de Geoci^encias, 35024.https://doi.org/10.11137/2021_ 44_35024.Puskarczyk, E., 2019. Artiﬁcial neural networks as a tool for pattern recognition andelectrofacies analysis in Polish palaeozoic shale gas formations. Acta Geophys. 67,1991–2003.https://doi.org/10.1007/s11600-019-00359-2 . Quinlan, J.R., 1986. Induction of decision trees. Mach. Learn. 1, 81 –106.https://doi.org/ 10.1007/BF00116251.Reverdy, X., Argaud, M., Walgenwitz, F., 1983. Minerological Analysis Required for LogInterpretation in Complex Lithologies. Paper H, Transactions of the SPWLA 8thEuropean Symposium.Rosenblatt, F., 1958. The perceptron: a probabilistic model for information storage andorganization in the brain, Cornell aeronautical laboratory. Psychol. Rev. 65 (6),386
–408.https://doi.org/10.1037/h0042519 . Rhys, G.H., Lott, G.K., Calver, M.A., 1982. The Winterborne Kingston Borehole, Dorset,England. Rep CF81/03. Stationery Of ﬁce Books, p. 196, 13:978-0118841931, London, United Kingdom.Rider, M.H., 1986. Geological Interpretation of Well Logs. Blackie, ISBN 9780216918467,p. 175. New York (U.S.A.). Rider, M.H., 1990. Gamma-ray log shape used as a facies indicator: critical analysis of anoversimpliﬁed methodology. Geol. Soc. Lond. Spec. Publ. 48, 27 –37.https://doi.org/ 10.1144/GSL.SP.1990.048.01.04 . Rogers, S.J., Fang, J., Karr, C., Stanley, D., 1992. Determination of lithology from welllogs using a neural network (1). AAPG (Am. Assoc. Pet. Geol.) Bull. 76, 731 –739.Russell, W.L., 1944. The total gamma ray activity of sedimentary rocks as indicated byGeiger counter determinations. Geophysics 9 (2), 180 –216.https://doi.org/10.1190/ 1.1445076.Sarkar, S., Majundar, C., 2020. A comparative analysis of supervised classi ﬁcation algorithms for lithofacies characterization. In: EAGE Digitalization Conference andExhibition, Nov 2020. European Association of Geoscientists &Engineers, pp. 1–5. https://doi.org/10.3997/2214-4609.202032090 . Scholle, P.A., Spearing, D., 1982. Sandstone Depositional Environments, vol. 31.American Association of Petroleum Geologists Memoir, ISBN 9780891813071,p. 410.SciKit Learn, 2022a. Supervised and Unsupervised Machine Learning Models in Python,2022a.https://scikit-learn.org/stable/ , 2nd February 2022. SciKit Learn, 2021a. GridSearchCV: Exhaustive Search over Speci ﬁed Parameter Values for an Estimator in Python.https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html , 2nd February 2022. SciKit Learn, 2021b. Bayesian Optimization of Hyperparameters in Python. https://scikit -optimize.github.io/stable/modules/generated/skopt.BayesSearchCV.html , 2nd February 2022.SciKit Learn, 2022b. Cross-validation: Evaluating Estimator Performance. https://scikit -learn.org/stable/modules/cross_validation.html , 2nd February 2022. Selley, R.C., 1978. Concepts and Methods of Subsurface Facies Analysis. AmericanAssociation of Petroleum Geologists Education Course Notes Series #9. https:// doi.org/10.1306/CE9397. Shashank, S., Mahapatra, M.P., 2018. Boosting Rock Facies Prediction: WeightedEnsemble of Machine Learning Classi ﬁers. Abu Dhabi International Petroleum Exhibition&Conference, Abu Dhabi, UAE, 2018, SPE-192930-MS. https://doi.org/ 10.2118/192930-MS.Sun, Z., Jiang, B., Li, X., Li, J., Xiao, K., 2020. A data-driven approach for lithologyidentiﬁcation based on parameter-optimized ensemble learning. Energies 13 (15),3903.https://doi.org/10.3390/en13153903 . Tran, T.V., Ngo, H.H., Hoang, S.K., Tran, H.N., Lambiase, J.L., 2020. Depositional FaciesPrediction Using Artiﬁcial Intelligence to Improve Reservoir Characterization in aMature Field of Nam Con Son Basin, Offshore Vietnam. Offshore TechnologyConference Asia, Kuala Lumpur, Malaysia, November 2020 OTC-30086-MS. https:// doi.org/10.4043/30086-MS. Underhill, J.R., Stoneley, R., 1998. Introduction to the development, evolution andpetroleum geology of the Wessex Basin. In: Underhill, J.R. (Ed.), Geol. Soc. Lond, vol.133. Spec. Publ, pp. 1–18. Wood, D.A., 2018. Transparent Open-Box learning network provides insight to complexsystems and a performance benchmark for more-opaque machine learningalgorithms. Adv. Geo-Energy Res. 2 (2), 148 –162.https://doi.org/10.26804/ ager.2018.02.04.Wood, D.A., 2019. Lithofacies and stratigraphy prediction methodology exploiting anoptimized nearest-neighbour algorithm to mine well-log data. Mar. Petrol. Geol. 110,347–367.https://doi.org/10.1016/j.marpetgeo.2019.07.026 . Wood, D.A., 2020. Bakken stratigraphic and type well log learning network fortransparent prediction and rigorous data mining. Nat. Resour. Res. 29 (2),1329–1349.https://doi.org/10.1007/s11053-019-09525-1 . Wood, D.A., 2022. Gamma-ray log derivative and volatility attributes assist faciescharacterization in clastic sedimentary sequences for formulaic and machine learninganalysis. Adv. Geo-Energy Res. 6 (1), 69 –85.https://doi.org/10.46690/ ager.2022.01.06.Wrona, T., Pan, I., Gawthorpe, R.L., Fossen, H., 2018. Seismic facies analysis usingmachine learning. Geophysics 83 (5), O83 –O95.https://doi.org/10.1190/GEO2017- 0595.1.Xie, Y., Zhu, C., Lu, Y., Zhu, Z., 2019. Towards optimization of boosting models forformation lithology identiﬁcation. Math. Probl Eng., 5309852 https://doi.org/ 10.1155/2019/5309852.D.A. Wood Artiﬁcial Intelligence in Geosciences 2 (2021) 148 –164
164