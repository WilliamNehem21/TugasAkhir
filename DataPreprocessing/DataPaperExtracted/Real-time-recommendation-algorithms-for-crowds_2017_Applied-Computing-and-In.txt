ORIGINAL ARTICLE
Real-time recommendation algorithms forcrowdsourcing systems
Mejdl Safrana,b,*, Dunren Chea
aComputer Science Department, Southern Illinois University, Carbondale, IL, USA
bComputer Science Department, King Saud University, Riyadh, Saudi ArabiaReceived 3 October 2015; revised 31 December 2015; accepted 2 January 2016Available online 23 January 2016
KEYWORDSCrowdsourcing;Recommendationalgorithms;Task recommendation;Worker recommendation;Top-ktasks;Top-kworkersAbstractCrowdsourcing has become a promising paradigm for solving tasks that are beyond thecapabilities of machines alone viaoutsourcingtasks to online crowds of people. Both requesters and workers in crowdsourcing systems confront a ﬂood of data coming along with the vast amount oftasks. Fast,on-the-ﬂyrecommendation of tasks to workers and workers to requesters is becomingcritical for crowdsourcing systems. Traditional recommendation algorithms such as collaborativeﬁltering no longer work satisfactorily because of the unprecedented data ﬂow and the on-the-ﬂy nat-ure of the tasks in crowdsourcing systems. A pressing need for real-time recommendations hasemerged in crowdsourcing systems: on the one hand, workers want effective recommendation ofthe top-kmost suitable tasks with regard to their skills and preferences, and on the other hand,requesters want reliable recommendation of the top- kbest workers for their tasks in terms of work- ers’ qualiﬁcations and accountability. In this article, we propose two real-time recommendationalgorithms for crowdsourcing systems: (1) TOP-K-T that computes the top- kmost suitable tasks for a given worker and (2) TOP-K-W that computes the top- kbest workers to a requester with regard to a given task. Experimental study has shown the efﬁcacy of both algorithms.
/C2112016 The Authors. Production and hosting by Elsevier B.V. on behalf of King Saud University. This isan open access article under the CC BY-NC-ND license ( http://creativecommons.org/licenses/by-nc-nd/4.0/ ).
1. IntroductionIt has been a conﬁrmed phenomenon that almost every area ofhuman activities, especially those related to scientiﬁc explo-ration and technological applications is now producing andconsuming large scales of data. Google estimated that everytwo days in 2010 the world generated as much data as thesum it generated up to 2003[1]. This phenomenon has broughta great challenge to the technological society and to the vastusers who often do not ﬁnd the desired information withinan acceptable time frame. In crowdsourcing systems, users
*Corresponding author at: Computer Science Department, SouthernIllinois University, Carbondale, IL, USA.E-mail addresses:mejdl.safran@siu.edu(M. Safran),dch@cs.siu.edu (D. Che).Peer review under responsibility of King Saud University.
Production and hosting by ElsevierApplied Computing and Informatics (2017) 13,4 7–56
Saudi Computer Society, King Saud University
Applied Computing and Informatics
(http://computer.org.sa)www.ksu.edu.sawww.sciencedirect.com
http://dx.doi.org/10.1016/j.aci.2016.01.0012210-8327/C2112016 The Authors. Production and hosting by Elsevier B.V. on behalf of King Saud University.This is an open access article under the CC BY-NC-ND license ( http://creativecommons.org/licenses/by-nc-nd/4.0/ ).(both requesters and workers) confront exactly the same prob-lem to which a feasible solution is thorough real-time
1recom- mendation. For many applications, recommendation is apersonalized ﬁlter, used to either predict the interestingnessof an item (aprediction problem), or to identify a set of itemsthat are interesting to a user (atop-k recommendation problem) [2,3]. Effective recommendation plays a critical role in suchweb-based systems and beneﬁts users in multiple ways, discov-ering relevant information, reducing waiting time, and increas-ing productivity, to name a few. Many of the leading e-commerce platforms such as Amazon and Netﬂix have alreadyadopted recommendation systems in their systems and demon-strated the great value of effective recommendation.Current recommendation systems are based on two mainapproaches, i.e., content ﬁltering and collaborative ﬁltering.As their names indicate, the content ﬁltering approach relieson the content of the items and the users’ proﬁles to identifythe best matches. On the other hand, the collaborative ﬁlteringapproach relies on the relationships among the items and thecorrelations among the users to draw new hidden, interestingrelationships between the items and the users. Theseapproaches have been showing their successes in many applica-tions, mostly online e-commerce systems.However, when it comes to recommending tasks on crowd-sourcing platforms such as AMT (Amazon Mechanical Turk),these traditional recommendation approaches do not ﬁt well.In other words, they would not be sufﬁciently efﬁcient any-more when they are used for task recommendations in crowd-sourcing systems. Before making detailed explanation, let’sreview the basics of crowdsourcing. In recent years, crowd-sourcing has become a popular paradigm for accomplishingtasks by outsourcing them to online crowds of people. Crowd-sourcing systems (usually built as online platforms) originatedfrom the idea of leveraging human abilities on solving prob-lems and accomplishing tasks that machines alone cannot dowell. Crowdsourcing has many different deﬁnitions [4], each emphasizing different aspects: the nature of the collaboration,the types of the target problems, the motivations of the crowdmembers, and the types of incentives[5]. The deﬁnition in[6]is concise and popular: ‘‘crowdsourcing is an online, distributedproblem-solving and production model ”. Crowdsourcing sys-tems may be categorized into four types[7]based on whether the workers’ contributions are convergent or not and whetherthey are homogeneous or heterogeneous. In the rest of thisarticle, our discussion is not limited to any particular type ofcrowdsourcing systems. Even though we use AMT (a crowdprocessing system) for illustration, the algorithms we presentin this article are suitable for any type of crowdsourcing sys-tems as long as the systems provide task categories or the taskscan be categorized.In AMT, requesters post tasks with speciﬁcations andrequirements; workers select tasks to work on according totheir interest and skills, and then get paid once the requestersaccept their completed results. In terms of performance, thenumber of tasks posted in AMT within a short period of timecan be huge. As a result, the number of available tasks as can-didates to be recommended to a worker is also huge. Addition-ally, tasks in crowdsourcing systems like AMT are short ones(taking a few seconds to a few minutes), so the life cycle of atask in crowdsourcing systems is very short. Consequently,effective recommendation of workers and tasks in crowd-sourcing markets such as AMT is not easily fulﬁlled becauseof the huge pools of tasks and workers and the limit of shortlife span of the tasks. In terms of quality of completed tasks,current crowdsourcing systems that include AMT have foundnumerous drawbacks. Since AMT is based on the ﬁrst-come-ﬁrst-serve basis, a less qualiﬁed worker may start working ona task while a better-skilled worker may not ﬁnd the right taskas it may be listed at a later page or has been already taken bya less-skilled worker. As a result, less qualiﬁed workers may getto work on a task and result in low-quality completion (some-times still accepted). If unsatisﬁed, the requester may have torepost the same task many times to get a quality result.Repeated receiving of low quality results may discourage therequesters from using the crowdsourcing system in the future.Consequently, the need for efﬁcient (real-time) recommen-dation of both tasks and workers in crowdsourcing systemsis becoming a rather pressing issue. Workers, on the one side,desire the top-kbest-ﬁtting tasks being promptly and effec-tively recommended to them, and requesters, on the otherhand, want the top-kbest workers recommended for theirtasks. This phenomenon had motivated our investigation andhas resulted in some interesting outcomes. The article reportsour work and brings in the following main contributions:(i) We inspect the characteristics of the tasks in crowd-sourcing systems as compared to the items/products ine-commerce markets, and the differences of the workers’interests in tasks vs. the users’ interests in items/prod-ucts. The products in e-commerce markets are usuallyoffered ascompleteditems to be purchased by onlineusers, whereas the tasks in crowdsourcing systems areposted activities that areyet to be completedby online workers. We incorporate a key mechanism, i.e., cate-gories of tasks, into our recommendation approach thatsigniﬁcantly accelerates the recommendation procedure.(ii) We propose the TOP-K-T algorithm to help workers incrowdsourcing systems to instantly identify the top- k most suitable tasks for them in a ‘‘pulling ”manner. Therefore the workers can spend more time directly oncompleting the tasks[8]and maximize their productivityand awards.(iii) We also propose the TOP-K-W algorithm to helprequesters in crowdsourcing systems to quickly ﬁnd the
top-kmostqualiﬁedworkers in a ‘‘pushing”manner. To the best of our knowledge, there is no such algorithmproposed that supports requesters by pushing their tasksto the right workers.(iv) We conduct extensive experiments on synthesized large-scale datasets generated based on the scenarios of real-world applications of crowdsourcing systems. Ourexperimental results show that our algorithms (TOP-K-T and TOP-K-W) can make valid recommendationsin real-time performance (in milliseconds or less) at allthe set scales of the test data.The remainder of this article is organized as follows. In Sec-tion2, we brieﬂy review the current recommendation
1In this article, we use the term ‘‘real-time ”in a less strict sense just to emphasize the greatpromptnessorefﬁciencyrequired for the recommendations in real crowdsourcing systems, given the fact thatmany short tasks take minutes or even seconds and may have alreadybeen completed by others before being recommended to a worker.48 M. Safran, D. Cheapproaches. In Section3, we present our new recommendationalgorithms: TOP-K-T and TOP-K-W. In Section 4, we show and discuss our experimental results. In Section 5, we comment on related works and make comparisons with ours. Section 6 concludes the article.2. Current recommendation approachesIn this section we brieﬂy review current recommendationsmethods centered around the two main recommendationapproaches: (1) the content ﬁltering approach and (2) the col-laborative ﬁltering approach.Thecontent ﬁlteringapproach recommends items to a userbased upon the description of the items and the proﬁle of theuser’s interests[9]. A proﬁle is created for each user and foreach product/item. The user proﬁle can be simply a collectionof the user’s historical ratings on purchased items. The productproﬁle is a set of keywords representing the product. Similari-ties between user proﬁles and product proﬁles are computed.Products with high similarities will be recommended to thecorresponding users. Obviously, the approach does not havecold start problem. The problems this approach may faceinclude the following: (1) some items may not be easilydescribed using content keywords; (2) distinct items may sharethe same set of features described by the same keywords; (3)proﬁle information is not always available; and (4) poor per-formance scalability.Thecollaborative ﬁlteringapproach is probably the mostsuccessful and popular approach used in recommendation sys-tems[3]. Comparing to content ﬁltering, the collaborative ﬁl-tering approach relies only on the user’s past behavior. Thisapproach identiﬁes hidden user-products relationships by ana-lyzing the relationships among users and the correlationsamong products[10,9,3]. One remarkable advantage of thisgeneral approach is that it usually generates pretty accurateresults because the learned user-product relationships implic-itly incorporate many subtle aspects that are hard to be explic-itly proﬁled. The approach notoriously suffers from the coldstart problem because it relies on collected historical informa-tion that new users/products do not yet have. Another equallyremarkable drawback of this approach at the current status isits high runtime complexity, which is typically polynomial w.r.t. both the number of users and the number of items, whichboth can be huge in future crowdsourcing systems. Therefore,in principle this attractive approach will not result in real-timerecommendation which is very much needed by future, very-large-scale crowdsourcing systems. The approach has evolvedinto two different methods as follows.Theuser-based collaborative ﬁlteringmethod recommendsto a user the products that have already been liked by like-minded peers of the user. It consists of two steps [3]. First, a user’s historical information is used to identify a neighborhoodof people who in the past have exhibited similar behavior, e.g.,purchased similar products. Second, the identiﬁed neighbor-hood is analyzed to ﬁgure out new products that may be likedby the user. We furnish additional details of the user-based col-laborative ﬁltering method inSupplementary Table 1. Theitem-based collaborative ﬁlteringmethod recommendsitems similar to the items that a user already liked [2,10]. This approach consists of two phases. The ﬁrst phase is called themodel phase that computes the similarity between every pairof items, and may be executed ofﬂine. The second phase com-bines and compares the computed similarity scores to deter-mine the most similar items to the items that have beenpurchased in the past by the user. We provide more detailsof the item-based collaborative ﬁltering method in Supplemen- tary Table 1. To build the model, the algorithm takes Oðm
2nÞ time[10], wheremis the number of items andnis the number of operations needed to compute the similarity between everytwo items. The second phase takesOðkjPjÞtime[10]to decide thekmost similar items for each item inP(i.e., the set of itemspurchased by a given user). We will see later in this article whythis polynomial algorithm does not result in a satisfactory,real-time solution for crowdsourcing systems.3. Proposed recommendation algorithmsIn this section, we ﬁrst motivate our overall strategy and pre-sent the key supportive data structures. Based on that we thenpresent our two recommendation algorithms, TOP-K-T andTOP-K-W, in turn.3.1. Motivation, data structures, and matching scoresWe observe several aspects of essential difference between tra-ditional e-commerce systems and crowdsourcing systems thatought to be carefully considered in the design of the recom-mendation algorithms for crowdsourcing systems.(1) The items in e-commerce markets are completedprod- ucts to be purchased by online users or customers,whereas the tasks in crowdsourcing systems are postedactivitiesyet to be completed(or solved) by online work-ers. The tasks in crowdsourcing systems may be com-pleted atvaried levels of quality, and thus could berejected by the requesters/owners of the tasks if the com-pletion does not fulﬁll the required quality standard.(2) The items in e-commerce systems typically have manycopies and can be sold by different sellers, whereas thetasks in crowdsourcing systems areunique(except for the occasional case that a requester purposefully poststhe same task multiple times in order to gather majorityopinions or alternative solutions). Furthermore, thetasks in a crowdsourcing system usually have prettyshort life span, of which many can be completed in min-utes or seconds by experienced workers.(3) A user’s interest in e-commerce markets is unrestrictedsince one can buy basically anything in the market thathe/she likes as long as he/she has the money, whereas aworker’s choice in a crowdsourcing system is reasonablylimited by his/her expertise/skills and personal interests.Generally, a worker only picks up tasks that ﬁt his/herskills and interest, typically are a much restricted subsetof a potentially huge set of all tasks available in a crowd-sourcing system.Of the above observation, items 1 and 2 indicate the highcomplexity, high diversity, and high velocity inherently exis-tent in crowdsourcing systems, which further imply thatstraightforward utilization of the recommendation methodsdeveloped for traditional e-commerce systems would not resultin satisfactory performance. A novel recommendationReal-time recommendation algorithms 49approach is much needed in order to deliver the required high(real-time) performance of recommendations for both tasksand workers in crowdsourcing systems. Fortunately, item 3brings up a twilight of hope toward overcoming the challengeof recommendations of tasks and workers at real-time speed incrowdsourcing systems. The mapping between the tasks andthe workers is much restricted compared to the unlimited map-ping between products and buyers in an e-commerce system.This difference isessential, analogous to the difference betweena highly selectiveh-join and an unlimited cross-product oper-ation in a relational database system. This observation enlight-ened us to introduce an efﬁcient intermediate mechanismsitting between the tasks and the workers to dramatically limitthe mapping between the two sets, and thus to avoid comput-ing recommendations from the huge set of all possible pairingof tasks and workers.Categoriesas such a mechanism, a medi-ator between the set of workers and the set of tasks, thus comeinto the play. Tasks can be put into various (multi-) categoriesaccording to the skills needed, and workers can also be associ-ated with various (multi-) categories per their proﬁles regard-ing their expertise/skills, personal interests/preferences, andhistorical performance. For e-commerce systems, categoryhas little use (except for browsing products) since it is infeasi-ble to limit the buying choice of a customer to a few categoriesof products. For crowdsourcing systems, categorization oftasks and workers not only makes sense, but is a great dealin facilitating fast recommendation of tasks (for a worker)and workers (for a task requester). In crowdsourcing systems,categories function as effective mediators and provide ‘‘short-circuited”, but meaningful connections between tasks andworkers, which make fast (real-time) recommendations practi-cally achievable. Our two novel algorithms, TOP-K-T andTOP-K-W were thus designed based on leveraging the media-tion mechanism of categories, as a result of the afﬂatus out-lined above.Categorization of tasks is a prerequisite for applications ofour proposed algorithms. The literature has many differentapproaches to achieve satisfactory categorization levels. Thelatest approach is to use a text classiﬁcation system to create‘‘ﬁlters which allow narrowing down the search results basedon predeﬁned ﬁlter categories”[11]. Furthermore, the text clas-siﬁcation system can be improved with the help of human(online crowd) annotators involved into the training processwhere different learning techniques can be combined such asensemble learning and active learning[12]. Categories as an effective mediation mechanism introduced in our algorithmsare mainly to boost the recommendation performance andthe quality of completed tasks. Other researchers [13]have reported that the worker’s perspective is a crucial factor tobe considered in crowdsourcing systems.We may generally consider the top-ktask recommendationas computation of a restricted 1-to-K mapping from workersto tasks, and, in reverse, the top-kworker recommendationas computation of a restricted 1-to-K mapping from tasks toworkers. In order to efﬁciently compute these mappings, wedesign commensurate data structures to facilitate the computa-tion process. These data structures are described below.We introduceC!T(category–task) as an array ofncate- gories,fc
1;c2;...;c ng, where each elementc ipoints to an array of available tasks in categoryc
ias illustrated inFig. 1(a); and W!C(worker–category) as an array ofmworkers,fw
1;w2;...;w mg, where each elementw jpoints to an array ofncategories,fc
1;c2;...;c ng, which each is paired with theworker’s matching scores
i;j(to be deﬁned shortly) with the cor-responding category (as illustrated inFig. 1(b)). A matching scores
i;jmeasures the historical performance, preference, andexpertise of workerw
jwith categoryc i. For each workerw j, we keepnmatching scores in correspondence tondistinct cat- egories. The list ofncategories of each workerw
jðj6mÞis sorted in non-increasing order of the workers’ matching scores,s
i;jð16i6nÞ. ExpressionW j!C iquickly retrieves thematching score of theith most preferable task category ofworkerw
j. For example,W 1!C 1gives the matching scoreof the ﬁrst most preferable category of worker w
1. The W!Cdata structure is illustrated inFig. 1(b) using some randomly set matching scores.To facilitate top-kworker recommendation, theW!C data structure (Fig. 1(b)) alone is not enough since theW!Conly represents the relationship between workers andcategories in one direction (i.e., from workers to categories).
Figure 1Data structures.50 M. Safran, D. CheWe need an additional data structure to conveniently associatequaliﬁed workers to corresponding task categories, i.e.,C!W, as illustrated inFig. 1(c). To avoid redundancy, theworker lists inC!Whold pointers to the same entries inW!C, but ordered differently. InC!W, each category is associated with a list of workers sorted according to theirmatching scores in that category, whereas in W!C, each worker is associated with a list of categories sorted based onthe workers’ matching scores with those categories.In the above discussion, we forward referenced the metricterm, matching score, which is yet to be deﬁned below. Fora given workW
j(i.e., thejth worker) and a task categoryC i
(i.e., theith category), the worker’s matching score with thetasks of this category is deﬁned by the following equation:S
i;j¼AR i;j/C2CPS i;j/C2Similarityðpj;ciÞð1Þ The equation deﬁnes matching score as a product ofthree factors, which in turn stands for the acceptance rate,the category preference score, and the proﬁle-category similar-ity score, which are respectively deﬁned by Eqs. (2)–(4)in the sequel.AR
i;j¼AT i;j
CT i;jð2ÞCPS
i;j¼CT i;j
TCT jð3ÞSimilarityðp
j;ciÞ¼Phk¼1pjk/C2c ikﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃP
hk¼1p2j
kq/C2ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃP
hk¼1c2i
kqð4ÞAcceptance RateðAR
i;jÞis the ratio of the number ofaccepted tasks to the total number of completed tasks in cate-goryc
iby workerw j.Category Preference ScoreðCP i;jÞis the percentage of completed tasks in category c
iby workerw jto the total number of completed tasks by the worker in all cate-gories.Proﬁle–Category Similarityis a cosine similaritybetween a worker’s proﬁlep
j(e.g., expertise, certiﬁcates, hon-ors, etc.) and the category descriptionc
i. It is worth to notethat this score is computed ofﬂine after worker registrationand recomputed every time the worker’s proﬁle is updated.The vector-space model is used where the proﬁle and categoryare represented by their keywords (hkeywords as in Eq.4). Thetf/C2idfweighting method proposed in[14]is used to give each keyword a weight, wheretfmeasures the frequency of akeywordtandidfvaries inversely with the number of docu-ments that containst.3.2. TOP-K-T recommendation algorithmAs the popularity and scale (including both the numbers oftasks and workers) of crowdsourcing systems keep increasing,workers tend to spend more time on ﬁnding proper tasksmatching their skills and interests than on the tasks themselves[15,8]. The motive of our work is to help workers to instantlyﬁnd best matching tasks and to help requesters to quickly iden-tify the best workers for their tasks at hand. Our ﬁrst algo-rithm, TOP-K-T, was thus designed to makerecommendation of the top-kmostsuitabletasks for a worker at real-time speed.Algorithm 1.TOP-K-T Task Recommendation Algorithm.
Our TOP-K-T was designed with the assumption that, in acrowdsourcing system, at any given time, there is a huge list ofavailable tasksðft1;t2;...;t sgÞof which each belongs to cer-tain categories, and a huge list of online workers which eachis associated to certain (usually a few) categories. With the sup-port of the data structures introduced earlier, our algorithmTOP-K-T is nearly straightforward, as shown in Algorithm 1. For a given worker,W
index, the algorithm iterates throughthe categories of the worker maintained in W
index!Cthat is sorted in non-increasing order based on the matching scoresof the worker’s proﬁle with these categories (Line 3 in Algo- rithm 1). The matching scores of the worker with the associ-ated categories are pre-normalized to sum up to 1. Duringeach iteration, one category of the worker is retrieved fromW
index!CintoC target(line 4), and the matching score of theworker with this category is fetched into S
Ctarget ;Windex(line 5). The algorithm then evaluates categoryC
target to select some available tasks from that category. The number of tasks tobe selected fromC
target is the result ofcascade rounding(to be explained shortly via an example) of the product of theworker’s normalized matching score with the category andthe parameterk(line 6). Herein, two cases need to be differen-tiated. (i) The number of available tasks in the considered cat-egoryC
target!Tis less than needed. In this case, all theavailable tasks inC
target!Tare selected and added into theoutput task listL(line 9) and the remaining number of tasksyet to be identiﬁed is passed to the next iteration (line 8). (ii)The number of available tasks inC
target!Tis more than needed. In this case, the algorithm randomly selectsnumselectedþpasstonexttasks fromC
target!Tand adds them to output listL(line 11). An illustrative example is shown inSupplementary Table 2, furnished with explanations.Updating of workers’ matching scores. Each time when aworker completes a task, the acceptance rate (deﬁned by Eq.(2)) and the category preference score (deﬁned by Eq. (3))o f the worker ought to be updated, which further propagates tothe worker’s matching score and calls for resorting of theentries in arraysC!TandC!W. However, it would betoo time-consuming to update these scores and the arraysInput:C!T: the category–task data structure.W!C: the worker–category data structure.index: the index of the worker seeking tasks.k: the number of tasks to be recommended.Output:L: an array of the top-ktasks for the worker.1Initialize output arrayL2passtonext 03 fori 1toW
index!C:sizedo4C
target getCategoryðW index!C iÞ; 5S
Ctarget ;Windex getScoreðW index!C iÞ 6numselected cascaderoundðS
Ctarget ;Windex/C2kÞ; 7i fnumselectedþpasstonext>C
target!T:sizethen 8passtonext passtonextþnumselected/C0C
target!T:size 9L all tasks in C
target!T10 else11L randomly selectðnumseletedþpasstonextÞtasks from C
target!T12 end13 endReal-time recommendation algorithms 51every time a worker completes a task. Therefore, our approachadopts periodic batch update on these scores and the arrays aswe assume that each time when a worker completes one task,the affect on the worker’s matching score is marginal. Thisapproach may not satisfy the need of the workers who wantthe recommendation system to recommend tasks that are sim-ilar to their recently chosen and completed ones [13]. This is an issue of trade-off between performance and accuracy of recom-mendations. A possible solution would be to offer ‘‘instantscore update”as a user controllable function in the interface.Alternatively, the system may be set to automatically adjustthe update pace based on explicit feedback from workersregarding their satisfaction with the recommendations madeby the system to them. This information ought to be integratedinto the proﬁles of the workers and used in the future towardmore personalized recommendation. The above ideas have notbeen reﬂected in our current algorithm.Dealing with the cold-start problem. New workers face acold-start problem, which means the matching scores of theseworkers are not available. This is a serious problem that, if leftunattended, new workers will never be recommended a task tostart with. To solve this problem, for new workers we countonly on the similarity scores (Eq.(4)). Recommendationsbased on similarity scores reﬂect the worker’s expertise, skills,and personal preferences only. Once a new worker has a cer-tain number of tasks completed, the standard matching scorecomputation (Eq.(1)) will be switched on. Here we assumethat a crowdsourcing system requires workers to choose somepreferences when they try to register to the system. Thisrequirement is not directly reﬂected in our algorithm showninAlgorithm 1. Alternatively, new workers may choose tobrowse the listed tasks, select and work on their interestedtasks to mitigate the cold-start problem. Using similarityscores as substitute for the matching scores may not wellencourage diversiﬁcation of task categories since higher simi-larity scores tend to lock on fewer categories. We propose todifferentiate between eager workers and lazy workers, ofwhich, the former are inclined to try new types of tasks eventhough they may not do their best with, while the latter wantto keep working on the types of tasks they used to work onand can do their best with. A partial solution to task diversiﬁ-cation for eager workers is to switch our cascade roundingtechnique (exempliﬁed inSupplementary Table 2) from rounding-up to rounding-down in order to increase the chanceof selecting tasks from additional categories.For a given worker, our TOP-K-T algorithm takesOðaþkÞruntime to produce recommendation, where ais the number of task categories covered by the worker’s proﬁleandkis the number of tasks to be recommended to the worker.Both parametersaandkare usually small numbers in real-world scenarios. Evidently, algorithm TOP-K-T is extremelytime-efﬁcient, regardless of the size of the data ﬂow in a crowd-sourcing system; the real-time recommendation of top- ktasks to any given worker can be guaranteed. To recap, our TOP-K-T algorithm achieves its real-time performance owing to thecreative incorporation of categories that signiﬁcantly reducesthe search space for best matching tasks; the algorithm also‘‘welcomes”new workers (i.e., dealing with the cold-startproblem) by automatic switching of its matching scorecomputation.3.3. TOP-K-W recommendation algorithmFor a posted task, our TOP-K-W algorithm identiﬁes thetop-kmostsuitable(technically qualiﬁed and interested) work-ers to recommend to the requester for soliciting them to workon the task. In order to obtain real-time performance, similarstrategy and data structures are used in the algorithm. The rec-ommendation problem faced by our TOP-K-W algorithm isstated as follows: given any tasktassociated with a weightedlist of categories thattbelongs to, say,fðc
1;b1Þ;ðc 2;b2Þ;...;ðc r;brÞg, what are the top-kmost suitable workers to be recommended to work on the task?The TOP-K-W algorithm is described inAlgorithm 2. The algorithm iterates through the categories of a given task, i.e.,listTaskCat(starting at line 3 inAlgorithm 2). During each iteration, the next category index is fetched from listTaskCatinto variableC
target, and the associated categoryweight is fetched into variableC
weight (lines 4 and 5, respec-tively). The number of workers selected from C
targetis decided by the product of the category’s weightC
weight and the param- eterkafter applying cascade rounding (line 6). Similar to algo-rithm TOP-K-T, two speciﬁc cases need to be separatelyaddressed, of which the deliberation is omitted due to analo-gous disposition.Algorithm 2.TOP-K-W Recommendation Algorithm.
Input:C!W: the category–worker data structure.TaskCat: list of the weighted categories of given task.k: the number of workers to be recommendedOutput:L: list of top-kworkers for recommendation.1Initialize output arrayL2passtonext 03 fori 1toTaskCat:sizedo4C
target getCategoryðTaskCat½i/C138Þ 5C
weight getWeightðTaskCat½i/C138Þ6numselected cascaderoundðC
weight/C2kÞ 7i fnumselectedþpasstonext>C
target!W:sizethen 8passtonext passtonextþnumselected/C0C
target
!W:size9L all workers in C
target!W(not already inL) 10 else11L firstðnumseletedþpasstonextÞworkers fromC
target!W(not already inL) 12 end13 end
Special case discussion. The TOP-K-W algorithm may face asituation where all the recommendedkworkers are busy doingother tasks or unavailable for any other special reasons. OurTOP-K-W algorithm solves this problem by taking the advan-tage of the already sorted list of workers stored in C
index!W. The algorithm periodically increases the value of kuntil one of the recommended workers starts working on the task. Insteadof simply recommending alternative workers in the subsequentrounds of recommendation, our algorithm retains previouslyrecommended workers in the recommendation list in order to52 M. Safran, D. Cheretain the opportunity of getting those high-ranked workers astheir statuses may change soon.In summary, the TOP-K-W algorithm takes OðkþkÞrun- time, wherekis the number of categories that a given taskbelongs to andkis the number of workers to be recommendedfor the task. It is evident that bothkandkare usually small numbers in real-world scenarios. Our TOP-K-W algorithm isable to obtain real-time performance (in less than a millisecondper our experiments, to be detailed shortly), regardless of thepotentially huge volume of data ﬂow typically found in crowd-sourcing systems. The TOP-K-W algorithm adopts an incre-mental recommendation strategy to bring down the possibledelay of task completion to the minimum. Similar to algorithmTOP-K-T, this algorithm also assumes ofﬂine batch update onworkers’ matching scores and resorting of the worker listunder each category in order to deliver real-time performance.4. Experimental resultsIn this section, we evaluate our proposed algorithms, TOP-K-T and TOP-K-W, through experimental study. As currently(to the best of our knowledge), there are no applicabledatasets gathered from real-world crowdsourcing systems that are pub-licly available and ﬁt the need of the presented work, we con-ducted our study based on synthesized datasets. To makesynthesized datasets realistic and representative, we generatedour datasets at various scales and at every step we tried tomimic the scenarios in a real-world crowdsourcing system.Table 1shows the characteristics of generated datasets. Uni-form distribution had been assumed at several places duringthe process of generating these synthesized datasets. Supple- mentary Figs. 3–6show the distribution features of a sampleof the synthesized datasets. Our proposed algorithms and thedata generation are implemented using C#. All experimentsare conducted on a PC with Intel Xeon 2.40 GHz processorsand 16 GB DDR3 RAM in a light load condition. Everyexperiment presented below is conducted twenty times andthe average running time is computed. In the following, wepresent the experiment results of algorithms TOP-K-T andTOP-K-W, respectively.4.1. TOP-K-TAs mentioned earlier, the theoretical time complexity of theTOP-K-T algorithm isOðaþkÞ, whereais the number of worker’s categories andkis the number of tasks to be recom-mended. To fairly evaluate the performance of this algorithm,we select three different types of workers, i.e., workers withmaximum number of categories (MAXworker), workers withaverage number of categories (AVGworker), and workers withminimum number of categories (MINworker). Besides, weconsider three different values fork, namely, 1, 20, and 50,to see how different values ofkwould affect the performanceof TOP-K-T.Fig. 2(a) shows the performance of TOP-K-T with theparameterkset to 1 (i.e., to recommend only one task to eachworker). As shown in the ﬁgure, the runtimes are basicallyconstant in terms of dataset sizes, but with noticeable ﬂuctua-tions in the range from 132 to 143 ns. The reason that causedthe ﬂuctuations is the randomness in the numbers of categoriesof workers, the numbers of tasks of categories, etc. For exam-ple, when a preferred task category does not have any or doesnot have enough available tasks, the algorithm needs to runadditional iterations to selects tasks from subsequent cate-gories.Fig. 2(b) shows the performance of TOP-K-T with k set to 20 (i.e., to recommend top 20 tasks for each worker).The 20 tasks are selected from different categories, and therunning time increases as the number of categories probedincreases. For example, the case with MINworker runs thefastest as it involves the minimum number of categories to pro-cess.Fig. 2(c) shows the performance of TOP-K-T with kset to 50 (i.e., to recommend top 50 tasks to each worker). Asexpected, the times taken accordingly increase when k increases from 20 to 50. The performance plots show basicallyconstant performance with regard to varied dataset sizes andour explanation for the performance data is basically the sameas with the cases of smaller
kvalues. The only thing we wouldlike to point out herein is that whenkis 50, which is prettylarge in real-world scenarios, our TOP-K-T algorithm remainsextremely efﬁcient, taking up to only a couple of millisecondsin our experiments.Analytically, the running time of our TOP-K-T algorithm isaffected only byaandkwhich are typically very small num-bers, regardless of the data sizes (the numbers of workers,tasks, etc.). Our experimental study conﬁrms the validnessand the constant time performance of our algorithm.4.2. TOP-K-WAs pointed out before, our TOP-K-W algorithm takesOðkþkÞtime, wherekis the number of categories that a giventask belongs to andkis the number of workers to be recom-mended to the task requester. To evaluate the algorithm weassume the following scenario: (1) a requester posts 5 tasksðt
1;t2;t3;t4;t5Þand sets parameterkto 3, 10, 20, 30, and 50,respectively; (2) the tasks,t
1;t2;t3;t4, andt 5respectively belong to 1 category, 4 categories, 7 categories, 3 categories,and 10 categories.Fig. 3shows the performance plots ofTOP-K-W with regard to the above assumptions. It can beeasily observed fromFig. 3that the running times are basicallyconstant in terms of dataset sizes, affected only by parameterskandk(both in practice are very small numbers). It can alsobe observed that the sizes of the datasets do not have notice-able inﬂuence on the running time of the algorithm as the timeplots all appear to be constant plots with regard to varied data-set sizes.5. Related worksThe study of task recommendation in crowdsourcing systemshas been growing to such a point of forming a distinct disci-
Table 1Synthesized datasets and characteristics.
Dataset #Workers #Categories #Completedtasks#Availabletasks DS1100,000 300 178,898,799 80,710DS2300,000 500 974,854,896 490,815DS3500,000 600 1,908,867,719 960,814DS41,000,000 1000 3,127,310,923 1,396,721Real-time recommendation algorithms 53pline with its own identity and merits. Several representativeapproaches[15–18]have been proposed to tackle the recom-mendation problem in crowdsourcing systems. In this section,while we review these related works, we make comparisonswith ours.Our argument for effective, real-time recommendation oftop-ktasks and top-kworkers in crowdsourcing systems isnot alone. Ipeirotis[15]examined the task posting and comple-tion activities on AMT, and concluded that AMT is a heavy-tailed market, i.e., it has a heavy-tailed distribution of boththe completion time and posting time, as illustrated in Supple- mentary Fig. 1, where the number of tasks arrived on Novem-ber 10th, 2013 reached 50,000, followed by 400,000 on the nextday. The tasks in crowdsourcing systems include micro-tasks,particularly on AMT, that have very short life spans, e.g., fromminutes (if not seconds) to hours. These unique features ofcrowdsourcing systems, i.e., huge ﬂow of tasks with very shortlife spans, make traditional recommendation algorithms inap-plicable simply because they were not designed and are unableto deliver the desired real-time recommendation performanceby most crowdsourcing systems.Ambati et al.[16]proposed a task recommendationapproach based on a classiﬁcation technique. Their proposedapproach ﬁrst generates a worker model by acquiring the
Figure 3Performance of TOP-K-W with varied kvalues.
Figure 2Performance of TOP-K-T withk¼1, 2 and 50.54 M. Safran, D. Cheworker’s performance information, based on which, a classiﬁeris then trained to classify the available tasks as interesting oruninteresting to a given worker. Per our understanding, thisapproach may suffer with the following three issues: (1) simi-larity computed based only on task description may not ade-quately capture the true nature of the tasks since two taskswith similar keywords may not be similar in nature and theskills needed; (2) this approach relies on a carefully-selected,balanced training set which is very hard to obtain for emergingresearch topics such as crowdsourcing; and (3) this approachmay also suffer from poor scalability when applied to reallylarge crowdsourcing systems.The work reported in[17]improves in[16]by additionally incorporating a worker’s task selection history besides theworker’s performance history. The proposed algorithm in[17]assumes that there is a set of categories predeﬁned; andany task posted by a requester can be categorized into oneof those categories. The algorithm recommends to a workera list of tasks sorted according to the worker’s preferencesand the acceptance tendency of the worker’s completed tasksby the requesters. Comparing to our work, this approach hasthe following limitations: (1) limited scalability since it iteratesthroughall available tasks in all categories(which can be enor-mous) every time a worker logs into the system and needs toupdates the worker’s scores every time s/he completes a taskand (2) this approach has the cold-start problem.The same group extended their algorithm in [18]. In the extended version, a worker-task matrix is used where eachentry in the matrix has a value from 1 to 5. The main goalof this approach is to predict the missing values in theworker-task matrix. This approach employs matrix factoriza-tion technique to understand the worker’s preference on thetasks. Comparing to our work, this approach has the followingconcerns: (1) this approach may still suffer from scalabilityissues since it records all interactions between all the workersand the system, and yet, its matrix is expanding rapidly whichmakes the relearning of the matrix much harder to handle and(2) it is difﬁcult to obtain the worker’s task searching historysince it is only accessible to the crowdsourcing systems’ admin-istrators as the authors pointed[18].6. Conclusion and future workWith the increased popularity and scales, crowdsourcing sys-tems involve a ﬂood of data which could leave the workersand requesters at dismay when they (as workers) are tryingto ﬁnd suitable tasks to work on or (as requesters) to ﬁndthe best workers for their tasks. Therefore, making the goodrecommendation on the ﬂy has become critical to these sys-tems. In this article, we revealed our insight into the essentialdifference between the tasks in crowdsourcing systems andthe products/items in e-commerce markets, and the differencebetween a buyer’s interest in products/items and a worker’sinterest in tasks. Our insight inspired us to bring up categories as a key mediation mechanism between workers and tasks,which has been proven an highly effective means in our efforttoward designing extremely scalable and efﬁcient recommen-dation algorithms for crowdsourcing systems. Our effort hasresulted in two novel algorithms, TOP-K-T (computing thetop-kmost suitable tasks to recommend to a worker) andTOP-K-W (computing the top-kbest workers to recommendto a task requester). Both algorithms demonstrate superb(real-time) performance — make valid recommendations injust a few milliseconds regardless of dataset sizes, whichexplains the great scalability and efﬁciency of our algorithms.Besidescategoriesas a general mediation mechanism, our var-ious data structures (illustrated inFig. 1(a)–(c)) provide instru-mental support to the implementation of our approaches.These data structures absorb a major part of the intrinsic com-plexities of the recommendation problems, and render us suc-cinct algorithms with great efﬁciency and scalability. We havedone extensive experimental study of our algorithms with syn-thesized datasets because no suitable real dataset is availablefor our study. We did not do horizontal comparison withrelated algorithms in the experimental study as our algorithmsare quite different in nature from all other related algorithms,and are evidently superb to them, which makes equal-footingempirical comparison with them less interesting andunnecessary.As part of our future work, we are looking forward toobtaining real datasets from the existing crowdsourcing sys-tems such as AMT to further evaluate our algorithms. Mean-while, we plan to take workers’ rewards and preferred worktimes as additional factors into our recommendation frame-work in order to make our recommendations more appealingto both workers and requesters.Appendix A. Supplementary materialSupplementary data associated with this article can be found,in the online version, athttp://dx.doi.org/10.1016/j.aci.2016.01.001.References
[1]D. Che, M. Safran, Z. Peng, From big data to big data mining:challenges, issues, and opportunities, Database Systems forAdvanced Applications, vol. 7827, Springer, Berlin, Heidelberg,2013, pp. 1–15 (Chapter 1)
.[2] B. Sarwar, G. Karypis, J. Konstan, J. Reidl, Item-basedcollaborative ﬁltering recommendation algorithms, in: 10thInternational Conference on World Wide Web, Hong Kong,Hong Kong, 2001, pp. 285–295.[3] G. Karypis, Evaluation of item-based top-n recommendationalgorithms, in: 10th International Conference on Informationand Knowledge Management, 2001, pp. 247–254.[4]
E. Estelle´s-Arolas, F. Gonza´lez-Ladro´n-De-Guevara, Towards an integrated crowdsourcing deﬁnition, Inf. Sci. 38 (2) (2012)189–200
.[5]
A. Doan, R. Ramakrishnan, A. Halevy, Crowdsourcing systemson the world-wide web, Commun. ACM 54 (4) (2011) 86–96
. [6]
D. Brabham, Crowdsourcing as a model for problem solving: anintroduction and cases, Convergence: Int. J. Res. New MediaTechnol. 14 (1) (2008) 75–90
.[7]
D. Geiger, M. Schader, Personalized task recommendation incrowdsourcing information systems current state of the art,Decis. Support Syst. 65 (2014) 3–16
. [8] L. Chilton, J. Horton, R. Miller, S. Azenkot, Task search in ahuman computation market, in: The ACM SIGKDD Workshopon Human Computation, New York, NY, USA, 2010, pp. 1–9.[9]
Y. Koren, R. Bell, C. Volinsky, Matrix factorization techniquesfor recommender systems, Computer 42 (8) (2009) 30–37
. [10]
M. Deshpande, G. Karypis, Item-based top- nrecommendation algorithms, ACM Trans. Inf. Syst. 22 (1) (2004) 143–177
.Real-time recommendation algorithms 55[11] S. Schmidt, S. Schnitzer, C. Rensing, Text classiﬁcation basedﬁlters for a domain-speciﬁc search engine, Comput. Ind. (inpress), 2015 (http://dx.doi.org/10.1016/j.compind.2015.10.004 ). [12]S. Schnitzer, S. Schmidt, C. Rensing, B. Harriehausen-Muhlabauer, Combining active and ensemble learning forefﬁcient classiﬁcation of web documents, Polibits 49 (2014) 39–45
.[13]
S. Schnitzer, C. Rensing, S. Schmidt, K. Borchert, M. Hirth, P.Tran-Gia, Demands on task recommendation in crowdsourcingplatforms – the workers perspective, in: CrowdRec Workershop,ACM RecSys, 2015
.[14]
G. Salton, C. Buckely, Term-weighting approaches in automatictext retrieval, Inf. Process. Manage. 24 (5) (1988) 513–523
.[15]P. Ipeirotis, Analyzing the Amazon Mechanical Turkmarketplace, ACM XRDS 17 (2) (2010) 16–21
. [16] V. Ambati, S. Vogel, J. Carbonell, Towards taskrecommendation in micro-task markets, in: The 25th AAAIWorkshop in Human Computation, AAAI, 2011.[17]
M.C. Yuen, I. King, K.S. Leung, Task matching incrowdsourcing, in: The 4th IEEE International Conference onCyber, Physical and Social Computing, IEEE ComputerSociety, 2011, pp. 409–412
.[18] M.C. Yuen, I. King, K.S. Leung, Task recommendation incrowdsourcing systems, in: ACM KDD Workshop on DataMining and Knowledge Discovery with Crowdsourcing, 2012.56 M. Safran, D. Che