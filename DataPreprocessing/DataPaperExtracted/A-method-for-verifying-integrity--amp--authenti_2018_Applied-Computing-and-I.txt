A method for verifying integrity & authenticating digital media
Martin Harrana, William Farrellya, Kevin Curranb,⇑
aLetterkenny Institute of Technology, Donegal, Ireland
bUlster University, Derry, United Kingdom
article info
Article history:Received 6 March 2017Revised 22 May 2017Accepted 24 May 2017Available online 31 May 2017Keywords:Secure authenticationIntegrityDigital certiﬁcatesSecurityNetwork securityabstract
Due to their massive popularity, image ﬁles, especially JPEG, offer high potential as carriers of other infor-mation. Much of the work to date on this has focused on stenographic ways of hiding information usingleast signiﬁcant bit techniques but we believe that the ﬁndings in this project have exposed other ways ofdoing this. We demonstrate that a digital certiﬁcate relating to an image ﬁle can be inserted inside thatimage ﬁle along with accompanying metadata containing references to the issuing company.Notwithstanding variations between devices and across operating systems and applications, a JPEG ﬁleholds its structure very well. Where changes do take place, this is generally in the metadata area and doesnot affect the encoded image data which is the heart of the ﬁle and the part that needs to be veriﬁable.References to the issuing company can be inserted into the metadata for the ﬁle. There is an advantage ofhaving the digital certiﬁcate as an integral part of the ﬁle to which it applies and consequently travellingwith the ﬁle. We ultimately prove that the metadata within a ﬁle offers the potential to include data thatcan be used to prove integrity, authenticity and provenance of the digital content within the ﬁle./C2112017 The Authors. Production and hosting by Elsevier B.V. on behalf of King Saud University. This is anopen access article under the CC BY-NC-ND license ( http://creativecommons.org/licenses/by-nc-nd/4.0/ ).
1. IntroductionMore of today’s communications are moving to exclusively dig-ital format with no hard copy backups being kept. This has impli-cations regarding integrity, authentication and provenance invarious areas such as litigation where it is necessary that bothsides are satisﬁed with the integrity of digital evidence or in theinsurance industry where claims can succeed or fail on verydetailed terms and conditions; it may be necessary to know exactlywhat the terms and conditions were at the time the policy was cre-ated[1]. There is also a need to verify the terms of a contract thatapplied when the contract was agreed and establish dates of orig-inal creation when copyright issues arise regarding digital content[2]. Likewise, real world requirements exist to establish priorknowledge before signing Non-Disclosure Agreements. Animportant aspect of this is that the raw data content of a ﬁle canbe veriﬁed even when the metadata is altered due to the ﬁlemoving across operating systems or devices.Widespread and easily available tools have become common forvideo synthesis. It is important to ensure the authenticity of videouses such as in courts of law, surveillance systems, advertisementsand the movie industry. There is therefore a large body of researchin the ares of video authentication and tampering detectiontechniques[3–5]. There is also research using Darwin InformationTyping Architecture in protecting the integrity of digital publishingapplications[6].Although there are many tools available to create, encrypt andextract data, there is relatively little available in the area of estab-lishing integrity, authentication and provenance. For instance, [7] creates and issues a certiﬁcate containing a SHA 256 hash valueof the submitted media ﬁle along with the user details and a times-tamp. That certiﬁcate is in turn veriﬁed by a digital certiﬁcateissued by leading certiﬁcation authority Comodo. The problemhere however is that the original ﬁle and the certiﬁcation are sep-arate entities and could easily become separated during distribu-tion or circulation of the ﬁle. In general, wrapping the ﬁle and itscertiﬁcation inside an outer envelope is no real guarantee thatthe ﬁeld and its certiﬁcation will remain together. Inserting thecertiﬁcation into the ﬁle is the only apparent reliable methodand is the approach used by leading companies such as Microsoftand Adobe for digital signing of Ofﬁce and PDF documents [8].A limitation with inserting the certiﬁcate inside the ﬁle is that it
http://dx.doi.org/10.1016/j.aci.2017.05.0062210-8327//C2112017 The Authors. Production and hosting by Elsevier B.V. on behalf of King Saud University.This is an open access article under the CC BY-NC-ND license ( http://creativecommons.org/licenses/by-nc-nd/4.0/ ).⇑Corresponding author.E-mail address:kj.curran@ulster.ac.uk(K. Curran). Peer review under responsibility of King Saud University.
Production and hosting by ElsevierApplied Computing and Informatics 14 (2018) 145–158
Contents lists available atScienceDirect
Applied Computing and Informatics
journal homepage: www.sciencedirect.com
must follow the metadata speciﬁcation set out for the particularﬁle type which means that distinct software applications or com-ponents have to be developed for every ﬁle type.This research outlines a method in which integrity, authentica-tion and provenance can be established for raw data within a ﬁleeven when the metadata attached to it has changed. We alsoachieve this in a manner in which a digital proof stamp can bemade visual to help achieve virality for the end users.2. Digital ﬁngerprintingDigital ﬁngerprinting is based on the use of a mathematicalfunction to produce a numerical value where the function takesan arbitrary length of data as its input and outputs a numericalvalue of a speciﬁed length; 128 bits (16 bytes), 256 bits (32 bytes)and 512 bits (64 bytes) are typical lengths. The output value ofsuch a function is generally referred to as a hash valueor simply hash.In order to be useful, the function used to produce a digitalﬁngerprint must be quick to use but in order to be trustworthyfor authentication purposes, it must also meet certain securityrequirements[9]. For this reason, digital ﬁngerprinting uses crypto- graphic hash functions; the authors describe the general securityproperties of these functions as preimage resistance, secondpreimage resistance (or weak collision resistance) and collisionresistance (or strong collision resistance) where:/C15Preimage resistance means that for a hash function Hand an output value ofz,i ti scomputationally infeasible
1to ﬁnd an input valuemsuch thatz¼HðmÞ. This property is also known asone- wayness.
/C15Second preimage resistance means that given an input m 1,i ti s computationally infeasible to ﬁnd a different message m
2where Hðm
1Þ¼Hðm 2Þ. This is also known asweak collision resistance. /C15Collision resistance means that it is computationally infeasibleto ﬁnd two different inputs where m
1and m 2whereHðm 1Þ¼ Hðm
2Þ. This is also known asstrong collision resistance.Ref.[10]stated that collision resistance implies second preim-age resistance but does not guarantee preimage resistance. Ref.[11]pointed out that that the validity of those claims is limitedto speciﬁc deﬁnitions of the various terms. The subtletiesinvolved, however, have no impact on this project as only secondpreimage resistance applies in regard to the use of digital ﬁnger-prints for ﬁle authentication - a potential attacker has access toboth the original input (the ﬁle) and the output (the hash valuefor the ﬁle).A wide range of algorithms have been developed to meet therequistite security requirements as well as having the underlyingperformance requirement of computational speed. Two of the mostcommonly encountered functions are MD5 and the SHA family offunctions. MD5 (Message Digest algorithm 5) was developed byRef.[12]who had previously developed earlier versions MD2 –MD4. It became extremely popular following its release but begin-ning in 1996, vulnerabilities were increasingly identiﬁed in regardto collision resistance. Ref.[13]stated that although practicalapplications were not yet threatened, it ‘‘comes rather close” andadvised users to move to other algorithms. Eight years later, Ref.[14]announced collisions based on the full hash. Four years afterthat, Ref.[15]based MD5 collision vulnerabilities to create a roguedigital certiﬁcate which would be accepted by all commonbrowsers. The credibility of MD5 was effectively terminated inDecember that year by the release of a Vulnerability Notice byUS-CERT[16]which stated that ‘‘it [MD5] should be consideredcryptographically broken and unsuitable for further use”. AlthoughMD5 is still adequate for checking ﬁle consistency and other non-secure applications, the known weaknesses should have effectivelyended its use for digital signatures. It is still in widespread use,however, as late as 2012 when it was used to fake a Microsoft dig-ital signature in theFLAMEmalware attack[17]. Rivest has pro- duced an MD6 version but after submitting it to the NIST opencompetition for SHA-3, he withdrew it stating that it was not readyfor use[18]. Following the decline of MD5, the predominant algo-rithms in use today are members of the SHA family.2.1. Secure hash algorithmSecure Hash Algorithm (SHA) is a family of cryptographic hashfunctions developed by the US National Security agency (NSA) andpublished as standards by the US National Institute of Science andTechnology (NIST). It is the required algorithm for secure applica-tions used by US government agencies. An important feature of theSHA algorithms is that they implement an avalanche effectwhich means that a minor change to the input cascades into a majorchange in the output value.The ﬁrst version, SHA-1 produces a 160-bit value and wasreleased in 1993; it was, however, withdrawn shortly after publi-cation due to an undisclosed vulnerability and a modiﬁed versionwas released two years later[19]. In 2002, NIST published theSHA-2 family of functions. Unlike SHA-1 with hash size ﬁxed at160 bits, SHA-2 is offered in six versions producing a range of out-put sizes from 224 to 512 bits of which the most widely used areSHA-256 and SHA-512. Like MD5 and SHA-1, the SHA-2 functionsare based on the Merkle–Damgård construction. The algorithmused for SHA-256 is:1. A 256-bit buffer is created, made up of 8 /C232-bit words which are initialised with the ﬁrst 32 bits of the fractional parts of thesquare roots of the ﬁrst 8 primes.2. A 64 element table of constants is prepared using the ﬁrst 32bits of the fractional parts of the cube roots of the ﬁrst 64primesThe input is padded with an initial bit ‘1’ and the length of theoriginal input expressed as a 64-bit integer, separated by therequired number of zeros required to make the message length,including the padding, a multiple of 512 bits.3. Each 512-bit block is processed through 64 rounds where eachround involves a series of operations comprised of bitwise oper-ations and modular addition.4. The value of the buffer on completion of each block is the initialvalue for the following block; at the end of the ﬁnal block, thebuffer contains the hash value.Despite offering better security and faster performance, SHA-2was only adopted slowly over the next three years with SHA-1remaining in extensive use. The main contributory reasons were
that SHA-2 was not supported on systems using Windows XP(SP2) or older, there was no perceived urgency as no collisionshad yet been found in SHA-1 and SHA-256 is about 2.2 timesslower than SHA-1 though some of that drop can be reduced bya move to SHA-512 on 64-bit hardware and operating systems[20].Ref.[21]revealed collision attacks on the full SHA-1 function.This work did not completely undermine the practical reliabilityof the function – it was astrong collision attackwhich did not impact on the preimage – but the following year, NIST instructed
1An expression used in cryptology to signify that, given enough time andresources, it may be theoretically possible to decrypt the result of a cryptographicfunction but the time and resources actually available make it impractical in anymeaningful way.146 M. Harran et al. / Applied Computing and Informatics 14 (2018) 145–158federal agencies to stop using SHA-1 as soon as practical and statedthat after 2010, SHA-2 would be compulsory for digital signatures,digital time stamping and other applications requiring collisionresistance[22]. Although SHA-1 is still in extensive use and is stillsecure for most practical purposes, applications that continueusing it are likely to run into ever increasing problems as softwaredevelopers drop support from new versions of their applications;Microsoft, Chrome and Mozilla, for example, have all announcedthat SHA-1 will not be supported in browser versions beyond 2016.No signiﬁcant attack on SHA-2 has ever been demonstrated.Nevertheless, in what can be regarded as a pre-emptive move, NISTlaunched an open competition in 2007 for the development ofSHA-3. The reason for adopting an open competition approachwas to ﬁnd an alternative to the Merkle–Damgård constructionas that had been the basis of the now discredited MD5 and SHA-1 as well as SHA-2. The eventual winner, KECCAKusing what is known as thespongeconstruction, was announced in 2012 andthe new standard published three years later [23]. The pre- emptive nature of SHA-3 is clearly indicated by NIST whose currentpolicy on hash functions[24]states that there is no need to transi-tion applications from SHA-2 to SHA-3.2.2. RSAThe original concept of a digital authentication scheme was ﬁrstproposed by Difﬁe and Hellman[25], who revolutionised cryptog- raphy by proposing a method of creating a shared secret over pub-lic or unsecured channel which would enable traditional symmetric cryptography to be used electronically. In their paper, they alsodiscussed the idea of a system of public key cryptographybased onpublicandprivatekeys and also the need forone-way authenti- cationbut did not propose solutions for either of these. Two yearslater, such a solution was developed at Massachusetts Institute ofTechnology (MIT) by three researchers [12]which became known by the initial letters of their surnames, RSA (Rivest- Shamir- Adle-man). The RSA public/private key algorithm is based on the difﬁ-culty of factoring large numbers and produces a private key anda public key where a message encrypted using the public key canbe decrypted using the private key but calculating the privatekey from the public key is computationally infeasible. This isknown asasymmetricencryption. The RSA algorithm is too slowfor encrypting lengthy messages but it can be used to create ashared secret which can then be used for high-speed symmetricalencryption.2.3. Digital signaturesRef.[12]also proposed that authentication of content, whetherencrypted or in plain-text, could be achieved by using the keys toencrypt and decrypt a digital ﬁngerprint. The overall process, amessage accompanied by a hash of the message encrypted withthe sender’s private key constitute what is known as a digital signa- ture.This process fulﬁlls the twin requirement of authentication i.e.identiﬁcation and non-repudiation. If the calculated hash valuematches the decrypted hash value from Alice, then Bob can be con-ﬁdent that the message was indeed sent by her and the messagehas not changed in transit. Alice, in turn, cannot deny sendingthe message provided that ker private key was genuinely used toencrypt the hash. That was the main outstanding problem – estab-lishing a trustworthy way to distribute public keys. The processesare open toman-in-the-middleattacks where a third party couldsubstitute their own public key for that belonging to Alice and senda different ﬁle and hash to Bob and he will be duped into believingit is a genuine message from Alice.Reliable distribution of public keys can be achieved through theuse ofdigital certiﬁcates, also known aspublic key certiﬁcates,whichare electronic documents that verify the owner of a public key.These certiﬁcates are issued by a Certiﬁcation Authority(CA), an organisation which specialises in the business of issuing certiﬁ-
cates, usually on a commercial basis and which can be trusted byrecipients. The certiﬁcate is a binding between an entity and itsassociated public key and contains information about the issuingCA as well as information about the person or organisation towhom the certiﬁcate applies. This information is generally pre-sented in the format of an X.509 certiﬁcate. Digital certiﬁcatesissued by third-party certiﬁcation authorities are the backbone ofsecure Internet connections based on Transport Layer Security(TLS), formerly known as Secure Sockets Layer (SSL); a secure con-nection is most recognisable when a website uses Hypertext Trans-fer Protocol Secure (HTTPS) and a padlock icon appears in the URLor at the bottom of the browser. The digital certiﬁcate for the sitecan be viewed by clicking on the padlock. Until comparativelyrecently, secure connections using SSL/TLS were primarily usedfor webpages involving ﬁnancial transactions but they are cominginto wider use in popular sites such as Google and social mediasites such as Facebook and Twitter.The highest level of CA is known as a Root CAand public keys for these root CAs have to be authenticated using the issuer’s ownpublic key. These keys therefore have to be readily available andare built into operating systems and browsers. In addition to roottrusted CAs, a range of other categories is included such as TrustedPublishers, Trusted People and Other People. These are managedthrough a hierarchical structure where higher levels of CA can del-egate authority to lower level CAs for speciﬁc uses. This requires achain of trustbetween the root CA and the ones descended from it.Despite this chain of trust and a proliferation of intermediaryCAs and digital certiﬁcate resellers, the market in reality is domi-nated by a small number of organisations. In the TLS/SSL marketfor April 2016 for example, just 5 players issued 89% of the certiﬁ-cates – Comodo had 41% of the market, Symantec (including Veri-sign) had 26%, Godaddy had 12% and GlobalSign had just under10%. No other player had more than 1%. Digital certiﬁcates canbe used for a wide range of applications ranging from email toﬁnancial transactions and CAs offer certiﬁcates for speciﬁc uses.Various types of use require different levels of security in regardto owner identiﬁcation and CAs typically offer different classesof certiﬁcate to reﬂect this, ranging from those where minimal check-ing is done on the applicant to those where the applicant mustundergo a rigorous identiﬁcation process. Unfortunately, there isno standardised procedure for these classes and their implementa-tion varies among issuers. Extended Validation (EV) is an enhancedprocedure for validating the owners of websites, developedthrough a voluntary group of certiﬁcation authorities [25]. The need for that improved level of authentication was demonstratedin 2011 when an intruder hacked into the systems of an Italianreseller of Comodo digital certiﬁcate and directly into the systemsof leading Dutch certiﬁcation authority DigiNotar and managed toget digital certiﬁcates that appeared to be issued in the names ofvarious high-proﬁle
2organisations[26]. Comodo identiﬁed the problem with the Italian reseller within hours and were able torevoke the certiﬁcates and notify customers thus minimising dam-age to their own reputation. In the case of DigiNotar, however, thecompany’s systems were found to be so insecure that the root certiﬁ-cate had to be marked as untrusted which in turn invalidated all cer-tiﬁcates issued under the root and, despite the intervention of theDutch government, the company was forced into bankruptcy. Theseattacks, however, were an exempliﬁcation of the adage that any sys-tem is only as secure as the procedures it implements – they did not
2Reputed to include Gmail, Hotmail and Yahoo Mail but that has not beenconﬁrmed.M. Harran et al. / Applied Computing and Informatics 14 (2018) 145–158 147undermine the underlying principle of either RSA or digital certiﬁ-cates. RSA –based digital certiﬁcates remain the main techniquefor digital authentication in use today.
3. Utilising metadata for authenticityA core research question we had was whether ‘‘Is it possible toadd additional data to the existing metadata of a ﬁle in such a waythat the added data that can be used to check the integrity, authen-ticity and provenance of the digital content within the ﬁle?”This necessitated reviewing existing methods of editing andinserting metadata into ﬁles to determine what limitations existand whether existing applications could be adapted to fulﬁl therequirement rather than developing a new software artefact fromscratch. There is limited native support in operating systems formetadata editing. Most Linux distros do not have any native meansof viewing metadata although applications such as ExifTool can beinstalled. The most notable exception is Ubuntu desktop which dis-plays some of the metadata similar to Mac OS X, again uneditable.An example can be seen inFig. 1.Unlike Mac OS X and Linux, Windows Explorer does provide thefacility to edit several tags which have been marked with an aster-isk inFig. 1. Editing in Windows Explorer, however, causes radicalchanges to the structure of the JPEG. There is a wide range of imag-ing processing and management applications that handle editingand inserting metadata to various degrees. The most powerfuland ﬂexible application available is the open source ExifTool byPhil Harvey (available fromwww.sno.phy.queensu.ca/~phil/exif- tool/). It covers a wide range of ﬁle types, executables as well asimage ﬁles and offers extensive functionality for both viewingand editing metadata. It is available both as a Perl library and asa command line application and it is the application of choice forLinux[27]due to the fact that the author has published the codeand invited the open source community to participate in its ongo-ing development.A number of Windows front-ends for ExifTool have been devel-oped such as XnViewMP (available from http://www.xnview.com/ en/xnviewmp/) but these have limited editing facilities. ExifTool isat its most powerful at the command line where it can be used toview and/or edit not only all tags for all known image formats butalso for a wide variety of other ﬁle types including executables.Open source Exiv2 by Andreas Huggel (available from http:// www.exiv2.org/getting-started.html ) is similar to Exif tool but is published as a C++ library and command line utility. It offers verysimilar functionality to ExifTool but does not cover as wide a rangeof ﬁle types.EXIF is supported by many Graphical User Interface (GUI) appli-cations for reading metadata but editing facilities are generallylimited, especially where tags need to be inserted. This authordid ﬁnd a couple of shareware applications for doing so – Exif Pilot(available fromwww.colorpilot.com/exif.html) and Photome (available fromwww.photome.de/) but their functionality is restricted.IPTC/XMP metadata is generally well supported. Due to therelationship between IPTC and Adobe, the latter’s ﬂagship ﬁle man-agement application,Bridge, gives extensive support to IPTC acrossthe full range of Adobe applications - Acrobat, ImageReady, InDe-sign and PhotoShop as well as JPEG and PNG – and is the applica-tion of choice for managing IPTC and XMP. Other applicationssupport IPTC to various degrees; several freeware applicationssuch as IrfanView and XnViewMP offer good view-only functional-ity but Gimp, the main open source alternative to Photoshop, offerssome limited IPTC/XMP editing facilities.There are also some API libraries available such as Windows Imaging Componentin Windows .Net Framework which supportediting and inserting metadata in both JPEG and PNG images.Problems have being found with that library [28]. Apple OS X also has a programmatic way of accessing metadata using Spotlight andthe tagkMDItemalthough detailed study of that was not carriedout.In regard to the proposed software artefact, careful considera-tion was given to using either ExifTool or Exiv2 which are availableas opensource libraries but a unanimous decision was made towrite a new application form scratch. The main reason for thiswas that both applications/libraries were far more wide rangingthan needed for the proposed application and it was difﬁcult to justextract the speciﬁc functionality needed; also, there was the addedcomplexity with ExifTool of having to access a Perl module fromwithin C++. The most decisive factor, however, was that neitherof these libraries would support inserting a digital certiﬁcate. Itwould be easier to add in new code for handling metadata rather
than trying to include 3rd party modules. Both Microsoft Ofﬁceand Adobe Acrobat provide the facility to insert digital certiﬁcatesinto their relative document types and the new 3MF ﬁle type for3D printing has the facility built in. These are all for proprietary ﬁletypes, however, based on XML structures and are not applicable toJPEG, PNG or plain text ﬁles. Despite extensive searching, no off-the-shelf library or application could be found to insert data intoits own section in these ﬁle types. Developers and programmershave sought to add data other than metadata into JPEG ﬁles in par-ticular, sometimes for good reasons such as watermarking imagesand other times for nefarious ones; although an image ﬁle cannotexecute any code, the Zeus banking Trojan used a JPEG ﬁle to dis-guise and distribute a crucial conﬁguration code. Theseapproaches, however, involve changing the image data to addwatermarking or by stenographic techniques using the Least Signif- icant Bit. Also, stenographic techniques are used to hideinforma- tion whereas we would like the inclusion of a digital certiﬁcateto be as visible as possible. There is no native support for editingmetadata in PNG ﬁles in any of the main operating systems (Win-dows, OS X, Linux). A number of applications were tried including
Fig. 1.Metadata edit and view - Windows Explorer.148 M. Harran et al. / Applied Computing and Informatics 14 (2018) 145–158PNGCrush and TweakPNG but the only one that was found to bereally worthwhile was ExifTool.We conclude that a digital certiﬁcate needs to be inserted into aunique ﬁeld due to the risk of it being overwritten by other meta-data editing applications. In effect, that meant that existing appli-cations and libraries were of little use and an application that couldhandle inserting a digital certiﬁcate would have to be developedfrom scratch. That required a more in-depth analysis of the twoimage types selected. Details of that work follow in the nextsection.3.1. JPEGThe ﬁrst two bytes in a JPEG ﬁle are the ﬁle signature with avalue of 0xFFD8. This is known as the Start Of Image (SOI) markerand it is matched at the end of the ﬁle by a two-byte End Of Image(EOI) marker with a value of 0xFFD9. Inside these markers, the ﬁlecontains the encoded image data preceded by a number of seg-ments as shown inFig. 2. All segments are in the form where theﬁrst two bytes have a tag identifying the type of segment andthe next two bytes indicate the length of the segment, excludingthe bytes for the tag but including these two. In the exampleshown inFig. 3, the ﬁrst two bytes – 0xFFD8 - are the JPEG File Sig-nature. Bytes 3 and 4 are the segment tag - 0xFFE1 - and the lengthof the segment is 0xEDF6 bytes. The rest of the segment containsthe segment data. As the length has to be expressed in two bytes,the maximum length of a segment excluding its tag is 64K. Somesegments can, however, occur multiple times which allows thatlimit to be overcome. Although there are a range of deﬁned seg-ment tags, there is nothing to prevent the use of a custom segment.Provided the format is followed, a well behaved application whichdoes not recognise the tag will simply use the stated length tojump to the next segment. The ﬁrst group of segments after theSOI markers hold the metadata for the ﬁle which will be discussedin detail in the next section as this is the primary focus of the soft-ware solution devised.The metadata segments are followed by segments holding datarelevant to the compression algorithm. JPEG is a lossy compressiontechnique which uses quantization and Huffman coding. Depend-ing upon the way the image was created or edited, other segmentsmay be present for parameters such as Restart Interval (DRI). Com-pression information segments are of no direct interest in this pro-ject but the fact that they can be restructured has to be taken intoaccount; for example, inserting an extra metadata ﬁeld in variousapplications may split a single DQT or DHT segment into multiplesegments which collectively hold the exact same information asthe original single segment Even though the contained data hasnot changed, the simple act of splitting it will change the hashvalue for the ﬁle. The encoded image data is not held in a segmentas there is no restriction on its length. The encoded data is assumedto start immediately after the SOS segment and ﬁnish immediatelybefore the EOI marker. It should also be noted that as well as themain image, a JPEG usually contains a thumbnail nested insidethe metadata section which will be stored as separate JPEG withits own SOI, compression information segments, encoded dataand EOI; it will not usually contain any metadata.3.1.1. JPEG metadata segmentsSixteenapplication segmentsare allocated for metadata, referredto as APP0...APP15 using the markers 0xFFE0 to 0xFFEFc [29].A n application segment can be used for any purpose and multipleinstances of a particular segnment can be used within a ﬁle; thespeciﬁc purpose of each segment is indicated by a signature imme-diately following the two bytes stating segment size. Metadadareaders should skip over a segment if they do not recognise thesignature. The most common segments apart from APP0 andAPP1 are:APP2: Originally dedicated to Flashpix tags. Introduced in 1996,the Flashpix format is now obsolete but some of its structuresare included in the EXIF speciﬁcation and may still be encoun-tered in some cameras; also used by Photoshop when editing acamera image.APP13: used by Adobe for Photoshop tags.APP14: used by Adobe for image encoding information relatingto DCT ﬁlters.APP0 must be used for JFIF information where it is included,signed with the ASCII values for the character ‘‘JFIF”. It is used bysoftware applications for compatibility with other applicationsand does not appear in an image straight from camera. It is there-fore of no direct interest to this project except in regard to takingaccount of its possible presence when analysing or processing aﬁle. Strictly speaking, the JFIF and EXIF speciﬁcations are incom-patible because both of the speciﬁcations state that the segmentcontaining their data should be the ﬁrst segment in the JPEG ﬁle.In practice, they coexist without any problems and when a JPEG ﬁleis created in a digital camera and later edited in a software appli-cation, it will typically contain JFIF data in its ﬁrst segment markedas APP0 and EXIF data in its second segment marked as APP1. APP1is used by both EXIF and XMP for metadata and there will be twoAPP1 Segments if the ﬁle contains both EXIF and XMP. The signa-ture for an EXIF segment is the ASCII values for ‘‘Exif” followedby two nulls.Fig. 3shows the EXIF signature highlighted.The signature for an XMP segment is the ASCII values for http://ns.adobe.com/xap/1.0/
nx00; an example is shown inFig. 4. Analy- sis of ﬁles using a hex editor is excessively laborious and tedious sowe developed JPEGReader, an application to view JPEG structuresin a much simpler way. A different version, PNGReader, was alsodeveloped for reading and modifying PNG ﬁles. The followingscreenshots from JPEGReader illustrate the different ways in whichsegments can be used inside a JPEG ﬁle.Fig. 5shows the segments structure for an image ﬁle straightfrom a digital camera. The ﬁle contains a single APP1 segmentholding EXIF data, some of which can be seen in the text values.The markers combo box. JPEGReader also provides some detailsabout the segment such as its start address in the ﬁle and itslength. The APP1 segment is followed by ﬁve segments relatingto the decompression – DQT, DRI, SOF0, DHT and SOS. The startof encoded data is indicated by 0000 () as encoded data is not ina segment and therefore has no segment marker. Fig. 6shows
Fig. 2.JPEG Overall Structure.M. Harran et al. / Applied Computing and Informatics 14 (2018) 145–158 149the structure after adding some metadata through WindowsExplorer. A second APP1 segment has been added to hold XMPdata. The XMP signature can be seen in the values box below themarkers combo box. Windows Explorer has split the DQT data intotwo segments and the DHT data into four segments. There has beenno overall change to the data and despite extensive research, it hasnot been possible to ﬁnd an explanation for why Windows splitsthese segments.Fig. 7shows the structure for the original image with the samemetadata added using Bridge, an Adobe application for image man-agement (but not image processing). Like Windows Explorer,Bridge adds a second APP1 to hold XMP. For some unknown rea-son, it also adds an APP13 segment holding some Photoshop stylemetadata Photoshop related data, even though this particularimage has not been processed in Photoshop and that same infor-mation is already stored in the XMP segment. Unlike WindowsExplorer, the segments containing compression related data areleft as single segments (seeFig. 8).Fig. 7shows the effect of opening the original ﬁle in Photoshopand re-saving it. Although no changes have been made to theimage, it is treated as having been processed by software so anAPP0 segment is added to the start to hold JFIF data. As well asthe second APP1 and the APP13 segments added by the previousexample in Bridge, an additional APP14 segment is added to holdadditional Photoshop data.At this stage of the research, it was clear that application seg-ments offer a great range of ﬂexibility and it seemed that an appli-cation segment could be an ideal place for holding a digital
Fig. 3.EXIF Signature.
Fig. 4.XMP Signature.
Fig. 5.JPEG straight from camera.150 M. Harran et al. / Applied Computing and Informatics 14 (2018) 145–158certiﬁcate. The potential for this was conﬁrmed by a ‘quick anddirty’ test, manually inserting an existing certiﬁcate into the orig-inal image used in the previous examples. The results are showninFig. 9. The digital certiﬁcate has been inserted into an APP1 seg-ment and the text box shows the text to which the digital certiﬁ-cate applies. Initially, it was thought that a less commonapplication segment such as APP8 should be used but it was foundthat anything other than APP1, APP13 or APP14 could, in some cir-cumstances, be deleted by the iOS platform which is the target ofour mobile application. APP1 was found to be generally safe fromoverwriting.3.2. EXIF metadata structureEXIF metadata is always contained in an APP1 segment which isspeciﬁed to be the ﬁrst segment in the ﬁle but can in practice bepreceded by an APP0 segment. The presence of EXIF metadata isindicated by the EXIF signature immediately after the two bytes
Fig. 6.JPEG edited in Windows Explorer.
Fig. 7.JPEG edited in Adobe Bridge.M. Harran et al. / Applied Computing and Informatics 14 (2018) 145–158 151stating the segment size. That signature is the ASCII values for‘‘Exif” followed by two nulls. The EXIF structure is based on theTIFF speciﬁcation and the EXIF signature is immediately followedby an 8-byte TIFF header. An example of a TIFF header is showninFig. 10. The format is as follows (hex values shown in italicsare fromFig. 10) (seeFig. 11).Bytes 0–1:0x4D4D.Byte order within the TIFF segment. Thereare only two legal values – 0x4949 (‘‘II”) indicating little endianand 0x4D4D (‘‘MM”) indicating big endian. The letters ‘‘I” and‘‘M” are from Intel and Motorola, the two dominant chipset manu-facturers at the time TIFF was developed; Intel used a little endianarchitecture and Motorola a big endian one. TIFF endianness variesamong camera manufacturers – Canon uses little endian, Pentaxuse big endian – and among mobile phone manufacturers - Sam-sung uses little endian while Apple use big endian. Byte 0 alsohas an important role for the calculation of offsets; TIFF makesextensive use of these offsets and they are all calculated from theaddress of byte 0.Bytes 2–3:0x002A.An arbitrary but carefully chosen number(42) that further identiﬁes the ﬁle as a TIFF. Effectively, the ﬁrsttwo endianness bytes along with these two give TIFF a uniquesignature.Bytes 4–7:0x0000000A.The offset (in bytes) of the ﬁrst ImageFile Directory (IFD) which holds information about the image aswell as pointers to the actual image data. The value 0x0000000Ain this case added to the start address of the TIFF header –0x000C – tells us that the ﬁrst Image File Directory starts at0x0016.An Image File Directory has a structure where the ﬁrst twobytes state the number of ﬁelds that the IFD contains. The ﬁnal 4bytes of the IFD give the offset to the next IFD from the start ofthe TIFF header; they are set to zero if this is the ﬁnal IFD.
Fig. 8.JPEG edited in Adobe Photoshop.
Fig. 9.JPEG ﬁle with certiﬁcate inserted.152 M. Harran et al. / Applied Computing and Informatics 14 (2018) 145–158Fig. 12shows the physical ﬁle layout for a range of devicesincluding three digital cameras from leading manufacturers, aniPhone, a Windows Phone, and two Android Phones - one highend and one low end. Several things are worth noting in Fig. 12.I. The sequence of IFDs varies between devices; Pentax andCanon, for example put Interop IFD before IFD1 which comeslast in the sequence but Nikon put the Interop IFD last.II. A number of the devices do not include an Interop IFD at alleven though this is mandated in the DCF which they are allsupposed to follow. The default values for the Interops tags,however, are ‘‘R98” in the ﬁrst tag which is a reference to the1998 DCF that ﬁrst introduced the Interops IFD and Version1.0 in the second tag. Closer analysis showed that all thedevices that include the IDF have those default values;whilst documentation of this could not be found, it seemsreasonable to conclude that devices that do not speciﬁcallyinclude the IFD work are in fact using those defaults.III. Although all the devices have chosen to place values for eachIFD immediately following the IFD, that is not strictly neces-sary as will be seen later when editing metadata isdiscussed.3.3. Metadata tagsIFD0 tags are not included as there are 231 of them but only ahandful are generally used in JPEG. Although there are no rulesin the EXIF speciﬁcation about the order of IFDs, all tags insidean IFD must be in numerical order. The ﬁrst 10 tags shown(F0...F9) are generally used in IFD0 as well as the Exif and GPS tagswhich can be seen at the bottom of the list of tags in this. There are4 tags identiﬁed as unknown. No documentation could be foundfor those tags, they are not listed in the TIFF or EXIF speciﬁcationsand their values are all set to zero, so they appear to be privateones added by Huawei but either not used or reserved for futureuse. Hauwei, however, appear to have broken TIFF rules here –all private tags used in a TIFF IFD are mandated to use id markersabove 0x8000[30]as can be seen, for example, with the Exif andGPS private tags. Examples of EXIF and GPS tags in the same ﬁleare shown inFig. 13.There are over 30 GPS tags available; Latitude, Longitude andAltitude tags are ubiquitous; other GPS tags vary between devices.IFD1 holds the image thumbnail and can, in theory, contain anyTIFF tags i.e. the same as IDF0. In practice, however, only the tagsinFig. 14are generally used. The tags for ThumbnailOffset(0x0201) and ThumbnailLength (0x0201) are used only in IFD1,having been deprecated for IFD0 where the image data is takento start immediately after the SOS segment and run to the end ofthe ﬁle, ending with 0xFFD9. The tag MakerNote (0x927C) is storedinside the EXIF IFD and is another tag that is used to point to datastored in an IFD type structure. It is intended for free use by thecamera or device manufacturer and generally contains extendeddata about the camera, the lens and the various settings for whenthe image was captured. Not all manufacturers use MakerNote,Hauwei for instance do not and there are major inconsistenciesamong manufacturers who do include it. First of all, manufacturersuse different lengths for the initial string of bytes that usually actas a signature for the manufacturer. Secondly, whilst the actualmetadata is stored in an IFD structure, some manufacturers includean internal TIFF header and this becomes the reference point forcalculating offsets to the tag values. Other manufacturers calculateoffsets relevant to the TIFF header at the start of the APP1 segment;that means that if the tag values get moved (see next section) thenthe offsets have to be all recalculated or they will be wrong. Inpractice, that recalculation is made extremely difﬁcult if notimpossible due to very little if any information about MakerNote
Fig. 10.TIFF Signature.
Fig. 11.Image File Directory.M. Harran et al. / Applied Computing and Informatics 14 (2018) 145–158 153being published by the manufacturers; most of the informationthat is available has come from reverse engineering by researcherslike Phil Harvey, developer of ExifTool [31]which reads and writes metadata for a vast range of ﬁle formats, executables as well asimage, audio and video ﬁles. His website provides the most com-prehensive list available of information relating to metadata acrossthese formats including all known JPEG, TIFF and EXIF tags [32]. Leading camera manufacturer Canon includes over 80 tags inMakerNote identiﬁed by ExifTool.4. EvaluationChanges in metadata do not necessarily affect the integrity ofa ﬁle if the core data of the ﬁle is not changed. This is no differ-ent from paper documents where notations added to a documentdo not affect the validity of the document. If a person receives animage ﬁle from someone else and, for example, adds a tag to helpﬁnd it afterwards then that should not affect the integrity of theactual image. That principle should equally apply to metadatachanges arising from the transfer of a ﬁle between devices oroperating systems which should not be invalidated so long asthe image data is not altered. This should also apply to the com-pression segments in a JPEG ﬁle which essentially are metadataabout the compression used; for example, if a single DHT seg-ment is split into four that should not affect the validity of theﬁle again as long as the encoded image data is not affected.We propose that the primary ﬁngerprint for a JPEG ﬁle shouldbe the hash value for the encoded image data. This is analogousFig. 12.JPEG ﬁle layout for different devices.
Fig. 13.Tags in EXIF IFD.154 M. Harran et al. / Applied Computing and Informatics 14 (2018) 145–158to the approach taken by Microsoft Word and Adobe Acrobatwhich concatenate a digital signature with the document towhich it relates and, when the document is being veriﬁed, thedigital certiﬁcate is ignored for computing the hash value ofthe document.We also retain three ﬁngerprints - metadata, compression andimage data which we developed in JPEGReader as it will allow usto build into its visibility approach a green/amber/red symbolismwhere green means a ﬁle has been unaltered since the digital cer-tiﬁcate was issued, amber means that metadata or compressionhas been altered but the core image data is not changed so the dig-ital certiﬁcate is still valid and red means that the digital certiﬁcateis no longer valid as the core image data has been altered. A keyrequirement is the ability to insert additional data as well as a dig-ital certiﬁcate. For example, the comment metadata ﬁeld shouldhold a URL to a website where a user can check the validity of a ﬁlewithout having third party software installed by users. We alsoincorporate automatic copyright stamping. In order to retain max-imum ﬂexibility, Title, Author, Copyright and Comments are enu-merated ﬁelds within our software but additional ﬁelds could beinserted by supplying the appropriate tag index along with thevalues.Changes can take place in metadata either deliberately by auser or inadvertently as a result of moving the ﬁle betweendevices and operating systems. It would therefore be safest toinsert and digital certiﬁcate into its own application segment.iOS has intolerance for application segments other than APP1,APP13 and APP 14 in images received by email. Like other appli-cations, however, it does allow multiple instance of APP1. It wastherefore decided to use an APP1 segment to hold the digital cer-tiﬁcate. This APP1 would be distinguished from other APP1s by itsown signature. An example of a JPEG with a digital certiﬁcateinserted is shown inFig. 15. The ﬁrst APP1 is selected on the leftand the EXIF ﬁelds can be seen in the values; the second APP1 isselected on the right and the signature can be seen in the valuesalong with the initial part of the certiﬁcate. The overall algorith-mic approach for creating a ﬁle with references and a digital cer-tiﬁcate inserted can be summarised as:Overall ProcessExternalApplicationThisLibrary 1 Open ﬁle X2 Get reference X3 Insert reference & accompanyingdata into metadata X4 Calculate SHA256 hash value formetadata segments. X5 Calculate SHA256 hash value forcompression segments X6 Calculate SHA256 hash value forimage data. X7 Return hash values as pointer toarray of pointers. X8 Return hash values to owner X9 Get digital certiﬁcate X10 Insert digital certiﬁcate into ownsegment. X11 Return ﬁle as pointer to new datastream. X12 Save and close ﬁle. X
The corresponding process to verify a ﬁle is straightforward:
1 Extract digital certiﬁcate from ﬁle.2 Read hash values from digital certiﬁcate.3 Compute hash values for each section of the ﬁle - metadata seg-ments, compression segments and encoded image data.4 Compare computed hash values to the values extracted fromthe digital certiﬁcate and report as appropriate:0 = the ﬁle has been unaltered since the digital certiﬁcate wasissued.1 = the metadata or compression has been altered but the coreimage data is not changed so the digital certiﬁcate is still valid.2 = the digital certiﬁcate is no longer valid as the core imagedata has been altered
Fig. 14.Tags in IFD1.M. Harran et al. / Applied Computing and Informatics 14 (2018) 145–158 155We developed JPEGReader and PNGReader to assist in the anal-ysis of image ﬁles. These were developed in C# using MicrosoftVisual Studio. In order to keep the header ﬁle uncluttered, the codewas written used thePimpl Idiom, also known as theCheshire Cator Opaque Pointerwhich is a method of avoiding the forward declara-tion of all private variables and methods in a C++ header ﬁle [33]. Our documented code is available at http://www.api.masters.mar- tinharran.com. Our work shows that it is possible to insert a digitalcertiﬁcate into a JPEG ﬁle and to edit the EXIF metadata ﬁelds toshow references to a certiﬁcate. These would be visible in nativeapplications such as Windows Explorer and OS X Inspector as wellas third party image viewers and editors.Independent testing was carried out by Georgia Tech out on theoriginal Digiprove process.
3The procedure used by Georgia Techwas replicated for the process developed in this project:
Step 1: For selected ﬁle samples, hash values were pre-calculated using the same encryption used by us (software usedwas sha256deep from md5deep version 3.4).Step 2: Each ﬁle was then put through our content signing pro-cess to generate a digitally-signed content certiﬁcate.Step 3: A 3rd party digital signature veriﬁcation utility (Certiﬁ-cates, Microsoft Corporation, Version: 5.1.2600.0) was used toverify the integrity of the signature using our public X.509 dig-ital identity certiﬁcate (issued by VeriSign).Test metadata was inserted into an image ﬁle (baby.jpg) usingthe Photoprove writer library. The SHA256 value for this ﬁle wascalculated using sha256deep from md5deep v4.3. The result: c7a0a355a9b5926f7c332807e4ca380e378e20aee652a1f6d066276aab6324fe was then put through a content signing process whichyielded the same SHA256 value as Step 1. The resulting PS7 ﬁleproduced and emailed was inserted into an APP1 using the Photo-prove writer library. In order to conﬁrm persistence, the ﬁle wascopied across devices and operating systems in a similar processto that used earlier for testing persistence across operating systemsi.e. Windows via USB to Linux via DropBox to OS X via iCloud toiPhone via Windows Explorer to Windows 10 (baby _ﬁnal.jpg). Ahex editor – HxD – was then used to manually strip the digital cer-tiﬁcate back out of the ﬁnal ﬁle and save it as a PS7 ﬁle (CertEx-tracted.p7s) and the JPEG minus the stripped APP1 was resaved(baby_ﬁnal_cert_extracted.jpg). This allowed the processed ﬁle tobe verifoied against the extracted digital certiﬁcate. SHA256 wasrecalculated for the stripped ﬁle and was identical. The PS7 ﬁleextracted at Step 2 was opened in PS7Viewer, which veriﬁed thedigital signature. P7S viewer also has the facility to open the orig-inal unsigned text to which the digital signature applies; this isshown inFig. 16where the ﬁle ﬁngerprint can be seen (line 10)along with the date/time stamp and other information inserted.Again, that ﬁngerprint matches the one calculated in Step 2 usingsha256Deep.We next checked the effect of sending the ﬁle with the insertedcertiﬁcate to an iPhone by email and comparing the original withthe image saved by the iPhone. As it was already known fromthe previous testing that the iPhone would change the metadataby creating a new thumbnail, there was no point in comparingthe overall hash value butFig. 17shows that the second APP1 hold-ing the digital certiﬁcate has remained intact and Fig. 18shows that only the hash value for the metadata section has changed,the compression segments and image data are unchanged.
Fig. 15.Digital certiﬁcate in an APP1.
Fig. 16.Testing - view original text.
3Report for process evaluation & penetration testing service (D9507) Submitted by: Mayur Ramgir, Georgia Tech Ireland, Athlone Business & Technology Park, Gar-rycastle, Dublin Road, Athlone mayur.ramgir@gtri.gatech.edu.156 M. Harran et al. / Applied Computing and Informatics 14 (2018) 145–1585. ConclusionWe demonstrate that a digital certiﬁcate relating to an imageﬁle can be inserted inside that image ﬁle along with accompanyingmetadata containing references to the issuing company. Notwith-standing variations between devices and across operating systemsand applications, a JPEG ﬁle holds its structure very well. Wherechanges do take place, this is generally in the metadata area anddoes not affect the encoded image data which is the heart of theﬁle and the part that needs to be veriﬁable. References to the issu-ing company can be inserted into the metadata for the ﬁle. There isan advantage of having the digital certiﬁcate as an integral part ofthe ﬁle to which it applies and consequently travelling with theﬁle. We ultimately prove that the metadata within a ﬁle offersthe potential to include data that can be used to prove integrity,authenticity and provenance of the digital content within the ﬁle.Our research has also uncovered a wide range of previouslyunknown aspects of how metadata gets handled by various operat-ing systems, devices and image management applications. This isknowledge that could be valuable to others working in the ﬁeld.An unanticipated beneﬁt of the work has been the software toolsdeveloped for examining and analysing image ﬁles. Those toolshave already attracted the interest of the wider forensics commu-nity. Due to their massive popularity, image ﬁles, especially JPEG,offer high high potential as carriers of other information. Muchof the work to date on this has focused on stenographic ways ofhiding information using least signiﬁcant bit techniques but webelieve that the ﬁndings in this project have exposed other waysof doing this. If a digital certiﬁcate can be inserted into a JPEG, socould the payload for a virus or a communication between criminalor terrorist organisations.Appendix A. Supplementary materialSupplementary data associated with this article can be found, inthe online version, athttp://dx.doi.org/10.1016/j.aci.2017.05.006 .References
[1] F. Buccafurri, L. Fotia, G. Lax, Allowing privacy-preserving analysis of socialnetwork likes, in: Eleventh Annual International Conference On Privacy,Security And Trust, Pst 2013, Eleventh Annual International Conference onPrivacy, Security and Trust, PST 2013, IEEE Computer Society, Tarragona(Spain) (USA), 2013.[2] F. Buccafurri, L. Fotia, G. Lax, Allowing Non-identifying Information Disclosurein Citizen Opinion Evaluation, Egovis/edem 2013, August 26–28, 2013, in:Proceedings of International Conference on Electronic Government and theInformation Systems Perspective and International Conference on ElectronicDemocracy (EGOVIS and EDEM 2013), Springer Verlag, Prague, Czech Republic(DEU), 2013, pp. 241–254.[3]
K.N. Sowmya, H.R. Chennamma, Video authentication using watermark anddigital signature—a study, in: S. Satapathy, V. Prasad, B. Rani, S. Udgata, K.Raju (Eds.), Proceedings of the First International Conference on ComputationalIntelligence and Informatics Advances in Intelligent Systems and Computing,vol. 507, Springer, Singapore, 2017
. [4] F. Buccafurri, L. Fotia, G. Lax, Allowing Continuous Evaluation of CitizenOpinions Through Social Networks. International Conference on ElectronicGovernment and The Information Systems Perspective and Intern, in:
Fig. 17.Testing email to iPhone - Digital Certiﬁcate.
Fig. 18.Testing email - hash values.M. Harran et al. / Applied Computing and Informatics 14 (2018) 145–158 157Proceedings of International Conference on Electronic Government and theInformation Systems Perspective and International Conference on ElectronicDemocracy (EGOVIS and EDEM 2012), Springer Verlag, Vienna (DEU), 2012.[5] F. Buccafurri, L. Fotia, G. Lax, Privacy-Preserving Resource Evaluation in SocialNetworks, Tenth Annual Conference on Privacy, Security and Trust (pst 2012),in: Proceedings of the Tenth Annual Conference on Privacy, Security and Trust,IEEE Computer Society, Paris (USA), 2012, pp. 51–58.[6] Y. Ye, K. Xie, Q. Zeng, A study on DITA in digital publishing, in: Proc. SPIE10322, Seventh International Conference on Electronics and InformationEngineering, 103224N (January 23, 2017); http://dx.doi.org/10.1117/12. 2265276.[7] C. Kinsella, Establishing Proof of Existence and Possession of Digital Content,Irish Patent Ofﬁce 84803, 2008. < https://eregister.patentsofﬁce.ie/ HttpHandler/Handler.ashx?HandlerType=PDF&DocumentType=PT&DocumentId=22647205>.[8] Microsoft Ofﬁce Support. Digital Signatures and Certiﬁcates, Ofﬁce Support,2016. <https://support.ofﬁce.com/en-us/article/Digital-signatures-and-certiﬁcates-8186cd15-e7ac-4a16-8597-22bd163e8e96 >. [9]P. Christof, P. Jan, Understanding Cryptography: A Textbook for Students andPractitioners, Springer, Berlin, Heidelberg, 2010
. [10]
A.J. Menezes, P.C. Van Oorschot, S.A. Vanstone, Handbook of AppliedCryptography, CRC Press, 1996
. [11]
P. Rogaway, T. Shrimpton, Cryptographic hash-function basics: deﬁnitions,implications, and separations for preimage resistance, second-preimageresistance, and collision resistance, Fast Software Encryption (2004) 371–388 (Springer)
.[12] R. Rivest, RFC 1321: The MD5 message-digest algorithm, April 1992’, Status:INFORMATIONAl, 1992.[13]
H. Dobbertin, The status of MD5 after a recent attack, CryptoBytes 2 (2) (1996) . [14] X. Wang, Y.L. Yin, H. Yu, Finding collisions in the full SHA-1, in: Advances inCryptology–CRYPTO 2005, Springer, 2005, pp. 17–36.[15] A. Sotirov, M. Stevens, J. Appelbaum, A.K. Lenstra, D. Molnar, D.A. Osvik, B. deWeger, MD5 considered harmful today, creating a rogue CA certiﬁcate’, in:25th Annual Chaos Communication Congress, 2008.[16] C.R. Dougherty, Vulnerability Note VU# 836068 MD5 Vulnerable To CollisionAttacks’, 2008. <https://www.kb.cert.org/vuls/id/836068 >. [17] Swiat. Flame Malware Collision Attack Explained, Microsoft Technet, 2012.Available: <https://blogs.technet.microsoft.com/srd/2012/06/06/ﬂame-malware-collision-attack-explained/ >. [18]
R.L. Rivest, A. Shamir, L. Adleman, A method for obtaining digital signaturesand public-key cryptosystems, Commun. ACM 21 (2) (1978) 120–126
.[19] NIST. ‘Secure Hash Standard (SHS)’, FIPS PUB 180-1, 1995. Available: < http:// www.umich.edu/~x509/ssleay/ﬁp180/ﬁp180-1.htm >. [20] S. Gueron, S. Johnson, J. Walker, SHA-512/256, Information Technology: NewGenerations (ITNG), in: 2011 Eighth International Conference on, IEEE, 2011,pp. 354–358.[21] X. Wang, D. Feng, X. Lai, H. Yu, Collisions for Hash Functions MD4, MD5,HAVAL-128 and RIPEMD, IACR Cryptology ePrint Archive, 2004, 199.[22] NIST, ‘Secure Hash Standard (SHS)’, FIPS PUB 180-2, 2002. Available: < http:// csrc.nist.gov/publications/ﬁps/ﬁps180-2/ﬁps180-2.pdf >. [23] NIST. ‘SHA3 Standard: Permutation-based hash and extendable-outputfunctions’, FIPS PUB 202, 2015. Available: < http://nvlpubs.nist.gov/nistpubs/ FIPS/NIST.FIPS.202.pdf>.[24] NIST, NIST’S POLICY ON HASH FUNCTIONS, National Institute of Standards andTechnology, 2016. Available: < http://csrc.nist.gov/groups/ST/hash/policy. html>.[25]W. Difﬁe, M.E. Hellman, New directions in cryptography, IEEE Trans. Inform.Theory 22 (6) (1976) 644–654
. [26]
N. Leavitt, Internet security under attack: the undermining of digitalcertiﬁcates, Computer 44 (12) (2011) 17–20
. [27] M. Fioretti, How to Add Metadata to Digital Pictures from the Command Line,Linux.com, 2008. Available: < https://www.linux.com/news/how-add- metadata-digital-pictures-command-line >. [28] J.S. Moreland, Dream.In.Code -> Updating Jpeg Metadata Wthout Loss ofQuality [online], Dream In Code, 2010. Available: < http://www.dreamincode. net/forums/blog/1017/entry-2305-updating-jpeg-metadata-wthout-loss-of-quality/>.[29] P. Harvey, JPEG Tags, ExifTool, 2016. < http://www.sno.phy.queensu.ca/ ~phil/ exiftool/TagNames/JPEG.html >. [30] IPTC, Embedded Metadata Initiative - Manifesto [online], Embedded MetadataInitiative, 2016. <http://www.embeddedmetadata.org/embedded-metatdata-manifesto.php>.[31] P. Harvey, ExifTool by Phil Harvey, ExifTool, 2016. Available: < http://www. sno.phy.queensu.ca/~phil/exiftool/>. [32] P. Harvey, ExifTool Tag Names, ExifTool, 2016. < http://www.sno.phy.queensu. ca/~phil/exiftool/TagNames/index.html >. [33] Z. Miners, Facebook, Twitter Called out for Deleting Photo Metadata [online],Network World, 2013. Available: < http://www.networkworld.com/article/ 2164374/software/facebook–twitter-called-out-for-deleting-photo-metadata.html>.158 M. Harran et al. / Applied Computing and Informatics 14 (2018) 145–158