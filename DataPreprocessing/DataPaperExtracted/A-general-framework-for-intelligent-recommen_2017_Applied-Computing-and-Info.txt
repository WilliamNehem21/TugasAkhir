ORIGINAL ARTICLE
A general framework for intelligent recommendersystems
Jose Aguilara,*, Priscila Valdiviezo-Dı´azb, Guido Riofriob
aCEMISID, Departamento de Computacio´n, Universidad de Los Andes, Me´rida, Venezuela Prometeo Researcher, UTPL, Loja, Ecuador
bDepto. de Ciencias de la Computacio´n y Electro´nica, Universidad Te´cnica Particular de Loja, EcuadorReceived 20 April 2016; revised 29 July 2016; accepted 25 August 2016Available online 21 September 2016
KEYWORDSRecommender system;Cognitive maps AbstractIn this paper, we propose a general framework for an intelligent recommender systemthat extends the concept of a knowledge-based recommender system. The intelligent recommendersystem exploits knowledge, learns, discovers new information, infers preferences and criticisms,among other things. For that, the framework of an intelligent recommender system is deﬁned bythe following components: knowledge representation paradigm, learning methods, and reasoningmechanisms. Additionally, it has ﬁve knowledge models about the different aspects that we can con-sider during a recommendation: users, items, domain, context and criticisms. The mix of the com-ponents exploits the knowledge, updates it and infers, among other things. In this work, weimplement one intelligent recommender system based on this framework, using Fuzzy CognitiveMaps (FCMs). Next, we test the performance of the intelligent recommender system with special-ized criteria linked to the utilization of the knowledge in order to test the versatility and perfor-mance of the framework.
/C2112016 The Authors. Production and hosting by Elsevier B.V. on behalf of King Saud University. This isan open access article under the CC BY-NC-ND license ( http://creativecommons.org/licenses/by-nc-nd/4.0/ ).
1. IntroductionThe main goal of the Recommender Systems (RS) was to helpusers in their decision making. This area proposes the develop-ment of RS to provide high-quality recommendations in differ-ent contexts. In general, a recommender system is softwarewhich provides suggestions of items for users [15]. Various techniques for recommendation have been proposed. Fromthe domains such as artiﬁcial intelligence, data and semanticmining, information retrieval, approaches of RS haveemerged. The RS traditionally have been classiﬁed ascontent-based, collaborative, knowledge-based, and hybrid.A knowledge-based recommender system only exploits theknowledge naively. We argue that a recommender systemhas an intelligent behavior if it has the next set of capabilities:knowledge representation, learning capabilities, and reasoningmechanisms. The mix of these capabilities can exploit largelyknowledge, update them, and infer them, among other things.Based on these ideas, in this paper we propose a new type ofrecommender system, called Intelligent Recommender System
*Corresponding author.E-mail address:aguilar@ula.ve(J. Aguilar).Peer review under responsibility of King Saud University.
Production and hosting by ElsevierApplied Computing and Informatics (2017) 13, 147–160
Saudi Computer Society, King Saud University
Applied Computing and Informatics
(http://computer.org.sa)www.ksu.edu.sawww.sciencedirect.com
http://dx.doi.org/10.1016/j.aci.2016.08.0022210-8327/C2112016 The Authors. Production and hosting by Elsevier B.V. on behalf of King Saud University.This is an open access article under the CC BY-NC-ND license ( http://creativecommons.org/licenses/by-nc-nd/4.0/ ).(IRS), which is an extension of the knowledge-based RS. TheIRS considers learning algorithms, knowledge representationmechanisms, and reasoning motors, among other aspects. Inthis paper, we deﬁne an IRS, and describe its components,and the relationships among them, among other things.An IRS can use any intelligent technique (fuzzy logic, onto-logical approaches, etc.) for its implementation. Additionally,we give an example of its application using the FCMs. TheFCMs have been used in different domains [1–3]. The FCMs are based on the Cognitive Maps (CMs) theory, to model sys-tems based on concepts that describe the main characteristicsof the modeled system (variables or states of the system),and the causal relationships between them. FCMs are basedon the fuzzy logic theory to deﬁne their structure and theirinference process from a given data input. FCMs have beenapplied to diverse ﬁeld such as supporting group-decision,political analysis[2].In the following section we present some backgroundsabout the RS. Section3presents the theoretical bases of ourapproach and then Section4presents the IRS framework. Sec-tion5presents details of the description of the knowledgemodels of the IRS. Section6presents the implementation ofIRS using FCMs. Lastly, the next sections present a casestudy, the utilization of IRS based on FCMs, the experiments,and the analysis of the results.2. Literature reviewIn the literature, there are a lot of papers about RS. In this sec-tion we present some works, speciﬁcally knowledge-based RSor based on intelligent techniques. In[4]the Team Recom-mender Systems (TRS) is presented, which is a knowledge-based RS that helps organizations deﬁne the team needed tocarry out a task requiring multiple skills. TRS solves twoimportant problems. First, it manages semantic heterogeneitythat occurs when the data describing the same entities are rep-resented in different ways. It manages specialization excess ofthe objects of highest similarity with the user, leaving out con-sideration of irrelevant information. Additionally, theydevelop an ontology used to handle the semantic heterogeneityproblem. In[5,6]an overview of knowledge-based RS in differ-ent domains, such as restaurants, movies is presented. Addi-tionally, they discuss the strengths and weaknesses ofknowledge-based and collaborative-ﬁltering RS, and introducea hybrid RS that combines the two approaches. In theirapproach, the knowledge-based RS is the bootstrap of the col-laborative ﬁltering engine while the data spool is small, and thecollaborative ﬁlter is the post-ﬁlter of the knowledge-based RS.In[9]a work to deﬁne the proﬁle of the customers is pre-sented. Additionally, algorithms for generating personalizedbuying proposals, based on the collaborative, content-basedﬁltering, and knowledge-based approaches are presented.The proﬁle is created from the user’s nature, and evolvesaccording to the events observed. Also, they present someideas about RS based on the social web and on the consumerbuying behavior theory. In[10]a recommendation system ofacademic papers is deﬁned. The paper proposes user situationawareness and a recommendation system based on fuzzy clus-tering analysis and fuzzy cognitive maps. They use fuzzy clus-tering analysis to describe the correlation between lexicalsemantics, and FCM to deﬁne the qualitative distribution ofuser interests. The fuzzy clustering analysis introduces the viewof the information entropy theory. It carries out a quantitativedescription of the information in the database, and generates atree data structure based on this, which is converted into a netdata structure used by a FCM for the recommendations. Theyverify the validity of the algorithm to recommend sites of aca-demic theses. In[12]a recommender system based on fuzzylogic is proposed. This recommender system mines informa-tion, in order to provide recommendations to potential buyersabout products based on their personal needs. This personal-ized recommender system driven by fuzzy logic techniquemines information about the features of laptop computers,and provides services to potential buyers by recommendingoptimal products based on their personal needs. They usethe Fuzzy Near Compactness concept to measure the similaritybetween consumer needs and product features. In [13]a Fuzzy linguistic approach to represent the user ratings, and a FuzzyMulticriteria Decision Making approach, are used to rankthe relevant items to a user. Their system handles the uncer-tainty and fuzziness of human decision making behavior.For that their model of the user ratings considers the subjec-tive, imprecise and vague nature of the user’s perceptionsand opinions, using fuzzy set paradigm. They test theirapproach in a Music Recommender system.In[17]an ontological approach to recommend on-line aca-demic research papers is explored. Research papers are classi-ﬁed using ontology. Recommendation algorithms are used torecommend papers seen by similar people. They create userproﬁles representing the proﬁles based on ontology of researchissues. Additionally, they use a proﬁle visualization approach,in order to acquire proﬁle feedback. The ontological inferenceimproves the user proﬁling, and external ontological knowl-edge is used to bootstrap the recommender system. In [18] an E-Learning RS is presented, based on the use of web miningtechniques, to build an agent that can recommend online learn-ing activities or course Web sites, based on the learners’ accesshistory, to assist the online learning process. These techniquesare integrated on the RS platform. Additionally, they present aSurvey about E-Learning RS in the literature. In [19]it is pre- sented a fuzzy-based recommender system for stimulatingpolitical participation and collaboration. The recommendation
engine is based on a modiﬁed fuzzy c-means algorithm, and theSammon mapping technique is used for visualizing recommen-dations. Additionally, they develop a framework for ePartici-pation, which allows to analyze different projects and theirdevelopment, in order to evaluate the citizens’ participationand empowerment. In[20]it is explored the role of cognitivedecision effort in RS, using indicators about ‘‘informationquality”and ‘‘service quality”, to examine the performanceof the RS according to the user opinion, in a internet bookstore. They conclude that the information quality of the RShas inﬂuence in the consumer shopping decision-making pro-cess, and that the e-commerce platform provides recommenda-tions and information necessary, but, the recommendationsystem has not signiﬁcant inﬂuence in the decision-makingeffort during the process of consumer’s shopping decision-making.In[21]it is determined that collaborative ﬁlter-based RScan be improved by incorporating side information, such asnatural language reviews. Additionally, they introduce a modelof reviews based on the recurrent neural network, and study itseffects on collaborative ﬁltering performance. The recurrent148 J. Aguilar et al.neural network has the ability to act as a regularizer of the itemrepresentations to be recommended. In[22]a personalized rec-ommendation system is introduced based on accurate modelswhich capture the user preferences. They propose a picture-based approach: they use a set of travel related picturesselected by a user, and an individual travel proﬁle is deduced.This is accomplished by mapping those pictures onto sevenbasic factors, which reﬂect different travel aspects. This modelconstitutes the basis of their recommendation algorithm. In[23]a semantic recommendation approach of pedagogicalresources is proposed within a learning ecosystem. Thisapproach is based on a voting system, where each memberof the ecosystem evaluates the pedagogical resources foundin his/her sharing space. In this way, they deﬁne a coherentlearning ecosystem that promotes collaborative learning,which allows exchanging and sharing knowledge and/or skills.Finally,[15]is a book which present trends, concepts, method-ologies, challenges and applications on RS. This bookdescribes the classical methods, as well as novel approachessuch as Context-Aware RS and RS in the social web.3. Recommender systemsRS are techniques used to provide suggestions of items to theuser[15]. Formally, a recommendation problem can be deﬁnedby a utility function ‘‘rec”, which predicts the utility of an itemi of a set of items I, for a speciﬁc user u of a set of users U. Rec is a functionR U/C2I. whereRis in the interval [0,1], and itis the utility score of the recommended item. Recdenotes the item’s capability to satisfy the needs of the users. In thisway, the prediction task of a recommender system is to deﬁnethis utility score for a given user and item. In general, the dataand knowledge available for RS can be very diverse [15]:/C15Itemsare the objects to recommend. They are deﬁned bytheir complexity and their utility. The complexity of an itemis deﬁned by its structure, representation, and dependenceof other items. Normally, RS recommend one speciﬁc typeof item (movies, music, etc.)./C15Usersof RS are very diverse with respect to their interests,goals, etc. RS personalize the recommendations with theinformation about the users. This information can be orga-nized in different ways, and the recommendation techniqueused deﬁnes the information in the user model./C15Transactionsdeﬁne the interaction between the users andthe RS. Transactions are the data generated during thehuman-RS interaction. The types of information used forthe recommendation generation techniques are very differ-ent, for example, the item selected by the user, the descrip-tion of the context of the query. Also, the transaction caninclude an explicit feedback of the user. Normally it iscalled criticity such as its rating of an item.Various recommendation techniques have been proposed inthe literature[9,15](seeTable 1).The concept of critiquing is very important in our frame-work. It is based on the idea that users specify their requestsas goals not satisﬁed by the recommended ongoing item [9]. Critiquing-based RS articulates preferences without forcingusers to specify concrete values for item properties. The majorsteps of a critiquing-based RS are[9]:–Item recommendation.This step selects a set of itemsrto be presented to the user. In the ﬁrst critiquing cycle, theselected items are based on a user query q(similarity between the requirements and the candidate items).–Item reviewing.In this step the user reviews the recom-mended item, in order to accept the recommendation orselect a critique, which restart a new critiquing cycle. If acritique has been chosen, only the items that fulﬁll the cri-teria deﬁned in the critique are further taken into account(it reduces the candidate item set).Our IRS extends the ideas behind the classical RS with thisconcept[5,6], because it tries to understand users, discover
their interests, etc., through the creation of knowledge, reason-ing, etc. During this process, we use the notions of ‘‘unit cri-tique”and ‘‘compound critiques”. Unit critique operates
Table 1Taxonomy of RS.
Type DescriptionContent-based recommendationapproach In this approach, the RS recommend items, which are similar to the ones that the user chosen in thepast. The similarity is computed according to the characteristics associated with the compared items Collaborative recommendation approach This approach uses the opinions of users’ community, or the information about the past behavior, to predict the items the user will be interested Demographic recommendation approach It recommends items according to the demographic proﬁle of the user. The idea is that each demographic niche has diﬀerent recommendation needs Utility-based or knowledge-basedrecommendation approach This approach recommends items on the basis of the knowledge about how the item characteristicsmeet the needs and preferences of the users. There are two cases: case-based where the system usesthe knowledge, about both the user and the items, to carry out recommendations based onsimilarity metrics. Constraint-based recommenders use knowledge bases with set ofrecommendation rules about how to map user requirements with item characteristics Community-based recommendationapproach This approach is based on the idea that people have more conﬁdence in recommendations fromtheir friends than from anonymous individuals. The popularity of social networks has generatedinterest in these RS Hybrid approach This approach is the combination of the previous techniques, in order to use the advantages of each one. The combination of the diﬀerent techniques generates better or more preciserecommendations, and exploits better the current informationIntelligent recommender systems 149over one speciﬁc property of an item. It deﬁnes the changerequests of a single item property. For example a unit critiquein a PC IRS can infer that the user is interested in a PC withmore memory than the normally recommended PC; ‘‘morememory”is a critique over the memory feature. There are cri-tiques that operate over multiple properties, called compoundcritiques. For example a compound critique in our IRS for thePC domain can infer lower price, faster CPU, and more mem-ory. The compound critiques are very important because theyreduce the number of critiquing cycles and allow a faster nav-igation into the item space.4. A framework for an intelligent recommender systemIn this section, we deﬁne the main components of our IRS. Thedifference with respect to a knowledge-based recommendationapproach is that in an IRS there are four main elements. Thefour main elements are/C15A knowledge acquisition mechanism based on learningalgorithms./C15A knowledge explicit modeling, which represents all theknowledge necessary to recommend./C15A reasoning mechanism to infer information from thestored knowledge./C15A criticality system based on the automatic inference capa-bility of the IRS.Our IRS does not only recommend items based on speciﬁcknowledge about how the item features meet user needs andpreferences, such as knowledge-based recommendationapproach; our system uses the rating of the items like the col-laborative approach, and it discovers the aspects, interests,properties that the user would like about the items (criticalitysystem), infers the rating of the items, etc. In this way, it mixesthe classical RS idea based on similarity to infer how much theuser needs the item[9,15]and the concept of criticality deducedautomatically to infer user goals that are not satisﬁed by theitem currently under consideration[22].The IRS exploits all the knowledge, which is obtained auto-matically (by learning mechanism), and is modeled appropri-ately, in order to be used by reasoning mechanisms to inferhow much the user needs the item. If the user’s goals are sat-isﬁed by the current items. Basically, two aspects must bedeﬁned in our IRS. The two aspects are its architecture, andthe knowledge to model. The general architecture is showninFig. 1.The main component is the semantic knowledge model,which stores the different types of knowledge that it uses forrecommending items. This knowledge must be updatedbecause it requires learning mechanisms. Finally, in order toexploit the knowledge, it uses a reasoning mechanism, whichis responsible for recommending items using all the knowledgeavailable. Now, listed below are the different components ofarchitecture:–Knowledge modeling:the main aspect was to deﬁne theparadigm of knowledge representation. There are a lot ofparadigms[1,2,4,10,12]: ontologies, fuzzy rules, conceptualmaps, etc. The main points to select one are the capabilitiesof representation of all the knowledge available, and thepossibility to deﬁne reasoning mechanisms with them. Ingeneral, our recommendation paradigm requires differenttypes of knowledge such as the user model, the contextualmodel, the domain model, the item model that have beenrecommended, and the rest information about the behavior
Figure 1The IRS architecture.150 J. Aguilar et al.between the users-items that stores ratings, critiques, etc.(we call it the critical model). Section3describes in detailthe different types of knowledge of our IRS.–Knowledge acquisition:this phase is deﬁned to learn aboutthe current situations, etc. There are a lot of approaches(supervised, unsupervised, etc.)[21], but the main point isto deﬁne an approach that allows all the knowledge avail-able to be discovered in a given moment. In general, the dif-ferent machine-learning techniques can be potentially used,according to the context, for example: information onlineavailable and real time information. The sources of knowl-edge are very varied and they can be structured (For exam-ple, the transactional database, or data-warehouse, of anorganization), semi-structured (For example, xml ﬁles) orunstructured (For example, GPS tracking information,audio streams, etc.) data, which represent informationabout the users, context, etc. The knowledge is acquiredthrough learning mechanisms based on data mining, seman-tic meaning (web mining, text mining, ontological mining),among other techniques[6,9]. The learning mechanisms tobe used depend on the knowledge model and the sourceof data. For example, if the knowledge model is ontologyand the source of data is the web, we can use semantic min-ing techniques to extract knowledge. Additionally, in thiscase, data science tasks are very important, in order toexplore, clean, transform and reduce the data, before apply-ing the learning techniques to extract the knowledge [15]. –Reasoning mechanism:according to the paradigm choice,there are speciﬁc reasoning mechanisms which can be used.The main point is that these mechanisms must allow forinferences. The user needs if the user goals are not satisﬁedby the current items, considering all the knowledge avail-able. There are three main reasoning mechanisms that canbe used: induction, abduction, and deduction. Each onecan be used for different tasks, such as analyzing why a rec-ommendation can be given, predicting an item that can beinteresting for a user and that means, it allows various typesof reasoning: ﬁnd a ‘‘relaxation”or ‘‘compromise”(for example, What if the user’s requirements cannot be ful-ﬁlled?), ﬁnd a ‘‘diagnosis”(for example, Why a certain itemis recommended), carry out a ‘‘veriﬁcation ”and ‘‘repara tion-debugging”(for example, What if the user require-ments are inconsistent?), and so forth. The idea is to deﬁnelogical explanations about the different aspects to be con-sidered during a recommendation process, using the avail-able knowledge. There are classic RS responses only tosome of them.–Criticality system:it is an automatic system to infer the userpreferences without asking users about them, only using theknowledge stored in the RS[9]. In each cycle of a recom-mendation session there is a reasoning phase where theaspects are deduced to accept or criticize. These cycles con-tinue until a recommendation is carried out. The learningmechanisms provide the knowledge necessary like a feed-back procedure, to deduce the preferences of the users.They provide the knowledge necessary to deduce them toinfer the rating of the items, built over a series of recom-mendation cycles. If a new cycle has been triggered, thenthe only items that fulﬁll the criteria deﬁned in the critiqueare further taken into account (reduction in the candidateitems set, in order to reduce the space of search: candidateitems). In general, this process continues until the reasoningmechanism determines that the user can accept the recom-mendation and exhausted all the possibilities, or terminatesthe recommendation cycles.5. Knowledge model in our intelligent recommender systemThe main component of our IRS is knowledge. An IRS mustexploit all the knowledge available, and to do that, all theadvances must be used in different domains (such as informa-tion retrieval, data mining), in order to extract this knowledge.Classically, a RS estimates the similarity among the item prop-erties and the user preferences, or estimates the ratings for theitems that have not been seen by a user. IRS exploits knowl-edge to infer the rating of the items, to infer the preferencesof the users, and to match the item properties with the userpreferences. For that, it deﬁnes different types of knowledge:–An extended user proﬁle(including its opinions, critiques,etc.): Normally, the information that is modeled is abouthis/her preferences, his/her personal information (age, gen-der, profession, and education), etc.[8,17,22]. Here, we pro-pose to extend with new information about his/heropinions, critiques; his/her relationship with other users(his/her friend groups, etc.). The user model proﬁles, withthe rest of semantic model of IRS must infer the preferencesand needs of the users.–An extended item proﬁle:it represents a full description ofan item based on four dimensions: (i) the general descrip-tion of the product (name, branches that produce the items,etc.); (ii) the functional information about the item (its func-tions, etc.), (iii) the structural information about the item(its components, the relationships among them, depen-dence, etc.) and ﬁnally, (iv) the operational informationabout the item (how can be used, etc.). Some of this infor-mation can be learned, or inferred from the informationstored.–Context and domain knowledge:
it is very important to knowthe domain where the items will be used, the context wherethe individual is going to make the decision, etc. The con-textual knowledge is all the knowledge that explains a givensituation[15,20]. The domain knowledge is the knowledgeof an area of a discipline, a human activity, etc. [15,23]. This type of knowledge is not currently considered, or the RSmust be customized to be used in a speciﬁc context, chang-ing part of its structure. Here, we propose to model explic-itly these aspects.–A critical knowledge:This is a knowledge that must be dis-covered, based on the transactions over the RS (relationsbetween users and items). A transaction may describe thecontext of the recommendation, may refer the item chosen,and may include the feedback the user has provided, amongother things[9,15]. Normally, this knowledge describes thebehavior-based knowledge, and must be discovered usingmachine-learning technique in order to obtain interestingpatterns. This knowledge normally represents the interestsof the users. In our IRS, this knowledge must be learnedor discovered.In our case, the similarity among the item properties andthe user preferences, or the estimation of the ratings for theitems, is the result of an inference process about the knowledgeIntelligent recommender systems 151model used (for example, if the knowledge model is ontology,then we can apply an ontological reasoning).In general, our IRS must use the knowledge available in agiven moment without degrading its performance. That is,depending on the application domain and the usage scenario,may be only parts of the previous knowledge are available,and the IRS must continue to carry out recommendations.In this way, the deﬁnitions of the different types of knowledgeare very important, but our IRS is very robust in order to workwith the knowledge available. The main difference with theKnowledge-based RS is that this requires knowledge engineer-ing, and an IRS uses learning mechanisms from differentsources: product databases, social media, etc. Our system canexploit the different techniques of machine learning, semanticmining, in order to build the knowledge that is need. Forexample, if the knowledge model is ontology, then we canapply the merging and alignment of ontologies (two types ofsemantic mining techniques) to enrich the model [24]. In this way, our IRS avoids the problem of acquisition of knowledgeof the knowledge-based RS. Additionally, it has not the ramp-up or cold-start problem because IRS can draw inferencesabout the users or items, even when it has not yet gathered suf-ﬁcient information. Its recommendations do not depend onlyon the user ratings (case of collaborative RS), or on gatheringinformation about a particular user or item (case of content-based RS), because it infers this information. We dedicatethe rest of this section to explaining this knowledge.5.1. Extended user proﬁleIn this model, the knowledge about the users is deﬁned. Thismodel must allow for responding to queries such as (seeTable 2): Who is the person? What personal data are available?How is his/her performance? What projects were assigned?What tasks have been carried out? What skills has he/she?Table 2deﬁnes user proﬁles of IRS.Some of this information is obtained by asking the users,but some of it is obtained by learning approaches. For exam-ple, the networks of friends can be obtained using social net-work analysis[22], or the ideological trend using semanticmining mechanisms.5.2. Extended item proﬁleIn this model, we deﬁne the set of features that represent anitem. There are different types of characteristics that candescribe an item:/C15General or objective characteristics, such as: functionalinformation, structural information, descriptiveinformation./C15Speciﬁc or subjective characteristics, which can be: level ofuse, score or rating, utility.These characteristics can be represented by abstract con-cepts or attributes that can be described by their properties,which can be the following:/C15Intrinsic or statics (own)./C15Dynamics (changing properties).In our case, we are going to characterize each item by four(4) dimensions[11,14]:/C15Descriptive:information about its intrinsic characteristics.Answer the question: What is it?/C15Structural:elements that compose the item (entities, attri-butes, processes), relationships and constraints betweenthem, etc. It reﬂects the invariant structure. Answer thequestion: What is its composition?/C15Functional:speciﬁc functions of the items. Answer the ques-tion: What does it do or allow?/C15Operational:how it can be used, interacted with it, or inte-grate with other systems. Answer the question: Can it beused/reused?Table 3deﬁnes the different attributes that describe an itemin our system (the ﬁrst letter next to the item represents if theattribute is static (I) or dynamic (D), and the second if theattribute is Descriptive (D), Structural (S), Functional (F) orOperational (O)):Some of the subjective attributes are deﬁned here, but theyreally belong to critical knowledge, because of a knowledgebased on the judgment of the users. In our case, this judgmentis inferred using reasoning mechanisms over the knowledgestored and the transactional information of the users.5.3. Context and domain knowledgeTwo additional knowledge, to give more semantic informationto our IRS, are as follows:–Knowledge about the context:in this case, it is necessary tocatch all information speciﬁc to the context in which therecommendation is given (seeTable 4).–Domain knowledge:It is the valid knowledge used in a givenarea of human activity, in a specialized discipline, etc. Nor-mally, the experts use and develop their own domain knowl-edge. In IRS, it refers to the speciﬁc area/domain where itwill be used.
Table 2User proﬁle in IRS.
Personal data Name, address, ID, Sex Age,relationship status, personalityPhysical features Size, weight, physical defectsUser type Student, research, etc.LanguagesSome tastes, preferences We can ask explicitly to the user,but some of this information can beinferredEducation Level of the education: PhD, etc.OccupationSocio-cultural aspects Behavior patterns, needs, culturalbehaviorEconomics aspects Income, buying habits, etc.Political aspects Ideological trend, etc.Most inﬂuential sectors Networks of friends, etc.Technological skillsIntellectual capabilitiesProjects developedPositions held152 J. Aguilar et al.5.4. Critical modelThe user’s behavior is modeled in order to determine his/herpreferences, opinions, trends, etc.[10]. The model representsthe opinions, critiques (seeTable 5). Particularly, the useropinion (critique) about the items recommended is stored,as a result of an inference process, a learning process, acalculation (estimation), or asking the users elicitation. Thismodel is navigated (it is the space of the critique to the prod-ucts) in order to be used during the recommendation processand represents the discovered preferences. In this way, theIRS can recommend items that satisfy the ongoing critique,are similar to the previous recommendation, satisfy themajority of the previous critiques, etc. Our system infersthe user preferences and works through a cycle of recommen-dations to build it.6. Example of speciﬁcation of our IRS in an intelligent techniqueOne of the advantages of our system is that its implementationcan be carried out using any intelligent techniques. The intelli-gent paradigm (ontologies, based on the evolutionary process,etc.) can be chosen according to the source of information,tools available, etc. In this Section, we give one example ofimplementation based on the FCM.6.1. Fuzzy cognitive mapsCognitive Maps (CMs) are directed graphs that model a realsystem as a set of concepts and causal relationships betweenthem[1–3]. Each concept is a node in the graph, and representsa characteristic/state of the system. The causal relationshipsare positive or negative signs, with speciﬁc weights. The valueof a node is the activation degree of a concept in a given time.This value is deﬁned as the sum of all values of the concepts atthe preceding state and the incoming edges.Speciﬁcally, a CM is deﬁned bynconcepts (mathematicallyis anstate vector A), and an*nweighted matrixE. Each ele- mentEijof the matrix is the value of the weight between con-ceptsC
iandC j(it measures how muchC icausesC j). The activation levelA
ifor each conceptC iis calculated by thefollowing:A
i¼fXnj¼1AjEji !þA
oldið1ÞA
iis the activation level ofC iat timet+1 ,A jis the activation level ofC
jat timet,Aoldiis the activation level ofC iat timet, andfis a threshold function. In this way, the new state vectorA is deﬁned by the change in the activation level of one con-cept due to the other concepts. A CM starts with A
0=S 0, and repeatedly calculatesA
i, until the system convergences(for example, whenA
newi¼Aoldi) or other stopping criteria.The last value of the state vector A is the response to the ‘‘whatif”question[1–3].CMs have been extended by Kosko, considering fuzzy logicand neural network theories[2]. This approach has been calledFCM, and often is deﬁned by concepts that can be deﬁned asfuzzy sets, and causal relationships between the concepts thatcan be deﬁned by fuzzy implications. Also, the threshold func-tion of the weighted sums can be fuzzy. There are differentlearning algorithms for a FCM in the literature. There aretwo examples of learning algorithms. One is based on the opin-ion of the experts and another is based on the historical data.In[1,3]an exhaustive presentation of different learning algo-rithms is given.6.2. IRS based on FCMWe propose a FCM based on two levels, the ﬁrst level containsthe concepts inferred, which represent the knowledge about thecritiques of the products, the preferences of the users, the rec-ommendations, among other concepts. The second level repre-sents the description of the current situation: the informationabout the items and users, the context, etc. They are deﬁnedaccording to our models presented in Section 5. In this way, the ﬁrst level is the knowledge generated by our system, whichcan be used in different ways: to recommend, to discover infor-Table 3Item proﬁle in IRS.
General attributes Subjective attributes– Item ID (I, D)– Name (I. D)– Type of item (I, D)– Description (I, D)– Localization (I, D)– Author of the item (I, D)– Date of elaboration (I, D)– Provider (I, D)– Dimension(I,D)– Version (I, D)– Format (I, D)– Components (I, S)– Relationship betweencomponents (I, S)– Constrains (I, S)– Technical Requirements(I, S)– Goal (I, F)– Requirement cover (I, F)– Level of use (D, O)– Utility (D, O)– Punctuation/Qualiﬁcation (D,O)– Type of Problems where canbe used (D, O)– Reusability (D, O)– Extensibility (D, O)– Interoperability (D, O)
Table 4Contextual Knowledge in IRS.
– Environmental conditions– Space characteristics– Time: current and historical– Activities– Resources and devices– State– Peoples
Table 5Critical model in IRS.
Attribute Critical typeBehavior patterns Unit and compound critiquesTrends Directional or replacementOpinions Directional or replacementPreferences Unit and compound critiquesPunctuation Unit and compound critiquesIntelligent recommender systems 153mation about the users, products, etc. The second level repre-sents all the knowledge available in a given moment (see Fig. 2, the FCM developed with the FCM Design tool [7]): (a) First level:In this level, there are concepts inferred from the conceptsof the second level or from concepts on the same level. Mainly,they represent concepts linked to the recommendations (oursystem can recommend different things, for example interest-ing items, similar items), but additionally, other types of con-cepts about information inferred about the products or items(for example, users opinions, or punctuation of the item). Ingeneral, the attributes of the critical model belong to this level,and they reduce the space of candidate items. The concepts onthis level are deﬁned inTable 6.(b) Second level:In this level, the concepts represent the different attributesof the user and item proﬁles, extended by the knowledge aboutthe context and domain (see Section5). They are groupedaccording to the knowledge that is represented (users, prod-ucts, etc.).The relationship between the concepts is according to thecausal relation between them. They determine the dependentrelationships among the concepts. In this case, the learningprocess adapts the relationships among the concepts: deleting,updating or adding. In this way, our FCM is reconﬁgurableaccording to the quality of recommendations given.Fig. 2shows the initial FCM. In the ﬁrst level we can seethe concepts inferred listed inTable 6, as the preferences,usability, Use Level (‘‘nivel the uso”in Spanish), etc. In thesecond level the concepts are deﬁned in Section 5about users proﬁle deﬁned inTable 2(Languages (‘‘idioma”in Spanish), Sex, User type (‘‘tipo de usuario”in Spanish), etc.), and itemproﬁle deﬁned inTable 3(Name (‘‘Nombre”in Spanish), Localization, etc.), among others. The initial values of the arcshave been deﬁned by a group of experts on learning resources,and they have been adapted using the learning mechanisms ofthe FCM Designer Tool[7].Particularly, we can see that in FCM the similarity isinferred due to the relationships between the concepts of theitem proﬁle and users proﬁle with the concepts inferred (in spe-cial, with the ‘‘Item of interest”and ‘‘Item preferred by user” concepts). The recommendation and preference concepts areexamples of elements of the critical model included in theFCM model which are also inferred. In this way, all the ele-ments of the different models are included naturally in theFCM.7. Case studyIn this case study, we deﬁne an IRS of learning resources. InSection5we have presented the general knowledge used by
Figure 2Our multilevel FCM.
Table 6Inferred concepts.
Item of interest It refers to the usefulness of the item for the userPunctuation It refers to score or rating that a user provides tothe itemItem preferredby userIt is the priority that a user has for the itemPreferences It refers to user-deﬁned preferences based on itsproﬁle informationUse Level Indicator of the user interaction with the itemUsability It refers to the ease with which user can use theitemInteroperability It concerns whether the item can be integratedinto diﬀerent systems or platformsSimilar user It concerns whether there are other users with thesame characteristics as the active user154 J. Aguilar et al.IRS. Now we need to customize the IRS based on FCM forthis domain.7.1. Analysis of the user proﬁle of IRS of learning resourcesWe use the IMS standard, which describes the general infor-mation to be collected about a student or a producer of learn-ing content, to customize the user proﬁle[8]. The IMS LearnerInformation Package (IMS LIP) speciﬁcation deﬁnes the inter-operability of internet-based Learner Information systems,with other Internet systems used by learning processes. OurIRS must consider this information. The main aspects to con-sider from the IMS standard are afﬁliations, competencies,goals, identiﬁcations, interests, qualiﬁcations, certiﬁcations,accessibilities, activities, and relationships.We verify whether this information is included in the userproﬁle deﬁned previously (seeTable 7). InTable 7we can see that our proﬁle contains the main attributes of the IMSLIP speciﬁcation and of the Reusable Deﬁnition of Compe-tency or Educational Objective (RDCEO) speciﬁcation. TheRDCEO allows deﬁning competencies in the learning domain.Any additional information to be included in our user proﬁle isspeciﬁed like part of the domain knowledge of the IRS. In ourcase, initially we do not add more information. Finally, ourFCM will use the same set of concepts, seeTable 7. 7.2. Analysis of the item proﬁle of IRS of learning resourcesBased on the same idea of the previous Section, we need toadapt the item’s proﬁle to the context of application of theIRS. In this case, we need to compare the items to be recom-mended for a standard in the domain of the Learning Resource(LR). Speciﬁcally, we use the LOM-IEEE standard [11]. The LOM-IEEE deﬁnes 9 categories: (a) General category (GC):general information about the LR, (b) Lifecycle Category(LC): metadata related to the history and current status ofthe LR, (c) Metadata Category: information about the meta-data itself, (d) Technical category (TC): metadata about thetechnical requirements of the LR, (e) Educational category:metadata for educational uses of LR, (f) Rights Category:metadata about property rights and intellectual material, (g)Relation Category: metadata used to establish relationshipsbetween the LRs, (h) Annotation Category: annotations andcomments on the LR, and (i) Classiﬁcation Category: LR clas-siﬁcation like taxonomies.The general category of the LOOM-IEEE standard includesnine types of metadata, such as: Identiﬁer (ID), Title, Lan-guage, among others. The technical category includes Format,Size, Location, etc. Educational category groups the metadata:Interactivity Type (‘‘Active”, ‘‘Expositive”), LR Type (exercise,simulation, questionnaire, slide, experiments, lecture, etc.),Interactivity Level (low, high, etc.), Context, Difﬁculty, TypicalLearning Time, among others. For the rest, see [11].Table 7User proﬁle in IRS and IMS speciﬁcations.
Attribute StandardPersonal data (name, id, sex, etc.) IMS-LIPPhysical Features (physical disability)User type IMS-LIPLanguagesSome tastes, preferences (likes) IMS-LIPEducation (academic degree) IMS-LIPOccupationSocio-cultural aspects (behavior, behaviorpatterns) IMS-LIPEconomics aspectsPolitical aspects (context)Most inﬂuential sectors (networks of friends) IMS – RDCEO Technological skillsIntellectual capabilities(score intellectual) IMS – RDCEO Projects developed IMS-LIPPositions held (employment performed)
Table 8Item proﬁle in IRS and in LOM.
General attributes Speciﬁc attributes LOM– Item ID (I, D) – Identiﬁer (GC) – Name (I. D) – Title – Title (GC)– Type of item (I, D) – Catalog entry (GC) – Description (I, D) – Description (GC) – Localization (I, D) – Location (TC) – Author of the item (I, D) – Manager/Artist/Composer– Date of elaboration (I, D) – Year of manufacture/production– Provider (I, D)– Dimension (size) (I,D) – Longitude, latitude, Size– Version (I, D) – Model, language – Version (LC)– Format (I, D) – Language (GC) – Components (I, S) – Structure (CC) – Relationship between components (I, S) – Relation category – Rights category – Constrains (I, S) – Requirements, Installation Remarks – Technical Requirements (platform, – e-learning platform– types problems) (I, S)– Goal (I, F)– Requirements cover (topic, career, area) (I, F) – Course Area, Certiﬁcation, subject – Educational categoryIntelligent recommender systems 155Now, we verify whether this information is included in ouritem proﬁle, and the rest is included as part of the domainknowledge model (seeTable 8).We can see that the IRS covers the main attributes of thestandard LOM, and any additional attribute of this standardto be included is part of the domain knowledge. In our case,we do not add additional knowledge.In the Sections7.1 and 7.2we show two examples of imple-mentation of the user and item proﬁles of our IRS model. Inthis study case, we have used two standards of the domainof learning to deﬁne these proﬁles: the LOM standard forthe item proﬁles, and the IMS standards for the user proﬁle.We conﬁrm that the general user and item proﬁles deﬁned inSection5are part of these standards. In this way, the FCMimplementation of the IRS deﬁned in Section 6is correct. 8. Results and discussion8.1. Experiments with the IRS based on FCMIn this section, we evaluate the capabilities of our FCM-basedIRS in terms of the learning methods and reasoning mecha-nisms. In the previous sections, we have deﬁned the knowledgemodels used by the FCM-based IRS. The knowledge modelbased on FCM is deﬁned by the concepts that represent theinformation about the users, items, domain, context and criti-cisms (see Sections5–7). In this section, we evaluate the learn-ing and reasoning capabilities.8.1.1. Learning processThis process is based on two steps:1. Determination of the initial values of the weights: itincludes the assignment of initial values (weights) of therelationships between concepts by human experts. Theassignment of the relationship weights is obtained fromthe mean weights established by several experts (see [1,3] for more details of this process).2. Adjustments of weights based on initial experiments: usingthe FCM generated in step one, we have taken a sample ofreal examples in which we knew in advance for each case,the students and the learning resources to recommend.We have run our recommender system based on FCM,and its results are compared with the real cases to determinewhether the weights given by the experts provide the desiredoutput, or whether it is necessary adjust them, in order toobtain the desired output (see the details of this procedurein[1,3]).8.1.2. Inference processOur RS can be used in two cases: to recommend an LR for agiven student, and to infer quality aspects in an LR. In this sec-tion, we are going to test both capabilities. To recommend LR,we only need infer concepts linked to preferences, and to inferthe quality of a learning resource, we only need infer conceptslinked to the characteristics of the learning resources (seeTable 9).Additionally, the concepts about student and item proﬁlesto be used by the FCM, for the recommendation or inferenceof the quality, are reduced (seeTables 10 and 11), consideringonly those important for the recommendation, or the qualityof a LR. According toTables 10 and 11, for the recommenda-tion, the concepts linked to detailed information of an LR anda student are not relevant to deﬁne preferences (they aredeleted); and for the inference of the quality, we delete the con-cepts about the detailed information of the student, and theinformation is not relevant for an LR, to determine theirusability and interoperability.If we like to study the preferences (ﬁrst case), then we needto keep all the student concepts, and some of the conceptsabout learning resources (such as item ID, type, goal). Theattributes related to the educational characteristics of the itemare important in this case (seeTable 11). To deﬁne the prefer-ences of a student we need all of its concepts (see Table 10), but to infer the quality of the learning resources only the studentconcepts about its physical characteristics (sex, disability,etc.) are of interest (seeTable 10).8.1.2.1. To recommend learning resources.Now, we present anexample of the FCM to recommend an LR. In this case, theIRS infers whether a student is interested or not in an LR,whether it has a preference for it, whether the LR is usefulfor the student, etc. For this experiment, an example of the val-ues of the student attributes is given inTable 12, and of the LR inTable 13.These values of the concepts are deﬁned at the beginning bythe users, according to the relationship between the user con-cepts (architecture student) and the speciﬁc educationalresource (Construction). For example, the goal of the item isaccording to the proﬁle of the student (for this reason, the con-cept about ‘‘requirements cover”is 0.8), and the learningresource can be used in different platforms; for this reason,the value of the ‘‘constraints”concept is 0.8. In this way, wedeﬁne the initial values of the different concepts of theFCM, and the FCM starts to iterate until its convergence.We have used the FCM Designer Tool
[7]. We have carriedout several recommendations for the same student and differ-ent learning resources, and these results are shown in Table 14. The FCM iterates, until the values of the inferred conceptsare stabilized. The ﬁrst column corresponds to the results ofthe pair LR and student, ofTables 12 and 13. In this case, the FCM iterates 10 times. In that example, we can see thatthe values obtained for the inferred concepts indicate thatthe LR is recommended (has a good punctuation and prefer-ence), it should be useful for the student, there are similar stu-dents that have used this LR, and the student will have a goodlevel of interaction with the LR. We can carry out a similarinterpretation of the concepts, for the rest of results.Table 9Inferred concepts in each case.
Item of interest To recommendlearning resourcesTo infer the quality of alearning resource Punctuation XItem preferredby userXPreferences XUse Level XUsability XInteroperability XSimilar user X156 J. Aguilar et al.Table 10Concepts about students without impacts in each case.
Attribute To recommend learning resources To infer the quality of a learning resourcePersonal data (name, id, sex, etc.)Physical Features (physical disability)User type X LanguagesSome tastes, preferences (likes) XEducation (academic degree) XOccupation X Socio-cultural aspects (behavior, behavior patterns) XEconomics aspects X Political aspects (context) XMost inﬂuential sectors (networks of friends) XTechnological skills X Intellectual capabilities (score intellectual) XProjects developed X Positions held (employment performed) X
Table 11Concepts about LR without impacts in each case.
General attributes To recommend learning resources To infer the quality of a learning resourceItem ID (I, D) X Name (I. D) X Type of item (I, D)Description (I, D) X Localization (I, D) XAuthor of the item (I, D) XDate of elaboration (I, D) XProvider (I, D) XDimension (size) (I,D) XVersion (I, D)Format (I, D) XComponents (I, S) XRelationship between components (I, S) XConstrains (I, S) XTechnical Requirements (platform, types problems) (I, S)Goal (I, F) X Requirements cover (topic, career, area) (I, F) X
Table 12Input value of the student concepts.
Attribute Student Concept valuePersonal data (name, id, sex, etc.) Vannesa Alarco ´n, ID 3474342, female, etc. 1 Physical Features (physical disability) Without physical disability 0.5User type Genius 1Languages Spanish, French, English 1Some tastes, preferences (likes) Painting, music, reading 1Education (academic degree) Student of Architecture 1Occupation Student 0.5Socio-cultural aspects (behavior, behavior patterns) Dance, walk, fans of social network 0.7Economics aspects Middle class 0.3Political aspects (context) Unknown 0Most inﬂuential sectors (networks of friends) Her parents, her friends of study 0.6Technological skills Programmer,Intellectual capabilities (score intellectual) Analytical, thinker 0.5Projects developed Design of a church 0.6Positions held (employment performed) Nothing 0Intelligent recommender systems 1578.1.2.2. To infer the quality of a learning resource. In this case, we test the FCM to infer the characteristics of usability andinteroperability. An example of the input of the pair LR andstudent is given inTables 15 and 16.This FCM can predict the characteristics of usability andinteroperability of a LR. This is an interesting use of theFCM, in order to determine whether a LR can be interestingfor a given course (that can be very important in courses wherethere are students with physical disability). For example, forthe case of theTables 15 and 16, the ﬁrst column inTable 17 describes the inference. In this case, the FCM infers a highusability and interoperability of the LR. Particularly, theFCM infers the LR is easy to use for the students with the pro-ﬁle ofTable 15(usability), and can be integrated into otherplatforms (interoperability).8.2. General result analysisIn the Section8.1, we have evaluated the learning and reason-ing capabilities of the FCM-based IRS. Particularly, the rea-soning capabilities allow different types of inferences notonly to recommend but also to infer other types of informationsuch as the quality of the learning resource. With the modelsand results obtained in Sections6,7 and 8.1, we have evaluatedthe entire FCM-based RS as an IRS.Now, we compare the FCM-based IRS approach withother knowledge-based RS. In order to determine the compar-ison criteria, we deﬁne some questions about how the knowl-edge is managed by the different approaches in the contextof learning resources. These questions are as follows: Howcan our IRS be evaluated? How can we measure the qualityof the IRS? In general, we are going to use metrics that tryto determine how the knowledge in our IRS is exploited. Forthis reason, we propose the next criteria[9,15]:–Validity:if the RS gives explanations to allow users validatethe recommendation. For example, ‘‘I recommend thishouse because you have four children. Because of the num-ber of children, I cannot recommend a small apartment ”. –Comprehension:determines whether the explanations/rec-ommendations are based on a deep knowledge about thedomain of interest.–Efﬁciency:determines whether the RS reduces the decision-making effort of the users. In our case, the interesting mea-sure of efﬁciency is the cognitive effort.–Persuasiveness:it determines whether the IRS can changethe behavior of the users. In this sense, recommendationspersuasively aim to change the user’s behavior.Table 13Input value of the learning resource concepts.
General attributes Educational resource ValueName Construction 1Type of item Video, book and slides 1Description This resource describes acourse about constructions ofchurches1Constrains Windows, Linux, 0.8Technical Requirements(platform, typesproblems)3K Ram, VLC tool, players,OpenOﬃce, graphic processor0.5Goal Bases about the construction ofchurches0.6Requirements cover(topic, career, area)Technical drawing, calculation,etc.0.8
Table 14Results of some recommendations of learning resources.
Attribute inferred Recomm. 1 Recomm. 2 Recomm. 3 Recomm. 4Item of interest 0.93422 0.93242 0.01451 0.64154Punctuation 0.80453 0.89453 0.01385 0.45484Preferences 0.88349 0.95136 0.10340 0.51858Use Level 0.95364 0.86465 0.04256 0.39552Similar user 0.83544 0.82345 0.12034 0.54321Table 15Student Concepts in the FCM to infer the charac-teristics of usability and interoperability of a learning resource.
Attribute Student Concept value Personal data (name, id,sex, etc.)Vannesa Alarco´n, ID3474342, female, etc.1Physical Features(physical disability)Without physicaldisability0.5Languages Spanish, French, English 1
Table 16Learning resource concepts in the FCM to infer thecharacteristics of usability and interoperability of a learningresource.
General attributes Educational resource ValueType of item Video, book and slides 1Date of elaboration Dec 2016 1Provider Heber Hoeger 1Dimension (size) 10 Gb 1Version First version 1Format Pdf, ppt 1Components One part 1Relationship betweencomponentsSequential 1Constrains Windows and Linux 0.8Technical Requirements(platform, typesproblems)3K Ram, VLC tool, players,OpenOﬃce, graphic processor0.5
Table 17Results of some recommendations about the qualityof the learning resources.
Attribute inferred Inference 1 Inference 2 Inference 3Usability 0.89545 0.45633 0.09435Interoperability 0.91322 0.34613 0.12322158 J. Aguilar et al.–Effectiveness:determines whether the recommendationshelp users for making high-quality decisions.–Transparency:if the RS provides information at the user tounderstand the reasoning which it uses to recommend.In this section we compare our IRS with other works, usingthese metrics to determine how the knowledge is exploited ineach RS (seeTable 18).In general the IRS gives good results. It gives a good expla-nation of its recommendations and advices based on its infer-ence process (see Section7.1) and its knowledge model aboutthe domain of interest (see Sections5–7). Due to that thisinformation can persuade to the users in a transparent wayin order to help them in their processes of making decisions.The only criterion where our IRS is not good is in efﬁciency,because the user needs to customize the input and to interpretthe inference process of the IRS. The FCM-based IRSincreases the decision-making effort of the users that is dueto the technique used to test our IRS (FCM), and not to theIRS framework, because the user needs to know the FCM the-ory to understand the process followed by the RS.The works[14,16]do not give explanations about their rec-ommendations because their recommendations are not basedon a knowledge model. The work presented in [10]has the same problem of efﬁciency as our work because it is basedon the same technique, but it has not a learning process andthe users must update manually the cognitive map (trans-parency). Additionally, the knowledge model of [10]is very simple. It does not consider aspect as the context and the crit-icisms, and its user and item proﬁles are very simple. Theselimitations in the knowledge model or the inexistence of theknowledge model in[14,16], reduce their persuasive capabili-ties and for the same reasons in some cases the recommenda-tions do not help users for making high-quality decisions.We like to highlight that[10]uses the same technique thatour example of IRS, but its knowledge representation is verysimple and has not a learning mechanism. Our IRS frameworkintroduces some aspects such as the knowledge representation,the learning and the reasoning mechanisms, all of whichimprove the recommendation process.In general, the IRS framework is the only one that coversthe different criteria very well and the rest have problems,because they are ambiguous in the inference process (trans-parency), which impacts in the persuasion to users. Addition-ally, our IRS can be used in different contexts.The evaluation of Section8.1allows determining theadvantage of the different capabilities of an IRS (learn, reason,etc.), and the comparison in this section allows determining theadvantage about how the knowledge is managed in our IRS.These different comparisons and evaluations allow having anentire idea of the interest of an approach as the IRS.9. ConclusionsIn this paper, we have presented a new type of RS, called IRS.We have argued that an IRS framework improves the qualityof the recommendations due to its knowledge representation,and its learning and reasoning mechanisms. The classical RShave not all these characteristics simultaneously; for example,[10]uses the same technique that we have used to implementour example of the IRS, but in[10]it is deﬁned as aknowledge-based RS. In the Section8.2, we have determinedthat our system has better behavior due to these characteristicsused simultaneously.Our IRS allows navigating over knowledge in order toexploit it. Additionally, our IRS can infer interesting informa-tion, what is not traditionally deﬁned by classic RS, about userpreferences, critiques, etc. Our IRS can use the knowledge indifferent ways (to explain, to persuade, to predict etc.), for dif-ferent things (to infer or to recommend), in a transparent way.Our IRS avoids some of the classical drawbacks in RS: it doesnot have a ramp-up problem since its recommendations do notdepend on a base of user ratings, it does not require a knowl-edge engineering process, and it does not have to gather infor-mation about a particular user because its similarity judgmentsare independent of individual tastes, etc. It is immune to statis-tical anomalies because its recommendations are based onknowledge, which is updated by learning mechanisms. TheIRS framework has a well-deﬁned knowledge model, whichconsiders knowledge about the users, items, domain, contextand criticisms. The learning mechanism allows update thisknowledge that initially is deﬁned using the context anddomain information, and is used in the ﬁrst inferences. ThenIRS exploits the knowledge extracted by the learning mecha-nism particularly about the users to improve its performance.The implementation of the IRS using FCM shows the ver-satility of the framework. The main aspects that must guaran-tee the intelligent techniques to be used to implement IRS, arethe capabilities of reasoning, representation of diverse knowl-edge and learning. Particularly, the learning capability of theFCM is used easily by the RS, and the reasoning is deﬁnedby the iterative process implicit in the FCM.The criteria about the management of knowledge deﬁned inSection8.2, are well achieved by our approach. Our approachobtains two types of results: qualitative (cognitive map) andquantitative (inferences). With these results it meets the crite-
ria.[14,16]do not reach the validity and efﬁciency criteriabecause they do not explain how the results are obtained andTable 18Comparison with other approaches.
Criteria[10] [14] [16] Our IRS Validity Not Not Not YesComprehension Yes Yes Yes YesEﬃciency Not Yes Yes NotPersuasiveness Maybe Maybe Maybe YesEﬀectiveness Sometime Sometime Sometime YesTransparency Yes Not Not YesIntelligent recommender systems 159the students/teachers must reason about why to use the learn-ing resources recommended (the validity is not reached). Also,[10,14,16]are not persuasive and effective due to the knowl-edge model used which only cover partial information aboutthe students or learning resources or to the inexistence of aknowledge model. This does not allow convincing a person,because it is not possible to deﬁne arguments based onknowledge.Further works must test the IRS in other types of problemswith other intelligent techniques, like the ontologies, the fuzzylogic, in cases which require large knowledge about the domainand context. Also, more experiments are necessary to deter-mine other uses of the knowledge stored by the IRS in the con-text of RS (e.g., for diagnosis).AcknowledgmentDr. Aguilar has been partially supported by the Prometeo Pro-ject of the Ministry of Higher Education, Science, Technologyand Innovation of the Republic of Ecuador.References
[1]J. Aguilar, Different dynamic causal relationship approaches forcognitive maps, Appl. Soft Comput. 13 (1) (2013) 271–282,Elsevier
.[2]
J. Aguilar, A Survey about fuzzy cognitive maps papers, Int. J.Comput. Cognit. 3 (2) (2005) 27–33, Yang’s Scientiﬁc ResearchInstitute
.[3]
J. Aguilar, Dynamic random fuzzy cognitive maps, RevistaComputacio´n y Sistemas, Revista Iberoamericana deComputacio´n 7 (2004) 260–271
.[4]
M. Ayub, A. Cian, M. Caliusco, E. Reynares, Developing anontology-based team recommender system using EDONmethod: an experience report, SADIO: Electron. J. of Inform.Operat. Res. 13 (2014) 1–13
.[5] R. Burke, Integrating Knowledge-based and Collaborative-ﬁltering Recommender Systems, AAAI Technical Report WS-99-01, pp. 69–72.[6] R. Burke, Knowledge-based recommender systems, in: A. Kent(Ed.), Encyclopedia of Library and Information Systems, 69(32), Marcel Dekker Publisher, 2000.[7]
J. Contreras, J. Aguilar, The FCM designer tool, in: M. Glykas(Ed.), Fuzzy Cognitive Maps: Advances in Theory,Methodologies, Tools and Application, Springer, 2010, pp. 71–88
.[8] IMS Global Learning, <http://www.imsglobal.org/cc/index.htm>.[9]D. Jannach, M. Zanker, A. Felfernig, G. Friedrich,Recommender Systems: An Introduction, CambridgeUniversity Press, New York, 2011
.[10]
W. Liu, L. Gao, Recommendation system based on fuzzycognitive map, J. Multimedia 9 (7) (2014) 970–976
. [11] LOM-IEEE standard. <http://ieeeltsc.org/wg12LOM/>. [12]
B. Ojokoh, M. Omisore, O. Samuel, T. Ogunniyi, A fuzzy logicbased personalized recommender system, Int. J. Comput. Sci.Inform. Technol. Secur. (IJCSITS) 2 (5) (2012) 1008–1015
. [13]
K. Palanivel, R. Sivakumar, Fuzzy multicriteria decision-making approach for Collaborative recommender systems, Int.J. Comput. Theory Eng. 2 (1) (2010) 57–63
. [14]
A. Rodriguez, J. Gago, L. Rifo´n, R. Rodrı´guez, A recommender system for non-traditional educational resources: a semanticapproach, J. Univ. Comput. Sci. 21 (2015) 306–325
. [15]
F. Ricci, L. Rokach, B. Shapira, P. Kantor (Eds.),Recommender Systems Handbook: A Complete Guide forResearch Scientists and Practitioners, Springer, New York,2011
.[16]
L. Rifon, A. Canas, V. Roris, J. Gago, M. Iglesias, Arecommender system for educational resources in speciﬁclearning contexts, in: 8th International Conference onComputer Science & Education (ICCSE), 2013, pp. 371–376
. [17]
E. Stuart, N. Shadbolt, D. De Roure, Ontological user proﬁlingin recommender systems, ACM Transact. Inform. Syst. 22 (1)(2004) 54–88
.[18]
R. Sikka, A. Dhankhar, C. Rana, A survey paper on e-learningrecommender system, Int. J. Comput. Appl. 47 (2012) 27–30
. [19]
L. Tera´n, SmartParticipation: A Fuzzy-Based RecommenderSystem for Political Community-Building, Springer,Switzerland, 2014
.[20]
C. Tsai, H. Chuang, The role of cognitive decision effort inelectronic commerce recommendation system, Int. Schol. Sci.Res. Innovat. 5 (10) (2011) 36–40
.[21]
A. Almahairi, K. Kastner, K. Cho, A. Courville, Learningdistributed representations from reviews for collaborativeﬁltering, in: 9th ACM Conference on Recommender Systems(RecSys ’15), 2015, pp. 147–154
.[22]
J. Neidhardt, R. Schuster, L. Seyfang, H. Werthner, Eliciting theusers’ unknown preferences, in: 8th ACM Conference onRecommender systems (RecSys ’14), 2014, pp. 309–312
. [23]
C. Mediani, M.H. Abel, Semantic recommendation ofpedagogical resources within learning ecosystems, in: 2016International Conference on Industrial Informatics andComputer Systems (CIICS), 2016, pp. 1–5
. [24]
M. Mendonc¸a, N. Perozo, J. Aguilar, An approach for multiplecombination of ontologies based on the ants colonyoptimization algorithm, in: Asia-Paciﬁc Conference onComputer Aided System Engineering (APCASE), 2015, pp.140–145
.160 J. Aguilar et al.