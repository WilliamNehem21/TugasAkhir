Combining clusterings in the belief function framework☆
Feng Lia, Shoumei Lia, Thierry Denœuxb,c,*,1
aBeijing University of Technology, College of Applied Sciences, Beijing, China
bUniversit/C19e de Technologie de Compi /C18egne, CNRS, Heudiasyc (UMR 7253), France
cInstitut Universitaire de France, Paris, France
ARTICLE INFO
Keywords:Evidence theoryBelief functionsClustering ensembleIntuitionistic fuzzy relationABSTRACT
In this paper, we propose a clustering ensemble method based on Dempster-Shafer Theory. In the ﬁrst step, base partitions are generated by evidential clustering algorithms such as the evidential c-means or EVCLUS. Base credal partitions are then converted to their relational representations, which are combined by averaging. The combinedrelational representation is then made transitive using the theory of intuitionistic fuzzy relations. Finally, theconsensus solution is obtained by minimizing an error function. Experiments with simulated and real datasetsshow the good performances of this method.
1. IntroductionClustering is an important task in Machine Learning and PatternRecognition. It is a statistical method to divide objects into groups, insuch a way that objects are similar within each group, and dissimilaracross different groups. Clustering methods have proved useful in manyreal-world application domains, such as data mining, image segmenta-tion, etc.According to the form of clustering output, we can distinguish be-tween hard and soft partitional clustering; the latter includes fuzzyand evidential clustering. In particular, evidential clustering, based onDempster-Shafer (DS) theory (also called the theory of belief functions)[8,31], has recently attracted the attention of many researchers.Evidential clustering computes acredal partition, which describes cluster membership uncertainty using DS mass functions.In recent years, several evidential clustering algorithms have beendeveloped. Denœux and Masson (2004) [12]ﬁrst introduced an evidential relational clustering method called EVCLUS. This methodﬁnds a credal partition such that the degree of con ﬂict between the mass functions associated with any two objects match their dissimilarity.Antoine et al. [3] proposed a constrained version of EVCLUS, calledCEVCLUS, which utilizes prior information provided as pairwise con-straints. Denœux et al. [14] introduced a faster version of EVCLUS, calledk-EVCLUS, where a new cost function is de ﬁned and optimized by aniterative row-wise quadratic programming (IRQP) algorithm. Li et al.[23] further expanded thek-EVCLUS method by taking prior knowledgeinto account.In Ref. [26], Masson and Denœux introduced the evidential c-meansalgorithm (ECM), which is an extension of the classic and fuzzy c-meansin the framework of DS theory. The ECM alternatively searches for thebest credal partition and the best prototypes. Masson et al. [ 27] proposed a variant of ECM for dissimilarity data, called RECM. Antoine et al. [ 2] introduced a constrained version of ECM (called CECM) by consideringprior knowledge. Liu et al. [25] proposed another variant of the ECMalgorithm, called CCM, by introducing the notion of meta-cluster. Zhouet al. [43] extended the median c-means and median fuzzy c-means to theMedian Evidential c-means (MECM). Denœux et al. (2015) [10] intro- duced a new evidential clustering algorithm (Ek-NNclus) based on theevidentialknearest neighbor rule.Different clustering algorithms may obtain different clustering resultsfor one dataset, and even a single algorithm with different initializationsmay yield different solutions. It is generally agreed that there is no bestsingle clustering algorithm [1]. To solve this problem and furtherimprove the robustness, consistency and stability of the solution, clus-tering ensemble methods have emerged as an approach for combiningmultiple clustering results into an improved solution. Among those, theEvidence Accumulation Clustering (EAC) method [ 16,17] has attracted a
lot of attention. It constructs a co-association matrix from base partitions,
☆This research was supported by grant No. 11571024 from NSFC, and by the Overseas Talent program from the Beijing Government.* Corresponding author. Universit /C19e de Technologie de Compi /C18egne, CNRS, Heudiasyc (UMR 7253), France. E-mail address:tdenoeux@utc.fr(T. Denœux).
1Professor Thierry Denoeux, one of the authors of this paper, is the Editor-in-Chief of Array. The editorial process for this manuscript was handled in dependently and the manuscript was subject to the Journal ’s usual peer review process.
Contents lists available atScienceDirect
Array
journal homepage:www.elsevier.com/journals/array/2590-0056/open-access-journal
https://doi.org/10.1016/j.array.2020.100018Received 11 October 2019; Received in revised form 20 December 2019; Accepted 21 January 2020Available online 31 January 20202590-0056/©2020 The Authors. Published by Elsevier Inc. This is an open access article under the CC BY-NC-ND license ( http://creativecommons.org/licenses/by-
nc-nd/4.0/ ).Array 6 (2020) 100018which can be processed by a hierarchical clustering algorithm to obtaintheﬁnal solution.In this paper, we introduce an evidential clustering ensemble methodthat can be seen as an extension of the EAC method in the DS framework.In our method, base evidential partitions are generated by evidentialclustering algorithms. As noted in Ref. [ 14], evidential partitions allow for ambiguity, uncertainty or doubt in the assignment of objects toclusters, and constitute a rich and informative description of the clus-tering structure of a dataset. The base credal partitions are transformedinto their relational representations [ 11], which are combined using different rules of DS theory. The fused relational representation corre-sponds to the co-association matrix in the EAC method. It can be seen asdeﬁning an intuitionistic fuzzy relation [22], which is made transitive to obtain an intuitionistic fuzzy equivalence relation. The ﬁnal evidential partition is obtained by minimizing an objective function based on thecredal Rand index [11]. Experiments with real and simulated data showthat our approach can reveal the underlying clustering structure ofcomplex-shape datasets and achieve better results than EAC and singleclustering algorithms.The rest of this paper is organized as follows. Basic notions are ﬁrst recalled in Section2. Our method is then described in Section 3, and experimental results are reported in Section 4. Finally, Section5con- cludes the paper.2. BackgroundIn this section, we brieﬂy introduce some basic notions used in thispaper. The main deﬁnitions of DS theory areﬁrst recalled in Section2.1. The notions of credal partition and relational representation are thenreviewed in Section2.2. Section2.3introduces intuitionistic fuzzy re- lations and the transitive closure theorem. We then describe the EACmethod in Section2.4, and we review some related work in Section 2.5.2.1. DS theoryLetΩ¼f
ω1;…;ωcgbe aﬁnite set. Amass functiononΩis a mapping from the power set 2
Ωto½0;1/C138, satisfying the conditionX
A/C18ΩmðAÞ¼1: (1)Each subsetAofΩsuch thatmðAÞ>0is called afocal set. In DS theory, a mass function is viewed as a piece of evidence about some question ofinterest, for which the true answer, denoted by
ω, is supposed to be an element ofΩ. For any nonempty focal setA,mðAÞis a measure of the belief that is committed exactly toA[31]. The massmð∅Þassigned to the empty set is a measure of the belief that the true answer might not belongtoΩ. The massmðΩÞis a measure of ignorance. A mass function is said tobelogicalif it has only one focal set. It is said to be normalizedif the empty set is not a focal set, andunnormalizedotherwise. An unnormalized mass functionmcan be converted into a normalized one m
/C3byDempster's normalization operationdeﬁned bym
/C3ð∅Þ¼0andm
/C3ðAÞ¼mðAÞ1/C0mð∅Þ: (2)Given a mass functionm, the correspondingbeliefandplausibility functions are deﬁned, respectively, asbelðAÞ¼X
∅6¼B/C18AmðBÞandplðAÞ¼X
B\A6¼∅mðBÞ;for allA/C18Ω. Clearly, functionsbelandplare linked by the relationplðAÞ¼1/C0belðAÞ, where Adenotes the complement ofA. The quantity belðAÞrepresents the degree of total support in A, whileplðAÞcan be interpreted as the degree to which the evidence is consistent with A. Different combination rules have been proposed in the literature. Forexample, theconjunctive rule[32] and the dualdisjunctive rule[33] are deﬁned, respectively, as
(3a)
(3b)for any two mass functionsm
1andm 2on the same frameΩand allA/C18Ω. As shown by Smets [33], the conjunctive rule assumes that all massfunctions to be combined are derived from reliable sources of informa-tion, whereas the disjunctive rule only assumes that at least one source ofinformation is reliable, but we do not know which one. Dempster's rule,denoted by/C8,i sd eﬁned by the conjunctive rule (3a) followed bynormalization (2), i.e.,ðm
1/C8m 2Þð∅Þ¼0 and
(4)for allA6¼∅.TheDubois-Prade (DP) rule[15] assumes that when two sources arenot in conﬂict, they are both reliable, and at least one is correct whenthey are conﬂicting. Speciﬁcally, for two mass functionsm
1andm 2, their combination by the DP rule, denoted by m
1⊞m 2,i sðm
1⊞m 2ÞðAÞ¼X
B\C¼AB\C6¼∅m1ðBÞm 2ðCÞþX
B[C¼AB\C¼∅m1ðBÞm 2ðCÞ;8A6¼∅:(5)It can be seen as a reasonable trade-off between the conjunctive anddisjunctive rules.Let us now assume that mass function mrepresents our current state of knowledge about
ω, and we need to choose one or several elements ofΩas our estimate about the true answer. Decision rules in the DSframework are reviewed in Ref. [7]. Here, we only mention two rules thatwill be used in the sequel. Themaximum plausibility ruleselects the element
ω/C3with the highest plausibility,
ω/C3¼argmax
ω2ΩplðfωgÞ: (6)This rule yields one single result. In contrast, the interval dominance rule[7] is based on the following dominance relation:
ωdominates ω0, iff belðf
ωgÞ>plðf ω0gÞ. Then the set of its maximal (non-dominated) ele-ments can be obtained asΩ
/C3¼fω2Ωjplðf ωgÞ/C21belðf ω0gÞ;8ω02Ωg:(7) Instead of reaching a single decision, this rule selects a set of potentialresults.2.2. Credal partitionsLetObe a set ofnobjects, andΩ¼f
ω1;…;ωcgthe set of clusters. Each object is assumed to belong to at most one cluster. Uncertain knowledgeabout the cluster-membership of object o
iis represented by a mass func- tionm
ionΩ.Acredal partition[12]i sd eﬁned as ann-tupleM¼ðm 1; ::; m
nÞ. The notion of credal partition is more general than those of hard orfuzzy partitions, and a credal partition can be summarized into a parti-tion of any other type [9]. Credal partitions also encompass rough par-titions as a special case [14,30]: a rough partition corresponds to a credalpartition in which all mass functions m
iare logical, namelym iðAiÞ¼1for someA
i/C18Ω. Thelower and upper approximationsof cluster ωkcan then beF. Li et al. Array 6 (2020) 100018
2deﬁned as follows,
ωLk¼fo i2OjA i¼fωkgg (8a)and
ωUk¼fo i2Ojωk2A ig: (8b) For a non-logical mass functionm
i, the setA ican be selected by the interval dominance rule (7), after which a rough partition can beobtained.Supposem
iandm jare two mass functions related to objects iandj.W e consider the frameΘ
ij¼fs ij;:sijg, wheres ijmeans that“Objectsiandj belong to the same cluster”, and:s
ijmeans that“Objectsiandjbelong to different clusters”. A mass functionm
ijonΘ ijrepresenting our beliefs about the joint cluster-membership of objects iandjcan be computed fromm
iandm jas follows [11]:m
ijð∅Þ¼m ið∅Þþm jð∅Þ/C0m ið∅Þm jð∅Þ;(9a)m
ij/C0/C8s
ij/C9/C1¼X
k¼1miðfωkgÞm jðfωkgÞ;(9b)m
ij/C0/C8:s
ij/C9/C1¼X
A\B¼∅miðAÞm jðBÞ/C0m ijð∅Þ;(9c)m
ij/C0Θ
ij/C1¼X
A\B6¼∅miðAÞm jðBÞ/C0m ij/C0/C8s
ij/C9/C1;(9d)The tupleℛ¼ðm
ijÞ1/C20i/C20j/C20n is called therelational representationofM. We note thatm
ijð∅Þ¼0wheneverm ið∅Þ¼0andm jð∅Þ¼0. Given two credal partitionsMandM
0and their relational representationsℛand ℛ
0,thecredal Rand index[11]i sd eﬁned as
ρSð0Þ¼1/C0P
i<jδ/C16m ij;m0
ij/C17nðn/C01Þ=2; (10)whereδis the Jousselme's distance [20]. In the special case where mass functions are normal, i.e.,m
ijð∅Þ¼m0
ijð∅Þ¼0, we can write mass functionm
ijas a vectorm
ij¼/C0m ij/C0/C8s
ij/C9/C1;m
ij/C0/C8:s
ij/C9/C1;m
ij/C0Θ
ij/C1/C1T:Jousselme's distance betweenm
ijandm0
ijis then deﬁned asδ/C16m
ij;m0
ij/C17¼/C1812/C0m
ij/C0m0
ij/C1TJ/C0m ij/C0m0ij/C1/C191=2
;whereJis the Jaccard matrixJ¼0@10 1=201 1=21=21=211A: (11)The range of
ρSis½0;1/C138, and it boils down to the Rand index when bothMandM
0are hard partitions. The credal Rand index measures the simi-larity between any two soft partitions.2.3. Intuitionistic fuzzy equivalence relationFuzzy relations.In classical set theory, an equivalence relation pro-vides a partition of the underlying set into disjoint equivalence classes. Infuzzy set theory, afuzzy relation Ron aﬁnite setXis deﬁned as a fuzzy subset of the Cartesian product X
2, i.e., a mapping fromX2to Ref.½0;1/C138[29]. Each membership valueRðx;yÞrepresents the degree to whichxstands in relationRwithy. For a fuzzy relationR,w ed eﬁne the following properties:Reflexivity:For allx2XRðx;xÞ¼1Irreflexivity: For allx2XRðx;xÞ¼0Symmetry: For allðx;yÞ2X2Rðx;yÞ¼Rðy;xÞTransitivity: For allðx;y;zÞ2X
3minðRðx;yÞ;Rðy;zÞÞ/C20Rðx;zÞ Furthermore,Risdual transitiveiff 1/C0Ris transitive. If a fuzzy rela- tion is reﬂexive, symmetric and transitive, it is called a fuzzy equivalence relation.Sometimes, another triangular norm (t-norm) than the minimum isused in the deﬁnition of transitivity. For a t-norm T,Ris said to beT- transitiveif for allðx;y;zÞ2X
3,TðRðx;yÞ;Rðy;zÞÞ /C20Rðx;zÞ:Themax-T compositionfor two fuzzy relationsRandQonXis the fuzzy relationR∘Qdeﬁned byðR∘QÞðx;yÞ¼max
z2XTðRðx;zÞ;Qðz;yÞÞ:(12)DenotingR∘RasR
2, theT-transitivity property can be expressed asR
2/C18R.The max-Ttransitive closure
Rof a fuzzy relationRis the smallest max-Ttransitive fuzzy relation containing R. It can be computed as
R¼[∞i¼1Ri; (13)where[is the fuzzy set union based on the maximum t-conorm. Inparticular, ifRis a reﬂexive and symmetric fuzzy relation on aﬁnite setX of cardinalityn, then
R¼Rn/C01[4].Intuitionistic Fuzzy relations.The notion ofIntuitionistic Fuzzy Relation (IFR) is a further generalization of relations based on the theory ofintuitionistic fuzzy sets [22]. An intuitionistic fuzzy subset (IFS) AofXis a pair of mappings
μA:X→½0;1/C138and νA:X→½0;1/C138such that μAðxÞþ
νAðxÞ/C201for eachx2X. The values μAðxÞand νAðxÞrepresent, respec- tively, the membership degree and non-membership degree of element x in the setA. The pairð
μAðxÞ;νAðxÞÞis called an intuitionistic fuzzy value(IFV).LetLbe the set of all IFVs, i.e.,L¼f
α¼ðμα;ναÞjμα2½0;1/C138; να2½0;1/C138;
μαþνα/C201g. A partial ordering relation onLcan be deﬁned as follow:
α/C20Lα0⇔μα/C20μα'and να/C21να';for allð
α;α0Þ2L2. Any pairð α;α0Þ2L2has a unique least upper bound
α_α0and a unique greatest lower bound α^α0given, respectively, by
α_α0¼ðmaxð μα;μα'Þ;minð να;να'ÞÞand
α^α'¼ðminð μα;μα'Þ;maxð να;να'ÞÞ:ThusðL;/C20
LÞis a complete lattice, with topð1;0Þand bottomð0;1Þ. An IFR on a non-empty setXis an IFS ofX
2, i.e., a mappingR:X2→L. For an IFRRwe deﬁne the following properties:Reflexivity: For allx2XRðx;xÞ¼ð1;0Þ;Symmetry: For allðx;yÞ2X
2Rðx;yÞ¼Rðy;xÞ;Transitivity: For allðx;y;zÞ2X
3Vy2XðRðx;yÞ^Rðy;zÞÞ/C20 LRðx;zÞ; Ar eﬂexive, symmetric and transitive IFR is called an Intuitionistic Fuzzy Equivalence Relation(IFER). An IFRR¼ð
μR;νRÞis an IFER if and only if
μRis reﬂexive, symmetric and transitive, and νRis irreﬂexive,F. Li et al. Array 6 (2020) 100018
3symmetric and dual transitive [22]. Consequently, the transitivity of anIFR can be obtained by making
μRand 1/C0 νRtransitive. In the experiments reported in Section4, we consider three t-norms: the minimum, theproduct, and the Lukasiewicz t-norm deﬁned asTða;bÞ¼maxð0;aþb/C0 1Þ.2.4. Evidence Accumulation ClusteringIn this section, we brieﬂy summarize the EAC method [16,17]. More details can be found in Refs. [18,38,42]. The EAC method uses the co-association matrixto avoid the label correspondence problem. Moreprecisely, assume that a dataset has nobjectsO¼fo
1;o2;…;o ng. Suppose thatNbase partitionsP
1;…;PNhave been obtained in theﬁrst step. In the second step, each base partitionP
bis mapped to a co-association matrix S
bof sizeN/C2Nwith general termsbij¼Iðcbi¼cbjÞ;wherecbiis the cluster index ofx
iinPbandIis the indicator function. The co-association matrix,denoted asS
/C3¼ðs/C3ijÞ, is the average of allSb; its general term iss
/C3ij¼1NXNb¼1sbij: (14)Each elements
/C3ijrepresents the proportion of base partitions in whichobjectso
iando jare assigned to the same cluster. The co-association ma-trix can be treated as a new similarity matrix and used as input to single-linkage hierarchical clustering.In EAC, the co-association matrix is computed by only taking intoaccount whether two objects belong to the same cluster or not. Someresearchers [19,37,40] have proposed to use additional information toconstruct a similarity measure that is more expressive about the rela-tionship between objects. For instance, Yang [ 41] proposed a fuzzy co-association matrix to summarize the ensemble of fuzzy partitions,where the membership of an object to clusters is expressed by a fuzzymembership function.We can remark that, in the EAC method, the numbers of clusters in thebase partitions do not need to be close to the “true”number of clusters. Indeed, in Ref. [17], the authors construct the base partitions using thek-means algorithms with a large (and sometimes random) number ofclusters. For instance, in one dataset with two clusters, they constructbase partitions with up to 80 clusters. The underlying assumption is thatobjects that truly belong to true same cluster are likely to be assigned tothe same cluster in different partitions, which is summarized in theco-association matrix. The number of clusters in the ﬁnal aggregated partition is determined by analyzing the dendrogram after applyingsingle-link hierarchical clustering to the co-association matrix.In this paper, we propose to extend the EAC method in the frameworkof DS theory. In our method, the membership of an object to clusters isrepresented by a mass function in the credal partition, which containsmore information than fuzzy and hard partitions. To better exploit thistype of information, we use the relational interpretation recalled inSection2.2to measure the“similarity”between objects, which can be seen as a generalization of the co-association matrix. To capture theneighborhood relationship, we make the combined relational represen-tation transitive based on IFR theory recalled in Section 2.3.2.5. Other related workIn the ensemble clustering literature, most contributions focus onhard partitions, and some are based on fuzzy partitions. Only a fewmethods are based on DS theory. DS theory is a sound approach forensemble clustering methods, because it provides ways to combinedifferent pieces of evidence. Preliminary results have already demon-strated the feasibility of this approach. For example, in Refs. [ 13,28] the authors propose to deﬁne mass functions on the lattice of interval par-titions of a set of objects; they obtain a consensus belief function by asuitable combination rule, and use hierarchical clustering to get the ﬁnal partition. Unlike other direct methods relying on a voting process, Liet al. [24] introduce another direct approach based on Dempster's rule ofcombination; their method consists of two steps: ﬁnding the correspon- dence labels and using the combination rule to produce the ﬁnal result. Although these ensemble clustering methods are rooted in Dempster'stheory, they still consider hard partitions as input and also output of theprocedure. Wang et al. [39] propose an ensemble clustering method forevidential partitions. After solving the label correspondence problem, theﬁnal results are obtained by combining the selected base partitions. Dueto high computational complexity, they only consider the ﬁxed (true) number of clusters in the base partitions.In this paper, we combine credal partitions, a very general form ofpartitions that can be generated by hard, fuzzy, rough or evidentialclustering algorithms. After mapping the base partitions to their rela-tional representations, we combine these partitions in a coarser frame,where we only need to consider two focal sets. The combined relationalrepresentation is made transitive using the theory of IFRs. Finally, wegenerate an evidential partition that matches the combined relationalrepresentation, providing a much more informative output than can beobtained using hard or fuzzy clustering methods.3. Evidential clustering ensemble methodIn this section, we introduce the proposed method. The generationand combination of base credal partitions are described in Section 3.1. The computation of transitive closures to make the combined relationalrepresentation transitive is then addressed in Section 3.2, and the method for computing theﬁnal credal partition is presented in Section 3.3.3.1. Generation of base partitionsIn theﬁrst step of our method, base partitions can be obtained byhard, fuzzy and rough clustering methods, which all produce specialforms of credal partitions. In this paper, we focus on base partitionsgenerated by evidential clustering methods. We assume that we startwithNbase partitionsM
b¼ðmb1;…;mbnÞ,b¼1;…;Ngenerated by evidential clustering algorithms such as ECM or EVCLUS. The number ofclusters in base partitionbis denoted byk
b. Before converting credal partitions to their relational representations, we compute the averagemass assigned to the empty set for each object iasbm
ið∅Þ¼1NXNb¼1mbið∅Þ;i¼1;…;n;(15)and we normalize each base credal partition by (2). We denote the b-th normalized credal partition asM
b*¼ðmb*1;…;mb*nÞ, wheremb*iis the normalized mass function deﬁned bym
b*ið∅Þ¼0andm
b*iðAÞ¼mbiðAÞ1/C0m
bið∅Þ; (16)for all nonempty subsetAofΩ. The reason for this normalization is thatthe analogy between relation representations and IFRs developed inSection3.2requires the mass functions to be normalized. However, wecannot just discard the mass on the empty set, because it is useful todetect outliers. This information will be utilized in the last step of ourmethod (see Section3.3).After the relational representationsℛ
b*have been computed, they can be combined using different rules. The combined relational representa-tion is denoted byℛ
/C3¼ðm/C3ijÞ1/C20i/C20j/C20n . For example, using the average rulewe getF. Li et al. Array 6 (2020) 100018
4m/C3ij¼1NXNb¼1mb*ij:We can remark that, when the base partitions are hard, the n/C2 nmatrix with general term½m
/C3ijðfsgÞ/C138boils down to the co-association matrix (14). As a consequence, EAC is a special case of our method.Other combination rules introduced in Section 2.1can also be used.3.2. TransitivityThe combined relational representationℛ
/C3sometimes cannot be successfully exploited because it lacks a notion of transitivity, namely: ifwe believe that objectsiandjbelong to the same cluster, and objects j andkalso belong to the same cluster, then we should believe that this isalso the case for objectsiandk. When applying hierarchical clustering inthe second step, this property is used implicitly in the EAC method.A relational representation is not a classical fuzzy relation, because itspeciﬁes two numbers for each pairði;jÞ; the degree of belief thatiandj belong to the same cluster, and the degree of belief that they do notbelong to the same cluster. We can observe the similarity between thiskind of information and IFRs recalled in Section 2.3. Using this formal analogy, we consider the combined relational representation ℛ
/C3as an IFR, and we make it transitive using the techniques reviewed in Section2.3.For a normalized mass functionm
/C3ijonΘ ij, the degrees of belief in s
ijand:s ijare, respectively,bel
/C3ij/C0/C8s
ij/C9/C1¼m/C3ij/C0/C8s
ij/C9/C1andbel
/C3ij/C0/C8:s
ij/C9/C1¼m/C3ij/C0/C8:s
ij/C9/C1;withbel
/C3ijðfsijgÞþbel/C3ijðf:s ijgÞ/C201. These numbers deﬁne an IFRR¼ð μR;
νRÞon the setOof objects, with
μR/C0o
i;oj/C1¼bel/C3ij/C0/C8s
ij/C9/C1and
νR/C0o
i;oj/C1¼bel/C3ij/C0/C8:s
ij/C9/C1:This IFR is reﬂexive (asbel
/C3iiðfsiigÞ ¼1andbel/C3iiðf:s iigÞ ¼0for alli) and symmetric, but it is usually not transitive. As recalled in Section 2.3,Ris transitive iff
μRis transitive and νRis dual transitive, i.e., νdR¼1/C0 νRis transitive. To obtain an IFER, we thus need to replace
μRandνdRby their transitive closures. We observe that
νdR/C0o
i;oj/C1¼1/C0bel/C3ij/C0/C8:s
ij/C9/C1¼pl/C3ij/C0/C8s
ij/C9/C1:Denoting by
μRandνdRthe transitive closures of μRandνdR, let
belij/C0/C8s
ij/C9/C1¼μR/C0o
i;oj/C1and
plij/C0/C8s
ij/C9/C1¼νdR/C0o
i;oj/C1:These belief and plausibility values correspond to new mass functions
mijsuch that mijð∅Þ¼0and
mij/C0/C8s
ij/C9/C1¼belij/C0/C8s
ij/C9/C1; (17a)
mij/C0/C8:s
ij/C9/C1¼1/C0plij/C0/C8s
ij/C9/C1; (17b)
mij/C0Θ
ij/C1¼plij/C0/C8s
ij/C9/C1/C0belij/C0/C8s
ij/C9/C1:(17c)The new relational representationℛ¼ð mijÞ1/C20i/C20j/C20n will hereafter be referred to as thetransitivized combined relational representation .3.3. Recovering the combined credal partitionIn the EAC method, theﬁnal result is obtained by applying hierar-chical clustering to the association matrix. We could apply the sameprocedure to matricesð
belijðfsijgÞÞorð plijðfsijgÞ, similarly to what was proposed in Ref. [28]. However, our objective is to recover a credalpartition, which cannot be obtained by a hierarchical clusteringalgorithm.Our approach is toﬁnd a normalized credal partition M
/C3whose relation representation is as close as possible to the transitivized com-bined relational representation
ℛ, closeness being measured by thecredal Rand index (10). We need toﬁx the numberk
rof clusters as well as the focal sets in the credal partition M
/C3. For example, we can take the singletons andΩas focal sets, or we can also consider some pairs ofclusters.We thus seek a normal credal partition M
/C3, solution of the maximi- zation problemmax
M/C3ρSðℛðM/C3Þ;ℛÞ; (18)whereℛðM
/C3Þis the relational representation of M/C3. From (10), maxi- mizing (18) is equivalent to minimizing the following stress (error)function:SðM
/C3Þ¼X
i<j/C16m
/C3ij/C0mij/C17T
J/C16m/C3ij/C0mij/C17;(19)wherem
/C3ij¼/C16m/C3ij/C0/C8s
ij/C9/C1;m/C3ij/C0/C8:s
ij/C9/C1;m/C3ij/C0Θ
ij/C1/C17T
;
mij¼/C0mijðfsgÞ; mijðf:sgÞ; mij/C0Θ
ij/C1/C1T;andJis the Jaccard matrix (11). To solve (19), let us write m
/C3ijas a function of mass functionsm
/C3iandm/C3jin matrix form. Assuming that each massfunctionm
/C3ihasffocal setsF 1;…;F f, it can be written as anf-vectorm/C3i¼ ðm
/C3iðF1Þ;…;m/C3iðFfÞÞT, and the credal partition can be written as an n/C2 fmatrixM
/C3¼ðm/C31;…;m/C3nÞT. LetS¼ðS kℓÞandC¼ðC klÞbe thef/C2 fmatrices deﬁned as follows:S
kl¼/C261i fk¼landjFkj¼10 otherwise; (20)andC
kl¼/C261i fFk\F l¼∅;0 otherwise: (21)We have:m
/C3ij/C0/C8s
ij/C9/C1¼/C0m/C3i/C1TSm/C3j; (22a)m
/C3ij/C0/C8:s
ij/C9/C1¼/C0m/C3i/C1TCm/C3j; (22b)m
/C3ij/C0Θ
ij/C1¼1/C0m/C3ij/C0/C8s
ij/C9/C1/C0m/C3ij/C0/C8:s
ij/C9/C1:(22c) We can observe thatm
/C3ijis linear inm/C3iand, consequently,SðM/C3Þis quadratic inm
/C3i, the other mass functions beingﬁxed. Consequently, we can minimizeSðM
/C3Þusing a cyclic coordinate descent algorithm, mini-mizingSðM
/C3Þwith respect to eachm/C3iin turn, while keeping the otherm
/C3jconstant; this is the iterative row-wise quadratic programming (IRQP)algorithm [35], also used in Ref. [14]. Using this approach, we minimizeF. Li et al. Array 6 (2020) 100018
5at each step the following cost function:g
i/C0m/C3i/C1¼Xnj¼1j6¼i/C16m
/C3ij/C0mij/C17T
J/C16m/C3ij/C0mij/C17;(23)which is quadratic inm
/C3i. To simplify the expression of this function, letus deﬁne the matrixA
jof size 3/C23fasA
j¼I 3/C10/C16m/C3j/C17T
: (24)whereI
3is the identity matrix of size 3/C23and/C10is the Kronecker product, and the matrixBof size 3f/C2fasB¼0@SC1/C0S/C0C1A: (25)with these notations, (23) can be written asg
iðmiÞ¼Xnj¼1j6¼i/C0A
jBm/C3i/C0mij/C1TJ/C0A jBm/C3i/C0mij/C1(26)Developing the right-hand side of (26) and rearranging the terms, weobtaing
i/C0m/C3i/C1¼/C0m/C3i/C1TΣm/C3iþuTm/C3iþc 0;(27)withΣ¼B
T0BBBB@X
j¼1j6¼iATjJAj1CCCCAB (28a)
u¼/C020BBBB@X
j¼1j6¼imTijJAj1CCCCAB (28b)c
0¼X
j¼1j6¼imTijJmij: (28c)Minimizinggðm
iÞunder the constraintsðm/C3iÞT1¼1(where 1¼ ð1;…;1Þ
T) andm/C3i/C210is a quadratic programming (QP) problem, whichcan be solved efﬁciently with any QP solver. As we iteratively updateeach row ofM
/C3, the overall stressSðM/C3Þdecreases and eventually reaches a local minimum. As in Ref. [14], we compute the following runningmean after each cycle of the algorithm as e
0¼1ande
t¼0:5e t/C01þ0:5jSt/C0S t/C01jS
t/C01; (29)wheretis the iteration counter andS
tis the error at iterationt. The al- gorithm stops whene
tbecomes less than some given threshold ε. LetbM
/C3¼ðbm/C31;…;bm/C3nÞdenote the normalized credal partition obtainedafter convergence of the algorithm. The last step is to “denormalize”it using the massesbmð∅Þon the empty set computed in (15). This is done bymultiplying each massbm
/C3ðAÞwithA6¼∅by 1/C0bmð∅Þ: bm
iðAÞ¼½1/C0bm ið∅Þ/C138bm/C3iðAÞ; (30)for allA22Ωnf∅g. Theﬁnal consensus credal partition isbM¼ðbm 1; …;bm
nÞ. The whole procedure is summarized in Algorithm 1.
Algorithm 1Summary of the method.
RequireNcredal partitionsMb¼ðmb1;…;mbnÞT,b¼1;…;N, combination rule, numberk
rof clusters and focal setsF 1;…;F fof the combined credal partition Computebm
ið∅Þ,i¼1;…;nusing (15)Normalize the base credal partitions by (16)Compute the base relational representationsℛ
b*¼ðmb*ijÞ,b¼1;…;N Compute the combined relational representationℛ
/C3¼ðm/C3ijÞR¼ð mijÞ t←0,e
0←1InitializeM
/C3randomly, compute its relational representationComputeS
0using (19)whilee
t/C21εdot←tþ1S
t←0fori¼1tondoComputeA
jfor allj6¼iusing (24)ComputeΣ,uandcusing (28)Findm
/C3ðtÞiby minimizing (27) subject toðm/C3iÞT1¼1andm/C3i/C210 Replace rowiofM
/C3byðm/C3ðtÞiÞT
St←S tþg iðm/C3ðtÞiÞend fore
t←0:5e t/C01þ0:5jS t/C0S t/C01j=St/C01
end whileLetbM
/C3¼ðbm/C31;…;bm/C3nÞwithbm/C3i¼m/C3ðtÞi,i¼1;…;n Denormalize the combined credal partition using (30)returnCredal partitionbM
Concerning the time complexity of the method, converting each basecredal partition to its relational representations requiresOðn
2Þoperations, wherenis the number of objects, and combining theaverage partition takesOðn
2NÞ. To compute the transitive closure, Lee[21] describes an optimal algorithm with Oðn
2Þtime complexity. Conse- quently, the calculation of the transitivized combined relational repre-sentation
ℛcan be performed inOðn2NÞoperations. The most computationally demanding step of the method is to recover the credalpartition from the obtained relational representation. The complexity ofthis step depends on the Quadratic Programming (QP) problem (27)solved at each iteration. As the Jaccard matrix (11) is positive de ﬁnite [5], so is matrixΣin (27) (of sizef/C2f, wherefis the number of focal sets). Consequently, the quadratic function (27) being minimized inconvex. It is known [36] that convex QP problems can be solved inpolynomial time. The computing time of the optimization can becontrolled by limited the number of focal sets in the recovered credalpartition.4. ExperimentsIn this section, we evaluate our approach using various datasets. InSection4.1, we study the inﬂuence of different parameters using simu-lated datasets. Detailed results with simulated and real datasets are thenreported in Section4.2.4.1. Qualitative experimentsIn this section, we present the results on simulated datasets toinvestigate different stages of the ensemble procedure. We study the ef-fect of different combination rules and transitive closure with different t-norms.Effect of different combination rulesWeﬁrst investigate the effect of different combination rules on theFourclassdata, consisting of four classes in two-dimensional space, eachgenerated from a Gaussian distribution. From Fig. 1a, we can see that theF. Li et al. Array 6 (2020) 100018
6Fig. 1.Results for theFourclassdata with different combination rules: original data (a), one of the base partitions (b), average rule (c), Dempster's rule (d), disjunctiverule (e), DP rule (f).F. Li et al. Array 6 (2020) 100018
7clusters overlap, and there is an outlier.In theﬁrst step, we ran the ECM algorithm [6,26] with theFourclass dataset for generating base partitions. To obtain useful information, weuse the two-step approach introduced in Refs. [ 14,34] to extract infor- mative focal sets. More precisely, the ECM algorithm was ﬁrst run with∅, the singletons andΩas focal sets. Based on the obtained credal partition,the similarity between each pairs of clusters f
ωj;ωlgwas measured bysðj; lÞ¼P
ni¼1plijplil, wherepl ijandpl ilare the normalized plausibility thatobjectibelongs, respectively, to clusterjandl. The pairsf
ωj;ωlgof mutual K¼2nearest neighbors were then selected as informative focal sets. Inthe second step, the evidential clustering initialized with the credalpartition computed in the previous step was run again with those infor-mative focal sets. In Ref. [14], this method has been shown to be tractableand to yield good results even when the number of clusters is large.In this experiment, we generated N¼20base partitions, each of which hadk
b¼15clusters, and we setδto the 0.2-quantile of the dis- similarities between objects. The diversity of the partitions is obtained bysetting the number of clusters to a large number and using differentrandom initializations. We considered the four combination rulesreviewed in Section2.1: average, Dempster, disjunctive and DP. Forsimplicity, after combining the relational representations we did notmake the corresponding IFR transitive. We recovered a credal partitionwith four clusters,k
r¼4. In the second step, weﬁrstly recovered a credal partition with the mass on the singletons and Ω, and secondly with the mass on the informative focal sets as we did in the generation step. One ofthe base partitions is shown inFig. 1b. InFig. 1b–f, each point is repre- sented by a symbol corresponding to its true class, and a color corre-sponding to the maximum plausibility cluster (6). The convex hulls of thelower and upper approximations computed using the interval dominancerule (7) are displayed using solid and broken lines, respectively.FromFig. 1d, we can see that Dempster's rule fails to capture thestructure of this dataset. As recalled in Section 2.1, important assump- tions for Dempster's rule are that all the mass functions come from reli-able and independent sources; it is clear that none of these assumptions issatisﬁed in our case. When generating the base partitions, the number ofclusters is set to a larger value than the number of “natural”clusters, and the base partitions, being based on the same data, are not independent.The DP rule behaves better than Dempster's rule, as it relaxed theassumption of perfect sources. However, the DP rule also cannot recog-nize the structure of the dataset (Fig. 1f). The average and disjunctive rules both yield acceptable results (Fig. 1c and e), but the credal partition obtained by the disjunctive rule is too imprecise: the inner approxima-tions of the clusters are very small and the upper approximations areidentical, which means that all objects possibly belong to any cluster(Fig. 1e). This result is due to the very cautious assumption underlyingthis combination rule (at least one source is reliable). In contrast, theaverage rule successfully identiﬁes the objects that can be clustered withhigh conﬁdence (those in the inner approximations), as well as the ob-jects in the overlapping area between clusters ( Fig. 1c). As the average rule appears to be the most effective, it was used in subsequentexperiments.Effect of transitive closure with different t-normsIn this section, we investigate the effect of transitive closure withrespect to different t-norms onHalf-ringsdata. This dataset is composed of two clusters in two-dimensional space, separated by a nonlinearboundary (Fig. 2a). Such non-spherical clusters are typically dif ﬁcult to identify without prior information. The parameter settings were the sameas before, except that we setk
b¼15,N¼20,k r¼2andδequal to the 0.1-quantile of the dissimilarities between objects in this experiment. Wecombined the relational representations by the average rule and madethe belief and plausibility matrix transitive with respect to the minimum,Lukasiewicz and product t-norms. We also considered the results withouttransitivity comparison. One of the base partitions is shown in Fig. 2b. The recovered partitions with the different transitive closureoperations are shown inFig. 2c–e, and the recovered partition withouttransitivity is displayed inFig. 2f. In theseﬁgures, each point is repre- sented by a symbol corresponding to its true class, and a color corre-sponding to the obtained cluster using the maximal plausibility rule. Wecan see that, without transitivity, our method fails to identifynonspherical clusters (Fig. 2f). The results with the Lukasiewicz t-normare similar to those without transitivity ( Fig. 2d). The best result is ob- tained with the minimum t-norm (Fig. 2c). Discovering clusters with complex shape is one of the most chal-lenging issues in clustering. In this experiment, we have show that ourmethod has the ability to discover such clusters after making the com-bined relational representation transitive in the sense of IFRs.4.2. Quantitative experimentsIn this section, we apply our method to the simulated and real datasummarized inTable 1. Five simulated datasets2are shown inFig. 3; the ﬁrst four datasets contain complex shape clusters, while R15contains a comparatively larger number of well-separated clusters. All the realdatasets can be found in the UCI Repository of machine learning data-bases.
3For all the datasets considered in this study, we assume that the“ground-truth”partition exists. To compare an evidential partition withthe true partition, weﬁrst converted it to a hard partition using themaximum plausibility rule, and we computed the adjusted Rand index(ARI) between the derived hard partition and the true partition.We used the ECM algorithm with informative pair of clusters togenerate base partitions for each dataset. We considered three cases forthe number of clusters in the base partitions ( Table 2):ﬁxed small number (case 1); randomly selected from an interval (case 2) and ﬁxed large number (case 3). We averaged the relational representations, andwe computed the transitive closure operations with the minimum,product and Lukasiewicz t-norms. We also included the solution withouttransitivity for comparison. The true number of clusters was assumed tobe known; in practice, this number can often be guessed using, e.g.,visualization techniques. When recovering the combined credal parti-tion, weﬁrst used only singletons andΩas focal sets (denoted by“simple” in the table), and then we included informative pairs informative pairs(denoted by“pairs”in the table) as explained in Section 4.1. The ensemble size wasN¼20. The procedure was run 10 times for eachexperiment. The average ARI values are shown in Table 3, and the standard deviations are shown in parentheses.For comparison, we show the results of the ECM algorithm with thetrue number of clusters. For this method, only∅and singletons were treated as focal sets, and weﬁxedδ¼100. We also compared our method with the EAC method: in theﬁrst step we used the hard c-means algorithm to obtainN¼100base partitions; in the second step, we usedsingle-linkage hierarchical clustering to obtain the true number of clus-ters. For the EAC method, we also considered three cases as we did in ourmethod. The results for the ECM algorithm and the EAC method areshown in theﬁrst and second columns ofTable 3. FromTable 3, we can see that the results obtained by our method arebetter than those obtained by the ECM algorithm, except for the Wine data. When compared to the EAC method, our method achieves higheraccuracy and better stability, especially for real datasets. The EACmethod performs very well with simulated datasets, but better or similarresults were obtained with our method, except for the Spiraldataset. Comparing the results obtained with different t-norms for the tran-sitive closure operation, we can see that the minimum t-norm oftenperforms well, except with theR15andSeedsdataset, for which better results are obtained with the other t-norms, or even without transitivity.The results with the Lukasiewicz and product t-norms are often similar tothose obtained without transitivity. Generally, it seems that making the
2Available athttp://cs.joensuu.ﬁ/sipu/datasets/.
3Available athttp://archive.ics.uci.edu/ml.F. Li et al. Array 6 (2020) 100018
8Fig. 2.Results forHalfringsdata: original data (a), one of base partitions (b), and recovered partition from transitive closures the minimum (c), Lukasiewicz (d) andproduct (e) t-norms, as well as without transitivity (f).F. Li et al. Array 6 (2020) 100018
9combined relational minimum-transitive is bene ﬁcial for datasets with complex-shaped clusters, but it can sometimes degrade the performancefor datasets with overlapping clusters. The reason is that, where there isan overlapping area between clusters and we make the fuzzy relationtransitive, objects from different clusters become similar to each other,which hinders the performance of the method. As far as the number ofclusters in the base partitions is concerned, better results are generallyobtained in Cases 2 and 3, i.e., with a larger number of clusters.5. ConclusionWe have presented a method for combining clusterings in the DSframework. Each base clustering is assumed to take the form of a credalpartition, in which the clustering membership of each object is allowed tobe uncertain and represented by a mass function. This very generalformalism encompasses hard, fuzzy and rough partitions as special cases[9]. Credal partitions of special forms can be generated by hard, fuzzy orrough clustering algorithms, and general credal partitions can be ob-tained by evidential clustering procedures such a EVCLUS [ 14], ECM [26], BPEC [34], CCM [25], etc.Base credal partitions cannot be combined directly, because there isnot always a clear correspondence between clusters in different parti-tions; in particular, base credal partitions can have different numbers ofclusters. To circumvent this difﬁculty, we proposed to convert each basecredal partition to its relational representation, de ﬁned as the collection of pairwise mass functions describing the uncertain joint cluster-membership for each pair of objects. After the normalized relationalTable 1Datasets used in the experiments.
Dataset Number of objects Number of clusters Number of attributesAggregation788 7 2Compound399 6 2Flame240 2 2Spiral312 3 2R15600 15 2Iris150 3 4Seeds210 3 7Wine178 3 13Ecoli307 4 5
Fig. 3.Simulated datasets: Aggregation (a), Compound (b), Flame (c), Spiral (d) and R15 (e).Table 2Number of clusters in base partitions.
Dataset Case 1 Case 2 Case 3Aggregation10 [10,20]2 0 Compound10 [10,20]2 0 Flame8[8,15]1 5 Spiral30 [30,40]4 0 R1520 [20,30]3 0 Iris8[8,15]1 5 Seeds5[5,10]1 0 Wine5[5,10]1 0 Ecoli8[8,15]1 5F. Li et al. Array 6 (2020) 100018
10representations have been computed, they can be aggregated using anycombination rule of DS theory. The best results have been obtained withthe averaging operator.Using the similarity between relational representations and intui-tionistic fuzzy relations studied in Ref. [ 22], we have proposed a way to transitivize the combined relational representation by computing thetransitive closures of two fuzzy relations, based on a t-norm. Ourexperimental results suggest that the minimum t-norm often yields thebest results, especially for datasets with complex-shaped clusters. How-ever, making the relational representation transitive does not alwaysimprove the results, and may even degrade them in the case of datasetswith many spherical clusters.After the combined relational representation has been computed, thelast step of our method consists in constructing a credal partition whoserelational representation is as close as possible to the combined relationalrepresentation obtained in the previous step. We have proposed an errormeasure based on Jousselme's metric, which can be minimized using agrouped coordinate descent algorithm that solves a convex quadraticoptimization problem at each step. After a normalized credal partitionhas been obtained, we“denormalize”it by assigning to the empty set the average of the masses assigned to the empty set by the base partitions,which provide useful information to signal outliers.We have applied this method to a variety of simulated and realdatasets. It has been shown to perform well in terms of adjusted Randindex as compared to the EAC method and to the ECM algorithm alone. Itshould also be emphasized that, in contrast with EAC and most existingensemble clustering methods, our approach computes a credal partition,which constitutes a richer description of the clustering structure of adataset, as compared to hard or fuzzy partitions.Although very encouraging, these results are still preliminary. Thedetermination of the number of clusters remains a crucial issue that re-mains to be thoroughly investigated. The application of this approach tovery big datasets with a large number of clusters still represents a chal-lenge. Finally, we could apply this approach not only to combine credalpartitions, but also to combine all kinds of partitions generated by allkinds of clustering algorithms. These research directions will be inves-tigated in future work.CRediT authorship contribution statementFeng Li:Methodology, Investigation, Writing - original draft. Shou- mei Li:Supervision, Funding acquisition.Thierry Denœux:Conceptu- alization, Methodology, Writing - review&editing, Supervision.References
[1]Akbari E, Dahlan HM, Ibrahim R, Alizadeh H. Hierarchical cluster ensembleselection. Eng Appl Artif Intell 2015;39:146 –56. [2]Antoine V, Quost B, Masson M-H, Denoeux T. CECM: constrained evidential c-means algorithm. Comput Stat Data Anal 2012;56(4):894 –914. [3]Antoine V, Quost B, Masson M-H, Denoeux T. CEVCLUS: evidential clustering withinstance-level constraints for relational data. Soft Computing 2014;18(7):1321 –35. [4]Boixader D, Jacas J, Recasens J. Fuzzy equivalence relations: advanced material. In:Dubois D, Prade H, editors. Fundamentals of fuzzy sets. Boston: Kluwer AcademicPublishers; 2000. p. 261–90. [5]Bouchard M, Jousselme A-L, Dor /C19e P-E. A proof for the positive deﬁniteness of the Jaccard index matrix. Int J Approx Reason 2013;54(5):615 –26. [6] Denœux T. evclust: evidential Clustering. R package version 1.0.3. URL,https://CRAN.R-project.org/package=evclust ; 2016. [7]Denoeux T. Decision-making with belief functions: a review. Int J Approx Reason2019;109:87–110.[8]Denœux T, Dubois D, Prade H. Representations of uncertainty in arti ﬁcial intelligence: beyond probability and possibility. In: Marquis P, Papini O, Prade H,editors. A guided tour of artiﬁcial intelligence research. Springer Verlag; 2020. Ch. 4.[9]Denoeux T, Kanjanatarakul O, September. Beyond fuzzy, possibilistic and rough: aninvestigation of belief functions in clustering. In: Soft methods for data science(proc. Of the 8th international conference on soft methods in probability andstatistics SMPS 2016). Vol. AISC 456 of advances in intelligent and soft computing.Rome, Italy: Springer-Verlag; 2016. p. 157 –64. [10]Denoeux T, Kanjanatarakul O, Sriboonchitta S. EK-NNclus: a clustering procedurebased on the evidential k-nearest neighbor rule. Knowl Base Syst 2015;88:57 –69. [11]Denoeux T, Li S, Sriboonchitta S. Evaluating and comparing soft partitions: anapproach based on Dempster-Shafer theory. IEEE Trans Fuzzy Syst 2018;26(3):1231–44.[12]Denœux T, Masson M-H. EVCLUS: evidential clustering of proximity data. IEEETrans Syst Man Cybern B Cybern 2004;34(1):95 –109. [13]Denœux T, Masson M-H. Evidential reasoning in large partially ordered sets. AnnOper Res 2011;195(1):135–61. [14]Denœux T, Sriboonchitta S, Kanjanatarakul O. Evidential clustering of largedissimilarity data. Knowl Base Syst 2016;106:179 –95
. [15]Dubois D, Prade H. Representation and combination of uncertainty with belieffunctions and possibility measures. Comput Intell 1988;4(3):244 –64.Table 3Average ARI results for simulated and real datasets. The best results are shown in bold.
ECM EAC minimum Lukasiewicz product no transitivitysimple pairs simple pairs simple pairs simple pairs [b]Aggregationcase 1 0.68(0.05) 0.81(0.06) 0.83(0.08)0.73(0.08) 0.72(0.07) 0.72(0.07) 0.79(0.07) 0.82(0.09) 0.72(0.06) 0.71(0.05) [t] case 2 0.87(0.04) 0.97(0.04)0.95(0.07) 0.69(0.05) 0.67(0.05) 0.82(0.07) 0.76(0.05) 0.76(0.06) 0.7(0.05) case 3 0.91(0.07) 0.98(0.01) 0.98(0.01) 0.73(0.04) 0.71(0.05) 0.81(0.08) 0.77(0.06) 0.74(0.03) 0.73(0.04) [b] Compoundcase 1 0.53(0.09) 0.65(0.09) 0.78(0.02)0.72(0.03) 0.52(0.01) 0.52(0.01) 0.51(0.04) 0.5(0.06) 0.52(0.04) 0.52(0.04) [t] case 2 0.86(0.03) 0.87(0.04)0.78(0.07) 0.48(0.06) 0.49(0.05) 0.5(0.04) 0.47(0.06) 0.49(0.05) 0.49(0.05) case 30.89(0.01)0.73(0.1)0.88(0.05)0.41(0.02) 0.41(0.02) 0.45(0.06) 0.45(0.06) 0.42(0.04) 0.39(0) [b] Flamecase 1 0.49(0) 0.93(0) 0.9(0.02) 0.9(0.02) 0.75(0.14) 0.75(0.14) 0.92(0.01) 0.92(0.01) 0.79(0.05) 0.79(0.05) [t] case 2 0.19(0.39) 0.91(0.02) 0.91(0.02) 0.69(0.33) 0.69(0.33) 0.93(0.04) 0.93(0.04) 0.82(0.03) 0.82(0.03) case 3/C00.01(0.06)0.92(0.01) 0.92(0.01) 0.47(0.25) 0.47(0.25) 0.66(0.23) 0.66(0.23) 0.53(0.3) 0.53(0.3) [b] Spiralcase 1 0.01(0)1(0)0.82(0.21) 0.72(0.28) 0.01(0) 0.01(0) 0.01(0.01) 0.01(0) 0.01(0) 0.01(0) [t] case 21(0)0.88(0.16) 0.87(0.16) 0.03(0.01) 0.03(0.01) 0.05(0.03) 0.03(0.01) 0.04(0.04) 0.04(0.01) case 31(0)0.96(0.06) 0.76(0.19) 0.08(0.06) 0.11(0.07) 0.14(0.02) 0.14(0.11) 0.06(0.04) 0.03(0.01) [b] R15case 1 0.93(0.07)0.99(0)0.56(0.12) 0.57(0.08) 0.99(0) 0.99(0) 0.98(0.03) 0.97(0.03) 0.99(0) 0.99(0)[t] case 20.99(0)0.67(0.09) 0.62(0.07) 0.99(0) 0.99(0) 0.99(0) 0.99(0) 0.99(0) 0.99(0) case 30.99(0)0.86(0.02) 0.66(0.11) 0.99(0) 0.99(0) 0.99(0) 0.99(0) 0.99(0) 0.99(0) [b] Iriscase 1 0.73(0) 0.6(0.04) 0.7(0.03) 0.69(0.05) 0.84(0.03) 0.8(0.04) 0.86(0.03)0.85(0.03) 0.84(0.03) 0.8(0.03) [t] case 2 0.57(0) 0.76(0.06) 0.68(0.04) 0.79(0.05) 0.73(0.02) 0.8(0.05) 0.75(0.03) 0.82(0.05)0.74(0.02) case 3 0.57(0) 0.85(0.04)0.78(0.04) 0.77(0.05) 0.7(0.03) 0.76(0.03) 0.7(0.03) 0.74(0.11) 0.69(0.03) [b] Seedscase 1 0.78(0.01) 0.29(0.09) 0.48(0) 0.48(0.02) 0.78(0.01) 0.78(0.02) 0.78(0) 0.79(0)0.78(0.01) 0.78(0.01) [t] case 2 0.22(0.08) 0.72(0.03) 0.66(0.08) 0.77(0.02) 0.78(0.02)0.75(0.01) 0.75(0.02) 0.78(0.02)0.77(0.02) case 3 0.24(0) 0.73(0.09) 0.55(0.07) 0.77(0.02)0.72(0.04) 0.74(0.03) 0.7(0.04) 0.76(0.04) 0.7(0.06) [b] Winecase 10.9(0)0.35(0.24) 0.66(0.18) 0.8(0.09) 0.71(0.13) 0.88(0.02)0.78(0.18) 0.85(0.07) 0.77(0.16) 0.87(0.01) [t] case 2 0.09(0.2) 0.78(0.09)0.73(0.13) 0.68(0.17) 0.7(0.17) 0.73(0.18) 0.73(0.21) 0.7(0.16) 0.69(0.13) case 3 0.17(0.23) 0.83(0.05) 0.83(0.05) 0.58(0.17) 0.58(0.17) 0.78(0.1) 0.8(0.07) 0.71(0.19) 0.72(0.19) [b] Ecolicase 1 0.52(0) 0.47(0.16) 0.57(0.07) 0.62(0.1) 0.64(0.09) 0.62(0.09) 0.65(0.09)0.6(0.09) 0.62(0.09) 0.62(0.09) [t]
case 2 0.51(0.04) 0.6(0.08) 0.55(0.11) 0.62(0.1) 0.63(0.1) 0.66(0.08) 0.67(0.07) 0.69(0.06)0.69(0.07) case 3 0.48(0.01) 0.45(0.11) 0.47(0.13) 0.62(0.13) 0.63(0.11)0.62(0.14) 0.62(0.1) 0.62(0.1) 0.61(0.1) [b]F. Li et al. Array 6 (2020) 100018
11[16]Fred ALN, Jain AK. Data clustering using evidence accumulation. In: Internationalconference on pattern recognition; 2002. p. 276 –80. [17]Fred ALN, Jain AK. Combining multiple clusterings using evidence accumulation.IEEE Trans Pattern Anal Mach Intell 2005;27(6):835 –50. [18]Ghaemi R, Sulaiman m n, Ibrahim H, Mustapha N. A survey: clustering ensemblestechniques. World Acad Sci Eng Technol 2009;38:644 –53. [19]Iam-on N, Boongoen T, Garrett S. Re ﬁning pairwise similarity matrix for cluster ensemble problem with cluster relations. Discovery Science 2008:222 –33. [20]Jousselme A-L, Grenier D, Boss /C19e E. A new distance between two bodies of evidence. Inf Fusion 2001;2(2):91–101. [21]Lee H-S. An optimal algorithm for computing the max-min transitive closure of afuzzy similarity matrix. Fuzzy Set Syst 2001;123(1):129 –36. [22]Li B, He W. The structures of intuitionistic fuzzy equivalence relations. Inf Sci 2014;278:883–99.[23]Li F, Li S, Denoeux T. k-CEVCLUS: constrained evidential clustering of largedissimilarity data. Knowl Base Syst 2018;142:29 –44. [24]Li F, Qian Y, Wang J, Liang J. Multigranulation information fusion: a Dempster-Shafer evidence theory-based clustering ensemble method. Inf Sci 2017;378:389–409.[25]Liu Z, Pan Q, Dezert J, Mercier G. Credal c-means clustering method based on belieffunctions. Knowl Base Syst 2015;74:119 –32. [26]Masson M-H, Denoeux T. ECM: an evidential version of the fuzzy c-meansalgorithm. Pattern Recogn 2008;41(4):1384 –97. [27]Masson M-H, Denœux T. RECM: relational evidential c-means algorithm. PatternRecogn Lett 2009;30(11):1015 –26. [28]Masson M-H, Denoeux T. Ensemble clustering in the belief functions framework. IntJ Approx Reason 2011;52(1):92 –109. [29]Ovchinnikov S. An introduction to fuzzy relations. In: Dubois D, Prade H, editors.Fundamentals of fuzzy sets. Boston: Kluwer Academic Publishers; 2000. p. 233 –59. [30]Peters G, Crespo F, Lingras P, Weber R. Soft clustering: fuzzy and rough approachesand their extensions and derivatives. Int J Approx Reason 2013;54(2):307 –22.[31]Shafer G, et al. A mathematical theory of evidence. Princeton university press;1976.[32]
Smets P. The combination of evidence in the transferable belief model. IEEE TransPattern Anal Mach Intell 1990;12(5):447 –58. [33]Smets P. Belief functions: the disjunctive rule of combination and the generalizedbayesian theorem. Int J Approx Reason 1993;9(1):1 –35. [34]Su Z-G, Denoeux T. BPEC: belief-peaks evidential clustering. IEEE Trans Fuzzy Syst2019;27(1):111–23.[35]ter Braak CJF, Kourmpetis Y, Kiers HAL, Bink MCAM. Approximating a similaritymatrix by a latent class model: a reappraisal of additive fuzzy clustering. ComputStat Data Anal 2009;53(8):3183 –93. [36]Vavasis SA. Complexity theory: quadratic programming. Boston, MA: Springer US;2001. p. 304–7.[37]Vega-Pons S, Ruiz-Shulcloper J. Clustering ensemble method for heterogeneouspartitions. Progress in pattern recognition, image analysis, computer vision, andapplications, 5856; 2009. p. 481 –8. [38]Vega-Pons S, Ruiz-Shulcloper J. A survey of clustering ensemble algorithms. Int JPattern Recogn Artif Intell 2011;25(3):337 –72. [39]Wang X, Han D, Han C. Ensemble clustering based on evidence theory. In: 201720th international conference on information fusion (fusion); 2017. p. 759 –67. [40]Wang X, Yang C, Zhou J. Clustering aggregation by probability accumulation.Pattern Recogn 2009;42(5):668 –75. [41]Yang L, Lv H, Wang W. Soft cluster ensemble based on fuzzy similarity measure.IMACS: multiconference on computational engineering in systems applications, 1;2006. p. 1994–7. 2.[42]Zhan J-M, Chen J-T, Xing J-Q. Research advance of clustering ensemble algorithm.In: 2017 international conference on wavelet analysis and pattern recognition(ICWAPR); 2017. p. 109–14. [43]Zhou K, Martin A, Pan Q, Liu Z-G. Median evidential c-means algorithm and itsapplication to community detection. Knowl Base Syst 2015;74:69 –88.F. Li et al. Array 6 (2020) 100018
12