 AASRI Procedia   1  ( 2012 )  293 ‚Äì 298 
2212-6716 ¬© 2012 Published by Elsevier Ltd. doi: 10.1016/j.aasri.2012.06.045 
 
2012 AASRI Conference on Computational Intelligence and Bioinformatics 
The 3D Data Extraction for Hip Joint Based on CT 
Luo Sandinga,*, Zou Zhenga, Chen Yuanbinga, Liu Qianlana 
College of Information Science and Engineering, Central South University, Changsha 410083, China   
Abstract 
The 3D data can be extracted by measuring healthy hip joint, which is the basis of making proper artificial hip conform to right physiological characteristics. In this paper, firstly, we use adaptive windows directed by neighbouring CT slices for reducing ranges of searching. Secondly, a method based on 2D contour characteristic points matching in multilayer is proposed to effectively correct contours. Thirdly, according to complexity in the primary contours, location and fitting quasi-circular contours femur head with circle are used to adjust contours of femur head. Finally, a projecting method based on distance transform has been used for locating key points of hip joint such as intersection of head and neck, which meets anatomy features, can obtain effective and efficient 3D data. In fact, experiment in this paper shows that the method in paper can accurately extract 3D data on proximal femur in CT Series Images.  
 ¬© 2012 Published by Elsevier B.V. Selection and/or peer review under responsibility of  American Applied Science Research Institute  
Keywords: Hip  Joint; CT images Process; 3D data extraction 
1. Introduction Hip joint consists of femur head, neck and backbone. Femur head is the round end between femur and pelvic bone, surrounding by muscles. It looks like circu larity in appearance. Femur neck is smaller which connects femur head and femur backbone. Femur below femur neck appears tubular. In order to make artificial hip fit the biological and physical characteristics, and matching the structure of acetabular bone better, 
 
 
* Luo Sanding. Tel.: +86-13187066098. E-mail address: sdluo88@gmail.com. 
AASRI
Procedia
www.elsevier.com/locate/procediaAvailable online at www.sciencedirect.com
Open access under CC BY-NC-ND license.
Open access under CC BY-NC-ND license.294   Luo Sanding et al.  /  AASRI Procedia   1  ( 2012 )  293 ‚Äì 298 
it is necessary to fully understand the pattern of hip join t. Extracting some information from hip surface is the foundation and basis of making artificial hip fit patients. Extracting hip contour is the premise of 3D data extr acting. The segmentation of bones is difficult because of the irregular physiology bones structure, fuzziness of the contour line caused by conjunction of femur head and acetabular bone, low contrast and noise etc. No-seed region segmentation is employed in [1], this method is very useful since there are some holes in the region  which can be ignored, but it depends on initial value too much. Non parameter Level Set method for image segm entation which proposed in [2] has great adaptability for images with low contrast, however it is complicated to calculate. In [3] the solution is introduced that extracting the dental contours from frame to frame with region growing method combined with radial line method. The new solution can get good segmentation if quasi circular bone parameters are fixed and interactive input is specific, but it seems not adaptiv e enough to resolve quasi circular femur segmentation with flexible radius, so its level of automation is not high. In view of the shortcomings of the former study, th e paper proposes a method which extracts data based on associated interframe tracing based on interlayer pilot 2D  contour characteristic combined with bidirectional contour information fusion, then it can quickly extract accurate 3D data on the femur surface. 2. Primary Contours Extraction Some processes of original images based on gray level an d border are useful to reduce the noises and errors that produced by shape mutations of bones. 2.1. Primary contour determination The border tracking method [4] is improved to g et primary contours, through searching clockwise the border of bone continuously till coming back to beginn ing position, then recording the subsequence of border points, combined to internal or external situation again st border can determine border. However, this method gets more than one external border in a slice. Considering area occupied by required bone is bigger than other bones in ROI, we can pick the right border with ca lculating the biggest area as the primary contour. Meanwhile, by normalizing the contour point information, the 2-dimensional position data can be reduced to 1-dimensional one. 3.  Determining Series Contours With Interframe Tracing Method Interframe tracing method processes slices from bottom to  up, it make all use of similarity between slices, employing the previous frame to conduct current frame ho w to update its contours to get an accurate result. 3.1.  Determining adaptive window   Adaptive window can be used for reducing analysis ra nge of current frame image, because the contour in current contour must be close to contour in previous fr ame. In order to get the adaptive window, the detail is this as followed. x Construct a border rectangle 
bR according to all contour points boundary extreme values in previous frame. x Expand n pixels in the border rectangle 
bR along each direction respectively (n is the maximum possible difference value in neighboring frames), and it forms contour which surrounds the border rectangle 
bR in current frame. Data analysis in current frame will be focus on this area. 295  Luo Sanding et al.  /  AASRI Procedia   1  ( 2012 )  293 ‚Äì 298 
x For improving the accuracy of post analysis, integral image interpolation operation will be used in the border rectangle 
bR for three times. 3.2. Determining edge points with characteristic matching  The shell of bone is compact while core of bone is loos e, and part bone edges are low contrast in some slices, then it results in trench curves among bone edges in Fig 1(c). To remove trench curve, matching contour points in two neighboring frame and finding all th e matching points in current frame, examine length of neighboring matching points to decide whether ne ighbouring matching edge points should be adjusted. x Aligning initial contour points in neighboring frames, suppose current contour is
iP, previous contour is1iP. x Pick evenly 
N points in1iP, point1jiK is a even point in 1iP (0 )jN , suppose  there are M event points in 
iP  search  minimum distance D with Two Searching Method 
1 m i n { ( ) } ( 0, 0)tjiiDd i s K K j N t M   d d d d                                                                                    (1) Among that, 
1 ()tjiidis K K  is the distance between contour point tiKand 1jiK, if there exists a point tiK which can get the most minimum distance with 
1jiK, tiKis  a matching point of 1jiK. 
   
    
    
  
        (a)   (b)   (c)   (d)  Fig. 1. (a) original image of frame i; (b) contour of  frame i-1; (c) contour of frame i; (d) adjusted contour of frame i 
x Get all the matching points jiK in iP, if  the length of neighboring matching points is longer than its length of even part divide by N, edge points between neighboring matching points should be removed and updated by a line, adjusted contour can be seen in Fig 1(d).                
1() ( ( ) )jjii a v e a v e idis K K d d length P N D!                                                                                         (2) Among that, 
aved is the even length of iP, D is coefficient  determine length range, generally D>1. 3.3. Adjusting femur head contours 
  
  
(a)        (b) Fig. 2. (a) cutaway view for bone; (b) series contour projection on XZ plane 296   Luo Sanding et al.  /  AASRI Procedia   1  ( 2012 )  293 ‚Äì 298 
The first step for adjusting is finding the frame range of femur head. In Fig 2(a), which is a cutaway view for bone, and there exists characters that the line link from top greater trochanter to bottom femur head is horizontal. The position is marked in Fig 2 as
bK, and contour areas change greatly form frame bK to 1bK, we can get 
bK through find the biggest difference of contours between neighboring frames. In Fig 2(b)eK is where femur head disappears, and it is an image projecting on XZ plane. In the top of head, horizontal distance is smallest, then it is easy to get
eK, andmK is where the center of head lies, due to the contour in  
mK appears close to circle, in framemKcontour has a biggest circle area. The second step is fitting the contour from frame
bK toeK update the center of contour in every frame, which is helpful for removing interferent.  4. Locating Key Points As long as position of head-neck intersection is ensu red, other 3D data can be ensured, so head-neck intersection is very important. In order to meet the anatomy features for intersection, a projecting method based on distance transform has been used for locating key points. 4.1 Determining section  We cut the whole bone from top to bottom vertically, which make the section basically lie at the axile line. Due to section is vertical to XY plane, section depend on cut line on the top of bone. In order to find right cut line which evenly cut whole bone, we project all contours in all frames to XY plane as Fig 3(a).  
 
  
  
(a)    (b)      (c)  
Fig. 3. (a) projecting contour; (b) cut line in external contour; (c) vertical section 
In Fig 3, the projecting contours can form a series of interlaced contour lines, and border tracking method is employed to find the enclosed external contour line 
P of projecting contours in Fig 3(b).  Point LPand RP on 
P divide P  into two parts ,and 1S and 2S are separately their areaÀàwhen12SS , the line linked by LP and 
RP is the right cut lineÀàthen L can cut every contour in every frame and form two intersections, eventually , all intersections can get a vertical section
Fas Fig 3(c). 4.2 Locating head-neck intersection Considering head-neck intersection lies in corner of fe mur a a method based on distance transform in four neighborhoods is used to process the section 
F, and steps are like this. x Fill the section 
Fwith horizontal lines. x Set initial gray in area out of border F to 0, while initial gray in section 
F is 255. x Current point gray is
ijV, compare gray between left neighborhood and up neighborhood to get minimum gray to update current point gray.  
1, 1, 1 min( , ) 1i j ijijVV V            (3) 297  Luo Sanding et al.  /  AASRI Procedia   1  ( 2012 )  293 ‚Äì 298 
x Compare gray between right neighborhood and down n eighborhood to get minimum gray to update current point gray. 
,1 1 ,1 min( , ) 1iji j i jVV V                      (4)  x Finally, there exists a point 
maxP which has a maximum in bone corner, seeing Fig 4(a). 
                    (a)                                      (b) Fig. 4. (a) intersection with distance transform; (b) head-neck angles 
After getting head-neck intersection, femur head center is  easier obtained. In fact, head centre can get from frame 
mK, then we can see from Fig 4(b), hP is head centre, and nP is head-neck intersection, combined with  centre of bottom backbone forms a head-neck angle, which is widely used to diagnose whether the patient ‚Äôs hip is deformed. 5. Experiment And Results In this experiment, there are some hip joint CT series scanning images from male subjects (512
u512 pixel, interlayer distance is 1mm, pixel distance is 0.78125mm). Choose 5 groups of images randomly for detecting of left side and right side in hip. Compared with manual segmentation results, the results of automatic head- neck angle detection (demonstrate in table 1) are evaluated by objective different degree 
O. It is defined as in (5). 
100%MD OA AM  u                                                                                                                    (5) 
Table 1. Estimating objective different degree with head-neck angle  
ID Side DA MA MDAA  (100%)O  
1 L 122.9 123.5 0.6 0.485 
R 125.2 124.2 1.0 0.805 
2 L 131.7 132.7 1.0 0.754 
R 129.1 128.2 0.9 0.702 
3 L 125.5 124.7 0.8 0.642 
R 126.2 126.5 0.3 0.237 
4 L 130.8 131.4 0.6 0.456 
R 129.5 128.7 0.8 0.621 
5 L 127.0 125.3 1.7 1.194 
R 127.1 125.6 1.5 1.356 
From Table 1 above, we can see that most of subjects ‚Äô objective different degrees are less than 1.0, and results are stable, which indicates that the automatic segmentation results are coincide with manual ones. The 298   Luo Sanding et al.  /  AASRI Procedia   1  ( 2012 )  293 ‚Äì 298 
main reason for results more than 1.0 in fifth groups is backbone length, which can be calculated from CT slices, if length below lesser trochanter is less than  5cm, backbone has a deflection between extracted backbone and vertical plane, which result in th e inaccurate center of the bottom backbone. 6. Conclusion In this paper, an automatic and effective method for hip segmentation and data extraction is proposed. We employ bottom-to-top strategy to process serial imag es. Meanwhile, this paper also introduces an associated interframe tracing method, and makes full use of contour in known slices to analyze contour of subsequent slices with interframe correlation, and avoid the interferenc e of other contours, improve speed of obtaining. In order to locating head-neck intersection with projectin g method based on distance transform, which meets  anatomy features, can obtain effective and efficient 3D  data. Compared with manual segmentation, the method can segment proximal surface of hip join femur accu rately, and prepare a good basis for later study on characteristics of proximal femur. References [1] Liao Shenghui, Xu Duanging, Dong Jinxiang . Image Segmentation and Contour Correspondence and Branching Problem in Human Mandible Reconstruc tionJOURNAL OF COMPUTER-AIDED DESIGN    COMPUTER GRAPHICS 2004, 16(9): 1225-1230. [2] Sokratis Makrogiannis, Rahul Bhotika,James V.M iller. Nonparametric Intensity Priors for Level Set Segmentation of Low Contrast Structures[C].MICCAI 2009,PART 1,LNCS 5761:230-238. [3] Zhang Fei,Fan Yubo, Pu Fang, Liu Zhan, ‚ÄúA Semi-automatic Method for Tooth Segmentation in Dental CT Images,‚Äú J Biomed Eng, vol. 24, Feb. 2007, pp: 15-18. [4] Chang Chun, Jen Chen, Chi Jen Lu. A Linear Time Component Labeling Algorithm using Contour Tracing Technique[J].Computer Vision and Image Understanding,2004,93(2):206-220. [5] Zhang Huizhang. ‚ÄúResearch on Image Understanding Based on Visual Perception, ‚Äù Northwestern Polytechnical University, Nov.2003. 