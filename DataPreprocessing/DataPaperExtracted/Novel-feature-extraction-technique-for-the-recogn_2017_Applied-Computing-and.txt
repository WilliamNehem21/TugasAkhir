ORIGINAL ARTICLE
Novel feature extraction technique for therecognition of handwritten digits
Abdelhak Boukharoubaa,*, Abdelhak Benniab
aFaculte´des Sciences et de la technologie, De´partement d’Electronique et de Te´le´communications, Universite´8 Mai 1945 Guelma, BP 401, Guelma 24000, Algeria
bFaculte´des Sciences de la Technologie, De´partement d’Electronique, Universite´Constantine 1, AlgeriaReceived 15 December 2014; revised 1 May 2015; accepted 17 May 2015Available online 27 May 2015
KEYWORDSFeature extraction;Feature selection;Digit recognition;Support vector machineAbstractThis paper presents an efﬁcient handwritten digit recognition system based on supportvector machines (SVM). A novel feature set based on transition information in the vertical and hor-izontal directions of a digit image combined with the famous Freeman chain code is proposed. Themain advantage of this feature extraction algorithm is that it does not require any normalization ofdigits. These features are very simple to implement compared to other methods. We evaluated ourscheme on 80,000 handwritten samples of Persian numerals and we have achieved very promisingresults.
/C2112015 The Authors. Production and hosting by Elsevier B.V. on behalf of King Saud University. This isan open access article under the CC BY-NC-ND license ( http://creativecommons.org/licenses/by-nc-nd/4.0/ ).
1. IntroductionThe recognition of handwritten script is a difﬁcult task due tothe different handwriting qualities and styles that are subject tointer-writer and intra-writer variations. Many recognition sys-tems in many applications have been proposed in recent yearswhere higher recognition accuracy is always desired. Typically,the recognition systems are adapted to speciﬁc applications toachieve better performance. They can be divided into threemain steps: preprocessing step, feature extraction and selectionstep, and classiﬁcation and veriﬁcation step. Handwritten digitrecognition problem can be seen as a subtask of the opticalcharacter recognition (OCR) problem. Unconstrained hand-written digit recognition has been applied to recognizeamounts written on checks for banks or zip codes on envelopesfor postal services, etc.This paper focuses on feature extraction and classiﬁcation.The performance of a classiﬁer can rely as much on the qualityof the features as on the classiﬁer itself. A good set of featuresshould represent characteristics that are particular for oneclass and be as invariant as possible to changes within this class[1]. Commonly used features in character recognition are:invariant moments[2], projections[3], zoning feature[4], Four- ier descriptors[5], and contour direction histogram[6]. A fea- ture set made to feed a classiﬁer can be a mixture of suchfeatures.While handwritten Latin digits recognition has been exten-sively investigated[7–10]through various techniques, little
*Corresponding author. Tel.: +213 777 08 32 32; fax: +213 37 20 7268.E-mail address:boukharouba_abdelhak@hotmail.com (A. Boukhar- ouba).Peer review under responsibility of King Saud University.
Production and hosting by ElsevierApplied Computing and Informatics (2017) 13,1 9–26
Saudi Computer Society, King Saud University
Applied Computing and Informatics
(http://computer.org.sa)www.ksu.edu.sawww.sciencedirect.com
http://dx.doi.org/10.1016/j.aci.2015.05.0012210-8327/C2112015 The Authors. Production and hosting by Elsevier B.V. on behalf of King Saud University.This is an open access article under the CC BY-NC-ND license ( http://creativecommons.org/licenses/by-nc-nd/4.0/ ).work has been done for Arabic/Farsi digit recognition. Direc-tion histograms using segmented characters from words in theCEDAR database[11]and transition information from thebackground to the foreground pixels in the vertical and hori-zontal directions of a character image[12]have been investi- gated. Later, feature extraction techniques generating localand global features were proposed[13]wherein local featureswere obtained from sub-images of the character including fore-ground pixel density information and directional information.The global features measured the fraction of the characterappearing below the word baseline and the characters’width/height ratio. Furthermore, gradient features have beenproposed for handwritten character recognition [14,15]where Awaidah and Mahmoud combined them with structural andconcavity features for the recognition of Arabic (Indian)numerals using hidden Markov models (HMM) [16]. A probabilistic neural network (PNN) approach for therecognition of the handwritten Indian numerals [17]based on the center of gravity and a set of vectors to the boundarypoints of the digit has been presented however Montazeret al.[18]proposed a holistic approach using neuro-fuzzyinference engine to recognize the Farsi numeral characters.Finally, Impedovo et al. introduced a genetic algorithm basedclustering approach using zoning features [19]whereas an adaptive zoning techniques for handwritten digit recognitionare presented[20,21]where the features are extracted accord-ing to an optimal zoning distribution. The experimental testsshow the effectiveness of the latter with respect to traditionalapproaches for zoning design.The literature details many high accuracy recognition sys-tems for handwritten Farsi digit database [22]used in our research. While an efﬁcient feature set based on modiﬁed con-tour chain code has been proposed in[23], two types of featuresets based on modiﬁed chain-code direction frequencies in thecontour pixels of input image and modiﬁed transition featureshave been presented[24]. A support vector machine (SVM) isproposed as classiﬁer to recognize Persian isolated digits.Besides, combinational methods for improving the recognitionrate of multi-class classiﬁers using confusion matrix andGenetic Algorithms have been proposed[25,26]. From the lit- erature survey of the existing feature extraction techniques forcharacter/digit recognition, most of them need digit normaliza-tion and consequently cannot preserve the shape of the inputimage for feature extraction step, which could react negativelyto the recognition phase. For that reason, the main contribu-tion of this work focuses on novel feature extraction approachwhere the digit image does not require any normalization.This paper is broken down into ﬁve sections. Section 2 provides details on the feature extraction and selection tech-niques. Section3deals with the classiﬁers used for the recog-nition purpose, experimental results are discussed inSection4, and ﬁnally Section5presents some conclusionsand perspectives.2. Feature extraction and selectionIn this section, we describe two feature extraction techniquesthat are investigated in this work. The ﬁrst is the chain codehistogram (CCH)[27], which is developed to simply describestatistically the boundary of each digit’s image. To eliminatethe effect of contour direction distortion caused by digit imagenormalization, we compute the feature vector without normal-izing digit image. Finally, we normalize feature vector by mak-ing its module equal to one. The second feature extractiontechnique builds on the white–black transition informationin the vertical and horizontal directions of a digit image. Eachtransition feature is characterized by the area deﬁned by thecorresponding transition and normalized by dividing it bythe whole digit’s area.The ﬁrst feature set is the chain code histogram (CCH),which is a statistical measure for the directionality of the con-tour of a digit. In this work, we measure the slope between twosuccessive points, which would give the angle made by the linejoining them and thex-axis. Then the set of possible slopes is(0/C176,4 5/C176,9 0/C176, 135/C176), which are identical to the directions (180/C176
, 225/C176, 270/C176and 315/C176). Thus, the directions between two succes-sive pixels are encoded as 0, 1, 2 and 3 direction codes, respec-tively as shown inFig. 1. Consequently, one of four directioncodes is assigned to each two connected pixels.The Canny algorithm is more robust to noise and morelikely to detect true weak edges but some digit samples are withbad qualities so that after applying canny operator someredundant pixels are remained, which affect the contour fol-lowing, these pixels should be removed. The redundant pixelremoval process is based on the condition that every contourpixel can only have two 8-connected pixels around it. If thereis a pixel which has more than two 8-connected pixels aroundit, the redundant pixels must be detected and removed. Anexample of redundant pixel removal process is shown inFig. 2where pixel 2 is a redundant one and must be removed.After removing redundant pixels, the contour becomes of unitthickness and consequently, we ﬁnd that only 4 possible seg-ments exist in the contour structure, which are considered asbasic segments consisting of two pixels. Consequently, the fea-ture extraction process is independent of the tracing direction.To extract features from digit contour, we employ a his-togram of the 4-chain code directions. The 4-bin histogramof chain code directions is computed where each bin representsthe frequency of the one direction.First, the smallest bounding box enclosing the digit contouris computed. If any of the number of rows or columns of thebounding box is not a multiple of 3, one or two rows/columnsof zeros should be added. If only one row of zeros is to beadded then it will be added on the right side of the image. Iftwo rows of zeros are to be added then each one must be onone side and similarly for columns. Consequently, the imagecan be divided into 3/C23 zones of equal area. The tracing pro-cess starts from the end point on the contour element, search-ing for the next nonzero pixel in any direction until end point is
1203
Fig. 1Diagram of the 4-chain code directions.20 A. Boukharouba, A. Benniareached. The remaining contour elements are traced in thesame way.Fig. 3shows an example of chain code histogram of thecontour points of the middle-left and top-right zones of thedigit٣.Afterward, the contour feature vector composed of 9 /C24 (36) components is normalized as follow.f
i¼hi
khik;i¼1;2;...;36ð1Þ whereh
iis theith bin of the tangent histogram of the wholedigit,f
iis theith component of the feature vectorf, which is between 0 and 1, andkkis the 2-norm. Thus,kfk¼1. Conse- quently, these features are a translation and scale invariantcontour descriptors and they are independent of the way a con-tour is traced.The second set, which is used as complementary descriptionof digits, is based on the white–black transition information inthe vertical and horizontal directions of a digit image. Thistechnique is an extension of that presented in [28]where the transition description is based on the length of the transitions.However, this technique is based on the areas between thesetransitions and the bounding box of the digit as regiondescriptors.Each transition feature is calculated as the ratio betweenthe area deﬁned by each transition type and the whole digit’sarea. The area is computed as the number of pixels betweenthe left/top boundary of the bounding box of the digit imageand the digit’s edge deﬁned by the transition location in thehorizontal/vertical direction.fh
k¼hak
w/C1h;fvk¼vak
w/C1hfork¼1;2 andfh3¼P
kP3hak
w/C1h; fv
3¼P
kP3vak
w/C1h:wherehakandva kare the areas of the regions deﬁned by theedge of thekth transition in the horizontal and vertical direc-tion, respectively.wandhare the width and the height of thedigit image.In the horizontal direction, the bounding box of each digitis divided horizontally in two equal parts. For each part, thethree transition features are calculated in the horizontal direc-tion. In the vertical direction, the three transition features areevaluated on the whole digit.Fig. 4shows an example of the different areas made by thewhite–black transitions of the digit۸. In the horizontal direc-tion we have only tow transition types of each part: the areaformed by the ﬁrst transition is at the left side of each part,the area formed by the second transition is at the right sideof each part, and as we have not a third transition, the corre-sponding area is equal to zero.In the vertical direction we have only one transition: thecorresponding area is at the bottom side of the digit; and aswe have only one transition, the second and third area is equalto zero.Finally, relative area feature is calculated with respect topre-ﬁxed area (w
0/C1h0):ratio=w/C1h/w 0/C1h0wherewandh are the width and the height of the digit image respectively.In this work the pre-ﬁxed areaw
0/C1h0is equal to 2000.As a result, we obtain a feature vector of 46 componentsper digit.Feature selection aims to reduce the dimensionality of thefeature space for classiﬁcation by selecting the most informa-tive features. The most informative features are the ones thatbest separate the different classes. Feature selection has beenused previously for many applications, yielding higher speedand reduced computational cost for the classiﬁcation process.One way to evaluate the pertinence of the extracted featuresis to calculate the discriminative power of each feature. Inorder to select the most discriminative features, we adopt theFisher criteria, which compute directly the discriminativepowerD
kof each featurekas follow[29]: D
k¼1
r2k;where r2k¼XCi¼1pðw iÞr2ik ð2ÞwhereCis the number of classes,p(w
i) is a prior probability ofclassw
i, andr ikis the variance of featurekaccording to the classi. These parameters are estimated from the trainingdataset.The features must be ordered in the descending order interms of their discriminative powers in order to select the most4
32
1
Fig. 2The redundant pixel removal principle: pixel 2 is aredundant pixel and must be removed.
Fig. 3Chain code histogram of the contour points of the middle-left and top-right zones of the digit ٣.Novel feature extraction technique 21pertinent features. There is no theoretical criterion to calculatethe threshold that separates the pertinent features from theredundant ones. The threshold is then determined with thehelp of many experiments by undertaking trainings on theselected features. Finally, we retain the threshold that providesthe best performance in terms of recognition rate.3. Support vector machinesSVM is a classiﬁer derived from statistical learning theory ﬁrstpresented by Boser et al.[30]. SVMs were introduced in[31]as learning machines with capacity control for regression and bin-ary classiﬁcation problems. It has also been proved to be verysuccessful in many other applications such as handwritten digitrecognition, image classiﬁcation, face detection, object detec-tion, and text classiﬁcation. In the case of classiﬁcation,SVM try to ﬁnd an optimal hyperplane that correctly classiﬁesdata points by separating the points of two classes as much aspossible. For the linearly separable case, the support vectoralgorithm simply looks for the separating hyperplane with lar-gest margin. This can be formulated as follows: suppose thatall the training data satisfy the following constraints:x
TiwþbPþ1 foryi¼þ1 andxTiwþb6/C01 foryi¼/C01. Then the hyperplaneðx
TwþbÞseparates the data if and onlyif:y
iðxTiwþbÞP1;8i:ð3Þ The optimal separating hyperplane is a margin classiﬁerwhose output is given by:fðxÞ¼signðx
TwþbÞð4Þ wherexis the input pattern,wis the weights vector, andbis the bias. The bias and the weights are computed by maximiz-ing the margin 1=kwksubject to the constraint that the N train-ing patterns are well classiﬁed and outside the margin:min
12kwk 2
s:t:yiðxTiwþbÞP1;i¼1;...;N:ð5Þwithy
i2f /C01;1grepresenting the label of the training patternxi. The solution corresponds to the saddle point of the primalLagrangian:Lp¼12kwk 2/C0XNi¼1ai½yiðxTiwþbÞ/C01/C138ð6Þwhere thea
iare the Lagrange multipliers. This problem leadsto the maximization of the dual Lagrangian with respect to a
i:L
D¼XNi¼1ai/C012XNi;jaiajyiyjðxTixjÞs:t:a
iP0;i¼1;...;N;X
Ni¼1aiyi¼0 ð7ÞThis is a standard quadratic problem, where a global max-imuma
ican always be found andwcan be recovered as:w¼X
Ni¼1aiyixi ð8ÞMany ofa
iare zero, which implies thatwis a linear combi- nation of a small number of data. The set of elements x
iwith non-zeroa
iare calledsupport vectors.Then, the resulting separating rule is:fðxÞ¼signX
support vectorsyiaiðxTixÞþb ! ð9ÞThe SVs are the training patterns that lie on the marginboundaries. An advantage of this algorithm is its sparsity sinceonly a small subset of the training examples are used to com-pute the output of the classiﬁer.Fig. 5represents a binary clas-siﬁcation problem where ﬁlled circles and squares are thetraining data while hollow circles and triangles are the testingdata.In case of such separating hyperplane does not exist, weintroduce a set of slack variablesn
ito allow points inside themargin during the training.min
12kwk 2þCXNi¼1ni
s:t:yiðxTiwþbÞP1/C0n i;i¼1;...;N:ð10Þ where penalty parameterCis used to tune the trade-offbetween the classiﬁcation errors and the maximization of themargin. The formulation(6)is often called soft margin
Fig. 4Example of the different areas made by the white–blacktransitions of the digit۸.
Fig. 5Linear separating hyperplanes for the separable case:ﬁlled circles and squares are the support vectors.22 A. Boukharouba, A. BenniaSVM. This new formulation leads to the same dual problembut with box constraints on the Lagrange multipliers:06a
i6C;i¼1;...;N;ð11Þ The tuning of the hyperparameterCis a delicate task. Acommon method is to perform a grid search, i.e. to test manyvalues ofCand estimate for each the generalization error.This approach is valid whenever the set of points of the twoclasses are linearly separable. Nevertheless in real data this isusually not the case. In order to work with non-linear decisionboundaries the key idea is to transformx
ito a higher dimen-sion space using a transformation function, so that in thisnew space the samples can be linearly separable. SVM solvethese problems using kernels. One only has to calculate theinner products of the vectors in the feature space via the kernelfunctionK(/C1,/C1). This is thekernel trickthat allows the con-struction of a decision function that is nonlinear in the inputspace but equivalent to a linear decision function in the featurespace:fðxÞ¼signX
support vectorsyiaiKðx i;xÞþb ! ð12ÞwhereK(x
i,x) stands for the kernel function. Typical kernelfunctions are:RBF (Gaussian) kernel:Kðx
i;xÞ¼exp/C0kx/C0x ik2
2r2/C16/C17. Sigmoid kernelKðx
i;xÞ¼tanhðcðxTxiÞþcÞ:Polynomial kernelKðx
i;xÞ¼ðcxTxiþcÞd:There are two common methods to solve a multi-classproblem with binary classiﬁers such as SVMs: one-against all(or one-vs-rest) and one-against-one. In the one-against-allscheme, a classiﬁer is built for each class and assigned to theseparation of this class from the others. For the one against-one method, a classiﬁer is built for every pair of classes to sep-arate the classes two by two. Another approach to the recog-nition of n different digits is to use a single n-class SVMinstead of n binary SVM subclassiﬁers with the one-against-all method, thus solving a single constrained optimizationproblem.4. Experiments and resultsIn this section we present the experimental results to illustratethe beneﬁts of the chain code histogram combined with thetransition features in digit recognition ﬁeld. We evaluate ourmethod on a large handwritten dataset of Farsi digits, named‘‘Hoda”[22]. This dataset consists of ten digit classes from 0 to9(۹۸۷۶۵۴۳۲۱۰.) For experimental results, 80,000 handwrittensamples are considered; 6000 samples per class for training and2000 samples per class for testing.Fig. 6shows some digit sam-ples extracted from the used database with different styles andqualities.Firstly, Canny operator is used for digit contour extractionthen the bonding box of each digit contour is divided into nineequal zones. Within each zone the redundant pixels is removedand the contribution of the 4-chain codes are counted in thecorresponding histograms. The transition features are calcu-lated as shown above: in the horizontal direction, the bound-ing box of each digit is divided horizontally in two equalparts. For each part, the transition features are calculated inthe horizontal direction. In the vertical direction, the transitionfeatures are evaluated on the whole digit. Finally, relative areais calculated. The used feature vector is equal to 10. f, wherefis the vector of the 46 features.Secondly, the proposed architecture of SVM based classiﬁeris composed of ten one-against-all SVMs. The classiﬁer struc-tures were empirically set as follows. The RBF kernel is usedwhere the variance parameterris equal to 1 (r= 1) and the hyperparameterCis equal to 100 (C= 100).Table 1shows the details of misrecognition and recognitionaccuracy of each digit where the recognition accuracy of98.48% is obtained on the whole test set (20,000 samples). Itmay be noted that out of 305 misrecognized samples, 183(60%) samples belong to {۲,٣,۴} group and 122 (40%)samples belong to the remaining digits. Thus, the major mis-recognized digits are among 2, 3 and 4 digits. To improvethe recognition accuracy, we use a scheme similar to one intro-duced in[24]. We utilize a classiﬁer composed of seven one-against-all SVMs where {۰,۱} and {۲,٣,۴} represent two separate classes as shown, inFig. 7. After that, we use oneagainst-all SVM to separate the combined { ۰,۱} class. For the recognition of digits۲,٣,۴, we also use twice one-against-all SVM.Fig. 7illustrates the recognition system where arrowweights represent the number of the misrecognized digits ofeach class. Out of a total of 20,000 digits in the testing set,there are 291 digits that are not successfully recognized. Con-sequently, we obtain 98.55%, which showed slight improve-ment when compared with the ﬁrst scheme. Note that wehave got an accuracy of 100% on the training samples(60,000 samples) and also an accuracy of 100% when the train-ing is made on the whole dataset (80,000 samples).
Fig. 6Digit samples of handwritten Farsi digits [22], (a) different qualities, (b) different styles.Novel feature extraction technique 23The performances of most of the works available for Per-sian numerals are presented in[23–26]where detailed compar-isons with recent published works are discussed. Table 2shows a comparison with the most excellent existing works, that areto the best of our knowledge the only works in the literaturethat deal with Farsi digits composing Hoda dataset.FromTable 2it is clear that the highest recognition rate is99.02%[24]when 196 features are used for training. In ourwork, we reached an interesting recognition rate of 98.55%with only 46 features.The second experiment investigates the performance ofSVM classiﬁer based on the reduced feature sets.In order to yield higher speeds and reduced computationalcost for the classiﬁcation process, we choose to reduce thenumber of features involved in the training and testing stagesof SVM.Table 3illustrates the individual discriminative power ofeach feature. The ﬁrst column represents the discriminativepowers of the features extracted from transitions and the rela-tive area respecting the order described in the transition featureprocedure. The discriminative powers of CCH features are pre-sented in a 3/C23 grid with 4 values in each cell matching thecorresponding image region. The threshold value of discrimi-native powers used to select the pertinent primitives must bedetermined by practical tests. First, the primitives have beenranked in descending order of their discriminative powers.The threshold is then determined by undertaking trainingson the selected features. We retain the threshold that providesthe best performance in terms of recognition rate.Table 4shows the best results obtained for different num-bers of selected features using the SVM classiﬁer with the sameparameters used above (r= 1 andC= 100).The ﬁrst column represents the value of threshold of thediscriminative power, second column represents the numberof selected features, and the last column represents the recog-nition rate achieved on the test data set.The highest recognition rate achieved here is 98.46% using40 features and 98.44% using only 36 features, which areslightly less than the rate obtained with the 46 features. It isthen sufﬁcient to retain only the 36 primitives whose discrimi-native powers are the most pertinent.Moreover, the discriminative powers help us to analyze thepertinence of the different features. FromTable 3, among the 10 less pertinent features there are only two from the transitionfeatures and the remaining are from the CCH features. We canalso notice that the most pertinent feature is the area made bythe second transition of the low part in the horizontal directionwith discriminative power of 0.8217, which prove the perti-nence of the transition features.The best performance/complexity is obtained with an SVMclassiﬁer (r= 1 andC= 100) using 36 primitives, which ismore efﬁcient than the system trained on 106 primitives [25].Fig. 7Recognition scheme: arrow weights represent the numberof the misrecognized digits.Table 1Misrecognition and recognition accuracy of the tendigits.
Number(Farsi)Number of misclassiﬁeddigitsRecognition accuracy(%) (test) 0 14 99.301 7 99.652 42 97.903 109 94.554 32 98.405 15 99.256 30 98.507 20 99.008 4 99.809 32 98.40
Table 2Comparisons to other systems in the literature.
Algorithms Numberof featuresDataset size Accuracy (%)Train Test Train Test[23]196 60,000 20,000 99.99 98.71[23]196 80,000 – 99.37 –[24]196 60,000 20,000 99.99 99.02[25]106 60,000 10,000 – 98.89[26]106 40,000 20,000 – 97.12Proposed algorithm 46 60,000 20,000 100 98.5546 80,000 – 100 –Table 3Discriminative powers of 46 used features.
Transition features Chain code histogram features0.1553 0.1241 0.2023 0.16670.2092 0.1926 0.1504 0.18240.2671 0.1769 0.1732 0.16790.3647 0.1887 0.1704 0.34900.8217 0.2135 0.1553 0.21450.2760 0.1451 0.1562 0.21290.3711 0.2191 0.1251 0.31420.3879 0.3249 0.1668 0.17900.1391 0.2594 0.3810 0.17550.2024 0.1415 0.1901 0.24910.2287 0.1318 0.23470.2178 0.1849 0.2302
Table 4Effect of the size of the feature vector on therecognition rate.
Threshold ofdiscriminative powerNumber of selectedfeaturesRecognitionrate (%) 0.1500 40 98.460.1600 36 98.4424 A. Boukharouba, A. BenniaMoreover, it is important to note that the architecture of aclassiﬁer, by reducing its size, requires less storage capacityfor its parameters.We can augment the feature space using some structuralfeatures to efﬁciently remove some confusion and to achievebest results but the main purpose of this work is to demon-strate the efﬁciency of these new features.The most noticeable improvement is that a 100% recogni-tion rate is achieved in the training phases for all digits(60,000 and 80,000 samples), which is better than all of thosepresented in the literature. We believe that our results are verycompetitive and quite promising since we used only 36 simplefeatures.As we have achieved a rate of 100% on training datasets,then we can achieve a higher accuracy rate if we train SVMclassiﬁers on appropriate support vectors, because the general-ization property of an SVM does not depend on all the trainingdata, but only support vectors.Finally, we can see from the results that the achieved accu-racy is due to the discriminatory power of features and theregression capabilities of SVM classiﬁers.5. ConclusionThis paper presents a system for the recognition of the hand-written Persian numerals that could be used for automaticreading of numerical amounts of checks. The main contribu-tion of this work focuses on feature extraction where a novelfeature set based on transition information in the verticaland horizontal directions of a digit image combined with thewell-known chain code histogram (CCH) is discussed andcompared with others in the literature. The classiﬁcation sys-tem is based on SVM, which is considered one of the mostpowerful classiﬁcation techniques and is now widely used inmany pattern recognition applications. The results of ourexperiments show that feature selection procedure reducesthe dimensionality of the feature space without affecting theperformance of the classiﬁer where the system can maintainhigh performance with less computational complexity compar-ing to the systems in the literature.From experimental results, it is evident that our systemresulted good performance. We noted that most of misclassi-ﬁed samples were from classes of۲,٣, and۴, which are similar in shapes where their recognition is sometimes difﬁculteven for human being.Among the most important advantages of this featureextraction algorithm; it does not require any normalizationof digits where the most of the published works need digit nor-malization, which degrade the image quality. These featuresare also very simple to implement compared to other methods.It is obvious that to improve the performance of proposedsystem further, we need to investigate more on sources oferrors. Potential features other than the presented ones mayexist. In future, we plan to use some structural features likeconcavity analysis which may remove some of confusionsamong similar classes.Concerning the SVM classiﬁers, the tuning of the hyperpa-rameterCis a delicate task. We are sure that the RBF kernelparameters (randC) used in our experiments are not the bestchoices and are not implemented optimally because we havetried only a few experiments to choose them. Thus, we canimprove the performance of the system by testing many valuesof these parameters and estimate for each the generalizationerror.Finally, because we have achieved a rate of 100% on train-ing datasets then as perspective we will try to train automati-cally SVM classiﬁers on the support vector set that representthe more delicate examples instead of the whole training setto achieve higher recognition accuracy.References
[1]F. Lauer, C.Y. Suen, G. Bloch, A trainable feature extractor forhandwritten digit recognition, Pattern Recogn. 40 (2007) 1816–1824
.[2]
C.H. The, R.T. Chin, On image analysis by the methods ofmoments, IEEE Trans. Pattern Anal. Mach. Intell. 10 (1988)496–513
.[3] A.L. Koerich, Unconstrained handwritten character recognitionusing different classiﬁcation strategies, in: Proceedings ofInternational Workshop on Artiﬁcial Neural Networks inPattern Recognition, 2003.[4]
L.S. Oliveira, R. Sabourin, F. Bortolozzi, C.Y. Suen, Automaticrecognition of handwritten numerical strings: a recognition andveriﬁcation strategy, IEEE Trans. Pattern Recogn. Mach. Intell.24 (11) (2002) 1438–1454
.[5]
H. Kauppinen, T. Seppanen, M. Pietikamen, An experimentalcomparison of autoregressive and Fourier-based descriptors in2D shape classiﬁcation, IEEE Trans. Pattern Anal. Mach. Intell.17 (1995) 207–210
.[6]
K.M. Mohiuddin, J. Mao, A comprehensive study of differentclassiﬁers for handprinted character recognition, PatternRecogn. (1994) 437–448
.[7]
X.X. Niu, C.Y. Suen, A novel hybrid CNN–SVM classiﬁer forrecognizing handwritten digits, Pattern Recogn. 45 (2012) 1318–1325
.[8]
Z. Man, K. Lee, D. Wang, Z. Cao, S. Khoo, An optimal weightlearning machine for handwritten digit image recognition, SignalProcess. 93 (2013) 1624–1638
.[9]
E. Mohebi, A. Bagirov, A convolutional recursive modiﬁed selforganizing map for handwritten digits recognition, NeuralNetw. 60 (2014) 104–118
.[10]
M. Hanmandlu, O.V. Ramana Murthy, Fuzzy model basedrecognition of handwritten numerals, Pattern Recogn. 40 (2007)1840–1854
.[11]
H. Yamada, Y. Nakano, Cursive handwritten word recognitionusing multiple segmentation determined by contour analysis,IECE Trans. Inform. Syst. E79-D (1996) 464–470
. [12]
P.D. Gader, M. Mohamed, I.H. Chiang, Handwritten wordrecognition with character and inter-character neural networks,IEEE Trans. Syst. Man Cybern. Part B: Cybern. 27 (1997) 158–164
.[13]
F. Camastra, A. Vinciarelli, Combining neural gas and learningvector quantization for cursive character recognition,Neurocomputing 51 (2003) 147–159
. [14]
C.L. Liu, Normalization-cooperated gradient feature extractionfor handwritten character recognition, IEEE Trans. PatternAnal. Mach. Intell. 29 (8) (2007)
.[15]
C.L. Liu, C.Y. Suen, A new benchmark on the recognition ofhandwritten Bangla and Farsi numeral characters, PatternRecogn. 42 (2009) 3287–3295
.[16]
S.M. Awaidah, S.A. Mahmoud, A multiple feature/resolutionscheme to Arabic (Indian) numerals recognition using hiddenMarkov models, Signal Process. 89 (2009) 1176–1184
. [17]
F.A. Al-Omari, O. Al-Jarrah, Handwritten Indian numeralsrecognition system using probabilistic neural networks, AdvEng. Inform. 18 (2004) 9–16
.Novel feature extraction technique 25[18]G.A. Montazer, H.Q. Saremi, V. Khatibi, A neuro-fuzzyinference engine for Farsi numeral characters recognition,Expert Syst. Appl. 37 (9) (2010) 6327–6337
. [19] S. Impedovo, F.M. Mangini, G. Pirlo, A genetic algorithmbased clustering approach for improving off-line handwrittendigit classiﬁcation, in: International Conference on InformationScience, Signal Processing and their Applications (ISSPA), 2012.[20] S. Impedovo, F.M. Mangini, G. Pirlo, A new adaptive zoningtechnique for handwritten digit recognition, in: ICIAP, 2013.[21]
F.M. Mangini, G. Pirlo, Adaptive zoning design by supervisedlearning using multi-objective optimization, Int. J. Comput.Intell. Appl. 13 (01) (2014)
.[22]
H. Khosravi, E. Kabir, Introducing a very large dataset ofhandwritten Farsi digits and a study on the variety ofhandwriting styles, Pattern Recogn. Lett. 28 (10) (2007) 1133–1141
.[23] A. Alaei, U. Pal, P. Nagabhushan, Using modiﬁed contourfeatures and SVM based classiﬁer for the recognition of Persian/Arabic handwritten numerals, in: 7th Int. Conf. on Advances inPattern Recognition, 2009 ‘a’, pp. 391–394.[24] A. Alaei, P. Nagabhushan, U. Pal, Fine classiﬁcation ofunconstrained handwritten Persian/Arabic numerals byremoving confusion amongst similar classes, in: 10th Int.Conf. on Document Analysis and Recognition, 2009 ‘b’.[25] H. Parvin, H. Alizadeh, B. Minaei-Bidgoli, M. Analoui, Ascalable method for improving the performance of classiﬁers inmulticlass applications by pairwise classiﬁers and GA, in: 4thInt. Conf. on Networked Computing and AdvancedInformation Management, 2008.[26] H. Parvin, H. Alizadeh, M. Moshki, B. Minaei-Bidgoli, N.Mozayani, Divide & conquer classiﬁcation and optimization bygenetic algorithm, In: 3rd Int. Conf. on Convergence andHybrid Information Technology, N., 2008.[27] J. Iivarinen, A. Visa, Shape recognition of irregular objects, in:David P. Casasent (Ed.), Intelligent Robots and ComputerVision XV: Algorithms, Techniques, Active Vision, andMaterials Handling, SPIE 2904, 1996, pp. 25–32.[28]A. Boukharouba, A. Bennia, Recognition of handwritten Arabicliteral amounts using a hybrid approach, Cogn. Comput. 3 (2)(2011) 382–393
.[29]
K. Fukunaga, Introduction to Statistical Pattern Recognition,Academic Press, 1990
.[30] B.E., Boser, I.M. Guyon, V.N. Vapnik, A training algorithm foroptimal margin classiﬁers, in: 5th Annual Workshop onComputational Learning Theory, 1992, pp. 144–152.[31]
V.N. Vapnik, The Nature of Statistical Learning Theory,Springer, New York, 1995
.26 A. Boukharouba, A. Bennia