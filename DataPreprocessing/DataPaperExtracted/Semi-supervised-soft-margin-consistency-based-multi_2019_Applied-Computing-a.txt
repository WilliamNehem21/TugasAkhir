Semi-supervised soft margin consistency based multi-view maximumentropy discrimination
Changming Zhua,⇑, Zhe Wangb
aCollege of Information Engineering, Shanghai Maritime University, Shanghai 201306, PR China
bCollege of Information Science and Engineering, East China University of Science and Technology, Shanghai 200237, PR China
article info
Article history:Received 16 August 2017Revised 6 October 2017Accepted 20 October 2017Available online 14 August 2018Keywords:Semi-supervised multi-view learningMulti-view maximum entropydiscriminationSoft margin consistencyabstract
Multi-view maximum entropy discrimination (MVMED) and alternative MVMED (AMVMED) are pro-posed as extensions of maximum entropy discrimination (MED). In MVMED and AMVMED, they use hardmargin consistency principle that the decision of margin parameter is related to classiﬁer parameterdirectly. While the decision always be indirectly in practice, thus soft margin consistency based multi-view maximum entropy discrimination (SMVMED) has been proposed. But it is found that SMVMED isonly adaptive to supervised problems. In this paper, we extend the model of SMVMED to the semi-supervised problems and develop a semi-supervised SMVMED (SSMVMED). Related experiments onmulti-view data sets from different aspects have validated the effectiveness of SSMVMED theoreticallyand empirically. From the experiments, it is found that (1) compared with SMVMED, the average testaccuracy of SSMVMED has a 2 %enhancement; (2) SSMVMED costs more training time than SMVMED and the extra time is not more than 10 %; (3) in terms of the generation of additional unlabeled instances, ‘mid’ strategy has a better test accuracy than ‘self’ and taking all instances to get the center brings a bettertest accuracy as well; (4) with SSMVMED, the applications to estimation problem and regression problemwill be more feasible./C2112018 The Authors. Production and hosting by Elsevier B.V. on behalf of King Saud University. This is anopen access article under the CC BY-NC-ND license ( http://creativecommons.org/licenses/by-nc-nd/4.0/ ).
1. Introduction1.1. BackgroundMulti-view data set is composed of instances with multipleviews and each view consists of multiple features. A correspondingfeature group is made up of these features. Take a video data set asan example, suppose this data set consists of multiple videos andeach video appears in multiple different forms including visual,audio, and text. Then we treat each form as a view of a video. More-over, each view has several features, for example, text view can bedescribed by text color, text size, text content and color, size, con-tent form a feature group of text view. In order to process thosemulti-view data sets, many multi-view learning machines are pro-posed as below.(1) pre-fusion methods: multiple kernel learning (MKL) [1], cen- tered alignment-based MKL algorithms (CABMKL) [2], sim- ple MKL method (SMKL)[3], group Lasso-based MKLmethod (GLMKL)[4], localized MKL (LMKL)[5]. (2) late-fusion methods: robust late fusion method (RLF) [6]. (3) subspace approaches: multi-view linear discriminant analy-sis (MV-LDA)[7], multi-view canonical correlation analysis(MV-CCA)[8], multi-view locality preserving projections(MV-LPP)[9].(4) disagreement-based methods: co-training [10], conﬁdent co-training with data editing (CoTrade) [11], co-regularized Laplacian SVM (Co-Lap)[12].But these learning machines always neglect to consider uncer-tainties over model parameters and then maximum entropy dis-crimination (MED)[13]has been developed to consider this issueand learn a discriminative classiﬁer. In MED, it learns a distributionpð
HÞover classiﬁer parameter Hand this is contrast to the tradi-tional learning machines. In terms of traditional learning machines,
https://doi.org/10.1016/j.aci.2017.10.0042210-8327//C2112018 The Authors. Production and hosting by Elsevier B.V. on behalf of King Saud University.This is an open access article under the CC BY-NC-ND license ( http://creativecommons.org/licenses/by-nc-nd/4.0/ ).⇑Corresponding author.E-mail addresses:cmzhu@shmtu.edu.cn(C. Zhu),wangzhe@ecust.edu.cn (Z. Wang).Peer review under responsibility of King Saud University.
Production and hosting by ElsevierApplied Computing and Informatics 15 (2019) 172–181
Contents lists available atScienceDirect
Applied Computing and Informatics
journal homepage: www.sciencedirect.com
they only ﬁnd a single classiﬁer parameter pð HÞof the discriminant functionLð
HÞ(e.g.,LðX tjHÞ¼hTXtþb;H¼fh;bg). While MED obtains a joint distributionpð
H;cÞoverHand margin parameters
cby minimizing its relative entropy with respect to some prior tar-get distributionp
0ðH;cÞunder certain large margin constraints,MED marginalizes out
cto obtainpð HÞ[14]. Although MED considers the uncertainties over model parame-ters, its applicable scope limits to single-view problem. Thus multi-view maximum entropy discrimination (MVMED) [15]and alter- native MVMED (AMVMED)[16]are developed to extend the modelof MED to multi-view problems. MVMED and AMVMED exploitmultiple views in a different style called margin consistency andenforce the margins from two views to be identical. In other words,they adopt the hard margin consistency while have no ability toprocess large data sets. So soft margin consistency based multi-view maximum entropy discrimination (SMVMED) [17]has been proposed. Different from MVMED and AMVMED, SMVMEDachieves ‘soft’ margin consistency by utilizing the sum of two KLdivergencesKLðpð
cÞjjqðcÞÞandKLðqð cÞjjpðcÞÞin the objective func- tion, wherepð
cÞandqð cÞare the posteriors of two view margins,respectively. By balancing all involved terms in the objective func-tion, SMVMED is more ﬂexible.While SMVMED is only feasible for supervised problems, i.e.,the used instances are labeled. Indeed, most real-world multi-view data sets consist of labeled and unlabeled instances and theyare named semi-supervised data sets. In order to process semi-supervised data sets, semi-supervised learning machines havebeen developed and introduced in many applications [18–24].I n terms of the applications of MED, there also exist some relatedlearning machines for semi-supervised problems, for example,semi-supervised multi-sensor classiﬁcation via consensus-basedmulti-view maximum entropy discrimination [25], semi- supervised learning via generalized maximum entropy [26], and semi-supervised multi-task learning via self-training and maxi-mum entropy discrimination[27]. But these learning machinesdo not consider soft margin and we ﬁnd that soft margin has itsspecial physical meaning. As[17]said, if one view corresponds toone special sub-learning machine, its parameters include classiﬁerparameter
Hand margin parameter c. If the decision of cis related to
Hdirectly, we deﬁne it as hard margin consistency while if thedecision is not directly, we call it as soft margin consistency. Forsoft margin consistency,[17]has also validated that the decisionof
cis more ﬂexible and the performance and the conduction ofa learning machine is much better and fast.1.2. Proposal and troubleThus, in this paper, we still adopt soft margin consistency andapply it to semi-supervised problems and then propose the semi-supervised soft margin consistency based multi-view maximumentropy discrimination (SSMVMED). But during the process ofSSMVMED, there is a potential trouble when the data sets consistof few labeled instances and many unlabeled ones. As we know,compared with unlabeled instances, labeled ones can provide moreuseful discriminant information while in real-world applications,most data sets consist of few labeled instances and many unlabeledones and labeling instances is a high-cost task. Thus, for traditionalsemi-supervised problems, the performances of learning machinesare sensitive to the data sets. In order to enhance the performanceof a learning machine, a widely used and feasible method is gener-ating additional unlabeled instances with the original labeled orunlabeled ones and combining all instances together. These addi-tional unlabeled instances will possess some discriminant informa-tion derived from the original labeled and unlabeled instances.Here, Universum learning[28]is such a kind of method. ForUniversum learning, it aims to create additional unlabeledinstances (also called Universum instances or Universum set) andincorporates priori knowledge which is introduced in the form ofadditional unlabeled instances into the learning process [29].B y Universum learning, the performance of a traditional learningmachine can be boosted. Now Universum learning has been grad-ually spread into different applications [30–34]and some related methods are also developed including Universum support vectormachine (U-SVM)[35]and self-Universum support vector machine(SUSVM)[36]. So for our SSMVMED, we also adopt Universumlearning to add useful discriminant information.But for these Universum-based learning machines, there stillexists two key problems. First one is that when generating Univer-sum set, the weights of views and features which play differentdiscriminant roles are always neglected. Second one is that whengenerating the additional unlabeled instances, traditionalUniversum-based learning machines only adopt labeled or unla-beled instances for generation. In order to solve the ﬁrst problem,we adopt weighted multi-view clustering (WMVC) [37]which is a multi-view clustering method and can ﬁnd the optimal clusterassignment. With WMVC, the weights of views and features canbe gotten. For the second problem, we try to design some schemesand adopt both labeled and unlabeled instances to generate theadditional unlabeled instances.1.3. Novelty and practical applicationsThe novelty of the proposed SSMVMED is given below.First, compared with some semi-supervised learning machineswith MED, SSMVMED adopts the soft margin and inherits theadvantages of soft margin consistency which makes the decisionof margin parameters be more ﬂexible and the performance andthe conduction of a learning machine be much better and faster.Second, SSMVMED extends the model of SMVMED to semi-supervised problems and this enlarges the applicable scope ofMED.Third, during the procedure of SSMVMED, it improves theUniversum learning methods, and when generating the additionalunlabeled instances, the weights of views and features will be con-sidered and both labeled and unlabeled instances are used for thegeneration.The practical applications of SSMVMED can include estimationproblems, regression problem, classiﬁcation problems and so on.In our work, we will adopt some related experiments to showthe effectiveness of our proposed SSMVMED in these applications.1.4. FrameworkThe rest of this paper is organized as below. Related work aboutMED is given in Section2. Description of SSMVMED is given in Sec-tion3. Experiments are given in Section 4. The conclusions are given in Section5.2. Related workSince our SSMVMED is the extension of SMVMED and SMVMEDis different from MVMED and AMVMED, thus we will reviewMVMED, AMVMED, and SMVMED here.2.1. MVMEDMVMED was proposed as an extension of MED to the multi-view learning setting and it considers a joint distributionpð
H1;H2Þover the view 1 classiﬁer parameter H1and view 2 clas- siﬁer parameter
H2. Using the augmented joint distributionC. Zhu, Z. Wang / Applied Computing and Informatics 15 (2019) 172–181 173pðH1;H2;cÞ, the model of MVMED is given in Eq. (1) [15]where 16t6N. In this model,L
1ðX1tjH1ÞandL 2ðX2tjH2Þare discriminant functions from two views, respectively. y
tis the class label oftth labeled instanceX
tand its margin parameter is ct.X1tandX2tare the representations ofX
tin the ﬁrst and second views, respectively.With MVMED, multi-view feature selection, multi-view multi-tasklearning, multi-view structure learning, and some other problemscan be solved well.
min pðH1;H2;cÞKLðpðH1;H2;cÞjjp0ðH1;H2;cÞÞ ð1Þ s:t:Rpð
H1;H2;cÞ½ytL1ðX1tjH1Þ/C0ct/C138dH1dH2dcP0Rpð
H1;H2;cÞ½ytL2ðX2tjH2Þ/C0ct/C138dH1dH2dcP0(
2.2. AMVMEDDifferent from MVMED, AMVMED considers two separate dis-tributionspð
H1ÞoverH1andpðH2ÞoverH2and balances KL diver- gences of their augmented distributions with respect to thecorresponding prior distributions. The model of AMVMED is givenin Eq.(2) [16]and 16t6N;
qis a coefﬁcient.
min p1ðH1;cÞ;p2ðH2;cÞqKLðp1ðH1;cÞjjp0ðH1;cÞÞ ð2Þ þð1/C0
qÞKLðp2ðH2;cÞjjp0ðH2;cÞÞs:t:Rpð
H1;cÞ½ytL1ðX1tjH1Þ/C0ct/C138dH1dcP0Rpð
H2;cÞ½ytL2ðX2tjH2Þ/C0ct/C138dH2dcP0Rpð
H1;cÞdH1¼RpðH2;cÞdH28><>:
As[17]said, for both MVMED and AMVMED, they exploit themultiple views in a different style called margin consistency whichindicate the margins from two views are enforced to be identical.Moreover, the margins are related to the parameters
H1andH2
directly and those margins are named as hard margins. AlthoughMVMED and AMVMED have provided state-of-the-art multi-viewlearning performance, hard margin requirement is somewhat toostrong to fulﬁll in many cases. For example, all positive marginscan lead to the same label prediction in binary classiﬁcations.2.3. SMVMEDSMVMED is different from MVMED and AMVMED due to themargin of SMVMED is soft. SMVMED achieves margin consistencyby minimizing the KL-divergence between the posteriors of marginparameters from two views. Then a trade-off parameter balancinglarge margin and margin consistency is also introduced to makethe model more ﬂexible. The model of SMVMED is given below.Here,pðHÞorqðHÞis a distribution overHandpðH
1;H2Þis a joint distribution overH
1andH 2. The parameter ais a parameter play- ing the trade-off role of balancing large margin and soft marginconsistency. Compared with MVMED and AMVMED, SMVMED ismore ﬂexible and the performance and the conduction of a learn-ing machine with SMVMED is much better and faster.
min pðH1;cÞ;qðH2;cÞKLðpðH1Þjjp0ðH1ÞÞ þKLðqð H2Þjjq0ðH2ÞÞ ð3Þ þð1/C0
aÞKLðpð cÞjjp0ðcÞ Þþð1/C0 aÞKLðqð cÞjjq0ðcÞÞ þ
aKLðpðcÞjjqðcÞÞ þaKLðqðcÞjjpðcÞÞ s:t:Rpð
H1;cÞ½ytL1ðX1tjH1Þ/C0ct/C138dH1dcP0Rqð
H2;cÞ½ytL2ðX2tjH2Þ/C0ct/C138dH2dcP0(
3. Semi-supervised Soft Margin Consistency based Multi-viewMaximum Entropy Discrimination (SSMVMED)Our proposed SSMVMED consists of three steps. First, computethe weights of views and features by WMVC [37]. Second, generatethe additional unlabeled instances. Third, apply the originallabeled, unlabeled, and the generated additional unlabeledinstances into the model of SSMVMED.3.1. Obtain the weights of views and featuresIn order to obtain the weights of views and features, we adoptWMVC for help. Suppose there is a multi-view data set consistingofNinstances represented by Vviews, i.e.,v¼fX11;X21;...;XV1;...;X1N;X2N;...;XVNgwhereXv
i2Rdvis the repre- sentation ofith instanceX
iin thevth view anddvis the dimension ofvth view. Here, we letX
v¼fXv
1;Xv
2;...;Xv
Ngrepresent thevth view and
vcan be represented as v¼fX1;X2;...;Xv;...;XV/C01;XVg. Then according to the notion of WMVC, we try to obtain the weights ofviews and the weights of features for each view. Let weight of eachview be
xvwhere v¼1;2;...;Vand weight for thelth feature of vth view is
sv
lwherel¼1;2;...;dv. Here, each weight should notbe less than zero. Furthermore,P
V
v¼1xv¼1 and for each view X
v;Pdv
l¼1sv
l¼1. Then according to the notion of WMVC, the wholemulti-view data set should be divided into several clusters. Let thenumber of clusters beM;kdenote the index of clusters, and d
ik
denote the belonging of the instance X i, if instanceX ibelongs to kth cluster, thend
ik¼1, otherwise,d ik¼0. For any instance X
i;PMk¼1dik¼1. The objective function of WMVC is given in Eq. (4).
minfdikgMk¼1;fxvgV
v¼1;fsvgV
v¼1eH ð4Þs:t:P
Mk¼1dik¼1; 8i;d ik2f0;1gP
V
v¼1xv¼1; xvP0P
dv
l¼1sv
l¼1; 8v;sv
lP08>><>>:
In this function, eH¼PV
v¼1ðxvÞpPNi¼1PMk¼1dikjjdiagð svÞðXv
i/C0mv
kÞjj2þ
bPV
v¼1jjsvjj2;sv¼fsv
1;sv
2;...;sv
dvg, anddiagð svÞrepresents the diagonal matrix where other elements in this matrix are zeros.Moreover,m
v
k¼PNi¼1dikXv
iPNi¼1dikis the cluster center ofkth cluster in the vth view. Furthermore,bP
V
v¼1jjsvjj2is used to control the sparsity of the feature weight vectors
sv;8vso as to avoid the situation thatonly a few features are selected in getting a very small but mean-ingless objective value. The parameters pandbare the exponential and balancing parameters, which are selected according to the pri-ori knowledge of data so as to help controlling the sparsity of theview weight vector
x¼fx1;x2;...;xVgand the feature weight vectors
sv;8v¼1;2;...;Vrespectively.Then with WMVC,
xvcan be updated by Eq.(5)and svcan be updated by Eq.(6)until the computations of
xvandsvbe conver- gent or the iteration times is up to a maximum number. In theseequations,D
v¼PNi¼1PMk¼1dikdiagðsvÞðXv
i/C0mv
kÞ/C12/C12/C12/C12/C12/C12/C12/C122andBv
l¼bþ ð
xvÞpPNi¼1PMk¼1dikðXv
i/C0mv
kÞ2lwhereðHÞlrepresents thelth element ofðHÞ.
xv¼1P
Vu¼1 Dv
Du/C16/C171=ðp/C01Þp>1ð5Þ
xv¼1;v¼argminuDu
0;otherwise/C26p¼1
sv
l¼1P
dv
m¼1Bv
l
Bv
m8l ð6Þ
Finally, we can get the optimal or ﬁnal xandsvand the weights of views and features are also gotten.174 C. Zhu, Z. Wang / Applied Computing and Informatics 15 (2019) 172–1813.2. Approaches of generating additional unlabeled instancesAfter we get the weights of views and features, we will adoptUniversum learning to generate the additional unlabeled instances(i.e., Universum instances or Universum set). In our paper, the gen-eration approaches used are given in Table 1. From this table, it is found that each approach has a code with the form ‘A-B-C’. ‘A’ hasthree choices, ‘all’, ‘unlabeled’, ‘labeled’. ‘B’ has three choices, ‘all’,‘near’, ‘far’. ‘C’ has two choices, ‘mid’ and ‘self’. For ‘A’, ‘all’ (‘unla-beled’, ‘labeled’) represents that one computes the midpoint ofall (unlabeled, labeled) instances as a center. For ‘B’, ‘all’, ‘near’,and ‘far’ represent that one uses all instances, Kinstances which locates nearest from the center, and Kinstances which locates far- thest from the center as selected instances respectively. For ‘C’,‘mid’ represents one takes the midpoint of a selected instanceand the center to construct Universum set while ‘self’ representsUniversum set consists of the selected instances themselves. Wetake_U
1/C02as the example. In this approach, we ﬁrst to computethe mean of all instances as a center, then we select Kinstances which locates nearest from this center, ﬁnally take the midpointof a selected instance and the center to construct Universum set.For all approaches used here, when we compute midpoint ordistance, the weights of views and features should be used. Con-cretely speaking, if there are two instances, X
1¼fX11;X21;...;XV1g andX
2¼fX12;X22;...;XV2g. The weights of views are x1;x2;...;xV
and the weights of features are svwhere v¼1;2;...;Vand
sv¼fsv
1;sv
2;...;sv
dvg.dvis the dimension ofvth view and sv
lrepre- sents weight of thelth feature ofvth view. Then the midpoint ofX
1
andX 2isPV
v¼1xvPdv
l¼1ðsv
lðXv
1þXv
2ÞlÞ2and the distance betweenX 1andX 2
isPV
v¼1xvPdv
l¼1ðsv
lðXv
1/C0Xv
2Þ2lÞwhereðHÞlrepresents thelth ele- ment ofðHÞ.3.3. Solution of SSMVMEDOnce we generate additional unlabeled instances, we will applythem along with the original labeled and unlabeled instances intothe model of SSMVMED. For convenience, we adopt a binary-viewdata set for example. For a data set with more than two views, wecan divide it into several binary-view problems, and for eachbinary-view problem, a sub model of SSMVMED is gotten and theycan be integrated together and get the ﬁnal model for multi-viewdata sets.Suppose for a binary-view data sets, there are N(hereNis dif- ferent from theNin Section3.1which denotes the number of allinstances) labeled instancesfX
1t;X2t;ytgandLunlabeled instances (including the generated additional ones) fU
1i;U2ig. Here,X1t(X2t) represents the ﬁrst (or second) view of the tth labeled instance X
tandytis its class label. ForU1i(U2i), it represents the ﬁrst (or sec-ond) view ofith unlabeled instanceU
i. Different from Eq.(3), the model of SSMVMED adds the constraint of unlabeled instancesand the parameter
c¼fcjgwherej¼1;2;...;N;Nþ1;...;NþL. Namely, SSMVMED considers the margin constraint of each labeledor unlabeled instance. Eq.(7)shows the model of SSMVMED. Inthis model, 16t6N;16i6L;pðHÞ(qðHÞ) is a distribution overHandpðH1;H2Þ(qðH 1;H2Þ) is a joint distribution overH 1and H
2.ais still a parameter playing the trade-off role of balancinglarge margin and soft margin consistency.
H1(H2) is the view 1 (2) classiﬁer parameter.
cis the margin parameter.
min pðH1;cÞ;qðH2;cÞKLðpðH1Þjjp0ðH1ÞÞ þKLðqð H2Þjjq0ðH2ÞÞ ð7Þ þð1/C0
aÞKLðpð cÞjjp0ðcÞ Þþð1/C0 aÞKLðqð cÞjjq0ðcÞÞ þ
aKLðpðcÞjjqðcÞÞ þaKLðqðcÞjjpðcÞÞs:t:Rpð
H1;cÞ½ytL1ðX1tjH1Þ/C0ct/C138dH1dcP0Rqð
H2;cÞ½ytL2ðX2tjH2Þ/C0ct/C138dH2dcP0Rpð
H1;cÞ½L1ðU1ijH1Þ/C0ci/C138dH1dcP0Rqð
H2;cÞ½L2ðU2ijH2Þ/C0ci/C138dH2dcP08>>>><>>>>:
In order to optimize Eq.(7), we use an iterative scheme for ﬁnd-ing a solution to Eq.(7)which is similar with the one given in [17]. In themth iteration, we successively update p
ðmÞðH1;cÞand q
ðmÞðH2;cÞby solving the following two problems (Eqs. (8) and (9)) and before the solution, we choose some initial value forq
ð0ÞðH2;cÞwithq0ðH2;cÞand this makes Eq.(8)be a standard MED problem.
pðmÞðH1;cÞ¼argminpðmÞðH1;cÞKLðpðmÞðH1Þjjp0ðH1ÞÞ ð8Þ þð1/C0
aÞKLðpðmÞðcÞjjp0ðcÞÞ þaKLðpðmÞðcÞjjqðm/C01ÞðcÞÞ s:t:Rp
ðmÞðH1;cÞ½ytL1ðX1tjH1Þ/C0ct/C138dH1dcP0Rp
ðmÞðH1;cÞ½L1ðU1ijH1Þ/C0ci/C138dH1dcP0(q
ðmÞðH2;cÞ¼argminqðmÞðH2;cÞKLðqðmÞðH2Þjjq0ðH2ÞÞ ð9Þ þð1/C0
aÞKLðqðmÞðcÞjjq0ðcÞÞ þaKLðqðmÞðcÞjjpðmÞðcÞÞ s:t:Rq
ðmÞðH2;cÞ½ytL2ðX2tjH2Þ/C0ct/C138dH2dcP0Rq
ðmÞðH2;cÞ½L2ðU2ijH2Þ/C0ci/C138dH2dcP0(
The Lagrangian of Eq.(8)can be written as
L¼ZpðmÞðH1ÞlogpðmÞðH1Þp
0ðH1ÞdH1 ð10Þþð1/C0
aÞZpðmÞðcÞlogpðmÞðcÞp
0ðcÞdcþaZp
ðmÞðcÞlogpðmÞðcÞq
ðm/C01ÞðcÞdc
/C0XNt¼1Zp
ðmÞðH1;cÞkðmÞ1;t½ytL1ðX1tjH1Þ/C0ct/C138dH1dc
/C0XLi¼1Zp
ðmÞðH1;cÞ/ðmÞ1;i½L1ðU1ijH1Þ/C0ci/C138dH1dc
¼ZpðmÞðH1;cÞlogpðmÞðH1;cÞp
0ðH1Þ½p0ðcÞ/C1381/C0a½qðm/C01ÞðcÞ/C138a
/C0XNt¼1Zp
ðmÞðH1;cÞkðmÞ1;t½ytL1ðX1tjH1Þ/C0ct/C138dH1dc
/C0XLi¼1Zp
ðmÞðH1;cÞ/ðmÞ1;i½L1ðU1ijH1Þ/C0ci/C138dH1dc
Table 1The codes of used Universum set construction ways.
Code Way Code Way Code Way_U
1/C01all-all-mid _U2/C01unlabeled-all-mid _U3/C01labeled-all-mid _U
1/C02all-near-mid _U2/C02unlabeled-near-mid _U3/C02labeled-near-mid _U
1/C03all-far-mid _U2/C03unlabeled-far-mid _U3/C03labeled-far-mid _U
1/C04all-near-self _U2/C04unlabeled-near-self _U3/C04labeled-near-self _U
1/C05all-far-self _U2/C05unlabeled-far-self _U3/C05labeled-far-selfC. Zhu, Z. Wang / Applied Computing and Informatics 15 (2019) 172–181 175wherekðmÞ1¼fkðmÞ1;tgand/ðmÞ1¼f/ðmÞ1;igare sets of nonnegative Lagrange multipliers, one for each classiﬁcation constraint. Thenwe take the partial derivative of Eq. (10)with respect to p
ðmÞðH1;cÞ, set it to be zero and get the solution of pðmÞðH1;cÞas below.
pðmÞðH1;cÞ¼1Z
ðmÞ1ðkðmÞ1Þp0ðH1Þ½p0ðcÞ/C1381/C0a½qm/C01ðcÞ/C138að11ÞeP
Nt¼1kðmÞ1;t½ytL1ðX1tjH1Þ/C0ct/C138þPLi¼1/ðmÞ1;i½L1ðU1ijH1Þ/C0ci/C138
whereZðmÞ1ðkðmÞ1Þis the normalization constant andeis the exponen- tial operation. According to[17]said,k
ðmÞ1is set by ﬁnding the unique maximum of the following concave objective function.
JðmÞ1ðkðmÞ1Þ¼/C0logZðmÞ1ðkðmÞ1Þð 12Þ
Then for Eq.(9), we adopt the same analysis and obtain thesolution ofq
ðmÞðH2;cÞas below.
qðmÞðH2;cÞ¼1Z
ðmÞ2ðkðmÞ2Þq0ðH2Þ½q0ðcÞ/C1381/C0a½pmðcÞ/C138að13ÞeP
Nt¼1kðmÞ2;t½ytL2ðX2tjH2Þ/C0ct/C138þPLi¼1/ðmÞ2;i½L2ðU2ijH2Þ/C0ci/C138
wherekðmÞ2¼fkðmÞ2;tgand/ðmÞ2¼f/ðmÞ2;igare another sets of nonnega- tive Lagrange multipliers. Likek
ðmÞ1;kðmÞ2is set by ﬁnding the unique maximum of the following concave objective function.
JðmÞ2ðkðmÞ2Þ¼/C0logZðmÞ2ðkðmÞ2Þð 14Þ
As[17]said, after each iteration, we calculate the relative errorbetween values of Eq.(12)from two successively iterations andthat of Eq.(14), respectively, and utilize them for determining con-vergence. When the relative errors
JðmÞ1ðkðmÞ1Þ/C0Jðm/C01Þ1ðkðm/C01Þ1ÞJ
ðm/C01Þ1ðkðm/C01Þ1Þ ð15Þ
and
JðmÞ2ðkðmÞ2Þ/C0Jðm/C01Þ2ðkðm/C01Þ2ÞJ
ðm/C01Þ2ðkðm/C01Þ2Þ ð16Þ
are both less than some tolerance /C15, the iteration ends and ﬁnally wecan get the optimalpð
H1Þandqð H2Þ. Then for a test instance X
r¼fX1r;X2rg, we can use^y1¼signRpð H1ÞL1ðX1rjH1ÞdH1/C16/C17to get the class label ofX
rfrom the ﬁrst view while ^y
2¼signRpð H2ÞL2ðX2rjH2ÞdH2/C16/C17is used to compute the class labelofX
rfrom the second view. Finally, we can use^y¼sign
x1RpðH1ÞL1ðX1rjH1ÞdH1þx2RpðH2ÞL2ðX2rjH2ÞdH2/C16/C17 to get the class label ofX
rin the whole sample space without consider-ing the view spaces where
x1andx2are the weights of views respectively.
4. ExperimentsIn order to validate that SSMVMED has a better performance,we conduct our experiments on ﬁve parts. They are (1) comparisonfor test accuracy, (2) comparison for training time and computa-tional complexity, (3) comparison between different additionalunlabeled instances generation approaches in terms of test accu-racy and training time, (4) application to estimation problem,and (5) application to regression problem.The used data sets and compared learning machines are givenin related experimental contents and we will show the commonexperimental settings and the setting for our SSMVMED. Con-cretely speaking, (a) for each data set, we run the compared learn-ing machine for 10 times and 70 %instances for each data set arechosen in random for training and the remaining are chosen fortest. In the training set, we randomly choose 30 %as the labeled instances while the left 70%are treated as unlabeled instances;(b) for SSMVMED, (b-1) when we compute the weights of viewsand features, the setting can be referred to [37], i.e., exponential parameterpis selected from the setf1;2;...;30gand balancing parameterbis initialized to be 0:1, the cluster number equals tobe the class number, the maximum iteration times is 300 ;xv¼1V, and
sv
l¼1dv;8l¼1;2;...;dv;8v¼1;2;...;V; (b-2) when we gener- ate the additional unlabeled instances, the used approaches canrefer toTable 1. In terms of the number of instances which locatesfarthest or nearest from the center Kis selected from the set f1; ::;N
e/C0max gwhereN e/C0max ¼N t/C0N max.N tis the total number of training instances andN
maxis the number of instances from largesttraining class. For example, a training data set consists of threeclasses, one has 100 instances, another has 120 instances, andthe third has 140 instances, thenN
e/C0max ¼220; (b-3) since we have given the solution ofpð
H1Þandqð H2Þand furthermore, we also have given the way to predict a test instance with the optimalpð
H1Þandqð H2Þ, thus it is found that the key of solution is theexpressions ofL
1ðX1tjH1ÞandL 2ðX2tjH2Þ. In our practical experi- ments, we adopt linear classiﬁer assumptions, i.e.,L
1ðX1tjH1Þ¼hT1X1tþb 1andL 2ðX2tjH2Þ¼hT2X2tþb 2. Furthermore, in our experiments, we refer to [17]and suppose that p
0ðH1;cÞ¼p0ðH1Þp0ðcÞ¼p0ðh1Þp0ðb1Þp0ðcÞandq0ðH2;cÞ¼ q
0ðH2Þq0ðcÞ¼q0ðh2Þq0ðb2Þq0ðcÞwherep0ðh1Þandq0ðh2Þare satis- ﬁed with Gaussian distributions with mean 0 and standard devia-tionI;p
0ðb1Þandq0ðb2Þare set to non-informative Gaussiandistributions, andp
0ðcÞ¼QNt¼1p0ðctÞQLi¼1p0ðciÞandq0ðcÞ¼QNt¼1q0ðctÞ Q
Li¼1q0ðciÞ. Here,p0ðctÞ¼q0ðctÞ¼cﬃﬃﬃﬃ
2ppe/C0c22ð1/C0ctÞ2andp0ðciÞ¼q0ðciÞ¼
cﬃﬃﬃﬃ
2ppe/C0c22ð1/C0ciÞ2which are Gaussian priors with mean 1 that encour-ages large margins wherecis selected from the set f2
1;22;...;215g. Finally, for SSMVMED, the tolerance /C15is initialized to be0:001.4.1. Comparison for test accuracyFirst, we will show the effectiveness of the proposed SSMVMEDon test accuracy. Since related experiments have been validatedthat SMVMED outperforms MED, MVMED, and AMVMED [17] and the effectiveness of MED-related learning machines have alsobeen validated compared with the traditional multi-view learningmachines due to MED-related learning machines consider theuncertainties over model parameters [13–16], thus the used com- pared learning machine is SMVMED here. Experimental setting ofSMVMED can be referred to the one of SSMVMED (see (b-3)) sincethe parameters of SSMVMED include the ones of SMVMED. More-over, the used data sets are six multi-view data sets Course, Cite-seer, Cora, WebKB, NewsGroup, and Reuters. Information of themis summarized inTable 2whereCrepresents the class number. (1) Course data set[10]is used to describe web pages and we wantto predict whether the given web page is a course page or not; (2)Citeseer and Cora data sets both consist of 4 views and we chooseview content and cites here[38]; (3) WebKB data set consists ofweb pages collected from four universities: Cornell, Texas, Wiscon-sin and Washington which have 5 categories, i.e., student, project,course, stuff and faculty. Data in WebKB are described with twoviews: content and citation. We treat WebKB in four separate datasets grouped by universities[39]; (4) NewsGroup data set[40]is of six groups extracted from the 20-Newsgroup dataset, i.e., M2, M5,176 C. Zhu, Z. Wang / Applied Computing and Informatics 15 (2019) 172–181M10, NG1, NG2, NG3. Every group contains 10 data sets, and wechoose the ﬁrst set for all six groups in our experiments (seeTable 2). For each data set, there are three views, PartitioningAround Methods, Supervised Mutual Information, and Unsuper-vised Mutual Information; (5) In terms of Reuters, it is the abbre-viation of Reuters RCV1/RCV2 Multilingual and this data setconsists of machine translated documents which are written in ﬁvedifferent languages[41,42]. These ﬁve languages are English (EN),French (FR), German (GR), Italian (IT), and Spanish (SP). Each lan-guage is treated as a view of this Reuters data set and each docu-ment can be translated from one language to another language.For this data set, the documents are also categorized into six differ-ent topics, i.e., six classes. They are C15, CCAT, E21, ECAT, GCAT,M11.Table 3shows the related experimental results about the com-parison for test accuracy between SSMVMED and SMVMED. Fromthis table, it is found that the proposed SSMVMED outperformsSMVMED in average since on 12 data sets, SSMVMED has a betterperformance. The average accuracy of SSMVMED has a 2 %enhancement. Moreover, from the standard deviation values, it isfound that the performance of SSMVMED is more stable thanSMVMED.Furthermore, in order to validate the difference betweenSSMVMED and SMVMED is signiﬁcant, we adopt paired t-test[45](paired t-test is different from t-test) and Nemenyi statisticaltest[46]for quantitative evaluation analysis. Paired t-test is usedto analyze if the differences between two compared learningmachines on one data set are signiﬁcant or not. Then for Nemenyistatistical test, it is used to analyze if the differences between twocompared learning machines on multiple data sets are signiﬁcantor not. Nemenyi is different from another famous test, i.e., Fried-man statistical test which is used to analyze if the differencesbetween all compared learning machines on multiple data setsare signiﬁcant or not. Since the number of compared learningmachines here is two, thus we adopt Nemenyi statistical test ratherthan Friedman statistical test. In generally, the differences alwaysindicate the ones in test accuracy. Thus, here we conduct quantita-tive evaluation analysis in terms of test accuracy.(A) For paired t-test[45], we use sig-value to represent the sig-niﬁcant differences of test accuracy. When sig-value is lessthan 0.05, it indicates that the compared two learningmachines have a signiﬁcant difference in the test accuracyon one data set. Furthermore, the difference is more signiﬁ-cant when the sig-value is smaller. According to Table 3,w e useðHÞindicates the sig-value with the comparisonbetween SSMVMED and SMVMED. From the table, we ﬁndthat the difference between SSMVMED and SMVMED is sig-niﬁcant in average.(B) For Nemenyi statistical test, the performance of two learningmachines on all data sets is signiﬁcantly different if the cor-responding average ranks differ by at least the criticaldifference
CD¼qaﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
kðkþ1Þ6Nr ð17Þ
where critical valueqais given inTable 4,Nis the number of data sets,kis the number of learning machines.Table 2Brief data set description.
Data set CN V dv(v¼1;2;...;V)Course 2 1051 2 66, 5Citeseer 6 3264 2 3703, 3264Cora 7 2708 2 1433, 2708Cornell 5 195 2 1703, 195Texas 5 185 2 1703, 185Washington 5 217 2 1703, 217Wisconsin 5 262 2 1703, 262News-M2 2 1200 3 2000, 2000, 2000News-M5 5 500 3 2000, 2000, 2000News-M10 10 500 3 2000, 2000, 2000News-NG1 2 500 3 2000, 2000, 2000News-NG2 5 400 3 2000, 2000, 2000News-NG3 8 1000 3 2000, 2000, 2000Reuters 6 1600 5 2000, 2000, 2000, 2000, 2000
Table 4Critical values for the two-tailed Nemenyi test. Each critical value q
ais based on the studentized range statistic [46]divided byﬃﬃﬃ2p.
No. learning machines 2 3 4 5 6789 1 0q
0:05 1.960 2.343 2.569 2.728 2.850 2.949 3.031 3.102 3.164q
0:10 1.645 2.052 2.291 2.459 2.589 2.693 2.780 2.855 2.920Table 3Test accuracies (average value ± std.) compared with SMVMED. Last row list the win/tie/lose counts of SSMVMED on all data sets with t-test against SMVMED atsigniﬁcance level 95%. The best performance on each data set is in bold. ( H) indicates the sig-value with paired t-test.
Data set SSMVMED SMVMEDCourse0.957±0.0080.943 ± 0.011 (0.032) Citeseer0.737±0.0080.714 ± 0.008 (0.041) Cora0.827±0.0020.815 ± 0.010 (0.047) Cornell0.788±0.0210.760 ± 0.041 (0.023) Texas0.797±0.0140.785 ± 0.037 (0.031) Washington0.826±0.0190.816 ± 0.039 (0.026) Wisconsin0.884±0.0110.868 ± 0.023 (0.043) News-M2 0.967 ± 0.003 0.972±0.010(0.057) News-M50.989±0.0110.965 ± 0.015 (0.037) News-M100.855±0.0030.829 ± 0.017 (0.033) News-NG1 0.929 ± 0.001 0.931±0.025(0.049) News-NG20.953±0.0060.912 ± 0.009 (0.012) News-NG30.915±0.0060.901 ± 0.009 (0.016) Reuters0.783±0.0010.753 ± 0.016 (0.033) Average0.872±0.0080.855 ± 0.019 W/T/L SSMVMED vs. SMVMED 13/1/0C. Zhu, Z. Wang / Applied Computing and Informatics 15 (2019) 172–181 177According toTable 3, the average rank of SSMVMED 1 :1429 is while the one of SMVMED is 1:8571. Then for Nemenyi statisticaltest, if
a¼0:05, the critical valueq0:05is 1:960 (seeTable 4) and the correspondingCDis 1:960ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
2/C1ð2þ1Þ6/C114q¼0:5238. Under such a case, since 1:1429þ0:5238¼1:6667<1:8571, so the difference between the average rank of SSMVMED and the one of SMVMEDis signiﬁcant. When
a¼0:10, the critical valueq0:10is 1:645 (see Table 4) and the correspondingCDis 1:645ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
2/C1ð2þ1Þ6/C114q¼0:4396. Under such a case, since 1:1429þ0:4396¼1:5825<1:8571, so we get the similar conclusion.In other words, with paired t-test and Nemenyi statistical test,we can validate the effectiveness of SSMVMED from the quantita-tive evaluation analysis aspect.4.2. Comparison for training time and computational complexityHere, we still adopt SMVMED for comparison about the trainingtime and computational complexity. As we know, compared withSMVMED, our proposed SSMVMED has to generate additionalunlabeled instances. Thus SSMVMED has to cost more trainingtime theoretically andTable 5validates that. From this table, wecan ﬁnd that SSMVMED costs more training time than SMVMED.But the extra time is not more than 10 %which is acceptable for us. In other words, we can achieve better test accuracy with onlya little extra time with SSMVMED adopted.In order to validate the higher training time, we give the com-putational complexity of them theoretically. As we know, inSSMVMED, it consists of three steps. So here, we will discuss thecomputational complexities for different steps. For convenience,we let the number of labeled instances be N, the number of original unlabeled instances beL, the number of additional unlabeledinstances beU.For the ﬁrst step, the computation focuses on
xvandsv
l.I n terms of
xv, its computational complexity depends on D vand the computational complexity of D
visOðMðNþLÞððdvÞ2þ2dvÞÞ. In terms of
sv
l, its computational complexity depends on Bv
lwhich computational complexity isOðMðNþLÞÞ. Thus, for the ﬁrst step, the computational complexity is OðVMðNþLÞððd
vÞ2þ 2d
vÞÞ þOðdMðNþLÞÞwhered¼PV
v¼1dv;Mis the number of clus- ters, andVis the number of views. Here, for d
vin OðVMðNþLÞððd
vÞ2þ2dvÞÞ þOðdMðNþLÞÞ, we can select the lar- gestd
vand in fact, this selection won’t inﬂuence too much.For the second step, the computational complexity consists ofthree parts. For ‘A’, if we select ‘all’, the computational complexityisOððNþLÞdVÞ; if we select ‘unlabeled’, the computational com-plexity isOðLdVÞ; if we select ‘labeled’, the computational com-plexity isOðNdVÞ. For ‘B’, if we select ‘near’ or ‘far’, thecomputational complexity isOðNðN/C01ÞdV=2Þ; if we select ‘all’, we can omit the related computational complexity. For ‘C’, if weselect ‘mid’, the computational complexity is OðKdVÞor OððNþLÞdVÞwhich depends on the selection of ‘B’ and Kis the number of selected instances; if we select ‘self’, we can also omitthe related computational complexity. As a result, the total compu-tational complexity of the second step is ½minfOðLdVÞ;OðNdVÞg; maxfOððNþLÞdVÞþOðNðN/C01ÞdV=2ÞþOðKdVÞ;2OððNþLÞdVÞg/C138. For the third step, the computational complexity is similar withthe one of SMVMED. In this step, the computational complexity ofSSMVMED isOððNþUÞ
2Þwhile the one of SMVMED isOððNþLÞ2Þ. Totally speaking, the computational complexity of SSMVMED isOðVMðNþLÞððd
vÞ2þ2dvÞÞ þOðdMðNþLÞÞ þ ½minfOðLdVÞ;OðNdVÞg; maxfOððNþLÞdVÞþOðNðN/C01ÞdV=2ÞþOðKdVÞ;2OððNþLÞdVÞg/C138þ OððNþUÞ
2Þand compared with SMVMED, the extra computationalcomplexity isOðVMðNþLÞððd
vÞ2þ2dvÞÞ þOðdMðNþLÞÞþ ½minfOðLdVÞ;OðNdVÞg;maxfOððNþLÞdVÞþOðNðN/C01ÞdV=2Þþ OðKdVÞ;2OððNþLÞdVÞg/C138 þOððNþUÞ
2Þ/C0OððNþLÞ2Þ. From this result, it looks like that our proposed SSMVMED seems to cost moretraining time, but compared with OððNþUÞ
2Þand OððNþLÞ
2Þ;OðVMðNþLÞððdvÞ2þ2dvÞÞþOðdMðNþLÞÞþ½minfOðLdVÞ; OðNdVÞg;maxfOððNþLÞdVÞþOðNðN/C01ÞdV=2ÞþOðKdVÞ;2OððNþLÞ dVÞg/C138won’t inﬂuence too much due to NþUandNþLis always much larger thand;V;M;K.Now according to the theoretical analysis about computationalcomplexity, we can also validate the conclusion derived from thisexperimental item that with SSMVMED adopted, we can achievebetter test accuracy with only a little extra time.4.3. Comparison between different additional unlabeled instancesgeneration approaches in terms of test accuracy and training timeHere, we will discuss the difference between additional unla-beled instances generation approaches which are given in Table 1 in terms of test accuracy and training time. Figs. 1 and 2show the test accuracy and training time of different approaches given inTable 1on the used data sets. In these ﬁgures, orders in‘Approaches inTable 1’ represent the approaches inTable 1, i.e., 1-_U
1/C01,2 -_U 1/C02,3 -_U 1/C03,4 -_U 1/C04,5 -_U 1/C05,6 -_U 2/C01,7 -_U 2/C02,8 -_U 2/C03, 9-_U
2/C04, 10-_U 2/C05, 11-_U 3/C01, 12-_U 3/C02, 13-_U 3/C03, 14-_U 3/C04, and 15-_U 3/C05. Then from these ﬁgures, it is found that different additional unla-beled instances generation approaches bring different perfor-mances. We ﬁnd that for_U
1/C0xðx¼1;2;3;4;5Þapproaches, they can get better test accuracies compared with the _U
y/C0xapproaches wherex¼1;2;3;4;5 andy¼2;3 in average. Moreover, we ﬁndthat take ‘mid’ strategy for experiments has a better test accuracythan ‘self’. In terms of training time, approaches with taking allinstances as the center bring longer training time due to allinstances rather than labeled or unlabeled instances are used tocompute the center.4.4. Application to estimation problemHere, we apply our SSMVMED to estimation problem so as tovalidate its effectiveness. The estimation problem discussed hereaims to forecast the demographic trends which has also been dis-cussed in[43]. For the forecast, USs Census population data is used.In the experiments, we predict the demographic distribution in theyear 2010 based on the historical data in years 2000 and 2006. Theprediction is then compared with the actual Census data in theyear 2010. This setting is same as the one in [43].I n[43], the authors conducted the estimation experiments with three stages
Table 5Comparison about average training time (in seconds).
Data set SSMVMED SMVMEDCourse 2.249 2.170Citeseer 290.545 277.717Cora 212.896 201.727Cornell 91.870 87.120Texas 87.832 84.980Washington 2.933 2.677Wisconsin 1.099 1.010News-M2 30.396 29.913News-M5 258.455 241.120News-M10 275.072 263.533News-NG1 199.226 183.350News-NG2 176.051 173.270News-NG3 259.336 259.153Reuters 234.180 222.730178 C. Zhu, Z. Wang / Applied Computing and Informatics 15 (2019) 172–181and showed the experimental results with 12 ﬁgures, while sincethe limitation of paper length, we won’t show all the results. Forconvenience, we will only show the average difference betweenthe estimation and the real values of age in year 2010. SMVMEDand the proposed method in[43](we call it EDT) are used for com-parison.Fig. 3shows the related experiments. From this ﬁgure, it isfound that compared with SMVMED and EDT, the predicted agedistribution of our SSMVMED can accord with the real age distribu-tion to a large extent.4.5. Application to regression problemHere, we apply SSMVMED to regression problem. The regres-sion problem discussed here aims to estimate full joint distribu-tions from incomplete information which has also been discussedin[44].I n[44], authors proposed generalized cross entropy model(GCEM) and estimated the distribution of Singapore householdproﬁle (http://www.singstat.gov.sg) with the joint probability dis-tribution of the household dwelling type (HD), household size (HS)and home ownership (HO) measures. In those experiments,authors conducted the experiments on three different cases: (1)pure entropy with constraints, (2) minimum discrimination infor-mation without constraints, and (3) minimum discriminationinformation with constraints. Moreover, authors adopted (a) accu-racy heat maps to compare the accuracy of the three cases, (b)KullbackCLeibler (KL) distance to compare the estimated joint dis-tribution and the observed one, and (c) Linfoots measures to com-pare a wide range of spatiotemporal signals from brain waves tohuman dynamics. For accuracy heat maps, if the estimated heatmap is close to the true heat map, we say the estimation is better.For KL distance, the smaller the KL distance between any two dis-tributions is, the closer are their proﬁles. For Linfoots measures, ithas three indexes,Cmeasures the relative structural content, F looks at the ﬁdelity or peak alignment, and Qreﬂects the correla- tion quality[44]. If these three indexes are more closer to 1, thenwe say the estimated distribution is more closer to the true distri-bution. From those experiments, it was found that case 1 and case2 had comparable performance and case 3 had a best performance.In our experiments, for the limitation of paper length, we won’tconduct all experiments given in[44]. We will only adopt GCEM and SSMVMED for comparison on the Singapore household proﬁlewhen case 3 is considered. In order to show the results clearly, wecombine the results of accuracy heat maps (here, the differencesbetween estimated heat maps and the true ones are given), KL dis-tance, and Linfoots measures together and only show that whetherSSMVMED brings a better performance or not. Table 6shows the results in a simple manner. From this table, it is found that withSSMVMED, the error of estimation is decreased and the difference1 2 3 4 5 6 7 8 9 10 11 12 13 14 150.40.50.60.70.80.91test accuracy comparisontest accuracyCourse
Citeseer
Cora
Cornell
Texas
Washington
Wisconsin
1 2 3 4 5 6 7 8 9 10 11 12 13 14 150.50.60.70.80.91
Approaches in Table 1News−M2
News−M5
News−M10
News−NG1
News−NG2
News−NG3
Reuters
Fig. 1.Comparison between different additional unlabeled instances generation approaches in terms of test accuracy.
234567891011121314100150200250300training time comparisontraining time (s)Course
Citeseer
Cora
Cornell
Texas
Washington
23456789101112131480100120140160180200
Wisconsin
News−M2
1234567891011121314156080100120
Approaches in Table 1News−M5
News−M10
News−NG1
12345678910111213141501234
Approaches in Table 1News−NG2
News−NG3
Reuters
Fig. 2.Comparison between different additional unlabeled instances generation approaches in terms of training time.C. Zhu, Z. Wang / Applied Computing and Informatics 15 (2019) 172–181 179between the estimated distribution and the true distribution ismore smaller. In other words, SSMVMED brings a better regressionperformance.5. ConclusionsTraditional multi-view learning machines do not consider theuncertainties over model parameters. Thus maximum entropy dis-crimination (MED) and its extended versions multi-view maxi-mum entropy discrimination (MVMED) and alternative MVMED(AMVMED) are developed for this issue. While for processingmulti-view data sets, they only use the hard margin consistencyprinciple that the decision of margin parameter
cis related to clas- siﬁer parameter
Hdirectly. As we know, the decision always beindirectly in practice. So soft margin consistency based multi-view maximum entropy discrimination (SMVMED) has been pro-posed. Although related experiments have validated the effective-ness of SMVMED, it is only adaptive to supervised problems.Indeed, in real-world, most data sets are semi-supervised, namely,the data sets consist of labeled instances and unlabeled instances.So this paper extends the model of SMVMED to the semi-supervised problems and develop a semi-supervised SMVMED(SSMVMED). Furthermore, in order to get more useful discriminantinformation, we propose some schemes to generate more addi-tional unlabeled instances. Moreover, these generated additionalunlabeled instances will also be used in the model of SSMVMEDalong with the original labeled and unlabeled instances so thatthe performance of a learning machine can be boosted. Relatedexperiments on multi-view data sets from different aspects havevalidated the effectiveness of SSMVMED theoretically and empiri-cally. From the experiments, it is found that (1) compared withSMVMED, the average test accuracy of SSMVMED has a 2 % enhancement; (2) SSMVMED costs more training time thanSMVMED and the extra time is not more than 10 %which is accept- able for us; (3) in terms of the generation of additional unlabeledinstances, ‘mid’ strategy has a better test accuracy than ‘self’ andtaking all instances to get the center brings a better test accuracyas well; (4) with SSMVMED, the applications to estimation prob-lem and regression problem will be more feasible.AcknowledgmentThis work is supported by (1) Natural Science Foundation ofShanghai – China under Grant No. 16ZR1414500 (2) National Nat-ural Science Foundation of China – China under Grant Nos.61602296, 41701523, 51575336 and the authors would like tothank their supports.References[1] R. Bach, G.R. Lanckriet, M.I. Jordan, Multiple kernel learning, conic duality, andthe SMO algorithm, in: Proceedings of the 21st International Conference onMachine Learning, 2004, pp. 6–13.[2] C. Cortes, M. Mohri, A. Rostamizadeh, Two-stage learning kernel algorithms,in: Proceedings of the 27th International Conference on Machine Learning,2010, pp. 239–246.[3]
A. Rakotomamonjy, F. Bach, S. Canu, Y. Grandvalet, SimpleMKL, J. Mach. Learn.Res. 9 (2008) 2491–2521
. [4] M. Kloft, U. Brefeld, S. Sonnenburg, A. Zien, Non-sparse Regularization andEfﬁcient Training with Multiple Kernels, 2010. Available from: arxiv preprint<arXiv:1003.0079>.[5] M. Gönen, E. Alpaydin, Localized multiple kernel learning, in: Proceeding of the25th International Conference on Machine Learning, 2008, pp. 352–359.[6] G. Ye, D. Liu, I.H. Jhuo, S.F. Chang, Robust late fusion with rank minimization,in: Proceedings of the IEEE Computer Society Conference on Computer Visionand Pattern Recognition, 2012, pp. 3021–3028.[7]
A. Iosiﬁdis, A. Tefas, N. Nikolaidis, I. Pitas, Multi-view human movementrecognition based on fuzzy distances and linear discriminant analysis, Comput.Vis. Image Underst. 116 (3) (2012) 347–360
. [8] J. Rupnik, J. Shawe-Taylor, Multi-view canonical correlation analysis, in:Proceeding of Slovenian KDD Conference on Data Mining Data Warehouses,2010, pp. 1–4.[9]
X. Yin, Q. Huang, X. Chen, Multiple view locality preserving projections withpairwise constraints, Commun. Syst. Inform. Technol. 100 (2011) 859–866
. [10] A. Blum, T. Mitchell, Combining labeled and unlabeled data with co-training,in: Eleventh Conference on Computational Learning Theory, 1998, pp. 92–100.[11]
M.L. Zhang, Z.H. Zhou, Cotrade: conﬁdent co-training with data editing, IEEETrans. Syst., Man, Cybernet., Part B: Cybernet. 41 (6) (2011) 1612–1626
. [12] V. Sindhwani, P. Niyogi, M. Belkin, A co-regularization approach to semi-supervised learning with multiple views, in: Proceeding of ICML workshop onLearning With Multiple Views, 2005, pp. 74–79.10 20 30 40 50 60 70 80 90 10000.511.522.533.544.55x 106 difference between the estimation and the real values of age in year 2010
agenumber of people
real population distribution in the year 2010
estimated population distribution in the year 2010 by SSMVMED
estimated population distribution in the year 2010 by SMVMED
estimated population distribution in the year 2010 by EDT
Fig. 3.The predicted age distribution of US population for the year 2010 based on the population data in the years 2000 and 2006 with SSMVMED, SMVMED, and EDT us ed.
Table 6Comparison between GCEM and SSMVMED on Singapore household proﬁle withminimum discrimination information with constraints in terms of the results of heatmaps, KL distance, and Linfoots measures.
Measures SSMVMED SMVMEDAccuracy heat maps 0.017 0.012KL distance 0.0039 0.0028Linfoots measures C 1.016 1.003 Q 0.9991 0.9994F 1.007 1.004180 C. Zhu, Z. Wang / Applied Computing and Informatics 15 (2019) 172–181[13]T. Jaakkola, M. Meila, T. Jebara, Maximum entropy discrimination, Adv. NeuralInform. Process. Syst. 12 (2000) 470–476
. [14]
T. Jebara, Machine Learning: Discriminative and Generative, Kluwer Academic,2004
.[15] S.L. Sun, G.Q. Chao, Multi-view maximum entropy discrimination, in:Proceedings of the 23rd International Joint Conference on ArtiﬁcialIntelligence, 2013, pp. 1706–1712.[16]
G.Q. Chao, S.L. Sun, Alternative multiview maximum entropy discrimination,IEEE Trans. Neural Networks Learn. Syst. 99 (2015) 1–12
. [17] L. Mao, S.L. Sun, Soft margin consistency based scalable multi-view maximumentropy discrimination, in: Proceedings of the Twenty-Fifth International JointConference on Artiﬁcial Intelligence, 2016, pp. 1839–1845.[18] G. Tzortzis, A. Likas, Kernel-based weighted multi-view clustering, in: 2012IEEE 12th International Conference on Data Mining, 2012, pp. 675–684.[19]
S.L. Sun, Q.J. Zhang, Multiple-view multiple-learner semi-supervised learning,Neural Process. Lett. 34 (2011) 229–240
. [20]
M.Q. Deng, C. Wang, Q.F. Chen, Human gait recognition based on deterministiclearning through multiple views fusion, Pattern Recogn. Lett. 78 (C) (2016) 56–63
.[21]
F. Wu, X.Y. Jing, X.G. You, D. Yue, R.M. Hu, J.Y. Yang, Multi-view low-rankdictionary learning for image classiﬁcation, Pattern Recogn. 50 (2016) 143–154
.[22]
S.H. Zhu, X. Sun, D.L. jin, Multi-view semi-supervised learning for imageclassiﬁcation, Neurocomputing 208 (2016) 136–142
. [23]
H.Y. Wang, X. Wang, J. Zheng, J.R. Deller, H.Y. Peng, L.Q. Zhu, W.G. Chen, X.L. Li,R.J. Liu, H.J. Bao, Video object matching across multiple non-overlappingcamera views based on multi-feature fusion and incremental learning, PatternRecogn. 47 (12) (2014) 3841–3851
. [24]
R. Sheikhpour, M.A. Sarram, S. Gharaghani, M.A.Z. Chahooki, A survey on semi-supervised feature selection methods, Pattern Recogn. 64 (2017) 141–158
. [25] T.P. Xie, N.M. Nasrabadi, I.A.O. Hero, Semi-supervised multi-sensorclassiﬁcation via consensus-based multi-view maximum entropydiscrimination, in: IEEE International Conference on Acoustics, Speech andSignal Processing, 2015, pp. 1936–1940.[26] A.N. Erkan, Y. Altun, Y.W. Teh, M. Titterington, Semi-supervised learning viageneralized maximum entropy, in: International Conference on ArtiﬁcialIntelligence and Statistics, 2010, pp. 209–216.[27] G.Q. Chao, S.L. Sun, Semi-supervised multitask learning via self-training andmaximum entropy discrimination, in: Neural Information Processing, SpringerBerlin/Heidelberg, 2012.[28]
V. Vapnik, S. Kotz, Estimation of Dependences based on Empirical Data,Springer, 1982
.[29]V. Cherkassky, W.Y. Dai, Empirical study of the Universum SVM learning forhigh-dimensional data, Lect. Notes Comput. Sci. 5768 (2009) 932–941
. [30] D. Zhang, J. Wang, L. Si, Document clustering with Universum, in: InternationalConference on Research and Development in Information Retrieval, 2011, pp.873–882.[31]
B. Peng, G. Qian, Y.Q. Ma, View-invariant pose recognition using multilinearanalysis and the Universum, Adv. Visual Comput. 5359 (2008) 581–591
. [32]
C. Shen, P. Wang, F. Shen, H. Wang, Uboost: boosting with the Universum, IEEETrans. Pattern Anal. Mach. Intell. 34 (4) (2012) 825–832
. [33]
X.H. Chen, S.C. Chen, H. Xue, Universum linear discriminant analysis, Electron.Lett. 48 (22) (2012) 1407–1409
. [34]
Z. Wang, Y.J. Zhu, W.W. Liu, Z.H. Chen, D.Q. Gao, Multi-view learning withUniversum, Knowl.-Based Syst. 70 (2014) 376–391
. [35] J. Weston, R. Collobert, F. Sinz, L. Bottou, V. Vapnik, Inference with theUniversum, in: The 23rd International Conference on Machine Learning, 2006,pp. 1009–1016.[36]
D.L. Liu, Y.J. Tian, R.F. Bie, Y. Shi, Self-Universum support vector machine, Pers.Ubiquit. Comput. 18 (2014) 1813–1819
. [37]
Y.M. Xu, C.D. Wang, J.H. Lai, Weighted multi-view clustering with featureselection, Pattern Recogn. 53 (2016) 25–35
. [38]
P. Sen, G.M. Namata, M. Bilgic, L. Getoor, B. Gallagher, T. Eliassi-Rad, Collectiveclassiﬁcation in network data, AI Mag. 29 (3) (2008) 93–106
. [39] H.J. Ye, D.C. Zhan, Y. Miao, Y. Jiang, Z.H. Zhou, Rank consistency based multi-view learning: a privacy-preserving approach, in: ACM International onConference on Information and Knowledge Management, 2015, pp. 991-1000.[40] G. Bisson, C. Grimal, Co-clustering of multi-view datasets: a parallelizableapproach, in: Proceedings of the IEEE 12th International Conference on DataMining, 2012, pp. 828-833.[41] M.R. Amini, N. Usunier, C.Goutte, Learning from multiple partially observedviewsan application to multilingual text categorization, in: Neural InformationProcessing Systems (NIPS), 2009, pp. 28–36.[42]http://multilingreuters.iit.nrc.ca/ReutersMultiLingualMultiView.htm . [43]
G.Q. Li, D.X. Zhao, Y. Xu, S.H. Kuo, H.Y. Xu, N. Hu, G.S. Zhao, C. Monterola,Entropy based modelling for estimating demographic trends, Plos One 10.9(2015) e0137324
.[44]
H.Y. Xu, S.H. Kuo, G.Q. Li, E.F.T. Legara, D.X. Zhao, C.P. Monterola, GeneralizedCross Entropy Method for estimating joint distribution from incompleteinformation, Physica A 453 (2016) 162–172
. [45]
V.N. Vapnik, Statistical Learning Theory, Wiley Interscience Press, New York,1998
.[46]
J. Demsar, Statistical comparisons of classiﬁers over multiple data sets, J. Mach.Learn. Res. 7 (2006) 1–30
.C. Zhu, Z. Wang / Applied Computing and Informatics 15 (2019) 172–181 181