Machine learning of grammars finds many applications in software engineer- ing, syntactic pattern recognition, computational biology, computational lin- guistic, speech recognition, natural language acquisition, etc. For example, software engineers usually want to recover grammar from legacy systems in order to automatically generate various software analysis and modification tools. Usually in this case the grammar can be semi-automatically recov- ered from compilers and language manuals [12]. In application areas outside software engineering, grammars are mainly used as an efficient representation of artifacts that are inherently structural and/or recursive (e.g. neural net- works, structured data and patterns) [19]. Here compilers and manuals do not exist and semi-automatic grammar recovery as suggested in [12] is not possi- ble. The grammar needs to be extracted solely from artifacts represented as sentences/programs written in some unknown language.

Our work is also related to renovation and legacy systems where renovation tools can be rapidly built once a grammar is available. However, current gram- mar inference techniques are not able to infer grammars of general-purpose programming languages (e.g. Cobol) [11]. By using the approach presented in this paper it is possible to infer grammars for small domain-specific languages. The paper is organized as follows: Section 2 gives a short overview of the seminal results in the grammar inference literature. Details of the genetic

MARS [9] is a semi-automatic inference system in the area of Domain- specific modeling (DSM). DSM is an example of model-driven software engi- neering where domain experts can use high-level specifications to describe the solution of a problem in their domain using domain concepts. The motivation of the MARS project was to address the issue of metamodel drift, which oc- curs when instance models in a repository are separated from their defining metamodel. Making use of already existing tools along with new grammar inference algorithms, the MARS system recovers metamodels that correctly define the mined instance models.

To infer context-free grammars for domain-specific languages, the genetic pro- gramming approach was adopted. In genetic programming, a program is con- structed from terminal set T and user-defined function set F. The set T contains variables and constants and the set F contains functions that are a priori believed to be useful for the problem domain. In our case, the set T consists of terminal symbols defined with regular expressions and the set F consists of nonterminal symbols. From these two sets appropriate grammars (chromosomes) can be evolved, which can be seen as a domain-specific lan- guage for expressing the syntax. For effective use of an evolutionary algorithm we have to choose

Many grammars can be concocted which reject the negative samples. How- ever, our search converges to the desired grammar better when we obtain grammars which accept the positive samples. Hence, it is a natural move to search in the space of all grammars which accept the positive samples, only. Negative samples are only taken into account when a grammar is capable of

accepting all the positive samples. Another reason is that negative samples are needed mainly to prevent overgeneralization of grammars [7]. Keeping these facts in view, the fitness value of each grammar is defined to be between 0 and 1, where interval 0 .. 0.5 denotes that the grammar did not recognize all positive samples and interval 0.5 .. 1 denotes that the grammar recognized all positive samples and did not reject all negative samples. A grammar with fit- ness value of 1 signifies that the generated LR(1) parser successfully parsed all positive samples and rejected all negative samples. For the given grammar[i] its fitness fj(grammar[i]) on the j-fitness case is defined as:

Previous attempts at learning context-free grammars resulted in ineffectual success on real examples. We extended this work by introducing grammar- specific heuristic operators and facilitating better construction of the initial population where knowledge from positive samples has been exploited. Our future work involves exploring the use of data mining techniques in gram- mar inference, augmenting the brute force approach with heuristics, and in- vestigating the Support Vector Machine (SVM) classification technique for context-free grammar inference [3].

