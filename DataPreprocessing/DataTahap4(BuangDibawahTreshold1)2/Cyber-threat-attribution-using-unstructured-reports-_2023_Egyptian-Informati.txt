Cyber-threat intelligence (CTI) is the knowledge base which include context, behaviour, actions taken and what are the impli- cations of this attack. CTI provides this knowledge base to mitigate against attacks [1 2 3]. It allows organizations to take inform deci- sions about future attacks and provide an opportunity to access challenges and threats they are facing in cyber space [4 5 6]. Today organizations are focusing on building their own knowledge repos-

deception techniques to hide its identity. Various benchmark frameworks are used in this this research work such as MITRE ATT&CK framework [10 11 12]. MITRE ATT&CK is a knowledge repository for the tactics, techniques procedures and cyber actors on real world attack patterns. It is an open-source repository which is very useful for the research community and industry in utilizing knowledge. It is also providing threat feeds in STIX format for orga- nizations to utilize in security devices. According to MITRE frame- work, tactics are the objectives which an attacker wants to achieve. Techniques are the mechanism and tools which an attacker use to achieve its objective. Groups are the attacker or cyber threat actor, the perpetrator behind an attack. This framework also provides information how to mitigate these attacks. Its database is continu- ously updating with the help of research community. Other bench- mark framework used in this study are APT Groups and operations

Furthermore, inclusion of detailed feature set i.e., TTP, malware, tools, target country, target industry, target application to profile cyber-threat actor is another major contribution of this research work. In earlier research only limited features such as TTP, tools and malware were used. Results showed that inclusion of detailed feature helps in more accurate detection of CTA. Features such as target country, target organization and target application has not been used in the research so far.

The layout of this paper is as follows. Related work is explained in Section 2. Problem statement is in section 3, Objectives and sig- nificance is explained in section 4. Proposed methodology is explained in section 5. Experimentation and results are explained in section 6, conclusion, and future work in section 7.

In this research work, proposed a model for cyber-threat attri- bution. A feature extraction model [32] named similarity-based vector representation (SIMVER) is proposed to extract features from unstructured CTI reports. This model is compared with word2vec and smoothed binary vector (SMOBI). 238 unstructured CTI reports are used. Deep learning models are used for attribution of different cyber threat actors. In this study [15,16], proposed that cyber threat actors use different tools and techniques to conduct attacks on organizations. It is somewhat difficult for attacker to change its tools. Therefore, it is very important to identify attacker from its attack patterns. This will help the organizations to protect against future attacks. Identification of these attack pattern is very

in the recent past. As it is somewhat difficult for organizations to detect such type of attacks. In this proposed study [63] a model know as triangle model is proposed. This model uses three attri- butes such as TTP, sector and tools to draw a relationship for attributing cyber-threat actor. The benchmark framework used for drawing relationship is MITRE ATT&CK. The proposed model will help in attribution of cyber-threat actor more accurately.

Availability of CTI reports is a major challenge in this domain. As the forensic investigation is conducted by security vendors, pri- vacy of users is kept secret , so availability of these reports publicly is a major challenge. For this reason, results are generated on imbalanced data sets which can affect the accuracy and perfor- mance. Different benchmark frameworks are used for validation of features. A unified benchmark may be used for producing accu- rate and precise results. Another challenge is extraction of useful information, a report contains a lot of irrevalant information and only few sentences in a report contains information about attack patterns, so extracting useful information from these bulk of data is a challenging task. Another challenge is the availability of reli- able reports. If reports are biased, or not of reliable vendors, then results may be biased and inaccurate.

Another challenge is the unstructured format of these reports, as there is no standard format. Different security vendors publish reports according to their own formats, even reports published by a security vendor is in different formats. So, it becomes a chal- lenging task to extract meaningful information. A major challenge is huge amount of data available (unstructured reports, blogs, threat advisories, hacker forums, social media, CVE, NVD, dark web), so extracting useful information from this huge amount of data is a challenging task. A challenge in cyber-threat attribution is the design of a fully automated mechanism which can draw a complete automated flow of an attack. It is a challenging task to design a complete automated framework for cyber-threat attribu- tion as attacker goes through different stages and mechanisms to complete an attack. There exist semi-automated mechanisms for describing an attack flow which helps in the attribution of a threat actor. Identification of relationship between different Incident of Compromise such as TTP malware, tools is a quite a challenge in this domain.

Limited number of features (TTP, tools) are extracted for CTA attribution so far in the research. There are other important attri- butes such as target organization, target country, target application which may improve the cyber-threat attribution process. This may provide a detailed information about the attacker profile. L. Perry

[32] extracted tools and TTP from unstructured reports. Proposed an embedding model known as SIMVER, after removing some reports used by L. Perry, results are generated on filtered reports. Detailed feature set not used in this work. Various research work generates results on different data sets, so results of different tech- niques cannot be compared. So far, no fully automated mechanism has been designed for the cyber-threat attribution. There is semi- automated mechanism which design attack flow process. Cyber- threat attribution has been evaluated on different frameworks such as diamond model, CKC, F2T2EA, MITRE framework. There is a need for single benchmark framework, based on which experi- mentation may be performed for comparative analysis. In these

techniques relationship between different TTP is drawn. There is a need to draw relationship between other features such as tools/- software, malware. It will help in attribution and can provide a more detailed relationship between different attributes. Important aspects in this domain are highlighted below such as NLP and machine learning techniques, features, results generated, perfor- mance metrics, cyber-threat actors, tools and framework gener- ated used in this domain are highlighted. These aspects are as follows.

In this research question, machine/deep learning models used in this domain has been highlighted. The effective techniques used in the literature are random forest, deep learning neural network, decision tree, LSTM and SVM . The above models are effective in producing high results. Classification problem is either multi- class or multi-label classification. In multi-class, there are more than two classes in the datasets, while in multi-label classification, there are more than two labels for a feature. To solve this problem in the literature various techniques such as BR-SVM, BR-DT, LP- SVM and LP-Naive Bayes ha been used

Q3. What kind of performance metrics have been used in liter- ature & which metric is most used?The performance metrics mostly used in this domain are accuracy, precision, recall, f- measure, confidence, support, and lift. Precision is the most used and effective metric used in the literature. Other used metrics are recall, f-measure and accuracy. Confidence, support, and lift are metrics for finding regularities and patterns from the datasets. Q4. Which data sets have been used in the literature?There has been limitation of data sets in this domain. Identifying data sets will be helpful for research community for future research, without the availability of data sets from reliable sources future research will be difficult in this domain. The datasets identified are unstruc- tured CTI reports (in text and PDF format. They are shown in

There are two types of features commonly used in this domain. High-Level Incident of Compromise (IOC) and Low-Level IOC. Tac- tics techniques and procedures (TTP), malware and tools are High level IOC. Low-level IOC are IP, URL, hash, domain name, source/ destination port, timestamp, and infection type. After literature review, it is evident that TTP is the most used feature in this domain. In the experiments, now researchers are mostly focusing on high level IOC, as their impact is high and everlasting. Identify- ing them can force the attackers to change their tools which is very difficult task.

83.3 % recall and 87.9 % f-measure.a. Which ML and Deep learning models outperforms other methods in literature?Deep learning neural networks out-performs machine learning models in this domain. Random forest and Support Vector Machine (SVM) also produces high results for machine learning models.

Q7. Which feature selection techniques have been used in liter- ature?Information Gain has been mostly used in this area. It is the commonly used technique identified for feature selection [15]. Its role is to identify the most effective feature from the data set.

Different benchmarks frameworks used in the literature have been identified in this research question. MITRE ATT&CK is most used framework in this domain. The purpose of these benchmark frameworks is to validate a feature. CKC is also used by the researchers before development of MITRE framework. CVE data- base is also used for extraction of features. Threat actor ency- clopaedia published in 2020 by Thai-CERT describes the attacker goals and motivations.

In this research question, identification of tools, expressions and information sharing platforms used in the literature has been iden- tified. STIX is considered the most used expression for cyber threat intelligence. Trusted Automated Exchange of Indicator information (TAXII) and Open-IOC are the platforms for extracting threat feeds. Open-source intelligence (OSNIT) is also used by the researchers. It is an open-source repository for collecting information about the attacker.

In this research question identified the novel frameworks and tools developed. Some of the commonly used frameworks are explained below.STIXGEN: - It is a tool developed for generation of CTI threat feed in a more detailed and comprehensive manner from raw text data. It will ensure sharing and availability of CTI feeds among various organizations.Action-Miner: - The goal of this tool is to extract low level IOC from CTI feeds more efficiently and accurately as compared to other tools.

Identified the security vendors and external sources used in this domain. It is important to know the reliable vendors and sources refereed by the researchers. Symantec, Fire-eye, Crowd strike, Trend Micro are mostly used, while for extraction of threat actions from raw data twitter stream is mostly used.

Manual extraction of attack pattern from cyber threat reports is a tedious and challenging task. Cyber-threat attribution has been carried out by extracting technical features i.e., TTP, tools, mal- ware. These features are not accurately identifying and detecting the modern-day sophisticated attackers. These features are not providing detailed information about attacker profile. Due to com- plex nature of attackers, there is need to include detail feature set which may also include features such as target country, organiza- tion, and application. So, there is a need to include these features and analyse their impact on the attribution process.

Cyber-threat attribution is a challenging task. The aim is to know the attacker who has conducted the attack. It is important step in formulating responses to cyber-attacks. The objective of this research work is to profile or attribute cyber-threat actor from their attack patterns i.e. TTP, tools, techniques, malware, target organization, target country and target application. The aim in this work is to profile the attacker to who has conducted attacks. This attribution helps in finding identity of the attacker, what tools and techniques they had used for the attack, what are the target country/organization and target application. Based on this knowl- edge, organizations can protect them from future cyber-attacks. It is a challenging task to extract features from unstructured data

and convert it into intelligence. This work will help security ven- dors to attribute or profile cyber threat actor on basis of attack pat- terns identified from the attacks. Profiling attacker with detailed features will give comprehensive and detailed information about the attacker. The major difference between proposed method and earlier ones is the inclusion of detailed feature set. This will help security analysts to know about the detailed profile of the attacker.

Feature extraction phase consists of three steps. First step is text pre-processing phase or known as text cleaning. Second step is fea- ture extraction in which novel embedding model known as attack2vec is trained on domain specific embeddings from differ- ent cyber-threat intelligence data sets. The third step is semantic mapping or feature validation phase in which cosine similarity is used to find similarity between different documents and sen- tences. In this step feature extracted are validated from benchmark frameworks.

The task in this step is to validate extracted features against benchmark frameworks such as MITRE ATT&CK, CAPEC, APT group and Operations, Global Industry Standards, alternative country names from Wikipedia, application names from Wikipedia are used. Extracted feature is validated against benchmarks frame- works. If the feature is validated from benchmark framework, then it is included in the corpus. TTP, malware is validated from MITRE, CAPEC, APT group and operations. The feature target industry is

The next phase is the cyber-threat attribution, knowing the actor behind a cyber-attack. In the recent times role of machine learning in the cyber-threat attribution has been increased. The role of machine learning is becoming very important, and it is the need of hour also. As there is a need for development of accu-

It is a supervised machine learning algorithm that is used to solve classification as well as regression problems. This algorithm is constructed from decision tree algorithm. A random forest con- sists of many decision tree. The forest that is created is trained through different bagging and bootstrap aggregation techniques. This algorithm is more accurate than decision tree. It provides a mechanism to handle missing values. A major advantage of this algorithm over decision tree is that it can solve the problem of overfitting. It takes less time to train the model and it can handle large data sets.

embedding model is around two million. The extracted features are stored in index archive after using attack2vec model. These extracted features are matched against benchmark frameworks such as MITRE ATT&CK, CAPEC and APT group and operations by using cosine similarity. It is used because it is considered one of the leading method for document classification. If a document con- tains features its value is high, means it is most similar. If a docu- ment contains less matched features, then its value is low. After feature validation, the CTA attribution phase comes in which cyber threat actor is extracted by using different classification algorithms such as decision tree, random forest, and support vector machine. The aim of CTA attribution is to know about the actual attacker behind the attack.

of the model. Precision tells us that what percentage of tuples that classifier label as positive is positive. Recall is also known as sensi- tivity; it tells us that what percentage of relevant results are pre- dicted correctly by the classifier. F1 measure is the harmonic mean of precision and recall. The formulas used to calculate these metrics are shown below. Ratio of training and testing data is 80:20. Implementation of heat map of the model is shown in

96.6 %, 95.58 % and 95.75 %. The individual performance of threat actors shows that most of the threat actors are predicted accu- rately. APT3, APT17, APT28, APT29, Deep-panda, Fin7, Lazarus, Menu pass, Oilrig has 100 % precision, recall and F1 measure. Three classifiers i.e., Rocket kitten has 80 % precision, 100 % recall and

This work has certain limitations. There is limitation of data sets in this domain. It is difficult to find data sets for experimentation in this field. There is no standard format of reports (unstructured reports), so it is difficult to extract useful information. Imbalanced Data sets. No benchmark data set in this field. Different research work is done on different data sets, so it is difficult to compare dif- ferent techniques with each other. It is difficult to extract all fea- tures from a report, there can be missing values.

Future work in this area is to include behavioural features for cyber threat actors. The inclusion of behavioural feature might improve attribution of CTA. The major challenge in using beha- vioural attributes is the availability of datasets. How to extract behavioural attributes is still a major challenge in this domain. Future aim to find the optimal features for cyber-threat attribution by using hybrid features i.e., technical and behavioural features.

Kim BI, Kim N, Lee S, Cho H, Park J. A study on a cyber threat intelligence analysis (CTI) platform for the proactive detection of cyber-attacks based on automated analysis. 2018 International Conference on Platform Technology and Service (PlatCon). IEEE; 2018.

