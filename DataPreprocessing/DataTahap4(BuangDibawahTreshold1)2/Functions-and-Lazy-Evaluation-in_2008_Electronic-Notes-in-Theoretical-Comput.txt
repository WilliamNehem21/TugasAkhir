Both functional and logic programming styles provide appealing resources for pro- gramming and there have been different approaches for combining both paradigms in order to amalgamate the most interesting capabilities of them. This is the core idea of functional-logic languages such as Curry [8,9] or Toy [4,13]. They have a strong influence of Haskell in their syntax, higher order capabilities, type inference systems, etc. Moreover, following Haskell, lazy evaluation has been incorporated as a primitive feature. In a certain sense (apart from type classes and some other sophisticated features) they can be seen as an extension of Haskell. In fact, a big collection of Haskell programs runs in Toy or Curry with minor changes. In addition, these functional-logic languages incorporate from logic programming non- deterministic functions, logic variables treated by a generalization of unification

in our context, with non-deterministic computations involved, these delayed com- putations may destroy our intended semantics for programs. We do not provide a formal semantics in this work, but our informal argument is as follows: lazy declarations can achieve termination for functions that diverge under eager eval- uation. But assuming termination we want to obtain the same result(s) for a function call, with eager or lazy evaluation, or even with a mixture of both. This corresponds to the call-time choice semantics adopted in functional-logic systems like Toy or Curry. The above mechanism for lazy evaluation does not satisfy our aim, and we need to introduce some sharing structure (as in Toy and Curry).

There is an important aspect about the meaning of rules that we must clarify. Given a function rule, the order in which computation is performed is the following: firstly parameter passing is done by unification, then conditions are satisfied and finally the body of the rule is evaluated to obtain the result. This is not the only possible translation. An alternative way to proceed could be for example to do parameter passing, evaluate the body of the function and then satisfy the conditions.

Another interesting thing when mixing functions and predicates may be to use a predicate as a function choosing one or some arguments of the predicate as the returning value(s) of the function. The file prelude provides a projection function proj for this purpose. This projection is useful in general to exploit the built-in predicates of Prolog in a functional style. A call of the form proj(T,G) evaluates the goal G and returns the Prolog term T with the corresponding bindings for variables. For example, the following function takes a Prolog term and returns a pair with the main functor and the arity of it:

For higher order functions we perform a translation into first order using a well known technique that was also implemented in the language Toy [4]. The idea is to consider every partial application as a Prolog term instead of a proper function call and to use a new function @ (read apply) for applying these partial applications to arguments. The function @ is defined as an infix operator and the translation generates its rules for (every partial application of) all the functions of the program. As an example, consider the program:

We adopt a middle way: our functions are strict by default, but we allow lazy evaluation by means of explicit annotations. This idea is not new as the functional extension of Prolog proposed in [5] allows lazy annotations for functions. Further- more, some strict functional languages such as OCaml provide resources to suspend the evaluation of expressions and to force its evaluation when needed. In the next Sections we explore these approaches.

The proposal of [5] allows to declare a function to be evaluated lazily. In the translation to Prolog predicates, the evaluation of those functions is suspended until the result is demanded by unification at some predicate. This is done by means of the primitive control freeze(Var,Goal) that delays the execution of Goal until Var is bound. To illustrate this translation consider the following program:

Now consider again the evaluation of the function firstNats(3), i.e., the goal firstNats(3,L). The goal from(1,L1) generates a suspended call to from- Lazy(1,L1). The variable L1 will be demanded by unification when evaluating take(3,L1,L). Then we obtain a list with head 1 followed by a suspended call to fromLazy(2,L2). In this way we obtain a list with the elements 1,2 and 3, followed by a suspended call to take(0, <susp>, K) that provides the answer K = [] using the first clause of take.

The functions from and take have the same meaning as in previous examples. Notice that they must explicitly suspend and force evaluation according to the declared type. Finally, we can force the evaluation of a lazy list using the function nf, which takes a lazy list and returns a standard list in normal form (without any deferred computation). For example, the expression nf (take 4 (from 1)) will be evaluated to the list [1,2,3,4].

This last version contains essentially the idea that we will incorporate to our trans- lation, but it presents a problem: while the first version implicitly provides sharing (because OCaml stores the computed result after the evaluation of a thunk, for avoiding reevaluation), the second one does not. In our context this is not only a problem of efficiency, but the intended semantics could be destroyed as we will see in Section 5.2.

In our setting we provide laziness annotations for data type constructors. With only this information, the translator will introduce the appropriate suspensions and the corresponding manipulation for them. We start showing a basic translation scheme and then an extension to capture sharing.

The previous translation can have an undesirable (or at least unexpected) behaviour when non-determinism is involved. Let us examine an example to illustrate the situation. Consider the classical Prolog generate and test algorithm for sorting a list: generate permutations of the list in a non-deterministic way and test if they are sorted. This algorithm, using (non-deterministic) functions can be easily implemented in Functional Prolog as:

The function permut returns a permutation of the list by inserting the head of such a list into a permutation of the rest of the list; insert puts an element into a list at any possible possition (by backtraking). The function sorted checks if the given list is sorted. And finally, permutSort generates a permutation of the list and if it is sorted then returns it (if it is not sorted, by backtraking will search for another permutation). The function sorted checks if the given list is sorted. And finally, permutSort generates permutations of the list searching for a sorted one by backtracking. The function ifThen is defined in the prelude with the standard meaning.

This rule first checks if the expression has been previously evaluated by looking up the flag Ev. In such a case, the resulting value is the one stored in Res. In other case we evaluate Expr, set the flag and return the obtained value. The notation ExpRes indicates that the expression Exp must be flattened in such a way that the resulting value is Res. For example, the function app is defined in the prelude as:

Now, coming back to our example, the function permutSort works as desired and the goal permutSort([4,3,2,1],L) will produce a unique answer L=[1,2,3,4]. Using lazy lists the algorithm is drastically improved in efficiency as expected. Moreover, the translation incorporates some (quite technical) optimizations that improve the efficiency even more.

In this section we will give an idea of the capabilities of the functional Prolog model proposed in this work and its performance. We are interested in the comparison with similar approaches, in particular, with functional-logic programming and with the approach of [5] that we have summarized in Section 4.1.

The approach of laziness of Section 4.1 was introduced in [5] as an extension to Ciao Prolog [3]. That proposal is very close to our current approach, as both are functional extensions of Prolog, with optional laziness. It is different from ours in its treatment of higher order and some other aspects, but the most interesting difference is with respect to laziness. Unfortunately, the implementation is not included in the Ciao Prolog distribution and so we must use the translation scheme seen in Section 4.1 for comparison.

As we have pointed out in Section 4.1, implementing this model for laziness is quite straightforward just using the resources of standard Prolog for delaying com- putations. This approach has the advantage that most of the work about laziness is automatically done by Prolog, using its capabilities for delaying goals. Never- theless, this model of laziness can be hard to manipulate as, in general, choosing which program functions must be lazily evaluated is not a trivial issue. As an easy solution we could turn every function lazy, but in this case the efficiency of the program would be seriously affected.

Each row can be represented as a list, hence being the triangle an infinite list of lists. In general, the row i-nth (i > 0) is obtained adding pair of consecutive elements of the previous row and putting 1 as the first and last element in the resulting row. Given a row F , say [1, 3, 3, 1] we can elegantly obtain the next row as follows: we build the lists [0, 1, 3, 3, 1] and [1, 3, 3, 1, 0] and then add the elements at the same positions obtaining the list [1, 4, 6, 4, 1]. This process can be done within a single (functional) expression:

The function iter(F) evaluates all the next rows (an infinite number) from a given row F and pas calls it with the initial row [1] to obtain the complete triangle. The functions row and comb are functions for testing the program (nth(N) is defined in the prelude and returns the N-nth element of a list, starting at position 0). row(N) returns the N-th row of the triangle and comb(N,M) returns the combinatorial number N  using the fact that the M-nth element of the N-nth row of the triangle is exactly that combinatorial number. We can obtain for example the row 8 of the triangle by throwing the goal row(8,K), nf(K,L):

Having laziness associated to data type constructors instead of functions provides a finer control over the construction of data structures. In this example, we use (lazy) lists both for representing the rows of the triangle and also to collect those rows, but one could think about these lists as different kinds of structures. In particular, if we were interested in getting complete rows of the triangle (first goal above),we could improve this code by distinguishing two data type structures. Rows could be represented as (a new kind of) lists with constructors nil and cons:

The evaluation function eval is defined in a natural way using Prolog cuts (the last rule stands for a single number). The rule for division must make some tests as it is understood as integer division. Finally, the function sol(V,L) generates an expression with the operands of the list L and tests if it is a solution. By backtracking this function will find the solution for the problem if it exists. For example, sol(28,[3,6,4,5]) will return mult(plus(5, div(6, 3)), 4), that is, (5+6/3)*4. If we evaluate sol(26,[4,5,3]) we do not obtain any solution as the numbers 4, 5 and 3 do not allow to get the exact value 26. It would be interesting to obtain the best approximation to the solution from the program above. A typical solution in Prolog for this kind of problems is to use some meta-predicates to explore the search space. Using higher order functions we can encapsulate this search operation. It

expression. For example, genExpVal(17,[3,4,1]) may return (3*4+1,4) as 3*4+1=13 and the difference with the total 17-13=4; another result may be (3*4,5) as 17- 12=5. The function better(C1,C2) returns the best between the candidates C1 and C2, where a candidate is a pair expression-valorization as we have seen. Now, for the expression bestApprox(26,[4,5,3]) we would obtain the expression mult(3, plus(5, 4)) and the valorization 1 (3*(5+4)=27 and 27-26=1).

In this work we show how to extend Prolog with functions performing a translation of function rules into Prolog predicates. We introduce a simple syntax for func- tion definition and a transformation of higher order to first order syntax including lambda abstractions. With these features we can talk about functional Prolog. The extended language implements an eager evaluation mechanism, but we explore some alternatives for introducing lazy evaluation by means of user annotations.

It is possible to manipulate optional laziness by introducing annotations on func- tions or on constructors. In practice it is easier to use the second alternative because to decide which functions in a program must be lazily evaluated may be a hard task, while it is not difficult to think about the data structures that must be lazily con- structed. Moreover, experimental measurements show a better performance when using lazy constructors.

For the first problem we extend lambda abstractions with a sharing structure that ensures call-time choice. For the second one, the translation incorporates a complete mechanism for delaying computations and forcing later on their evalua- tion. Similar transformations have been proposed for eager functional languages [6] and are close to context-sensitive rewriting [7,14]. As a future work it would be inter- esting to study the relation of our lazy annotations with context-sensitive rewriting, at least for the declarative fragment of functional Prolog (excluding metaprogram- ming).

We have presented a collection of examples showing the capabilities of the pro- posal. In particular, we obtain a fine control on laziness that can be used to improve the efficiency of programs. On the other hand, combining the meta-predicates pro- vided by Prolog with the functional extension we obtain sophisticated resources for exploring the search space.

