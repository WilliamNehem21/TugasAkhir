We take HFC as a pivotal example of the open-source computer system plan. We abstract reusable functions (funclets) across system stacks among IoTs, edges, and data centers. Based on funclets, we rebuild the IoTs, edges, data centers, and humans-in-the-loop as a com- puter in a structural manner, with full-fledged functions of autonomic resource discovery, management, programming, workload scheduling, and coordinated collaboration between software, hardware and human components. Our plans are three-fold. First, we value the importance of benchmarks and funclet-based standards in evaluating and building the systems. Second, we emphasize the methodology and tool to facilitate the workload-driven exploration of the system and architecture design space. Third, we will provide the first open-source implementation of the funclet architecture of HFC systems.

We organize the rest of this paper as follows. Section 2 explains the motivation. Section 3 illustrates the HFC challenges. Section 4 explores the HFC software and hardware design space. Section 5 describes our plan. Section 6 summarizes the related work. Section 7 concludes.

the medical system can reasonably allocate medical resources for rapid rescue. It is worth noticing that medical experts play a deci- sive role in the system. Medical emergency management systems consider medical professionals a reliable external component in the control loop, which we call reliable-human-in-the-loop. In this scenario, the system may make recommendations, but the medical expert takes the responsibility, and the decision made by the system is Reversible.

The computation patterns follow the observe, fuse, recommend, and train patterns. The IoT devices observe the data of the pa- tients at different levels. The system may fuse various obser- vations at the edge or data center. The data centers or edges will train and update an AI model through the widely collected and labeled data. The IoT or edge makes a recommendation like alert and further-taken actions. The medical experts make a final decision.

Task types: highly-automated and mainly safety-critical. The future autonomous driving would be highly-automated, even fully-automated, and consider no human in the control loop. The corresponding system needs to perceive and collect multi-source and multi-dimensional data in real-time and respond within sev- eral milliseconds. Considering the properties of high autonomy, hard real-time, and potentially destructive effects, the decision and action made by the system are irreversible. It will be a system failure in hard real-time when missing a deadline. In auto-driving, missing a deadline will be catastrophic.

Various IoT devices generate a massive volume of hetero- geneous data. Autonomous driving depends on a large number of sensors; even a single car may deploy multiple kinds of sen- sors [28,29] including cameras, ultrasonic radar, millimeter-wave radar, lidar, IMU (Inertial Measurement Unit), etc., to obtain the environment information comprehensively. The input data are multi-source and heterogeneous; thus, the system should be able to fuse multi-sensor data for quick processing.

Organizability and manageability challenges. Unlike a tradi- tional computer system, e.g., a supercomputer or warehouse-scale com- puter, an HFC system is geographically distributed, consisting of IoTs, edges, data centers, and humans-in-the-loop. Moreover, they are dy- namic. For example, in smart defense systems and applications [6],

sensors or terminal control units can be dispersed by airdrop, inserted by artillery, and/or individually placed by an operation team [6]. In an extreme case, the spatial realm even has no bound. For example, un- manned spacecraft may have no bounded destination in interplanetary exploration applications.

The effective evaluation challenges. Generally, we need to deploy a system in a real-world environment and run a real-world applica- tion scenario to evaluate the performance and provide optimization guidelines. However, the real-world environment and emerging/future application scenarios are inaccessible and costly in assessing and verify- ing an HFC system. Hence, benchmarks as proxies of emerging/future

Simulation and validation challenges. At the early stage of system and architecture evaluation, the simulator plays a vital role due to the vast manufacturing investment of time and money and the immaturity of the corresponding ecosystem. For example, the effectiveness of the improved processor design, memory access technologies, etc., is evaluated on a simulator. Considering the cost of building a real-world HFC system, a simulation or vali- dation system supporting the whole environment simulation and technology verification is significant. However, the complexity and diversity of application scenarios pose substantial challenges in building such a simulator.

Second, simulation accuracy is a crucial metric. High accuracy means the simulator can reflect similar running characteristics to the real world and exhibit running differences under different sys- tem environments. Considering the difficulties of multiple-level or multiple-scale simulation, including hardware level, e.g., pro- cessor chip, cache, memory hierarchy, disk, and software level, e.g., operation system, ensuring the simulation accuracy is neces- sary but challenging.

CPU Benchmarks. We present CPU benchmarks covering typical workloads from emerging and future application scenarios from the low-level architecture benchmarking perspective. Constructing CPU benchmarks adopts a traceable methodology, managing the traceable processes from problem definition, problem instantiation, solution in- stantiation, and measurement [44].

For the second step, we attempt to define the ideal chiplet architec- ture for different IoT, edge, data center layers and different analyzed patterns. Specifically, according to the classifications in Step 1, we de- fine the computation, memory, networking chiplets for IoT, edge, and data center, respectively. Each layer of IoT, edge, or data center will contain multiple chiplets for different patterns of computation, mem- ory access, networking, etc. Additionally, each pattern may contain multiple chiplet designs according to the classifications of workload characteristics.

For the third step, we validate the chiplet architecture design and further performs improvements according to the feedback. We adopt FPGA-based simulation and evaluate the scenario, IoT, and CPU bench- marks to conduct the functionality and performance validation. Fur- ther, we explore the upgrades and design optimizations based on the validation results.

processor). We will implement the datapath processor as an accelerator. However, the network packet will be the first-class citizen in the datapath processor. The packet stream leaves the register file of the primary CPU and arrives at the datapath processor directly without going through a complex memory hierarchy. The datapath processor has full functionality, including access to the cache and main memory. Thus, the datapath processor can hold and process complex state infor- mation necessary for the data plane. The datapath processor also has accelerating units on the local bus; data exchange between the datapath processor core and accelerator can be low latency, highly paralleled, and fine-grain. We have not seen such the structure of the datapath processor before, but fortunately, open-source processors, like RISC-V based, allow us to design a novel processor architecture freely.

The design of a DSS needs to consider the characteristics of storage devices. We conclude two development trends of storage devices. On the one hand, the devices will be increasingly faster with microsecond- scale or even lower latency. Storage devices have experienced several technological breakthroughs in the past twenty years, such as the development of commercial SSD products, NVM-based SSD products (Intel Optane SSD [61]), and persistent memory products (Intel Optane PM [62]). Compared to HDD and ordinary SSD, NVM-base devices have much lower latency. In addition, emerging fast networks (e.g., 200 Gbps and 400 Gbps Infiniband) have round-trip latency of less than

The optimization object is uncertain. Finding the performance bottleneck in an HFC system is non-trivial. Users may feel confused about the optimization objects because of the optimization possibil- ities on IoTs, edges, or data centers and the complex hierarchies of algorithms, frameworks, software, and hardware.

Automatically co-optimization is non-trivial because of the vast op- timization space. There are thousands of optimization dimensions of the algorithm, software, and hardware, and the values of the variate vary in an extensive range. As a result, the optimization space is too huge to complete the search. Reinforcement learning has shown powerful capa- bilities for the problem of searching for optimal policies in a vast space. Evaluating is expensive in co-optimizing the algorithm, software, and hardware across the IoTs, edges, and data center. We will investigate the state-of-the-art learning algorithms and evaluation strategies and develop the corresponding tools for automatic optimization.

We abstract reusable functions (funclets) across system stacks among IoTs, edges, and data centers to guide the HFC system design and evaluation. We first propose to define a series of benchmarks and funclet-based standards and then build the tools to facilitate the workload-driven exploration of the system and architecture design space. Finally, we provide open-source implementations of an HFC sys- tem. We will perform system co-design from the vertical and horizontal dimensions throughout the process. Vertically, we comprehensively ex- plore the algorithms, runtime systems, resource management, storage, memory, networking, and chip technologies. Horizontally, we deeply discover the collaboration and interaction among IoT, edges, data centers, and humans-in-the-loop.

We summarize several HFC challenges: organizability and manage- ability, collaborations between software, hardware, and people com- ponents, irreversible effect, ecosystem wall, and effective evaluation. To tackle the above challenges, we propose reconstructing IoTs, edges, data centers, and humans-in-the-loop as a computer rather than a distributed system; we adopt a funclet methodology of building large systems out of smaller functions and exploring HFC design space in a structural manner. We will provide the first open-source implemen- tation of the funclet architecture of HFC systems. The source code will be publicly available from the project homepage: https://www. computercouncil.org/HFC/.

