Concepts from Information Theory have revealed quite convenient in this do- main. In particular, the notion of noisy channel has been used to model protocols for information-hiding, and the flow of information in programs. The idea is that the input of the channel represents the information to be kept secret, and the output represents the observable. The noise of the channel is generated by the efforts of the protocol to hide the link between the secrets and the observable, often achieved by using randomized mechanisms.

Now, the question is how to measure information, and (correspondingly) what do we actually mean by uncertainty. We consider here two possibilities. The first leads to a multiplicative notion of leakage, and it follows the proposal of Smith [13]. The second leads to an additive notion, and it is new.

Let us consider first ML+. Because of Corollary 6.5, we know that ML+ is reached on a corner point, i.e. a distribution of the form (q1,..., q2k ) where each qi is either 0 or 1/r, and there are r elements with value 1/r in the distribution.

