Generally, human action recognition procedure consists of two main steps: action representation, and action learning and classification. Existing action recognition approaches are classified by Weinland et al. [1] based on action representation into two main approaches: global and local representations. Global representation approaches focus on detecting the whole body of the person by using background subtraction or track- ing. Silhouettes, contours or optical flow are usually used for representing the localized person. These representations are more sensitive to viewpoint changes, personal appearance variations and partial occlusions.

[4] proposed the Cuboid detector by applying 1-D Gabor filters temporally, Willems et al. [5] proposed Hessian detector which measures the saliency with the determinant of the 3D Hessian matrix, and Wang et al. [6] introduced Dense sampling detector that extracts STIPs at regular positions and scales in space and time. Also, various descriptors for STIPs have been proposed such as Gradient descriptor [4], Histogram of Oriented Gradients (HOG) and Histogram of Optical Flow (HOF) descriptors [2], 3D Scale-Invariant Feature Transform (3D SIFT) [7], 3D Gradients descriptor (HOG3D) [8] and the extended Speeded Up Robust Features descriptor (ESURF) [5].

Despite the popularity of local representation approaches, it has some drawbacks. One of the main drawbacks is the ignorance of spatial and temporal relationships between local features. This may be a major problem in human action recog- nition. The spatial and/or temporal connections between the detected low-level action parts are necessary to introduce intrinsic characteristics of actions. A lot of attempts have been made to weaken this limitation of the local representation approaches based on BOW model. To capture these relation- ships early work was introduced such as Laptev et al. [2], Liu and Shah [9], Gilbert et al. [10], Zhang et al. [11] and Bregonzio et al. [12].

This paper is organized as follows. Section 2 reviews the previous related work. Section 3 describes the proposed trajectory-based approach for video representation. Section 4 presents the experimental setup, datasets and discusses the obtained results. Finally, Section 5 concludes the paper.

resolution videos with cluttered background and fast motion, the number of resulting keypoints is far from sufficient which increases redundancy and noise level. Due to its spares repre- sentation base, tracking Harris3D STIPs as in [13] enhances the generated trajectories but using KLT tracker does not guarantee the corresponding point in the next frame is a feature point. Also, the temporal scalability of 3D interest points is limited to capture only the short (simple) movements. Finally, tracking the densely sampled STIPs achieved a great success [19], but still not discriminative enough because of the large number of extracted trajectories and its computation- ally consumption. The effect of using optical flow in tracking is decreased in dense trajectories due to the large number of feature points.

In this paper, we go further on the trajectory-based approaches for a local representation of human actions. Our trajectories are characterized by its generation. We select the cuboid detector as a point detector to generate denser trajecto- ries and matching the spatial information of the detected STIPs over consecutive framers to extract their actual move- ments. Furthermore, to overcome the short temporal scalabil- ity of the detected STIPs, the flow vectors computation is used as a linker and/or explorer for short trajectories.

comparing our results with the state-of-the-art results. The evaluations have been performed on three popular datasets: Weizmann, KTH and UCF sports. These datasets are chosen to test the performance of our proposed approach on the con- strained and non-constrained environments with different conditions.

size 3000. TD and HOG descriptors achieve accuracy 74.82% and 84.26% at codebook sizes 1000 and 4000, respectively. The high performs of TD descriptor at small codebook size 1000 can be explained by that it described the actions with short dimension vectors (18 dimension) which yields a lot of similar- ity between the different actions representation.

[13] reported 74% using the velocity histories description for their trajectories. Sun et al. [16] obtained 86.8% using the trajectories statistics description. When we compare with the TD description of our trajectories, an improvement of 14.42% is obtained above Messing et al. [13] and 1.62% above

15 frames in [19] and the codebook size = 4000. It is longer than our trajectories and that explains the lower results of TD descriptor. Also, due to the use of Cuboid detector (denser than dense sampling) and SIFT matching, the number of gen- erated trajectories is lower than dense trajectories and more curved.

The experimental results demonstrated that an improve- ment of 2% is achieved by the proposed approach when eval- uated on the UCF sports dataset over the latest trajectory- based approaches (dense trajectories) proposed by Wang et al. [19]. Also, an improvement of 0.4% is achieved when evaluated on the KTH dataset over the dense trajectories approach.

