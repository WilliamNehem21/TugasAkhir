Known algorithms for manipulating octagons do not preserve their sparsity, leading typically to quadratic or cubic time and space complexities even if no relation among variables is known when they are all bounded. In this paper, we present new algorithms, which use and return octagons represented as weakly closed difference bound matrices, preserve the sparsity of their input and have better performance in the case their inputs are sparse. We prove that these algorithms are as precise as the known ones.

The problem of the performance of octagons has already been studied: in partic- ular, Singh et al. [17] proposed an implementation of the Octagon abstract domain optimized in the case its representation is sparse. But they do not address the fact that it is dense as soon as interval bounds are known for many variables, and we anticipate that, for this reason, the sparsity is very low in their implementation.

Instead, in this paper, we propose to use new algorithms for the Octagon abstract domain: these algorithms work on a sparse representation for octagons, so that the cost of the analysis of two independent sets of variables is the sum of the costs of the analyses of the two sets of variables, taken independently. Our algorithms have the same precision as the traditional ones. Our main idea is the following: in order to ensure an optimal precision of all the operations, the data structures representing octagons, difference bound matrices, are usually kept strongly closed : that is, algorithms make sure that any returned difference bound matrix is a best abstraction. However, most often, strongly closed difference bound matrices are dense because of the necessary strengthening step. In this paper, we propose to weaken the maintained invariant on difference bound matrices and to keep them weakly closed hence skipping the strengthening step. Weakly closed difference bound matrices are not necessarily dense, so that we can use sparse data structures to represent them. We prove that some algorithms can be kept unchanged to work on weakly closed difference bound matrices without losing any precision and give new algorithms for the other operations.

This has two benefits: first, all the different kinds of constraints allowed by (1) get factored out as one simpler form. Second, we can see these constraints as constraints on irregular environments, and further constrain them as being regular: we see that the study of the Octagon abstract domain starts by the study of a simpler abstract domain, where only differences of variables are bounded. The set of constraints, called potential constraints, of such an abstract domain is well studied in the lin- ear optimization literature, because it corresponds to the well-known shortest path problem in a weighted directed graph.

An important fact is that we can characterize best abstractions using the values they contain, and that we have algorithms to compute them. We expose these char- acterizations, together with these algorithms. Moreover, we give a weaker closedness condition over DBMs, that does not ensure canonicity, but that allows better algo- rithms without loss of precision.

Usually, the implementations of the Octagon abstract domain maintain all DBMs strongly closed, so that maximal information is known when performing an abstract operation. However, this breaks sparsity: indeed, matrix elements of the form Buu are non-relational interval bounds on the variables: as we expect many variables to be bounded, the strengthening step gives finite bounds for many DBM cells, and a strengthened DBM loses most of the sparsity. In general, a DBM has a quadratic size in the number of variables, and therefore this loss of sparsity is costly. Previous attempts at improving performances using sparsity [17] did not make this observation. We believe that, when using these implementations, DBMs quickly become dense, hence reducing the efficiency of sparse algorithms.

The rationale behind this example is that a join can create some amount of relationality that was not present in one or both operands. Our operator has to reflect this fact. Care should be taken, however, not to break the sparsity of the operands by introducing spurious finite values in the matrix. Our join for weakly closed DBMs is defined as follows:

The first step can be computed by iterating over all the matrix elements that are different in A and B. This first step thus preserves the sparsity, and consumes computing time only for variables that are different in both branches. The second step can be computed efficiently by first collecting in a list all the variables u for which Auu < Buu and, in another list, all those for which Buu < Auu. By iterating over the two lists, we can efficiently modify only the cells meeting the given condition. It should be noted that we break in the second step only the sparsity that needs to be broken, as the modified cells correspond to the cases where the join create new relational information (as in the example above).

In this paper, we presented new algorithms for the Octagon abstract domain, which preserve the sparsity of the representation of octagons. These algorithms are as precise as the usual ones, and rely on a weaker invariant over difference bound matrices, called weak closedness. We have shown that these algorithms can be used in the context of rational or real environments as well as in the context of integer environments.

