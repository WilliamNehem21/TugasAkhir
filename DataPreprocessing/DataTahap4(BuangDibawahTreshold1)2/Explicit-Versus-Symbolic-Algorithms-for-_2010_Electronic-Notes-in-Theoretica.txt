Static analysis can be seen as a two-phase process where we first transform the analysis problem into a set of constraints that, in the second phase, is solved to pro- duce the analysis result of interest. The constraints may be expressed in a language tailored to the problem at hand, or they may be expressed in a general purpose con- straint language; in this paper we follow the latter approach and consider ALFP, Alternation-free Least Fixed Point Logic, which is an extension of Datalog. ALFP has successfully been used as the constraint language for sophisticated analyses of a wide variety of programming paradigms including imperative, functional, concur- rent and mobile languages and more recently for model checking [4,12].

While a wide variety of analysis problems can be rephrased into the same con- straint language it is not necessarily the case that they all will benefit from the same solver techniques. We can for example imagine that certain solver techniques are better at handling certain types of input formulae, due to the use of specialized data structures. It is therefore desirable to be able to experiment with different data structures and algorithms for solving the constraints. Similar considerations

The rest of this paper is organized as follows. We first give the necessary back- ground information on Alternation-free Least Fixed Point Logic in Section 2. In Section 3 we describe the overall structure of the algorithm that is shared between the two solver algorithms. Sections 4 and 5 describe the data structures and the algorithms of the differential and the BDD based algorithms respectively. We con- tinue in Section 6 with experiments, employing model checking to verify a number of properties. We conclude in Section 7.

In the case of assertions the details depend on the actual algorithm and we shall return to those later. The case of conjunction is straightforward as we have to inspect both clauses. In the case of implication we make use of the function check that in addition to the precondition and the environment also takes the continuation execute(cl) as an argument. In the case of universal quantification we perform a recursive call using an updated environment; the details of which depend on the actual algorithm.

In this section we present the main data structures and the details of the differential worklist algorithm [14,13]. The algorithm computes the relations in increasing or- der on their rank and therefore the negations present no obstacles. It combines the top-down solving approach of Le Charlier and van Hentenryck [7] with the propaga- tion of differences [8], an optimization technique for distributive frameworks which is also known in the area of deductive databases [2] or as reduction of strength transformations for program optimization [15]. As mentioned above the main data structures are env and result representing the (partial) interpretation of variables and predicates, respectively.

In the case of universal quantification the function check needs to inspect all atoms from the universe and find the extensions of env that are compatible with the pre- condition pre. In order to do that we iterate over the entire universe, successively binding the atoms to x and modifying the partial environments to be compatible with the precondition pre. We enumerate the universe using the auxiliary function loop, which is initially called with the complete list of atoms in the universe. The recursive structure of the function loop reflects the fact that universal quantifica- tion is a conjunction over the entire universe. The pseudo code for the case is as follows:

The two algorithms have been implemented in F #, thereby allowing us to perform experiments for clauses with different characteristics. In this section we report on our experiments on problems arising from a modal logic representation of analysis problems. We make use of Action Computation Tree Logic (ACTL) [11] model checking to validate properties of programs written in a Pascal-like imperative lan- guage. A number of papers [18,17,16,9] have already noted the connection between iterative data-flow analysis and model checking. As an example the following ACTL formula expresses whether a variable x may have been last assigned at label l:

The formulation is based on abstractions of the actions that annotate the edges of a program model. Assignment statements, x := e, are abstracted to actions modx, whereas all other statements are abstracted to actions use. Intuitively, the formula verifies whether there exists a path, EF, not modifying variable x, leading to a state labeled l which has outgoing transition, EX, that modifies x. The ACTL formula is translated into the ALFP formula:

From the experiment results for modalities EX and EU we observed that both algorithms were slightly slower for the second case. This is caused by two fac- tors, greater length of the formula for modality EU and secondly the nesting of quantifiers, which in both cases is the same. Together, these factors determine the complexity of the algorithm [14]. What is more, the results show that the differen- tial algorithm outperformed BDD implementation by a factor of two in both cases. This is caused by the fact that when resuming computations the differential algo- rithm only propagates the differences, whereas in the current implementation of the BDD based algorithm entire clauses are recomputed.

