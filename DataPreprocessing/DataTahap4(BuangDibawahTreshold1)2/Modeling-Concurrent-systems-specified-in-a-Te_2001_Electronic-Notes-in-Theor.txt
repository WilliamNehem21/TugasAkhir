Our basic tool is the Timed Concurrent Constraint Programming (tcc) framework defined by Saraswat et al. to describe reactive systems. With this language we take advantage of both the natural properties of the declarative paradigm and of the fact that the notion of time is built into the semantics of the programming language. In fact, on this ground it becomes reasonable to introduce the idea of applying the technique of Model Checking to a finite time interval (introduced by the user). With this restriction we naturally force the space representing the behavior of the program to be finite and hence Model Checking algorithms to be applicable. The graph construction is a completely automatic process that takes as input the tcc specification.

cept to the CCP model. The fundamental contribution of the tcc model is to augment the ability of constraint programming to detect positive information with the ability to detect negative information. Such a negative information is crucial to model reactive and real-time computations [4]. tcc, in addition, incorporates the idea that once a negative information is detected it is too late to change the past. If some information has not been stored in that instant it will not be stored.

The method of Model Checking is an extremely successful approach to formal verification developed in the last two decades. With this method it is possible to verify a determined behavioral property of a reactive system over a model. It is an algorithmic method that makes an exhaustive enumeration of all the states reachable by the system and analyzes all possible behaviors [1,3,8,5].

In this paper we discuss the first two tasks with particular attention to the formalism for the representation of the model and to the restrictions for guaranteeing its finiteness. In fact, one of the main features of our approach consists in the fact that, working with a (declarative) constraint based lan- guage, we can build abstract versions of collection of models directly from the specification. Moreover, we also use the (explicit) notion of time present in tcc to bound variables and obtain models in which Model Checking can be performed classically. Indeed, the graph which we build is finite because in a given time instant we consider programs which are essentially determinate (terminating) ccp programs, while the evolution of graphs corresponding to different time instants is forced to be finite by the restrictions we impose on variable domains and time intervals.

In Section 2 we introduce the programming language tcc including a short description of its semantics and its main features. In Section 3 we introduce the definition of tcc Structure and present the basic definitions that allow us to formalize the method. In Section 3.3 we describe how to perform the first step in modeling the system producing a (finite) graph representation of an (a collection of) infinite state model(s). Then, in Section 4 we (briefly) discuss the introduction of the restrictions based on time parameters and values provided by the user. Finally, we draw our conclusions and comment on the steps which are necessary to complete the definition of our framework.

The other class of constructs are Timing constructs: Timed Negative Ask, Unit Delay, and Abortion that cause extension over time. Unit delay forces a process to start in the next time instant. Timed Negative Ask is a conditional version of Unit Delay, based on detection of negative information: it causes a process to be started in the next time instant if on the quiescence of the current time instant, the store was not strong enough to entail some information.

As a matter of fact, we will not proceed exactly in this way but we will leave some operator (e.g. the always A) non translated. This is done in order to obtain a finite representation of an infinite state model after the first modelization step.

One of the first activities in verifying properties of a system is to construct a formal model for the system. This model should capture those properties that will be verified. Reactive systems cannot be modeled by their input-output behavior: it is necessary to capture the state of the system, i.e. a description of the system that contains the values of the variables in a specific time instant. We have to model how the state of the system changes when an action occurs (transition of the system). In our case the state transition graph must be built starting from the tcc formalism introduced above and will eventually contain an explicit notion of time.

We can describe sets of states and transitions by first-order formulas es- sentially as usual (cf. [5,2]). The only difference in our case, is the fact that now our first-order formula representing the transition (R(V, V ',T )) has an extra parameter T expressing whether the transition corresponds to a passage to the next time instant or not.

A state of our graph (structure) is a set of constraints, that define the value of variables, and a set of labels, that represent the point of execution of the system. The labels are introduced in the original program and can be active or disabled, depending upon the store of the system at each time instant. If the store allows to execute the operation associated with a specific label, then this label is active, otherwise it is disabled. All labels representing a temporal operation are disabled while there exists a normal label active in the whole system (perhaps in another state).

In the following we define a construction that will return a graph represen- tation of a tcc structure associate to a given tcc specification. Such a graph can simply be seen as a pictorial counterpart of a tcc structure, with nodes representing the states and arcs representing the transition. To render the fact that we have two kind of transitions (depending upon the value of the third parameter in R) we will use two kind of arcs. The quiescence points can be identified in the graph because are those that preceded a temporal transition.

When we reach a state s where there is no active label, then we are in a quiescent point. Then we have to pass to the next time instant. In order to make this passage we have to analyze the labels in the labeling function of the quiescent state. First of all we analyze the Next agents, then the Negative Asks and finally the Always operators. In the graph construction it means that we create a new node t related with s by a temporal transition. In such node we introduce the labels associated to the body of the temporal agents present in the quiescence point. The store is set to the empty store and the execution proceeds as explained in the sketch of the procedure. Note the special case of the temporal labels associated to the always agents. For such labels we have

The existence of this cyclic behavior of the system is not guaranteed, it depends on the system itself. Thus, in order to ensure the finiteness of the graph construction we use the concept of (finite) time interval. This is the interval over which the verification will be executed, then we take an upper bound of such interval and, if we reaching such time instant whereas the construction is being performed, then we stop and obtain a model that is valid only for this specific verification. Otherwise, if we finish the construction before reach such time instant, we construct a generic model valid for whatever verification of the system. We describe now the construction of the graph for each syntactic construct.

Tell. tell c adds some information to the store in the current time instant. In our graph construction it is translated as a new node s' related with the node s from which it is executed. We define the labeling function L(s') as follows: the part representing the store is defined as the store of s plus the constraint c; the part representing the new point of execution is calculated removing the label representing the tell operator and obtaining the labels for the following agents in the specification. Finally we revise the active and disabled labels.

Positive Ask. if c then P verifies if the guard is satisfied in the present store and, if it is satisfied, then the program execution can continue with the body specification. In our graph representation we construct a new node where the part representing the store of the labeling function is defined as the union of the store in the previous state and the constraint specified in the guard of the agent. Note that it is necessary to introduce the information of the guard because the variables present in the condition could be parameters of a procedure. Then, the part of the labeling function representing the new execution point is calculated as in the previous case.

Parallel. (A || B) represents a concurrent agent where A and B are exe- cuted in parallel. It will generate different branches of execution. In our graph construction we introduce a new node related with the previous one that inherits from it the part of the labeling function representing the store. The part of the labeling function representing the new execution point will be calculated as it was explained in the previous cases. It is important to remark that for one node there will be as many direct descendants as activated labels contained in it.

Hiding. This operator represents the concealment of the variable to the rest of the system. It will be useful in the subprogram associated with the Hiding operator. In the graph representation it is expressed as a new node where the variables in the hiding operator are renamed apart. We apply the usual method to calculate the part of the labeling function that represents the point of execution.

Procedure Call. This operator refers to another procedure in the specifi- cation. All procedures will have different labels and variables. In our graph construction it is created a new node where the substitution affecting the parameters of the procedure p is applied and the label of the first agent of p is introduced. Finally we revise the active and disabled labels.

Always. always A allows us to model a cycle in the system behavior. In the graph construction we proceed by creating a new node s where the part of its labeling function representing the store is inherited from the ancestor node and the part of the execution point is calculated using our two pro- cedures follow and revision. These procedures will produce a temporal label associated to the always operator (again) and the label associated to the body of the always A agent.

The reason for which this structure cannot be used with classical ap- proaches is that we have not restricted the variable domains to be finite. Moreover, it is necessary to have all variable values in each state, whereas in our graph representation there are variables that do not have a specific as- signed value (for example, because it depends on the value of other variables). The solution to this problem is to introduce some kind of restriction to the representation forcing the variable domains to be finite.

We have defined an automatic transformation which takes a tcc program as input and returns a representation of the system behavior as a graph structure. Classical Model Checking approaches cannot be applied to the graph struc- ture constructed in this work because there exist some differences between the Kripke Structure constructed in classical works and our tcc Structure. The main difference is that we introduce two kinds of state transitions. In classi- cal approaches transitions between states represent the increase of time while in our framework normal transitions change state in the same time instant. There is an increment of time only when a timed transition is executed. This introduces a synchronization primitive because a process that would execute a timed operation has to wait until all other processes have finished their normal operations. Classical approaches are asynchronous because they as- sume that all parallel processes are independent from each other, thus they can be executed without waiting for any information calculated by the other

We ensure the finiteness of our construction by the following facts. In each time instant our language is similar to (terminating) determinate CCP, so each graph is finite. Moreover, for different time instants, we ensure finite- ness by imposing a restriction on the variable domains, by considering time intervals. Note a similarity with the work of Clarke et al. [2] in the fact that they introduce some synchronization when they impose that all processes of a parallel operation may finish at the same time instant.

