machine learning and text analysis algorithm, text can be classified into positive, negative and neutral categories according to sentence emotion. With the popularization of mobile Internet, network users have been accustomed to express their opinions and Sugges- tions on the Internet, such as the evaluation of commodities on e- commerce websites, social media reviews of brands, products, poli- cies, etc. How web users perceive and feel the real world, any choice they make is influenced by how other people perceive the real world. Therefore, it will excavate and analyze the opinions and feelings expressed by netizens on the things they are inter- ested in, and apply the research results to public opinion analysis, market research, customer experience analysis and other fields, this is the research significance of emotion analysis.

Because of the special structure of the tree, in this paper, Graph Convolutional Networks (GCN) is introduced to capture the high- level semantic information. Graph convolution was first proposed to solve non-Euclidean structural data in social networks, knowl- edge graphs and information networks. At present, it is widely used in image detection [9], user recommendation [10] and image classification [11]. Wan S [12] proposed that GCN network is used for text classification. The graph is constructed on the whole cor- pus set, the words and the number of articles are taken as nodes in the graph, and the edge in the graph is constructed by using co-occurrence information. Then the text classification problem is regarded as the node classification problem, and good results have been achieved [13]. In order to integrate grammatical infor- mation and make full use of syntactic structures in sentences, a syntactical dependence tree based GCN model is proposed to detect emotional polarity. First, it covers a Bi-GRU for feature extraction of each word; then, the word features and the adjacency matrix dependent on the analytic tree are fused into GCN, and the features are fused through the maximum pooling layer. Finally, the experiment results can be obtained through SoftMax function.

A novel graph convolutional network sentiment classifica- tion model (DTGRU) based on Chinese syntax-dependent tree is proposed. This model combines the preliminary fea- tures extracted by Bi-GRU with the syntactic tree of the sen- tence, and then convolves with GCN. To obtain the comprehensive characteristics of the text, so as to realize the emotional classification of Chinese text.

evaluation indexes. Through comparison experiments, the accuracy of DTGRU model and Macro_F1 value are improved by 4.45% and 3.71% compared with the benchmark model. It verifies the importance of using grammatical information and long-term word dependence, and proves the validity of DTGRU model in sentiment classification.

During the training, the model learns from the test samples used in the training, associating specific inputs (that is, text) with corresponding outputs (labels). An eigenvector converts the input text into an eigenvector. Pairs of eigenvectors and markers, input machine learning algorithms (e.g., Naive Bayes [1], SVM [14] (Sup- port Vector Machines) and LR [14] (Logistic Regression)) are used to generate models. During the prediction process, feature extrac- tors convert text inputs into feature vectors, which are then input into the model, generate a prediction label (such as positive, nega- tive, or neutral).

Kim [19] used convolutional neural network (CNN) to conduct a series of experiments on sentence level text classification with pre- trained word vectors. Thus, it shows that a simple CNN can achieve excellent results in multiple benchmarks with a small amount of super parameter adjustment and static vector. Makoto [20] pro- posed the emotional classification of customer comments by com- bining space pyramid pool with Max Pooling and using gated CNN. Meng [21] proposed a transfer learning method based on multi- layer convolutional neural network. Extracting features from the source domain, the weights are Shared in the convolutional layer and pooling layer between the source domain and target domain samples.

In addition to using CNN single, some researchers also combine CNN with RNN to achieve better classification effect. Jiang [22] combined LSTM and CNN, and utilized the ability of LSTM to deal with remote dependency and CNN to recognize local characteris- tics. Features extracted by the LSTM will be filtered again through convolution and pooling operations to find important local fea- tures. Luo [23] proposed that CNN with gated cycle unit could be used as classifier. According to the input characteristic matrix, GRU-CNN enhances word-to-word, text-to-text relationships to achieve high-precision classification of emotions. Abid [24] takes word embedding as the input of deep neural structure, three cyclic neural networks, namely Bi-LSTM, GRU and Bi-GRU, which are variants of RNN model, are used to capture long-term dependence. The above work does not use dependency resolution trees to train the deep learning network and ignores the syntactic informa- tion of the text. The dependency analytic tree can reveal the syn- onym structure of sentence more accurately and clearly. Therefore, the combination of Bi-GRU model and graphic convolu- tional neural network in this paper can enhance the emotional

In order to alleviate the long-distance dependence problem of traditional RNN and its gradient disappearance and gradient explo- sion in the back propagation process, based on RNN, LSTM adds input gate, forgetting gate and output gate to control input value, memory value and output value. In this way, the network can selectively discard or retain historical information. GRU is a further improvement on LSTM. GRU replaces forgetting gate and input gate in LSTM with updating gate. Due to fewer GRU parameters, the code is easier to modify and maintain, and the calculation amount in the process of training network parameters is greatly

each time step will learn to capture the characteristics of different dependent information under different time spans. In the classifi- cation of textual emotions, if the output of the current moment can be related to the state of the previous moment and the state of the next moment, just like a fill-in-the-blank, infer the word in the blank from the context of the blank. In this case, Bi-GRU is needed to establish this connection.

To sum up, although there is a growing body of research on ways to identify positive and negative emotions about a particular topic from online texts. However, most of these studies focus on sentiment analysis of English texts, while the field of Chinese sen- timent analysis is still in its infancy. Therefore, in order to learn more about the emotional characteristics of Chinese sentences and the hidden information in sentence grammar, a graph convo- lution network based on syntactic dependency tree is proposed. On the one hand, syntactic dependency trees are used to aggregate syntactic information into the representation of context and aspect words. On the other hand, the preliminary features of sentences are extracted through the Bi-GRU network and embedded into the syntactic dependency tree. Finally, the syntax-dependent tree input graph is convolved with the network to obtain the final emo- tional characteristics.

That is, the writing style is continuous, with no spaces. There- fore, according to the word segmentation standard, the steps of dividing Chinese text into a series of words are defined. This article selects Jieba, a Python package that deals with Chinese participles. It works by first tagging individual characters, then connect the tags with Spaces before returning the complete sentence.

Po oling is also known as sub-sampling. It only reduces the size of the matrix and does not change the depth of the three- dimensional tensor. Pooling layer can reduce the number of nodes in the full connection layer and alleviate the risk of overfitting by reducing the number of parameters in the whole neural network. In this paper, the maximum pool is used to extract some feature values from the output of the graph convolutional neural network. Only the value with the maximum score is taken as the pooling

There are two forms of dependency. One is to mark the depen- dency arrow and grammatical information directly on the sen- tence. The other is to make the grammatical relations of the sentence into a tree structure. This paper uses dependency arrows to indicate the grammatical relationships of sentences.

The experimental environment is Ubuntu16.04LTS operating system, CPU is COreI5-8300h, 64 GB memory, 2 TB hard disk, GPU is Nvidia GeForce GTX 1060. The experiment is based on deep learning framework Pytorch, and the development language used in the experiment is Python.

In order to verify the validity of the proposed DTGCN model, this paper crawled 99,300 valid microblog data. They are labeled as positive, negative and neutral. The training set and test set were divided in 8:2 ratios. For model training and for model testing. The

adopted. The Macro F1 value refers to the calculation of precision rate and recall rate respectively on the obfuscating matrix, and then the average value. Micro F1 first averages the corresponding elements of each confusion matrix to obtain the average values of TP, FP, TN, FN. Recall and precision are calculated based on these averages. For a single category, let TP be the correct predicted sam- ple, FP is the sample whose other category is judged as the current category, FN is the sample whose current category is wrongly judged as another category, then the exact rate P, Recall rate and F1 value can be calculated as follows:

better than other comparison models. The experiments of model 1 and Model 2 show that a single neural model (such as LSTM and CNN in the experiment). Due to the limitations of its own net- work results, it cannot better learn the emotional characteristics of the text. Therefore, it is difficult to improve the accuracy of emo- tion classification only by adjusting network parameters. The experiment of Model 3 is to add LSTM model on the basis of CNN model and input LSTM for semantic feature extraction. The output of LSTM is taken as the input of CNN for further feature extraction. Finally, the classification results are obtained. The experimental results show that although Model 1 and Model 2 are improved, the accuracy of model 3 is still low among other model results.

This section discusses the value achieved in this article. First of all, this paper established 99,200 large-scale Chinese emotion anal- ysis corpora through crawling microblog data for Chinese short texts in social networks emotional analysis; secondly, this paper combines the efficient double-layer gated neural network with the graph convolutional neural network to build the DTGCN model. In the data set, the DTGCN model achieved 90.51% accuracy and 90.34% recall rate. Compared with other most advanced deep learning technologies, LSTM and CNN, this result is better improved, because in previous studies, a model like Bi-LSTM only successfully captures context information. In this paper, GCN is

convolved in synter-dependent trees to optimize Bi-GRU embed- ding and obtain sentence structure and context information. Therefore, the DTGCN model is better than the more complex and up-to-date model when dealing with the same problem. Finally, the proposed DTGCN model can not only process the emo- tional analysis of Chinese text. If the corresponding language cor- pus is obtained and appropriate tags are added to the data set, it can better analyze the emotional polarity of other languages, such as English. This can provide a more detailed, deeper emotional analysis.

Next, this study will be further improved in the following aspects. Firstly, increase the granularity of sentences like good, joy, sorrow, anger, fear, evil, etc. Fine-grained partitioning helps provide data researchers with additional insights into existing data; secondly, the DTGCN model will be applied to other types of emotional tasks, such as user intention mining and false opinion detection. Evaluate the performance of the DTGCN model against data from other domains.

