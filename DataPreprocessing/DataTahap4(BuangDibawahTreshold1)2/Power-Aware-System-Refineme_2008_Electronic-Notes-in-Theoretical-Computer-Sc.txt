We propose a formal, power aware refinement of systems. The proposed approach lays its foun- dation to the traditional refinement calculus of Action Systems and its direct extension, time wise refinement method. The adaptation provides well-founded mathematical basis for the systems modeled with the Timed Action Systems formalism. In the refinement of an abstract system into more concrete one a designer must that show conditions of both functional and temporal properties, and furthermore, power related issues are satisfied.

where A and Ai, i = 1, 2, are actions; x is a variable or a list of variables; e is an expression or a list of expressions; and p and R are predicates (Boolean conditions). The variables which are assigned within the action A are called the write variables of A, denoted by wA. The other variables present in the action A are called the read variables of A, denoted by rA. The write and

Body P of the procedure p : p(in x; out y) : P , is in general any atomic action A, possibly with some auxiliary local variables w initialized to w0 every time the procedure is called. The action A accesses the global and local variables g and l of the host/enclosing system and the formal parameters x and y. Hence, the body P can be generally defined by: P [var v; init w := w0; A(g, l, w, x, y)]. If there are no local variables, the begin-end brackets [ ] can be removed together: [A(g, l, x, y]= A(g, l, x, y). If there are neither local variables nor parameters, the action only accesses the global and local variables of the host system, then the procedure p can be written as: proc p : A(g, l).

The interface part declares those variable, u, that are visible outside the action system boundaries, and thus accessible by another systems. It also introduces communication procedures that are either imported or exported by the system. The exported procedures are introduced by the system itself and the imported ones are introduced by some other systems. If a timed action system does not have any interface variables or procedures, it is a closed system, otherwise it is an open system.

Finally, the iteration section, the exec do-od loop of the system, contains the composition of the actions defined in the declarative part. The compu- tation of a timed action system is started in an initialization in which the variables (both global and local ones) are set to predefined values. In the it- eration part, the actions are selected for execution based on the composition and enabledness of the timed actions. If there are no such timed actions, the timed action system is considered temporary delayed. The computation resumes to execution when some other timed action system enables one of the action via interface variables or procedure calls.

In this section, we present a performance modeling framework for hardware systems by introducing how to model a size of an action system (timed or untimed one). Henceforward, we denote the size as area complexity. The purpose is to develop a framework that can be used to identify which one of the two arbitrary actions is larger, and therefore to make difference in energy consumption between these two actions. Furthermore, the energy of actions

Example 3.3 We briefly analyzed the accuracy of the addition and multi- plication operations using the BuDDy library. The OBBD was generated for addition operation described using full adders, and for basic binary multipli- cation using block multiplier structure. Both of these operators were analyzed using widths from 16 bits to 64 bits. The node counts of OBDD were com- pared with the width count of our area complexity model. The accuracy of our presentation was in both cases approximately 83%. This result is quite good for such a high abstraction level estimation, comparing to the amount of the information we have from the actions versus the fully defined Boolean functions, which are inputs for BuDDy.

Example 3.4 Consider a timed action system A which reads data from its local input buffer, performs an addition operation, and stores the result to its local output buffer. The system is modeled as a closed system, which does not interact with its environment. the system is defined by:

tion of the system, and the second term the static power consumption of the system. Dynamic power consumption is related to system operation. That is, dynamic power consumption can be reduced using different design methods such as self-timed design, see for example [16]. However, the static power consumption is caused by the leakage current Ileak, which is the combination of the sub threshold leakage (a weak inversion current across the device) and the gate-oxide leakage (a tunneling current through the gate oxide insulation) [15]. Detailed analysis of the leakage current can be found, for instance, in [15], [11]. In general, both the sub threshold and the oxide leakage depends on the total gate width or more approximately the gate count, temperature (sub threshold leakage), supply voltage, and oxide thickness (oxide leakage). The static power consumption can no longer be ignored, since the power con- sumption of chip leakage is approaching the dynamic power consumption, and the projected increases in off-state sub threshold leakage show it exceeding total dynamic power consumption as the technology drops below the 65 nm feature size [15]. Emerging techniques to moderate the gate-oxide tunneling effect could bring gate leakage under control by 2010. Let us first discuss the definition of the dynamic power consumption of an action including its energy model, and then the static power loss caused by an action.

Unlike dynamic power consumption, the static power consumption is not ac- tivity based. As stated above, it is a certain percent from the total power consumption of the system. To model the static power consumption of an ac- tion A, we adopt the unit action A1. The static power consumption in CMOS

where gA(t) refers to the guard of an action A at a given time t. Hence, the set SA(T ) contains all the actions that are enabled at some point during the observation period T . This includes actions that are either started or finished, or both started and finished, within the observation period T , as well as those actions that are started before and finished after the observation period T . The order of events in the set SA(T ) is determined by the temporal relations of the involved actions [22].

finish time T.ft denotes the time when the system is performed one oper- ation cycle T.ft = Op.ft. Naturally, the observation period is selected by the designer, but for simplicity, we illustrate the power analysis with single operation cycle. The average power consumption for the system is defined by

Relative constraints use relative timing of operations to define the order in which the operations much be executed with respect to each other in the time domain. The relative constraints are defined using relative orderings defined below. With the can be directly used in constraints to restrict the temporal behavior of timed actions. The relative constraints are, for example:

period T . Observe that, functionality inside the observation period in not altered during refinement steps. This restrictions follows from the deadline constraint, we cannot exceed the observation period if the deadline constraint holds for all timed actions in the system.

the system in question. A fundamental study of the trace refinement can be found in [7]. In the superposition refinement the behavior of a system model is enhanced by adding new functionality into the model while preserving the old one. The method is also extended to prove the correctness of data refinement of action systems with remote procedures in [20].

Timing behavior. From the timing point of view, we have to show that the constraint cnstD is satisfied by the new system. This can be proved by showing that the duration that it takes for data item to traverse through the new system does not violate the constraint. Therefore, we

8m+5 and C(W2)= m+5, respectively. The communication actions Snd and Rec are evaluated as follows: C(Snd)= 2m + 2, which includes the area complexity of the communication procedure n. The area complexity of the receiver action Rec is C(Rec)= m + 2, where the procedure call is modeled as a substitution operation. Observe that the area complexity of

P. Liljeberg, J Tuominen, S. Tuuna, J Plosila, and J. Isoaho. Self-Timed Methodology and Techniques for Noise Reduction in NoC Interconnects, Chapter 11 in Interconnect-Centric Design for Advanced SoC and NoC, Kluwer Academic Publishers, Boston, July 2004, pp. 285- 313, ISBN 1-4020-7835-8.

