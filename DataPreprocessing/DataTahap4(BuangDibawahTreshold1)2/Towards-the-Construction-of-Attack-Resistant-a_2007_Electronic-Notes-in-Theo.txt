Content dissemination generally follows one of three main delivery techniques, client-server-unicast, network multicast or application layer multicast. The client- server system architecture is relatively easy to implement and set-up and currently the prevalent solution. However, it suffers from the draw-backs of being unscalable over the number of clients and having a single point of failure: the server or cluster of servers itself. Though network layer multicast is far more scalable due to data replication in the routers of the backbone, it suffers from low acceptance and is not largely deployed today. This fact is due to a multitude of problems including billing issues and an inherent lack of scalability over the number of multicast groups [13].

Overlay streaming, or application layer multicast (ALM) [7], makes use of the resources at the edge of the network and thus introduces a different load balancing scheme. Due to its self-organization it is inherently resistant towards failure of and attack on nodes. This stability is increased for multi-source systems in contrast to single-source systems, which construct only one single streaming tree. In contrast, every node receives different parts of the content from different nodes, and the nodes are not necessarily reliant on a single preceding node only. Peer-to-peer systems have proven to be very resistant both towards failures and organized interference. The robustness of this system architecture becomes apparent when observing file sharing systems and the efforts to disable them.

[1] and it is comparably easy to create topologies which are resistant to random node failure, accomplishing attack resilience seems a significantly harder task. By implementing quick fall-back strategies and creating topologies with many leaf nodes and a small number of forwarding nodes only, high resilience towards node failure can be achieved. The load in this case is provided by a few nodes only and node failures in the large set of receiving nodes do not have any impact. An attacker however will most probably try to gain as much information about the topology as

Probabilistic Resilient Multicast (PRM)[4] is a derivative of the NICE[3] appli- cation layer multicast which in addition to the regular packet relaying implements a randomized forwarding scheme and retransmission of lost packets. Every node on top of the usual child nodes, which are provided with every received packet, chooses some additional nodes at random. Packets are forwarded to the additional nodes with a low probability, thus introducing a slight redundancy in the data delivery which leads to a lower susceptibility to node failure. Similar to PRM, FatNemo[5] is a hierarchical clustered application layer multicast derived from NICE. While in

With the content being routed from the source through the whole system, ALM cre- ate topologies of connections between neighboring nodes. Single source streaming systems build chains or multicast trees and multi-source streaming systems cre- ate a DAG or cyclic network of disjoint multicast trees. These topologies can be represented as special instances of graphs and used as a system model.

Multi-source approaches, which connect child nodes to more than one relaying parent, implicitly create a multitude of trees. If the resulting topology is a directed acyclic graph or a network with cycles depends on the routing decisions of the nodes. The construction of directed acyclic graphs and networks still hold different possibilities to achieve stability. While in a network a node in different stripes can be be both parent and child of another node, in a DAG all nodes are organized strictly hierarchical. In the event of a failing node, the orphaned child nodes in a DAG need to find out the position of other nodes in the hierarchy, in order to locate alternative parent nodes and to avoid loops. Thus, systems creating a DAG have the two draw-backs of an uneven relevance distribution of the nodes and the possibility to gain knowledge about their importance. In networks, the importance of nodes can easier be balanced by rearranging them.

Strict division of stripes in some cases can lead to dead locks. In this case a node can not drop all expensive links and has to forward another stripe in addition to its preferred one. However, it will try to pass the respected link to a different node in the next round.

In order to be able to keep the topology balanced, forwarding nodes keep track of the amount of successors of all its child nodes and their successors. Every node updates the successor information with its parents when it observes a situation change. To keep the protocol overhead low even in highly dynamic phases, this is done after waiting 10ms for additional changes.

In order to examine our algorithm and the routing decisions it takes, we evaluated the characteristics of the evolving topologies. Simulations of the system were con- ducted using OMNeT++, with varying capacities and amounts of stripes at first, to acquire snapshots of the topologies for further testing. To judge the stability, we used two metrics to measure the resistance: the mean node connectivity and the fraction of received packets after node removal.

To discover, why the evaluation did not always lead to the expected gains, we analyzed the topologies, which did not achieve the estimated results. Here we had to realize, that the gaps between the amount of additional stripes and both the rising stability and vertex connectivity were actually caused by dead-lock situations. In the topology construction, large subsets of nodes selected the same preferred stripe. This behavior led to problems that some nodes kept forwarding more than one stripe

Currently, we are examining the behavior of the dynamic system under attack. We are thus exposing the dynamic simulations of the system to greedy attacks based on global knowledge in order to measure the volatility and messaging overhead as well as the amount of lost packets due to different amounts of successfully attacked nodes. In future we plan to modify the algorithm to avoid the detected deadlocks in order to prevent long paths to evolve.

