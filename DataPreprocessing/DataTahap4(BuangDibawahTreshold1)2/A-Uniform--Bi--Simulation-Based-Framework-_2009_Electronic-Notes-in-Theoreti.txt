The downward (bi-)simulations, which straightforwardly generalise the appropri- ate backward (bi-)simulations from word automata to (bottom-up) tree automata, are compatible with the language inclusion preorder. That is, if a state r downward (bi-)simulates a state q, then the language accepted by q is a subset of the language accepted by r. Therefore, these relations are a natural choice for reducing the size of tree automata.

Moreover, in the previous works, we were randomly computing one relation out of the set of possible language-preserving combined relations. Here, we first prove that there is always a unique maximal combined preorder for a given upward simulation and its inducing downward simulation. In Section 6, we then provide a simple algorithm for computing this maximal preorder. From a practical point of view, using the maximal preorder instead of a random one has in some cases a great impact on the size of the reduced automaton as witnessed by our practical experiments.

The problem of computing (bi-)simulations over tree automata is addressed in [2,1,9]. In [2,1], a quite general method for computing tree (bi-)simulations via transforming this problem to special instances of the classical problem of comput- ing (bi-)simulations over labelled transition systems (LTS) is proposed. Classical (bi-)simulation algorithms like [11,12] are then applied to the LTSs obtained from the translation.

RTMC is the name of a family of techniques for analysing infinite-state sys- tems such as parameterised networks of processes, systems with queues, stacks, unbounded integers, and/or dynamic linked data structures like lists or trees. In RTMC, states are represented by trees, sets of states by tree automata, and tran- sitions by tree transducers (or, sometimes, also by some specialised operations on tree automata). ARTMC is a combination of RTMC and the abstract-check-refine paradigm which usually greatly improves the efficiency of the technique. Most of the algorithms in the frameworks of both RTMC and ARTMC rely crucially on ef- ficient automata reduction methods since the size of the generated automata often explodes, making computations infeasible without a reduction.

The tree automata that we have considered in our experiments arose within various computations within the frameworks of RTMC and ARTMC. Our experi- mental evaluation was carried out on an AMD Athlon 64 X2 2.19GHz PC with 2.0 GB RAM. We have compared the size of tree automata after reducing them with all the different reduction techniques considered in this paper.

The proposed framework is built on quite general principles and we believe that it can be extended to more advanced types of automata such as guided tree automata, nested word automata, or hedge automata that find their use in many applications in formal verification, decision procedures of various logics, structured document processing, or natural language processing. Reduction of automata from some of such classes has already been considered in the literature (e.g., in [8], the author proposes a bisimulation-based minimisation of weighted word automata, and a use of bisimulations for reducing weighted tree automata is considered in [10]).

From the practical point of view, it is also interesting to investigate more ef- ficient techniques of computing the (bi-)simulation relations, e.g., by computing them in a symbolic way (for symbolically encoded automata). Furthermore, it can be interesting to explore more deeply the principles of the proposed combination of downward and upward (bi-)simulation relations. One can, for instance, think of defining still weaker types of relations preserving the language of tree automata by using the combined relations repeatedly as inducing relations.

