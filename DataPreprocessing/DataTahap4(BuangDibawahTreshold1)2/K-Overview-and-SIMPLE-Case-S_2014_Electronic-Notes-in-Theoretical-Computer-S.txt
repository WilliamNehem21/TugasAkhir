The overview of the K framework presented in Section 2 is complemented by the complete literate definitions of the dynamic (Section 3) and static (Section 4) seman- tics of SIMPLE, a non-trivial programming language characteristic of the imperative programming paradigm. These sections demonstrate both the expressiveness and the modularity of the framework, as well as give compelling evidence that K can scale to larger languages. References to other research projects making use of K in achieving their goals are presented in Section 5. Section 6 concludes.

Functions and function values. Functions can have zero or more parameters and can return abruptly using a return statement. SIMPLE follows a call-by-value parameter passing style, with static scoping. Function names evaluate to function abstractions, which are ordinary values in the language, like the array references.

Concurrency via dynamic thread creation/termination and synchronization. One can spawn a thread to execute any statement. The spawned thread shares with its parent its environment at creation time. Threads can be synchronized via a join command which blocks the current thread until the joined thread completes, via re-entrant locks which can be acquired and released, as well as through rendezvous commands.

Syntax definition and parsing are difficult topics in their full generality, which have been extensively researched and implemented over several decades. Implementations of K would likely make use of existing techniques and tools for defining syntax and for parsing. However, at its very core, K is actually not concerned with concrete syntax at all. More precisely, the syntax of K currently consists of one syntactic category K for computational structures, or compactly just computations 3 , i.e., structures which have the capability to compute when put in the right context,

The corresponding cooling rules reverse the above rules. Note that, in particular, the cooling rule for the third context expects the wrapper to still be wrapping the expression, and it removes it upon plugging the expression back. This is to say that this wrapper should only have contextual meaning, used for altering the semantics, but being preserved by it. In some sense, these wrappers are actually providing locally typed evaluation contexts. One can devise other similar notations and it is likely that the K tool will incorporate new ones or different ones in the future. The point here is that the heating/cooling rules are quite powerful, giving K flexibility in defining complex evaluation strategies.

The concurrent K rewriting relation is more complex to define than the con- ventional concurrent term rewriting relation. That is because we want it to be as concurrent as possible, so that concurrent languages or calculi defined in K do not just have the standard concurrent semantics of rewriting logic, which forbids overlaps between concurrent redexes, but instead have greater concurrency by allowing over- laps between redexes, provided the overlaps only happen in their read-only portions. This means that two or more concurrent rewrites can simultaneously share some common portion of the state.

Capturing all the transitions of the K transition system using Maude would be possible (modulo interleaving some K concurrent transitions) by encoding all rules (both structural and computational) as rewrite rules. However, although providing completeness, this approach would have two drawbacks. First, to obtain the intended transition system from the one generated by Maude, all transitions obtained by applying structural rules will have to be regarded as internal transitions, hence the states they relate would have to be collapsed into a single state. Second, as mentioned above, even without the structural rules, the transition system quickly grows unfeasible to explore; with the addition of the structural rules (some of which are inverses of each other), this state space would become too large even for small and deterministic programs.

Arrays can be multidimensional and can hold other arrays, so their lookup operation takes a list of expressions as an argument and applies to an expression (which can in particular be another array lookup), respectively. The construct sizeOf gives the size of an array defined as the number of elements of its first dimension. Note that almost all constructs are strict in all their arguments. The only constructs which are not fully strict are the increment (since its first argument gets updated, so it cannot be evaluated), the input read which takes no arguments so strictness is irrelevant for it, the binary Boolean constructs which are short-circuited (and thus are strict only in the first argument), the thread spawning construct which creates a new thread executing the argument block and returns its unique identifier to the creating thread (so it cannot just evaluate its argument in place), and the assignment which is only strict in its second argument (for the same reason as the increment). The bracket specifies that the corresponding syntactic production is only used for grouping purposes (like a bracket) and should not be included in the abstract syntax tree.

The inclusion of values in expressions follows the methodology of syntactic definitions (like, e.g., in SOS): extend the syntax of the language to encompass all values and additional constructs needed to give semantics. In addition to that, it allows us to write the semantic rules using the original syntax of the language, and to parse them with the same (now extended with additional values) parser. If writing the semantics directly on the K AST, using the associated labels instead of

Ideally, one would like to perform syntactic desugarings like the one above before the actual semantics. Unfortunately, that is not possible in this case because the dimension expressions of the multi-dimensional array need to be evaluated first. Indeed, the desugaring rule above does not work if the dimensions of the declared array are arbitrary expressions, because they can have side effects (e.g., a[++x,++x]) and those side effects would be propagated each time the expression is evaluated in the desugaring code (note that both the loop condition and the nested multi-dimensional declaration would need to evaluate the expressions given as array dimensions).

This is tricky, because we want to allow both ++x and ++a[5]. Therefore, we need to extract the lvalue of the expression to increment. To do that we use the special kind of context specified in Section 2.4, stating that the expression to increment should be wrapped by the auxiliary lvalue construct when evaluated. The semantics of expressions wrapped by lvalue is defined at the end of this definition (Section 3.7). For now, all we need to know is that, under the lvalue wrapper, an expression and evaluates to a value representing its location. Location values, also defined in Section 3.7, are integers wrapped with the construct loc, to distinguish them from ordinary integers.

Untyped SIMPLE does not check array bounds. The first rule below desugars the multi-dimensional array access to uni-dimensional array access; recall that the array access operation was declared strict, so all sub-expressions involved are already values at this stage. The second rule rewrites the array access to a lookup operation at a precise location; we prefer to do it this way to avoid locking the store. The semantics of the auxiliary lookup operation is straightforward, and is defined towards the end of the definition.

The second rule pops the computation, the environment and the control data from the function stack when a return statement is encountered as the next compu- tational task, passing the returned value to the popped computation (the popped computation was the context in which the returning function was called). Note that the pushing/popping of the control data is crucial. Without it, one may have a function that contains an exception block with a return statement inside, which would put the xstack cell in an inconsistent state (since the exception block modifies it, but that modification should be irrelevant once the function returns). We add an artificial nothing value to the language, which is returned by the nullary return; statements.

Empty blocks are simply discarded, as shown in the first rule below. For non-empty blocks, we schedule the enclosed statement but we have to make sure the environment is recovered after the enclosed statement executes. Recall that we allow local variable declarations, whose scope is the block enclosing them. That is the reason for which we have to recover the environment after the block. This allows us to have a very simple semantics for variable declarations, as we did above. One can make the two rules below computational if one wants them to count as computational steps.

Dually to the above, when a thread terminates its assigned computation (the contents of its k cell is empty), the thread can be dissolved. However, since no discipline is imposed on how locks are acquired and released, it can be the case that a terminating thread still holds locks. Those locks must be released so other threads attempting to acquire them do not deadlock. We achieve that by removing all the locks held by the terminating thread in its holds cell from the set of busy locks in the busy cell (keys H returns the domain of the map H as a set, that is, only the locks themselves ignoring their multiplicity). As seen below, a lock is added to the busy cell as soon as it is acquired for the first time by a thread. The unique identifier of the terminated thread is also collected into the terminated cell, for the join construct.

The operation below is straightforward. Note that we tag it with the same lookup tag as the variable lookup rule defined above. This way we can specify that both rules should be considered transitions when exploring the state space by mentioning that the lookup tag defines transitions.

E is either a variable or evaluates to an array element. When that happens, E evaluates in this l-value context to a value of the form loc(L), where L is the location where the value of E can be found; for clarity, we use loc to structurally distinguish natural numbers from location values. In giving semantics to expression E in an lvalue context, there are two cases to consider. (1) If E is a variable, then all we need to do is to grab its location from the environment. (2) If E is an array element, then we first evaluate the array and its index in order to identify the exact location of the element of concern, and then return that location; the last rule below works because its preceding context declarations ensure that the array and its index are evaluated, and then the rule for array lookup (defined above) rewrites the evaluated array access construct to its corresponding store lookup operation.

Recall that, as mentioned in Section 2.4, the lvalue construct serves as a locally typed evaluation context. Therefore, the rules above preserve the lvalue context when evaluating expressions to their corresponding location values; the construct can only be added/removed by the heating/cooling rules which introduce it. For example, for the assignment evaluation context, the generated heating/cooling rules are:

Typically, there are two opposite tensions when designing a type system. On the one hand, you want your type system to be as permissive as possible, that is, to accept as many programs that do not get stuck when executed with the untyped semantics as possible; this will keep the programmers using your language happy. On the other hand, you want your type system to have a reasonable performance when implemented; this will keep both the programmers and the implementers of your language happy. For example, a type system for rejecting programs that could perform division-by-zero is not expected to be feasible in general. A simple guideline when designing typing policies is to imagine how the semantics of the untyped language may get stuck and try to prevent those situations from happening.

Each primitive value has its own type, i.e., int, bool, or string. There is also a type void for nonexistent values, e.g., for the result of a function meant to return no value (but only be used for its side effects, like a procedure).

Functions are also typed in a C/Java style. However, since in SIMPLE we allow functions to be passed to and returned by other functions, we also need function types. We will use the conventional higher-order arrow-notation for function types, but will separate the argument types with commas. For example, a function f returning an array of bool elements and taking as argument an array x of

We allow any variable declarations at the top level. Functions can only be declared at the top level. Each function can only access the other functions and variables declared at the top level, or its own locally declared variables. SIMPLE has static scoping.

For simplicity, exceptions only throw and catch integer values. We leave it as an exercise to the reader to extend the semantics to allow throwing and catching arbitrary-type exceptions. To keep the definition simple, here we do not attempt to reject programs which throw uncaught exceptions.

Note that spawn has not been declared strict. This may seem unexpected, because the child thread shares the same environment with the parent thread, so from a typing perspective the spawned statement makes the same sense in a child thread as it makes in the parent thread. The reason for not declaring it strict is because we want to disallow programs where the spawned thread calls the return statement, because those programs would get stuck in the dynamic semantics. The type semantics of spawn below will reject such programs.

The statements have the same syntax as in untyped SIMPLE, except for the excep- tions, which now type their parameter. Unlike in untyped SIMPLE, all statement constructs which have arguments and are not desugared are strict, including the conditional and the while. Indeed, from a typing perspective, they are all strict: first type their arguments and then type the actual construct.

Variable declarations type as statements, that is, they reduce to the type stmt. There are only two cases that need to be considered: when a simple variable is declared and when an array variable is declared. The macros at the end of the syntax above take care of reducing other variable declarations, including ones where the declared variables are initialized, to only these two cases. The first case has two subcases: when the variable declaration is global (i.e., the task cell contains only the k cell), in which case it is added to the global type environment checking at the same time that the variable has not been already declared; and when the variable declaration is local (i.e., a tenv cell is available), in which case it is simply added to the local type environment, possibly shadowing previous homonymous variables. The third case reduces to the second, incrementally moving the array dimension into the type until the array becomes a simple variable.

In spite of its youth, the K framework has already proven to be practical, as it has been used with relatively little effort to define complex languages like Java, Scheme, Verilog, or C, and to use those definitions for analyzing programs written in those languages. K is currently under heavy development, with bugs being fixed and new features and capabilities added on a regular basis. This is all possible due to the enthusiasm and strong belief of its designers and developers that K can be not only an academic exercise but also a solid, practical and scalable tool for programming language design and analysis, as well as due to generous funding under the NSA contract H98230-10-C-0294, the NSF grant CCF-0916893, and the (Romanian) SMIS-CSNR 602-12516 contract no. 161/15.06.2010.

