Many software systems are data-intensive and use a data management systems for data storage, such as Relational Database Management Systems (RDBMS). RDBMSs are used to store infor- mation in a structured manner, and to define several types of constraints on the data, to maintain basic consistency. The RDBMSs are mature, well tested, software products that one can trust to reliably store data and keep it consistent within the defined constraints.

There are, however, scenarios in which passing the responsibility of consistency enforcement to the RDBMS is not convenient, or simply not possible. In such cases, the alternative is to have that responsibility at the business logic level of the system. Hence, from the point of view of testing data-intensive applications, one of the most relevant aspects is to ensure correctness of the business logic in terms of data consistency.

In this article, we show how QuickCheck, a tool for random testing against specifications, can be used to test the business logic of an application to increase confidence on data integrity. We build an abstract model of the data containing the minimum information necessary to create meaningful test cases, while keeping its state substantially smaller than the data in the complete database. From the abstract model we automatically generate and execute test cases which check that data constraints are preserved.

Many applications use one or more databases to store vast amounts of data. They also provide a number of different interfaces to inspect and modify the data. Some application interfaces may be accessed from a web interface, others may be used from a desktop application. Different users have different access rights, and therefore are presented with different interfaces to the data.

The database normally constrains certain relations on the data that cannot be violated; given that the database management system is correctly imple- mented. On top of these built-in constraints there are other rules that are imposed by the application. These constraints involve not only data format or relationships, but also non-trivial calculations. For example, constraints on top of built-in constraints could be to ensure that a zip code is of the right format for a given country, or that a user can only update certain profile infor- mation after having completed updating some registration data. In general, these constraints are verified by the application, that is, the system validates that input data is of the right format, or that a process is followed before the database is actually queried. Neglecting to verify the information, will result in storing data in the database that does not fulfil the constraint.

We formulate the model as a QuickCheck 4 specification [4, 13]. QuickCheck is a tool for guided random testing. QuickCheck specifications are written in the functional language Erlang [2, 7] with some QuickCheck specific macro definitions. The tool automatically generates and executes test cases from the provided specifications.

The method for testing data-intensive systems by using QuickCheck that we propose, is presented in this paper by means of a little example illustrating an on-line shop. The method was developed, however, while testing a real insurance system [1]. We started testing that real application after it had been in service for a few years in order to obtain knowledge on how to test such systems. We have not identified any faults in the production code by using our method, but we were able to show usability of the method by injecting faults in the production code and detecting them by running the tests originating from our method. Moreover, after developing the method, a master student project was conducted in which another commercial database intensive system was tested in the same way. That project resulted in the detection of a number of faults [15] and showed that the method was applicable to a broader domain.

In this section we introduce a simple application that serves as the running example in the paper. The example demonstrates how in practise certain data constraints are better defined in the business logic layer instead of in the persistence layer of a system. We describe a general method on testing data consistency that generalises to much larger databases, such as the ones used in the case studies we will see in Section 5. The method is used for testing that the application cannot violate the business rules by accessing the database through the business logic layer, i.e., by using any of the possible application interfaces. The method should be applicable to relational as well as non-relational databases with several concurrent clients accessing the sys- tem. However, we have not explicitly addressed distributed databases or time critical databases in our research.

We call an interface function call a positive test if it is expected to return successfully, we call it a negative test if it is expected to return an error. Whether or not we expect an interface function to return successfully or to return an error depends on the state of the database or, in other words, on the preceding interface calls. For example, some tests would violate a business rule when performed at a given state, so we test that, given such state of the model, the result is an error message by the interface and the database state does not violate the business rules afterwards.

Now the challenge is to abstract from the data in the database and use that abstraction as a test model. Otherwise, we would end up with a copy of the entire database as state. Not only would that be potentially too large to handle, more seriously, we would have to re-implement (at least part of) the business logic to deal with it, since re-using the implementation under test would not enable us to find errors. Of course, implementing software twice is an unattractive idea; apart from the work involved, one would probably make similar mistakes.

We start by identifying the interface functions in our application. For example, in our shop example we have: new customer, add product, place order, etc. Of course, in a small example like the one we present here, the interface functions are limited and simple, but it explains our point.

We could implement a more specific generator, e.g. creating the name as a firstname and a lastname both starting with an uppercase character and the rest in lowercase. That, however, would only be significant if this indeed is part of the business rules and in case the interface functions should ensure this. Keep in mind that this allows to add the same user twice. We want this to be a potential test case, since the business logic may prevent or allow that situation.

testing approach [16] the product and customer are automatically generated when not present in the database. We propose a different tactic and use the test state (S) to keep track of created customers and products in order to use them in calls to place order and similar. In addition, we still choose now and then, with a small probability, a customer or product (or both) that is not present in the state, to test correct handling of those error scenarios (negative testing).

The lists of products will later be inhabited by codes of products that we have added in the executed test. Thus, the field products stores a list of indices. Respectively, the customer list contains a list of the customer data type, which is a record with two fields, #customer{id, orders=[]}, the customer identifier id and a list of orders placed, where an order is stored by its order identifier, needed for cancelling the order. We could also add all product codes that are ordered in the order information, but since our approach is to keep the model as simple as possible, therewith reducing the amount of work necessary, there is really no reason to do so. We only store the data that is created by the database and not part of the data provided in the test cases.

Each interface function execution may have an influence on the state, so we define a state transition function next state in our state machine model to reflect that. This function takes three arguments, first the present abstract state S, then a place holder for the result that the interface function returns, and the representation of the interface function. The next state function returns the updated test state, which is an abstraction of the state we expect the database to be in after executing the interface call.

where the generators customer id and product code pick a random inte- ger (since entity keys are represented by integers in the database of the on-line shop), and add it to the list of known keys. Besides, the QuickCheck generator oneof takes a random element from a given list 5 . Thus, we can generate calls to functions such as add product or place order with identifiers of products and/or customers that may already exist or not (with a lower probability) as arguments.

Since we use a transactional database, each access to the database is per- formed as a transaction. In order to be sure that the invariant checking does not affect the database state, we undo the transaction immediately after performing it. Strictly speaking there is no need for a rollback, since it is performed at the end of the test and also because we only retrieve entries in order to validate the invariant, we never modify an entry.

In our shop example, it is always possible to create a new customer and get a new identifier in return. We cannot possibly know which identifier will be returned, but there is no need for us to be aware of the precise value. There- fore, our local version of the new customer function invokes the corresponding interface function for creating a user and matches the result with the expected value, in this case just checking its type. Failure to match the value results in a failing test case.

In this particular case the combination of validator and interface function only contains the interface function, since no additional conditions on the database are checked. If the actual value matches the expected value, i.e. is an integer, then we return that value, otherwise we raise an exception and the test fails.

We implement a case distinction on the obtained result instead of on the combination of conditions. On the one hand this reduces the amount of code, since we need only one alternative for each possible return value. On the other hand, we specify different from what we would do when implementing the business logic layer. If code is different, it is less likely that we make the same mistake. But even more importantly than the two reasons above, we do not have to bother about the (normally) unspecified implementations of dealing with double faults; in case both product and customer do not exist, we have no clue which of the errors is produced. By looking at the result, no matter which of the two error messages is produced, we accept it.

after being tested by regular users during the last stages of development. Such testing process is common in software development, but it is hardly ever complete and exhaustive. The fact that an application has been running daily without major problems is just a weak empirical evidence of correctness.

For each interface function, write a local checking function in which firstly a number of predicates are evaluated (conditions on the existing data). Secondly, the actual interface function is called. And thirdly, it is validated whether the result of the real interface function corresponds to what could be expected from the previously computed predicates.

In our method we have assumed the RDBMS itself to be error free. We also assume that transactions are properly used to guarantee atomicity of the interface functions, such that testing in a concurrent setting is unnecessary for the kind of errors we are looking for. Of course, additional load testing may still explore the concurrency and distribution capabilities of the appli- cation. Last, we assume that unit tests have been performed for the system components, and this testing method is proposed at the system level testing. One of the advantage of having a model for testing is that we can per- form hundreds, thousands, or even hundreds of thousands of different tests, automatically generated and executed. If there is a change in the business rules, we can perform new tests only after reformulating a few SQL queries

