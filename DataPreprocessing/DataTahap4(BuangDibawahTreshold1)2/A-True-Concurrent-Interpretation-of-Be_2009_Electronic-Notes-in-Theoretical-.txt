Modern software applications increasingly take a view of computation as something that happens by and through interaction. Software systems are architected using components, which provide a coherent set of services through well-defined interfaces typed by ports. The overall system functionality is the result of, often complex and highly concurrent, interactions between components of the system. A thorough understanding of the behaviour exhibited at the interfaces of a component can increase expectations of a successful outcome prior to deployment.

It can be seen that components in UML 2.0 (and elsewhere, eg. Koala [15]) are understood as having multiple access points (ports, interfaces) through which they interact with other components. An intrinsic aspect of component-based design is the ability to capture the ordering relations between event occurrences on compo- nent ports and the dependencies that arise (whether they are ordered, concurrent or in conflict).

Component vectors are obtained by coordinatewise concatenation, for example, (x1, x2, x3).(y1, y2, y3) = (x1y1, x2y2, x3y3). In describing component interactions, we are interested in event occurrences over ports of the component. These are captured in our formalism using a specific kind of component vectors, termed column vectors, which have at most one event per coordinate.

In order to ensure that vectors in a component language are the result of con- catenations with column vectors only, the language must satisfy certain properties, namely discreteness and local left-closure. These properties lead to the characteri- sation of normal component languages and give rise to a class of automata [11] that provide a state-based description of component interactions in which concurrency is captured as an explicit structural property. Due to space limitations we do not discuss the state-based model further in this paper.

mapped onto a set of component vectors. The cardinality of the set is that of the set of component vectors associated with its previous location. This might seem somewhat counter-intuitive at this stage, but is necessary because the previous location might have been mapped onto more than one vector. This will be the case when any of the locations preceding l is the end location of a par or an alt interaction fragment.

The next location visited is l1, since time(l1) = time(l0) + 1. By Definition 4.2 we have that vec map(l1) = vl1 (since m = |vec map(l0)| and l0 is the immediately preceding location). The vector vl1 is given by vl1 = (vl11 , vl12 , vl13 ) where

At the end of an alt fragment we need to capture the fact that there are n alternative scenarios the component may have engaged in. We do this by associating the end location of an alt with the component vectors of the last location of each operand. This is formally put in the following definition.

4 Note that there might be some duplication (duplicate component vectors between last location per operand and end location of alt), but there is good reason for it. The component vectors of the last location per operand feed into the resulting component language V (cf Definition 4.10) while the compo- nent vectors of the end location are used for obtaining the component vectors associated with the location below it (the one visited next).

Simplifying somewhat, instead of considering that locations from different operands are reached in either order, which one would find in an interleaving ap- proach, we consider three cases: a) one location is reached first, b) the other location is reached first and c) both locations are reached at exactly the same time. An- other way of expressing this is by saying that locations from different operands are reached in no particular order. This perception of parallelism is rooted in the formal treatment of concurrency, via an independence relation [13], within our the- oretical framework. Independent events that are enabled, and occur consecutively, are concurrent.

The start location of par is identified using the function scope while the first location of each operand is identified through the combined use of scope and time, as before (Section 4.2). The following definition addresses such locations and is essentially an adaptation of Definition 4.4 for par.

All locations that appear in a par fragment other than the first of each operand and the end location belong to the set Loc' and they are mapped onto component vectors following Definition 4.2. It remains to address the end location of par.

Once the end location of par is reached, we need to consider the three cases, discussed earlier, for each location appearing within par. This is to reflect the fact that event occurrences appearing in different operands of par are effectively unordered (in parallel). We formulate each case below.

By considering the above three cases, each location l in a par fragment is mapped onto three (sets of) component vectors, vec map(l)I , vec map(l)II and vec map(l)III . Now the end location of par is associated with the component vec- tors (including all three cases) corresponding to each location appearing within the fragment. This is formally put in the following definition.

scope(l5) = prl.par(2). Thus, its component vectors are given by Definition 4.8. First, we determine the 3 cases for each location within par. In fact, we have seen that we do need to consider the locations of the last operand. So, in our example it suffices to determine the 3 cases for location l3 only.

The only locations that do not adhere to this rationale are locations within a par interaction fragment. We have already seen that the events associated with these locations are not ordered in any way (including simultaneity). This is captured in the vector mapping of the end location of this fragment. Thus, in obtaining the component language we include all vectors associated with a location along the

[14] translate scenarios into an FSP specification and use that to generate a labelled transition system (LTS) model of each component. The LTS semantics of FSP impose an interleaving interpretation of concurrency. LTSs are also used in [4] where MSCs are used for verifying component properties.

Furthermore, in checking the obtained language against discreteness and local left-closure we identify missing behaviours which may indicate emergent behaviour (e.g. race conditions, as shown in [9]) or were simply unthought in design. In this sense our approach supports the gradual elaboration of scenario-based specifica- tions to more comprehensive ones. Note that discreteness and local left-closure are preserved under composition as shown in [10].

