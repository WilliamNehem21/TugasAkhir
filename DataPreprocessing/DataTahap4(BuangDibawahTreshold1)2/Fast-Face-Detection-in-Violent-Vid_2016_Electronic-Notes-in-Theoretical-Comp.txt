In this work we aim to detect faces in violence scenes, in order to help the security control. We used the Violent Flow (ViF) descriptor with Horn-Schunck proposed in [50] for violence scenes detection at first stage. Then we applied the non-adaptive interpolation super resolution algorithm to improve the video quality and finally we fire a Kanade-Lucas-Tomasi (KLT) face detector. In order to get a very low time processing, we paralleled the super resolution and face detector algorithms with CUDA. For the experiments we used the Boss Dataset and also we built a violence dataset, taking scenes from surveillance cameras. We have promising results detecting faces in this environment, because of the benefits of our proposal.

For all these problems there are a lot of surveillance camera services, these systems can be easily implemented in order to monitor any stage, but it could be ineffective due to the lack of trained people who supervise the recording and the natural ability to pay attention [22]. Because of this, we are motivate to seek technological solutions that help us feel safer. Having support systems to detect possible serious violent actions are very useful in controlling public safety. Moreover, it is important for us to detect the violent people in the scene.

mance in terms of MediaEval cost function [11], in addition, we have to mentions that the MediaEval 2013 dataset is a collection of movies where the conditions as illumination, resolution, etc. are ideal. Recently [1] have proposed the use of audio and visual features also, as audio feature they use MFCC and for visual features they use HOF, ViF and color descriptors, they also evaluated their results in the MediaEval 2014 dataset. They concluded that the audio features are more rele- vant than the visual features, they also combined both features getting even betters results.

Estimated by projecting the image in high resolution the low resolution model degraded H, where P simulated the low-resolution frames generated. Then, the error simulated re-projected onto the high resolution image. Finally, according to the sum of rear projection error, the estimated high resolution image is renewed. The above process is repeated until the number of iterations reaches its maximum value.

It is understood that the normalization (super resolution and illumination) will work in a block (0.0), while it in parallel will work in the block (1.0) with face detection. As CUDA consists of functions running simultaneously in several very lightweight threads on the GPU, these threads have a hierarchy: the blocks, which

