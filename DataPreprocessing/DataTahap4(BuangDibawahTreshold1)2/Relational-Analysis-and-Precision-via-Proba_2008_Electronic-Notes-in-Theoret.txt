We abstract the Linear Operator Semantics in the framework of Probabilistic Ab- stract Interpretation [10,9]. The basic idea behind Abstract Interpretation is to analyse a program by looking at a simplified or abstract semantics which only reg- isters aspects of the program that are relevant to the specific analysis. Typically, these aspects are encoded in the definition of an abstract domain which is usually structured, like the concrete domain, as a complete partial order. In the standard Abstract Interpretation theory by Cousot and Cousot the translation between the concrete and the abstract semantics is achieved via Galois connections (i.e. pairs of adjoint maps) which guarantee the correctness of the abstraction [5]. In our setting where we deal with linear operators defined on vector spaces, the relation between the concrete and the abstract semantics is formalised via the notion of a linear gen- eralised inverse which can be seen as a linear analogon of a Galois connection [10]. This is the Moore-Penrose pseudo-inverse which is defined below. We refer in the following definitions to the general notion of Hilbert spaces as our (concrete and abstract) probabilistic domains, although as mentioned in Section 2, in this paper we restrict ourself mainly to the consideration of finite-dimensional vector spaces.

Note that, since PrecF(P, R) is a number expressing the loss in terms of com- pleteness of the given abstraction, the smaller it is the more precise is the resulting analysis. We will prove Proposition 4.4 based on the following two properties.

The abstraction Sw is weakly relational. We get in this case some infor- mation about the correlation between the values of two variables, but not, like with Sr modulo 4 but only about the parity (xi mod 2).  The dimensionality of this abstraction thus is a compromise between Sr and Sn , i.e.  we have

Regarding the precision of these three abstractions when used to analyse var- ious extremely short programs our experiments resulted in the following. For a program like var x:[0..10]; begin x:=k; stop (with k = 1 or k = 4) and var x:[0..10]; y:[0..10]; begin x:=y; stop we obtain the following relative precisions PrecT(P, R).

Other works have faced the problem of quantifying the precision of a static analysis. In [17], Rountev, Kagan and Gibas present an approach to evaluating the imprecision of a static analysis via the lower and upper bound of the set of false positive. This is a quite standard method in classical static analysis, but the authors suggest that for each fact a human experimenter should find a proof that a given result is not a false positive. This approach leads to know the exact percentage of false positive for one program and analysis. However, as it must be done by hand, there is a serious limitation to the size of the set to be tested and it could not be used inside a tool, for example to select the best analysis for a given program. To this aim our approach seems to be more promising: Given that we have a structured lattice of abstract interpretations, and a way to measure precision, we can think of a more systematic approach in the selection of the abstract domain. In particular, this can be achieved practically via a statistical interpretation of the number expressing the relative precision.

