Background: Current Augmented Reality systems in liver and bowel surgeries, are not accurate enough to classify the hidden parts such as gallbladder and uterus which are behind the liver and bowel. Therefore, we aimed to improve the visualization accuracy of bowel and liver augmented videos to avoid the unex- pected cuttings on the hidden parts. Methodology: The proposed system consists of an Enhanced hybrid recursive matching and k-parameterization techniques to improve the visualization. In addition, Mean Shift Filter is also added to improve the matching process while image registration. Results: Results proved that, the accuracy is improved in terms of liver and bowel surgeries Visualization errors about

0.53 mm and 0.22 mm respectively. Similarly, it can produce 2 more frames/sec compared to the current system. Conclusion: The proposed system worked towards the visualization of gallbladder and uterus while liver and bowel surgeries. So, this study solved the visualization issues, which are caused by neigh- bouring and hidden parts.

The main purpose of this article is to reduce the registration error, visualization error and processing time in the domain of liver and bowel surgeries. One of the best result from the current studies is Hybrid recursive matching (HRM). It is a latest recursive algo- rithm which includes many new features such as noise reduction, image segmentation, surface reconstruction etc. The HRM algo- rithm consists of block recursive and pixel recursive. We believed that, this algorithm is more reliable to our aim.

During our research, we reviewed various journals and anal- ysed. From this analysis, the main issues for AR surgery are local- ization of the tumour, visualization of tumours, organs, nerves and its structures, soft tissue deformations, image registration (complex part of the body such as heart, liver, eye, bowel). Some of those articles are described below.

Kersten-Oertel et al. [9] developed the augmented reality neuro navigation system that gives precise patient-to-image registration. This system merges the captured real time images with the pre- operative volume vessels. It displayed the registration error of 3.44, and the calibration & re-projection error is of 2.02 mm. How- ever, robust visualization techniques and rigorous evaluation need to be performed as there is no disruption of workflow. Therefore, this work has no further scope of improvement.

Ieiri et al. [12] obtained 3D reconstructed patient images by using 3D viewer software and Multi detector low CT (MDCT) data. Registration is done by using the optical tracking system and body fiducial markers. The accuracy in terms of registration is calculated by FRE named as fiducial registration error. FRE is a method to cal- culate the distances between marker position, TRE (Target registra- tion data) and 3D volume data. However, we are not interested to use trackers and markers. Wen et al. [13] developed a surgical robot system, which is guided by hand gestures and supported by an Augmented reality-based surgical system. This model used

The 3D images that are taken from the stereo endoscope camera are segmented to identify the organ of interest by using the ran- dom forest(RF) method. These segmented images are taken as input for surface reconstruction method that is Hybrid recursive matching(HRM) algorithm. It consists of two stages include block recursive stage and pixel recursive stage. Both stages will provide the information about three candidate vectors named as start vec- tor, update vector and final vector. The constructed depth map image is created by using these vectors data. These depth map images are combined with camera parameters and processed as an input for the registration process [1].

The resulted depth map is projected onto the intra-operative surface for depth matching with biomechanical model of the cur- rent frame. While matching process both the target and reference frames should lie on the same line. The deviations, displacements and boundary conditions are tracked and updated to the update vector. The final outcome of this phase is dynamic registration. Both the pre-operative and intra-operative biomechanical models are aligned by using 3D mosaic method. The aligned models are

10 Laparoscopic Cholecystectomy surgery sample videos and 8 endoscopic and CT images from different age groups and gender that underwent Laparoscopic Cholecystectomy surgery. The length of videos varies from 10 to 20 min. Comprehensive samples of dif- ferent age group, gender and weight are taken during this process. In addition, we classified these 10 samples into two sections, it includes 5 samples of liver surgery (to visualize the gallbladder) and 5 samples of bowel surgery (to visualize uterus) and in each image has to visualize its neighbouring organs to the surgeon. All the videos used during this research are taken from freely available online resources such as YouTube channels for medical students. The image frames are extracted using Mat lab, and all the frames are considered to generate AR video.

