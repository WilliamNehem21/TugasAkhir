In this paper, we describe cellPACKexplorer, a system designed to help developers of cellPACK find errors in and improve their algorithm. cellPACKexplorer focuses on visualizing the effects of cellPACK recipe parameters on the final packing output. We found that the developers have two different methods for understanding the output, numerical and visual, depending on their background. We designed cellPACK- explorer with a flexible interface to support both types of users. We evaluated our tool through case studies and questionnaires. Novice users were able to create cell models with cellPACK and explore the behavior of different parameters. Further, expert users discovered an error in the code and were able to locate the problem quickly with our new analysis tool. We conclude with a discussion of the implications of our findings in the wider visualization community.

A typical modeling process consists of a model setup, an op- timization process and a validation of that model. This is true whether dealing with agent-based modeling [1], statistical model- ing (such as regression, classification, or clustering) [2] or compu- tational modeling [3]. However, if the parameter space is vast, or if the optimization function is qualitative (e.g. through visual in- spection) then this model building process can be quite tedious. This is one of the first papers that focuses on the visual support of model building in the biological domain. The main motivation is to observe a very specific model building process and to show that visual support can tremendously speed up and help in model building.

Our contributions include a detailed user, data, and task analy- sis comparing the model building tasks of the cellPACK developers to model usage tasks which have been explored more thoroughly in the visualization community [6]. We focused on aiding the de- velopers in improving the core packing capabilities of their model to better help them select the crucial features (input parameters), hide less important ones from future users, and to find proper de- faults for some others so future cellPACK users (e.g. biologists, il- lustrators) are able to quickly create cellPACK outputs themselves. The developers of cellPACK were able to speed up the setup to large experiments from 30 min to 1 min and were able to analyze ensembles of hundreds of cellPACK outputs which they could not do before. It also revealed unknown behavior of their tool to them and helped them to validate the influence of input parameters on the generated outputs. Another advantage to cellPACK developers is that cellPACKExplorer makes collaboration and sharing of exper- iments easier.

As cellPACK is under constant development, the available pa- rameters are constantly being extended. One of the core questions is whether these parameters properly capture the range of realis- tic cells or whether they might be redundant with little influence to the final output generated. Our approach to help the develop- ers answer such questions is to let them visually inspect the in- fluence of new parameters on the range of possible outputs. This could be considered as a hybrid approach between code-level de- bugging and visual model building.

Many tools assist the user with the parametrization of a fixed model (i.e. a fixed algorithm). These methods are usually tied to a specific model. For example, in the context of segmented re- gression [9] and treed regression [10], Guo et al. [11] focused

Partitioning is often done using a clustering approach. For ex- ample, Design Galleries [23] uses a distance metric to present a set of visually distinct possible renderings of a scene. Likewise, Fluid explorer [24] clusters a set of fluid simulation animations into animation segments that are then inspected. While conve- nient, both approaches to a clustered presentation of the model outputs showed deficiencies. Hence, other researchers adopted a more manual adjustment. For example, Paramorama [25] is fo- cused on finding which parameter settings produce good segmen- tations based on manual inspection of the resulting images. They group outputs in a hierarchical fashion based on input parameter settings. Paraglide [26] enables a manual partitioning of the output space in order to draw conclusions on the input parameter values. An a priori partitioning scheme is not clear in the case of cellPACK- explorer. In addition, the partitioning scheme might be refined as the algorithmic description (and therefore the underlying model)

Ingredient parameters on the other hand mimic the behavior of real-world biological proteins, they have to be set for each ingre- dient type independently and specify which protein an ingredient mimics. An example for this parameter set is known binding part- ners for an ingredient (i.e. attraction to a specific other ingredient type). They decide whether an ingredient accepts or declines the position proposed by the algorithm. In the literature they are re- ferred to as control parameters [27], as they are meaningful in the biological domain.

cellPACKexplorer was developed over ten months using the de- sign study methodology [28]. This period consisted of two major development circles each ending with the evaluation of a proto- type tool by the cellPACK developers. During the first cycle we had weekly meetings with the cellPACK developers. During this time we developed our initial user, data, and task characterization. We also presented the developers with successively refined proto- types. After we evaluated our first prototype with the developers, we discovered that their analysis interests varied as the code was updated. Further we found that they preferred to keep control of their analysis and therefore did not like the automatic clustering. Additionally we observed that they hardly went back to the input part of the interface. We updated our user, data, and task char- acterization and designed a new prototype tool. We present the results of this second development cycle in the following sections.

We analyzed the workflow of the cellPACK developers in weekly meetings, asking them about their usual work and future goals for the cellPACK development. After collecting this data we character- ized their data types and tasks following the taxonomy of Mun- zner [29]. We then synthesized what we consider the main model building tasks conducted by the developers of cellPACK in order to help them improve the understanding of their model and ulti- mately improve cellPACK. In what follows we summarize the result of our analysis.

At the moment the developers work with smaller datasets vary- ing about 3 parameters and generating roughly a hundred output models. In the simple test cases the ingredients are simplified to spheres of different radii and limited to about 5 ingredients with about ten copies per ingredient type. For the more complex models such as HIV the number of ingredients packed scales up to millions of ingredients.

Currently, the developers use a simple trial and error [6] strat- egy, exploring one run at a time. They create a hypothesis what the cellPACK output for specific parameters will look like and then run the model to verify their hypothesis. This works well for ex- periments with a single ingredient type and a short computation time. As recipes get more complex and more ingredient types are packed, interaction effects between parameters make it impossible to predict the output.

To analyze these recipes they compute a few outputs one by one to rough out parameters and ranges to sample. These simpler experiments consist of only two to three parameters and about ten different seeds. They also run these small experiments to confirm that the system is still working after changing the code. The next step in their analysis is to write custom scripts in Python to sample the parameter ranges by varying less than twenty specified random seeds and less than five parameters. They analyze the outputs vi- sually and statistically in MS Excel. For the different analysis as- pects the developers use a suite of different 2D or 3D viewers to look at the raw outputs, create density maps of multiple ensemble members and illustrate renderings of single output cells. Finally,

T3-Identify: Identify parameters to be exposed: Parameters that greatly impact the range of 3D outputs should be exposed to the future users of cellPACK. However, too many parameters could overwhelm a new user with unnecessary complexity and hurt the adoption of cellPACK. In addition, packing parameters might not be intuitive to non-technical users. Therefore, the developers of cell- PACK have to make a careful selection and need to understand the behavior of different parameters and their interactions.

During our collaboration with the cellPACK developers they were constantly updating and changing the code. Therefore we had to account for these changes and provide a highly flexible interface for them that adapts to these changes. In this section we will talk about changes that we applied to the interface throughout the de- sign process.

cellPACKExplorer is built as a client-server design with a web front-end. We chose this design as it simplifies installa- tion and helped the developers of cellPACK to share (T5-Share) their results and discuss findings. Plots are implemented using D3 [30] and crossfilter [31] which supports interactive filtering of large datasets. We used the approach of Talbot et al. [32] for axis labeling.

Set recipe: At first the developer selects a cellPACK recipe they want to analyze. This recipe is a .json file that specifies the packing volume, which ingredient types to pack, and default values for cellPACK input parameters. The recipe also declares the biolog- ical cell structure.

developers already worked with spreadsheets in the context of the analysis. Second, we wanted a flexible interface that adapts to al- gorithmic and analysis changes. With the spreadsheet layout, dif- ferent analysis aspects (presented by columns) can be swapped in and out or added.

cellPACK developer to compare (T2-Validate) different subsets of the output ensemble. A new row initially shows all runs of the experiment (i.e. no filters are applied and the whole output set is visible). The cellPACK developer can interactively adapt which runs are part of a horizontal group by creating a filter on any or several of inputs or derived measures represented by columns in the in- terface. The filters are combined with an AND operation such that groups are formed where each single output of a run has to fulfill all the filter constraints to be part of a horizontal row. Each filter only influences its own horizontal row in the interface. Filters in cellPACKExplorer can be adjusted in the bar charts directly. A click

i.e. how often a specific value has been used to generate outputs in that row. In case of filtering, the full histogram for all runs re- mains transparent in the background to provide the context of the full ensemble dataset. The updated opaque part of the histogram shows the distribution of the currently selected subset of a row fulfilling all the filters.

total packing volume covered by an ingredient type. For example, if ingredient A takes up 50% of the whole cube in which we are packing then the SpaceOccupancy value is 50%. Within each run the occupancy for each ingredient is averaged over all cells computed with different seeds. This measure gives an idea of the concentra- tion of ingredients compared to the total volume, the denser the volume is packed, the higher this measure will be.

The interface can easily be adapted by closing or open- ing columns of information (e.g. when exploring a 2D recipe, only one of the projected heatmaps is needed, features can be shown/hidden depending on the analyzed parameter). After the ex- ploration of an experiment, the underlying model (cellPACK) might be improved (T6-Improve) and a new experiment can be started.

We used two different setups for the evaluation of the tool. In addition to regular feedback from the cellPACK developers we asked them to use the tool on their own and provide qualitative feedback for us guided by a questionnaire (Sections 8.1, 8.2, 8.3). Second we asked some users without a biological background or previous knowledge about cellPACK to fulfill some tasks and also pr ovide some informal feedback (Section 8.4).

The developers were able to use cellPACKExplorer for large- scale debugging tests and to isolate more subtle issues with newly added code. Instead of debugging heuristically by adjusting param- eters and viewing one result at a time, cellPACKExplorer enabled them to setup and analyze thousands of models at a time, which could reveal statistical subtleties more readily. In a typical scenario the developer would first run small experiments and sample only two sets of parameters at a time with typically just two seeds (T1- Setup) to ensure the interface and the program are running cor- rectly (T2-Validate, T3-Identify, T4-Default). If the code failed, then they would debug it and adapt the cellPACK algorithm (T5-Share). Secondly, they would rerun with all the parameters they want to test with a small number of seeds (T1-Setup) to confirm that the pairwise tested parameters all worked together (T2-Validate, T3- Identify, T4-Default). Finally, they would greatly increase the num- ber of seeds for a deep analysis to explore the behavior of the cellPACK algorithm (T2-Validate, T3-Identify, T4-Default). If the cellPACK output was incorrect they would adapt the cellPACK al- gorithm again (T5-Share) and start a second round.

In order to measure the transferability of cellPACKExplorer to non-developers, we also conducted a usability evaluation with users who had not previously used cellPACKExplorer. We started with a brief introduction to cellPACKExplorer and a walk through of the interface. Then, each participant was asked to analyze the packing parameters for two recipes previously generated by the cellPACK developers through the online accessible tool. Both recipes described a packing problem of spheres on a 2D plane. Spheres occupy the intersecting circle on the plane. The develop- ers often use this simplified setup to quickly test code changes. It is helpful for quick intersection tests and increased rendering per- formance of outputs. We chose these data sets for our study as they are simple and fairly easy to analyze.

Some of our participants had troubles interpreting the derived metrics charts. After a brief clarification they were also able to answer questions related to this chart. In addition, some users preferred that the x- and y-axes in the graph showing the usage would be the other way around. The biological and UXDesigner participants preferred the output renderings on the right side of the interface over the numerical metrics. Two of our participants were curious how to set up their own experiment and use cell- PACKExplorer. We showed them how they can create their own datsets using our input interface.

on a pre-defined set of features and is usually applied in the of- fline stage of the workflow (i.e. after data generation but before the user starts his analysis). With our approach of manual filtering on inputs and outputs we keep the user in the loop and provide freedom to investigate the same dataset from different aspects.

To provide recommendation for a faster design process for fu- ture design studies we emphasize the use of a web based applica- tion. This eases installation for the users and allows us to deploy updates easily. This makes it easy to access the tool for a variety of users with different levels of technical skill.

The flexibility of cellPACKexplorer in terms of what metrics are shown opens it up to other application areas. For example, it could help to explain to meteorologists which parameters of weather simulations influence temperature, air pressure, or precipitation. Another possible domain is bioengineering where scientists gener- ate simulations of human organs and inspect the influence diseases can have on potential fields of the human heart [33]. As the visual columns in the right most side of the interface can be closed if a simulation does not provide visual output, our tool also is applica- ble to simulations in areas such as software engineering or math- ematics where simulations do not always result in visual outputs.

Committee on Mathematical Foundations of VerificationValidation, and Uncer- tainty Quantification; Board on Mathematical Sciences and Their Applications, Division on Engineering and Physical Sciences, National Research Council. As- sessing the reliability of complex models: mathematical and statistical foun- dations of verification, validation, and uncertainty quantification. The National Academies Press; 2012. doi:10.17226/13395. ISBN 9780309256346.

