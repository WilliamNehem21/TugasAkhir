Tactics decompose a goal into subgoals and call other tactics or themselves recursively to solve these subgoals. In this sense tactics are a way to structure strategic knowledge about proof search. This describes the static call graph of a set of related tactics. E.g. an induction tactic sets up the induction, applies a di erence reduction tactic to the induction conclusion and hypothesis, applies the induction hypothesis, and nally simpli es the result.

Executing such a tactic gives rise to another dynamic structure, namely the tree of tactic calls that were actually carried out while solving a problem. This structure is closely related to the call graph but depends on the goal the tactic is run on. It is a summary of the call stack over the time of the tactic execution and describes the computation that was carried out to apply the tac- tic to a concrete goal. Because tactics involve search (usually implemented by indeterministic choice and explicit failure with backtracking) whole subtrees of this structure may correspond to branches of the search space that turned out to be dead ends. I.e. they describe computations that do not manifest themselves in the nal proof representation. As an example, depending on the goal, the di erence reduction tactic might call itself twice on subproblems and a simpli cation tactic inside one of the recursive calls. Also it might have to undo the second call to itself because the call did not produce the desired result and try again in a di erent way after some additional rewriting.

If we have a closer look at this structure we see two ways in which a user can interact with a tactical theorem prover. First, the user can decide which tactics to apply at the top-level and let the tactics ll in the details. I.e. the user decides on the overall structure of the proof while the machine decides on the details. This technique is applied in many theorem provers like Isabelle, PVS, Coq, KIV, Inka.

Another way the user should be able to interact with the theorem prover is to let a tactic decide on the overall proof. If the prover gets stuck the user decides on the details by overriding decisions of the tactic, inserting inter- mediate steps or suggesting a di erent way to solve a particular subproblem without otherwise terminating the tactic. I.e. after the intervention by the user the tactic carries on with what was left for it to do when the user in- tervened. In current theorem provers this way of interaction is not possible without changing the code of tactics and rerunning them. This has two severe disadvantages: the code of the tactics needs to be changed by the user and the tactics have to be rerun, repeating all the search that the tactic carried out before the intervention. In current theorem provers, when a tactic gives up the prover either does backtracking and leaves the user with the original proof state the tactic started out with, or it leaves a proof state corresponding to the partial success the tactic had. In any case the tactic call stack is gone and the user is back at the top-level. There is no way to intervene and then

resume the original tactic at the place it gave up. That is, once a tactic has started it either produces a result fully automatically, or it does not produce a result at all. An integration of automation and interaction is not possible once a tactic has been started.

In this paper we describe a technique that enables the second mode of interaction. The basic idea is the following: while executing a tactic on a goal the prover collects a trace of the computation. Each element of this trace corresponds to a point of time in the execution of the tactic. If the user wants to suggest an intermediate step to the tactic, the prover can reexecute the initial part of the computation along the trace that it had collected earlier. When it reaches the point where the user wants to intervene it can execute a tactic that was given by the user. We call such a tactic callback. Since the prover has reexecuted the initial part of the computation, the callback can be executed in exactly the same situation in which the theorem prover was when the original, supposedly unsuccessful subtactic was executed. In particular all information that was collected by the execution of the tactic up to this point in time in the original execution is again present (including information entered by the user in the original execution). Our technique takes care that the reexecution of the trace is carried out in synchronization with the tactic that generated the trace in the rst place. This means that not only can the callback be executed in the situation in which the original tactic would have been carried on, but also can the original tactic be resumed at exactly the same place in its execution in which it was intercepted.

The user can also override a decision by the tactic. Assume that the tactic has decided to apply a particular lemma at some point in the proof search, but the user has decided that it would be better to use another lemma. This is achieved by reexecuting the initial part of the computation up to the point at which the wrong lemma was chosen by the tactic. This decision is overriden by the lemma determined by the user and the tactic resumes with the new lemma instead of the old one.

informally describes the technique. Sect. 4 revisits the earlier example and shows how the technique works in this case. Sect. 5 discusses how the techni- que can be used to reuse proofs analogically. Finally, we describe related work in Sect. 6 and conclude.

from which the quanti ers are removed by skolemization. `Ripple out' uses rippling to make the induction hypothesis applicable to the induction conclu- sion. Rippling [3,9] is a reasoning technique exploiting the semantic knowledge that the induction hypothesis must be applied in the step case, and additio- nally assumes that the induction conclusion contains syntactically the induc- tion hypothesis. The di erences between induction conclusion and induction hypothesis are called wave-fronts and are denoted by boxes, while the com- mon parts compose the skeleton and are denoted by underlining them. E.g., in our example the di erences between induction conclusion and induction hypothesis are represented by

In current systems, what we have to do in this case is either to change the tactic code and try again from scratch, or to remove the parts of the proof representation that was built after `normalize' and carry out the introduction of wave rules and the rest of the induction tactic manually. Since our tactics are procedural (rather than declarative), we cannot use the induction tactic in the latter case because we would have to restart it right in the middle. In Sect. 3 we describe a technique that enables us to interact with the theorem prover in such a way that we can intercept the induction tactic before `ripple out' is called, introduce the wave front manually, and then resume the tactic as if the wave front had been introduced by the tactic itself.

In this section we explain our technique in an informal way. We describe the semantics of tactics in continuation passing style which is a standard techni- que (cf. [1,8,17,15,6,5]). The idea is to describe the evaluation of an expression e with respect to (wrt.) a continuation S which represents the future of the computation after e has been evaluated. A continuation S is a function of one argument. In order to evaluate e wrt. S, the continuation S is applied to the value that e evaluates to. Evaluation of a literal l wrt. S is, therefore,

We assume the tactic language includes a special operator choose which imple- ments search. It evaluates its argument, which should be a list of alternatives, and then chooses the rst alternative for which the remaining part of the eva- luation is successful, i.e. does not fail. If there is no such alternative, choose fails itself. As usual this is realised by backtracking and can be done straight- forwardly in the setting of continuations by using a second continuation F that encodes the future of the evaluation if the evaluation of an expression fails. Again this is a standard technique covered in the literature cf. [1]. Tac- tics can explicitly call fail which is an abbreviation for choose([]) and fails straightaway. In order for this to work properly, side e ects of tactics need to be restricted such that they can be backtracked over.

The net e ect is that the proof representation is always well-formed and only contains parts that correspond to successful evaluation paths. This is, of course, relative to the concrete de nition of the proof representation and its interface to the tactic evaluation. The technical details are out of the scope of this paper.

Remember that our aim is to be able to intervene a tactic in the middle of its execution and later resume it in the same context. The way we realise this is by reexecuting the tactic up to the point in its execution at which we want to intervene. When we reexecute a tactic, we do not want to repeat the search that was caried out when the tactic was originally executed. The idea is to remember the successful alternatives when executing a tactic and use them as an oracle for choosing the successful alternative without search on reexecution.

There is also a possibility to extract the trace of a computation that is not successful: we have de ned an operation abort that tactics can call to give up completely, i.e. abort to the top-level. However, the trace collected so far is passed back. Tactics will call abort on timeout or on manual interruption. We will ignore this detail for the rest of the paper, however.

Evaluation of a tactic expression is now de ned wrt. continuations and a computation trace t that we have collected as described above. We simply pass through t except for evaluation of choose and calls to named tactics. For choose, instead of setting up a choicepoint and searching for a successful alternative, we simply take the rst event in the trace t, say choice(v), and use v as the value of the choose form without setting up a choicepoint. For calls to a named tactic f we simply ignore the rst event in the computation trace, which is call to(f ).

As described in Sect. 2 the main point of the replay in our scenario is to be able to replay an initial part of a computation to recover the context for the rest of the computation. Obviously, the initial part of a computation is associated with a pre x of a computation trace. Therefore, we de ne evaluation of a tactic expression also wrt. a trace t which is a pre x of the trace s collected when the expression was evaluated earlier. Evaluation is now de ned as for simple replay if t is non-empty, and is de ned as for evaluation from scratch

With the evaluation strategy given so far we can replay an intial part of the computation corresponding to the evaluation of a tactic expression, and then revert to evalution from scratch in the proper context. In order to be able to intervene the tactic at this point in the evaluation instead of continuing, we allow the last event of a trace pre x to be changed before the pre x is replayed. If the last event is choice(v), we allow this event to be replaced by another event choice(v0 ). Instead of choosing the alternative v as in the original computation, on reexecution v0 is chosen and the tactic is resumed with v0 instead of v. This allows overriding choices that the tactic has made without interrupting the tactic. As an example, a lemma that a tactic may have chosen to apply at at speci c point may simply be the wrong one. By changing the event the tactic can be forced to use another lemma and carry on as before.

Another way to interact with tactics is to replace a call to a named tactic by the evaluation of another tactic expression, called a callback. Consider the example in Sect. 2 where the step case tactic applied ripple out without introducing the additional wave front. In this case, instead of calling the tactic ripple out, step case should let the user carry out a reasoning step interactively and then call ripple out and carry on with the tactic. To achieve this, if the last event of an initial trace is call to(f ), we allow this event to be replaced by callback(e). On reexecution, now instead of calling the tactic f we evaluate the expression e in the context in which f was called when t was collected. Since the context in which e is evaluated includes the lexical bindings of program variables, e may be an expression in the programming language that includes free occurrences of the program variables that were visible at the place in the original tactic de nition at which f was called.

We now go back to the example of Sect. 2 and show how the technique descri- bed in the previous section is applied to repair the failed proof attempt. We noted in passing in Sect. 2, that the user spotted a possible problem with the instantiation of Y to y in

In the process of repairing this proof the user is never aware of the com- putation traces and their replay. Pointing to the node in the proof represen- tation where the manual intervention should take place presents the user with a choice of possible actions, one of them being \Intervene and retry". In the example, the relevant node is the one which contains the formula (1) on which the `ripple out' has been applied.

Internally, each node of the proof representation is annotated with the computation trace that was collected when the node was created in the failed proof attempt and the tactic that was called on the relevant proof node. The- refore, the system can execute the rippling tactic from scratch by replaying the initial trace t up to (but excluding) the call to `ripple out' (the computa- tion trace stored with the node). Before replaying the tactic, the computation trace t that is to be replayed is extended by the callback event which calls a tactic implementing user interaction and, when the interaction tactic returns, calls `ripple out'. The evaluation rules of the tactic language ensure that after

 cations) are replayed to solve a target problem. Melis' approach is based on the paradigm of proof planning and thus on an explicit representation of control knowledge in terms of methods and proof plans. Our approach can be easily integrated into standard tactic languages thus allowing to implement derivational analogy in a procedural (instead of declarative) control language. Richardson and Smaill [18] use a technique similar to ours to be able to intervene with and then resume declarative methods. They store an explicit form of the continuation with the proof representation and do not collect or

In this paper we have described a technique that allows user interaction in tactics without terminating the tactics. Users can override choices of the tactic and insert other proof steps to be carried out before the tactic resumes. The technique works by replaying initial parts of tactic executions and then carrying on with the computation in the same situation in which the tactic execution was intercepted. The tactic can then be resumed.

The technique is a particular simple starting point to implement derivatio- nal analogy in tactical theorem provers. More sophisticated forms of analogy can be implemented by re ning the way in which choice points are transferred from the source to the target proof attempt. Also, ideas from transformatio- nal analogy can be used to patch traces before they are replayed. We will investigate these extensions in the future.

