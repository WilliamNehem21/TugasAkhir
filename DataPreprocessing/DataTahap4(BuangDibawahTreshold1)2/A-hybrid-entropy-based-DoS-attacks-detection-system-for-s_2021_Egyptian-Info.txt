There are many different factors that can affect the level of trust of nodes in a network, in this paper, we tackle the issue of trust in a network whose members may or may not be part of a denial of ser- vice botnet. Toward that end, we design an algorithm that would first determine whether or not nodes are participating in denial of service attacks. We then use this information to come up with a trust value that we assign to nodes. The algorithm then bans the offending nodes for a certain period of time and notifies their administrator, thus, giving them a chance to rehabilitate. If mali- cious behavior is repeated, the nodes are banned indefinitely.

Software defined networks are an emerging category of networks that present a new set of challenges from the security perspective. The authors in [3] provide a comprehensive overview of the security threats faced by this emerging architecture. Of these challenges, this paper focuses on denial of service attacks and how information about them can be incorporated into a trust mechanism that can inform routing decisions that occur on the network.

There are many papers that address the issue of detecting denial of service attacks. Some are based on entropy [4,5], while others use more advanced entropy based metrics to detect DoS attacks [6,7]. It should be noted that while entropy is a good metric for detecting DoS and DDoS attacks, it is possible to spoof it [8] and it is prone to false positives when the underlying behavior of the network changes [6,7].

However, to the best of our knowledge, no work has addressed the possibility of designing a hybrid system that uses both entropy and KL-divergence to detect DoS attacks in SDNs. Also, to the best of our knowledge, there is no work that targets the need to detect a denial of service attack while another one is on-going. In this paper, we design a hybrid algorithm that merges entropy and kl- divergence to address these issues.

Thus, for the first proposed system, we detect a DoS attack as occurring when the entropy of both the source and destination IP addresses drops below a certain level. This threshold can be stati- cally or dynamically determined. The assumption is that before the attacks occur, the entropy of the system is large because nodes communicate with each other in a random fashion. If this underly- ing assumption is violated, the technique is expected to detect many false positives.

For example, assume that one of the nodes transitions from nor- mal internet browsing to, for example, streaming an online movie. This is not an attack, but is expected to cause a rise in both the des- tination and source IP counts that may lead to a drop in entropy in both, triggering a suspicion of an attack. Having a dynamic thresh- old may help resolve this, but what is really needed is a model of normal traffic in the system. Any deviation from this normal model would then be considered anomalous and hence an attack.

Since it is the distribution of the source and IP addresses that change during an attack, it is desirable to build a model of these two values that can be used as a reference point to check against. In addition, such a model should be dynamic in the sense that it allows itself to be updated as the usage of the network changes. Toward that end, we design another method for detecting DoS that takes into account past behavior of the system. This second model is described in the next subsection.

This second model assumes that the network behavior is mod- eled over different time intervals, and if the behavior of the net- work changes from one time interval to the other, an ongoing attack is suspected. This is a reasonable assumption since network traffic will typically follow a specific pattern until an attack occurs to disrupt the normal pattern [20]. The tool used to model network behavior in any one time interval is the probability density func- tion (PDF) of the occurrence of both the source and destination IPs. Thus, an interval is represented by two PDFs. It is fairly easy to program the controller in an SDN network to count the occur- rences of destination and source IPs and create PDFs based on these numbers.

A method for computing the distance between the PDFs of any two time intervals is then needed in order to determine whether or not the normal behavior of the network has changed. We decided to use the Kullback-Leibler divergence [9] (or KL- divergence for short) to measure the distance between the PDFs of two successive time intervals. KL-divergence is not strictly a distance metric, it is not symmetric and does not obey the trian- gle property, but, for the purpose of our system, it suffices to compute the difference between the current and past source and destination PDFs.

In this model, we assume that the attacker has full information about the traffic patterns inside a network. Given this information, an attacker can spoof its attack packets so that they mimic normal network traffic. It was shown in [8], that if such knowledge exists, it is possible to circumvent entropy-based anomaly detection sys- tems for DoS attacks. The attacker can generate enough packets to mask the attack or to generate enough false positives to make the anomaly detection unusable.

In this section of the paper, we describe the experimental setup used to test the performance of the proposed DoS detection mech- anism. The topology used to test the idea is a fully connected SDN that contains a total of 20 nodes. There is only one controller in this topology.

Since the proposed algorithm determines whether a node is malicious or not at the end of each round of a round-based algo- rithm, we decided to keep track of the number of rounds during which the node exhibits malicious behavior. Our algorithm works over a window of five rounds, and measures the number of rounds within this window that the node exhibits malicious behavior. It then calculates the percentage of the five slots during which the node was identified as malicious. This percentage is compared to two thresholds th3 and th4, these thresholds are the low and high marks of suspected malicious behavior respectively. They are both percentages, and indicate the number of times that a node was sus- pected as malicious during a test window.

This is a very general framework, and does not depend on the metric used to measure trust. Any value can be used as long as a decision about whether or not a node is being malicious during a time slot can be derived from the metric. It is this binary decision, malicious or not malicious, that is used as an input to this framework.

