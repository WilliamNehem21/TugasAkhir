We evaluate energy consumption under unknown service demands using three policies: task assignment based on guessing size (TAGS), the shortest queue strategy and random allocation in a homogeneous environment. We modelled these policies using performance evaluation processing algebra (PEPA) to derive numerical solutions. Our results show that servers running under TAGS consumes more energy than other policies in terms of total energy consumption. In contrast, TAGS consumes less energy than random

The rest of this paper is organised as follows. In Section 2, we analysed and mod- elled TAGS using the Markovian process algebra PEPA. In Section 3, the numerical results to evaluate the performance metrics are presented. Section 4 introduces the energy model and the energy consumption results. Finally, Section 5 contains a discussion of future work and concludes the paper.

This section illustrates the random allocation policy, the shortest queue strategy and TAGS algorithm. We modelled the three policies in PEPA, a formal presentation of which can be found in [14]. We assume that in all cases, jobs arrive into the system in a Poisson stream and receive a single service before leaving the system.

Jobs are assumed to be independent and identically distributed. We studied energy consumption and performance under two service demand types: (i) exponential service demand and (ii) a two phase hyper-exponential service demand. The queues are bounded as PEPA (with a maximum capacity of 10 jobs) does not support infinite queues. As a result, queues can be full leading to rejecting new arrival jobs from joining the queue. We assume that all queueing is First-Come-First-Served. In Section 2.3 we present the PEPA specification of the model and its parameters.

The random allocation policy assigns arrival jobs to a queue randomly. So, it does not take into consideration how many jobs are already waiting in the queue. As a result, one queue might be overflowing with jobs while the other queue is empty or half full. Moreover, the probability of losing jobs is high, as sending a job to a full queue results in dropping that job permanently. Furthermore, short jobs might be delayed for a long time when getting stuck behind a long job, which is not detected by the random scheduler. However, random allocation can be an attractive option as no knowledge about the system is needed. Hence it is relatively trivial to implement.

The shortest queue strategy overcomes the problem of load balancing between the queues. When jobs arrive the policy forwards them to the queue with the least waiting jobs, thus leading to no queue becoming full while other queues still have available capacity. So, the probability of losing jobs is less significant as long as the arrival rate does not exceed the system capacity. However, short jobs might be delayed for a long time when getting stuck behind a long job, as this strategy only counts the waiting jobs and not their service demands. The shortest queue involves a management overhead as the policy has to have knowledge of the states of the queues. If the latency in polling queues is long then this overhead might be significant, leading to poorer performance in practice. However, in this paper we do not consider this aspect.

The TAGS scheme was initially introduced by Harchol-Balter [13] in order to address the problem of jobs with long service demands unduly delaying jobs with a short service. The main justification of this algorithm is to allocate jobs where the service demand is unknown before execution. In this approach, a job is sent to a single server queue. The server starts processing the first job in the queue until the job is completed and has departed successfully or until a fixed time out is reached. If the timeout is reached before the job is completed, then the job is transferred to the next server. When the job arrives at the next server, the same steps are repeated, but the timeout for this level is increased. The process is repeated with a longer timeout each time until the last server is approached. The job in this final

The queues are modelled in such a way that each job is represented as a sep- arately named derivative of the queue. The timeout at the first node is modelled using an Erlang distribution, and the number of ticks is fixed. While the queue is not empty, the timeout clock starts at the beginning of each derivative of the queue. This is done by introducing tick action at each derivative. A race exists between the timeout action and the service process service1. If the timeout action wins, the job is killed and transferred to the second node to restart service from the beginning. Otherwise, the task departs the system since it finished before the timeout action triggered. In both situations, the timeout clock is reset. If a job is waiting in the queue, the race starts again; otherwise, if the queue is empty, the server enters an idle state until a new job arrives.

As a result both queues will become full and if any new job arrives to the system will be dropped from the queue leading to an increase in the job loss rate. In contrast, TAGS reduces the chance that both queues become full if the timeout is well-tuned. The first queue is unlikely to become full as the timeout mechanism will kill long jobs and transfer them to the second server. Despite the fact that the processing time for each long job is 100 times longer than any short job, the

We have studied energy consumption by the TAGS policy and compared it with that of the shortest queue strategy and random allocation. We have focused on these policies in the case of the high variability in workload. In our model, we assumed we have a two-node system where servers are identical regarding energy consumption and performance. The downside is that in practice, data centres are heterogeneous environments in which energy consumption may differ from server to server. We rely on the processor performance states (P-states) value to calculate energy con- sumption. The main downside of this is that we neglect energy consumption by other components of the server, such as hard disk and memory.

Our analysis of energy consumption under the exponential distribution and hyper-exponential distribution concluded that the TAGS mechanism consumes more energy than the other two policies regarding total energy consumption. The energy consumed per job followed the same trend under the exponential distribution. In contrast, under the hyper-exponential distribution, TAGS consumed less energy per job than random allocation when the arrival rate was high. The shortest queue was the optimal policy in that case.

In this paper, the primary focus was to evaluate and compare energy consump- tion by TAGS, shortest queue strategy and random allocation. No trade-off between energy consumption and performance metrics were introduced. It is vital to have a comparison mechanism between energy consumption and performance for each policy in order to have a clear decision regarding which policy should be chosen. We should develop a cost function that considers performance and energy in order to trade off energy and performance.

Variations among server specifications and processing capabilities are other fac- tors that we should consider. We assumed servers are homogeneous regarding per- formance and energy while in reality, the data centre has a heterogeneous envi- ronment. It is worth while to study energy consumption when servers are not identical. If we have one server with low performance and high energy consumption and another server with high performance and low energy consumption, it will be valuable to determine which server should be the first server or second server. We are also aiming to investigate the benefit of using a multi-scheduling approach that combines TAGS with the shortest queue or random allocation to evaluate energy consumption.

