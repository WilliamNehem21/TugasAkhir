The main contribution of this paper includes an algorithm to discover the performance anomaly behavior and identify bottle- necks in the distributed application using SDN. The proposed method monitors the application and network infrastructure per- formance in real-time without prior knowledge about the running application or the need for application instrumentation. The SDN controller collects data from various network switches and calcu- lates the following performance metrics: (1) for the application, we calculate response time, throughput, and session number per application tier, (2) for the network, we calculate packet loss, delay, and available bandwidth per network link.

Identify the root cause of the bottlenecks using the multi-class support vector machine (MCSVM) algorithm that decides the prob- lem is due to network problems (packet loss, delay, or bandwidth) or an end-host problems. The algorithm enables selective monitor- ing only on the switch ports related to this application traffic to minimize the collected data and accelerate the identification pro- cess. Finally, the algorithm notifies the administrator of the source of the bottleneck to take corrective action.

The rest of this paper is organized as follows. Section 2 provides an overview of SDN technology and application performance detection methods. Section 3 presents some previous work about anomaly detection methods of the distributed application. Sec- tion 4 describes the design of the proposed algorithm. Section 5 discusses and analyzes the simulation results. Finally, Section 6 concludes the paper.

management of network resources [13]. It separates the network control plane of network devices from the underlying data plane that forwards network traffic. The SDN controller is the core element in the SDN technology that centrally manages the network devices to forward the traffic flow using the packet header information, as MAC address, IP address, port number, protocol type, and much other information. While in traditional network architecture, indi- vidual network devices make traffic decisions using the destination IP address for routing packets between IP networks and the destina- tion MAC address for switching packets in LAN networks [14].

Monitoring of applications using network traffic relies on cap- turing traffic information and analyzing it to assess its perfor- mance. These methods are classified into two techniques [18]. (1) Passive monitoring methods observe the transmitted traffic across network nodes. These methods do not affect network performance as they do not inject additional network traffic and are commonly used in the operational data center network. However, they need to install multiple monitoring points that are difficult to imple- ment, and it may take a long time to discover silent applications.

(2) Active approaches inject packets into the network or modify the packets to monitor the performance. This additional load affects the accuracy of the measurements and may cause network overload. This method has a lower false-positive rate; however, it cannot be used in the production DC because it may degrade its performance [19].

Chowdhury et al. [31] focused on the trade-off between moni- toring accuracy, timeliness, and network overhead. The proposed model supports various monitoring objectives like performance, fault-tolerance, and security. But their model did not correlate between the network and the performance metrics of the running application. They did not suggest a method to calculate the normal value of the performance metrics to detect anomalies.

Peng et al. [35] proposed a flow detection method based on the SDN to detect and classify distributed denial of service (DDoS) attacks using the double P-value of the transductive confidence machines for the K-nearest neighbor algorithm. Granby et al. [36] proposed a centralized SDN-based platform to detect the DC anomalies and mitigate the limitations of existing distributed monitoring techniques by reactively identifying threats in real- time.

Suarez-Varela and Barlet-Ros [37] proposed a scalable flow monitoring and classification solution for OpenFlow switches using a sampling-based method. For the monitoring process, the SDN controller installs a set of rules in the network switches to enable traffic flow sampling. The DC switches match the incoming packets to check whether they are part of the flow monitoring entries. If it matches, the packet counters are updated. The flow classification method uses a combination of deep packet inspection and machine learning techniques, focusing on web and encrypted traffic identi- fication. Elsaadawy et al. [38] proposed a network monitoring approach using custom port detection techniques and compare the different switch port mirror methods like a port mirror, selec- tive mirror, tunnel mirror, and truncated mirror using quantitative comparison.

Tahari et al. [41] proposed a synchronization mechanism for aggregating traffic flow statistics from distributed SDN controllers that manage the DC networks. The proposed solution consists of two layers; the first layer collects flow statistics from the network switches and sends them to a coordinator, in the second layer, to aggregate the flow information.

Liu et al. [42] presented OpenMeasure as a flow measurement and inference framework with continuous online learning to track the most informative network flows. They proposed two online learning algorithms for designing adaptive flow measurement rules: an algorithm based on weighted linear prediction and another algorithm that adopts the strategy used in multi-armed bandit problems [43].

Yang and Yeung [45] proposed the lonely flow first (LFF) algo- rithm to monitor network flows that pass through only a single switch to minimize the bandwidth consumed by monitoring traf- fic. They divide the DC switches into, with or without the lonely flows. Also, they used a weight function to decide the polling order and cost of flow polling and defined the distance and the message overhead as two communication costs to decide whether to use poll-single or poll-all switches. The proposed method compared the cost of each switch group to decide the polling method, poll- single messages method are used if the poll-all is a higher cost and vice versa until all flows are covered.

Tang and Haque [47] proposed a resilient monitoring frame- work named ReMon that can efficiently recover from link failure by merging the network packet measurement with the aggregated network statistics to improve the measurement accuracy and min- imize the measurement cost. Their solution consists of three algo- rithms. (1) The Weight Assisted Selecting (WAS) algorithm selects a group of switches to be monitored to minimize the monitoring cost and polls the flow statistics from those switches using the sFlow protocol [48]. (2) Anchor Assisted Recovery (AAR) and Weight Assisted Recovery (WAR) algorithms and integrated them in the ReMon framework to provide measurement resiliency in the case of link failure.

Rezende et al. [49] proposed SDNMon as an extension module of the SDN controller to monitor the network devices in the data plan and improve the control plan information about the network topology. SDNMon can monitor the bandwidth and latency per port and flow. SDNMon exploits threads to collect selected port

Shen [50] proposed a monitoring method based on SDN to observe a selected group of the OpenFlow switches to reduce resource consumption. The proposed method consists of two phases. 1) The monitoring phase selects the monitored switches according to the following steps: scans all network switches, counts their flows, sorts them according to their number of flows, and selects switches with the highest number of flows. At the end of this phase, the covered flows are removed from the unselected network switches. 2) The flow re-routing phase tries to combine switches with the lowest re-routing cost to re-route the flows cov- ered by the selected network switches.

The proposed method evaluates the distributed application per- formance using the support vector machine technique (SVM) to detect the anomalies and identify the root causes of bottlenecks based on SDN. The SDN controller collects statistics from the SDN switches, and calculates the performance metric for both the distributed application components and network devices. We calculate response time, throughput, and session number per application tier while calculating packet loss, delay, and available bandwidth per network link. We train the SVM algorithm using the performance metrics data and build a baseline model for nor- mal application behavior under varying network and end-host load.

The proposed method monitors the front-end server response time and classifies its performance as normal or abnormal using the one-class support vector machine (OCSVM) algorithm. We select the response time, as it represents the overall performance of the application and the network. If performance is classified as normal, it means that all application components and network devices function efficiently. Otherwise, the performance has devi- ated from the baseline model. This means that a network device or application component is operating improperly. In this case, we initiate the multi-class support vector machine (MCSVM) algo- rithm to identify the performance bottleneck and discover the responsible application tier or the network device that degrades the overall application performance. A detailed explanation of all the modules will be covered in the following parts.

This module proposed a dynamic baseline model to evaluate the application performance metrics instead of using a static and fixed threshold value to classify the application performance. We build the baseline model using the SVM model and train it using the performance metrics data. The performance metrics data is col- lected using a varying workload to simulate the real data center as load changes from time to time.

tions divided by the total number of predictions. As a performance measure, accuracy is inappropriate for imbalanced classification problems. The main reason is that the overwhelming number of the majority class will overwhelm the number of the minority class, meaning that even unskillful models can achieve accuracy scores of 90 percent depending on how severe the class imbalance happens to be. An alternative to using classification accuracy is to use precision and recall metrics.

(H). During the run-time, we inject an increase in packet loss at time 25 min, an increase in the delay at time 50 min, a decrease in bandwidth at time 75 min, and high CPU usage at time 100 min. Each anomaly lasts for 10 s.

In this paper, we proposed a new SDN-based monitoring algo- rithm to detect the performance anomaly and identify the bottle- neck of the distributed application in the cloud data center using the support vector machine algorithm. The SDN Controller collects data from network switches and calculates performance metrics for distributed application components and network devices. These performance metrics used to train the SVM algorithm and build a baseline model of the normal behavior of the distributed applica- tion on DC. The SVM model detects performance anomaly behavior and identifies the root cause of bottlenecks in two steps. (1) The One-class support vector machine (OCSVM) classifies the response time performance of the front-end server as normal or abnormal.

The proposed algorithm tries to minimize monitoring overload on the network devices using selective monitoring techniques. Finally, the algorithm notifies the administrator of the source of the bottleneck to take corrective action. The benefits of the pro- posed method, including it has a lower false alarm rate and moni- tors the performance of the datacenter infrastructure in real time without prior knowledge about the running application or the need for application instrumentation.

For future work, we plan to increase the collected metrics of the data center infrastructure and mainly focus on end-host parame- ters. Extend this solution by testing it to monitor the big data pro- cessing application like Map Reduces framework. Additional machine learning models will be included in the comparison.

