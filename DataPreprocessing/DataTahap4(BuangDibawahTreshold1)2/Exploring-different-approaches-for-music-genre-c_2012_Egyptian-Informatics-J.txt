alternatives were each popular as well. Another study [2] shows that genre is so important to listeners that the style of a piece can influence their liking for it more than the piece it- self. Finally [3], shows that categorization in general plays an essential role in music appreciation and cognition.

The remainder of this work is organized as follows. Section 2 presents a re-view on literature about music genre classifica- tion techniques, covering the state-of-the-art in the field. The proposed approach is described with details in Section 3. Sec- tion 4 lists the tests carried out with different classification schemes, input parameters, and music styles that we adopted. Lastly, useful comments and conclusions are included in Sec- tion 5, demonstrating that prominent results were achieved, strongly stimulating further research in this area.

Mckay and Fujinaga [4] elaborated a paper on why should researchers continue efforts to enhance the area of AMGC. The issues they point out are related to ambiguity and subjec- tivity in the classifications and the dynamism of music styles. It takes a lot of expertise and time to manually classify record- ings, and also there is limited agreement among human anno- tators when classifying music by genre. Very few genres have clear definitions and there is often significant overlap among them. Also, classifications tend to be by artist or album rather than by individual recordings, and metadata found in mp3 tags tend to have unreliable annotations. Finally, new genres are introduced regularly, and the understanding of existing genres changes with time.

Panagakis and Kotropoulos [12] proposed a music genre classification frame-work that considers the properties of the auditory human perception system, i.e., 2D auditory temporal modulations representing music and genre classification based on sparse representation. The accuracies they obtained outper- formed any rate ever reported for the GTZAN and IS- MIR2004 datasets, i.e., 91% and 93.56%, respectively.

What is shown is that a lot of work is being done in the area, but most of the approaches explore the timbre texture, the rhythmic content, the pitch content, or their combinations. As illustrated above, our work explores the use of entropies and fractal dimensions, thus, eliminating the use of musical information such as harmony, melody, beat and tempo. Infor- mation theory concepts are the basis of our approach.

which corresponds to 72 songs, to train it. On the other hand, when only 10% of the database was used to train it, correct recognition rates varied from 51.8% to 92.6%. Thus, although full accuracy was reached by using a considerable part of the database for training, a modest training dataset was sufficient to produce strong classification rates, i.e., the proposed ap-

