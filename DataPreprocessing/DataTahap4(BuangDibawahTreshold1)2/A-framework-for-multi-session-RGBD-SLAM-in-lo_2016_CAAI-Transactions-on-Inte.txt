Simultaneous localization and mapping (SLAM) has been a core technique enabling the autonomy of robots, such as robot car [1] and autonomous underwater vehicle [2]. Compared to these high cost and large devices, the small to medium sized devices, such as mobile manipulator, flying robot and hand- hold devices began to raise the attention in recent years due to the high flexibility, low cost and thus the highly promising application. These devices also call for SLAM to achieve the capacity of long-term operation. The main challenge for such

the map at each session, but this method discards all history experience. Our solution is to manage the dynamics in a map. Specifically, the multi-session SLAM component was utilized to accumulate the map building. On the top of that, a map management component was proposed to keep the map compact and in track of the environment changing. With this framework, we are able to address all three challenges.

In the previous studies, various SLAM methods have been presented for mapping the environment with this kind of sensors. Existing RGBD mapping methods were mainly on single session and for relatively static environment or with high dynamics [3e5]. However, the low dynamics emerging in multi-session scenario did not draw much attention. Some methods [6e8] were proposed to deal with the challenge. They used vision or planar laser sensor, which captured limited dynamics and cannot be simply extended to that using RGBD sensor. The methods using vision sensor can tell whether a frame has a significant change in appearance as it is feature based. Since the RGBD sensor also provides depth informa- tion, we can capture the geometric change and know exactly what is changed in a frame. The methods using laser sensor usually took a 2D grid occupancy map as its map represen- tation, which is not available in RGBD SLAM system due to the high complexity of 3D grid. Besides, the dynamics captured in 2D is only a slice of the 3D dynamics, which can be semantically insufficient.

multi-session SLAM and graph management. The multi- session SLAM component has a graph model with each node being a pose and each edge being a constraint, thus fusing the information from previous sessions and current session to keep the map in one global coordinates. The graph management component can keep the graph model in date and with non-accumulative complexity using the out- of-dated scan identification module and redundant scan identification module.

environment which is changed in current session. The goal of this module can be explained by setting an example, a cup was on the desk in previous sessions, but is removed in the current session. Then, the poses observing that cup on the desk should be found and pruned to keep the map in track of the environment changes. Because the unavail- ability of grid occupancy model, our idea is to adopt camera projection model and connected component detection to find the difference between the maps gener- ated by the scans in the previous sessions and that in the current session. With this method, the poses reserved are always with in-dated scans and robust to noise and holes occurred in RGBD sensor.

with others. This module is to reduce the number of poses if the number of in-dated scan is higher than a pre-defined threshold, which enables the computational time of the SLAM relevant to the size of the map and one session SLAM, instead of the all sessions SLAM. The idea of our method is to find a subset of poses that can generate a map similar to the original one using all poses, in the measure of KullbackeLeibler divergence. By applying this method, when a robot executes multi-session SLAM in a fixed sized static region in low dynamic environment, the computation complexity will keep constant since poses with redundant scans have been pruned despite that they are in date.

The objective of graph pruning is to relate the number of nodes to the size of mapping area instead of the trajectory. In Ref. [16], a reduced pose graph was proposed for mapping a large scale multi-session dataset by merging the edges when a loop closure occurred. But this method cannot control the graph size to a pre-defined number. In both Ref. [17] on 2D laser mapping and our recent work Refs. [18,19] on feature mapping, the methods are derived from the information gain of sensor readings. Thus the graph size can be controlled as users want. From the perspective of a framework, a control- lable node pruning method compatible to other modules should be designed.

One of the most similar research to the presented frame- work is [7], where multi-session 2D laser SLAM in low dy- namic environments is studied. Their method was different from our work in several aspects: First, we use RGBD sensor which makes out-of-dated scan identification more difficult. As a result, the completed dynamic objects can be captured while in 2D map it is almost impossible. Second, we apply

When a new session begins, the new poses will be added to a new pose graph before an inter-session loop closure is found, hence there are two isolated sub-graphs in the pose graph. The loop closure detection follows the method in Ref. [3], but is conducted among poses from previous sessions. If the detected loop closure constraint connecting to the poses in previous ses- sion, an inter-session loop closure is found. Then the two isolated sub-graphs are transformed into universal coordinates, the state vector and information matrix are concatenated. Generally, the number of isolated sub-graphs in the pose graph indicates the number of coordinates of the map. Optimization will be applied to each sub-graph. In most cases, there will be only one sub- graph after a session unless the new session is conduct at a new place, leading to no inter-session loop closure found.

To estimate the pose transform for both inter and intra- session constraints, we apply a feature-based alignment fol- lowed by a dense ICP alignment. SURF [22] features are extracted and matched for RANSAC based 3D-2D pose alignment [23]. It was used as the initial value for ICP, which in the system is a point to plane EM derived version [24]. In the backend at session t the optimization problem is formu- lated as

In grid occupancy map, if a grid has a status of unknown, it means there is no beam traversing that grid. If a grid is free, it means there is a beam traversing and passing through that grid. This indicates that a sensor measurement model is applied during the map building. In grid occupancy map, this model is applied implicitly using the ray casting when a new scan is registered into the map. Inspired by this insight, a camera projection model is applied explicitly to those points in grid belonging to case 1 and case 2. The measurement model is as follows,

point. The third entry of u, u(3), is the depth of p from this pose. At the same time, we have the real measurement d in the pixel (u(1)/u(3), u(2)/u(3)) of the depth image. If d is smaller than u(3), then this point is occluded from this pose, thus no information is acquired. If d is larger than u(3), then it means from this pose the point should have been observed but actually is not observed. The only reason is that this point is removed when measurement is taken in this pose, which gives the cues to the change in environment. The algorithm is shown

using the optimized pose xj . Z is the set of all such global coordinated scans. Zezj is a subset set of all scans except zj. The ith grid in the volume obtained from the out-of-dated scans identification module has mi valued 1 or 0 to indicate

the grid is occupied or not. Each point in the grid is regarded as a positive observation meaning that this grid is occupied. Thus the idea behind is to find a subset of scans that generate a volume that has similar occupancy to the original one.

Different from the grid occupancy mapping based method [17], our method uses the model only considering the end point of a beam, so that the volume obtained during out-of- dated scans identification can be employed directly in this step. The expensive computation of ray casting to build 3D occupancy grid map is also avoided. In this model, there will be no negative observations, which gives information that a grid is unoccupied. For the ith grid, the pth positive observa-

The low dynamic environment includes the static envi- ronment as a special case. When a robot executes a multi- session SLAM in a fixed sized static environment, the robot has loop closures all the time. If no extra pruning technique is employed, the size of the graph will keep growing as all scans are in-dated in such environment without change. Besides the environmental dynamics, this example also shows that in long term there exists redundancy due to continuous re-visiting of a mapped static area even in a low dynamic environment.

In this section, we demonstrate the performance of the proposed algorithm using dataset collected from the real world. There are three steps to evaluate the performance of the framework. We firstly show the effectiveness of redundant scans and out-of-dated scans identification by comparing them with other algorithms. The framework on the top of the two algorithms is evaluated on a 2-session dataset to illustrate the process of the proposed framework. The parameters are also tuned on this dataset. Secondly, with the best parameters, the

redundant scans identification. One can see that for the number of poses more than 30 after pruning, the performance of coverage is more than 95 percent, which means covering almost the whole map using half of the poses when proposed method is applied. So the size of final pose graph at each session is set 30.

To evaluate the performance of the out-of-dated scans identification, we compare the proposed algorithm with 3D occupancy grid map based algorithm, which is a direct extension of 2D occupancy grid map in Ref. [7], on the 10- session dataset. Between two consecutive sessions, an event is defined as adding or removing an object in the scene. Moving an object from one place to another in the scene consists of two events. There are in total 42 dynamic events in the dataset. An identification is defined as a component was labeled as dynamic. If the component is corresponding to the real dynamic event, the identification is defined as true positive. The precision and recall are defined as the ratio of the number of true positive over the number of identification and the number of events respectively. The computational time is included as an indicator of efficiency. The results were calculated based on the dynamic events across all sessions.

maps are compared to derive the dynamics, the tolerance of noise for each grid is the size of grid, which can be very sensitive to the noisy RGBD sensor measurement, especially when the depth is large due to the increasing uncertainty with respect to growing depth. If the grid size is enlarged to in- crease the tolerance of noise, the resolution degenerates. However, in our model, the points in grids are projected back to the depth image plane, the tolerance of noise then can be modeled in the image plane, which is decoupled from the size of grid, hence more appropriate for the RGBD sensor. Besides, the 85.4 times faster computation, which may be argued by implementation details, can at least show that our method was much more efficient by replacing the expensive ray casting with matrix multiplication, validating our hypothesis in Sec- tion 4.

In both laboratory and workspace of industrial robot, there are three kinds of typical failures for out-of-dated scans identification: (1) The small objects are captured by the RGBD sensor with low quality, which is regarded as noise by the algorithm. This failure may be solved by adding the resolution of grid. (2) The two objects are regarded as one dynamic object by the algorithm. This problem cannot be solved if no high level object segmentation or detection of the object is considered. (3) The object is removed, but the new object is added in the same position. Such change cannot be reflected by the geometric shape. This problem calls for more infor- mation from appearance clues, such as vision and semantics. However, the last two potential improvements are out of the scope in this paper.

To increase the efficiency of optimization, the method in Ref. [27] can be applied to sparsify the information matrix. For large scale mapping in dynamic environment, we want to achieve it by a submap joining technique. For each submap, the computation would be efficient. Besides, a comparison will be better if the ground truth is available as benchmark. Since we have not seen a dataset on multi-session low dy- namic environment, we are planning to calibrate a Kinect with motion capture to collect and publish such a dataset.

