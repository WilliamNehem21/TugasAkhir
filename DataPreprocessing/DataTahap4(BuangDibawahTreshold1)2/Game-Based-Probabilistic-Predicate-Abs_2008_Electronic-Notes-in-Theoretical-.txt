Modelling and verification of systems such as communication, network and security protocols, which exhibit both probabilistic and non-deterministic behaviour, typically use Markov Decision Processes (MDPs). For large, complex systems, abstraction techniques are essential. This paper builds on a promising approach for abstraction of MDPs based on stochastic two-player games which provides distinct lower and upper bounds for minimum and maximum probabilistic reachability properties. Existing implementations work at the model level, limiting their scalability. In this paper, we develop language-level abstraction techniques that build game-based abstractions of MDPs directly from high-level descriptions in the PRISM modelling language, using predicate abstraction and SMT solvers. For efficiency, we develop a compositional framework for abstraction. We have applied our techniques to a range of case studies, successfully verifying models larger than was possible with existing implementations. We are also able to demonstrate the benefits of adopting a compositional approach.

Verification of systems that exhibit both non-deterministic and probabilistic be- haviour has proved to be very useful in domains such as communication and net- work protocols, security protocols, and randomised distributed algorithms. Markov Decision Processes (MDPs) are a natural model for such systems and several tools, such as PRISM [13] and LiQuor [4], implement efficient solution methods for these models. As in the field of non-probabilistic model checking, however, the state space explosion problem tends to limit the scalability of these approaches and techniques to counter this are an important area of research.

to separate the non-determinism that is introduced by the abstraction from the non-determinism present in the original MDP. This results in abstract models that provide distinct upper and lower bounds on minimum and maximum reachability probabilities. This is in contrast to alternative abstraction methods [6], where only an upper bound on the maximum probability and a lower bound on the minimum probability can be extracted. Besides being a more informative abstraction, these bounds also provide a measure of the quality of the abstraction. This information is potentially very useful when considering refinement.

A limitation of the existing implementation in [18] is that abstractions are per- formed at the model level, i.e. the full concrete model (MDP) is constructed and then reduced to the corresponding stochastic game. In this paper, we develop tech- niques to construct the abstraction directly from a high-level description of the MDP (in this case the modelling language of PRISM) using predicate abstraction [12,1,5], which has been very successful in the non-probabilistic setting.

Predicate abstraction for PRISM models was recently considered in [22], but using the abstraction technique of [6] which represents abstractions as MDPs. Ap- plying predicate abstraction to the approach of [18] provides the additional benefits of the game-based approach but proves to be more involved. This is because the game-based abstraction preserves additional information which is non-trivial to ex- tract from language-level descriptions of PRISM models.

The techniques introduced in this paper are for Markov Decision Processes (MDPs). However, in order to adopt a compositional approach, we use a variant called Con- trolled Markov Decision Processes which represent components of an MDP. These are similar to the probabilistic modules of [7].

We now describe the parallel composition of ACMDPs. As for CMDPs, ACMDPs can only be combined when they agree on the total set of variables and their control variables are disjoint.  We call such ACMDPs composable.  Let Ai =

Suppose we wish to abstract a PRISM model. One possibility is to (compositionally or non-compositionally) apply the abstraction method of Section 3 to its CMDP semantics. In either case, the disadvantage of such a method is that the concrete CMDPs have to be constructed, limiting the applicability of the approach. In this section we define a language-level abstraction method to remedy the situation.

In Definition 4.4 each abstract command is induced by a concrete valuation and the concrete commands enabled for this valuation. However, considering each con- crete valuation individually is clearly inefficient. Our implementation therefore em- ploys an approach which detects multiple valuations inducing identical commands.

Practical approaches for abstracting MDPs are presented in [6,18], the former us- ing MDPs themselves as abstract models and the latter using stochastic two-player games. In [6] the tool RAPTURE is presented which performs successive abstrac- tions and refinements for checking bounds on reachability probabilities. In [18], a prototype implementation is used to construct abstract models from the correspond- ing MDPs and partition of the state space and compute upper and lower bounds on reachability probabilities.

we provide conditions which guarantee a precise abstraction. We have developed an implementation of our techniques based on the SMT solver Yices and present experimental results from a range of case studies, illustrating how our work can generate game-based abstractions for larger models than was previously possible. We also highlight the benefits of adopting a compositional approach.

In the future, we hope to improve the performance of our tool chain using symbolic decision procedures [19]. We also plan to integrate this with ongoing work to develop an abstraction-refinement loop for MDP verification. Finally, we also intend to extend the current method to imperative programming languages.

