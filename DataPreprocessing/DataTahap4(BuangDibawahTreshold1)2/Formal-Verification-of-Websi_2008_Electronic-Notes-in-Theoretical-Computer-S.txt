In this paper, a model for websites is presented. The model is well-suited for the formal verification of dynamic as well as static properties of the system. A website is defined as a collection of web pages which are semantically connected in some way. External web pages (which are related pages not belonging to the website) are treated as the environment of the system. We also present the logic which is used to specify properties of websites, and illustrate the kinds of properties that can be specified and verified by using a

model-checking tool on the system. In this setting, we discuss some interesting properties which often need to be checked when designing websites. We have encoded the model using the specification language Maude which allows us to use the Maude model-checking tool.

Internet is an essential component of the modern Information Society. It provides easy and flexible access to information and to resources distributed all around the world. The development of the Hypertext Markup Language (HTML) [22] and the Hypertext Transfer Protocol (HTTP) in the nineties led to a happy marriage between wires, waves, and software components (which we call now the Web) which can be thought of as the main developments driving this change.

associated to each node of the website. Such annotations can be thought of as abstractions of the (contents of the) HTML document. We show how to verify properties which are specified by using a Linear Temporal Logic (LTL [18]). Then we show how to apply a model-checking tool to the system in order to check the properties in practice. If the output from the model checker is yes, then we are sure that the system satisfies the property. Otherwise, the model checker provides a counterexample showing a trace (or path in our case) in which the property is not satisfied. This counterexample can be very useful for detecting (and eventually fixing) the error.

classical approaches to formal verification). Here, a website is a collection of web pages which are semantically related in some way and hosted at a single machine. Note that we could easily extend the notion of system by considering, for instance, a set of websites instead of a single one. In that case, a preprocess of the web page documents is mandatory in order to adapt the notions, but the contents of this paper would remain valid. It is important to note that our focus is not on analyzing the entire Web, but rather an specific part. Therefore, we represent the environment (i.e., other parts of the Web) as a single special node. This fact does not limit the applications of the framework presented since, due to the flexibility of the notion of system, our method allows one to analyze huge parts of the Web. Moreover, as we are dealing with a formal model, optimization techniques of model-checking algorithms such as symbolic representations [6] or abstract interpretation [9] can be adapted to the Web context.

In this section, we introduce some notions related to web pages and websites that will be used along the paper. We focus on the information that we intend to handle for the verification process. In particular, our model abstracts out from concrete contents of web pages such as text, images, etc.

The system to be checked consists of a website. Usually, each web page in the website is defined by means of a document, typically specified in HTML, XHTML or XML markup languages. The examples shown along this paper assume that the specification language is (X)HTML, but the definitions can be parametrized w.r.t. any specification language with a similar expressiveness. The document (web page)

In order to be able to define a link to a specific point within a document, a label (or anchor ) at such point must be defined in the document. This label will later be used in a link to specify the destination point in the web page. Links and labels are the only information about the structure of a web page that our model considers. We discuss later how the model also includes semantic information.

mechanism and host is omitted. This means that we can specify the access to a web page in the website by using a relative or an absolute URI. In this paper we assume that, whenever possible, URIs are specified in its relative form. This allows us to classify links depending on the type of URI which is used to specify the resource.

The way in which links are specified depends on the specification language. Typically, links and anchors are defined by means of the LINK and A elements of the language. In order to specify the different characteristics of the link or anchor, some attributes can be associated to these elements. In this paper we focus on the name and href attributes. name is associated to the A element in order to define a label (anchor) to a specific point of the document. href can be associated to both A and LINK elements, and contains the URI where the destination of the link is located.

In any formal verification process, one of the first tasks to be performed is the definition of the model that the verification algorithm will handle. In the following, we present a graph structure modeling websites. Recall that a website is defined as a collection of web pages that is not merely a set of web pages but rather an entity with some properties characterizing the website. The model is defined in terms of a directed graph. Each node in the graph represents a web page whereas edges represent links from the source node to the destination node.

the nodes representing web pages. Additional, more specific information could be added in a similar way. For example, we could add the keyword mvp in web pages represented by nodes 4 and 5. Finally, labels on the edges represent how the web page will be displayed by the navigation tool: in the same window as the source web page ( self), or in a new window ( blank). We aim at using all the information represented in the model to verify properties such as whether we can directly reach the homepage from every web page in the site.

In the following, we define the different components of our model. First of all, we describe how nodes of the graph are formed. Each node represents a single web page of the website. Later we introduce how each component of the node is defined. These components represent the structure and connections that correspond to each web page.

A site link is defined similarly. The difference w.r.t. local links is that the tuple has an additional component: the path from which the document can be retrieved. In order to retrieve the document, we need an auxiliary function doc that, given a URI uri(mech,host,res), retrieves the document associated to it. For example, if we had the URI uri(m,h,r), then doc(m,h,r) = d denotes that d is the document associated to such URI.

The third considered class of link is external links. We assume that these links point to resources hosted at any machine. These pages are not part of the system, i.e., part of the website, but they are part of the environment of the system. External links are defined as a tuple composed of five components:

We have already described the five first components of a node: the URI, the set of anchors and the three allowed kinds of links. The last component of each node models web semantics, i.e., the semantic annotations which are associated to the web page and that must be defined in the document; for instance, in the meta

Let us now define the edges which link the nodes. Recall that each node is a web page, and that edges represent links among web pages and are defined depending on the components of each node. In order to show how edges are defined in the graph, we need an auxiliary function which, given a link, retrieves the node corresponding to the destination document of such a link.

Note that the labeling function L is essential to determine which formulas are satisfied by a model. The classical model-checking technique [7] takes a Kripke Structure as the model of the system and a temporal formula as the property to be checked. The verification algorithm explores the model guided by the formula and answers whether the model satisfies it or not.

Temporal logic makes possible the specification of safety properties (ensuring that nothing bad will happen) and also of liveness properties (ensuring that something good will eventually happen). These properties are related to the infinite behavior of a system. In our context, the temporal view of the classical model-checking approach is transformed into an accessibility view, since the modal operators are interpreted on the links connecting web pages. Therefore, we check properties related to paths among web pages. Let us consider some interesting properties that can be modeled.

Finally, a relevant property that is commonly checked in the literature (see, e.g., [14]) concerns connectivity, i.e., ensuring that every node in the website is reachable from an initial one. In order to deal with this problem, we should verify, for each

Recall that a model checker is a tool able to formally verify whether a property is satisfied by a model, and in case it was not satisfied, then it provides the coun- terexample found. In the classical approach, this allows the programmer to detect where the error is located and to fix it. In our case, the counterexample helps the designer to identify a flaw in the website design.

As the experiments with our prototype have provided very interesting results, we think it is worth extending the system in several ways. First of all, we plan to develop parsers for other markup languages (not only HTML). We think that it is an important issue since the correct definition of the model is a crucial step on the verification process. Writing the model by hand is an error-prone process than we should avoid.

The guide [19] establishes some principles for the easy and intuitive navigation inside a website. The rules that the guide proposes regard the style of navigation in terms of the size and the architecture of sites. The guide specifies some properties that cannot be specified by using the LTL logic, in particular these where quantification is needed.

In order to be able to check such kind of properties, a real-time temporal logic is needed, i.e., not a qualitative but a quantitative temporal logic where counting the number of time instants is possible [4,5]. To deal with this kind of logic, the model-

We also plan to consider not only quantifying on the number of steps, but also on the number of paths. Properties regarding the number of links pointing to one page, or the number of links defined in a document can be very useful for a web designer, for example to restrict the number of links defined in (to) a web page. To be able to check such kind of properties, we need to quantify on the number of possible paths, thus a branch temporal logic able to count branches is needed.

Another important difference w.r.t. [1] is the kind of properties we are able to verify, implied by the fact that our model captures different information from the site. Finally, we want to mention that there exist many tools which verify static properties of websites, such as the size, connections, etc. Our method is able to analyze dynamic properties in the sense that paths can be analyzed in order to check their properties.

In [17], a different formalism is used in order to check the web. Term rewriting techniques are used in order to model the dynamic behavior of the Web. Then, properties regarding reachability can be verified under some restrictions that are imposed due to the decidability results of reachability for the different term rewriting theories. Our approach improves the one in [17] in the sense that we are able to verify more expressive properties by using an effective algorithm. Finally, note that

The rule-based approach has also been used in [2,3], where static properties re- garding both syntax and semantics of the web are verified. A new technique inspired in declarative debugging algorithms has been developed in order to check errors re- garding correctness as well as completeness of websites w.r.t. a given specification. The main difference between this approach and the framework presented in this paper is that we are interested on dynamic properties that can be specified by using temporal logics and that can be checked by using a model-checking algorithm.

Finally, other models for the web have been defined along the years such as the different versions of the random graph models [15,16]. The principal aim of these works is not to apply formal methods to the analysis or verification of websites. Random graph models are useful in order to measure the web in the sense that they try to model the web and perform a number of search algorithms that counts, for example, the number of links that contains a web page, or the number of links that points to a given web page.  The numeric results are analyzed in order to

identify clusters regarding a topic, hub web pages, etc. However, our main purpose is the verification of properties by applying formal methods, in particular model- checking algorithms, thus the model must differ. Note that it is possible to quantify and measure the web by using quantitative logics such as the real-time logics as mentioned in Section 5. In conclusion, we are able to analyze different properties by using an unified formalism: temporal logics, whereas in [15,16] different algorithms must be run in order to study different aspects of the web. Finally, we note that some of the search algorithms described in these works abstract the environment of the system similarly as we do.

In this paper we have defined a new model for websites which is more precise and flexible than other approaches. In our framework, the modeled and analyzed system can be a single website intended as a collection of web pages semantically related, but also a set of websites. We have demonstrated that the model captures enough information to apply formal methods such as model checking or inference of properties. We have established a concrete relation between our model and Kripke Structures, what makes possible to apply the model-checking technique to the Web. The most important issue in such relation is the definition of the labeling function of the Kripke Structure. In particular, we have shown how the labeling function must be defined in order to handle web semantic information of websites. This allows us to check properties related to the semantic information of web pages such as the topic, the language in which it is written, etc.

We have illustrated which kind of properties can be specified and verified by using the LTL logic, and which logics should be considered in order to specify more sophisticated properties. We have also described the possible extensions of our framework, which we plan to address as future work. A very interesting extension is to develop a methodology to infer information from the properties.

