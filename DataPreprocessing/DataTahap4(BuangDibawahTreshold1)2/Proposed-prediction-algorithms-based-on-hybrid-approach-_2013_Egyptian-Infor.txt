Abstract The RFID technology has penetrated the healthcare sector due to its increased function- ality, low cost, high reliability, and easy-to-use capabilities. It is being deployed for various appli- cations and the data captured by RFID readers increase according to timestamp resulting in an enormous volume of data duplication, false positive, and false negative. The dirty data stream gen- erated by the RFID readers is one of the main factors limiting the widespread adoption of RFID technology. In order to provide reliable data to RFID application, it is necessary to clean the col- lected data and this should be done in an effective manner before they are subjected to warehousing. The existing approaches to deal with anomalies are physical, middleware, and deferred approach. The shortcomings of existing approaches are analyzed and found that robust RFID system can be built by integrating the middleware and deferred approach. Our proposed algorithms based on hybrid approach are tested in the healthcare environment which predicts false positive, false nega- tive, and redundant data. In this paper, healthcare environment is simulated using RFID and the data observed by RFID reader consist of anomalies false positive, false negative, and duplication. Experimental evaluation shows that our cleansing methods remove errors in RFID data more accu- rately and efficiently. Thus, with the aid of the planned data cleaning technique, we can bring down the healthcare costs, optimize business processes, streamline patient identification processes, and improve patient safety.

RFID is a technology which uses radio communication be- tween tags and readers to automatically identify the locations of items. In a networked environment of RFID readers, enor- mous data are generated from the proliferation of RFID read- ers [1]. The raw data generated from the readers cannot be directly used by the application because it consists of enor- mous volume of data duplication, false positive, and false neg- ative. Thus, the RFID data repositories must cope with a

number of quality issues. These data quality issues include data redundancy, false positive, and false negative. Poor data quality has adverse effects at the operational, tactical, and stra- tegic levels of an organization. This is especially true in the healthcare field where cost pressures and the desire to improve patient care drive efforts to integrate and clean organizational data.

An RFID reader periodically sends out RF signals to its range. When an RF tag that moves within the range of the reader receives the signals, it will send a response signal along with its unique identifier code, timestamp, and location ID. The reader receives the response signal and registers the data stream as one entry. There would be some RF tags which are not supposed to be detected by the reader and may be read due to the spatial divergence of RF signals sent by the reader. Such readings are termed as false positive readings [8,9].

Duplicate readings are classified into reader duplicates and data duplicates. The former occurs when a tag is present in the vicinity of more than one reader which is simultaneously send- ing signals to it. Consider a scenario where readers R1, R2, and R3 are redundant since the tag T1 is read by all three read- ers at the same time, thus responsible for reader level redundancy.

The latter occurs when a reader reads a large amount of non-difference information at a time interval. For instance, in Hospital Management System, a tagged entity (Say a doc- tor) may move to his consulting room and sit the whole day and send the data to the RFID management system constantly through the reader placed in his vicinity. But, from the man- agement point of view, the most useful information for event detection is when the tagged entity (Say a Doctor) enters and exits his consulting room. Therefore, it is necessary to reduce RFID data redundancy before processing.

parallel. This is because of overlapping in the reading vicinity of multiple readers and it is termed reader level duplication. Duplicate readings at the data level occur when an RFID read- er keeps reading the same object repeatedly. The proposed CBADE predicts and cleans the duplication in middleware ap- proach. The middleware cleaned data are stored into the database

rules that specify an RFID tag and its mobility. It defines the list of all allowed tag-location combinations. Timestamp here defines the assumption or set rule that specify an RFID tag and its validity in a specific region mentioned in precondi- tion with a time bound limit. It defines the list of all allowed time window for a specific tag-location combination.

The middleware cleaned data are stored into the database. Here, the precondition based algorithm R-PFP checks whether the tag is in the allotted location at the specified time. If it is exactly true, then there is no anomaly. With the help of this algorithm, the presence of false positive is detected and cleaned in deferred approach. Precondition is the assumption or set

