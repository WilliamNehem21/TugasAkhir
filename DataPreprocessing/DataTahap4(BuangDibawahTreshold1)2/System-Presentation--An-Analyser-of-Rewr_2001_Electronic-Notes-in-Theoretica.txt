We consider term rewriting systems built over three distinct sets: function symbols (de ned symbols), constructors, and variables. The function symbols and constructors are ordered by a precedence F , constructors are considered as the smallest elements of the precedence. A program is a set of rewriting rules.

ICAR (Implicit Complexity AnalyseR) rst checks the termination of the given rewriting system and then tries to nd a bound on its complexity. This work is based on [5,7,2] for complexity analysis. Program transformation by means of memoization is based on Jones work [4].

One of the main interests of our approach is that this analysis gives an upper bound on the complexity of the function computed rather than on the com- plexity of the program. This kind of complexity analysis was dubbed implicit. So ICAR also gives a way (i.e. a new operational semantics) to e ectively achieve this bound.

The signature C[F and the set E of rules induce a rewrite system which brings us the operational semantics. Recall brie y some vocabulary of rewriting theories. For further details, one might consult Dershowitz and Jouannaud's survey [3] from which we take the notation. The rewriting relation ! induced by a program main is de ned as follows t ! s if s is obtained from t by

De nition 2.3 Let main be a con uent program and main 2 F be a function symbol. The function computed by main is the partial function JmainK : T (C)n ! T (C) where n is the arity of main which is de ned as follows. For

Claim 4.1 With this restriction, the precedence can be found in quadratic time with respect to program size. So termination by either MPO or LPO can be checked in time 2c k where k is the maximal arity of a function symbol and c is a constant.

 nding polynomial interpretations) seems to be undecidable. Fortunately, quasi-interpretations are quite easy to nd because an upper bound on the program denotation turns out to be a good candidate. So, even if nding one is a hard task for a computer, it's an easy job for the programmer. The idea is to provide a potential quasi-interpretation together with the rewriting rules, and the program just has to check it.

Time measurement is the number of reduction steps needed to reach normal form and space measurement is the size of the environment and the cache, i.e. the number of objects stored into the environment plus the number of objects stored in the cache. These measurements are not very accurate because the real time needed to perform a reduction step and the size of a term depend on the term. But in both cases, the increment is polynomial in the size of the term, so the polynomial bounds are not broken and the measurements give a not so bad idea of what happens.

Proof. If t and s are ordered when g F f then for all i; 1  i  n, there exists a j; 1  j  n such that vi  mpo uj (by de nition of MPO). So for all i, vi  mpo t, so the two terms are ordered if g  F f.	2

Lemma 5.3 Let t = f(u1;   ; un) and s = g(v1;   ; vn) be two terms. If s mpo t or s lpo t, no symbol (function or constructor) in s may have a precedence greater than the greatest symbol in t.

Proof. As l is the left-hand-side of a rewriting rule, l = f(p1;   ; pn) where pi are patterns, that is terms build only over variables and constructors. Since constructors have a precedence smaller than any function symbol, f has the maximal precedence of l. So by the previous lemma, it must also have the maximal precedence of r.	2

Proof. By examining rewriting rules and by lemma 5.4, we obtain a set of constraints of the form f F g. Then, graph-reachability between any two symbol tells whether f F g or not. If there are both f F g and g F f, then there must be f  F g. If there is only g  F f, then lemma 5.1 and	5.2

As previously said, nding a polynomial quasi-interpretation is probably an undecidable problem. But it appears that the semantics of a function is a good candidate (e.g. the function add, computing the addition of two numbers, admits addition as a quasi-interpretation). Of course, nding the semantics automatically is also undecidable. But when one writes a program, one is suppose to know what the program will compute, so one can give to ICAR something very likely to be a quasi-interpretation.

The idea is to plug ICAR into ELAN 3 , which is a quite big system devel- oped at Loria to deal with term rewriting systems. Having a bound on the complexity of some of the systems will be very usefull for the ELAN-people. During spring and summer 2001, Mitch Harris rewrote ICAR in TOM, the (futur) parser of ELAN terms.

