The problem I want to discuss in this note, one that I have been working on for the last ten years or so, is simple to state. I want a computer system that reads sentences in English and constructs a logical representation of these sentences in an automatic and efficient way. I do not want very complicated sentences, no need for several layers of meaning, metaphors or poetry. Simple, factual language that your average twelve-year old would understand is the goal here.

1 Thanks to all my ex-colleagues at PARC for insights and discussions. Thanks to Rodrigo de Salvo Braz for inviting me to give a talk at SRI, that became this note. Special thanks to Dick Crouch and Ann Copestake, who tried to teach me this, a long time ago.

is by now somewhat accepted, the use of logical methods for language is still not accepted as useful. The hugely successful use of statistical and learning methods for all tasks initially associated with symbolic processing of language meant that purely symbolic processing is now considered somewhat obsolete. But it should be clear that the symbolic methods should not be tossed aside.

Existing applications have been multiplying, and the more data one has, the better these methods perform. For example, machine-learned statistical translation is nowadays much better than it was only a few years back and for some tasks it is good enough. Some believe that all the problems of computational linguistics will be solved by throwing more data at systems, but it seems clear to me that we need both machine learning and symbolic methods in tandem. In particular data-driven methods seem to not perform well in the presence of negation and antinomy. For example it is clear that the sentences below are contradictory, if we are referring to the same incident:

The traditional architecture of a symbolic system for language understanding consists of four components: a preprocessing module, a parsing module (based on some grammar), a semantics module and a post-processor. Traditionally many different kinds of grammar (based on different linguistic theories) are available, as are many different kinds of semantics. While for grammaticality there is at least some degree of consensus and there are huge numbers of annotated sentences with judgements, the situation for semantics is very different. There is almost no consensus and almost no annotated data.

The logic system associated with the system Bridge has been synthetized from the actual descriptions produced by the system. Each sentence produces a represen- tation, consisting of concepts and contexts. The logic of the representations system thus summarized, called TIL for (textual inference logic) was described in Bobrow et al. [7] and de Paiva et al. [12]. ( The second paper discusses how the Bridge system went from a system based on the common sense ontology Cyc to one based on the PARC Unified Lexicon ontology and how this change was not problematic.)

Then for each sentence si in C a bridge system will produce a representation repi of the semantical content of si. This representation consists of a collection of assertions, relating the concepts and contexts mentioned in the sentence si. Any sentence has one or more contexts. Simple sentences like The boy arrived will have a single context, which we write as context(t). This context represents the world from the viewpoint of the author of the sentence.

Given that we were trying to formalize an evolving system, it seemed a good strategy, at least as a first cut, to discuss possible logics of contexts over a proposi- tional basis in an abstract and modular fashion and to try to match these possible systems with the output coming up from the implemented system. This was the approach pursued in [6], [8] and [10]. We recap some of this approach, so that we set up some open problems later on.

Several options of logical systems, some partially described, some not investigated at all, were mentioned in the previous subsections. It is my belief that these sys- tems should be, at least minimally, investigated for their potential uses as logics of context. To help start this chartering of the land, I present the following diagram, explaining some of the connections.

We discussed a class of systems that take natural language sentences as input and produce logical formulas corresponding to these sentences. We called these systems bridges and we looked at possible targets for these bridges from language to logic. Then we surveyed some of purely logical systems. Much remains to be done. This enterprise is necessarily an empirical one and one of the main success criteria will be the coverage that any such system obtains. The pipelines of processing those possible bridges are long and there are opportunities for mistakes at every junction, so robust regression systems have to be in place.

