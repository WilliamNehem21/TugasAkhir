Fault-based testing uses test data designed to demonstrate the absence of a set of pre-specified faults. A well-known fault-based technique is mutation testing. In mutation testing, first, faults are injected into a program by altering (mutating) its source code. Then, test cases that can detect these errors are designed. The assumption is that other faults will be caught, too. In this paper, we apply the mutation technique to both, specifications and programs.

The theory we contribute was designed to be a complement to the existing body of knowledge. Traditionally, theories of programming focus on semantical issues, like correctness, refinement and the algebraic properties of a programming language. A complementary testing theory should focus on the dual concept of fault. The main idea of a fault-centred testing approach, also called fault-based testing, is to design test data to demonstrate the absence of a set of pre-specified faults.

The paper is structured as follows. After this general introduction, Section 2 gives a very brief introduction to the theory of designs of [11] and defines what we mean by a faulty design. The next two sections include the main contributions of this paper. Section 3 contains a construction for test cases that will find anticipated errors in a design. This test case generation technique works on the semantic level of designs. In Section 4, a purely algebraic (syntax-oriented) test case generation technique is presented. It is based on the algebraic properties of a small, but nontrivial, programming language. Finally, in Section 5 we discuss the results as well as its related work, and present an outlook on future research directions.

Here, we restrict ourselves to model-based (model-oriented) specifications. More precisely, we use the design calculus of UTP to assign specifications a precise seman- tics. Designs are a special form of predicates with a pre- and postcondition part, together with an alphabet. The alphabet is a set of variables that declares the ob- servation space. The free variables of a design predicate are a subset of the alphabet and represent state variables before (undecorated variable names) and after execu- tion (decorated variable names) of a program. In addition, special Boolean variables

In this section, we relate test cases via refinement to designs and programs. This is possible, since we give test cases a denotational semantics by viewing them as specification predicates. The result is a test case generation technique based on non-refinement.

Previous work of the first author [1] has shown that refinement is the key to understand the relation between test cases, specifications and implementations. Re- finement is an observational order relation, usually used for step-wise development from specifications to implementations, as well as to support substitution of soft- ware components. Since we view test cases as (a special form of) specification, it is obvious that a correct implementation should refine its test cases. Thus, test cases are abstractions of an implementation, if and only if the implementation passes the test cases. This view can be lifted to the specification level. When test cases are

this condition is at the heart of our test domain. Since we have to show non- refinement, this must hold for all the non-deterministic choices of P ( j ). Finally, each non-deterministic choice of Pm may contribute to non-refinement ( k ).

Operators that distribute through least upper bounds of descending chains are called continuous. Fortunately, all operators in our language are continuous and, therefore, this normal form transformation can be applied. Unfortunately, this infinite normal form can never be computed in its entirety; however, for each n, the finite normal form can be readily computed. The normal form for our full programming language is, thus, defined as follows

Example 4.8 Assume that we want to find an index t pointing to the smallest element in an array A[1..n], where n is the length of the array and n > 0. A program for finding such a minimum can be expressed in our programming language as follows:

It can be seen from the first three approximations that our normal form approxi- mations represent computation paths as guarded commands. As the approximation progresses, more and more paths are included. Obviously, the normal form approx- imations of the whole program, including the initialisations of k and t, can be easily obtained by substituting 2 for k and 1 for t in S1, S2,... .

The first test case generation law (Definition 3.4) is a general criterion for fault- based test cases. It is not completely new, but has been translated from our previous work [1] to the theory of designs. It states that a test case in order to find a fault in a design (which can range from specifications to programs) must be an abstraction of the original design, and in addition, it must not be an abstraction of the faulty design. No such test cases exist if the faulty design is a refinement of the original one. Note that the translation of this criterion from a different mathematical framework was straightforward. Since our previous definition was solely based on the algebraic properties of refinement, we just had to change the definition of refinement (from weakest precondition inclusion to implication). This demonstrates the generality of our refinement-based testing theory. In [2] we applied this technique to labelled transition systems.

The second test case generation law (Theorem 3.8) is more constructive and specialised for designs. It can be applied to specification languages that use pre- and postconditions, including VDM-SL, RSL, Z, B and OCL. Its finding is based on the conditions, when refinement between designs does not hold. It uses the operations on predicates (conditions and relations) to find the test cases. This approach forms the basis for our constraint solving approach to generate test cases from OCL specifications in [3].

Tai and Su [15] proposed algorithms for generating test cases that guarantee the detection of operator errors, but they restrict themselves to the testing of singular Boolean expressions, in which each operand is a simple Boolean variable that cannot occur more than once. Tai [14] extends this work to include the detection of Boolean operator faults, relational operator faults and a type of fault involving arithmetic expressions. However, the functions represented in the form of singular Boolean expressions constitute only a small proportion of all Boolean functions.

Burton presented a fault-based test case generator for Z specifications [6]. He uses a combination of a theorem prover and a collection of constraint solvers. The theorem prover generates a disjunctive normal form, simplifies the formulas and helps in formulating different testing strategies.

