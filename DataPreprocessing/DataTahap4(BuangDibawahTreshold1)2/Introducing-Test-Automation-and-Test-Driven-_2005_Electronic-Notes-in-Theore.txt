This paper identifies and presents an approach to software component-level testing that in a cost effective way can move defect detection earlier in the development process. A department at Erics- son AB introduced a test automation tool for component-level testing in two projects together with the concept test-driven development (TDD), a practice where the test code is written before the product code. The implemented approach differs from how TDD is used in Extreme Programming (XP) in that the tests are written for components exchanging XMLs instead of writing tests for every method in every class. This paper describes the implemented test automation tool, how test-driven development was implemented with the tool, and experiences from the implementation. Preliminary results indicate that the concept decreases the development lead-time significantly.

The method used for answering the first two questions was a combination of analysis of lessons learned from previous improvement attempts together with a thesis study [7] on how to increase the test efficiency at the department. The thesis study included qualitative and quantitative enquires, analysis of project statistics, and a literature study. Answers to the other two questions were captured from qualitative and quantitative interviews with users of the introduced concept.

commands and no looping) and more importantly, it was not properly in- tegrated with the development process. When the department had realized this, the earlier mentioned thesis study [7] evaluated the test process with the purpose to identify tool and process changes that would increase the test efficiency. The thesis study showed that the cost of finding and fixing defects increases significantly the later in the development process they are found. This is also considered a common fact in software development [5], [10], [21]. Since the thesis study also discovered that the developers normally put little effort on testing isolated components, the thesis suggested that this is where to focus the improvement efforts.

After determining that the improvement efforts should focus on the Basic Test level, the thesis study determined that the main reasons for why the developers at the department did not Basic Test all functionality was because of insufficient test tools (e.g. DailyTest) and process deviations when the deadline pressure was high due to delayed schedules. When the development activities were delayed, the projects tended to deliver the code untested hoping that it in a miraculous way would work anyway. Likewise, this phenomenon seems far from uncommon in the software industry [14], [21].

After providing some background information, sections 3.1 and 3.2 give a technical tool description and Section 3.3 describes how the tool was integrated with the development process at the department. After that, Section 3.4 lists some observations and lessons learned and finally, Section 3.5 presents the expected lead-time gains from introducing the concept.

Next, the department needed to choose a language to write the test cases in. The major benefits of using standard script languages as for example Vi- sual Basic and JavaScript are that programmers tend to be less error-prone compared to when using system-programming languages [17]. Still, the depart- ment chose to use C++ as test case language. Firstly, because the developers do not need any training on how to use it since they write the product code in it. Secondly, C++ has the power to handle features that are not included in the actual tool, e.g. it is possible to make direct calls on functions in the product code when the tool has no support for it implemented. Finally, when the test cases are written in the same language as the product code, the de- velopers can take advantage of the programming tools already available [9], [20].

Just providing a good tool does not ensure successful test automation; a tool only becomes as good as the people using it [21]. Since this tool was to be used with TDD (see Section 2.1), the test cases should be written before the code. As earlier mentioned, the department introduced TDD on a component

level instead of on a class level, i.e. the developers construct a set of test cases for each component instead of a set of test cases for each class. The test strategy was to capture all inputs and outputs of each component. Thereby, the tests represent the external design of each component. This also led to test cases that could serve as a part of the design documentation, replacing some of the old design (e.g. component specifications). The result of this was a more thorough design (in comparison to plain English, C++ does not leave room for misinterpretations) and that some design time could be saved when being able to remove some of the old design documentation.

Another challenge the department had to address was to implement the new Basic Test concept on products that already existed since several years and therefore, the components contained a lot of old functionality that did not have such tests. Since developing tests for all old functionality when introducing the tool would be far too costly for a single project to handle, the department chose only to develop tests for new and modified functionality. Henceforth, the strategy was to develop tests for more and more of the old functionality during upcoming projects (i.e. in future releases of the product).

... what gets measured gets done [13], [23]. When the department started the introduction of the new concept for Basic Test, the target projects gave it modest attention. However, when the projects started measuring the progress for number of test cases developed and passed, the usage rates increased.

... beware of attempts to deviate from the agreed process. When in time- pressure, projects tend to neglect some activities which might give near-time benefits but that might be devastating in the long run [13]. Therefore, such deviations should not be allowed without being agreed on by all involved

... test tools easily become the excuse for every problem [8]. Reasons for a problem can be in either the test tool, the development environment or in the application under test; still, the Basic Test tool became the scapegoat for most problems since it is in the tool the problems first are discovered no matter where they origin.

... benefits from test automation are hard to obtain in the first project release. Other reports support this experience by claiming that upfront costs eliminate most benefits in the first project and benefits from regression testing are usually not realized until the second release [16].

... test automation should be introduced in small steps, e.g. as a pilot project to avoid taking unnecessary risks (if something is introduced in the wrong way but only in small scale, the cost of fixing the problem is most likely lower). This advice is also given in the research literature [9], [12], [17].

... minimizing maintenance costs is the most difficult challenge in test au- tomation. The test cases must be robust to changes during bug fixes and in new product versions. Since this is hard to achieve, the most common problem in test automation is probably uncontrolled maintenance costs [17].

Test case generators are the most advanced test automation tools. They exist in several variants: structural generators (generate test cases from the struc- ture of the code); data-flow-generators (use the data-flow between software modules as base for the test case generation); functional generators (gener- ate test cases from formal specifications); and random test data generators [3]. Test case generators can generate several test cases fast but are still not always more cost-effective since expected results need to be added manually. Further, the generated test cases/executions of the test cases must also be checked manually to verify that they test the right functionality.

First, the development process that the developers follow needs to be mature enough. If the process is poor, test automation will not help [9], [17]. Prefer- ably, the test automation effort should be easy to adapt to current practices; if the change is too great, the risk for resistance among the developers in- creases [15]. Furthermore, if the developers do not want to work as directed, they will not [13]. At the department, the developers were aware of that ne- glecting Basic Test results in increased verification lead-time [7]. Therefore, they were open to improvements in Basic Test. Second, the managers must be committed to the new methods because it is they that have to grant the upfront costs with introducing test automation (that most likely will impact short-term budgets and deadlines negatively [4]). Test tool costs is just the tip of the iceberg [9], [17].

The Ericsson department introduced a new test automation tool incorporated with an alternate approach to Test-Driven Development (TDD), i.e. TDD on a component level where the interfaces comprise socket connections exchang- ing XML data instead of classes and methods. With such an approach to test-driven development, robust and uniform component interfaces make test automation easier.

The main characteristic of the tool is that it uses C++, the same standard programming language as the developers write the product code in, because the developers are already familiar with it, it is more powerful than a script language, and the developers can take advantage of programming tools already available (e.g. compilers and debuggers).

The developers that have used the concept have estimated that the project lead-time will decrease more and more for each new project version that uses it (see Section 3.5). Further, preliminary project evaluations indicate signifi- cantly decreased fault rates from the introduction of the new concept.

