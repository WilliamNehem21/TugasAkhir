Building verified compilers is difficult, especially when complex analyses such as type checking or data-flow analysis must be performed. Both the type checking and program optimization communities have developed methods for proving the correctness of these processes and developed tools for using, respectively, verified type systems and verified optimizations. However, it is difficult to use both of these analyses in a single declarative framework since these processes work on different program representations: type checking on abstract syntax trees and data-flow analysis-based optimization on control flow or program dependency graphs.

We present an attribute grammar specification language that has been extended with constructs for spec- ifying attribute-labelled control flow graphs and both CTL and LTL-FV formulas that specify data-flow analyses. These formulas are model-checked on these graphs to perform the specified analyses. Thus, verified type rules and verified data-flow analyses (verified either by hand or with automated proof tools) can both be transcribed into a single declarative framework based on attribute grammars to build a high- confidence language implementations. Also, the attribute grammar specification language is extensible so that it is relatively straight-forward to add new constructs for different temporal logics so that alternative logics and model checkers can be used to specify data-flow analyses in this framework.

To build a verified compiler one must write a specification of the compiler that addresses all aspects of the language and that is amenable to the kinds of anal- yses that are done to generate proofs of correctness. An obstacle to this is that different aspects of the compiler are more naturally defined using different nota- tions for different program representations. For example, type-checking is typically a syntax-directed activity and thus the process of checking types in a program and of proving the correctness of a type system is tightly coupled to the syntax-tree program representation. On the other hand, optimizing transformations are often written as rewrite rules with data-flow analysis-based side conditions, and perform- ing data-flow analysis and proving its correctness are tightly coupled to the control flow graph or dependency graph program representations.

As an example of data-flow analysis-based optimizations, we show how (imme- diate) dead code analysis on the assign production is used to determine if the as- signment should be changed to a skip statement. The synthesized higher-order [22] attributes opt stmt and opt stmts are used to construct the optimized program. In the root production, the value of the opt stmts attribute (on s::Stmts) is the tree representing the optimized program.

The results of the model checker (stmts.deadResults in this case) are passed down as an inherited attribute to the productions that need the results. The ex- tension provides a construct to check whether a particular substitution satisfies the formula on a particular node. The syntax of this construct is

A distinguishing characteristic of this work is that Silver is designed and built as an extensible language. Thus it can easily be extended with new language constructs and semantic analyses of those constructs. Above we presented extensions that allow Silver to perform data-flow analysis based on two different temporal logics. Extensions to use other logics and model checkers can also be added in a straight- forward way.

Silver attribute grammar specifications are implemented by translating them to Haskell code. This Silver-to-Haskell translator is implemented as an attribute gram- mar written in Silver. (A good test for Silver was to write a compiler for it in itself.) The declarative, modular, and extensible nature of attribute grammars is the key to implementing the DFA extensions to Silver [21]. To add new language constructs to Silver, one adds new productions that define their concrete and abstract syntax and attribute definitions for the attributes that label the nonterminals in the abstract grammar for Silver.

We built these data flow analysis extensions to Silver because in other research endeavors we need to write high-level language specifications that include both syntax-directed and control flow graph-based analyses in a single framework. We use Silver to write specifications for extensible host languages and language exten- sions that add new language constructs, semantic analyses of these constructs, and optimizations of these constructs (often based on data-flow analysis) to the host language. Many of the language extensions we have specified contain domain spe- cific constructs. Examples include an extension that embeds SQL into an extensible Java host language and a computational geometry extension that adds efficient un- bounded numeric types. We expect that language extensions will be written by people who are experts in these specific domains but are not programming lan- guage implementation experts. Thus, we want to provide a high-level formalism for specifying data-flow properties that may be used in optimizations of domain specific constructs. Temporal logics provide such a high-level formalism.

