For representation based image classification methods, it is very important to well represent the target image. As pixels at same positions of training samples and test samples of an object usually have different intensities, it brings difficulty in correctly classifying the object. In this paper, we proposed a novel method to reduce the effects of this issue for image classification. Our method first produces a new representation (i.e. virtual image) of original image, which can enhance the importance of moderate pixel intensities and reduce the effects of larger or smaller pixel intensities. Then virtual images and corresponding original images are respectively used to represent a test sample and obtain two rep- resentation results. Finally, this method fuses these two results to classify the test sample. The integration of original image and its virtual image is able to improve the accuracy of image classification. The experiments of image classification show that the proposed method can obtain a higher accuracy than the conventional classification methods.

Image classification is a significant branch of computer vision. In this branch, the representation based classification methods have attracted considerable attention. A good repre- sentation for target images is greatly beneficial to improve the performance of image classification [1,2]. An object can be distinguished from the others when its image is well repre- sented by the other images from this object. The combination of multiple representations of images is an effective method to improve the performance of representation based methods [3,4]. Therefore, it is an important and meaningful topic to find a proper representation for representation based image classification methods.

still face with some great challenges. Different poses and ex- pressions, various intensities of illuminations and insufficient training samples seriously influence the recognition effects. In order to address these challenges, people have made many ef- forts. For various illuminations, by handling the original images to enhance pixels with moderate intensities of the original im- ages and reduce the importance of other pixels, Xu et al. [10] obtained the complementary images to improve the accuracy of image classification. Producing the mirror image of the face and integrating the original face image and its mirror image are also useful to improve the recognition accuracy of representation-based face recognition [11]. For the problem of insufficient training samples, Huang et al. [12] proposed a robust kernel collaborative representation classification method based on virtual samples for face recognition to reduce the in- fluence of insufficient training samples. The use of symmetrical face images generated from original face images is very useful to overcome the problem of varying appearances of faces [13,14]. Until now, many works focus on generating virtual or synthesized face images to enhance the recognition accuracy

[15e19]. The simultaneous use of original face images and their virtual face images can improve the accuracy of face recognition. What is more, several works have shown that vir- tual image obtained by exploiting the adjacent rows of original image are also useful for image classification [20e24].

Wright et al. [25] proposed the sparse representation clas- sification (SRC) algorithm which can reach satisfactory result. There are many SRC algorithms [26e30]. However, the orig- inal SRC algorithm with the constraint of l1 minimization is time consuming. Zhang et al. [31] proved that the essence to obtain the satisfactory performance of the SRC algorithm is the collaborative representation but not the sparsity, and proposed a collaborative representation classification (CRC) method with the constraint of l2 minimization. CRC methods can obtain comparative performance to SRC algorithm, but is much faster than SRC algorithm. Various representation methods with the constraints of l2 minimization are also proposed, such as linear

shown to be beneficial to improve the recognition accuracy. The method also exploits the correlation of adjacent rows in a good way. (3) It increases the number of training samples, and represents a test sample effectively by combining original and virtual images.

The remainder of this paper is organized as follows. Section 2 presents the proposed novel representation method of im- ages. Section 3 describes the underlying rationale of the pro- posed method. Section 4 shows the experimental results. Section 5 provides the conclusions of this paper.

Our method mainly includes two procedures. By the first procedure, we obtain the novel representation of original im- ages as follows. Let I stand for an original image which has been converted into a gray image, andIij represents the pixel intensity at the i-th row and j-th column of I. Let m be the maximum pixel intensity of the gray image. For conventional gray images,

Different intensities of pixels have different importance in image classification and we can exploit a subset of all image pixels for image classification [36]. Hence, it seems that setting different weights to different pixels is reasonable. Furthermore, the important features of an image are mainly concentrated on the moderate intensities of pixels, so it should emphasize the moderate intensities of pixels [10]. Fortunately, our method has the idea that different pixel intensities play different roles in representing the object.

We conduct image classification and face recognition ex- periments to test our method. As shown later, the recognition accuracy obtained by using our method is satisfactory. Three databases including a non-face image database, the COIL20 database, are used in these experiments. Moreover, in order to balance the classification results of different training samples, a is set to be different value in CRC and LRC.

In this section, we use the ORL database to test our method. The ORL database [37] includes 400 face images taken from 40 subjects each providing 10 face images. For some subjects, the images were taken at different times, with varying lighting, facial expressions, and facial details. Each image was resized to a 92 by 112 image matrix. They are all converted into gray

number of training samples is 3, the rates of classification errors of original CRC is 13.21% and our method's is 8.93%. That is, our method can improve 4.28% for the recognition accuracy. We also know that our method is better than the method proposed in [10].

In this section, we use the AR database [40] to test our method. The AR database contains over 4000 color face im- ages of 126 people. In this paper, we only choose 120 people of them. Hence, the used database contains 3120 images taken from 120 people and each people has 26 images. We resized each image to a 50 by 40 image matrix. In experiments of the

The authors are grateful to College of Automation Harbin Engineering University, this paper is supported by National Natural Science Foundation of China (No. 51109047), Natural Science Foundation of Heilongjiang Province (No. LC201425), and the Fundamental Research Funds for the Central Universities (No. HEUCF0415).

the Control Science and Engineering in Harbin Engi- neering University. She is a visiting scholar of the University of Louisiana at Lafayette (American) and the Texas A&M University (American) in 2006e2007 and 2013e2013, respectively. She has published more than 50 journal and conference papers. Her research interests include target detecting, tracking and recog- nition, image and video enhancement.

