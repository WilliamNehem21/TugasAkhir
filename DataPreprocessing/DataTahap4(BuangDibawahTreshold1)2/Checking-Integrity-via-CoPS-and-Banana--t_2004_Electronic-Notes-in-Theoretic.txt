In the last decades the protection of confidential data from undesired accesses has been widely investigated both on systems and networks. Information is typically protected via some access control policy, limiting accesses of entities (e.g., users, processes) to data. There are different levels of flexibility of access control policies depending on the possibility for one entity to change rights to its own data. In the case of mandatory policies, entities cannot change access

rights. For example Multilevel Security [1] imposes that entities and data are associated to (ordered) security levels and no access to data at higher level is ever possible. This strong security policy has been designed to avoid internal attacks performed by Trojan Horse programs. Unfortunately, even with a multilevel security policy data can be indirectly leaked by Trojan Horses (see, e.g., [18,22]).

Insert the process(es) to be checked in the editor pane. The process(es) can be either typed or loaded from a file. A tree is automatically drawn to facilitate the navigation among processes. The syntax is highlighted to get a better readability. Both fonts and colors can be changed by the user.

L. In the case of protocols we can assume that the users of level L are the honest participants, while H is the external, possibly malicious, environment. Since an intruder may have complete control of the network, we assume that the channels are of level H. In this way all the protocol actions are of level H, while the actions of level L are extra observable actions that are added to the protocol to check its properties. Hence, the way in which the low level actions are added depends on the security property we are interested in. For instance, in the case of integrity, if we want to check that an action h2 can be performed only after the execution of an action h1, we add a low level action l1 after each h1 and a low level action l2 after each h2 and we check that in the low level behavior l2 occurs only after l1.

Notice that if the prices are correct while the payment data are wrong the process E-sales reads the prices and outputs the remaining set of data (i.e., payment and address). In this case AccountsRec blocks the process since it cannot read a wrong payment. Another possibility would be to add to

of confidentiality. This is obtained by exploiting the labeling of the ambi- ents. In particular, the set of ambient labels is partitioned into three disjoint sets: high, low and boundary labels. Ambients labeled with boundary labels (boundary ambients) are the ones responsible for confining confidential infor- mation. Information leakage occurs if a high level ambient exits a boundary, thus becoming possibly exposed to a malicious ambient attack. In the follow- ing examples, we will use b to label boundaries, h for high level ambients, and c for capabilities. For instance, let P2 be a labeled extension of process P1, in which the envelope contains confidential data hdata (labeled high) which needs to be safely sent from venice to pisa.

In [3], a more accurate abstract domain that separately considers nesting inside and outside security boundaries is proposed, yielding to a much more sophisticated control flow analysis for detecting unwanted boundary crossing, i.e., information leakage. The main idea is to distinguish among nestings either protected or unprotected by boundaries.

A post-processing module, that interprets the results of the analysis in terms of the boundary-based information-flow model proposed in [3], where infor- mation flows correspond to leakages of high-level (i.e., secret) ambients out of protective (i.e., boundary) ambients, toward the low-level (i.e., untrusted) environment.

Banana is implemented in Java and strongly exploits the modularity of object-oriented technology, thus allowing scalability to other analysis and ex- tensions of the target language. Moreover, it is conceived as an applet based on AWT and thus compatible with the majority of current web browsers sup- porting Java. A tutorial about the use of Banana is available in the tool web pages.

Notice that in our modeling each sub-ambient of the Server opens an ambi- ent: each opening represents the fact that a checking phase has been passed. Also the client must be explicitly modeled. The whole system will be the parallel composition of the two. All the capabilities to move from one sub- ambient of the Server to another have to be included in the sub-ambients of the Client. In particular, itemprice has to exit from Client, enter into Server and then into E-sales. If the order is correct, itemprice is opened. After the opening of itemprice, an ambient creditcardnum has to enter into AccountsRec.

is passed with the opening of creditcardnum, and finally the third checking phase is passed with the opening of address. We are interested in ensuring that the three checking phases are performed in the correct order, e.g., we do not want that the address is opened inside Shipping before itemprice is opened inside E-sales.

that the first check correctly starts and ends. Similarly, the other pairs are related to the second and the third checks. The correct order of the checks is assured by the nesting of the ambients inside the client, which forces itemprice to be opened before creditcardnum, and creditcardnum before address.

On the other hand, an intruder is a process which tries to corrupt the casual chain, by skipping one of the checking phases. For example, the following intruder C3 sends his address directly to the Shipping process. In this way he receives the items without paying for them.

Let us now exploit the tool for what it was originally intended, that is, de- tecting information leakage. This security property is orthogonal to integrity, thus the results obtained are independent one another. Our starting point is the fact that the ordering information sent by the client cannot be disclosed to other untrusted users of the system. We model this fact by labeling as high ambients itemprice, creditcardnum, and address. Then, we apply the analysis of [5], also supported by the tool, to verify if the process is secure and, if not, which ambients should be labeled boundary in order to protect the system.

Notice that in order to exploit the static analysis technique to verify integrity we had to prove Proposition 3.3. In fact, we had to prove that, thanks to particular syntactic hypothesis on the processes, the over-approximation is limited. We are presently investigating a possible generalization of this result not depending on the particular system under analysis.

We thank Annalisa Bossi, Agostino Cortesi, Riccardo Focardi, Flaminia Luc- cio, and Sabina Rossi for their suggestions and comments. We also thank Riccardo Cannas, Stefano Filippone, and Enrico Pivato who were involved in the developing of the tools. Finally we thank Roberto Zunino for the useful discussion during the Mefisto meeting in Pisa.

