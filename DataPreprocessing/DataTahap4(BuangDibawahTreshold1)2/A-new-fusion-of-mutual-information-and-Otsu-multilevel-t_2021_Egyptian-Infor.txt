Hyperspectral imaging spectrometers are adept at collecting a huge number of bands with different wavelengths channels for a given spatial area on the topological surface and with huge cursed dimensionality. These bands contain high spectral information and can identify similar materials [1,2]. Every band of pixel value is continuous spectra with the different classes of labels present on it. Over the decades, researchers have stated that hyperspectral dataset creates the Hughes phenomenon effect which decreases the classification accuracy due to the high dimensionality of spectral bands with the redundancy of information [3,4]. The redundancy of information needs to be sorted to overcome the above difficulties by choosing any one of the two broad categorized concepts: 1) Feature extraction or 2) Feature selection methods.

Feature extraction techniques such as PCA (Principal Component Analysis) and ICA (Independent Component Analysis) are projected from the high to low dimensionality. Feature selection creates the subset from the original data to reduce the dimensionality with fewer features. In hyperspectral remote sensing, several bands are considered as features. The feature or band selection tech- niques involve selecting the highly informative bands, and that reduces the dimensionality and increases the classification accu- racy. This paper is a study of band selection methods.

uncertainty is MI [7]. There are many research studies employed MI techniques which often proved the high accuracy even with fewer bands. This paper concentrates on MI for band selection. The main contribution of the work is to select higher informative band from hyperspectral data with minimum number of selected bands and the classification method is used to prove the perfor- mance of proposed algorithm. The major advantages of the pro- posed algorithm for band selection include the reduction in false rate, delay in band selection and occurred higher accuracy com- pared to other previous works.

The rest of this paper is arranged as follows: Section 2 provides a survey of related works in the areas of hyperspectral band selec- tion and classification. Section 3 depicts the architecture of the mutual information and Otsu method (MI-Otsu) and also explains the proposed algorithm. Section 4 illustrates the results obtained from this work and provides relevant discussions on them. Sec- tion 5 concludes the paper with future work.

The adaptive measurement of MI concept is proposed by deriv- ing entropy and measuring the dependency of two random vari- ables by statistical methods for hyperspectral image fusion. AVIRIS hyperspectral dataset is experimented by selecting the dif- ferent cutoff of the bands with kernel classification techniques [8]. MI technique is enhanced by using the same experimental data and concentrating on the neighboring band to avoid redundancy with the application of complementary threshold technique. If the information retains the same mutual informative values in the adjacent band, then rejection of bandwidth will take place [9]. Spatial entropy based mutual information is introduced to collect highly informative bands, which is the extended version of Shannon entropy and mutual information. Spatial entropy is measured by intra-distance (average between pixels) and extra-distance (average distance of pixels) respectively [6].With the continuous effort from [8,9], the authors constructed an estimated reference map by applying mutual information for the experimental dataset AVIRIS Indian pines scene as the improved accuracy of 86.18% [10].

There are many approaches for the hyperspectral band selection on search-based methods. In this case, the hyperspectral bands are considered as a time series. Initially, clustering of spectral is done with training samples which offer the spectral curves for each class. The next step involved the creation of a candidate band sub- set using key points extracted from the spectral curves, and it fol- lows the search procedure. The last stage is to filter the spectral bands through conditional MI, and bound search algorithms are adapted to optimize the band information [11].The band selection techniques used to detect the blueberry fruit are the combined algorithm of Kullback-Leibler divergence with pair wise class dis- criminability, hierarchical dimensionality reduction, and non- Gaussianity. K-nearest neighbor, AdaBoost and Support Vector Machine are used for the classification and to test the performance of the above three algorithms [12].

Jeffries-Matusita distance method is used for maximizing the classes separability. Highly correlated neighbor bands are merged to select efficient bands. To find the performance for selected bands the bagger algorithm, SVM, and KNN (k-nearest neighbors) are used to classify the classes. Other than that, this work was extended by implementing a post-classification algorithm which helps to identify the misclassified pixels namely classification error correction [3]. The Interband correlation coefficient method is used to select the bands automatically and is followed by SVD (Singular Value Decomposition) and QR decomposition. The kernel classi- fiers GURLS (Grand Unified Regularized Least Squares) and are employed to analyze the performance of these algorithms [13].

The MIMR-DGSA (Maximum-Information-Minimum-Redun dancy - Discrete Gravitational Search Algorithm) adapts the vari- able bandwidth fast pair wise mutual information algorithm on enabling the neighborhood concepts to select the informative bands by increasing the hyperspectral bands entropy and by min- imizing the mutual information between hyperspectral bands in each subset. And it is depending on the MIMR criterion goal to increase the entropy of bands and diminish the mutual informa- tion between the bands in a subset. The effect of this is that the achieved classification accuracy is subject to high variance [21]. An efficient clustering method based on Shared Nearest Neighbor (SNNC) to select the most representative bands from the original HS has also been introduced [22]. Based on improved subspace decomposition (ISD) and the artificial bee colony (ABC) algorithm, a band selection technique known as ISD-ABC to address the prob- lem of dimensionality reduction in HIS (Hyperspectral Image) clas- sification is executed. Subspace decomposition is achieved by calculating the correlation coefficients between adjacent bands and using the visualization result of the HSI spectral curve. This provides good classification accuracy compared with six other state-of-the-art band selection techniques [23].

In [24], multi objective based models helps to identify the hyperspectral band subsets with the different number of bands. The hyperspectral bands are selected by using Weakly-pareto- Optimal problem along with the novel boundary intersection adap- tive penalty based approach. Basically there are three steps involved in the multi objective hyperspectral band selection method are the initialization of the subset, through the iteration the ideal point need to be identified and the current population and ideal points need to be updated. To select the highly potential hyperspectral bands can be identified by estimating Gaussian and triangular objectives functions to invoke the similarity fuzzy rela- tionship through various parameters. The information measure (IM) is involved to reduce the uncertainty of hyperspectral bands and the highly mutual informative bands helps to classify the class labels well. Thus [25], combines both IM and Fuzzy rough set (FRS) to select the potential bands. In [26], Spectral and spatial pixel information of hyperspectral band correlations are measured through the double graph model, then Maximum information and minimum noise (MIMN) criterion is used to increase the max-

imum entropy of bands by reducing the noise. Then the determi- nantal point process (DPP) search algorithm helps to identify the subset of the hyperspectral bands. Thus [26] developed the MIMN-DPP algorithm by combining both MIMN and DPP to select the highly informative bands to improve the classification accuracy.

Recently, the cluster based mutual information approaches are used widely for hyperspectral band selection. In [27], the weighted entropy and the mutual information are calculated for hyperspec- tral bands and then the K-Means and Fuzzy-K-means pre- clustering algorithms are adapted to select the highly informative bands. In [28], the objective functions such as normalized cut criterion (NC)/top rank cut criterion is measured to develop the Optimal Clustering Framework (OCF) for hyperspectral band selec- tion. The cluster Ranking strategy is applied with NC-OC-MVPCA (Maximum-variance principal component analysis) is used to determine the potential bands. In [29] ONR (Optimal Neighboring Reconstruction) method was developed by introducing the neigh- boring reconstruction based criterion objective function to identify the highly correlated bands and then based on the search strategy the optimal hyperspectral bands are identified. In [30] S&M (Split and Merge) method developed for hyperspectral band selection by without infringing the spectral data which means of spatially, the adjacent bands are split to find the potential sub-bands. These potential sub-bands are again merged to reduce the dimensional

The literature study of information theory in band selection shows that MI plays a major role in band selection over the decade which often shows the proven result. This research study took the Shannon entropy based mutual information. The hyperspectral data contains several number of bands Bi {where i = 1: n}. The first step is to estimate the probability using normalized distribution for each band. Consider the P(x) and P(y) is the probability distribu- tions for Bi and Bi + 1 respectively. Then the entropy is estimated using three entropy measures such as Joint, Conditional and Relative.

adjacent bands using joint, conditional and relative. There are 199 mutual informative bands are generated with respect to the entropy measure. The Otsu multilevel thresholding technique is applied to find the highly informative bands from an estimated 199 MI bands. The training samples are taken from the AVIRIS

AA (Average Accuracy) and Kappa statistics for different set of arbi- trary training samples fed in the SVM classifier. Grass pasture mowed achieves high accuracy of 100% even with all training samples per class. Stone steel towers class achieves 100% of accu- racy in 40 and 50 training samples per class. All other classes in the relative entropy achieve more than 60% with the all training sam- ples in each class. The accuracy achieved for relative entropy using

for high accuracy with less selected bands. Three different entropy measures are employed for hyperspectral band selection. The selected bands for joint, conditional, and relative entropy with mutual information are 94, 78, and 36 respectively. The experi- mental study on the AVIRIS dataset concluded that with less selected bands, the SVM classification technique could be employed to justify the performance. The relative entropy MI_Otsu algorithm offers high accuracy of 92.16% when compared to the other two entropy measures, OCF, ONR and S&M methods. The pro-

posed joint and conditional entropy MI_Otsu classification accura- cies are near to the relative entropy MI_Otsu are 91.64% and 92.04% respectively. Also, the results on individual classes of accu- racy indicate that there could be a potential issue on spectral unmixing in a pixel which would lead to lower accuracy. In the future, this research work taken to the further novel extraction or classification with the selected bands and nonlinear spectral unmixing will be considered to improve the classification better.

