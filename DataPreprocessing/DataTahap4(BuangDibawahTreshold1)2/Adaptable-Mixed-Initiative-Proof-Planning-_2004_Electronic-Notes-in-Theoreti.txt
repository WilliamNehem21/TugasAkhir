In this paper, we present proof planning as back-engine for interactive proof exercises as well as an interaction console, which is part of our graphical user interface. Based on the proof planning situation, the console offers suggestions for proof steps to the learner. These suggestions can dynamically be adapted, e.g., to the user and to pedagogical criteria using pedagogical knowledge on the creation and presentation of suggestions.

The structure of the article is as follows. After a brief introduction to proof planning and to ActiveMath in Section 2, we introduce in Section 3 four learning scenarios for the application of a proof planner. In Section 4, we focus on the realization of one scenario, the interactive proof planning scenario, and on examples of its usage. In particular, this section explains how exercises can be adapted to particular learners and how suggestions are presented in an interaction console. This console together with a multi-modal display of the partial proof plan is our current GUI for proof exercises. Section 5 contains a summary and future work.

To structure the repertoire of proof planning methods and make the proof planning process more hierarchical, strategies have been introduced [9]. A simple proof planning strategy is specified by a set of methods and search heuristics. Different proof planning strategies correspond to and implement different proof ideas.

The proof planner has an automatic and an interactive mode. In the auto- matic mode the proof planner searches for a solution proof plan, i.e., in each intermediate state it searches for applicable methods and valid instantiations. Mathematics-oriented heuristics guide this search. In interactive proof plan- ning, the user has to make all the search decisions and these include the choice of strategies and methods and the instantiation of meta-variables.

The command suggestion mechanism is not restricted to the creation of suggestions of tactic applications. In Section 4, we describe how we use the same mechanism in order to create suggestions for method applications as well as suggestions for meta-variable instantiations. Moreover, note that it is not necessary that there are agents for each argument of a command applying a tactic (or a method). If an agent for an argument is missing, then all created suggestions are partial, and the user has to specify the missing parts.

All these scenarios need a corresponding appearance in the proof GUI. For instance, the GUI-objects and functionalities of interactive proof planning and island planning differ. User-adaptivity to the learner and the context is our key design goal for the educational tool that is based on our proof planner.

ferent ideas for proving. That is, different strategies, which comprise different methods, tackle a proof planning problem in a different way. If a strategy is selected for the problem at hand, then there has to be at least one command and corresponding agents for each method of the strategy.

Author-specified commands and agents can also provide over-specified sug- gestions. An over-specified suggestion comprises not only the specification of all input necessary to apply a method but also (parts of) the results of the application of the method (i.e., new assumptions and goals in the proof state resulting from the application of the method). For example, consider a method

that uses a Computer Algebra System to simplify a term in a goal by per- forming arithmetical simplifications. The automatically generated command comprises only one argument, the goal to which the simplification should be applied. An author who wants to teach the learner to perform the simplifi- cations can specify a command with an additional argument for the result of the simplification. Then, the learner has to provide input for this argument in suggestions for the application of the method and the result of the method application can afterwards be compared with the input of the learner.

The automation of the application of certain methods avoids bothering the learner with the specification of proof steps, which she already knows. Meth- ods that decompose logical quantifiers and connectives are typical examples for automated methods. Moreover, methods that perform some normalization or re-writing of assumptions and goals can be applied automatically, in case the learner is diagnosed to understand the outcome of these methods.

choosing a method from a list causes less distraction from the actual learning and understanding of proof. However, in certain learning situations and for certain learners it may be important to remember a method or to look it up in the course material before using it in a proof. That is, choice menus are not always appropriate (similar to multiple choice questions which may not serve the learning purpose enough).

The current GUI does not adapt the presentation of proofs, suggestions, and feedback to the needs of different learners. This will be the goal in the near future. Moreover, we are currently examining possibilities for the automated generation of faulty and over-specified suggestions.

