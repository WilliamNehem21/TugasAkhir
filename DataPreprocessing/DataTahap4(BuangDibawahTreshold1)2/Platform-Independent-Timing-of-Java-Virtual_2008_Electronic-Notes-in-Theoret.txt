The remainder of this paper is structured as follows. Section 2 documents back- ground and related work undertaken in this field and Section 3 documents our experimental design and methodology. Section 4 presents and analyses our plat- form independent instruction timing results and Section 5 compares these results against results acquired using the RDTSC assembly instruction. Finally, Section 6 concludes the paper and identifies some future areas of research on this topic.

We can model this quantisation effect using standard statistical techniques to achieve high resolution timing in the presence of low resolution clocks. Lilja doc- uments the use of Bernoulli trials to achieve high resolution timing [18]. Beilner presents a model of event timing and presents timing results using his technique for the times taken to pass a message between two processes [4]. Danzig et al. use the technique to develop a hardware micro-timer to time machine code executing on Sun 3 and Sun 4 workstation [9].

In contrast, work on bytecode timing is relatively sparse. Herder et al. present the results for Java bytecode timing, although, the technique used to gather such results is not documented [13]. Wong et al. present a technique for the measure- ment of bytecode execution times, although, the final technique is not platform independent and relies on native method invocations [26].

The analysis of machine level instruction execution timings has also been un- dertaken. The work of Peuto et al. was directed toward the production of an instruction timing model to model CPU performance measurements [20]. Architec- ture manufacturers such as Intel and IBM also detail the execution time in clock ticks of the machine instructions associated with their architectures.

Albert et al. propose a framework for the cost analysis of Java bytecode [1]. This technique involves transforming the iterative bytecode structure to a recursive representation, and inferring cost relations from this representation. In [2], Albert et al. apply their previously proposed framework to Java programs that include operations such as: recursion, single loop methods, nested loops, list traversal as well as dynamic dispatching.

Stark et al. presented a decomposition of the JVM into a number of sub-machines [22]. Each sub-machine has the ability to execute particular subsets of the JVM instruction set. We also adopt this approach, by concentrating on individual cores of the JVM and their respective programming paradigms, and believe that a clearer understanding of the interaction of a Java application and JVM can be gained. In particular, we concentrate on reporting timing results of the 137 JVM instructions that compose the imperative core of the JVM.

The platform independence of our technique is insured by using only standard Java library timing methods. There are two timing methods available for consider- ation: System.currentTimeMillis and System.nanoTime. Our choice was based on timing precision and accuracy and as such the former of the two was chosen. This choice was made as System.nanoTime cannot guarantee nanosecond accuracy. All Java timing classes, containing the JVM byte code instruction to be timed, were engineered using the byte code engineering library (BCEL) [3].

All experiments conducted where carried out on a Rocks Linux cluster containing 100 nodes. Each node contained one 1.13GHz Intel Pentium III dual core processor with 1Gb of RAM and a cache size of 512Kb running the Linux CentOS operating system release 4.4 (kernel version 2.6.9) executing at run level 3 with no X-Server. The Sun Java(TM) 2 Runtime Environment, Standard Edition (build 1.5.0.07-

The identification of a number of groups of instructions, where each instruction within a group exhibits similar execution time, would help in reducing the dimen- sionality of any timing model dependent on knowing the execution time of each JVM instruction. In performing the cluster analysis we choose a granularity value as a cut-off point, so that when the instructions in a cluster differ by less than the granularity value we do not subdivide them further. Thus there is a trade-off: small granularity values give better accuracy at the cost of a larger number of groupings.

In this paper we have presented a technique for the timing of Java bytecode in- structions that is platform independent. We have investigated the effect of timer overhead and the importance of subtracting this quantity from instruction timings. We have characterised the execution times of all Java imperative instructions. We have considered the clustering of instructions based on their execution times and finally we have presented a comparison of our technique against instruction timings acquired using the RDTSC assembly instruction.

The contributions of this paper are: First we have presented a technique that statistically estimates the execution time of Java instructions within a particular confidence level. In particular, we can quantify the error associated with each instruction timing. We have characterised instruction execution times and have identified a group of imperative instructions, primarily floating point conversion instructions, that execute considerably slower than all other instructions. We have presented a technique that clusters instruction timings within a predefined granu- larity. Finally we have identified a strong positive linear relationship between in- struction times acquired using our statistical method and those acquired using the RDTSC assembly instruction. We have modeled this linear relationship and have identified that platform independent instruction timing analysis under estimates the execution times of instructions by approximately 23%. However, the strength of the linear model still allows us to accurately calibrate the measurements.

For future work, we intend to quantify the effect of processor pipelines and cache miss rates on instruction timings. We also intend to carry out our experiments on different platforms and investigate the correlation of results acquired from different JVM implementations. We also intend to extend our instruction timing model to include instructions from within other cores of the JVM. As part of future work we also intend on applying our results to existing JVM models. In particular, we intend on using our instruction execution times, as part of a larger model to predict the execution times of Java applications.

