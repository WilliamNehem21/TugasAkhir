In recent years, many re-id methods for video surveillance ap- plications have been proposed. Generally, they can be classified into two categories [1]: feature representation and matching strategy. For feature representation, researchers mainly focus on generating robust and efficient body appearance representation using infor- mation such as color [2] and texture [3], since in surveillance environment the captured RGB images are usually in low- resolution. For matching strategy, metric learning [4] and learning to rank methods are explored a lot. And methods based on metric learning achieved good performances.

Although these multi-modal methods achieved good perfor- mances on public dataset, these methods might obtain unsatis- factory performance on handling relatively varying environments for two reasons. On one hand, most conventional approaches usually learn the similarity metric model offline, so that they cannot adapt to new scenes which are significantly different from the training data, caused by varying illuminations, camera views, backgrounds. On the other hand, blindly combining a bunch of features to calculate person similarity is prone to error accumula- tion, and also brings unnecessary computational cost.

To overcome the drawbacks of above methods, an effective online re-id framework is proposed in this paper. Based on obser- vations, clear face images contain more reliable and distinguishing information but may be difficult to obtain in many situations such as people with his back to the camera. While, body images are more ambiguous but are usually easy to capture. Therefore, the face and body images are complementary.

Secondly, the metric model is learned offline using labeled training data. Then, the face information is utilized to update the metric model online. Finally, the feature similarities are fused by feature funnel model which is based on the degree of feature reliability.

The rest of this paper is organized as follows. In section 2, the related works are reviewed. In section 3, our method is presented in its main components: features extraction, online metric model update and feature funnel model. In section 4, experiments run for assessing the performance and comparing our method to the state- of-the-art methods are discussed. Finally conclusions are drawn in Section 5.

Appearance-based methods are easily impacted by varying en- vironments such as illuminations, and geometric method has low inter-class variability. Thus, re-identifying persons only relying on a single source of biometric information can actually be difficult. For this reason, multimodal biometric systems are adopted to make re- id more reliable.

Many multimodal systems have been proposed which can be classified into two categories [13]: One approach is to fuse infor- mation at feature level [14,15] by concatenating the feature vectors as final feature. However, this method often overlooks the reli- ability differences between different features. The other is to fuse information at score level [6,7], i.e. combining the scores of different sub-systems, and our feature funnel model belongs to this type.

vision applications [16], since they can utilize both labeled and unlabeled data in classifier training [17] to improve the perfor- mance using unlabeled data. P-N learning [18] is an effective semi-supervised learning method which is guided by positive (P) and negative (N) constraints restricting the labeling procedure of the unlabeled set. In this paper, we adopt P-N learning in our online re-id framework to utilize the clear face images to improve the metric model online. Through face information, the measured-error examples are screened out to retaining the metric model and make the metric model adaptive to new environment.

Primarily, each person is described by appearance and geo- metric features utilizing skeleton information. Then metric models are updated for each feature modality. The concrete steps of online metric learning are follows: (I) Train the initial metric model offline using labeled data; (II) Measure the similarities of unlabeled data pairs obtained online with metric model; (III) Label the unlabeled data pairs whose measure results are inconsistent with reliable face verification results; (IV) Extend the training set with the new labeled data; (V) Retrain the metric model. Finally, the feature similarity is obtained by our feature funnel model which will be explained in 3.3.

The first step of our framework is to extract features which are robust to varying illumination and pose. Inspired by Ref. [11], we extract features around person skeletal joints to overcome pose variation. In order to overcome illumination varying, we adopt noise-insensitive appearance-based features and illumination- invariant geometric features.

Pattern (SILTP) [19] histograms are extracted from each joint. SILTP is an improved operator over the Local Binary Pattern (LBP) [20]. LBP is a gray-scale invariant texture feature, but is susceptible to the noises. In order to overcome this drawback, SILTP introduces a scale invariant local comparison tolerance, achieving invariance to

Face contains more powerful information for person identifi- cation than body appearance. Besides, face verification research has achieved highly reliable performance on large unconstrained LFW dataset [22]. Additionally, towards re-id on robot platform, captured face images are usually in high resolution compared to surveillance environment. Thus, we use face information to update the metric model online.

improvement on the IAS-Lab is more obvious than on the RobotPKU RGB-D dataset. This is due to the obvious scenery variation. How- ever, it is not obvious on SILTP owing to SILTP is insensitivity to varying illumination. In general, the online update strategy can adapt to the new environment than offline strategy.

In this paper, we present an online re-id learning framework. To overcome the drawback of offline training, that metric model can not well adapt to the changing environment, face information is utilized to update metric model online. In particular, the face in- formation is used to find measured incorrect examples, then these examples are added to training set to update metric model. In

This work is supported by the National Natural Science Foundation of China (NSFC, nos. 61340046), the National High Technology Research and Development Programme of China (863 Programme, no. 2006AA04Z247), the Scientific and Technical Innovation Commission of Shenzhen Municipality (nos. JCYJ20130331144631730), and the Specialized Research Fund for the Doctoral Programme of Higher Education (SRFDP, no. 20130001110011).

