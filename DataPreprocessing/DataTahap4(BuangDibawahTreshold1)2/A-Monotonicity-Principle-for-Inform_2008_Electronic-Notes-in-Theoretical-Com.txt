Apart from their use in information theory, the notions of channel and capacity have been proven quite useful in the area of security. It has been shown that in many scenarios, systems or protocols can be fruitfully viewed as channels, and the capacity of these channels can be regarded as a measure of the security guarantees of the system. Techniques from information theory have been applied to a broad range of security fields, including those of information flow ([12,4]), quantum cryptography ([15]), anonymity ([13,3]) and trust ([14]).

However, an important drawback of capacity is its complexity. Despite its sim- ple definition, there is no analytical formula that gives the capacity of a discrete channel in the general case. It can be only computed approximately using numerical algorithms such as the Arimoto-Blahut algorithm ([5]). And even in simple cases where an analytical formula does exist, for example in the case of binary channels having only two inputs and outputs, it is complicated and difficult to use in practice. For example, in many problems we need to be able to predict how a channel will perform, but find that its noise matrix varies with several parameters that depend on random aspects of the environment which arise during the transmission. In such cases we cannot compute the capacity of the channel, but we would still like to obtain bounds on it or compare the performance of different classes of channels. The resulting formulae, however, make this goal very challenging.

It is thus natural to seek tools that allow high-level reasoning about capacity. Developed in a recent line of work, algebraic information theory ([11]) offers such tools for binary channels. In that work, studying the relation of order, algebra and topology, a domain of binary channels is considered and it is shown that capacity is Scott-continuous, providing a tool to compare channels. Moreover, in [9] it is shown that capacity is a measurement on this domain.

As a case in point, we derive a lower bound on the capacity of a hidden channel within quantum key distribution in the presence of noise. Previously, a bound was known ([8]) only for the case where the noise is due solely to eavesedropping, in which the noise matrix has a simple symmetric form. We establish a fundamental theoretical limit of 1 H(1/4) 0.18 for the case of arbitrary noise caused by any combination of eavesdropping and/or environment. Our results also make it clear that there is a best way to interrupt this hidden communication, and they even tell us what this way is.

Because Theorem 3.1 can be applied to any line that ends on a minimum capacity channel, it provides a powerful technique for comparing the capacity of channels. One immediate application of it is that we can solve the capacity reduction problem for arbitrary (m, n) channels. In the capacity reduction problem, we have an (m, n) channel x and would like to systematically obtain a channel whose capacity is smaller by some specified amount. The monotonicity principle offers a solution:

By contrast, rx is monotone with respect to , but lx is not. The reason for this difference is that P x  x P holds for all x P, and this inclusion is strict. So even though P is not commutative, it has a special property commutative monoids have which ensures that both lx and rx are monotone with respect to . The monotonicity of lx and rx implies that

Intuitively, the Euclidean distance det is a canonical upper bound on capacity. Our goal now is to prove this. First, det is determined by its value on the set N of nonnegative channels. Next, as a function on N, it preserves multiplication, convex sum and identity. There are only two functions like this in existence:

Earlier we studied partial orders on binary channels, each offers a different way of relating a pair of channels to one another. We then jumped up a level of abstrac- tion and studied relations that exist between fundamental monotone mappings on binary channels. However, the partial orders are not merely partial orders, and the monotone mappings are not merely monotone. In each case, more mathematical structure is present, and by taking this additional structure into account, a new relation between capacity and distance emerges. This one is topological.

Definition 5.11 Let (P,  ) be a partially ordered set or poset. A nonempty subset S   P is directed if ( x, y  S)( z  S) x, y  z.  The supremum  S of S   P is the least of its upper bounds when it exists. A dcpo is a poset in which every directed set has a supremum.

ordered by reverse inclusion with an explicit isomorphism given by N  I[0, 1] :: (a, b)  [b, a]. This correspondence implies that N forms a domain, called the interval domain, where  S =  S, for directed S  I[0, 1] and x  y iff y  int(x). Notice that int(x) refers to the interior of the interval x in its relative Euclidean topology.

In this section, we will learn a few of the fascinating implications the results in this paper have within the realm of communication. We first review the basic protocol for quantum key distribution. Because we intend for this paper to be readable by someone with no prior knowledge of quantum mechanics, we discuss only the minimal background needed to understand quantum key distribution. The few ideas we make use of are very simple.

Like all systems, a quantum system has state. The state of a quantum system is represented by a unit vector in a vector space that has a lot more structure than most, known as a Hilbert space. The state of a quantum system is also called a ket. Here are two examples of kets: 0 and 1 . It is useful to think about these two particular kets as being quantum realizations of the classical bits 0 and 1. Each refers to a legitimate state of a quantum system. A photon is an example of a quantum system and its polarization (state) is something we need kets to describe.

Is Bob guaranteed to receive the information sent by Alice? No. There are many reasons why. Suppose an eavesdropper just happens to measure only the qubit that holds the information in the wrong basis, then there is a 50 percent chance that Bob has the wrong bit, even though he believes he has the right bit. Or suppose that background light acts as noise which causes the information bit to flip. In either case, Bob would have no idea, and neither would Alice. But chances are good that such errors, whether caused by the environment or an eavesdropper, would also manifest themselves in the check bits as well, which would then enable them to estimate the likelihood that their attempt to communicate will succeed. Alice and Bob always have the option of aborting the protocol if their chances of success are not deemed high enough. The question we want to answer is: what is the capacity of this channel?

X and Z bases at random. Or suppose some of the noise is caused by the en- vironment. Then it is no longer necessarily the case that 1 and 0 flip with the same probability, so whatever the noise matrix of the hidden channel is, we know that it is not necessarily binary symmetric. For instance, a well-known effect like

