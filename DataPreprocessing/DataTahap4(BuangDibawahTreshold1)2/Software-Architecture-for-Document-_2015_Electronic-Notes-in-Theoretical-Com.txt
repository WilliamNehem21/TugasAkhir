Document management is the set of activities for the creation, reception, orga- nization, storage, preservation, access and dissemination of documents within an organization [20]. Through the use of technology it is possible to improve man- agement and maximize the value of the huge amount of information within those documents. In this context, two apparently conflicting interests arise: organizations must ensure confidentiality of the personal information they handle, but restricting access to such information is not a valid alternative. This happens whenever the

organization needs to make available much of their information, either because of transparency or because the stored documents have a scientific, biomedical or legal value which has no relation with the personal information contained within them. A solution to this problem is document anonymization, i.e. the total or partial replacement of personal data by eliminating any reference to their identity, without altering the value or usefulness of the original document [6]. Such anonymization can be manually performed by a user, being tedious, repetitive, error-prone and time consuming, not providing added value to the organization. This problem has driven research and development of techniques and methodologies for (semi)automatic

The rest of this paper is structured as follows. In Section 2 we introduce the main aspects concerning document anonymization. In Section 3 we present the main architectural initiatives addressing this problem and we describe their common and special features. In Section 4 we describe our proposal and in Section 5 we present the development of a prototype of the reference architecture and its application on a case study. Finally, in Section 6 we present the main conclusions and some ideas for future work.

organization. In fact, there are regulatory and legislative basis that expose the dis- semination of personal data to civil and criminal penalties. Particularly in Uruguay there is a law of personal data protection [5] regulating the responsibility for the protection of personal data held by citizens or legal persons. Among other things, the law determines what kind of information is public (e.g. name, surname, ID) and what kind information is defined as sensitive data (i.e. data revealing racial or ethnic origin, religious or moral convictions or information concerning health or sexual life) and therefore need the consent of their owner to be published.

The definition of public or sensitive data is context-dependent and thus vary according to the domain of interest and country. For example, the Uruguayan law which protects personal data within medical records [5] states that the medical record is owned by the patient, it must be reserved and can only be accessed by the medical care and administrative personnel in a direct relationship with the patient, the patient itself or his family, and the Ministry of Public Health if necessary. How- ever, HIPAA (Health Insurance Portability and Accountability Act) in the United States [3], that regulates similar aspects, defines that a hospital can use patient data for research without consent, if a process of depersonalization of the information is done.

Beyond the restrictions, depending on the nature of the business domain of an organization, their documental databases are a source of knowledge that can be used by other organizations or individuals, sometimes with a huge scientific, social or technical benefit, since documents have an intrinsic value that is independent of the confidential information contained therein. Examples include e-government, biomedical sciences (e.g. medical records management) and judicial areas. In re- sponse to this problem is that anonymization arises.

The anonymization is focused on the preservation of the confidentiality of per- sonal data, without modifying the value or usefulness of the documents. An ac- cepted definition of anonymity is in the Law 14/2007 of Spain [6] with respect to biomedical research. This law defines anonymization as the process by which it is no longer possible to establish by reasonable ways the link between data and the subject to which it is related. There are two levels of anonymization: irreversible and reversible. Irreversible anonymization involves removing any information that can identify an individual or organization without the possibility of recovering it later. Meanwhile, with reversible anonymization (also called depersonalization) sen- sitive information is cross-referenced with other information such that an authorized entity can re-identify the anonymized information.

The anonymization process must preserve the useful content of the document and maintain its semantic coherence. In this sense, it is desirable that when for example the name of a person is identified as sensitive information, the anonymization process must replace each reference to that person with the same generic term. Beyond that, the name could appear written in different ways, e.g. it is common to refer to a person initially with its full name and then only with its last name or initials. The anonymization process must combine these terms in a single entity (Named Entity [14]), in order to keep the consistency of the original document. It is also

desirable to identify if the entity was a name, a geographic location, a date, etc., before the anonymization process begins. In this case the generic term must also refers to this fact in order to preserve even more the meaning of the document.

There are other proposals that provide a partial solution to the problem, basi- cally following the same approach as before, but with some differences. Free software HIDE [10] uses a labeling process for linking all sensitive information to an entity (age, address, name of a person, etc.) and lets you select a strategy for full or partial anonymization of some critical attributes. On the other hand, other natural

language processing tools can be used, such as a morphological tagger, which basi- cally label the terms in a text by assigning a list of grammatical categories. In [8] a morphosyntactic tagger for Spanish language is presented that incorporates the use of heuristics to determine the nature of words processed by the morphological analyzer with higher accuracy. The author also proposes a heuristic of great interest for the anonymization process for the identification of proper names using a long list of names of people, towns, cities and countries. For the identification of the proper name, the heuristics consider the appearance of the word in any of these listings, the presence of a capital letter at the beginning of the word, the position of the word in the sentence, the fact of been recognized by the morphological analyzer or not, etc. An additional aspect, not specifically shown in any of the surveyed architectures is about the identification of co-references, which consists in applying a clustering technique to identified entities [18], e.g. group the full name of a person

In every proposal, the main component is the Named Entity Recognition (NER, [14]) that recognizes and labels entities of interest in the text. There are several NER tools [21,15,17], with more or less levels of accuracy in their results. Some of them also provide additional features such as the classification of entities. It has sense to think about an architectural in which it is possible to adapt and interchange these NER tools. In addition, every proposal identifies a component that performs the final processing of the text (Anonymizer). Specializations of this module must also be considered, as the anonymization process may be reversible or irreversible,

Some of the approaches propose the concept of feedback after processing entities. One of them (MOSTAS) proposes a post-processing of the results using a spell checker when some elements were not identified. It would be desirable in a reference architecture that these potential post-processing steps have similar input and output interfaces, so that individual components may be added and removed as if they are links in a chain. Likewise, it is desirable to apply heuristics or group entities. Another approach is to allow an expert to identify the type of errors made by the NER component using some user interface and provide feedback to improve training of the NER component.

OpenCalais [17]. It is a semantic processor of unstructured documents devel- oped by Thomson Reuters corporation, allowing, among other things, to identify and classify named entities. Free access is provided for both personal and com- mercial use through web services. It has some limitation in terms of a maximum number of queries per day allowed for each registered user. In some tests performed with this utility, we observed very good effectiveness in the identification of named entities, which coincides with the results of the study conducted for NER systems in [13].

LingPipe [1]. It is a commercial framework that can be integrated into other applications, providing a wide range of services such as grammatical tagging, recog- nition of named entities, clustering, spell checking, among others. LingPipe can be used free of charge for academic purposes.

The Judiciary of Uruguay publish jurisprudence information of the Courts of Appeals and the Supreme Court to citizens through the BJN system (Base de Jurisprudencia Nacional [4]). In such system, the identity of organizations and in- dividuals is protected when it comes to certain types of legal proceedings. Such is the case for example of the identity of minors in proceedings related to fam- ily. Anonymization techniques are used to guarantee confidentiality. However, the process is manually performed by court officials who read each of the statements, identify sensitive data (named entities) to be anonymized, and finally replace such information with generic terms.

For the purpose of testing the prototype, we take a set of judicial sentences which are publicly available in the BJN system (not anonymized) and we execute the automatic anonymization process. We got mixed results. In some cases the system had good levels of recognition of named entities and sensible data, and in others we found false positives. One of the sources of error is that within these sentences it is common to use capitalized terms that are not necessarily named entities. These could be listed and excluded from the anonymization process using rules and patterns. In addition, sentences contain many references to literature or authors related to the law, which can be erroneously identified as sensitive data, affecting the semantics of the document to be anonymized. It is also common to find Latin terminology, which confuses the tools when they are trained over a Spanish corpus. These problems can be solved with a better training of the tools we use. We can also include a validation step taken by an expert user (already supported

We have shown how this kind of systems can be developed with reasonable costs, since there are available tools to perform various tasks of the anonymization process, such as the recognition of named entities and clustering. The prototype was implemented using open-source technologies and it is focused on the anonymization of jurisprudence of the Judiciary of Uruguay. We observed that it is feasible to apply a semi-automatic process and that it speeds up the traditional anonymization process. However, court decisions have peculiarities for which the recognition of named entities based on models trained using generic corpus, do not provide good results. In this sense, it is interesting to explore the use of a specific corpus to get better results in this application domain and language. Furthermore, it is possible to optimize the process by identifying rules and patterns that apply to this kind of documents. For example, a domain expert could identify terms to exclude from entities recognition. This kind of custom processing is already supported by the reference architecture.

